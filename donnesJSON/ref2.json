{"abstract": "Results from propagation measurements, conducted in an indoor office environment at 2.4, 4.75, and 11.5 GHz, are presented. The data were obtained in small clusters of six measurements, using a coherent wideband measurement system. The channel characteristics for the three frequencies are compared by evaluating path loss, rms delay spread, and coherence bandwidth. An analytical model for evaluation of the bit-error rate (BER) of the stationary frequency selective indoor channel is developed for a coherent binary phase shift keying (BPSK) receiver, based on the complex impulse response of the channel. Computational BER results are obtained for data rates up to 50 Mb/s, using the measured multipath channel impulse responses. The BER results for a number of clusters are presented and compared for the maximum reliable data rate as inferred by the measured rms delay spread of the channel.", "authors": ["Gerard J. M. Janssen", "Patrick A. Stigter", "Ramjee Prasad"], "n_citation": 238, "references": ["5f90c5b9-273e-4927-aa8d-3ac7101ee81f"], "title": "Wideband indoor channel measurements and BER analysis of frequency selective multipath channels at 2.4, 4.75, and 11.5 GHz", "venue": "IEEE Transactions on Communications", "year": 1996, "id": "47b6b7ee-1947-453a-b664-e2e1f9f31def"}
{"abstract": "Loops with multiple-exits and flags detract from the quality of imperative programs. They tend to make control-structures difficult to understand and, at the same time, introduce the risk of non-termination and other correctness problems. A systematic, generally applicable procedure, called loop rationalization, which removes such features and logically simplifies loop structures is presented. This method, which is founded on the principle of separation of concerns, employs strongest postcondition calculations and congruent equivalence transformations to improve loops. A byproduct of the process is that it detects a range of defects such as unreachable code and a class of non-termination problems.", "authors": ["S. Pan", "R.G. Dromey"], "n_citation": 50, "references": ["02e0342a-33d3-4d3f-9f1d-b14081edbc39", "0ef582cb-9c7b-4737-b0fc-56007bf64840", "3e463040-e697-4c3c-a555-5635b90ef134", "79ddfd98-ef81-4a4a-879c-dff0ee3dad21", "95a82a7f-b1ba-493b-ac66-0702e95ec731", "d09f7451-5342-4b5a-aac6-01c4449ed097", "e4755a3a-68bb-4440-9f5f-1395d05f4323"], "title": "Re-engineering Loops", "venue": "The Computer Journal", "year": 1996, "id": "8ddc5f94-7228-4779-b742-19713e8f36f7"}
{"abstract": "Connectivity is an important property for QoS support in mobile ad hoc networks (MANETs). Recently, there has been a big effort in exploring the critical transmission range (CTR) analytically, based on different network models. While most of these studies rely on a geometric model and come up with asymptotic bounds, their significance regarding finite 802.11 based MANETs is unclear. In this paper, we investigate connectivity in MANETs from a layered perspective. We first point out how the transmission range affects the end-to-end connection probability in a log-normal shadowing model and compare the results to theoretical bounds and measurements in the path loss model. We then show how connectivity issues behave in 802.11 and IP based networks if the fading effect increases. The paper concludes with an analytical model for the link probability in log-normal shadowing environments as a function of the number of nodes, network area, transmission range, path loss exponent and shadowing deviation.", "authors": ["Patrick Stuedi", "Oscar Chinellato", "Gustavo Alonso"], "n_citation": 64, "references": ["0d4d0363-07b5-43b6-976d-955e96044709", "21c6d8ec-a7dd-4dbd-88c1-89dbb0d9189a", "314c5a50-5eb8-4377-9861-e4367ff86462", "40c44a88-a009-477d-a5ad-0158479567ca", "624b1173-cf98-4faa-9b22-6f067e1f73c7", "6a7ce1b5-fcee-4a2a-8bc0-5ce9dbf09fcc", "8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae", "92ed2e2c-f127-4094-a840-122cefbe775e", "a829e1b5-90fb-4280-8e93-bf4401e45caf", "e1aec8d9-e4a4-4fbb-b76b-227a00c69a6c"], "title": "Connectivity in the presence of shadowing in 802.11 ad hoc networks", "venue": "wireless communications and networking conference", "year": 2005, "id": "f7884d6d-5d39-433b-b930-8690519e988e"}
{"authors": ["Kevin D. Ashley", "Vincent Aleven"], "n_citation": 50, "references": ["059f8c76-0d30-43f9-a94b-c667e30f832b", "1718abe8-9c3c-4879-88b4-b2ebb3fecce6", "86a76be8-0112-4780-a39d-4651d642bc1c", "8c269ab0-9017-4359-9fa2-1b9f9ab96791", "a49ff97a-d5c2-49b2-ae44-d9b9c1017f7d", "a4f33572-378b-45ca-93a3-428259063cef", "b2e15a7e-18d2-4ebb-9b3c-27bd7b972545", "c096e998-a73f-4ec4-85ac-976346b40a91", "cb9b9943-4898-4632-a285-ab0c69360043", "f3530f67-994c-4569-b8eb-76104eca3b36"], "title": "A Logical Representation for Relevance Criteria", "venue": "", "year": 1993, "id": "127a352a-f645-4fef-9626-fd8400cfe5a6"}
{"abstract": "In personal communications applications, users communicate via wireless with a wireline network. The wireline network tracks the current location of the user, and can therefore route messages to a user regardless of the user's location. In addition to its impact on signaling within the wireline network, mobility tracking requires the expenditure of wireless resources as well, including the power consumption of the portable units carried by the users and the radio bandwidth used for registration and paging. Ideally, the mobility tracking scheme used for each user should depend on the user's call and mobility pattern, so the standard approach, in which all cells in a registration area are paged when a call arrives, may be wasteful of wireless resources. In order to conserve these resources, the network must have the capability to page selectively within a registration area, and the user must announce his or her location more frequently. We propose and analyze a simple model that captures this additional flexibility. Dynamic programming is used to determine an optimal announcing strategy for each user. Numerical results for a simple one-dimensional mobility model show that the optimal scheme may provide significant savings when compared to the standard approach even when the latter is optimized by suitably choosing the registration area size on a per-user basis. Ongoing research includes computing numerical results for more complicated mobility models and determining how existing system designs might be modified to incorporate our approach.", "authors": ["Upamanyu Madhow", "Michael L. Honig", "Kenneth Steiglitz"], "n_citation": 267, "references": ["6e44ec75-6a9e-406a-a4fe-d195f572f5b6", "d0b9428d-dfb9-477c-ac05-5844e4a0ad19"], "title": "Optimization of wireless resources for personal communications mobility tracking", "venue": "IEEE\\/ACM Transactions on Networking", "year": 1995, "id": "2ce2d423-6841-4de6-b563-4ece5a0b677a"}
{"abstract": "Abstract As efforts grow to develop spatio-temporal database systems and temporal geographical information systems that are capable of conveying how geographical phenomena change, it is important to distinguish the elements that are fundamental to scenarios of change. This paper presents a model based on the explicit description of change with respect to states of existence and non-existence for identifiable objects. Such changes are of concern when, for instance, modelling and reasoning about nations that are subsumed through conflict only to return once more at a later time, or about water bodies that fluctuate due to seasonal or climatic change. The basis for tracing these changes is the concept of object identity. Identity, distinct from an object's properties, values, or structure, is that unique characteristic that distinguishes one object from another. Based on a small set of primitives relating to the identity states of objects, we model the semantics associated with change and through a systemati...", "authors": ["Kathleen Hornsby", "Max J. Egenhofer"], "n_citation": 383, "references": ["6662e83b-e31c-4c5d-8ee5-ee440ef31a0c", "66e87ac3-13f8-4d5a-9f15-84135ffcc216", "ae77c82a-379f-4afc-820b-1a3ef0d7b03d", "cdb8b957-2807-4785-9e41-2f681f9e6bfb", "e0268d10-29b1-4f30-a28f-79af8960f728", "e1c09a0f-4367-4a26-842c-83f20478c2c7", "eb433478-5271-44e3-aa64-5dea64e91baf"], "title": "Identity-based change: a foundation for spatio-temporal knowledge representation", "venue": "International Journal of Geographical Information Science", "year": 2000, "id": "270d4223-6637-4891-8658-3b220eefd83b"}
{"abstract": "Process Mining is a technique for extracting process models from executionlogs. This is particularly useful in situations where people have an idealizedview of reality. Real-life processes turn out to be less structured than peopletend to believe. Unfortunately, traditional process mining approaches haveproblems dealing with unstructured processes. The discovered models are often\"spaghetti-like\", showing all details without distinguishing what is important andwhat is not. This paper proposes a new process mining approach to overcome thisproblem. The approach is configurable and allows for different faithfully simplifiedviews of a particular process. To do this, the concept of a roadmap is used asa metaphor. Just like different roadmaps provide suitable abstractions of reality,process models should provide meaningful abstractions of operational processesencountered in domains ranging from healthcare and logistics to web servicesand public administration.", "authors": ["Cw Christian G\u00fcnther", "Wil M. P. van der Aalst"], "n_citation": 600, "references": ["08e139c7-baf8-4ed3-a927-31c62d2a5a5c", "32bed853-ef8e-4fdc-9ab1-6836a8b00df9", "38135245-8eff-4078-af6a-ea559ffa660b", "39b6a924-e7ad-4a5b-b7ab-ef877a513cc7", "50303516-dc41-41d9-992b-ab288fecf300", "834f41d9-408e-4d98-bdcf-5639d088bdc4", "c2d7363c-bb57-4526-a914-066015b48638", "e9719142-6066-4710-824c-f0e8d89773e8", "eab02cf7-8b39-4ace-8e0b-061ab0b9f2ef"], "title": "Fuzzy mining: adaptive process simplification based on multi-perspective metrics", "venue": "business process management", "year": 2007, "id": "fb63a144-94aa-479f-b9ca-cf14bef3112c"}
{"abstract": "\"How can we make sure our students learn what we want them to?\"  is the number one question in teaching. This paper is intended to provide the reader with: (i) a general answer to this question based on The Theory of  Constructive Alignment  by John Biggs; (ii) relevant insights for bringing this answer from theory to practice; and (iii) specific insights and experiences from using constructive alignment in teaching model-based design for concurrency (as a case study in implementing alignment).", "authors": ["Claus Brabrand"], "n_citation": 46, "references": ["056bb04c-ff8a-47e0-8fc0-6e92a712e7c0"], "title": "Constructive Alignment for Teaching Model-Based Design for Concurrency", "venue": "", "year": 2008, "id": "3687f6b5-ae60-4c91-b031-ffab95c3be54"}
{"abstract": "In this paper, we exploit the stylistic characteristics of high-quality entertainment movie sequences in terms of their textured background for coding purposes. More specifically, we propose a content-based coding method by texture replacement. At the encoder, texture is removed from selected regions of the original frames. The resulting frames with the texture removed and the parameters of the removed texture are then encoded. At the decoder, the boundaries of the regions without texture are identified and new texture, which is synthesized using the decoded texture parameters, is mapped onto these regions. Our experimental results confirm the main advantages of the proposed texture replacement method: significant bit rate reduction of the compressed movie sequences with the texture removed, and higher visual quality of the textured background regions in the decoded movie sequences with synthesized texture than that of the regions in the sequences simply encoded and decoded. Even more, our method can be applied as an overlay onto any standards-compliant coding system.", "authors": ["Adriana Dumitras", "Barry G. Haskell"], "n_citation": 61, "references": ["00e85e0f-4918-49dd-ad1a-816a8eb14c5d", "04b7c8bc-5100-4d71-834c-de6d205cb909", "13c30336-1bbe-4679-9961-e7b9b58c77b2", "15b97643-1763-4c9b-bfd5-873f62e1ad88", "23309049-0d82-45d8-90ce-7fd947605e14", "24ebcd2d-c537-4485-a0f9-6cd605eed71b", "25187aec-b848-4748-853d-7e2609d08f49", "2a43931b-50c5-4804-966a-316ada56caf0", "2e15bb65-97cb-4a27-977c-deaa2c495216", "2fe35d6f-76b6-45ca-aad6-efd9fb85b118", "363132f0-3ba2-4382-8dc2-5966f09a95f9", "442895c4-93e2-4dea-afb7-4be44eaded41", "44c3f6e0-d482-4ac6-8050-16ca2b3cff09", "4554de76-6285-4afd-a234-b6d78a2c8c6d", "47ba4f93-d774-4c9c-8715-7450fb5ab456", "4cc695ac-1bb4-49a7-ad53-426dffeeebfe", "4d6a850a-a91b-48de-98b6-11715eaee7b1", "68d734f8-c860-43a0-9c2b-182e8a40e50d", "6bbc35c0-83b4-474e-b6c0-7079055d2c12", "709a1167-8c46-4ea7-ba46-48cda5fc93d8", "7262578e-d4de-491b-84d3-6436d451f9e0", "74b1ed57-51e2-4514-a093-848d7d0b0788", "760c9f78-841c-46e0-a9c2-2d5888856d87", "7aaad71c-367e-4140-b65e-fb85ca331eef", "7cbdc4d5-2111-4ea0-8fdd-0a49b9e951bf", "7d2a4162-2cbb-4720-9ef6-d660b225f578", "7d6cfa3a-2da5-46cc-930b-c4558aade231", "8e1823cf-c2b3-4c08-8fe1-2a09dba3fcc9", "8ff4f037-e8ae-40a1-b5b5-b7a779a39790", "94a65b6b-811d-4dd1-887f-a80475413104", "94eefa4c-a631-4316-acee-1bb02cc10e3d", "98df207d-2dfc-4365-846a-c875a2a3a59e", "9a3a49ad-3c55-48e2-89df-a5e4af16d48d", "9cef868f-eb6d-4189-acd1-43eac87cf81e", "a3218d27-3254-4f93-bd89-59b15468b1a7", "a4cd48ec-e170-49a7-9c26-8f4dc616507a", "b045f8f6-fee8-45ec-809f-d34c83ef9562", "b4d60f41-4941-48cd-9b48-9c4aed5dc161", "c29f21cc-0d74-4432-aad8-35038af5b3c3", "c83fb401-2038-4ff7-8f61-d3c81015f936", "d269bca4-fd4b-40c9-8dc7-67276608c502", "d2a20f32-4b32-4480-b7f9-7efc93a04229", "ea9abf47-2693-426c-9cb2-f6950c50e163", "f0baaf8e-2483-4f3c-a4fa-39f3bc410f1b", "f1e7c5a5-779e-4899-8d9e-62d5127a1939"], "title": "An encoder-decoder texture replacement method with application to content-based movie coding", "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "year": 2004, "id": "baa716e4-702a-47ba-9cb5-0e60aedbd3b0"}
{"abstract": "The design of a module system for constructing and maintaining large programs is a difficult task that raises a number of theoretical and practical issues. A fundamental issue is the management of the flow of information between program units at compile time via the notion of an interface. Experience has shown that fully opaque interfaces are awkward to use in practice since too much information is hidden, and that fully transparent interfaces lead to excessive interdependencies, creating problems for maintenance and separate compilation. The \u201csharing\u201d specifications of Standard ML address this issue by allowing the programmer to specify equational relationships between types in separated modules, but are not expressive enough to allow the programmer complete control over    the propagation of type information between modules.  These problems are addressed from a type-theoretic viewpoint by considering a calculus based on Girard's system F \u03c9 . The calculus differs form those considered in previous studies by relying exclusively on a new form of weak sum type to propagate information at compile-time, in contrast to approaches based on strong sums which rely on substitution. The new form of sum type allows for the specification of equational, as well as type and kind, information in interfaces. This provides complete control over the propagation of compile-time information between program units and is sufficient to encode in a straightforward way most users of type sharing specifications in Standard ML. Modules are treated  as   \u201cfirst-class\u201d citizens, and therefore the system supports higher-order modules and some object-oriented programming idioms; the language may be easily restricted to \u201csecond-class\u201d modules found in ML-like languages.", "authors": ["Robert Harper", "Mark Lillibridge"], "n_citation": 365, "references": ["0c66bc00-bede-4c8f-9216-717fad194fae", "192a0fe0-b5ae-41a4-8e59-afbf21bd979e", "1cc071b5-2460-4213-b32b-973671d2b85a", "23c82e3b-76e3-401a-835b-7b7cc9e708c0", "3f4927bd-a061-4aaf-9968-d5aa13144bce", "4d25be0e-2f99-4dc7-a7d6-e4c74f7192fd", "555c6ed2-8b27-42eb-9685-3425ba3cad40", "5ee52c84-d896-4172-bfc3-1790171ce5b8", "639bc67d-ead6-43c7-a7f1-0fc3027fba8e", "6c9702db-33bb-4f8f-bb48-14f0e914848b", "7c59931e-f1e7-4ca4-8262-1303b45e7c97", "7efb35fb-4a85-4990-8694-f74c155f392c", "9076bd34-4562-4817-96bd-0154eb2f047c", "a80f245f-2906-42f4-9b2b-f5a131248665", "ad1a5ee4-ef35-4c5f-b8a0-93f1e857786d", "bf3187b7-6952-4ff0-9ed5-ac79a41dbdf0", "c7febbc7-ad21-4029-9fe1-816ff8528eb4", "d07c764f-3cc5-44de-a95f-d6bc2fae8535", "fb323255-aabf-4374-86f9-50fcf9a5cd35", "fbcad938-9d40-4bd7-b7c5-2cf040dc0bec"], "title": "A type-theoretic approach to higher-order modules with sharing", "venue": "symposium on principles of programming languages", "year": 1994, "id": "a4e39a60-7224-4b47-a371-1de04beac23a"}
{"abstract": "Most legged robots must negotiate unknown environments with little or no terrain knowledge, as autonomous terrain mapping for robots is limited. A predictive terrain contour mapping strategy is proposed, which employs the use of a feed-forward neural network to predict the contours in environments, based on the positions of the neighboring legs. The predicted performance is better than previous implementations.", "authors": ["Stephen Urwin-wright", "David Sanders", "Sheng Chen"], "n_citation": 31, "references": ["6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "98628033-2948-4f30-b6de-4364cb7a646e", "aeeb0b2a-50ff-4a00-96aa-e69a6eb8924a", "cef27fd4-1590-43e2-b40a-3853aed84956"], "title": "Terrain prediction for an eight\u2010legged robot", "venue": "Journal of Robotic Systems", "year": 2002, "id": "840be646-a670-4c87-a494-bddbd8dc548f"}
{"authors": ["Boualem Benatallah", "Marlon Dumas", "Zakaria Maamar"], "n_citation": 50, "references": ["03fe039d-3c04-450c-83aa-c8f0627e90d4", "0d261b6a-c94a-4d5e-b44e-eb6ae46581fc", "3ef801a4-9ba6-4bb8-b494-c6b725154298", "bd6de100-9148-4899-ae64-0c61f42ac938", "c0012fce-ddfd-4c23-9ca6-7518071a912d"], "title": "Definition and Execution of Composite Web Services: The SELF-SERV Project.", "venue": "IEEE Data(base) Engineering Bulletin", "year": 2002, "id": "ff767e81-edbc-4969-9f85-628d5b04ea10"}
{"authors": ["Deepak Kapur"], "n_citation": 45, "references": ["04a0b111-f18e-49d8-a1ec-a2f289d46961", "24ddf3df-bb27-4be4-ae8a-ea7a99546444", "342b1735-525a-40a0-82c3-7b85e4bc33b1", "610e6d6e-e7fd-4b0c-8d91-125789bc710b", "6d08958e-79c0-4bec-97e6-ab363407cf4d", "b08988b0-ee6b-4141-9fa8-2a7cd9fd11e6", "c75eb754-bffa-4d61-a3b3-a6d9a380a494", "c9f73dd8-c345-4ca7-8b1d-5e8083a9bcfd", "e801dffd-d773-4615-a637-223478bee91f"], "title": "Geometry theorem proving using Hilbert's Nullstellensatz", "venue": "", "year": 1986, "id": "26fcaf19-5aff-472a-a37d-bc077db1c540"}
{"abstract": "A novel construction of linear parameter-varying controllers is presented. For arbitrarily fast parameter variations it is shown how full block multipliers allow to considerably reduce conservatism. Various auxiliary results of independent interest are included.", "authors": ["Carsten W. Scherer"], "n_citation": 484, "references": ["19c7669e-a01a-46e0-900a-90395015e438", "dc261289-cded-49f4-81a0-69e26d606c88"], "title": "LPV control and full block multipliers", "venue": "Automatica", "year": 2001, "id": "e699f701-4c92-48e7-8b8a-fb3b6b72577c"}
{"abstract": "Hashing based Approximate Nearest Neighbor (ANN) search has attracted much attention due to its fast query time and drastically reduced storage. However, most of the hashing methods either use random projections or extract principal directions from the data to derive hash functions. The resulting embedding suffers from poor discrimination when compact codes are used. In this paper, we propose a novel data-dependent projection learning method such that each hash function is designed to correct the errors made by the previous one sequentially. The proposed method easily adapts to both unsupervised and semi-supervised scenarios and shows significant performance gains over the state-ofthe-art methods on two large datasets containing up to 1 million points.", "authors": ["Jun Wang", "Sanjiv Kumar", "Shih-Fu Chang"], "n_citation": 284, "references": ["2a3a6115-439a-48bf-9154-6175c0e0fe0b", "63692e82-1fd0-4caa-a0e4-188e9aa784e0", "9c697c56-73fb-4f88-b07d-ecadadd55df8", "b944f77f-113b-4a02-ae5e-d4a124b8fd5b", "c61efabe-4f71-4d5c-a6cc-9e50be780411", "d32037a4-d0ae-4c79-b1f3-f86d6a440178", "dda32e99-40c9-4d5f-8982-51e4b1dca885", "ecd9cd74-0e98-4765-8c32-f56c631a8be0", "f7999688-9193-4db6-ab5a-0955ad5c0a32"], "title": "Sequential Projection Learning for Hashing with Compact Codes", "venue": "international conference on machine learning", "year": 2010, "id": "572cf0d9-4cd1-4022-a430-91e4ac34dd40"}
{"abstract": "Recently, the Internet has witnessed the emergence of content distribution networks (CDNs). In this paper, we study the problem of optimally replicating objects in CDN servers. In our model, each Internet autonomous system (AS) is a node with finite storage capacity for replicating objects. The optimization problem is to replicate objects so that when clients fetch objects from the nearest CDN server with the requested object, the average number of ASs traversed is minimized. We formulate this problem as a combinatorial optimization problem. We show that this optimization problem is NP complete. We develop four natural heuristics and compare them numerically using real Internet topology data. We find that the best results are obtained with heuristics that have all the CDN servers cooperating in making the replication decisions. We also develop a model for studying the benefits of cooperation between nodes, which provides insight into peer-to-peer content distribution.", "authors": ["Jussi Kangasharju", "J. Roberts", "Keith W. Ross"], "n_citation": 532, "references": ["36f0f3cb-6b32-4284-8e08-0972ee67074f", "5a2cfd16-73c3-4a9a-9e92-96a5d0f34fe6", "5e82f06b-faf3-4eea-98b6-d0c0e0fbbf4c", "6c30c592-28a5-4a03-80ee-92e759fbea3a", "7cce7b5b-ce6d-4239-9984-819d9c7e5b9e", "f0e60bfa-27ae-4777-a265-d92c1f33aa40"], "title": "Object replication strategies in content distribution networks", "venue": "Computer Communications", "year": 2002, "id": "be0fef07-03a8-465c-a154-b58d69430785"}
{"abstract": "Detecting network path anomalies generally requires examining large volumes of traffic data to find misbehavior. We observe that wide-area services, such as peer-to-peer systems and content distribution networks, exhibit large traffic volumes, spread over large numbers of geographically-dispersed endpoints. This makes them ideal candidates for observing wide-area network behavior. Specifically, we can combine passive monitoring of wide-area traffic to detect anomalous network behavior, with active probes from multiple nodes to quantify and characterize the scope of these anomalies.#R##N##R##N#This approach provides several advantages over other techniques: (1) we obtain more complete and finer-grained views of failures since the wide-area nodes already provide geographically diverse vantage points; (2) we incur limited additional measurement cost since most active probing is initiated when passive monitoring detects oddities; and (3) we detect failures at a much higher rate than other researchers have reported since the services provide large volumes of traffic to sample. This paper shows how to exploit this combination of wide-area traffic, passive monitoring, and active probing, to both understand path anomalies and to provide optimization opportunities for the host service.", "authors": ["Ming Zhang", "Chi Zhang", "Vivek S. Pai", "Larry L. Peterson", "Randolph Y. Wang"], "n_citation": 176, "references": ["01fddcb9-1845-4b2a-83f8-04d9fb23594c", "08188609-efda-4b54-ad07-da2740a6dcd8", "0ba640e8-a0ab-4d39-b13b-c85572a5c57d", "2bab04c8-e9b8-4da1-88eb-abd2e99aa4d5", "3128753a-7c29-4f32-8f69-bc677559a6f0", "3d02b614-3aa0-4647-9e95-8e3fde4c4371", "4571792a-b623-4c8f-b9e6-839393a08a6e", "4b5c9003-da3b-4a1c-9ddd-0262278668e5", "4d8b2a4a-185f-4c7a-b7c0-136f1dc233f8", "5ced6102-00b6-46ce-b1ec-c69d8e403d32", "6365da54-02f9-464d-812d-f6f37a6dc648", "862d641e-42d2-4e82-9a36-822b809f288d", "8df0f1e0-c75c-4c63-81d9-b8ab58daa4fd", "91109dc7-752c-46b4-a760-e1c8546172de", "a29630f9-df4e-4f58-b066-423b90e2b4e7", "a369afee-a619-4e9a-9250-5fd2b06e8a05", "bca24aff-d6ba-4f1c-b82a-ffbc52815148", "d8d45f06-8f07-4d67-919d-46071c69593f", "fd0ef33c-7fcf-4776-beb9-0e3f706a90c6"], "title": "PlanetSeer: internet path failure monitoring and characterization in wide-area services", "venue": "operating systems design and implementation", "year": 2004, "id": "7d2c160f-ed51-4e30-acf7-3d034e059f3a"}
{"abstract": "String Matching String Distance and Common Sequences Suffix Trees Approximate String Matching Repeated Substrings.", "authors": ["Graham A. Stephen"], "n_citation": 436, "title": "String searching algorithms", "venue": "", "year": 1994, "id": "62e71c26-bbf1-4ff7-a349-03478580e648"}
{"abstract": "We are interested in the automatic verification of digital designs specified in the popular hardware description language VHDL. This paper presents a static analysis that computes a superset of the states maybe reached during the simulation of a VHDL design. We follow the methodology of abstract interpretation. To model the execution of a VHDL description, we first define a concise structural operational semantics. Our analysis is then derived by abstraction from this formal model. It is designed so as to be parametric in the representation of sets of states. Hence, trade-offs between cost and precision can be made by plugging in different abstract domains. This is of particular importance in the case of hardware verification, where one of the major obstacle to the integration of automatic tools in the design flow is the state-explosion problem they face. We instantiate our analysis with a domain that consists in a collection of vectors of constants and whose size is linear in the size of the unit under verification. Among other things, our analysis allows us to assert safety properties.", "authors": ["Charles Hymans"], "n_citation": 10, "references": ["0bc91cdf-6602-4b6e-b753-60297dd20f0d", "0dda85de-b47e-4412-a80f-495f9d42df4a", "0e1c3de2-0019-4cf0-a9af-2f5972a85af0", "2cb9280c-6479-4242-bc30-61ad2b345c10", "34d67173-5d3f-4dbe-8c4c-1c2af7509fc0", "3be3f2d2-b2f8-4811-a57a-2a3a1c7fc162", "4b8d5647-b891-4bd0-b974-010bb0a27d6f", "5f51f095-db6f-4ef7-bb7e-9aaeeb59b3b9", "649e7be8-45b2-49d4-9f8b-0c7022f2ff83", "6741eb2a-7fd7-4a79-b305-ed4e9dd62e6a", "7bb71afa-91b8-46e7-9008-da84e0427b93", "838d99b5-5b05-41a8-adc7-a597195fefad", "8d6dc616-8728-49a3-8962-71a2530d16bc", "9a4984f9-27d4-47eb-8bc8-0469bf540f94", "c00bbb49-6e29-4103-8883-55acd23c248b", "e54b994e-9293-4b1e-82d1-771b0fc76035"], "title": "Checking Safety Properties of Behavioral VHDL Descriptions by Abstract Interpretation", "venue": "static analysis symposium", "year": 2002, "id": "cda57883-d856-4979-be67-9c047dfe49ff"}
{"abstract": "Scenarios, or Message Sequence Charts, offer an intuitive way of describing the desired behaviors of a distributed protocol. In this paper we propose a new way of specifying finite-state protocols using scenarios: we show that it is possible to automatically derive a distributed implementation from a set of scenarios augmented with a set of safety and liveness requirements, provided the given scenarios adequately \\emph{cover} all the states of the desired implementation. We first derive incomplete state machines from the given scenarios, and then synthesis corresponds to completing the transition relation of individual processes so that the global product meets the specified requirements. This completion problem, in general, has the same complexity, PSPACE, as the verification problem, but unlike the verification problem, is NP-complete for a constant number of processes. We present two algorithms for solving the completion problem, one based on a heuristic search in the space of possible completions and one based on OBDD-based symbolic fixpoint computation. We evaluate the proposed methodology for protocol specification and the effectiveness of the synthesis algorithms using the classical alternating-bit protocol.", "authors": ["Rajeev Alur", "Milo M. K. Martin", "Mukund Raghothaman", "Christos Stergiou", "Stavros Tripakis", "Abhishek Udupa"], "n_citation": 16, "references": ["05c9fa68-f099-40b2-9410-ca768f97e078", "10204087-66fe-4abe-9205-3b8b0f57435e", "15634966-aaf7-434b-8f27-49b608056418", "41541aed-a11d-487f-a124-12117ed6facb", "46ba978f-bf6b-4037-9479-385eda95ed86", "5bac5b42-4dec-4389-9fc6-6aaa62aae4c4", "66290726-8f4d-4596-a0ac-9ae00bed0c6f", "8a1a29a3-9994-45c0-9e54-bad0ce8db2a6", "91909db5-058e-4571-a03d-340f018d743b", "9849d9c4-a97f-452f-882c-42a8c6cab0b5", "9fd310d2-e15e-4573-bcfe-69bdbca70ca5", "c00bbb49-6e29-4103-8883-55acd23c248b", "ce278443-2cb6-41e9-baba-d3dd41cf6c15", "d22c3e71-e9b0-4503-a793-5b6c61db2e74", "dacf6e0e-a9cd-49f6-8f07-84bfdc361288", "e5c2e303-c14d-46d8-a0c2-2a6117156523", "eb98521e-76c2-43aa-aee9-4e257441e066", "ec62acdd-2c83-4f7d-aac3-2d3cdbda863c"], "title": "Synthesizing Finite-State Protocols from Scenarios and Requirements", "venue": "haifa verification conference", "year": 2014, "id": "2c43bcba-0302-48c6-9a0e-97e189bc23e3"}
{"abstract": "Many modern enterprises require methods for guaranteeing compliance with privacy legislation and announced privacy policies. IBM has proposed a formal language, the Enterprise Privacy Authorization Language (EPAL), for describing privacy policies rigorously. In this paper, we identify four desirable properties of a privacy policy language: guaranteed consistency, guaranteed safety, admitting local reasoning, and closure under combination. While EPAL achieves only one of these four goals, an extended language framework allows us to achieve three out of four, while retaining the basic EPAL framework of restricting access and imposing obligations on users of confidential information.", "authors": ["Adam Barth", "John C. Mitchell", "Justin Rosenstein"], "n_citation": 45, "references": ["111edcc3-54bd-443a-aa7b-512eb0bfaf00", "cced324d-680b-4cba-9fce-fb862f048ec5"], "title": "Conflict and combination in privacy policy languages", "venue": "workshop on privacy in the electronic society", "year": 2004, "id": "81221a96-6f50-4adb-808f-fb7b410e61a6"}
{"abstract": "This paper addresses the identifier ownership problem. It does so by using characteristics of Statistical Uniqueness and Cryptographic Verifiability (SUCV) of certain entities which this document calls SUCV Identifiers and Addresses, or, alternatively, Crypto-based Identifiers. Their characteristics allow them to severely limit certain classes of denial-of-service attacks and hijacking attacks. SUCV addresses are particularly applicable to solve the address ownership problem that hinders mechanisms like Binding Updates in Mobile IPv6.", "authors": ["Gabriel Montenegro", "Claude Castelluccia"], "n_citation": 92, "references": ["0b868c0b-2b01-4732-abfb-06a8773783cb", "1696546d-24b6-4975-aa6c-80ed97054166", "2edff2b9-4eb1-4aa1-bed3-52101abd8f0b", "7a265b1f-19fa-46df-98c9-f2438c815327", "a76086c3-fd36-4c8d-8a98-619ac62a3d5c", "b68fc787-7817-421e-8e66-8a98ab9db1ad", "c6839294-591d-4707-bcf0-678b26d185b8", "ccc96384-6f47-49ab-8694-5b0240c32c26", "f6761766-2a23-4271-9b01-2639770d52cd"], "title": "Crypto-based identifiers (CBIDs): Concepts and applications", "venue": "ACM Transactions on Information and System Security", "year": 2004, "id": "a9b4022d-c8e8-4dcd-8bca-1ceca1c7fe5f"}
{"abstract": "We show how the Hindley/Milner polymorphic type system can be extended to incorporate overloading and subtyping. Our approach is to attach constraints to quantified types in order to restrict the allowed instantiations of type variables. We present an algorithm for inferring principal types and prove its soundness and completeness. We find that it is necessary in practice to simplify the inferred types, and we describe techniques for type simplification that involve shape unification, strongly connected components, transitive reduction, and the monotonicities of type formulas", "authors": ["Geoffrey Smith"], "n_citation": 91, "references": ["01efaa0b-5728-466a-8aff-3035e986a1b6", "0ae1bce8-7965-45f9-9a2b-f3f26a36b92c", "14a936ba-8334-4fc8-b92f-84f0bee0f06a", "332a4fe3-05dd-41bc-b228-d0f0e0f32580", "5434e88f-afe5-4e52-b302-15e819a10c02", "5e38e823-24d6-41dd-a4b8-d104f8f50cfa", "71b1a449-3d16-4590-9e05-d4fa7eedf87e", "800057f4-0e2a-4f6b-8356-25275d19a523", "977e5755-6337-4e5a-8659-71c94f940423", "a43fa38b-ae64-48e1-95e2-f3e9112f10af", "bad54083-f2f9-4d6d-b7ff-a51bcd3ebe61", "c38ddc98-cedc-4635-a8b2-cab2685b5329", "e1bfb6da-7b18-4f3d-bd73-c9f30f4add72", "e435c51c-247b-4386-8238-0f4d5d754eca", "edb7a8e6-909c-42eb-9a92-b3653fbefa83"], "title": "Principal type schemes for functional programs with overloading and subtyping", "venue": "Science of Computer Programming", "year": 1994, "id": "b7b4d756-cd29-4f00-9453-ad65872b45ae"}
{"abstract": "An atomic commit protocol can ensure that all participants in a distributed transaction reach consistent states, whether or not system or network failures occur. The atomic commit protocol used in industry and academia is the well-known two-phase commit (2PC) protocol, which has been the subject of considerable work and technical literature for some years.", "authors": ["George Samaras", "Kathryn H. Britton", "Andrew Citron", "C. Mohan"], "n_citation": 77, "references": ["137dccce-9930-40cb-9334-adbad669bc34", "17867166-0b00-4fba-91d9-ec6556fa8c00", "220a7341-08f6-481e-8713-974a99c810d5", "25b46064-0d14-4675-a8e7-ab20f1199e54", "29d2ce5c-0fe0-49c8-9d18-247ebdcb1647", "45d0224c-48ef-4263-a8d0-7dbdd670fbf3", "8c648248-bbf5-4f60-9782-1cca698b803e", "99f678c6-6e53-4c95-9c7a-e206a6cc8a87", "d03ec017-cd66-4aec-87f0-db584106c988", "e12ed635-4d2d-4ee0-ac6f-08d4168952d1"], "title": "Two-phase commit optimizations in a commercial distributed environment", "venue": "Distributed and Parallel Databases", "year": 1995, "id": "e44dc775-701a-4e39-a68b-839168ff0b43"}
{"abstract": "Discusses 3D motion of underwater vehicles. The authors describe kinematics of an underwater vehicle by six state variables and four inputs, and use a Lyapunov-like function to develop a nonlinear tracking control scheme. The control method effectively makes use of the nonholonomic nature of the system. Simulation results agreed with the theoretical predictions and confirmed the usefulness of the proposed scheme. >", "authors": ["Yoshihiko Nakamura", "Shrikant Savant"], "n_citation": 122, "references": ["12b62946-9c9c-4cda-ae93-2a091ba59a1a", "7c9165f1-b0a6-4e3e-a10c-8188febddcc0", "c3fc3334-2d68-4ed7-b728-4cff136d953e"], "title": "Nonlinear tracking control of autonomous underwater vehicles", "venue": "international conference on robotics and automation", "year": 1992, "id": "f16b286f-d4ad-435e-87e0-7956b89d271b"}
{"abstract": "Background: National electronic health record (EHR) programs are increasingly being pursued across the world with the aim of improving the safety, quality and efficiency of healthcare. Despite significant international investments, and particularly in the light of reported \"failures\", there is surprisingly little evidence on the specific and potentially transferable factors associated with the planning and execution of large-scale EHR implementations. England embarked on a National Program in 2002, characterized by \"top-down\", central procurement of a few, standardized EHR systems.  Objectives : To evaluate the national implementation and adoption of EHRs in English hospitals and derive lessons for this and other national EHR programs.  Design : We conducted a qualitative case study-based longitudinal evaluation drawing on sociotechnical principles.  Setting : Data were collected from 12 \"early adopter\" hospitals across England.  Data sources : Our dataset consisted of 431 semi-structured interviews; 590 hours of observations; 334 sets of notes from observations, researcher field notes and notes from conferences; 809 hospital documents; and 58 national and regional documents.  Results : A range of factors emerged as important. These included software characteristics and user involvement in shaping technology; realistic timelines, balancing the national EHR vision and stakeholder expectations; relationship building and communication; balancing national progress with allowing local accommodation; and maintaining central direction whilst permitting degrees of local autonomy.  Conclusions : It is not possible to be prescriptive for achieving \"successful\" national EHR implementations. Nonetheless, we identify dimensions likely to be of greater significance than others, in a range of national contexts. We argue that design, based on users' requirements, and accommodation of the technology in the healthcare setting need to occur on a small-scale first before building out to satisfy organizational, local health economy and national needs, and that this needs time. Our results will we hope offer evidence to inform national strategies for large-scale and expensive EHR ventures.", "authors": ["Kathrin Cresswell", "Ann Robertson", "Aziz Sheikh"], "n_citation": 11, "references": ["4da16bbd-ef8a-4faf-8b53-d8711554d530", "5a7d4cdc-3562-4354-945c-757e382e401a", "63741f4c-38eb-40b6-9f67-0c17e00eb938", "9459e559-e32e-47b0-94ca-4f5be58ecad8", "a365ecf4-c829-4316-ab17-e35c741e3612", "f34a2519-5625-4a5d-ac84-a1ce78ffa0de", "f67f5d4f-f4ff-42da-9ebd-ae4f5683f2e2"], "title": "Lessons learned from England's national electronic health record implementation: implications for the international community", "venue": "", "year": 2012, "id": "ce1b130a-d6e4-49da-89b2-179a7a14732e"}
{"authors": ["Nicolas Foloppe", "Alexander D. MacKerell"], "n_citation": 1347, "references": ["72d2484c-ae25-4f17-b0b4-e0d6f5899508", "904c35fd-1d6c-4215-b2c1-2602dd16ea49", "acfa70ff-9d2d-4390-ba6e-a1947c6fbc26", "b62ecd70-f7c4-4224-87f4-a754ca681ab4", "d92ef56c-18c7-4139-aef7-ea1409ff3090"], "title": "All\u2010atom empirical force field for nucleic acids: I. Parameter optimization based on small molecule and condensed phase macromolecular target data", "venue": "Journal of Computational Chemistry", "year": 2000, "id": "08411ac2-7653-45df-8029-d5715ea25c8f"}
{"abstract": "The Windows division of Microsoft Corporation is in the midst of a massive effort to improve the security and reliability of the next release of the product - Windows Vista. In this talk, I will explain how the Center for Software Excellence at Microsoft has used program analysis technology to build the tools that enable this effort. Along the way, I will cover the current Windows engineering process and the role of the tools in the process, the core program analysis techniques we have invented and used in the tools, business and environment issues that govern the engineering process, and research directions suggested by our experience so far.", "authors": ["Manuvir Das"], "n_citation": 50, "title": "PASTE at Microsoft", "venue": "workshop on program analysis for software tools and engineering", "year": 2005, "id": "1e4fca8a-993a-413b-9ce5-e1870ee7f7f0"}
{"abstract": "This paper introduces a hybrid scheme that combines the advantages of fuzzy sets and rough sets in conjunction with statistical feature extraction techniques. An application of breast cancer imaging has been chosen and hybridization scheme have been applied to see their ability and accuracy to classify the breast cancer images into two outcomes: cancer or non-cancer. The introduced scheme starts with fuzzy image processing as pre-processing techniques to enhance the contrast of the whole image; to extracts the region of interest and then to enhance the edges surrounding the region of interest. A subsequently extract features from the segmented regions of the interested regions using the gray-level co-occurrence matrix is presented. Rough sets approach for generation of all reducts that contains minimal number of attributes and rules is introduced. Finally, these rules can then be passed to a classifier for discrimination for different regions of interest to test whether they are cancer or non-cancer. To measure the similarity, a new rough set distance function is presented. The experimental results show that the hybrid scheme applied in this study perform well reaching over 98% in overall accuracy with minimal number of generated rules. (This paper was not presented at any IFAC meeting).", "authors": ["Aboul Ella Hassanien"], "n_citation": 132, "references": ["09c90288-2d77-4b99-9057-0a30e8027edc", "27ad8fe0-74fc-4fdc-bedf-106ac15afa51", "592e8a18-27bf-4561-89d2-01afb204534d", "5eb1d0fa-5022-4c63-941f-41d80c58d8ad", "7ac9aed2-1713-4a2a-9c87-c53a870c60ee", "87ac029e-e4ee-4d55-a116-076587638dd8", "a4589cfe-15e7-4c34-9349-d002d1d2c9df", "ba340c5c-275d-4210-8dbd-848ab4ded134", "e3f7d225-62b0-42bc-abd4-ac7d5298e1bb", "f22188fc-46e5-456d-bdde-16173d45a450"], "title": "Fuzzy rough sets hybrid scheme for breast cancer detection", "venue": "Image and Vision Computing", "year": 2007, "id": "a38546e9-a9aa-4c59-9f94-afb45aa20bfa"}
{"abstract": "Logic programming languages are today used to build applications accessing large database systems. This raises the possibility of building live development environments for them. Of particular interest is how specific language features such as level of abstraction, transactions, etc. affect the design of such an environment. In this paper, we explore this question for a specific logic language, Datalog, contrast traditional and live approaches for its tooling and discuss issues that arise.", "authors": ["Spencer Rugaber", "Zef Hemel", "Kurt Stirewalt"], "n_citation": 1, "references": ["ea309a35-543a-4833-bed0-085e550193a8", "ec4f2f4e-b00b-4615-8421-7009403ea1ee", "f01c3967-b176-4738-bc8a-6545552170e4"], "title": "Live logic programming", "venue": "", "year": 2013, "id": "ad4a567b-8042-4b73-9698-3d3753e13739"}
{"abstract": "We report on the largest experimental study to date in multimodal 2D+3D face recognition, involving 198 persons in the gallery and either 198 or 670 time-lapse probe images. PCA-based methods are used separately for each modality and match scores in the separate face spaces are combined for multimodal recognition. Major conclusions are: 1) 2D and 3D have similar recognition performance when considered individually, 2) combining 2D and 3D results using a simple weighting scheme outperforms either 2D or 3D alone, 3) combining results from two or more 2D images using a similar weighting scheme also outperforms a single 2D image, and 4) combined 2D+3D outperforms the multi-image 2D result. This is the first (so far, only) work to present such an experimental control to substantiate multimodal performance improvement.", "authors": ["Kyong I. Chang", "Kevin W. Bowyer", "Patrick J. Flynn"], "n_citation": 529, "references": ["38889058-f088-412a-a466-74b8975cc47b", "4f8131dc-752c-432e-9f6f-6f23bd1b3f63", "65c69398-39ee-4513-8e22-ac4159b5ca05", "a523c948-94ee-4c1c-9acc-6a68ed173db1", "c5e0a533-2805-4b6a-842c-a8d979e7a7be", "c8680181-365b-4975-bb5d-44be90179fa3", "e5257d15-4474-44b9-ad39-eba6ec566227"], "title": "An evaluation of multimodal 2D+3D face biometrics", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2005, "id": "a009f819-ca2d-47d4-812e-20f02876c950"}
{"abstract": "The extendible cell (EXCELL) method provides a data structure for efficient geometric access. It stores geometric data into computer storage blocksm corresponding to disjoint variable sized rectangular cells accessible by an address calculation type directory. We describe the method for point files and files of more complicated figures analyzing performance. We report algorithms for the nearest neighbour and point-in-polygon-network problems and describe applications to geographical data bases, hidden line elimination and geometric modeling.", "authors": ["Markku Tamminen", "Reijo Sulonen"], "n_citation": 94, "references": ["029702d2-6d0e-498f-9af8-7770379a3eb4", "36385a01-5ea6-4650-94b5-322ca5db1f67", "36969d46-24f2-4a0b-9b52-61fe52b61fd9", "7521efcf-e156-48f9-8882-ce9206987584", "768eea6d-8e82-4bbf-8bdd-1f2338ded29f", "76c004a0-487a-4313-a344-fc4a299e4b66", "8b65b412-cdae-4c04-8dca-a3872a7f9ad9", "a2fa9936-b762-4c7c-b13f-107a8029fd29", "cb441602-7d3b-46fb-a29b-741c0b2d86f0", "f13a2155-7026-4da7-8147-b6a3d152c089", "f9952fb8-ab4a-4d98-92d6-e35b6dcbcbd0", "fd1346fc-9641-4a60-9b3f-8130841df119"], "title": "The EXCELL Method for Efficient Geometric Access to Data", "venue": "design automation conference", "year": 1982, "id": "71731a5a-1cf3-47f3-b57a-1baaf25a6daf"}
{"abstract": "In this paper, four heuristic algorithms for the optimal allocation of limited optical-layer, resources in WDM networks (virtual-topology optimization by routing and wavelength assignment) under static traffic demand are compared. While some previous papers assumed that all connection requests must be necessarily satisfied, in this work algorithms are studied aiming at comparing their ability in minimizing both the usage of optical-layer resources and the number of connection requests that cannot be allocated. Thus, this paper reports the results obtained on a 13-nodes simplified topology of the pan-European optical transport network designed in the COST 239 Project. The results of a few hundreds simulations with different traffic matrices have been gathered, by considering separately the cost of resources allocated and the percentage of rejected connections. One algorithm resulted best performing, because in most tests it allocated the lowest cost of optical-layer resources. On the other hand, the four algorithms exhibited comparable performance with respect to the percentage of rejected connections.", "authors": ["Stefano Bregni", "Ugo Janigro", "Achille Pattavina"], "n_citation": 50, "references": ["1afb0f3f-ba2c-494f-9ca7-f6a9a6fb3353", "2d0d3b6f-e195-4810-a8ad-e8f84d17a78d", "2dfe24e8-79b1-4328-97ac-bf35dfa8ba98", "3ef6e64e-7179-4b1e-b3ed-1cee50f512da", "568921fb-af83-459f-bee7-0d0b2f8b8bfe", "662639cf-63d8-49bf-b398-6d20420b224b", "68cf5113-a9f7-44a5-a9e9-90a4c4d2e260", "6b6ab01b-e5fa-4863-a016-9e171a931afb", "80e4e32f-d624-4887-8d0d-2a7bcb91bc1e", "a32c81c0-8683-4876-b4a0-0e2d6ea9bcac", "bb18fbda-a425-4e30-8b83-dd6b89e1d8ac", "e8e9e4d3-89a2-42cb-b22c-8a0a2374b634"], "title": "Optimal allocation of limited optical-layer resources in WDM networks under static traffic demand", "venue": "global communications conference", "year": 2001, "id": "44e21049-2069-4bdd-9672-19aea703a08e"}
{"authors": ["Ragunathan Rajkumar", "Chen Lee", "John P. Lehoczky", "Daniel P. Siewiorek"], "n_citation": 108, "title": "Practical Solutions for QoS-Based Resource Allocation", "venue": "real time systems symposium", "year": 1998, "id": "bcbdc8ea-0731-4917-a2da-72a3ccee0577"}
{"abstract": "The topology of a wireless multi-hop network can be controlled by varying the transmission power at each node. In this paper, we give a detailed analysis of a cone-based distributed topology control algorithm. This algorithm, introduced in [16], does not assume that nodes have GPS information available; rather it depends only on directional information. Roughly speaking, the basic idea of the algorithm is that a node  u  transmits with the minimum power  p u, \u03b1   required to ensure that in every cone of degree \u03b1 around  u , there is some node that  u  can reach with power  p u, \u03b1  . We show that taking \u03b1 = 5\u03c0/6 is a necessary and sufficient condition to guarantee that network connectivity is preserved. More precisely, if there is a path from  s  to  t  when every node communicates at maximum power then, if \u03b1 l 5\u03c0/6, there is still a path in the smallest symmetric graph  G  \u03b1  containing all edges ( u, v ) such that  u  can communicate with  v  using power  p u, \u03b1  . On the other hand, if \u03b1 > 5\u03c0/6, connectivity is not necessarily preserved. We also propose a set of optimizations that further reduce power consumption and prove that they retain network connectivity. Dynamic reconfiguration in the presence of failures and mobility is also discussed. Simulation results are presented to demonstrate the effectiveness of the algorithm and the optimizations.", "authors": ["Li Li", "Joseph Y. Halpern", "Paramvir Bahl", "Yi-Min Wang", "Rogert Wattenhofer"], "n_citation": 508, "references": ["0e0e89e5-ef9b-47f9-8cfa-e12594390988", "31092ee3-ec8f-4dc6-bb0b-46d9bfee30c2", "3c1dd577-a7bc-4283-938f-5fb37f07b55d", "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b", "9b531247-bb38-4d26-94e8-dab8c453e3ca", "9dfc2115-597c-48eb-aefb-f8578b6081ff", "c7d68d2c-13b9-4792-b9cd-b8fb8e0dbac9"], "title": "Analysis of a cone-based distributed topology control algorithm for wireless multi-hop networks", "venue": "principles of distributed computing", "year": 2001, "id": "f7e70882-8aae-424f-9f08-5503487a5838"}
{"abstract": "Distributed systems are often difficult to debug and understand. A typical way of gaining insight into system behavior is by inspecting execution logs. However, manual inspection of logs is an arduous process. To support this task we developed Synoptic. Synoptic outputs a concise graph representation of logged events that captures temporal invariants mined from the log.#R##N##R##N#We applied Synoptic to synthetic and real distributed system logs and found that it augmented a distributed system designer's understanding of system behavior with reasonable overhead for an offline analysis tool. In contrast to prior approaches, Synoptic uses a combination of refinement and coarsening to explore the space of representations. Additionally, it infers temporal event invariants to capture distributed system semantics. These invariants drive the exploration process and are satisfied by the final representation.", "authors": ["Sigurd Schneider", "Ivan Beschastnikh", "S. A. Chernyak", "Michael D. Ernst", "Yuriy Brun"], "n_citation": 11, "references": ["03c13e3c-671e-474b-bb97-9bf4ad69c477", "136c4780-2f25-4068-90a5-aed6afaf2890", "141241e0-9e06-4640-a85b-dda94b809cd7", "19cc1dca-7b33-4c22-8f90-306ce3781da2", "1a456e87-7a32-4225-abc3-1d422672e756", "25b46064-0d14-4675-a8e7-ab20f1199e54", "3affdf45-39d4-4894-b95a-34575b18607c", "45305dcd-2013-41b7-b87f-82a87330ce9d", "5a886665-83d4-4446-b3a4-e134fb48d807", "5f14dc1c-a71a-47ad-8390-b8a8f1c0f62b", "65c674fe-fc63-4ba0-a6c9-6a0153454889", "68bcaf38-e521-4422-80e9-2e0421ed8f92", "71eb328b-16f6-4a2d-97c6-37de1b45f570", "85acf8c3-764c-4525-9f63-7422497880fd", "8c9d0706-cd82-45d5-ad51-5a7e4dc6e60d", "9cbd877c-34f3-42b0-bd5e-ee330479850d", "ae26eab9-8faf-41a5-b779-bcf59548a1d7", "b3551fdb-fd20-4d6e-a5ad-99b863c5fdb4", "b5340471-b3df-4c9f-9902-7459370382dc", "bdce9352-60ec-42d8-b4f0-e6a6a620cbba", "c73ecdee-4c67-47d7-afe8-aa930774697c", "cb3cec59-ff10-4070-bda4-b440614d59b7", "d196ebe5-517e-4423-a021-ec7206cad311", "d4633091-aadd-4a27-accd-344d3e773ac8", "d6302b8f-80c9-40d9-ab68-6db0815d41bc", "d9c271a7-a67d-4fb4-940d-012282c83b79", "dab547d1-305b-4774-9951-7c5e62181c3b", "dde3dfa5-e2a6-4262-8685-baf1ad01022c", "de3ab7c6-721a-4ad9-849f-2ca5614e5d80", "e5c0cbb5-00cf-4357-8581-9edd4469d1a2", "ea0064ec-616c-492f-bb16-b12342832f27", "f14b06d0-074f-4b8d-b30e-e7efffd99093"], "title": "Synoptic: summarizing system logs with refinement", "venue": "", "year": 2010, "id": "84d485d3-5992-4918-9d31-6ca19639792b"}
{"abstract": "Tracking methods are evaluated in a real-time feature tracking system used for human-computer interaction (HCI). The Camera Mouse, a HCI system for people with severe disabilities that interprets video input to manipulate the mouse pointer, was improved and used as the test platform for this study. Tracking methods tested are the Lucas-Kanade tracker and a tracker based on normalized correlation. Both methods are evaluated with and without multidimensional Kalman filters. Two-, four-, and six-dimensional filters are tested to model feature location, velocity, and acceleration. The various tracker and filter combinations are evaluated for accuracy, computational efficiency, and practicality. The normalized correlation coefficient tracker without Kalman filtering is found to be the tracker best suited for a variety of HCI tasks.", "authors": ["Christopher Fagiani", "Margrit Betke", "James Gips"], "n_citation": 55, "references": ["276c4b24-bf26-4171-b5d4-43bf0b5f2651", "5462cd20-5733-4c33-8a71-1de9787dc2ba", "57eadb55-c2fa-42e1-a0c4-9da5e1658ff9", "732f1cb3-c0c3-40de-bdd0-40de75ec3a66", "838a4ab2-d6bd-4d27-b399-cdb28dd5b58e", "83e76bdd-72d1-473b-bbcc-16ee400d534b", "898fc99a-3cc7-4c25-9b6f-9a7da43aabc1", "9e782ace-7971-4a8b-bed8-6d01fbbb88e1", "a9dacd32-fe87-4408-8d53-ff6d85d21437", "b1cee17b-a45f-4eb9-8ab7-ca4cb0b565a8", "fd99a7a7-0aa2-4607-91bd-975285af5ad1"], "title": "Evaluation of tracking methods for human-computer interaction", "venue": "workshop on applications of computer vision", "year": 2002, "id": "2358ad02-c6a0-4d0d-acb0-95ad4d4b1512"}
{"abstract": "We present SLED, a specification language for Encoding and Decoding, which describes, abstract, binary, and assembly-language representations of machine instructions. Guided by a SLED specification, the New Jersey Machine-Code Toolkit generates bit-manipulating code for use in applications that process machine code. Programmers can write such applications at an assembly language level of abstraction, and the toolkit enables the applications to recognize and emit the binary representations used by the hardware. SLED is suitable for describing both CISC and RISC machines; we have specified representations of MIPS R3000, SPARC, Alpha, and Intel Pentium instructions, and toolkit users have written specifications for the Power PC and Motorola 68000. The article includes representative excerpts from our SPARC and Pentium specifications. SLED uses four elements;  fields  and  tokens  describe parts of instructions;  patterns  describe binary representations of instructions or group of instructions; and  constructors  map between the abstract and binary levels. By combining the elements in different ways, SLED supports machine-independent implementations of machine-level concepts like conditional assembly, span-dependent instructions, relocatable addresses, object code, sections, and relocation. SLED specifications can be checked automatically for consistency with existing assemblers. The implementation of the toolkit is largely determined by our representations of patterns and  constructors. We use a normal form that facilitates construction of encoders and decoders. The article describes the normal form and its use. The toolkit has been used to help build several applications. We have built a retargetable debugger and a retargetable, optimizing linker. Colleagues have built a dynamic code generator, a decompiler, and an execution-time analyzer. The toolkit generates efficient code; for example, the linker  emits binary up to 15% faster than it emits assembly language, making it 1.7-2 times faster to produce an a.out directly than by using the assembler.", "authors": ["Norman F. Ramsey", "Mary Fernandez"], "n_citation": 182, "references": ["35b9cd87-9fde-479e-a7c3-f02be02c11cb", "388e03ed-99c4-4c88-9bb4-c370045d8ac1", "45625169-a598-4f0d-bc47-2680ffcfa1fc", "4edfea8a-b657-4fec-b280-b372a453b3b8", "549b0b7b-df75-4e3d-8cf3-8161d4ab43f5", "581db56b-eddb-473a-a97f-1a05b6daf20c", "6abc8702-c561-4d82-859f-db7a966e6d35", "6f9e1a29-ac8b-45b7-862d-ade5ecfe4a07", "76386448-2eec-4ace-a0d1-8cd771536b5d", "83c657ef-fc47-4041-92b5-f8dece84dd78", "850bfefe-0fb2-4756-9bb8-4ef1fa49d597", "8ec0c88a-0ac3-4937-913e-7b9adb25e699", "94a25085-e644-4777-845c-c14ee764da78", "c6075bcb-c5ea-43cf-a9eb-89b8e8934c3a", "c9e0c146-1aa3-4c96-9b35-5db3f406092b", "d3ec8a19-31e3-4098-8342-8b28263a2690", "dfe956b4-b304-497f-8db3-40b2b990282e", "e4124519-003e-4064-876c-865014bf6e2f", "f07cffe9-b33d-40c8-bb17-5629f0b73fd0"], "title": "Specifying representations of machine instructions", "venue": "ACM Transactions on Programming Languages and Systems", "year": 1997, "id": "75ef9821-c4f9-453f-9f2d-68f5cce3c382"}
{"abstract": "Several rapid-feedback-based quality assurance mechanisms are used to manage the quality of continuously evolving software. Even though graphical user interfaces (GUIs) are one of the most important parts of software, there are currently no mechanisms to quickly retest evolving GUI software. We leverage our previous work on GUI testing to define a new automatic GUI re-testing process called \"crash testing\" that is integrated with GUI evolution. We describe two levels of crash testing: (1) immediate feedback-based in which a developer indicates that a GUI bug was fixed in response to a previously reported crash; only select crash test cases are rerun and the developer is notified of the results in a matter of seconds, and (2) between code changes in which new crash test cases are generated on-the-fly and executed on the GUI. Since the code may be changed by another developer before all the crash tests have been executed, hence requiring restarting of the process, we use a simple rotation-based scheme to ensure that all crash tests are executed over a series of code changes. We show, via empirical studies, that our crash tests are effective at revealing serious problems in the GUI.", "authors": ["Qing Xie", "Atif M. Memon"], "n_citation": 29, "references": ["019b3bfa-756a-452b-bae3-89f67ac740e2", "01e087e8-e3c2-44f8-b31c-c7f1e029b5b0", "0399968c-12e3-4548-b07c-0b9eba53c985", "299cd412-bb5c-4a16-9e8c-8c728fdd51d4", "47eb5aad-f161-4adc-a64a-e8d45300a42b", "4c60e3b0-2255-4dc9-abca-266b59396e9b", "5454c4d3-5607-45cc-a167-918e469a10e8", "5d145d03-88af-483d-ba5f-2b5c9ae2c9f7", "5f5b25cb-066c-4716-a082-202b68447e2c", "845ef51e-20e7-430e-9f4b-3e47e97ae778", "97d39a97-468c-4d35-98a9-8a7181acc248", "ae037804-5fac-4d30-95ad-8d0f560019ec", "b2df37cd-3df1-46dc-af4d-cf109781c8a7", "d8636b8a-98ac-4e79-a192-8522cf8bd3f1", "e05f3c0d-8c8a-42dd-84ad-2fb52aaa6a82", "f0da0661-a305-4b3a-a5a3-4d1f6c77c1f7", "f83f978f-d19c-4307-8095-f7e08783b632", "fdee8fa4-2252-495e-b7ac-1e2315d9e276", "ff456593-2b0f-454a-b321-c16eb4339d35", "ffdd91d8-218e-43b7-8569-4c6618ddcca3"], "title": "Rapid \"crash testing\" for continuously evolving GUI-based software applications", "venue": "international conference on software maintenance", "year": 2005, "id": "abf8ae67-e311-4a6e-9133-4a093d0a38ab"}
{"abstract": "The development of mobile technology has been evolving rapidly over the past decade. The advancement of mobile devices, especially smartphones and tablets, enables people to gain access to online information without constraints of time and location. One of the distinguishing features of our society in this new millennium is the change of lifestyle by mobile technology. The way of learning is also changed by mobile technology. Students nowadays learn and share via mobile devices. Mobile learning, also named as m-learning, has already become an integral part of learning in many higher education institutes. Although m-learning is still at a nascent stage for many education institutes, the increasing adoption of mobile devices re-assures the popularity of m-learning in the learning sphere. This paper attempts to review on m-learning in technological and social perspectives. The situation in Hong Kong is critically reviewed. The review of the trend in the literature provides a reference for higher education institutes for decision making in developing m-learning for their students.", "authors": ["J. Lam", "C. G. Duan"], "n_citation": 50, "references": [], "title": "A review of mobile learning environment in higher education sector of hong kong: technological and social perspectives", "venue": "international conference on hybrid learning and education", "year": 2012, "id": "be05795b-d0d6-40e9-9b33-abab75b28197"}
{"abstract": "This chapter presents an initial \"4+1\" theory of value-based software engineering (VBSE). The engine in the center is the stakeholder win-win Theory W, which addresses the questions of \"which values are important?\" and \"how is success assured?\" for a given software engineering enterprise. The four additional theories that it draws upon are utility theory (how important are the values?), decision theory (how do stakeholders' values determine decisions?), dependency theory (how do dependencies affect value realization?), and control theory (how to adapt to change and control value realization?). After discussing the motivation and context for developing a VBSE theory and the criteria for a good theory, the chapter discusses how the theories work together into a process for defining, developing, and evolving software-intensive systems. It also illustrates the application of the theory to a supply chain system example, discusses how well the theory meets the criteria for a good theory, and identifies an agenda for further research.", "authors": ["Barry W. Boehm", "Apurva Jain"], "n_citation": 86, "references": ["9e913a8d-9c9a-4c32-a05d-617dfe387a53", "bdc94277-8125-4aff-bbcd-b5e6e1fda167", "e08a6135-3e02-45ce-b814-7c8b01876a4a", "e23615b5-1838-42b6-a2f4-8b3722093d5f", "e850a30c-0089-4865-9184-14ec5c79d874"], "title": "An Initial Theory of Value-Based Software Engineering", "venue": "", "year": 2006, "id": "1a62901f-08d6-4bb5-adf4-9a07bd1a98c1"}
{"abstract": "Materialized views ( MV ) at the data warehouse ( DW ) can be kept up to date in response to changes in data sources without accessing data sources for additional information. This process is usually refered to as \u201cself maintenance of views\u201d. A number of algorithms have been proposed for self maintenance of views, which use  auxiliary views (AV)  to keep some additional information in  DW . In this paper we propose an algorithm for self maintainability of multiple  MVs  using the above approach. Our algorithm generates a simple maintenance query to incrementally maintain an  MV  along with its  AV  at  DW . The algorithm maintains these views by minimizing the number and the size of the  AVs . Our approach provides better insight into view maintenance issues by exploiting the dependencies and constraints that might exist in the data sources and multiple  MVs  at  DW .", "authors": ["Sunil Samtani", "Vijay Kumar", "Mukesh K. Mohania"], "n_citation": 50, "references": ["22e5d4f3-9fff-4a66-bc1f-a5dc318a7ebf", "3f00f5e4-42c3-4cca-9ee5-44312a55c6d3", "76babdfa-c9e3-473f-98ca-9218625a9c7e", "8d52eebd-f428-4f56-a7fe-0e32d04d8c91", "d9b15916-c439-437e-bc2c-a34443124f2a"], "title": "Self maintenance of multiple views in data warehousing", "venue": "conference on information and knowledge management", "year": 1999, "id": "70fe66da-2191-44cc-829a-df153617f82b"}
{"abstract": "Algorithms to determine the itinerary of intelligent agents are fundamental in the context of distributed applications based on mobile agents with time constraints. In order to establish the agent itinerary it is necessary to consider the trade-offs between high-quality of results and meeting the deadline. In this paper, we describe and evaluate adaptive heuristics able to choose the best behaviour to be used for decision making in the itinerary definition. This decision-making is based on a log of benefits collected by the mobile agent in past executions. The paper's objective is to propose a new heuristic able to realize the change in the environment and adapt itself dynamically, changing its behaviour in order to meet the deadline of the mission and to achieve the greatest possible benefit.", "authors": ["Alex Magalh\u00e3es", "Luciana Rech", "Lau Cheuk Lung", "R\u00f4mulo Silva de Oliveira"], "n_citation": 3, "references": ["09c9dff9-8675-45a0-bd7c-058a6b843356", "0b472951-447a-4939-aaf2-4107cbb80cc7", "225ecaa1-7209-4cb4-99ab-ddc293d66be8", "4e24108b-476e-46e8-8b9c-33a6a4b2695a", "8591d706-afee-4106-9a90-082876db1a11", "9840d1e0-8ae1-4713-85f9-aa406a7f2a74", "9a3eacbe-090a-4953-87fd-8f66da1fb29a", "d7f62736-2bb9-44a3-a04b-3847e07e8af4", "f2a9d6da-216d-4137-8d1f-eb9ab40560d7"], "title": "Using intelligent mobile agents to dynamically determine itineraries with time constraints", "venue": "emerging technologies and factory automation", "year": 2010, "id": "5414566d-8b71-451c-8c6e-17324dc0022c"}
{"abstract": "Symbolic simulation is the simulation of the execution of a computer system on an incompletely defined, or symbolic, state. This process results in a set of expressions that define the final machine state symbolically in terms of the initial machine state. We describe our use of symbolic simulation in conjunction with the development of the JEM1, the world's first Java processor. We demonstrate that symbolic simulation can be used to detect microcode design errors and that it can be integrated into our current design process.", "authors": ["David A. Greve"], "n_citation": 66, "references": ["1408e33d-1b88-4454-bb95-046691aa3962", "7f1dc63a-9064-4768-a30d-3383d52aa81e", "93a79b77-7a70-4200-846f-28b96fa2e4e9"], "title": "Symbolic Simulation of the JEM1 Microprocessor", "venue": "formal methods in computer aided design", "year": 1998, "id": "efbf0af5-cff8-42e1-85ce-83319fc9c2e7"}
{"abstract": "In this paper we present sequential as well as distributed algorithms for model checking computational tree logic over finite-state systems specified as Petri nets. The algorithms rely on an explicit representation of the system\u2019s state space but do not require the transition relation to be explicitly available; it is recomputed whenever required. This approach allows us to model check very large systems, with hundreds of millions of states, in a fast and efficient way. For the case studies addressed, the distributed algorithms scale very well, as they show efficiencies in the range of 60% to 95%, depending on the test cases and case studies at hand.", "authors": ["Alexander Bell", "Boudewijn R. Haverkort"], "n_citation": 50, "references": ["045ee061-f35f-4785-a58c-a9ea4d812256", "078bf11b-8663-45db-848f-2aff817ce05c", "14b0f0db-71b6-4e22-8ec1-9c14535697e6", "16e0969d-e059-4216-bccc-6da8127ac2c4", "3d7de688-8299-4b9f-8f4b-c724cc24dad7", "3f7981eb-7e84-449e-bced-7a7dabba788c", "4814eca2-167a-48bd-a7e6-60150e7a54e3", "497a698e-aa79-42b0-84a2-d88cf30fc538", "4eebc8ad-4226-47a4-a521-b208cab11ead", "5ac56f9e-be79-4f14-aaba-95e0dc6d1880", "5c3f1cb9-0ea2-4ebd-9271-19791e07702e", "79798700-ca7e-418a-b18d-1daf48384395", "837d4855-cc93-42ff-a841-cd6e2a3b1dce", "adc997a3-6b67-42fb-a2f0-f7a8d1c4e3c6", "c00bbb49-6e29-4103-8883-55acd23c248b", "d4633091-aadd-4a27-accd-344d3e773ac8", "d60276db-9909-47c5-bb63-f3ea8ad1e81c", "e1161405-6718-4983-8717-1354ecac5401", "e5b14faf-898a-4e5d-b374-ddc5182da397", "e7d4f300-a318-4d6e-bbd8-0a255c7d19fd", "e9fee3d6-ad0e-4249-a070-185192456558"], "title": "Sequential and distributed model checking of Petri nets", "venue": "International Journal on Software Tools for Technology Transfer", "year": 2005, "id": "bbb09230-dcdc-43a2-b371-218d8d47c62c"}
{"abstract": "The basic idea of this paper is to investigate quantitatively the influence of sampling periods on fault detection performance. Then, based on it, adaptive and cooperative sampling mechanisms in networked control systems can be designed optimally by taking into account the constraint of limited bandwidth.", "authors": ["Ping Zhang", "Steven X. Ding", "Ronald J. Patton", "C. Kambhampati"], "n_citation": 5, "references": ["651ffb3a-bf5c-480f-848d-d92d84979fb0"], "title": "Adaptive and Cooperative Sampling in Networked Control Systems", "venue": "international conference on networking, sensing and control", "year": 2007, "id": "b67fc74c-c814-47de-9870-5b15c5c550da"}
{"abstract": "A mutation testing tool takes as input a system under test and a test suite and produces as output the mutation score of the test suite. The tool systematically creates mutants by making small syntactic changes to the system under test and executes the test suite to determine which mutants give different results from the original system. Almost all mutation testing tools have been developed for statically typed languages. The lack of tools for dynamically typed languages may be rooted in additional challenges that are caused by the lack of precise type information until the program is executed. Existing tools for dynamically typed languages mostly focus on mutation of literals because the type of literals are known statically.   This paper presents SMutant, the first mutation testing tool for Smalltalk programs. In addition to literal replacement, SMutant supports many mutation operators that are commonly seen in tools for statically typed languages, such as operator replacement. Instead of applying mutations statically, SMutant postpones mutating until execution and applies mutations dynamically, when the types are available. Also, SMutant enables the user to define new mutation operators by sending a single message. The tool automatically generates code to support new mutation operators.", "authors": ["Milos Gligoric", "Sandro Badame", "Ralph E. Johnson"], "n_citation": 50, "references": ["0ce49acd-1138-4fcf-9372-6527c2d6d386", "0fc99c4c-3bb5-4063-a7c2-ac8a627c0bfc", "2b47a5ec-fd51-4b53-bd29-f6fc5e44da8a", "6542a775-7b98-49ef-a205-e76641279f37", "86532031-dd42-47e2-88a0-8c81c4645158", "a7122806-c66c-49e6-8876-70093d70f605"], "title": "SMutant: a tool for type-sensitive mutation testing in a dynamic language", "venue": "foundations of software engineering", "year": 2011, "id": "6c75ee43-5bfb-4edb-9494-f968a7cb7970"}
{"abstract": "Traditional array dependence analysis, which detects potential memory  aliasing of array references is a key analysis technique for automatic parallelization. Recent studies of benchmark codes indicate that limitations of analysis cause many compilers to overlook large amounts of potential parallelism, and that exploiting this parallelism requires algorithms to answer new question about array references, not just get better answers to the old questions of aliasing. We need to ask about the flow of values in arrays, to check the legality of array privatization, and about the conditions under which a dependence exists, to obtain information about conditional parallelism. In some cases, we must answer these questions about code containing nonlinear terms in loop bounds or subscripts.  This article describes techniques for phrasing these questions in terms of systems of contstraints. Conditional dependence analysis can be performed with a constraint operation we call the \"gist\" operation. When subscripts and loop bounds are affine, questions about the flow of values in array variables can be phrased in terms of Presburger Arithmetic.  When the constraints describing a dependence are not affine, we introduce uninterpreted function symbols to represent the nonaffine terms. Our constraint language also provides a rich language for communication with the dependence analyzer, by either the programmer or other phases of the compiler. This article also documents our investigations of the praticality of our approach. The worst-case complexity of Presburger Arithmetic  indicates that it might be unsuitable for any practical application. However, we have found that analysis of benchmark programs does not cause the exponential growth in the number of constraints that could occur in the worst case.  We have studied the constraints produced during our aanalysis, and identified characteristics that keep our algorithms free of exponential behavior in practice.", "authors": ["William Pugh", "David Wonnacott"], "n_citation": 91, "references": ["14c4665f-878d-4991-8b66-5d7aacca4f07", "16d59783-e961-4e17-8542-9756a29e09ea", "1efdbed8-fea5-4513-ab95-73df7a2f447c", "20c1b270-9275-4ab7-a5d9-02e570b32015", "2448f6ce-230a-495c-8cab-21a8bf2865eb", "28598671-2e00-465c-93a3-42a115cf2790", "2ca9fd9c-c3b7-4a00-a46a-508f98550af6", "2fe409b9-b2cb-450a-9606-1be2ac38a33c", "3d7583eb-fdda-4438-93ed-10641a7e5ac4", "522460c1-2616-4888-aca6-946841041ca0", "5b03270b-2d1a-45ad-b0bc-dfa4e457d61c", "61d93b18-27c0-41fe-91b1-d85b7fb48587", "68e25213-c060-4306-8e1d-8b202c1b9776", "698c2bd0-2f68-40bc-a988-b01b39fd9dff", "6bab6e8a-c80e-4347-8313-028c4baa2d69", "7a9d68b2-c4ab-4334-a6e8-09e908868822", "87c7eaae-f161-4e5c-a8aa-5218dd452b1b", "90432161-7924-44cd-9fb3-54982d084fdd", "9202f95e-af7b-4124-a936-6f113217bc31", "a00f5dcb-5026-4f5b-8920-1f0580614a6e", "aa158d6f-e999-4f0e-8ae4-dc7534fe1a4e", "ac712608-647d-4621-9254-c33915a89594", "ad3f2339-0e47-4375-8912-3509f557e726", "cb2b2397-4ff9-42e5-be33-12dbde4266aa", "e57e4c23-6bcc-46e0-ba3a-4623bc128edf", "e876766d-aa24-4658-ba09-06b2c67351cb", "ecbe5f47-2fc1-467e-80c0-0ff38e63cd77", "f698af43-4aab-4673-99d0-80f21e70605d"], "title": "Constraint-based array dependence analysis", "venue": "ACM Transactions on Programming Languages and Systems", "year": 1998, "id": "89ca6ba7-ce33-496c-b5cb-58a20a3310ad"}
{"authors": ["Simon M. Kaplan", "Gail E. Kaiser"], "n_citation": 50, "references": ["012684bd-4559-4c84-940c-736834718cef", "0d8205fe-9b1c-41cc-8207-81061d2c56f0", "1d9e72ce-a7b4-4747-8ea3-e1871f60a564", "3737fe7a-2bb6-4d01-b873-a2b65f1ddeed", "44042820-38a4-4605-9462-f3b086fa3216", "4c5aab8d-62ff-4134-b5b0-f11fd601f20f", "4dde57b4-728b-4cb2-b59d-7d2353241d15", "6aec0cf3-52c8-4b68-bc14-0e0c89e7416f", "873b8294-fb6b-40e8-9dfb-d32c5929387e", "8c2682c7-5e25-4bd9-bbb0-47c106463228", "8cee46d9-232b-458f-88a3-21e214288749", "b121469e-115b-4341-9fe3-d4651d0f771d", "d17c7833-42e2-46a7-83b2-58baed028dba", "d5c19e18-5ebd-482b-bd5f-29b5216a221c", "d5fa4384-172e-44c7-9911-4ebc793f5b07", "d68a5ef3-6028-4a9f-9f7d-3bd0ac2ddab5", "e388819c-4a40-440c-a3d2-7a29c7d6766f", "e7204325-b8ee-4377-b2ca-c5a9baa7ee1c"], "title": "Incremental attribute evaluation in distributed language-based environments", "venue": "principles of distributed computing", "year": 1986, "id": "aa405885-cbca-48d4-b98e-18486ec3a402"}
{"abstract": "Poker is an interesting test-bed for artificial intelligence research. It is a game of imperfect information, where multiple competing agents must deal with probabilistic knowledge, risk assessment, and possible deception, not unlike decisions made in the real world. Opponent modeling is another difficult problem in decision-making applications, and it is essential to achieving high performance in poker. This paper describes the design considerations and architecture of the poker program Poki. In addition to methods for hand evaluation and betting strategy, Poki uses learning techniques to construct statistical models of each opponent, and dynamically adapts to exploit observed patterns and tendencies. The result is a program capable of playing reasonably strong poker, but there remains considerable research to be done to play at world-class level. Copyright 2001 Elsevier Science B.V.", "authors": ["Darse Billings", "Aaron Davidson", "Jonathan Schaeffer", "Duane Szafron"], "n_citation": 375, "references": ["49e97933-8602-4057-ac58-f001f791fa7f", "4ba453bb-08c9-44d1-a1ed-9901a68a96d4", "51910c07-13e8-4aa6-8d36-398f0ff128da", "63b14ec0-e23f-4cf6-ac46-282ca57826de", "68c7d3b8-54a0-4cf7-be62-24cd0a4b45d6", "782d8c51-9df1-4d5e-8a2c-ac267b2bca28", "a2ffc45b-39b4-4660-891f-8cc7f8e10b87", "a5a70bda-52e0-49b0-a3e2-d3d41796ab3a", "aa562ce8-76af-4024-b262-55e4e453c2d6", "adf629b8-5962-4703-8a8c-cec376a25ebc", "c9759779-dc2d-4bc3-95b4-e239e11efa90", "e3805986-15b8-49f1-91d3-6f2206e95aca", "e6bbafd8-a587-4a09-ac77-e35a5292eb8b", "e846fa71-837f-420c-9cd2-4aa6216dfb45", "e899cb89-58db-44be-99d7-1d318183ffc1", "ed209b67-02ff-40a8-b2d0-2ea313c79073", "f513b4b8-5f0e-4e4a-8d80-49592725790a"], "title": "The challenge of poker", "venue": "Artificial Intelligence", "year": 2002, "id": "14eef52c-d66b-4e83-ab19-8e2082c6c296"}
{"abstract": "We describe a methodology for modeling, analysis and distributed control design of a large vehicular formation whose information graph is a  D -dimensional lattice. We derive asymptotic formulae for the closed-loop stability margin based on a partial differential equation (PDE) approximation of the formation. We show that the exponent in the scaling law for the stability margin is influenced by the structure of the information graph and by the control architecture (symmetric or asymmetric). For a given fixed number of vehicles, we show that the scaling law can be improved significantly by employing a higher dimensional information graph and/or by introducing small asymmetry (mistuning) in the nominally symmetric proportional control gains. We also provide a characterization of the error introduced by the PDE approximation.", "authors": ["He Hao", "Prabir Barooah", "Prashant G. Mehta"], "n_citation": 50, "references": ["0804139f-8817-4349-a37f-6492ea20eefa", "0f00588a-98ef-4f39-a52d-901f0c189cdd", "1061c1a3-2382-4889-a379-9d4dd8b493d1", "145dc0ca-e4dc-4937-a8a4-1be283a7a1e7", "2777faab-709f-4462-b490-489400a64047", "39d09a06-2016-4912-a8e5-25130fa4905f", "4ba029ab-7fef-4b18-8366-d4a4b309ad48", "58f9e085-bbab-43f1-9992-d38abf391566", "6050f54b-7b9e-4df9-ab67-4d9981b9c87d", "694af7e9-a498-4552-b7b6-e6325fb66ae8", "7371549e-9920-4ba0-a85b-b30a2c2ffbc9", "a5b49fea-16a6-4513-8e72-6a991b7186ad", "ab35dc68-62bd-4c54-81d3-9a8406827489", "c8a4ee14-55c4-4695-ad9e-566736e682a4"], "title": "Stability Margin Scaling Laws for Distributed Formation Control as a Function of Network Structure", "venue": "IEEE Transactions on Automatic Control", "year": 2011, "id": "4516deab-d1c1-4467-927c-b5919c88dba5"}
{"abstract": "In this report, we investigate approaches and algorithms for establishing a multicast session in a mesh network while protecting the session against any single link failure, e.g., a fiber cut in an optical network. We propose two new and efficient approaches for protecting a multicast session: 1) segment protection in which we protect each segment in the primary tree separately (rather than the entire tree) and allow these backup segments to share arcs with the other existing primary and backup segments; and 2) path-pair protection in which we protect a path between each source-destination pair by finding a disjoint backup path. Unlike previous schemes such as finding link-disjoint trees and arc-disjoint trees, our new schemes 1) guarantee a solution where previous schemes fail and 2) find efficient solution requiring less network resources. Our algorithm, based on the path-pair protection scheme, called optimal path-pair-based shared disjoint paths (OPP-SDP) algorithm, finds a solution if such a solution exists and outperforms all the other schemes in terms of network cost. We also show that OPP-SDP performs close to the optimal solution obtained by solving a mathematical formulation of the problem expressed as an integer linear program (ILP).", "authors": ["Narendra K. Singhal", "Laxman H. Sahasrabuddhe", "Biswanath Mukherjee"], "n_citation": 21, "references": ["0aec67fc-8408-4da6-ae54-ad1d6fd5a27b", "79cd3c3f-674d-45be-bef4-28b2586f23aa", "a83bd9b3-8028-42c1-a64c-01ee09661ad6", "c460a595-161b-47c9-941c-fa4e3009c275"], "title": "Protecting a multicast session against single link failures in a mesh network", "venue": "international conference on communications", "year": 2003, "id": "c7b40c13-6b63-421a-8ebd-4d7c3b51733e"}
{"abstract": "Abstract   Today's Web sites are intricate but not intelligent; while Web navigation is dynamic and idiosyncratic, all too often Web sites are fossils cast in HTML. In response, this paper investigates  adaptive Web sites :  sites that automatically improve their organization and presentation by learning from visitor access patterns . Adaptive Web sites mine the data buried in Web server logs to produce more easily navigable Web sites.  To demonstrate the feasibility of adaptive Web sites, the paper considers the problem of index page synthesis and sketches a solution that relies on novel clustering and conceptual clustering techniques. Our preliminary experiments show that high-quality candidate index pages can be generated automatically, and that our techniques outperform existing methods (including the Apriori algorithm,   K  -means clustering, hierarchical agglomerative clustering, and COBWEB) in this domain.", "authors": ["Mike Perkowitz", "Oren Etzioni"], "n_citation": 222, "references": ["2256cad0-cf03-42da-bcf3-4a89be0ebf8e", "271c13a3-16b3-404c-8c59-4363010e8dc6", "30354d92-9f05-4adf-aedf-8017b18eebe1", "37a4e33a-b030-4cef-b05c-90dc19a3d2ed", "407ceb18-464f-4ab3-b731-68f7681fb26d", "5cd3671c-a055-4852-97d1-a46c9b12fbf8", "5f02e7c1-95dd-4c9b-b977-2f8bf079c296", "60c814e2-c4d1-47d7-9a5a-68f4141505ae", "626f6ec9-a09a-43b8-9127-f6dc17161d28", "694f475e-f6c4-4105-b645-84c7d592db30", "76d92787-34a0-4223-90df-13819b019fa4", "85168cf8-e1cc-4d32-91e3-11817038f489", "929abc46-4b62-459b-a972-caa1d09e0fcc", "9ae0142d-b12f-42b1-ac48-d655fdec233f", "aed60d95-2ef8-4bd9-a9ff-672c1fee150e", "b49c1e2b-0cd0-4950-a724-00c698e5b49d", "bea7a43c-c6ad-4876-9a9b-f12704074aa8", "c69ef004-087e-486c-97c9-9b4587d0b10a", "d4d4286f-609d-42cb-a3a5-47f057ff4a7e", "d8ddd4ae-16ab-4702-b4f5-65aff0e33533", "dafa6b3f-b2bd-41b1-8d81-f5a3ce6c8a54", "dddfbe50-c5c7-4fe7-8f92-02e8f10db47f", "e49d47ee-5ab6-4dab-85e1-78b5d46e2f93", "e8ab235f-d709-4d84-87d4-c2dba5b73d32", "e97695ef-712a-43d7-b685-5ead1dce1139", "ecd6a845-8439-49b0-abe8-f71fff81da23", "ef16821d-03cb-4b7c-8561-be78cfe62b0e", "f51b782d-815b-4b0d-b9d6-8e676b413969"], "title": "Towards adaptive Web sites: conceptual framework and case study", "venue": "Artificial Intelligence", "year": 2000, "id": "f2e8263b-a3f9-442b-b1b0-98b56a374f6a"}
{"abstract": "We evaluate the QoS of a number of VoIP end-points, in terms of mouth-to-ear (M2E) delay, clock skew, silence suppression behavior and robustness to packet loss. Our results show that the M2E delay depends mainly on the receiving end-point. Hardware IP phones, when acting as receivers, usually achieve a low average M2E delay (45-90 ms) under low jitter conditions. Software clients achieve an average M2E delay from 65 ms to over 400 ms, depending on the actual implementation. All tested end-points can compensate for clock skew, although some suffer from occasional playout buffer underflow. Only a few of the tested end-points support silence suppression. We find that these silence detectors have a relatively long hangover time (> 0.5 sec), and they may falsely detect music as silence. All hardware IP phones we tested support some form of packet loss concealment better than silence substitution. The concealment generally works well for two to three consecutive losses at 20 ms packet intervals, but voice will quickly deteriorate beyond that.", "authors": ["Wenyu Jiang", "Kazuumi Koguchi", "Henning Schulzrinne"], "n_citation": 64, "references": [], "title": "QoS evaluation of VoIP end-points", "venue": "international conference on communications", "year": 2003, "id": "2141c216-cbd1-40ae-aca1-4f8e621c628e"}
{"authors": ["Hajime Sawamura", "Shinya Maeda"], "n_citation": 16, "title": "An Argumentation-Based Model of Multi-Agent Systems.", "venue": "European Journal of Combinatorics", "year": 2000, "id": "37a43308-61a5-4fdc-9b62-fca0ab248111"}
{"abstract": "Graphs are a common means to represent structures in models and meta-models of software systems. In this context, the description of model domains by classifying the domain entities and their relations using class diagrams or type graphs has emerged as a very valuable principle. The constraints that can be imposed by pure typing are, however, relatively weak; it is therefore common practice to enrich type information with structural properties (such as local invariants or multiplicity conditions) or inheritance.#R##N##R##N#In this paper, we show how to formulate structural properties using graph constraints in type graphs with inheritance, and we show how to translate constrained type graphs with inheritance to equivalent constrained simple type graphs. From existing theory it then follows that graph constraints can be translated into pre-conditions for productions of a typed graph transformation system which ensures those graph constraints. This result can be regarded as a further important step of integrating graph transformation with object-orientation concepts.", "authors": ["Gabriele Taentzer", "Arend Rensink"], "n_citation": 73, "references": ["1d106e2e-1f1a-46ab-b836-2f61e08e6a46", "2413e167-ae62-47da-a8dc-702ee61143ec", "419a31a8-b10a-41cf-b291-0dcfc4369b94", "5c759cf4-9b03-4b71-9864-2982764f6f0b", "70d97a36-5af6-4671-aeb9-8ec7cd7575f1", "784d5154-818d-441a-a060-2bc47dc8ddba", "a6bdd45c-c00b-4e88-a6ad-f7e3780a2310", "db89ef2b-7a82-47d3-be7e-9431ef8700c7", "fb7ffaf3-0088-4095-beac-87c53de9b8c9"], "title": "Ensuring structural constraints in graph-based models with type inheritance", "venue": "fundamental approaches to software engineering", "year": 2005, "id": "580ab270-1e16-4d10-b0a8-2f3a1f3423a4"}
{"abstract": "Static program slicing is an established method for analyzing sequential programs, especially for program understanding, debugging and testing. Until now, there was no slicing method for threaded programs which handles interference correctly. We present such a method which also calculates more precise static slices. This paper extends the well known structures of the control flow graph and the program dependencc graph for threaded programs with interference. This new technique does not require serialization of threaded programs.", "authors": ["Jens Krinke"], "n_citation": 173, "references": ["12aa3526-bb4a-48cc-b204-bbdeef243056", "2c08d317-3848-40af-9dfa-20c8ce584ce9", "30505a63-6a9b-4614-aacf-5d7531eca52e", "4165e8ce-3dc3-451b-9d18-847adeb48e35", "4cfd9e1c-3af4-4ade-b37f-9ed2f3e54be3", "6a5e8bc9-987b-4b98-9b16-7dcfd574a225", "8bfd8def-3c14-4168-964f-177c9bb0b99c", "9ca80df5-ae9a-42bb-be17-b6aa39a1c5d8", "a24b03a5-fd2b-4a91-88f8-42c8b62fdab1", "aa9805b3-4f30-46ae-af5b-a2cf2e915265", "abde5ea1-99dc-4812-aa90-50f17478138f", "c2cdf370-379d-4086-ac68-9967856d8d66", "c64f5fdc-5aac-4cb8-bd70-e93c5211d2bd", "cb5db9ec-eb1b-4f10-8d23-3aa92c6f877c", "f9fbe00e-2980-4c0e-a9b1-4e62fd5fa383"], "title": "Static slicing of threaded programs", "venue": "workshop on program analysis for software tools and engineering", "year": 1998, "id": "57ed9435-e85e-4c7f-a5a4-6a5548e7bd6c"}
{"abstract": "Business and social life have become increasingly dependent on large-scale communication and information systems. A partial or complete breakdown as a consequence of natural disasters or purposeful attacks might have severe impacts. Survivability refers to the ability of a system to recover from such disaster circumstances. Evaluating survivability should therefore be an important part of communication system design. In this paper we take a model checking approach toward assessing survivability. We use the logic CSL to phrase survivability in a precise manner. The system operation is modelled through a labelled CTMC. Model checking algorithms can then decide automatically whether the system is survivable. We illustrate our method by evaluating the survivability of the Google file system using stochastic Petri nets.", "authors": ["Lucia Cloth", "Boudewijn R. Haverkort"], "n_citation": 63, "references": ["22f427aa-d09c-4a26-8f32-db00821e1dc8", "40e83483-0cf7-4af9-af5b-df0f85903260", "5002dd27-9ce6-4abb-a3d0-2ac112f58c37", "59d5d987-6a7d-414e-9a5b-bd5d9b97ba6a", "733cec9f-923f-4873-9b79-1bce19009d08", "777a9303-be1d-436f-942a-fae8d0004d4f", "9a7e8549-bc5a-4fac-bba9-c4951f655a31", "9ac2e856-8d6f-4303-a4a2-411eb8122c0e", "9bbebbca-6164-4692-9c21-eb23e42320b6", "af72ab9b-5c44-4a83-9e36-dc2401bbed04", "c00bbb49-6e29-4103-8883-55acd23c248b"], "title": "Model checking for survivability", "venue": "quantitative evaluation of systems", "year": 2005, "id": "491be0ea-0fcf-4954-aa87-c71a7f1b96c0"}
{"abstract": "Congestion control in the current Internet is accomplished mainly by TCP/IP. To understand the macroscopic network behavior that results from TCP/IP and similar end-to-end protocols, one main analytic technique is to show that the the protocol maximizes some global objective function of the network traffic. We analyze a particular end-to-end MIMD (multiplicative-increase, multiplicative-decrease) protocol. We show that if all users of the network use the protocol, and all connections last for at least logarithmically many rounds, then the total weighted throughput (value of all packets received) is near the maximum possible. Our analysis includes round-trip-times, and (in contrast to most previous analyses) gives explicit convergence rates, allows connections to start and stop, and allows capacities to change.", "authors": ["Naveen Garg", "Neal E. Young"], "n_citation": 50, "references": ["014516cc-568c-4fc6-bd8d-85e114276af8", "09024120-ea26-415c-8ef9-d6d3c355f6bf", "0ee7ee7f-9642-4584-87ca-69c6ccbb0923", "1642f59c-10a1-40da-abb1-0934ef864108", "29bba593-705d-4703-94f9-3ef02e5a4638", "37a95a01-a4de-4b4d-92a4-b6e837ef9f6b", "3982acbe-7389-4113-9f73-f2fec71f09ef", "3d5c33b8-9736-4558-99b9-8180672ee303", "41037d67-1c45-40a6-8645-8158ca9c4424", "482ff893-0a03-4ef6-b140-8a9556155396", "496f167a-6b15-4ac2-afac-e53dc358cd31", "57ce8bc9-ff60-4cff-9599-756d2f3ee1ec", "5a919d29-6fca-4876-95a0-222c97ed9d13", "707bd4a0-cf5f-4bdd-8c7b-fe199c8e95d1", "72546b27-f891-452b-ae1a-eedc3f6273c1", "73d7ec09-de22-48ba-946a-94fe50ccacf8", "7b3bf193-dc90-4c63-8875-5e258d57bf8a", "80aaca43-d689-4120-a783-a3476831f695", "8bd90200-a804-41c5-b239-fd167bdbaf85", "8fd6531b-c809-4e63-895b-fb91be11759d", "935a2633-715f-4d03-9079-cdc3015df579", "b3cae739-ffac-48c0-b164-11b3088cc22c", "b3e90cfb-6e6a-40db-9b6c-e50916bd4edf", "b693686e-8c93-4495-801e-2bcedb22851d", "ba1f5e5c-072d-4434-8dde-75d1a6a48bd3", "c150f791-1014-4732-b499-363e9e5ef77d", "c850974f-9734-43b4-85fb-f23c7914dd3f", "c85faf2d-c776-4452-a6dc-e49368226fb9", "d0f49d3d-b23c-492d-885f-362a1466add7", "d29b395f-af6e-46ca-a894-60d9bcad0cc0", "d2b7db5d-bc47-48c7-a173-865fed9bff96", "d6fa4b78-c598-4035-a02a-bbeb0d79c509", "e279dd10-33f5-4ce4-aeba-785d635d8cc8", "e323da49-a744-404d-9d19-67a42f823fe2", "f7ac29e4-ccec-4452-863e-0058fa8df2a3", "fbc3b7d9-07af-47cb-8e6f-e88cba4a9e02"], "title": "On-line end-to-end congestion control", "venue": "foundations of computer science", "year": 2002, "id": "21e2927a-8a91-4002-9fce-7e233de45baf"}
{"abstract": "Introduction: Fuzzy sets probability and fuzziness fuzzy models. Membership functions: heuristic selections clustering approaches adjustment and toning applications concluding remarks. Fuzzy clustering: clustering and fuzzy partition fuzzy c-means algorithm fuzzy cohonen clustering networks cluster validity and optimal fuzzy clustering applications concluding remarks. Fuzzy rules and defuzzification: rules based on experience learning from examples decision tree approach neural network approach minimization of fuzzy rules defuzzification and optimization applications concluding remarks. Fuzzy classifiers: fuzzy nearest neighbour classifier fuzzy multilayer perceptron fuzy decision trees fuzzy string matching applications concluding remarks. Combined clasifications: introduction voting schemes maximum poteriori probability Dempster-Shafer evidence theory trained perceptron neural networks applications concluding remarks.", "authors": ["Zheru Chi", "Hong Yan", "Tuan D. Pham"], "n_citation": 132, "title": "Fuzzy Algorithms: With Applications to Image Processing and Pattern Recognition", "venue": "", "year": 1996, "id": "ba340c5c-275d-4210-8dbd-848ab4ded134"}
{"abstract": "Nonlinear dimensionality reduction is formulated here as the problem of trying to find a Euclidean feature-space embedding of a set of observations that preserves as closely as possible their intrinsic metric structure - the distances between points on the observation manifold as measured along geodesic paths. Our isometric feature mapping procedure, or isomap, is able to reliably recover low-dimensional nonlinear structure in realistic perceptual data sets, such as a manifold of face images, where conventional global mapping methods find only local minima. The recovered map provides a canonical set of globally meaningful features, which allows perceptual transformations such as interpolation, extrapolation, and analogy - highly nonlinear transformations in the original observation space - to be computed with simple linear operations in feature space.", "authors": ["Joshua B. Tenenbaum"], "n_citation": 300, "references": ["2834deb1-eaf2-40c8-899c-fdf2d28e556f", "3e7823cd-cff6-43b3-8df8-990f5525eb50", "5cdfcbfd-fec5-4df1-9e61-408a2de6c360", "5e831d18-db83-4d3d-b051-6028f77637d0", "a388da07-1608-4b15-aa08-a6cbb53be603", "ba3a624a-9a10-4e40-9d1d-2db068775a14", "c8095f8d-4a90-4abf-8711-b238f2dd89f0"], "title": "Mapping a Manifold of Perceptual Observations", "venue": "neural information processing systems", "year": 1998, "id": "d4301efe-ad14-44bc-b80e-62ef478bf8bf"}
{"abstract": "This paper describes the implementation of RTI-Kit, a modular software package to realize runtime infrastructure (RTI) software for distributed simulations such as those for the High Level Architecture. RTI-Kit software spans a wide variety of computing platforms, ranging from tightly coupled machines such as shared memory multiprocessors and cluster computers to distributed workstations connected via a local area or wide area network. The time management, data distribution management, and underlying algorithms and software are described.", "authors": ["Richard M. Fujimoto", "Thom McLean", "Kalyan S. Perumalla", "Ivan Tacic"], "n_citation": 107, "references": ["3fde9cbc-651b-4d22-9262-782c3f2bc4a6", "48a75d0b-cfdc-45e9-a66f-59a8cbce97ac", "7f64b879-c8e6-4ce7-920e-cc11f6617b33", "b6b76b77-6af1-48ea-8bb7-405a7079a3d7", "f61dd60f-640e-4559-956d-207d943144b3"], "title": "Design of high performance RTI software", "venue": "", "year": 2000, "id": "5b16f934-afa9-4b07-a0a7-197345c4f89a"}
{"authors": ["Daniel P. Huttenlocher", "Ryan H. Lilien", "Clark F. Olson"], "n_citation": 26, "references": ["5ebbd1f5-dfe5-4eec-9883-b8b5efea366c", "85114f9d-70a8-4940-83aa-af504b75acf8", "d15e4b6e-465e-483a-9611-a5db993ce20c", "d9752a5a-1603-45cc-9a21-7997750d429f"], "title": "Object Recognition Using Subspace Methods", "venue": "european conference on computer vision", "year": 1996, "id": "972825ed-69da-47d0-8197-2584e09d6a74"}
{"abstract": "Inference in Conditional Random Fields and Hidden Markov Models is done using the Viterbi algorithm, an efficient dynamic programming algorithm. In many cases, general (non-local and non-sequential) constraints may exist over the output sequence, but cannot be incorporated and exploited in a natural way by this inference procedure. This paper proposes a novel inference procedure based on integer linear programming (ILP) and extends CRF models to naturally and efficiently support general constraint structures. For sequential constraints, this procedure reduces to simple linear programming as the inference process. Experimental evidence is supplied in the context of an important NLP problem, semantic role labeling.", "authors": ["Dan Roth", "Wen-tau Yih"], "n_citation": 184, "references": ["063785f0-223e-4638-ad59-9578ccdb3000", "0b1f5092-4b64-4d5e-8bf7-15295db41f4f", "1f73723c-b904-4d93-8045-d8de3772fb27", "218e9d40-0003-4504-beab-24f89b3341fc", "4500809f-ea3e-4106-891d-c32622ec532f", "685230c5-5dbb-46c0-95fa-c7d1b5c3f7c1", "6f6b90cb-3ae6-4bae-922a-4a9af20781cc", "79ae2985-fa2e-45be-8b53-55b8bdafd8f2", "ae829318-5d10-461d-9c99-34a95a3f8732", "cb52a956-2990-4c3d-8cd0-d6a5a581a124", "d0e64387-0b6c-47fb-bb68-7d5832bbdb29", "de77ac15-7032-467c-87eb-2ef88f36ce02", "e3c48c0b-9d30-4edd-851d-e825e337b18d"], "title": "Integer linear programming inference for conditional random fields", "venue": "international conference on machine learning", "year": 2005, "id": "99ffa437-8f9f-45cd-83a7-e7dd56cfda0c"}
{"abstract": "In the past few years, query languages featuring generalized path expressions have been proposed. These languages allow the interrogation of both data and structure. They are powerful and essential for a number of applications. However, until now, their evaluation has relied on a rather naive and inefficient algorithm.In this paper, we extend an object algebra with two new operators and present some interesting rewriting techniques for queries featuring generalized path expressions. We also show how a query optimizer can integrate the new techniques.", "authors": ["Vassilis Christophides", "Sophie Cluet", "Guido Moerkotte"], "n_citation": 141, "references": ["08d6bcd4-61b6-4887-80c1-8c5293f90c14", "1036541c-cce6-4d45-987f-a0391f464540", "28b88cc5-9a17-4af5-818b-f16bb082bbd9", "2e18ac87-fc29-4a15-9126-e5e88e4ae58f", "3c1aa955-5377-48fe-bfcb-79c16681121b", "5df5cae4-b410-42e4-a652-536d4925a8bc", "876b1d4e-8930-42aa-a9a3-68786b3cc870", "af1571c1-7d9d-4304-9336-fb87009c9204", "b93f1493-e332-485b-9d75-f302872c22fe", "c92ee63c-7471-4e6e-9f62-f5bd83db5eba", "cb449c4a-05ae-45ce-bcc5-d4c46d9bf772", "d0bdbf1b-3046-426a-a444-62219ea5349f", "f2139883-eb27-4541-aac2-6e5c7d21ef0c", "fe3c4ab4-f3dc-4348-a958-5d13886a5d81"], "title": "Evaluating queries with generalized path expressions", "venue": "international conference on management of data", "year": 1996, "id": "3b6cb460-8714-4bcf-8c5f-14631345de6c"}
{"authors": ["Ahmet Ugur", "Michael Conrad"], "n_citation": 13, "references": ["beafa140-cc67-46e3-b47c-8765afab24ab"], "title": "Stucturing Pattern Generalization Through Evolutionary Techniques", "venue": "", "year": 1997, "id": "409b3d1c-146d-4e19-94b0-152ada612a96"}
{"abstract": "Bandwidth-limited high-rate digital communications systems use large constellations such as M-ary QAM, M/spl isin/{64, 128, 256, 512, 1024}. These square or cross-shaped constellations, though easy to implement, do not pack the symbols together as efficiently as possible, and besides are symmetric when the symbols are equiprobable and independent, so that no channel information is available from blind third-order statistics of the channel outputs. We develop high-order \"optimum\" hexagonal constellations, some of which are naturally asymmetric, and all of which can be modified to be asymmetric without exceeding the peak and average power levels of the corresponding M-ary QAM constellations.", "authors": ["Charles D. Murphy"], "n_citation": 50, "references": ["3894525d-0d2d-404f-8087-a3223ccd4f9e", "ccd9a3fd-9bab-467e-9584-11fd142c625a"], "title": "High-order optimum hexagonal constellations", "venue": "personal indoor and mobile radio communications", "year": 2000, "id": "b9246c98-50da-473a-a280-b969b83179ca"}
{"abstract": "Discovering association rules between items in a large database is an important database mining problem. The number of association rules may be huge. In this paper, we define a cover operator that logically derives a set of association rules from a given association rule. Representative association rules are defined as a least set of rules that covers all association rules satisfying certain user specified constraints. A user may be provided with a set of representative association rules instead of the whole set of association rules. The association rules, which are not representative ones, may be generated on demand by means of the cover operator. In this paper, we offer an algorithm computing representative association rules.", "authors": ["Marzena Kryszkiewicz"], "n_citation": 97, "references": ["51a2a139-ff14-4e03-9ee7-4a3806385a31", "929abc46-4b62-459b-a972-caa1d09e0fcc", "e8ab235f-d709-4d84-87d4-c2dba5b73d32", "ecd6a845-8439-49b0-abe8-f71fff81da23"], "title": "Representative Association Rules", "venue": "knowledge discovery and data mining", "year": 1998, "id": "1d8efbe9-c4c5-438f-b916-4ecc4cde6cc6"}
{"abstract": "The goal of this work is to recover human body configurations from static images. Without assuming a priori knowledge of scale, pose or appearance, this problem is extremely challenging and demands the use of all possible sources of information. We develop a framework which can incorporate arbitrary pairwise constraints between body parts, such as scale compatibility, relative position, symmetry of clothing and smooth contour connections between parts. We detect candidate body parts from bottom-up using parallelism, and use various pairwise configuration constraints to assemble them together into body configurations. To find the most probable configuration, we solve an integer quadratic programming problem with a standard technique using linear approximations. Approximate IQP allows us to incorporate much more information than the traditional dynamic programming and remains computationally efficient. 15 hand-labeled images are used to train the low-level part detector and learn the pairwise constraints. We show test results on a variety of images.", "authors": ["Xiaofeng Ren", "Alexander C. Berg", "Jitendra Malik"], "n_citation": 252, "references": ["04d8a9cb-a14d-4ccf-8b19-da1327e86b91", "09a4efee-bef3-4493-9280-a35fbfed8250", "29f196b0-3df4-43c9-bf33-6411f5adf879", "45ca28df-8cfb-489c-838a-966e319d13b4", "605d1271-dfdd-4076-92d3-6d79e5dcabae", "6f6fe122-6003-498c-a584-b27b3f7a6be3", "75c6e7ad-f17c-40e1-8c39-965534096b2b", "7dbebd4e-58d8-43c2-b122-ad1e3f820ac2", "82cf52b0-c1d8-4147-b496-451ef66c5825", "8e4a459f-61ea-4355-803f-842f903c995b", "9674b456-2f27-4658-a53c-71cd8e68b1c8", "de7686aa-6d09-4f1f-90a3-ba7815808e1d"], "title": "Recovering human body configurations using pairwise constraints between parts", "venue": "international conference on computer vision", "year": 2005, "id": "db7c5757-6e5b-4e1a-8a81-e652712d7cb7"}
{"abstract": "Image sequence processing techniques are used to study exchange, growth, and transport processes and to tackle key questions in environmental physics and biology. These applications require high accuracy for the estimation of the motion field since the most interesting parameters of the dynamical processes studied are contained in first-order derivatives of the motion field or in dynamical changes of the moving objects. Therefore the performance and optimization of low-level motion estimators is discussed. A tensor method tuned with carefully optimized derivative filters yields reliable and dense displacement vector fields (DVF) with an accuracy of up to a few hundredth pixels/frame for real-world images. The accuracy of the tensor method is verified with computer-generated sequences and a calibrated image sequence. With the improvements in accuracy the motion estimation is now rather limited by imperfections in the CCD sensors, especially the spatial nonuniformity in the responsivity. With a simple two-point calibration, these effects can efficiently be suppressed. The application of the techniques to the analysis of plant growth, to ocean surface microturbulence in IR image sequences, and to sediment transport is demonstrated.", "authors": ["Bernd J\u00e4hne", "H. Haussecker", "Hanno Scharr", "Hagen Spies", "D. Schmundt", "Uli Schurr"], "n_citation": 66, "references": ["0a8a1c36-77ce-405f-8d15-60f3c38fd076", "29535561-7e61-40c1-892a-b29f5e247d93", "3bea704d-bc63-4340-95a9-6b37ff2ba664", "4db6c10f-b1bb-49c2-b00c-bca8425aa979", "7d280214-84b9-4fc5-8a07-0176d8a88b11", "8eac8f36-c783-4cac-8278-07853a47d557", "9ed31210-b90b-437f-ab22-b91f0bc24b08", "fbeec176-d8ca-4700-9ad9-484d78f2a609", "fd1e24ca-8100-441a-8750-d7f53a67e9e7", "fd99a7a7-0aa2-4607-91bd-975285af5ad1"], "title": "Study of Dynamical Processes with Tensor-Based Spatiotemporal Image Processing Techniques", "venue": "european conference on computer vision", "year": 1998, "id": "dd395d85-6606-41ab-b981-3f4e477827cb"}
{"abstract": "Accurate performance predictions are difficult to achieve for parallel applications executing on production distributed systems. Conventional point-valued performance parameters and prediction models are often inaccurate since they can only represent one point in a range of possible behaviors. The authors address this problem by allowing characteristic application and system data to be represented by a set of possible values and their probabilities, which they call stochastic values. They give a practical methodology for using stochastic values as parameters to adaptable performance prediction models. They demonstrate their usefulness for a distributed SOR application, showing stochastic values to be more effective than single (point) values in predicting the range of application behavior that can occur during execution in production environments.", "authors": ["Jennifer M. Schopf", "Francine Berman"], "n_citation": 103, "references": ["12fd0e5f-adf6-4d18-a425-d6d025f3442a", "23b9a18a-6e2d-4ee5-9735-de6ff94422f7", "d59cc913-0ce0-4cd0-87d9-6586ec86c46a", "e1161405-6718-4983-8717-1354ecac5401"], "title": "Performance prediction in production environments", "venue": "", "year": 1998, "id": "3258362b-1060-4934-89fe-4b7c0af1e4d2"}
{"abstract": "In this paper, we propose a multitier approach for significantly lowering the cooling costs associated with fan subsystems without compromising the system performance. Our technique manages the fan speed by intelligently allocating the workload at the core level as well as at the CPU socket level. At the core level we propose a proactive dynamic thermal management scheme. We introduce a new predictor that utilizes the band-limited property of the temperature frequency spectrum. A big advantage of our predictor is that it does not require the costly training phase and still maintains high accuracy. At the socket level, we use control theoretic approach to develop a stable scheduler that reduces the cooling costs further by providing a better thermal distribution. Our thermal management scheme incorporates runtime workload characterization to perform efficient thermally aware scheduling. The experimental results show that our approach delivers an average cooling energy savings of 80% compared to the state of the art techniques. The reported results also show that our formal technique maintains stability while heuristic solutions fail in this aspect.", "authors": ["Raid Ayoub", "Krishnam Raju Indukuri", "Tajana Simunic Rosing"], "n_citation": 50, "references": ["02d61538-e29b-4559-aa02-231583e35719", "0c6e5b5a-fc50-40bf-bba9-a14d1793d17a", "11633392-cb01-41b2-9e4c-e428f03a9d61", "32f676ba-9eb5-428d-8b64-950f6c359a1b", "41827b18-8548-4b46-9daf-a5699cd30fee", "4cb01acd-4ad1-42bd-b935-37e78cee7a71", "4ee3abb7-124c-41f9-8b80-26e14434584b", "54a1ad4d-3909-424f-8d8e-6b6a4af34fa3", "5a3a43a1-770a-463f-9754-7f0f64a44b5b", "5e50cd9e-5c7b-44aa-93d1-6e069cf6521b", "75873bb7-b522-427d-ab8f-916a71a7e03a", "7c3bf329-09ba-47a6-92ff-0e872a42199a", "7f639bc2-353c-434c-a87c-c2fa18877243", "8b050564-921d-4c5f-9c36-2edbfaf03e01", "bccef9e2-d1e0-4494-aa75-91d24a2e7016", "bffc7330-9c4b-435a-ad5f-abe4e71c6a18", "c0e46805-ef74-48fd-b783-510afa3f59db", "c5ca1ea5-b790-4bac-b020-34477d38ff09", "e829a185-6ede-4cc0-a921-10aecae18a16"], "title": "Temperature Aware Dynamic Workload Scheduling in Multisocket CPU Servers", "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems", "year": 2011, "id": "e1d528e0-da6c-4c9f-93c9-380aa0a0e299"}
{"abstract": "In recent years the term Web 2.0 has been used to describe the transformation of the internet from a world of publishers and readers to one of collaborators where everyone is a creator of content, and 'communities' bind participants in an ecosystem. We have also seen the success of some software as a service (SaaS) applications, such as Salesforce.com, to the extent that application development is itself available as a hosted service (Salesforce's AppExchange, Coghead, etc.). We call this 'Dev 2.0', where the line between users and developers is blurred, and an application is available to all stakeholders through the life-cycle as it evolves.", "authors": ["Gautam Shroff"], "n_citation": 50, "title": "Dev 2.0: model driven development in the cloud", "venue": "foundations of software engineering", "year": 2008, "id": "1475d3e0-833f-48f2-9f36-7ce076e4a31b"}
{"abstract": "Peer-to-Peer (P2P) applications continue to grow in popularity, and have reportedly overtaken Web applications as the single largest contributor to Internet traffic. Using traces collected from a large edge network, we conduct an extensive analysis of P2P traffic, compare P2P traffic with Web traffic, and discuss the implications of increased P2P traffic. In addition to studying the aggregate P2P traffic, we also analyze and compare the two main constituents of P2P traffic in our data, namely BitTorrent and Gnutella. The results presented in the paper may be used for generating synthetic workloads, gaining insights into the functioning of P2P applications, and developing network management strategies. For example, our results suggest that new models are necessary for Internet traffic. As a first step, we present flow-level distributional models for Web and P2P traffic that may be used in network simulation and emulation experiments.", "authors": ["Naimul Basher", "Aniket Mahanti", "Anirban Mahanti", "Carey L. Williamson", "Martin F. Arlitt"], "n_citation": 150, "references": ["0aec2bdb-069b-4cc5-af69-8c733bb4b076", "0ca1cbca-31af-4327-8641-5e36f9d37942", "0f171ce6-8711-4cf8-a24b-31cba84c2b97", "34960356-7a78-4fef-82d2-397a185ae4ad", "3bb9b6ca-18dd-4d95-8c16-e7003ef32df4", "54a63f42-ce8c-4e88-8d35-2bf1e811ec64", "58e33263-8266-4b31-935f-dc0121a0e48d", "65471063-9cf4-4f04-87dc-5a10a39dc712", "909ce280-78ce-4b44-b351-b2fe243cd2f0", "97df247f-ef2b-43a6-a9fc-40d487fb7341", "a59be9de-2672-4f92-8ff6-636b3afbce68", "afd4c865-5c81-424b-82c3-1dcb6150ea6d", "b0d375eb-27da-4757-b58f-14caf430bca2", "bea42b9b-24ec-4479-9e8d-470cd5a1e4af", "c15b22e6-e856-49d5-b7af-42a275aa54e2", "c47f30a1-0126-41fa-b903-ff6818d35aac", "c67250fb-4ffc-415a-8f16-c3fea467fa86", "c82d6f8e-5ad6-4317-af5a-86d4b6bcf225", "cb4bc544-0d95-47f7-b4d5-4cf63f516d0e", "e72f4b1d-9f53-4587-a6f5-dd2ecbe0bc06", "ed5533a6-6b1a-4d50-a213-6e5a6eb6bce4", "f023c059-6c3d-47e1-9498-97bcf6937b12"], "title": "A comparative analysis of web and peer-to-peer traffic", "venue": "international world wide web conferences", "year": 2008, "id": "44ab1d02-8517-4a55-8a42-f40a7ff58c30"}
{"abstract": "Longest common subsequence is a widely used measure to compare strings, in particular in computational biology. Recently, several variants of the longest common subsequence have been introduced to tackle the comparison of genomes. In particular, the Repetition Free Longest Common Subsequence (RFLCS) problem is a variant of the LCS problem that asks for a longest common subsequence of two input strings with no repetition of symbols. In this paper, we investigate the parameterized complexity of RFLCS. First, we show that the problem does not admit a polynomial kernel. Then, we present a randomized FPT algorithm for the RFLCS problem, improving the time complexity of the existent FPT algorithm.", "authors": ["Guillaume Blin", "Paola Bonizzoni", "Riccardo Dondi", "Florian Sikora"], "n_citation": 14, "references": ["02ed122f-8651-4ac7-8d48-2700c3f66168", "14833d0d-8e36-4314-9e52-ffc6241a1ba7", "1df6409a-d5dd-4dc0-b67d-3d28911f7cf9", "2707ebdb-1a02-4487-948c-eafa80af21a0", "2d842097-4d2c-4c8e-8d13-b37aadd3e4d8", "75941cd8-1f8c-4c98-8494-ab098b39d3ea", "90f268d8-fa42-4512-ad94-2c9c44746b02", "93460177-06de-4d98-a540-25e1fcdf276c", "949f24a5-d4d8-4096-a810-1bd94cfaa877", "ae483426-5c18-463e-852a-7d0afb5cacd0", "b47bfd40-2657-4c15-9fe1-adfa738da227", "bd97c9e6-976f-4691-a6e2-4e2ad12980a3", "c7b6640f-0d4e-49e2-8705-74778902c853", "fb3b47f5-8fa3-434d-91ce-4de2d744451b"], "title": "On the parameterized complexity of the repetition free longest common subsequence problem", "venue": "Information Processing Letters", "year": 2012, "id": "b2f8cb3c-dad8-4107-b34f-fbb33f9ad008"}
{"authors": ["Antoni Oliver", "Marko Tadic"], "n_citation": 50, "references": [], "title": "Enlarging the Croatian Morphological Lexicon by Automatic Lexical Acquisition from Raw Corpora.", "venue": "language resources and evaluation", "year": 2004, "id": "bf3fb7d4-08f3-4099-9e77-870542ea5a0b"}
{"abstract": "Multicasting enables a group of hosts to communicate and share the information simultaneously. IP multicast technology allows the underlying IP network to transport a copy of the sending host's information to all members of the group, which can range in size from a few hosts to several thousand. Members of a multicast group are identified by a single group address rather than by their individual host addresses. The paper discusses the basics and the challenges facing IP multicast. It then focuses on reliable multicast issues.", "authors": ["Christopher Metz"], "n_citation": 50, "references": ["19a6c722-ce16-4044-8469-273c0971ca03", "19bb3151-ecc6-47d3-a639-476590858f2b", "6f1bb20f-25f0-4d0b-a7a5-f31e3fa66bdd", "a54c6b5d-41aa-43cd-afc3-94a659e91f21"], "title": "Reliable multicast: when many must absolutely positively receive it", "venue": "IEEE Internet Computing", "year": 1998, "id": "3872abb1-964f-4389-846e-653917dfd06b"}
{"abstract": "If \u03c0 is a graph property, the general node(edge) deletion problem can be stated as follows: Find the minimum number of nodes(edges), whose deletion results in a subgraph satisfying property \u03c0. In this paper we show that if \u03c0 belongs to a rather broad class of properties (the class of properties that are hereditary on induced subgraphs) then the node-deletion problem is NP-complete, and the same is true for several restrictions of it. For the same class of properties, requiring the remaining graph to be connected does not change the NP-complete status of the problem; moreover for a certain subclass, finding any \"reasonable\" approximation is also NP-complete. Edge-deletion problems seem to be less amenable to such generalizations. We show however that for several common properties (e.g. planar, outer-planar, line-graph, transitive digraph) the edge-deletion problem is NP-complete.", "authors": ["Mihalis Yannakakis"], "n_citation": 433, "references": ["027ec095-3bb9-4baa-bee6-e15e6c643ed5", "172f9f68-8417-43bb-8fe5-b377d569f6b6", "5fd0ccbc-571a-41e5-84f6-661ef525b12c", "8110182e-b1fc-455d-83ff-4d51a55d02a5", "8727fa07-90bc-4d49-8e55-d073bd44c8b0", "8d09527f-b5ad-4902-ba34-5583f6759d3b", "ab6a1d99-660c-49cf-bdb1-602c9e63cada", "c5368c25-5748-4af2-8b0f-f2cca8dbb4f0", "cca64dcf-c7a9-4362-ae44-41ced61161ee"], "title": "Node-and edge-deletion NP-complete problems", "venue": "symposium on the theory of computing", "year": 1978, "id": "9e05a68a-35e4-4c9f-8c1a-49619ba25066"}
{"abstract": "Power consumption is becoming more and more important with the increased popularity of smart-phones, tablets and laptops. The threat of reducing a customer's battery-life now hangs over the software developer who asks, \"will this next change be the one that causes my software to drain a customer's battery?\" One solution is to detect power consumption regressions by measuring the power usage of tests, but this is time-consuming and often noisy. An alternative is to rely on software metrics that allow us to estimate the impact that a change might have on power consumption thus relieving the developer from expensive testing. This paper presents a general methodology for investigating the impact of software change on power consumption, we relate power consumption to software changes, and then investigate the impact of static OO software metrics on power consumption. We demonstrated that software change can effect power consumption using the Firefox web-browser and the Azureus/Vuze BitTorrent client. We found evidence of a potential relationship between some software metrics and power consumption. In conclusion, we explored the effect of software change on power consumption on two projects; and we provide an initial investigation on the impact of software metrics on power consumption.", "authors": ["Abram Hindle"], "n_citation": 52, "references": ["033ebb72-0119-4cc9-89b8-f011c55ddd79", "30ccc346-4179-4134-b24a-f09ac9f61532", "34f1f2b4-a3a4-4307-8d61-798b61b2d85d", "60b32dbe-09e6-43d2-bf6b-451e039da765", "6b91b086-ad84-4414-baac-6013f07e14fd", "71b6f9fb-8b40-475b-ae03-665a836652a8", "9cc0eeaa-ff28-4486-9d75-df02179fa440", "c2e7c06d-6ada-43ad-945e-7d585b4c3809", "ce6409b7-0e46-4124-bdc3-75b74f8d0b04", "d8e69069-e66a-4684-8287-802ad30fa65a", "e91af4e0-e4eb-4ab9-a699-b972fe71f8f6", "ee9581f3-16f3-4b9d-8a0d-be7e174a6326"], "title": "Green mining: a methodology of relating software change to power consumption", "venue": "mining software repositories", "year": 2012, "id": "78869e00-c856-48bb-a493-72f551aabe67"}
{"abstract": "A complete and sound resolution operation directly applicable to the quantified Boolean formulas is presented. If we restrict the resolution to unit resolution, then the completeness and soundness for extended quantified Horn formulas is shown. We prove that the truth of a quantified Horn formula can be decided in O(rn) time, where n is the length of the formula and r is the number of universal variables, whereas in contrast the evaluation problem for extended quantified Horn formulas is coNP-complete for formulas with prefix ??. Further, we show that the resolution is exponential for extended quantified Horn formulas.", "authors": ["Hans Kleine B\u00fcning", "Marek Karpinski", "Andreas Fl\u00f6gel"], "n_citation": 319, "references": ["430b65f3-e516-4655-b53e-39f6b4993964", "5dff42ad-e16b-4b6a-bce3-fe808d109177", "716accdd-26ef-46a2-b268-625ccc38c1b4", "846d1da3-ce95-4784-9637-885b70145038"], "title": "Resolution for Quantified Boolean Formulas", "venue": "Information & Computation", "year": 1995, "id": "19f7105f-9a49-452c-962b-fec4ba1f5adb"}
{"abstract": "Discusses the notion of software process inconsistency and suggests that inconsistencies in software processes are inevitable and sometimes desirable. We present an approach to process analysis that helps discover different perceptions of a software process and that supports the discovery of process inconsistencies and process improvements stimulated by these inconsistencies. By analogy with viewpoints for requirements engineering that allow multiple perspectives on a software system specification to be managed, we have developed the notion of process viewpoints that provide multi-perspective descriptions of software processes. A process viewpoint includes a statement of focus or \"world view\", a set of sources of process information, a process description and a set of organizational concerns that represent goals or constraints on the process analysis. We present a description and rationale of process viewpoints, discuss the process of applying process viewpoints for process understanding, and illustrate the overall approach using part of a case study drawn from industrial processes that are part of a safety-critical system development.", "authors": ["Ian Sommerville", "Peter Sawyer", "Stephen Viller"], "n_citation": 56, "references": ["0b9ac3a1-01af-42a5-af12-85d7189ea8eb", "216b40cd-fe3c-405d-97c9-f3d1ea9eb870", "28268248-f61f-4525-855c-6955189388c4", "41118e41-8c3f-40f7-b26a-84881793384c", "53361270-3fb2-4913-81a9-aedfa685559f", "646011ef-b57b-4c8a-a12a-63c26987605d", "6b0331b1-e151-45a9-8ba4-695531e11c3b", "83d54f51-723b-4ab2-9ef7-b844797dacc1", "8696e539-3052-48dd-b4a7-e7b6250ec7a0", "8f1dad1e-a4af-4d68-9d13-013910a3e356", "9c9dee20-98c6-43a6-93af-582bba82e14e", "9d75abaa-9b70-437c-9d98-1d38261a2d49", "a173a1f5-074c-46fd-b5bd-84bb04866f7f", "a564ab2e-facf-4001-9a7c-c8f2c1eaee5b", "ae88fa07-be76-4057-8a77-8975929a23b8", "af990493-a799-42d6-baec-7c547d07738b", "d4c3a0a8-80f6-4450-b678-639692543e25", "e50fa3ec-9688-4a57-8ea8-07c502a07919", "e6dd2db0-4320-4115-b555-c950f41466e6", "ebcbae9a-5c5c-4746-adfb-c21c341aa39f"], "title": "Managing process inconsistency using viewpoints", "venue": "IEEE Transactions on Software Engineering", "year": 1999, "id": "ee4d186b-41f1-47ff-9366-f3c7e5dce68a"}
{"authors": ["Antonio Brogi", "Evelina Lamma", "Paolo Mancarella", "Paola Mello"], "n_citation": 50, "references": ["112674c9-d07a-4414-914a-67a382b218e7", "2c8ff6dc-dd4f-4c23-9099-19f9cd21ac1d", "2da2445c-da6e-4a0a-83b9-d857e06dc853", "330f1a4c-ed88-46e6-ba48-b0d427964160", "383a12c3-24e0-46e4-93f0-f62573196847", "3b9e10f8-d325-409a-938e-1891c3a2e098", "3f76eb00-3cb3-4e78-9c01-f7c56ebe309f", "4062fafd-7b5e-4c5c-8e81-8ff891ac334f", "58d39974-4e0f-4037-bcdf-9bc17e254fb0", "6168f75e-2918-43b6-b2e6-9e5eb8a0065b", "6948a86b-0b5b-4800-b75a-d72ce5b68633", "73285ee6-58ea-47b1-82f3-d1a681b3b98b", "8cc60b40-a36b-41f7-a9ec-ccc5f3f848ba", "b7f11790-46de-4d1f-a1ae-4e0c8d29da7e", "c0acfb02-cf8f-4298-be31-920a1ccf4aa5", "e22908da-10e5-49ec-93ed-2d7b1e1e8da3"], "title": "An Abductive Framework for Extended Logic Programming", "venue": "international conference on logic programming", "year": 1995, "id": "d296765c-1e86-42ca-a1fb-8f0dc06e3591"}
{"abstract": "The article further develops Kolmogorov's algorithmic complexity theory. The definition of randomness is modified to satisfy strong invariance properties (conservation inequalities). This allows definitions of concepts such as mutual information in individual infinite sequences. Applications to several areas, like probability theory, theory of algorithms, intuitionistic logic are considered. These theories are simplified substantially with the postulate that the objects they consider are independent of (have small mutual information with) any sequence specified by a mathematical property.", "authors": ["Leonid A. Levin"], "n_citation": 257, "references": ["0c0404b0-f23d-4b86-9097-d718a166ca06", "6e1dba69-c43b-4fbe-b811-efda3f57b185", "859b8745-baba-48e0-afc6-77ad082323f2"], "title": "Randomness conservation inequalities; information and independence in mathematical theories", "venue": "Information & Computation", "year": 1984, "id": "9737c0be-9360-47b6-8184-7e7be9ebe729"}
{"authors": ["Gary J. Nutt"], "n_citation": 50, "references": ["27cb1f2e-f84a-459e-9c6b-290522d3011c", "3162ce63-ed95-4da6-8f65-fe3d35a5b801", "32842160-8d20-4c43-afda-cf91cc552a9a", "4ebac8da-a1e6-47c7-9029-e49e5c55e01e", "71b3c4bf-d1ab-4d08-8661-bde872828af3", "857f3075-9462-4994-8b6c-64076be570e0"], "title": "A simulation system architecture for graph models", "venue": "applications and theory of petri nets", "year": 1991, "id": "1c600a97-4598-497f-9ac6-dd579b46ba86"}
{"abstract": "Software maintainers are faced with the task of regression testing: retesting a modified program on a (large) number of test cases. The cost of regression testing can be reduced if old test cases and old test results can be reused. Reuse avoids the costly construction of new test cases and the unproductive rerunning of existing test cases when it can be guaranteed that the modified and original programs will produce the same results. An algorithm that uses language semantics to provide such a guarantee is presented. This algorithm uses semantic (not syntactic) differences and similarities between the old and new programs. The algorithm is based on the notion of common execution patterns, which is the interprocedural extension of equivalent execution patterns. Program components with common execution patterns are computed using a new type of interprocedural slice called a calling context slice. Whereas an interprocedural slice includes the program components necessary to capture all possible executions of a statement, a calling context slice includes only those program components necessary to capture the execution of a statement in a particular calling context (i.e., a particular call to the procedure).", "authors": ["David Binkley"], "n_citation": 52, "references": ["0d89ee51-90ff-4653-a547-adfd849d18d4", "2ac5fedd-db52-4207-ac12-b527da60b604", "52b2b3b2-d8fe-47e8-b84a-0a04d50809f5", "69914123-2c23-4944-bdd6-1ffdd1fafed2", "86d0bfad-a86f-4860-91c0-ccb96c6a5353", "8cee46d9-232b-458f-88a3-21e214288749", "913c0136-008b-42f5-8029-494fd94adcd0", "9d1af739-1c53-49ce-b99f-8d6a227bc557", "a69de53e-f078-47c5-adf1-92572a649dcd", "b93357ac-959a-461c-aed3-fd1ca5542420", "bccd429a-7839-43ca-8784-128e4b5793e2", "f9fbe00e-2980-4c0e-a9b1-4e62fd5fa383", "fec08d3e-46fa-4e15-9728-f7d5e369afec"], "title": "Reducing the cost of regression testing by semantics guided test case selection", "venue": "international conference on software maintenance", "year": 1995, "id": "94689b25-48a5-4985-88ba-5d92e9ea4330"}
{"abstract": "Safe & Sound uses location-aware mobile phones to create a \"virtual leash\"; a secure zone beyond which a child may not travel. If the child leaves this zone, both child and parent receive audible alerts, and the parent can communicate with the child by voice over the phone. The peer-to-peer transmission of location, and the accepted role of responsibility by care-givers, reduce the privacy concerns which often arise with location-aware systems.", "authors": ["Natalia Marmasse", "Chris Schmandt"], "n_citation": 50, "references": ["ab748b79-390c-42e3-b1da-857ac75f523f"], "title": "Safe & sound: a wireless leash", "venue": "human factors in computing systems", "year": 2003, "id": "3afe32e2-94dd-4e16-b547-4982757b33db"}
{"abstract": "We study a multiprocessor task scheduling problem, in which each task requires a set of \u00b5 processors with consecutiveness constraints to be executed. This occurs, for example, when multiple processors are interconnected by communication means, and the minimization of communication time may require the processors to be physically adjacent and each multiprocessor task to use only one subset of adjacent processors. In particular, we consider the case in which we have m processors arranged in a ring, and we want to find a schedule with minimum makespan. We investigate problem complexity, showing that the problem is NP-hard in almost all the possible cases, and provide an approximation algorithm that finds a feasible schedule whose makespan is not greater than two times the optimal value.", "authors": ["Giuseppe Confessore", "Paolo Dell'Olmo", "Stefano Giordani"], "n_citation": 50, "references": ["1c993a62-243d-466d-bf3b-93f7d4593aa4", "26c6c933-2635-45f8-a923-d9dc29d35ad1", "916fc05a-fa5c-4a90-b5ac-98cb165bc76d", "c7a5ccc3-459a-44aa-a403-dec2a63576df"], "title": "Complexity and approximation results for scheduling multiprocessor tasks on a ring", "venue": "Discrete Applied Mathematics", "year": 2003, "id": "6c9ea7fc-ffad-4d31-ad90-ea8418d9ae80"}
{"abstract": "Easily comprehensible ways of capturing main differences between two classes of data are investigated in this paper. In addition to examining individual differences, we also consider their neighbourhood. The new concepts are applied to three gene expression datasets to discover diagnostic gene groups. Based on the idea of prediction by collective likelihoods (PCL), a new method is proposed to classify testing samples. Its performance is competitive to several state-of-the-art algorithms.", "authors": ["Jinyan Li", "Limsoon Wong"], "n_citation": 32, "references": ["080f1756-16ea-49c5-8c66-1b5e0044a507", "3a90b5d2-3377-4ffa-9545-9ef332679370", "514d2e13-1ec4-4df2-a570-43a89d4be0e8", "5899eb6c-2e22-4d79-a2be-15fe67911177", "5e5b4829-9c64-4c2b-8e00-cf50a7c9511c", "62549bc2-e0b3-46e8-8d32-390dded105d5", "65f8bc18-dfba-4ca7-a7b4-568b3cade0f0", "7f82d87d-55d5-42a5-b356-d7d377bfb000", "91979159-37d8-410f-a245-a33ef80a092b", "91f98247-ab9a-459c-ac7c-309ee51f62bd", "d20df5c3-667b-42d4-a128-d5f0b649cc32", "d8f66da3-1fb0-4b7c-8ab5-390c837ff9f2"], "title": "Geography of Differences between Two Classes of Data", "venue": "european conference on principles of data mining and knowledge discovery", "year": 2002, "id": "c4bbb570-d07f-4186-8339-27306e3b0230"}
{"abstract": "This work discusses the supporting role of ontologies for geosensor network data focusing on methods for linking geosensor network datasets with ontologies. A major benefit gained from this kind of linking is the augmentation of databases with generalization or specialization relations from an ontology. We present methods for linking based on a transportation application where data on vehicle position is collected from sensors deployed along a road network and stored in a geosensor database. A mechanism for linking, implemented as a tab widget within the Protege ontology editor, is introduced. This widget associates data values from the geosensor database with classes in the ontology and returns linked terms (i.e., matches) to the user as a set of equivalence relations.", "authors": ["Kathleen Hornsby", "Kraig King"], "n_citation": 50, "references": ["11db345e-64a8-41bd-a6bf-433a50c1c1c1", "137de291-af63-4fe8-92f2-44a1e11a2ada", "1a0b3973-c710-4d9b-8d52-b63130345de3", "1b86e716-ddf2-43d3-83d9-697ff7d0d22a", "2a0203c2-80b2-44f6-bfb8-dc7953f3787b", "2dc3dc17-9887-4936-a496-e6af90114300", "32732142-7bf6-4ac2-8f67-e4735ddcc718", "434872be-aba7-437b-98ab-f1a83c474f3b", "5a862f73-1c5c-4aec-9bfe-2050b0b57e78", "66c95b9d-7dc4-4ada-9701-69b264129773", "836e620a-45b7-4392-833a-f79f00713a53", "85c7b0b4-a874-48d2-9292-0ccd7d3e7274", "900d6f8d-087f-443b-ba5c-bc3c9c42f073", "90d8a2e9-8a23-4a0b-ab32-0a41ed1c6611", "9a5998d9-83c7-4dd8-93cd-860996834679", "a812e6d6-4beb-4a7b-95b4-1caae26e3dce", "ba6985fe-d317-4309-8460-f2b13cc71a2e", "c306db54-6880-49e9-affd-cc5c41034538", "dac8b108-a7b1-4180-8762-c6ba01eca0a1", "db30b82f-83d0-483d-91ad-0df5417ef470", "dfe2f700-69de-4082-ac28-8530675d2746", "e3a03959-d881-46e3-8d11-ce2e534ec508", "ea712e3d-a72f-4a04-a979-b39c01b0d02e", "ed29e6a6-9b42-4522-ad45-c6a7d7474b48", "ef3b30a6-5e79-4e5f-9e00-c62bf80e0dee"], "title": "Linking Geosensor Network Data and Ontologies to Support Transportation Modeling", "venue": "geosensor networks", "year": 2008, "id": "a28b3ce0-c311-4008-963a-b349ecb8d9b6"}
{"abstract": "Multi-level annotation of images is a promising solution to enable more effective semantic image retrieval by using various keywords at different semantic levels. In this paper, we propose a multi-level approach to annotate the semantics of   natural scenes   by using both the dominant image components and the relevant semantic concepts. In contrast to the well-known image-based and region-based approaches, we use the salient objects as the dominant image components to achieve automatic image annotation at the content level. By using the salient objects for image content representation, a novel image classification technique is developed to achieve automatic image annotation at the concept level. To detect the salient objects automatically, a set of detection functions are learned from the labeled image regions by using Support Vector Machine (SVM) classifiers with an automatic scheme for searching the optimal model parameters. To generate the semantic concepts, finite mixture models are used to approximate the class distributions of the relevant salient objects. An   adaptive EM algorithm   has been proposed to determine the optimal model structure and model parameters simultaneously. We have also demonstrated that our algorithms are very effective to enable multi-level annotation of   natural scenes   in a large-scale dataset.", "authors": ["Jianping Fan", "Yuli Gao", "Hangzai Luo", "Guangyou Xu"], "n_citation": 88, "references": ["407954ac-5b24-408f-b111-c57ee378359a", "68e638ce-46c5-4372-a708-81194362e658", "6a323522-b788-407e-b857-4fb19b9f2465", "6b050045-343f-4944-8dd8-ece9595de169", "6f259e99-cf8a-4d51-bf52-cff59e67ddc9", "750b0ac1-2ac9-4273-a9c8-baad11e26fcd", "8bc5f80f-af26-47b4-aa0a-aab3a2e6c503", "8d446544-964a-478a-a5cd-0eb62197c99f", "904cbad5-94b6-4992-b1fa-4e68c56f18ab", "a2ed7fe7-dd1d-4910-9d5e-57f48f64598d", "b784ecb4-dfe3-4950-aeaf-c6b87ca500e5", "b7e4ddc6-b5ce-4457-a531-0eb6ea818ce8", "c883f4ce-8f94-4d80-8cf8-7aef1966b53e", "c8f80ea6-4602-458c-9a70-daf1c646c89b", "cb5e3b2d-a97e-461f-b99e-d4593d0ef2d7", "d7311e9f-19ba-41b5-b998-6802a12da2b8", "d8b8efc0-4de2-47e0-b05b-5959b61090a5", "e4a00699-ec7b-473f-afed-186f9f68990b", "f339c737-8324-4cfb-b1af-0b34cec252d2"], "title": "Automatic image annotation by using concept-sensitive salient objects for image content representation", "venue": "international acm sigir conference on research and development in information retrieval", "year": 2004, "id": "93c382be-ac49-470f-88fc-7e06e21a60a1"}
{"abstract": "Today, the Wideband Global SATCOM (WGS) system employs a new concept of adjusting the transponder power gain of individual links. A simple optimum method is derived for selecting these individual channel gains to minimize the amount of transponder power utilized. This new method directly solves a set of simple nonlinear equations and does not utilize any search algorithms or matrix inversions thus allowing it to be used with any number of links in a transponder.", "authors": ["John J. Knab"], "n_citation": 50, "references": [], "title": "Transponder Power Minimization Utilizing Optimum Channelizer Gains", "venue": "IEEE Transactions on Aerospace and Electronic Systems", "year": 2012, "id": "44aa1eda-606c-46f2-a624-a8eb1d04a604"}
{"abstract": "In this contribution we present an extension of the prediction scheme proposed in Manitius and Olbrot (1979) for the compensation of the input delay to the case of linear systems with both input delay and state delay. For simplicity of the presentation we treat the case of systems with one state delay.", "authors": ["Vladimir L. Kharitonov"], "n_citation": 13, "references": ["a8049107-a9c0-4468-9b4f-8e56cbbe1b88"], "title": "An extension of the prediction scheme to the case of systems with both input and state delay", "venue": "Automatica", "year": 2014, "id": "f6af0173-2cc2-4b56-981b-738d09764229"}
{"abstract": "This paper proposes a globally exponentially stable (GES) observer for attitude estimation based on a single time-varying reference vector, in inertial coordinates, and corresponding vector, in body-fixed coordinates, in addition to angular velocity readings. The proposed solution is computationally efficient and, in spite of the fact that the observer does not evolve on the Special Orthogonal Group SO(3), an explicit solution on SO(3) is also provided, whose error is shown to converge exponentially fast to zero for all initial conditions. The distinct roles of the inertial and the corresponding body-fixed vectors on the observability of the system are also examined and simulation results are shown that illustrate the performance of the proposed attitude observer in the presence of low-grade sensor specifications.", "authors": ["Pedro Tiago Martins Batista", "Carlos Silvestre", "Paulo Jorge Ramalho Oliveira"], "n_citation": 50, "references": ["15f04237-8b54-4a18-9959-561d33455262", "161e536c-8fa0-4280-8b2a-c70b7adf95bb", "3aaf4670-5045-41ed-bde1-71f9d81f99d3", "46ff7750-bfed-4a8c-bda8-182640e17464", "5868b246-5c3c-4cf9-a122-9a1f72dff1bc", "5f91dbb8-81a8-4e49-8002-8a6757fb5961", "64743278-7332-4232-ba2d-b67d9405cb73", "a7d20577-1ab8-4b9f-afd2-9fd7c7ed15ad", "bc6a0093-6cf5-4a2c-b999-0f84507a1a6f", "c007c5e0-3b5e-4997-be0d-e085cf06daae", "c343cf06-6d4f-48a7-aa89-4826ac4737cf", "cdcea9b8-825f-4ca5-a9ec-5246cc469c97", "f574ef42-0d10-4b19-afdc-b234aba26e02", "f5d8315e-8022-4964-a037-ba758a9a3827"], "title": "Brief paper: A GES attitude observer with single vector observations", "venue": "Automatica", "year": 2012, "id": "9ae76882-92d2-4c5d-a932-247ec42b5a12"}
{"abstract": "Many different distributed hash tables (DHTs) have been designed, but only few have been successfully deployed. The implementation of a DHT needs to deal with practical aspects (e.g. related to churn, or to the delay) that are often only marginally considered in the design. In this paper, we analyze in detail the content retrieval process in KAD, the implementation of the DHT Kademlia that is part of several popular peer-to-peer clients. In particular, we present a simple model to evaluate the impact of different design parameters on the overall lookup latency. We then perform extensive measurements on the lookup performance using an instrumented client. From the analysis of the results, we propose an improved scheme that is able to significantly decrease the overall lookup latency without increasing the overhead.", "authors": ["Moritz Steiner", "Damiano Carra", "Ernst W. Biersack"], "n_citation": 54, "references": ["3ff82e2d-f4bf-4c74-8ddd-3c7d13cd53c4", "412121e2-2d48-4c7b-9da1-3a6ad9e8fa05", "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4", "4ef0e696-ed0d-4801-a5f7-ae03e59f4d13", "8b6776c9-b65c-4a15-a9be-4b2034fb5d9c", "b68c5227-549b-4252-a57f-ac4c5679133c", "d06f8723-1b89-4684-99c9-c1045ddfb85c", "d70a953c-16e5-4e6c-8c20-d003c1d35900", "e1263ada-afda-498c-a37d-9b545293118a", "f14df1ed-e3e9-4348-9040-fc06e3411b95"], "title": "Faster Content Access in KAD", "venue": "international conference on peer-to-peer computing", "year": 2008, "id": "9a091d58-ca0b-4cb2-ac72-98e3f9bf3201"}
{"authors": ["Enrique Alba", "Jos\u00e9 M. Troya"], "n_citation": 371, "references": ["0ebbf572-def3-41b2-a7c8-849cea546e96", "16f6e38d-cea1-4b32-9d7c-78805508fe30", "1efe4068-d56f-47bb-9e86-8d2bf099f07d", "3152f0f5-207d-4fbc-95e5-6a8003cc4c36", "36e1d713-ea53-4307-849f-fc40d4575ea2", "3fae7550-7b05-4209-8e1a-160007edbad1", "4a3fcbdf-ca12-43fc-9749-14be278ad087", "58c8aafe-805f-4e4a-87ba-fa296a871f0b", "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "6d882eb9-28bb-48ea-8156-213cca215014", "700f12b2-84f6-415c-b403-160e4068707f", "771fa406-dd67-4f66-b113-70b27563c4d8", "779c96d1-210e-47fd-bfe0-cc60208340de", "9ab28841-6751-445c-93df-7180332c6906", "9b80e173-2d0d-4e2d-8cd0-0fcfe230fd81", "a15a2b46-1c30-4b65-a6d1-1af3fb3b7246", "a4f4cd45-f2bb-491b-b392-42d17849a807", "b4ec3584-b5e8-48c6-9b48-be4a0b2d458d", "bac5da35-9009-41a3-b758-21aec812a9ee", "c159e0f0-94e3-49c2-a92a-ce12d5e4655b", "d54b5273-8df7-4104-bc67-ca65cd0cd23b", "dfd41975-6848-411d-b231-67426f90b299", "e184cb56-a353-42dc-a4d3-8fc7648e63bd", "e6588c2d-5ce2-4cfe-a8d1-3e884cce2dda", "f0c39a75-65eb-47f0-9b9b-c64e53f12803"], "title": "A survey of parallel distributed genetic algorithms", "venue": "Complexity", "year": 1999, "id": "93460faa-50cb-4a01-b25b-86d8968c85a9"}
{"abstract": "Recent years have seen the development of a number of expert system type tools who's primary objective is to provide support to a human during the process of database analysis and design. It is generally accepted that these tools, although possessing database design knowledge, are in most cases ignorant of the application domains in which they work, and as such are required to ask what may be regarded as extremely trivial questions in order to elicit the required information. This paper illustrates how domain knowledge representing aspects of these applications may be represented within such tools using a thesaurus approach, and how this knowledge may be exploited by a tool during design processing. It discusses how the technique has been applied to a knowledge based tool designed to support the development of object-oriented databases, resulting in an increase in both the processing efficiency and the overall appearance of intelligence of the tool.", "authors": ["M. Lloyd-Williams"], "n_citation": 21, "references": ["132ba600-5d5a-43cb-b3bd-c058a70efc54", "275eb1c6-9930-4f47-9dba-7d3c1b0f9c17", "2b7288d1-f253-436e-aa41-7085e4c02e83", "3c58fab2-684b-41dd-ac58-d94b6a3e8b8e", "4b725b55-d71a-4339-941a-09d4b8e7e354", "4e9c347b-0852-495a-8fc4-59c0c5dd0a55", "c8ea58ca-6aa0-453c-9c57-3e4408374102", "fdf351d7-9f94-482e-8f42-6b80790570f2"], "title": "Exploiting Domain Knowledge During the Automated Design of Object-Oriented Databases", "venue": "international conference on conceptual modeling", "year": 1997, "id": "8e6cb43f-b602-4061-8f6f-e2023beb523c"}
{"abstract": "Abstract   The twisted cube topology is a variant of the binary hypercube structure for multiprocessors, with the same amount of hardware but a diameter of only ( d  + 1)/2 in a cube of dimension  d . It has a distributed routing algorithm that is slightly more complex than that for the hypercube. However, we demonstrate in this paper that the main drawback of the network is that it is asymmetric, and this fact has significant consequences for the dynamic performance of the system. We examine the effects of these asymmetries as well as the overall performance of this new structure as a case study in the architecture of better topologies for direct connected mutliprocessors. We find that the twisted cube delivers an improvement in performance over the hypercube, but not nearly as much as the reduction in diameter.", "authors": ["Seth Abraham", "Krishnan Padmanabhan"], "n_citation": 102, "references": ["124aa98b-5836-4386-96f0-62511fd93e05", "8118ee30-0a56-4ede-a815-6117478888b2", "e9c6fe64-7880-4ef1-b6d8-1e341e9ef92e"], "title": "The twisted cube topology for multiprocessors: a study in network asymmetry", "venue": "Journal of Parallel and Distributed Computing", "year": 1991, "id": "63a8f202-a2d7-4a26-a2a8-fb637aede755"}
{"abstract": "A type system is a syntactic method for automatically checking the absence of certain erroneous behaviors by classifying program phrases according to the kinds of values they compute. The study of type systems -- and of programming languages from a type-theoretic perspective -- has important applications in software engineering, language design, high-performance compilers, and security.This text provides a comprehensive introduction both to type systems in computer science and to the basic theory of programming languages. The approach is pragmatic and operational; each new concept is motivated by programming examples and the more theoretical sections are driven by the needs of implementations. Each chapter is accompanied by numerous exercises and solutions, as well as a running implementation, available via the Web. Dependencies between chapters are explicitly identified, allowing readers to choose a variety of paths through the material.The core topics include the untyped lambda-calculus, simple type systems, type reconstruction, universal and existential polymorphism, subtyping, bounded quantification, recursive types, kinds, and type operators. Extended case studies develop a variety of approaches to modeling the features of object-oriented languages.", "authors": ["Benjamin C. Pierce"], "n_citation": 2583, "title": "Types and Programming Languages", "venue": "", "year": 2002, "id": "9a4181a5-70d2-48b7-945d-8d72d9c74874"}
{"abstract": "A treatment of the positive observation problem for positive systems is provided, for the continuous and discrete-time cases. The proposed observers are positive, that is, they ensure that the estimates are nonnegative at any time. Moreover, necessary and sufficient conditions for the existence of such positive observers are formulated in terms of linear programming. Also, we show how positive observers can provide guaranteed bounds on the real states of uncertain positive systems. In addition, some implications are discussed; especially, it is shown that it is not possible to stabilise an unstable system using these positive observers. Finally, the applicability of the proposed interval estimation approach is shown for an illustrative application from pharmacokinetics.", "authors": ["Mustapha Ait Rami", "Fernando Tadeo", "Uwe Helmke"], "n_citation": 50, "references": ["0351b8be-8e97-4cf2-9bd4-e62206dc9e32", "50b4ef50-9df4-47e7-8fce-58b1f97b252b", "57c74b55-d96e-44d3-a123-cd2d484fe0ec", "fe7f23d6-5049-4ccf-ac88-959677d197b6", "ff3a0578-828c-4b2f-88d5-7c48dee833cb"], "title": "Positive observers for linear positive systems, and their implications", "venue": "International Journal of Control", "year": 2011, "id": "f1e50da3-21a0-4486-94e0-240d1dfec60f"}
{"abstract": "Heuristics have become an accepted and widely used adjunct method of usability evaluation in Internet and software development. This report introduces Heuristic Evaluation for Playability (HEP), a comprehensive set of heuristics for playability, based on the literature on productivity and playtesting heuristics that were specifically tailored to evaluate video, computer, and board games. These heuristics were tested on an evolving game design to assess their face validity and evaluation effectiveness compared to more standard user testing methodologies. The results suggest that HEP identified qualitative similarities and differences with user testing and that HEP is best suited for evaluating general issues in the early development phases with a prototype or mock-up. Combined with user studies, HEP offers a new method for the HCI game community that can result in a more usable and playable game.", "authors": ["Heather Desurvire", "Martin Caplan", "Jozsef A. Toth"], "n_citation": 202, "references": [], "title": "Using heuristics to evaluate the playability of games", "venue": "human factors in computing systems", "year": 2004, "id": "becf8747-4a1b-446e-9695-9ccbf2ff799f"}
{"abstract": "We use Hamilton-Jacobi-Bellman methods to find minimum-time and energy-optimal control strategies to terminate seizure-like bursting behavior in a conductance-based neural model. Averaging is used to eliminate fast variables from the model, and a target set is defined through bifurcation analysis of the slow variables of the model. This method is illustrated for a single neuron model and for a network model to illustrate its efficacy in terminating bursting once it begins. This work represents a numerical proof-of-concept that a new class of control strategies can be employed to mitigate bursting, and could ultimately be adapted to treat medically intractible epilepsy in patient-specific models.", "authors": ["Dan Wilson", "Jeff Moehlis"], "n_citation": 50, "references": ["199b77c6-57e2-40d3-85bf-f37abddabb86", "2ecbe2c2-c2d6-4214-b7af-77d4fbb1e858", "9af1249d-27b8-4f3a-bdbb-28aaf89a47a1", "c8fc8a70-42ac-4ba0-bb07-2a599d04b2e2", "c97c493e-9c69-48bd-977e-0d537441bae8", "e512dc80-42ae-4d6b-b7b8-4765377bef75"], "title": "A Hamilton-Jacobi-Bellman approach for termination of seizure-like bursting", "venue": "Journal of Computational Neuroscience", "year": 2014, "id": "1e2fa758-46d1-4558-9bd2-58857111d0f1"}
{"abstract": "Diagrams can be represented by graphs, and the animation and transformation of diagrams can be modeled by graph transformation. This paper studies extensions of graphs and graph transformation that are important for programming with graphs: /spl middot/ We extend graphs by a notion of hierarchy that supports value composition, and define hierarchical graph transformation in an intuitive way that resembles term rewriting. /spl middot/ We require that admissable shapes for hierarchical graphs are specified by context free graph grammars, in order to set up a type discipline for shapely hierarchical graph transformation. The resulting computational model shall be the basis of the visual language DIAPLAN for programming with graphs that represent diagrams.", "authors": ["Berthold Hoffmann"], "n_citation": 50, "references": ["016b16e5-a4de-4969-bc51-d264144c8818", "1e459f12-9ffa-43aa-8dcf-f22a6b8d2d5a", "330c47ed-d4c4-409e-a9ea-b404e2fb47d4", "3bbb99b2-0521-4e12-a549-ad4a97ec0970", "42ea6086-62ba-4bfa-b59c-4e454c848818", "769c3d0c-0abb-4b31-8153-36d5c51f96e0", "7d3cd478-1fb9-468a-9055-96c6e4c7ef4b", "81b6a0a2-aa09-4dde-be34-df18ce7a3b1e", "c2b74ddf-bf21-4d77-8af4-047770318c68", "c32832f1-b2d8-4c88-8da3-b9a6a5430128", "e6a3e90b-c365-43f0-a4b8-15e856eb7cc5"], "title": "Shapely hierarchical graph transformation", "venue": "", "year": 2001, "id": "2121bde2-4bcd-4e60-917e-7fc5b327cbd9"}
{"abstract": "Replacing the lscr 2  data fidelity term of the standard total variation (TV) functional with an lscr 1  data fidelity term has been found to offer a number of theoretical and practical benefits. Efficient algorithms for minimizing this lscr 1 -TV functional have only recently begun to be developed, the fastest of which exploit graph representations, and are restricted to the denoising problem. We describe an alternative approach that minimizes a generalized TV functional, including both lscr 2 -TV and lscr 1 -TV as special cases, and is capable of solving more general inverse problems than denoising (e.g., deconvolution). This algorithm is competitive with the graph-based methods in the denoising case, and is the fastest algorithm of which we are aware for general inverse problems involving a nontrivial forward linear operator.", "authors": ["Paul Rodriguez", "Brendt Wohlberg"], "n_citation": 186, "references": ["0faa4cfc-a770-45ec-b667-20232524f909", "1bc88bf1-8d70-44cd-a588-b9fb3c3a2c5a", "1c491f42-dbb1-4f9c-afd5-e921b54b45c1", "28191a51-1c6d-4fb7-842a-fa2be24fe6ec", "2ad802e0-dfe8-401c-b42f-0cfc575a4801", "3a5b3200-84ee-4a07-82f6-ea7de6fba3f9", "4c3633ec-bb74-4ee6-8059-21ed5b16e0e8", "609e4691-b520-4e1c-aa44-65a230512357", "6aebafce-f4c0-4a34-8a36-b9ede925fb8e", "7db1957b-66a4-439f-a9bd-ca89aea58642", "84718398-9e09-43a1-adfc-0fc4cfe015ba", "84bee1b3-94c1-4c5e-be80-7215b62480fb", "87df428e-4187-4857-afc2-2bbecb40e804", "9359a605-8a2a-4611-aec8-8605c91a04ee", "95036700-fda4-42de-81af-bf7ec7f06932", "9ec51dea-b1bb-49cc-9e36-9a13dfcadd52", "a44303f8-cb38-4156-801f-9eaed6f2e106", "a4806847-a0ff-4dff-bd65-720237ac541d", "bedf3789-4f62-4b70-963c-c4b390cd6f63", "e38d3d17-3296-400a-8dd0-48a5ab461049", "efa407cf-e88f-4de5-9d4a-c66b0802d5ea", "f2c1bdc4-bfb6-4c97-8efd-04bc4937adca", "fb3eb505-20cf-4163-b5f9-c95dae0ff98f", "fb9c6135-6964-4d0a-8b2f-e2f1f195ed3e"], "title": "Efficient Minimization Method for a Generalized Total Variation Functional", "venue": "IEEE Transactions on Image Processing", "year": 2009, "id": "af1ef030-6768-40a6-a2f1-6d4a8f81a63b"}
{"authors": ["Johannes Hummel", "Ulrike Lechner"], "n_citation": 22, "references": ["35b695cc-bd79-484b-a76e-49d272b435b6", "84e6b422-77b7-4536-8b5c-8a894530bb12", "d6285e34-13fa-4327-b4f9-203181baa8c6"], "title": "Communities - The Role of Technology", "venue": "european conference on information systems", "year": 2001, "id": "f4ba339f-15ce-4ddc-99b8-395617376098"}
{"abstract": "In this paper, we study the performance of frequency allocation schemes in forthcoming OFDMA-based systems. These systems include WiMAX and 3G long term evolution. We first develop an analytical model for the collisions for an arbitrary number of users in the different cells. We then calculate the capacity of the system using a Markov model and taking into account the inter-cell interference and its impact on the adaptive modulation. We apply this model to compare four frequency allocation schemes, namely reuse 1, reuse 3, and static and dynamic mixes of reuse 1 and 3. We also considered a fifth scheme, called partial isolation and proposed for 3G LTE systems, that uses different transmission powers in the different frequency bands, in order to reduce interference at cell edge. Our results show that the partial isolation scheme outperforms all the others, especially in the downlink, as it combines the advantage of the reuse 1 scheme (large overall throughput) with that of the mix of reuses 1 and 3 (good cell-edge performance).", "authors": ["Salah Eddine Elayoubi", "O. Ben Haddada", "B. Fourestie"], "n_citation": 267, "references": ["9c8c80a8-60ea-4ec0-9fe3-964e440eb0a2", "bedc75f1-98c4-4196-b322-bf585598250c", "c1ae6dd3-c59a-43ee-8388-755198ff94c1", "dea0bec4-8dbd-41ae-aa37-ea418843f296", "f0e5d0c7-72ce-49f1-a5a1-3e8eef50fd61", "f478067d-8d6a-433b-88c6-99806dcd81ee"], "title": "Performance evaluation of frequency planning schemes in OFDMA-based networks", "venue": "IEEE Transactions on Wireless Communications", "year": 2008, "id": "4719c378-0dca-4845-85f6-a4edc2e1d07b"}
{"abstract": "We describe a system for respiratory motion correction of MRI-derived roadmaps for use in X-ray guided cardiac catheterisation procedures. The technique uses a subject-specific affine motion model that is quickly constructed from a short pre-procedure MRI scan. We test a dynamic MRI sequence that acquires a small number of high resolution slices, rather than a single low resolution volume. Additionally, we use prior knowledge of the nature of cardiac respiratory motion by constraining the model to use only the dominant modes of motion. During the procedure the motion of the diaphragm is tracked in X-ray fluoroscopy images, allowing the roadmap to be updated using the motion model. X-ray image acquisition is cardiac gated. Validation is performed on four volunteer datasets and three patient datasets. The accuracy of the model in 3D was within 5 mm in 97.6% of volunteer validations. For the patients, 2D accuracy was improved from 5 to 13 mm before applying the model to 2-4 mm afterwards. For the dynamic MRI sequence comparison, the highest errors were found when using the low resolution volume sequence with an unconstrained model. (C) 2009 Elsevier B.V. All rights reserved.", "authors": ["Andrew P. King", "Redha Boubertakh", "Kawal Rhode", "Y. Ma", "Phani Chinchapatnam", "Gang Gao", "T. Tangcharoen", "Matthew Ginks", "Michael Cooklin", "Jaswinder Gill", "David J. Hawkes", "Reza Razavi", "Tobias Schaeffter"], "n_citation": 71, "references": ["07369065-7a42-46c4-8331-64ea647800bc", "1d8cece6-ede6-41b3-9824-25e76d78c497", "20ee86b8-fc94-4647-9a98-d0f174557f54", "37323397-84b3-417d-8acf-8f423cc9f00d", "4660ed7d-2c02-4f20-a5aa-50c377a647c1", "69e110be-d28f-45e8-84bd-0059502fb3e4", "802b0fd0-e9b3-48a1-971c-2e7d658f8b67", "b315430e-6894-44cf-b770-eaa32836fb51", "d29bbf41-8cf9-4fdb-a85f-36c3b6c68226"], "title": "A subject-specific technique for respiratory motion correction in image-guided cardiac catheterisation procedures", "venue": "Medical Image Analysis", "year": 2009, "id": "bec18dfe-449c-493e-87b5-cfb3d1900ac9"}
{"abstract": "In this paper, we have proposed a progressive alignment method using a genetic algorithm for multiple sequence alignment, named GAPAM. We have introduced two new mechanisms to generate an initial population: the first mechanism is to generate guide trees with randomly selected sequences and the second is shuffling the sequences inside such trees. Two different genetic operators have been implemented with GAPAM. To test the performance of our algorithm, we have compared it with existing well-known methods, such as PRRP, CLUSTALX, DIALIGN, HMMT, SB_PIMA, ML_PIMA, MULTALIGN, and PILEUP8, and also other methods, based on genetic algorithms (GA), such as SAGA, MSA-GA, and RBT-GA, by solving a number of benchmark datasets from BAliBase 2.0. To make a fairer comparison with the GA based algorithms such as MSA-GA and RBT-GA, we have performed further experiments covering all the datasets reported by those two algorithms. The experimental results showed that GAPAM achieved better solutions than the others for most of the cases, and also revealed that the overall performance of the proposed method outperformed the other methods mentioned above.", "authors": ["Farhana Naznin", "Ruhul A. Sarker", "Daryl Essam"], "n_citation": 50, "references": ["1804739a-79b0-4cfa-bcfc-2a7e3ce5aa86", "253b3138-05e6-4b4c-8250-110cb0b7b7d9", "315b67d3-9a3e-41c0-be24-938f047f4f51", "57446c43-44ad-4734-a65a-e1dea940bbb0", "58ccf255-97b9-408f-bd20-51c356142803", "595defb3-c346-4b10-b373-b8a74557ac1a", "6c65654c-52b7-4d4d-88e6-c098ab81cd1c", "6d5a2046-5d07-4693-8b74-f4899ce04f4d", "98edb5d2-0c50-4bca-b8ec-5560e9cfc773", "9c5a416c-77ef-4fdb-9a24-b4010c8e570d", "a9384399-70c0-458b-b987-4b3c4d8776ba", "a95e86bc-ae94-4833-90d3-41b421d1831d", "aff3cae6-fbcf-4ebc-ae07-053e51b7bb99", "b2f2e8ed-8e72-425c-a21e-292794165d95", "b93ad759-61e6-4127-9382-ac9c5d528207", "c4726d4f-e5dc-4052-a61a-1ca4057725a6", "c7a3a86e-1143-43dc-81f9-05676be52b3b", "cab268f0-b162-474e-86fd-21d623bc39e5", "e3d24655-feff-4e3b-a63f-a9a2066cca38", "fedfeb81-44ee-49d9-a02e-f0179d336bd3"], "title": "Progressive Alignment Method Using Genetic Algorithm for Multiple Sequence Alignment", "venue": "IEEE Transactions on Evolutionary Computation", "year": 2012, "id": "80995c72-2eb7-4fd1-b753-661447e1dd3c"}
{"authors": ["Chez Ciechanowicz", "Keith M. Martin", "Fred Piper", "Matthew J. B. Robshaw"], "n_citation": 50, "title": "Ten Years of Information Security Masters Programmes", "venue": "", "year": 2003, "id": "302077c1-81ce-4679-b05b-7141b32b3367"}
{"abstract": "We present an extensive analysis of software metrics for 111 object-oriented systems written in Java. For each system, we considered 18 traditional metrics such as LOC and Chidamber and Kemerer metrics, as well as metrics derived from complex network theory and social network analysis. These metrics were computed at class level. We also considered two metrics at system level, namely the total number of classes and interfaces, and the fractal dimension. We discuss the distribution of these metrics, and their correlation, both at class and at system level. We found that most metrics follow a leptokurtotic distribution. Only a couple of metrics have patent normal behavior while three others are very irregular, and even bimodal. The statistics gathered allow us to study and discuss the variability of metrics along different systems, and to devise a roadmap for further research.", "authors": ["Giulio Concas", "Michele Marchesi", "Alessandro Murgia", "Sandro Pinna", "Roberto Tonelli"], "n_citation": 26, "references": ["0de91a59-b37f-4008-b201-0d168f5645b8", "10652b6d-d7a7-4913-afa3-f635dff0ddcc", "1166c556-ad74-4838-9d1f-bbfbece046ac", "283a47a0-f895-4185-b433-fe7a35408aca", "30815526-0779-47a3-9dd4-6a0ea56e0448", "493f51c9-d389-4555-afb2-30aa84e56649", "57af1f08-da6a-466f-97a2-99e98a992768", "6e6202cd-6dbe-4bba-b198-326f2168c517", "842e96df-fb8b-43ba-8643-4b3714b44dbf", "b87a4fe7-505c-4b97-8568-570b158f3373", "d32786fc-ea8d-41f0-a803-5d00e550329c", "d4cd2afd-272c-4189-8686-7cb50d6e012c", "e5a2cb68-a00b-43ac-bf5f-b7c03292110d"], "title": "Assessing traditional and new metrics for object-oriented systems", "venue": "", "year": 2010, "id": "4ddbf7d6-9f75-419b-bdd4-f77753381305"}
{"abstract": "The WibQuS project investigates distributed computer and communication support for Total Quality Management in industrial organizations. An interdisciplinary study of this task reveals three aspects of intelligent cooperation required from such a system which we call conceptual, technical, and social integration. We use the repository standard IRDS to characterize these aspects. A solution concept derived from this characterization employs advanced conceptual modeling techniques to derive interoperability among technical subsystems and coordination technology for the human subsystem semi-automatically while taking important social factors into account.", "authors": ["Matthias Jarke", "Manfred A. Jeusfeld", "Peter Szczurko"], "n_citation": 50, "references": ["9db758f0-2b16-427f-a51b-47e3ace26b5f", "abd8710b-ef44-4ee6-92dd-34ceffe11a16", "d1d4f5e8-fa0d-4a89-bd61-6dc9dc47260f", "d63dd4ae-4b30-484b-8ffc-88d21839ddad"], "title": "THREE ASPECTS OF INTELLIGENT COOPERATION IN THE QUALITY CYCLE", "venue": "International Journal of Cooperative Information Systems", "year": 1993, "id": "b2f85682-d3a7-4be6-9695-242e38782a09"}
{"abstract": "The emergence of the Internet has broken down geographic and organizational boundaries, providing a virtual common workplace regardless of the heterogeneity of participating organizations. Enterprise projects that used to be done autonomously now span multiple organizations. While an inter-organizational workflow, as one of several technologies supporting inter-organizational collaboration, provides an easy-to-use collaborative work environment for users, it also increases the complexity of security maintenance and brings about security problems that are not considered before. Unconventional collaborations among business and organizations are formed to advance common goals. In this paper, we address the security services to support inter-organizational collaborative enterprises, which may span multiple organizations, and describe how we develop a secure workflow system to satisfy the requirements by integrating with existing, well known technologies. Although we apply our ideas to particular technologies, such as workflows and RBAC, in this paper, we believe it is always possible to apply our approaches to other systems, which support many users from different organizations.", "authors": ["Joon S. Park", "Myong H. Kang", "Judith N. Froscher"], "n_citation": 9, "references": ["0b80880f-e44f-4ba9-aa22-78250f2bd1b7", "31bc6b98-df30-40e0-b8f0-c902158a4d96", "34ae9d49-e94a-4665-9498-3f394598640e", "41cf9713-ed76-43a6-8e9f-538abc2f787c", "75abf605-134c-4fcc-b099-3d77de135d12", "8183f696-ff46-4211-bdb9-8182156b56a6", "aabd8f07-c961-4df7-98b9-759c8667497c", "d3fb098c-9e7c-4550-a76d-e0d3019b957f", "e3f3873c-4621-430d-9a1f-561bd8127562", "ecfb2022-e18c-4e5e-8733-d8bc6f4c8fc9"], "title": "A Secure Workflow System for Dynamic Collaboration", "venue": "information security", "year": 2001, "id": "b9cef5e4-950c-4800-ae3b-d11323d71c27"}
{"abstract": "Authoring the domain knowledge of an intelligent tutoring system (ITS) is a well-known problem, and an often-mentioned approach is to use authors who are domain experts Unfortunately, this approach requires that potential authors learn to write and debug knowledge written in a formal knowledge representation language If authors were able to use natural language to represent knowledge it would allow them to add and update knowledge far more easily In this paper, the design of such an authoring system, \u2018Natural-K' is presented Natural-K is an authoring system in which domain authors including non-programmers are able to add problem statements and background knowledge such as commonsense, in natural language.", "authors": ["Sung Young Jung", "Kurt VanLehn"], "n_citation": 11, "references": ["64aa7bd8-cdf8-40cc-82fe-5650e20e870f", "cb9b9943-4898-4632-a285-ab0c69360043"], "title": "Developing an intelligent tutoring system using natural language for knowledge representation", "venue": "intelligent tutoring systems", "year": 2010, "id": "775afb23-47fb-4faf-9e4b-f8e8c4145b96"}
{"abstract": "In this paper, we introduce a new algorithm called Multi-Population Genetic Algorithm (MPGA) as an effi- cient optimization technique for highly nonlinear problems. Our MPGA is a parallel implementation of a GA and shows its robustness for our problem domain (Task Based Design; TBD) where we design a manipulator which is best suited for a given task. The MPGA has the same number of optimization fuac- tions as the number of task points and maintains almost con- stant complexity and does not depend on the number of task points. In addition, we develop a framework called Progressive Design, in which we design progressively based on coarse-6ne approach.", "authors": ["Jin-Oh Kim", "Pradeep K. Khosla"], "n_citation": 50, "references": ["2ba9aea3-f296-432e-9903-82a923c1fe0c", "4f3b2637-a2c9-4e72-bbcf-52975024f3db", "551c5b46-5bd0-4a42-93c4-98edac02d8f0", "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "99c5c371-1aca-40b6-b9a1-054e780b3266", "a1d72860-6f84-4fd8-b0af-db37f610b920"], "title": "A Multi-population Genetic Algorithm And Its Application To Design Of Manipulators", "venue": "intelligent robots and systems", "year": 1992, "id": "d4ac28f4-f294-42b3-9f0d-3e3b247f141e"}
{"abstract": "Recently, a number of extensions to the traditional transaction model have been proposed to support new information-intensive applications such as CAD/CAM and software development. However, these extended models capture only a subset of interactions that can be found in such applications, and represent only some of the points within the spectrum of interactions possible in competitive and cooperative environments.   ACTA  is a formalizable framework developed for characterizing the whole spectrum of interactions. The ACTA framework is  not  yet another transaction model, but is intended to unify the existing models. ACTA allows for specifying the  structure  and the  behavior  of transactions as well as for reasoning about the concurrency and recovery properties of the transactions. In ACTA, the semantics of interactions are expressed in terms of transactions' effects on the commit and abort of other transactions and on objects' state and concurrency status (i.e., synchronization state). Its ability to capture the semantics of previously proposed transaction models is indicative of its generality. The reasoning capabilities of this framework have also been tested by using the framework to study the properties of a new model that is derived by combining two existing transaction models.", "authors": ["Panayiotis K. Chrysanthis", "Krithi Ramamritham"], "n_citation": 266, "references": ["35b671b4-5e95-4a09-bae3-f0d94e648119", "5d60aed9-9736-4448-9a12-a7e597ea83d1", "670c2a3e-5e72-44fb-acdf-73efdaca2acb", "7ebe29de-5725-40bc-9c4a-16289fd5f86e", "8b04c501-bd64-4041-9946-5d9e546ca437", "ec8ed5f7-51f6-47e3-8b04-97e5fe0122b7", "f9d4c631-85e7-43c1-8b16-b88cb5e77fa1"], "title": "ACTA: a framework for specifying and reasoning about transaction structure and behavior", "venue": "international conference on management of data", "year": 1990, "id": "2d6f2382-4ed9-486a-baad-dc8279b0eafc"}
{"abstract": "Biaxial contouring systems involve competing control objectives of maximising accuracy while minimising traversal time. In this paper, a model predictive controller for contouring systems is proposed where the control inputs are determined by minimising a cost function which reflects the trade-off between these competing objectives, subject to state and actuator constraints. To facilitate real-time implementation, a linear time-varying approach is proposed, and stability is guaranteed by introducing an additional contraction constraint. Simulation results for an XY table system demonstrate the effectiveness of the proposed contouring control scheme.", "authors": ["Denise Lam", "Chris Manzie", "M C Good"], "n_citation": 20, "references": ["0ce60417-2119-438e-8bc0-c3774f1d83dc", "18a711cf-af09-479c-8516-0ee6ae326afe", "2f09a4f1-df84-44eb-9b79-dee5a3297b53", "afb90136-02fa-45ab-bbce-a6a3d735b772"], "title": "Model predictive contouring control", "venue": "conference on decision and control", "year": 2010, "id": "d0748017-fca1-44e7-8c87-3c23e040868b"}
{"abstract": "From the participatory action research we have conducted in two rural communities in Australia we suggest six factors that assist in achieving sustainability for ICT initiatives undertaken in pursuit of regional development. They include: #R##N# #R##N##R##N#  Clearly specified sustainability goals;#R##N#  Leveraging micro-business enterprise development off government funded technical and human infrastructure provision, and using local industry strengths;#R##N#  Learning from global experiences whilst building on local assets;#R##N#  Finding innovative business models to capitalise on new opportunities for content and applications;#R##N#  Ensuring community involvement in deciding, planning and evaluating projects; and#R##N#  Adopting a learning approach.", "authors": ["Greg Hearn", "Megan Kimber", "June Lennie", "Lyn Simpson"], "n_citation": 38, "references": ["70b044cf-7e29-40f0-b23f-20c9657b1acd"], "title": "A way forward: Sustainable ICTs and regional sustainability", "venue": "", "year": 2005, "id": "76f93f96-d97c-4dbb-bbea-a9a149ade672"}
{"abstract": "Rough sets and fuzzy sets are both theories for handling uncertain problems, and the viewpoints between them are different. They are complementary than competitive. Much seminal research has been carried out into combining them both; the results are rough fuzzy sets and fuzzy rough sets. In this paper, we introduce the idea of fuzzy rough sets in research of decision tables with quantitative data. Thus, we can handle the decision table directly without discretization. Combining the idea of variable precision rough sets, we make the form of the upper and lower approximation uniform.", "authors": ["Du Weifeng", "Li Haiming", "Gao Yan", "Meng Dan"], "n_citation": 50, "references": ["a4589cfe-15e7-4c34-9349-d002d1d2c9df"], "title": "Another kind of fuzzy rough sets", "venue": "granular computing", "year": 2005, "id": "6d5951be-fe1c-485b-b87e-6aaac05bcab2"}
{"abstract": "A key technology of space robots is to maintain the satellite attitude while space service is proceeding. This paper discusses the motion planning and control methods for both robot satellite attitude and robotic end-effector actions in the form of collaboration. A single gimbal control moment gyro (SGCMG) system is adopted to maintain the satellite attitude because of higher output torque than traditional reaction flywheels. From the viewpoint of disturbance momentum calculations, the EGJM matrix is proposed and the motions are controlled without the complex dynamics calculations of disturbance torque which causes larger computation and less efficiency. At last an optimal end-effector path is designed to minimize the disturbance momentum which should be compensated by SGCMGs. The performance of designed strategies is tested in a hardware-in-the-loop simulation environment which involves the space robot dynamics.", "authors": ["Zhenyu Li", "Hong Liu", "Bin Wang"], "n_citation": 1, "references": ["135633b1-c8b1-42b5-b759-952f5e0972e7", "161ac9c1-77ad-4b54-8a90-b0c6674f05af", "627883c0-e4d7-492a-9b77-0b1def6dfda3", "83e53703-a350-46b2-a05e-2fce719183c9", "8baf9512-04fd-4d9d-9b02-c4aa165f82fa", "94ed54ae-5652-4124-a728-a9b093ae1063", "d5c0c3ad-b4e0-4a5a-ac4a-fe5ef4540dc9", "efbed683-6fda-4bc4-b831-af50ff6c775c"], "title": "Motion planning and coordination control of space robot using methods of calculated momentum", "venue": "robotics and biomimetics", "year": 2013, "id": "0c5e2b14-8d6d-4f14-bbc9-c62104c57f8b"}
{"abstract": "Real-time programming is a software engineering discipline that has been around ever since the dawn of digital computing. The dream of real-time programmers is to unlock the virtually unlimited potential of software for embedded computer systems - digital computers that are supposed to behave like analog devices. The perfect embedded computer system is invisibly hybrid, it works according to the largely unidentified laws of embedded software but acts according to the laws of physics. The critical interface between embedded software and physics is real-time and yet, while physical processes evolve in real-time, software processes do not. Only the embedded computer system as a whole - embedded software and hardware - determines a complex notion of so-called soft-time to which the software processes adhere: mapping soft-time to real-time is the art of real-time programming. We discuss various realtime programming models that support the development of real-time programs based on different abstractions of soft-time. We informally introduce a real-time process model to study (1) the compositionality of the real-time programming models and (2) the semantics of real-time programs developed in these models.", "authors": ["Christoph M. Kirsch"], "n_citation": 60, "references": ["069f6c80-0468-4bfa-9ca0-3338a4ecb999", "287dff48-c445-4c27-ad8a-b624852bb657", "2f75256b-de9d-43e8-83ef-ddece7d7e7b7", "4d88d8d2-de58-48eb-a375-3f61f13b2297", "8df9df7d-3d01-43bb-b168-50725b7a616b", "ac13706a-6f08-4800-9083-0c89385bd709", "c73c10aa-9100-49ca-bb95-b04ad6fecd50", "d38f2f4c-3436-4f14-a76b-f96aa46f5d51", "f684754c-6017-4bb8-a9bf-42140f97fa72", "fc71f2c9-226d-4448-86b7-3e7cd6b0f6e7"], "title": "Principles of Real-Time Programming", "venue": "embedded software", "year": 2002, "id": "afffbfd1-0a40-41c9-8b98-4da49a938db5"}
{"abstract": "When students are learning to develop algorithms, they very often spend more time dealing with issues of syntax rather than solving the problem. Additionally, the textual nature of most programming environments works against the learning style of the majority of students. RAPTOR is a visual programming environment, designed specifically to help students envision their algorithms and avoid syntactic baggage. RAPTOR programs are created visually and can be executed visually by tracing the execution through the program. Required syntax is kept to a minimum. Students preferred expressing their algorithms visually, and were more successful creating algorithms using RAPTOR than using a traditional language or writing flowcharts.", "authors": ["Martin C. Carlisle", "Terry A. Wilson", "Jeffrey W. Humphries", "Steven M. Hadfield"], "n_citation": 74, "references": ["06de2abd-e0f8-4040-91e1-e652bc658dc0", "b3d3b93e-7046-4235-a2c5-48546240f78e", "c38d06a0-ab9c-4804-a121-074ee1f332f8", "f7d9d7ee-1247-41cb-a5de-d15595362df0"], "title": "RAPTOR: a visual programming environment for teaching algorithmic problem solving", "venue": "technical symposium on computer science education", "year": 2005, "id": "6b6df4b6-3755-4523-8410-5b1fb8420bc4"}
{"authors": ["Marco Botta", "Attilio Giordana"], "n_citation": 5, "references": ["1724ba77-3bbb-49c0-8ebc-763902cbfff0", "2e0440f5-ff19-4894-891f-385d53dcf19d", "3c3dcb11-33b8-430e-84de-cba31caf1b0f", "9a5b3808-641b-4a6b-8916-b74a9577b4eb", "b49c1e2b-0cd0-4950-a724-00c698e5b49d", "ec86f1e1-1a22-4e2a-8dd2-4e1204563e81"], "title": "Learning Quantitative Features in a Symbolic Environment", "venue": "international syposium on methodologies for intelligent systems", "year": 1991, "id": "b9390952-a8ef-423d-9ceb-b919c1fcb702"}
{"abstract": "A Bayesian scheme for fully unsupervised still image segmentation is described. The likelihood function is constructed by assuming that the grey level at each pixel site is a realization of a Gaussian random variable of unknown parameters, there being an uncertain number of distinct Gaussian classes in the image. Spatial connectivity between pixels is encouraged via a Markov random field prior. The task of identifying the model parameters and recovering the underlying class label at each site (i.e. segmentation) is accomplished using a novel reversible jump Markov chain Monte Carlo (MCMC) scheme. This scheme explores the space of possible segmentations via proposals that are driven by the actual image realization-so-called data-driven proposals. The aim is to (i) induce good mixing in regions of high probability, and (ii) to optimize the acceptance probability of the proposals. A key development is a stochastic version of a recursive labeling algorithm which has been used in previous work for fast image region splitting. In the current stochastic context, it yields fast and effective split and merge proposals. The performance of the novel MCMC scheme is illustrated in simulation.", "authors": ["Ed Clark", "Anthony Quinn"], "n_citation": 50, "references": ["31e350c1-0600-4d59-9171-d2085a17d7bd"], "title": "A data-driven Bayesian sampling scheme for unsupervised image segmentation", "venue": "international conference on acoustics speech and signal processing", "year": 1999, "id": "7a91c4d4-2836-415f-8039-9ae5fb574dd5"}
{"abstract": "In recent years, it is remarkable to see the increasing number of studies related to the theory and application of fractional order controller (FOC), specially  PI   ?   D   ?  controller, in many areas of science and engineering. Research activities are focused on developing new analysis and design methods for fractional order controllers as an extension of classical control theory. In this paper, a new tuning method for fractional order proportional and derivative ( PD   ? ) or FO-PD controller is proposed for a class of typical second-order plants. The tuned FO-PD controller can ensure that the given gain crossover frequency and phase margin are fulfilled, and furthermore, the phase derivative w. r. t. the frequency is zero, i.e., the phase Bode plot is flat at the given gain crossover frequency. Consequently, the closed-loop system is robust to gain variations. The FOC design method proposed in the paper is practical and simple to apply. Simulation and experimental results show that the closed-loop system can achieve favorable dynamic performance and robustness.", "authors": ["Hong Sheng Li", "Ying Luo", "Yang Quan Chen"], "n_citation": 279, "references": [], "title": "A Fractional Order Proportional and Derivative (FOPD) Motion Controller: Tuning Rule and Experiments", "venue": "IEEE Transactions on Control Systems and Technology", "year": 2010, "id": "b4c50e7a-2fcd-4eb3-95a2-cf8d635f8d5e"}
{"abstract": "We propose a multiresolution color feature extraction scheme based on octree data structure to achieve efficient and robust image retrieval. With the proposed method, multiple color features, including the dominant color, the number of distinctive colors and the color histogram, can be naturally integrated into one framework. A selective filtering strategy is also described to speed up the retrieval process. Retrieval examples are given to illustrate the performance of the proposed approach.", "authors": ["Xia Wan", "C.-C. Jay Kuo"], "n_citation": 50, "references": ["2d64f94f-4bd7-4662-a06d-957e7dc515c4", "4d65c147-3ff3-4c80-82ad-760057fd2310", "9414a4e0-a36b-4203-bc68-d70b77a19132", "ce3aa99c-a4d6-4554-94f7-1c9ebde88a65"], "title": "A multiresolution color clustering approach to image indexing and retrieval", "venue": "international conference on acoustics speech and signal processing", "year": 1998, "id": "62d3d60d-c4e7-48ae-9a3f-5013c5b2e462"}
{"abstract": "Example-based graphics generation systems automatically create new information visualizations by learning from existing graphic examples. As part of the effort on developing a general-purpose example-based generation system, we are building a visual database of graphic examples. In this paper, we address two main issues involved in constructing such a database: example selection and example modeling. As a result, our work offers three unique contributions: First, we build a visual database that contains a diverse collection of well-designed examples. Second, we develop a feature-based scheme to model all examples uniformly and accurately. Third, our visual database brings several important implications to the area of information visualization.", "authors": ["Michelle X. Zhou", "Min Chen", "Ying Feng"], "n_citation": 12, "references": ["011b06c3-0cdc-4abd-adcf-4eb00a7054c7", "2d934dc9-8831-4667-aa10-ccd5f137c34a", "407954ac-5b24-408f-b111-c57ee378359a", "4955f343-c6b0-4469-a3c1-17f5af11466c", "8dcdf79e-e581-411e-9049-6d043b434efa", "972031ec-4564-40e3-86c9-e93f0722836c", "dfe695c6-b420-461c-96a1-c26e890825f4", "f755d843-bb4d-4131-8fd7-8094062d7460"], "title": "Building a visual database for example-based graphics generation", "venue": "ieee symposium on information visualization", "year": 2002, "id": "873b12c7-9e41-49a0-a790-77f6b33bba45"}
{"abstract": "Horn rule languages have formed the basis for many Artificial Intelligence application languages, but are not expressive enough to model domains with a rich hierarchical structure. Description logics have been designed especially to model rich hierarchies. Several applications would significantly benefit from combining the expressive power of both formalisms. This paper focuses on combining recursive function-free Horn rules with the expressive description logic ALCNR, and shows exactly when a hybrid language with decidable inference can be obtained. First, we show that several of the core constructors of description logics lead by themselves to undecidability of inference when combined with recursive function-free Horn rules. We then show that without these constructors we obtain a maximal subset of ALCNR that yields a decidable hybrid language. Finally, we describe a restriction on the Horn rules that guarantees decidable inference when combined with all of ALCNR, and covers many of the common usages of recursive rules.", "authors": ["Alon Y. Levy", "Marie-Christine Rousset"], "n_citation": 61, "references": ["119488d7-1070-4662-8980-118d452a23cd", "153825db-12f6-488e-9cb3-3658927f8837", "216f0956-56fa-4263-b5bb-315e1209e99b", "3e9e2fd0-f4ef-4340-840f-451825005a6b", "9b815fe5-41d4-4af7-8a88-219e3f91f609", "a674e214-e773-4409-aeda-43b97abb9576", "e659691e-b642-4369-9685-f99021c1d411", "ebb73833-5b9f-4ef4-83ff-75459cfbd75c"], "title": "The limits on combining recursive horn rules with description logics", "venue": "national conference on artificial intelligence", "year": 1996, "id": "f1390c9f-164c-4772-80f7-98fed7d319e2"}
{"abstract": "Categorization is a central task in cognitive science and artificial intelligence. Efficient reasoning about categories is becoming of great importance as intelligent agents are required to perform complex tasks in data-rich environments. Gardenfors and Williams [6] introduce a robust framework for categorization and reasoning about categories within conceptual spaces. This paper extends their work and presents a number of efficient reasoning properties that greatly reduce the search space resulting in fast derivation of reasoning about categories.", "authors": ["Ickjai Lee"], "n_citation": 8, "references": ["07709d0b-b27d-454d-be51-e04bd4d6c6c1", "e77baee1-437f-4f20-a5e0-537b9446c127", "ea8c17af-36fd-4e7a-8342-a355e943aa18"], "title": "Fast qualitative reasoning about categories in conceptual spaces", "venue": "", "year": 2003, "id": "08206fce-d7ae-46b3-9435-b208baf2485d"}
{"abstract": "This work proposes the use of groupware technology as an element for extending software process culture within development teams. The proposal relies on the application of workflow systems for software process support and on awareness mechanisms for software process visualization and understanding. We argue that this awareness information may help participants to both understand the processes they execute, and to better accept the idea of defining, standardizing and continuously improve their work tasks. We built an environment - PIEnvironment - using a commercial workflow system and evaluated its use for the enactment of some software process activities.", "authors": ["Renata Mendes de Araujo", "Marcos R. S. Borges"], "n_citation": 50, "references": ["03d4ccbf-d029-4793-801e-be213b0a86ab", "10b44b5f-ac3f-462d-9d12-365514f82a29", "1ef9cc2b-fd41-4e89-b594-58b5478d1cf8", "5a5b32e7-9a2f-40c8-8630-f4a6f6a22273", "b130d0bc-2e23-49ba-b630-54076beb8282", "bcfa7357-2f5b-4c67-9f97-1d8b1e89c052", "c3485c0f-cdff-4f46-a912-64129c7b37ea", "d869dfcb-389c-42c4-be81-8fcb41852484", "f3c76384-c250-420e-ba5d-33d1a32c3c40", "f7aae7a9-ffc4-4886-b636-cd771ce0dbd7"], "title": "Extending the Software Process Culture - An Approach Based on Groupware and Workflow", "venue": "product focused software process improvement", "year": 2001, "id": "17da62aa-2856-4d2c-a808-cd753aacbade"}
{"abstract": "We describe a linear-time algorithm that recovers absolute camera orientations and positions, along with uncertainty estimates, for networks of terrestrial image nodes spanning hundreds of meters in outdoor urban scenes. The algorithm produces pose estimates globally consistent to roughly 0.1\u00b0 (2 milliradians) and 5 centimeters on average, or about four pixels of epipolar alignment.#R##N##R##N#We assume that adjacent nodes observe overlapping portions of the scene, and that at least two distinct vanishing points are observed by each node. The algorithm decouples registration into pure rotation and translation stages. The rotation stage aligns nodes to commonly observed scene line directionss the translation stage assigns node positions consistent with locally estimated motion directions, then registers the resulting network to absolute (Earth) coordinates.#R##N##R##N#The paper's principal contributions include: extension of classic registration methods to large scale and dimensional extents a consistent probabilistic framework for modeling projective uncertaintys and a new hybrid of Hough transform and expectation maximization algorithms.#R##N##R##N#We assess the algorithm's performance on synthetic and real data, and draw several conclusions. First, by fusing thousands of observations the algorithm achieves accurate registration even in the face of significant lighting variations, low-level feature noise, and error in initial pose estimates. Second, the algorithm's robustness and accuracy increase with image field of view. Third, the algorithm surmounts the usual tradeoff between speed and accuracys it is both faster and more accurate than manual bundle adjustment.", "authors": ["Matthew E. Antone", "Seth J. Teller"], "n_citation": 77, "references": ["01fe6cc6-7660-4895-bef5-6a4d8ede9e3a", "042d18d1-aed3-4a9d-ba8b-fb7f3e14f568", "0ff7c995-1ad2-4b55-9a38-ab8a1192313c", "1005f0a1-5960-4fab-b32f-b69d59ee659f", "17b66681-4e73-41d8-ab09-cf52885b1442", "1b276b4b-7079-4e92-a4a8-436bc521e451", "1b2b9b22-3a4d-4b46-a8a7-7c29ea18281f", "2208bb93-b29d-44d2-986a-26d956a13a8b", "47450fea-5498-43af-8cb2-cb54a6d8ea8f", "4af36aae-e7f9-4e1c-af0f-eec7abdb9599", "4e7159fd-ca32-4dcd-953b-5e36a3bc9af4", "5605fd1e-c204-4f96-9f6c-a300c35dea76", "57c6fa5a-01c5-49ce-9178-1343109df1c2", "5eaad277-273d-49a4-8df6-2d7cce576d63", "63b598d0-b1b0-429c-8284-f1d2bfe7f71f", "6bf157a5-a017-4236-adac-e33707116d49", "72a29d01-1606-4788-b149-40bca4bd9ec5", "734d1033-f268-4b0e-acf8-c8f258455a70", "7e7f30f6-5d7b-4e89-8ece-48e54721ff5f", "870e0758-5885-4381-9d1d-7abc6f3b326a", "8c193276-1e32-4aa2-82c4-2b3b8e1cc371", "8efaad63-d174-43b2-815a-e82c095bd804", "a0c0a6e7-a511-4abd-8dae-66042b24ba60", "a37b5971-2bc6-4eb2-b56f-361b0b2458ff", "bba1e0d9-2c67-4b68-9c65-f947f0707a1f", "c9fa31f7-f6ce-49ea-b42c-8d03ae59dbe4", "d07378c8-154b-4dce-bbed-88d15e155bdd", "da31dd35-7443-411b-9635-980ade9852ff", "e92c3872-5ecd-4888-bd74-6a6103335ddd", "e9939b8b-6fcb-4ded-ac64-43c7fdfb52d6", "ebfca554-7a3c-4597-954b-07336a2e3030", "ee6e39c8-c5a9-4831-bfb7-2d2b520cf63a"], "title": "Scalable Extrinsic Calibration of Omni-Directional Image Networks", "venue": "International Journal of Computer Vision", "year": 2002, "id": "44bb8bed-cb00-4430-8c3b-182ac60be5a9"}
{"authors": ["Liliana Ardissono", "C. Barbero", "Anna Goy", "Giovanna Petrone"], "n_citation": 57, "references": ["0c1e459a-9540-49b9-909c-40eb5167605d", "0d2e7ec6-f3ec-4149-9c14-4ff48dc88a41", "32508b34-7eb3-4bb6-ab35-b31a73557b8f", "37210f64-0467-4cc9-930a-b71a6b4b06f2", "39de0c61-aa19-4c36-adad-86eb148f7714", "3e391bd7-96c8-46c1-9345-d3db932ce201", "6a3cbed9-51ef-4d30-a7cc-5af5dc2565c1", "6e671665-f037-41a2-ba11-a881d9f119df", "8ee324e5-2a44-49ed-8a02-2704b1253917", "c025faeb-6f41-4fe7-9789-d62428a31647", "c82c6f47-33ef-4ed8-a776-ade4efd39984", "d9c7cc6d-0067-4dae-848b-fcbe35b4aec9"], "title": "An agent architecture for personalized Web stores", "venue": "Autonomous Agents and Multi-Agent Systems", "year": 1999, "id": "aabf2ec6-a54e-42ed-b61a-d8d24a2708fd"}
{"abstract": "Model-Driven Engineering (MDE) has been promoted as a solution to handle the complexity of software development by raising the abstraction level and automating labor-intensive and error-prone tasks. However, few efforts have been made at collecting evidence to evaluate its benefits and limitations, which is the subject of this review. We searched several publication channels in the period 2000 to June 2007 for empirical studies on applying MDE in industry, which produced 25 papers for the review. Our findings include industry motivations for investigating MDE and the different domains it has been applied to. In most cases the maturity of third-party tool environments is still perceived as unsatisfactory for large-scale industrial adoption. We found reports of improvements in software quality and of both productivity gains and losses, but these reports were mainly from small-scale studies. There are a few reports on advantages of applying MDE in larger projects, however, more empirical studies and detailed data are needed to strengthen the evidence. We conclude that there is too little evidence to allow generalization of the results at this stage.", "authors": ["Parastoo Mohagheghi", "Vegard Dehlen"], "n_citation": 87, "references": ["0dc9864f-b832-46f8-bcaf-35d8be325658", "2207ac13-bc63-4824-9f41-9295b749e674", "5c263e0d-fd38-48fb-9de3-392ef36f8a1a", "660d2d7f-9e0b-48f6-9a0f-cc5bc6a01b79", "67a01f88-dab1-4b34-a836-48863ccf0fb0", "742f54b7-d953-44d6-8a2a-2ee08b53d06a", "7c877edf-c6d1-4d16-b9f0-6e80c8664be5", "7eb721ff-0df0-4c13-b334-b7ca48b92e86", "80c61a1a-2040-4c2f-8a41-ac4a35abc4f9", "99d692f3-01a6-4841-908e-15466ccac628", "ce5cc162-147a-4b3e-878c-2b14ce4e02db", "de80ba00-2d34-42e9-b298-0d581cefcffb", "defd6e9c-2223-4532-95d4-fdd2615215c3", "e25454e4-2428-4939-8acb-bbe372f05ec1", "ed8b8e34-d210-4d1b-b00a-cb8dcab0bea0", "fe9a4b69-8192-4d0d-be34-3d9f2a05d1fb", "ff6c909d-78f9-43e0-a94c-0b851029574b"], "title": "Where Is the Proof? - A Review of Experiences from Applying MDE in Industry", "venue": "", "year": 2008, "id": "84cde65d-23a5-4ab7-8443-f38fc2914b77"}
{"abstract": "Software is increasingly being developed/maintained by multiple, often geographically distributed developers working concurrently. Consequently, rapid-feedback-based quality assurance mechanisms such as daily builds and smoke regression tests, which help to detect and eliminate defects early during software development and maintenance, have become important. This paper addresses a major weakness of current smoke regression testing techniques, i.e., their inability to automatically (re)test graphical user interfaces (GUIs). Several contributions are made to the area of GUI smoke testing. First, the requirements for GUI smoke testing are identified and a GUI smoke test is formally defined as a specialized sequence of events. Second, a GUI smoke regression testing process called daily automated regression tester (DART) that automates GUI smoke testing is presented. Third, the interplay between several characteristics of GUI smoke test suites including their size, fault detection ability, and test oracles is empirically studied. The results show that: 1) the entire smoke testing process is feasible in terms of execution time, storage space, and manual effort, 2) smoke tests cannot cover certain parts of the application code, 3) having comprehensive test oracles may make up for not having long smoke test cases, and 4) using certain oracles can make up for not having large smoke test suites.", "authors": ["Atif M. Memon", "Qing Xie"], "n_citation": 237, "references": ["019b3bfa-756a-452b-bae3-89f67ac740e2", "351214c5-3dbb-470d-a120-c417c2aeb62e", "679378b7-ef32-4c9a-89cd-d959503f75a1", "880be4b0-8231-46be-9a52-218cab7ddaad", "e4567ae3-8928-41d5-8b44-4a6f970ce97b", "f0da0661-a305-4b3a-a5a3-4d1f6c77c1f7", "f83f978f-d19c-4307-8095-f7e08783b632", "fdee8fa4-2252-495e-b7ac-1e2315d9e276", "ff456593-2b0f-454a-b321-c16eb4339d35"], "title": "Studying the fault-detection effectiveness of GUI test cases for rapidly evolving software", "venue": "IEEE Transactions on Software Engineering", "year": 2005, "id": "902967b4-0c7f-49cf-927e-72182bcbccaf"}
{"abstract": "The algorithms for  structure from motion  require solution of the correspondence problem. By detecting only time-varying tokens, the problem may be significantly simplified. In this paper, a time-varying corner detector is described which is based on the and operation between the cornerness and the temporal derivative. It is shown that the corner detectors by  Zuniga and Haralick ( IEEE CVPR Conf. 1983 , pp. 30\u201337) ,  Kitchen and Rosenfeld ( Pattern Recognition Lett.   1 , 1982, 95\u2013102) , and  Dreschler and Nagel ( Proc. IJCAI, 1981 , pp. 692\u2013697)  are equivalent. In this time-varying corner detector, the Zuniga and Haralick, in loc. cit., corner detector is used for finding the cornerness at a point and the absolute value of difference in intensity at a point is used to approximate the temporal derivative. The results of the time-varying corner detector for the the real scenes and the synthetic images with random background and random object are shown.", "authors": ["Mubarak Shah", "Ramesh Jain"], "n_citation": 56, "references": ["0d66d358-49fa-4d9c-931e-98c828313246", "d98d389d-ca5f-43f4-b9bc-7dbea42e718e"], "title": "Detecting time-varying corners", "venue": "Graphical Models \\/graphical Models and Image Processing \\/computer Vision, Graphics, and Image Processing", "year": 1984, "id": "750e50f9-e801-4cf0-8d4d-c5d071b9590d"}
{"abstract": "There is a fundamental difference between wireless and wired networks, since the latter employ point-to-point communication while the former use broadcast transmission as the communication primitive. In this paper, we describe an algorithm, called self-selection, which takes advantage of broadcast communication to efficiently implement the basic operation of selecting a node possessing some desired properties among all the neighbors of the requestor. Self-selection employs a prioritized transmission back-off delay scheme in which each node's delay of transmitting a signal is dependent on the probability of the node's ability to best perform a pertinent task, and in turn, enables the node to autonomously select itself for the task. We demonstrate the benefits of self-selection in two basic wireless ad hoc network communication algorithms: flooding and routing. By relating back-off delay to the signal strength of a received packet, we design an efficient variant of conventional flooding called Signal Strength Aware Flooding. By using distance-to-destination to derive back-off delay, we design a novel and fault-tolerant wireless ad hoc network routing protocol named Self-Selective Routing.", "authors": ["Gilbert Chen", "Joel W. Branch", "Boleslaw K. Szymanski"], "n_citation": 50, "references": ["1af2080f-7848-4795-a98c-6e38e7731cdc", "1bbea8f4-81bf-4bb4-b015-f54a9654a2f5", "1ef326ef-a81f-4846-9e08-0f4fb306c37b", "23dd7fc0-1ebd-43ce-ab3e-43896512c209", "314c5a50-5eb8-4377-9861-e4367ff86462", "376e2afe-2334-4def-9486-03ddd29ff9de", "415c7281-44cb-4b78-84d5-890a3e88df26", "442c792a-ac19-4695-b965-56f91815c796", "5a7030e7-0190-436f-b25e-365b63e580ff", "60fb0dc2-bde3-4714-948e-de0ed12ab460", "74e7776b-ec3b-4dad-b225-7379364096fc", "83a2eb55-b330-4e0c-8dc9-05e9466d5028", "87a5fd29-47f3-4bc0-a3f5-954aba53d53e", "8dd37c4a-1463-4b77-9523-3cdf10aaaa70", "9efda63c-320d-46b0-8a7b-175012a2936f", "a9e900bd-a813-4ef6-a7df-68efc6df800e", "af3211ca-7fae-4653-ad2d-61404dbd58c6", "afc06b7c-7fb3-4f88-942b-3076ed77920e", "bbab87e7-3bc2-456f-80ba-c6a7065370d1", "d456a070-f468-489e-8e06-c2435c846210", "e9d5f1b9-a3d1-447e-9f7b-86e0beb74c37", "f682f022-3c5c-4638-a9d4-5b08bfa136a1", "f8ece2c5-c8b1-4a1e-8528-c09357ec23a4"], "title": "A Self-selection Technique for Flooding and Routing in Wireless Ad-hoc Networks", "venue": "Journal of Network and Systems Management", "year": 2006, "id": "f99b1ccd-75a3-4174-9aef-51b439959302"}
{"abstract": "We consider the gradient method $x_{t+1}=x_t+\\g_t(s_t+w_t)$, where $s_t$ is a descent direction of a function $f:\\rn\\to\\re$ and $w_t$ is a deterministic or stochastic error. We assume that $\\gr f$ is Lipschitz continuous, that the stepsize $\\g_t$ diminishes to 0, and that $s_t$ and $w_t$ satisfy standard conditions. We show that either $f(x_t)\\to-\\infty$ or $f(x_t)$ converges to a finite value and $\\gr f(x_t)\\to0$ (with probability 1 in the stochastic case), and in doing so, we remove various boundedness conditions that are assumed in existing results, such as boundedness from below of f, boundedness of $\\gr f(x_t)$, or boundedness of xt.", "authors": ["Dimitri P. Bertsekas", "John N. Tsitsiklis"], "n_citation": 278, "references": ["0e91ce6e-634b-48ef-960e-7e12f700b383", "d054eeb9-1e01-495d-b5a6-5f36a469c05a"], "title": "Gradient Convergence in Gradient methods with Errors", "venue": "Siam Journal on Optimization", "year": 1999, "id": "10669deb-490d-4c91-b7d6-788f94f467c4"}
{"abstract": "The software factory concept which symbolizes a desired paradigm shift from labor-intensive software production to a more capital-intensive style in which substantial investments can be made at an acceptable risk level is discussed. Most traditional software environments emphasize support for producing code and associated documents. In a software factory, the focus shifts to coordinating information between producers and consumers so that the right person always has the right information at the right time. A CASE environment architecture and two factory experiments, one a prototype software factory environment for real-time system development, and the other a factory for exploring information logistics, are reviewed. >", "authors": ["Christer Fernstr\u00f6m", "Kjell H\u00e5kan N\u00e4rfelt", "Lennart Ohlsson"], "n_citation": 60, "references": ["401eb13d-ccd2-4866-b881-a85c9136c40d", "52391e5d-c3cb-4313-b139-5d60a38f480e", "e1cfb778-f574-40a4-a00c-5f7655102451"], "title": "Software factory principles, architecture, and experiments", "venue": "IEEE Software", "year": 1992, "id": "c68af099-1392-479a-a21c-725d67051988"}
{"abstract": "We present a technique for evaluating the usability and effectiveness of ambient displays. Ambient displays are abstract and aesthetic peripheral displays portraying non-critical information on the periphery of a user's attention. Although many innovative displays have been published, little existing work has focused on their evaluation, in part because evaluation of ambient displays is difficult and costly. We adapted a low-cost evaluation technique, heuristic evaluation, for use with ambient displays. With the help of ambient display designers, we defined a modified set of heuristics. We compared the performance of Nielsen's heuristics and our heuristics on two ambient displays. Evaluators using our heuristics found more, severe problems than evaluators using Nielsen's heuristics. Additionally, when using our heuristics, 3-5 evaluators were able to identify 40--60% of known usability issues. This implies that heuristic evaluation is an effective technique for identifying usability issues with ambient displays.", "authors": ["Jennifer Mankoff", "Anind K. Dey", "Gary Hsieh", "Julie A. Kientz", "Scott Lederer", "Morgan G. Ames"], "n_citation": 563, "references": ["03c11bcd-1346-4618-99de-90dd35d29fbd", "0b0d6e01-22e0-4025-9997-a47eb760e476", "0cf64df2-61b8-4dd5-b70b-5eb120fdb31d", "1819e460-6ea9-4b82-a168-dbc67884ea2e", "2742be80-3778-4eae-a17c-abd6082fe5f0", "278f1d79-321b-4fb2-a53b-821581afdf82", "3d13a3a9-6390-4896-bc30-ff8d17eb534d", "40aeaa98-0311-41d4-ad22-05614cf11105", "410491a3-9f65-4f9c-b72e-de68be762c54", "9b7d8af6-cb3c-40e8-961a-04173bca89bf", "a49c0e9f-5a5a-4f6b-8a29-d1c5f475f8eb", "aaac1da3-8e6f-4857-a8b2-febf12795d8e", "b53a4e8b-970b-4a62-9789-71e333441489", "c7e9b96e-7c0c-483b-9400-56166488d536", "da9915ce-495d-4b2c-a423-e8cfc187e068", "df9d1854-fa68-4b6e-b71a-fe832155f77c", "e96d09c6-f370-418c-888b-3e6726b7088c", "ea951802-289d-4794-9fb7-fabe6a64ddbf"], "title": "Heuristic evaluation of ambient displays", "venue": "human factors in computing systems", "year": 2003, "id": "df04a587-16e6-4fbe-bcc6-80a9017a4131"}
{"abstract": "This paper offers a brief overview and critique of dominant approaches to knowledge management (KM) and its links with innovation. It then draws upon a case study example to offer a closer analysis of the link between KM and the development of communities of practice during processes of innovation. The paper argues, first, that in many cases innovation is an interactive process requiring knowledge and expertise from different functions and layers across the organization. In such cases critical problems concern the integration of knowledge across disparate communities, rather than the sharing of knowledge within communities. Second that if knowledge integration across communities is to develop, a more action-oriented perspective on KM and the development of KM tools is needed.", "authors": ["Jacky Swan"], "n_citation": 50, "references": ["0ff704ea-084a-489d-b0c4-02d4d80211dc", "104facd7-a275-4d60-ab50-9eca96de7468", "59048088-65c4-4ee1-b3ee-7d032f31b41c", "76f66f00-05e0-463d-8560-30fa7106f606"], "title": "Knowledge management in action: integrating knowledge across communities", "venue": "hawaii international conference on system sciences", "year": 2001, "id": "843b0473-a173-4ae9-9fce-0744a7197604"}
{"abstract": "Maintaining approximate aggregates and summaries over data streams is crucial to handle the OLAP query workload that arises in applications, such as network monitoring and telecommunications. Furthermore, since the entire data is not available at all times the maintenance task must be done incrementally. We show that R(elaxed)Hist(ogram) is an appropriate summarization under data stream scenario. In order to reduce query estimation errors, we propose adaptive approaches which not only capture the data distribution, but also integrate independent query patterns. We introduce a workload decay model to efficiently capture global workload information and ensure that the query patterns from the recent past are weighted more than queries that are further in the past. We verify experimentally that our approach successfully adapts to continuously changing workload as well as data streams.", "authors": ["Lin Qiao", "Divyakant Agrawal", "Amr El Abbadi"], "n_citation": 50, "references": ["0b6a1422-8659-457f-a00d-55d1fc821fc8", "2349f2c4-a0e1-4eeb-a5b6-e4eb99da399f", "2626b827-2ece-4577-84ca-c9565beb0c96", "384624dd-777d-4ef8-8bbe-3baab5c902a7", "40970714-b258-48e1-a46c-daa111337fa4", "456a8de2-84a2-45e4-86ca-cb704dd48ba1", "489d1dc3-8c64-4612-8f57-99a0c0b76ca4", "4eb8ac46-d74a-4ff4-8849-2e8b36640583", "51d23740-cd2d-4e13-85e2-a0e75bbf8624", "7119a529-aea7-4377-90a4-ea76eced37c1", "7adfd829-4b37-4729-8a78-7d4b78cf96b6", "90311064-2128-4afb-996d-a51d34c84055", "949b22b6-3895-4a56-9d07-f9154e30be15", "9c2edeee-3115-49b3-8cf6-effa50b63176", "b1458464-df4b-4925-87a2-c3f487413406", "db732fc0-0f9c-4b91-90f7-81c7091ba516", "dbd3d8ec-5a70-4c76-ba87-c89a3179a69a", "e4178a21-2bef-40fc-afb1-f671b3eb43de", "feac5554-d6fe-4346-aa49-51914552591a"], "title": "RHist: adaptive summarization over continuous data streams", "venue": "conference on information and knowledge management", "year": 2002, "id": "fad52dbf-9494-4a8b-b8ba-2146e4a0d788"}
{"abstract": "Particle swarm optimization (PSO) has shown to be an efficient, robust and simple optimization algorithm. Most of the PSO studies are empirical, with only a few theoretical analyses that concentrate on understanding particle trajectories. These theoretical studies concentrate mainly on simplified PSO systems. This paper overviews current theoretical studies, and extend these studies to investigate particle trajectories for general swarms to include the influence of the inertia term. The paper also provides a formal proof that each particle converges to a stable point. An empirical analysis of multi-dimensional stochastic particles is also presented. Experimental results are provided to support the conclusions drawn from the theoretical findings.", "authors": ["F. van den Bergh", "A.P. Engelbrecht"], "n_citation": 1001, "references": ["28a7e1da-7265-44b6-9704-972c29caa0a8", "c2105833-beb6-4e32-be0f-c304dcf659b4", "f5cc526f-6cd4-401e-aac1-416ac15aa146"], "title": "A study of particle swarm optimization particle trajectories", "venue": "Information Sciences", "year": 2006, "id": "34bdd089-9d50-46a0-ac69-b36432be7abf"}
{"abstract": "A speech enhancement scheme is presented integrating spatial and temporal signal processing methods for blind denoising in non stationary noise environments. In a first stage, spatially localized point sources are separated from noisy speech signals recorded by two microphones using a Blind Source Separation (BSS) algorithm assuming no a priori knowledge about the sources involved. Spatially distributed background noise is removed in a second processing step. Here, the BSS output channel containing the desired speaker is filtered with a time-varying Wiener filter. Noise power estimates for the filter coefficients are computed from desired speaker absent time-intervals identified by comparing only signal energy of separated source signals from the BSS stage. The scheme's performance is illustrated by speech recognition experiments on real recordings corrupted by babble noise and compared to conventional beamforming and single channel denoising techniques.", "authors": ["Erik M. Visser", "Te-Won Lee"], "n_citation": 50, "references": ["13a9af07-3ac2-425d-b51c-54581d70ec21", "3c5a2356-abb6-4867-b0fb-ae891b010592", "6f339396-22e8-41d0-a2f7-ff4f78665b45", "6fe6be0c-cddf-4ce1-9a45-227f5bc31a1c"], "title": "Speech enhancement using blind source separation and two-channel energy based speaker detection", "venue": "international conference on acoustics, speech, and signal processing", "year": 2003, "id": "bdd46fa0-f241-46be-aba2-b2d399821ff9"}
{"abstract": "We describe the design and implementation of an automatic invariant generator for imperative programs. While automatic invariant generation through constraint solving has been extensively studied from a theoretical viewpoint as a classical means of program verification, in practice existing tools do not scale even to moderately sized programs. This is because the constraints that need to be solved even for small programs are already too difficult for the underlying (non-linear) constraint solving engines. To overcome this obstacle, we propose to strengthen static constraint generation with information obtained from static abstract interpretation and dynamic execution of the program. The strengthening comes in the form of additional linear constraints that trigger a series of simplifications in the solver, and make solving more scalable. We demonstrate the practical applicability of the approach by an experimental evaluation on a collection of challenging benchmark programs and comparisons with related tools based on abstract interpretation and software model checking.", "authors": ["Ashutosh Gupta", "Rupak Majumdar", "Andrey Rybalchenko"], "n_citation": 55, "references": ["0278bce3-e509-4ae6-b130-87a283a4b819", "081db92d-9bd4-4a17-8b76-ac347634861f", "0831e54f-d81e-443f-9af5-8321ab003661", "19cc1dca-7b33-4c22-8f90-306ce3781da2", "2660744d-9c55-4eb6-af3c-1d9ee904a447", "2e242c02-8776-4102-9a5a-67fcdbe2d1e5", "35c8c06c-2ad0-46b4-9e92-2d684f3abd94", "3e72cb06-57e6-4f33-8927-53f0bf40c31d", "5e5342c6-ac8d-405a-badf-9b42137c52d2", "77d2ea65-9174-464d-a871-60b33377035c", "7968b5a6-b7ff-4f8a-88bb-0ebb7f74552e", "7bb71afa-91b8-46e7-9008-da84e0427b93", "a5c31c24-8e2c-438f-9358-b80cabbc7a70", "ba78b7e3-85cb-4afa-ae9e-76f390f99d07", "c7923c32-28e8-431b-b654-f17665541a21", "f34c51e3-1fa1-49a9-9708-97d3178c960b", "f4270e7e-3819-424b-9ae1-93539fd8901e", "fac8b38a-4904-4516-96fa-11d84129d3e1"], "title": "From Tests to Proofs", "venue": "International Journal on Software Tools for Technology Transfer", "year": 2013, "id": "eccd1796-ed62-4257-86de-1f1ca2039034"}
{"abstract": "Using a number of measures for characterising the complexity of classification problems, we studied the comparative advantages of two methods for constructing decision forests \u2013 bootstrapping and random subspaces. We investigated a collection of 392 two-class problems from the UCI depository, and observed that there are strong correlations between the classifier accuracies and measures of length of class boundaries, thickness of the class manifolds, and nonlinearities of decision boundaries. We found characteristics of both difficult and easy cases where combination methods are no better than single classifiers. Also, we observed that the bootstrapping method is better when the training samples are sparse, and the subspace method is better when the classes are compact and the boundaries are smooth.", "authors": ["Tin Kam Ho"], "n_citation": 79, "references": ["01cb0798-ade7-442b-8c47-fe43f1281f58", "0f115eea-2272-431f-9f21-6d6789b2bbc9", "17d88dfa-a5b8-47dd-9fb6-8779e5091c85", "32966ad0-869c-4187-bed7-c9b43c00d2f5", "3704f939-09a2-4e9f-b851-1261bcd310df", "3ae9664a-bf6f-45d2-852f-bba9b47e2b8a", "473308a4-a098-4eae-8bbf-8c30bc7701a4", "4be27794-9327-4ad0-8ce9-cd349ef2bccf", "5679933e-5817-4631-b275-5aabe012d3de", "65132812-7bec-4d7e-bebb-895eb6cf4647", "691a58c5-29f8-4dc4-a040-74889525d426", "6d68f549-9435-4ef9-b4ab-700a54109fdc", "b20c3b7c-866c-41b9-9777-4ede12264f07", "b4c5a572-c0a9-41e3-8782-9d4ee8105d81", "bf785e47-8af2-402e-a757-872148fa0638", "c95a66fe-8c91-45c4-ab28-52abc5709bc7", "cf3a93fa-0d81-4b4d-8f88-7af6840e60d4", "d75e04d9-dc8b-4953-aad2-747c3795222f", "f642c20d-a97f-4716-9c43-636ad1f87706"], "title": "A Data Complexity Analysis of Comparative Advantages of Decision Forest Constructors", "venue": "Pattern Analysis and Applications", "year": 2002, "id": "059d662d-7c78-4744-9487-3ce298861300"}
{"abstract": "Planning under partial observability is one of the most significant and challenging planning problems. It has been shown to be hard, both theoretically and experimentally. In this paper, we present a novel approach to the problem of planning under partial observability in non-deterministic domains. We propose an algorithm that searches through a (possibly cyclic) and-or graph induced by the domain. The algorithm generates conditional plans that are guaranteed to achieve the goal despite of the uncertainty in the initial condition, the uncertain effects of actions, and the partial observability of the domain. We implement the algorithm by means of BDD-based, symbolic model checking techniques, in order to tackle in practice the exponential blow up of the search space. We show experimentally that our approach is practical by evaluating the planner with a set of problems taken from the literature and comparing it with other state of the art planners for partially observable domains.", "authors": ["Piergiorgio Bertoli", "Alessandro Cimatti", "Marco Roveri", "Paolo Traverso"], "n_citation": 246, "references": ["0e4c1528-6e83-4e8e-b20d-397a4728e3d2", "207f6244-886c-4573-b68c-fd358cbd0e8a", "22ebecf3-41f0-4dea-8980-98f1f2c00dfe", "2809358b-e681-4abd-b4d4-526063a549fa", "2b5a5aea-bd75-4c22-8c96-cfdcd2c736b9", "5f25a21b-1bae-4715-af03-53c2b40c6a43", "6e17c689-004f-460a-8f13-dae1b066c096", "81541435-ee9c-4e08-a47c-76e93e1697d0", "86d177d1-9f3a-4052-8640-65d8433dab52", "87fa53ea-5202-40b0-8a47-885056e7b857", "8ea54639-35ea-46a6-b503-51ea152419a6", "95ca582a-9493-48c7-9c82-4cc1d7e55d42", "a6f0e3a6-d068-44c3-a7ec-24fe9b7f8875", "a86b6d45-55d4-48bc-951f-b8feb644e880", "b1d6b919-4d3d-4018-baec-b8631efb0ffa", "e28bdc5f-2df3-4201-b8fc-54b06a9bf005", "e688492c-9f2a-4acb-bd25-6a80b0022383", "ee809ead-133a-4e37-aa5d-09a125cc37f6"], "title": "Planning in nondeterministic domains under partial observability via symbolic model checking", "venue": "international joint conference on artificial intelligence", "year": 2001, "id": "ec7a61d5-81d5-477d-914b-12db5eb6434e"}
{"abstract": "We present a semantic role labeling system submitted to the closed track of the CoNLL-2005 shared task. The system, introduced in (Toutanova et al., 2005), implements a joint model that captures dependencies among arguments of a predicate using log-linear models in a discriminative re-ranking framework. We also describe experiments aimed at increasing the robustness of the system in the presence of syntactic parse errors. Our final system achieves F1-Measures of 76.68 and 78.45 on the development and the WSJ portion of the test set, respectively.", "authors": ["Aria Haghighi", "Kristina Toutanova", "Christopher D. Manning"], "n_citation": 72, "references": ["4b6c938b-ca48-4168-a03f-4ca28f16dd51", "5538b634-04f3-4d09-bb4e-90055817e3b1", "685230c5-5dbb-46c0-95fa-c7d1b5c3f7c1", "6d986416-3e63-41bd-89e4-3668e30e0e5a", "823a9445-3bb8-4382-b101-7a3b8cb0ffa5", "b97e0a93-9410-43c3-a0a7-8a37be4e9b8f"], "title": "A Joint Model for Semantic Role Labeling", "venue": "", "year": 2005, "id": "ba624358-9d64-4380-9146-10713c0ae780"}
{"abstract": "Analysing and modelling the characteristics of virtual machine (VM) usage gives cloud providers crucial information when dimensioning cloud infrastructure and designing appropriate allocation policies. In addition, administrators can use these models to build a normal behaviour profile of job requests, in order to differentiate malicious and normal activities. Finally, it allows researchers to design more accurate simulation environments. An open challenge is to empirically develop and verify an accurate model of VM usage for users in these applications. In this paper, we study the VM usage in the popular Amazon EC2 and Windows Azure cloud platforms, in terms of the VM request arrival and departure processes, and the number of live VMs in the system. We find that both the VM request arrival and departure processes exhibit self-similarity and follow the power law distribution. Our analysis also shows that the autoregressive integrated moving average (ARIMA) model can be used to fit and forecast the VM demands, which is an important requirement for managing the workload in cloud services.", "authors": ["Yi Han", "Jeffrey Chan", "Christopher Leckie"], "n_citation": 16, "references": ["1b9206da-2223-49e5-b6b8-579ebbb8f09d", "2222f1f9-b357-45ef-8943-ae096e660c5f", "3f80c5ba-3fbd-4ab7-b551-693e5077da47", "46d6eece-0327-44a6-8862-7fa4ba5dad1a", "4e37db7d-dbd4-4d1a-9c2e-29bbcd6bbfc5", "4f2bc852-9c60-4fa3-9573-d9735604cdb5", "7268dc49-a14a-4d97-9807-df8e69fa835d", "8dee0c7c-f1ad-4f4b-9218-258336bcff5c", "901f0295-c103-49b4-8a07-c9cc267f5d28", "91049645-fd15-4666-99ad-71a8e16f2883", "b072412c-a28e-42a4-8ed7-8f0abaf5915d", "b834e752-8d5d-4c54-a8d0-8c62ef865dfc", "c39f07ed-fe77-4b02-be22-0fd9687ab648", "c82d6f8e-5ad6-4317-af5a-86d4b6bcf225", "cf756253-8f5f-4195-832a-430b96ead4de", "ed9bb748-6bfd-4727-acc2-f408c975bd50", "f111da6b-d106-4bce-aeac-72eeffd220db", "f751bb33-6360-40fe-974d-928dba8dadf3"], "title": "Analysing Virtual Machine Usage in Cloud Computing", "venue": "", "year": 2013, "id": "8627575d-9b1c-4534-9711-597354900853"}
{"abstract": "New proofs of two properties of the polynomial-time hierarchy are given. The classes in the hierarchy are characterized using polynomially bounded quantifiers. Using this result, a sequence of complete sets for the hierarchy is exhibited.", "authors": ["Celia Wrathall"], "n_citation": 331, "references": ["172f9f68-8417-43bb-8fe5-b377d569f6b6", "2e38e95a-3b6e-4efc-a926-d21200cc334c", "332ccd03-1ee1-4619-9a34-779c2fec35d4", "430b65f3-e516-4655-b53e-39f6b4993964", "5539290f-8c10-49f7-95bf-d57f8c445a06", "8d09527f-b5ad-4902-ba34-5583f6759d3b", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "c5368c25-5748-4af2-8b0f-f2cca8dbb4f0"], "title": "Complete sets and the polynomial-time hierarchy\u2606", "venue": "Theoretical Computer Science", "year": 1976, "id": "3f5cdf34-9aac-47a0-83ef-6efc12fbfac1"}
{"abstract": "Probabilistic methods and statistical learning theory have been shown to provide approximate solutions to \"difficult\" control problems. Unfortunately, the number of samples required in order to guarantee stringent performance levels may be prohibitively large. This paper introduces bootstrap learning methods and the concept of stopping times to drastically reduce the bound on the number of samples required to achieve a performance level. We then apply these results to obtain more efficient algorithms which probabilistically guarantee stability and robustness levels when designing controllers for uncertain systems.", "authors": ["Vladimir Koltchinskii", "Chaouki T. Abdallah", "M. Ariola", "Peter Dorato", "Dmitry Panchenko"], "n_citation": 92, "references": ["3cbc139d-0e14-403a-8ad3-436d609ccd37", "5e6cc941-0bf8-4af4-85ce-fae98d518238", "cc8c91a0-9d5c-4137-b5c0-692f0d1b7001", "d32e8242-e42b-4640-8119-0a9d8fc780fc"], "title": "Improved sample complexity estimates for statistical learning control of uncertain systems", "venue": "IEEE Transactions on Automatic Control", "year": 2000, "id": "e08afe20-c0e7-4bb8-9523-168e260e1311"}
{"abstract": "There is little or no guidance to systematically design a self-organising emergent solution that achieves the desired macroscopic behaviour. This paper describes decentralised coordination mechanisms such as gradient fields as design patterns, similar to patterns used in mainstream software engineering. As a consequence, a structured consolidation of best practice in using each coordination mechanism becomes available to guide engineers in applying them, and to directly decide which mechanisms are promising to solve a certain problem. As such, self-organising emergent solutions can be engineered more systematically, which is illustrated in a packet delivery service application.", "authors": ["Tom De Wolf", "Tom Holvoet"], "n_citation": 109, "references": ["0631dab5-0555-4449-a39c-2534e771e7ef", "1bdf666b-ce5b-4e6c-82b6-ca8759764529", "30932642-fd17-4ae9-9a5b-90e67adcfe41", "32a271b3-58b8-4ff2-b39b-0b4155239dbb", "352838dd-9583-402f-be39-52df4810a25f", "352d0531-d578-41e6-ba8d-cc98bcfa85fb", "5745bdca-8edf-48f8-9bf5-52a8b946dbe8", "621d1071-8350-4386-b1e8-519c4dfa8c5d", "7b37b0e2-2a23-422e-ab4b-a6d9f9127fe4", "95616c3f-7eb6-411d-a4da-f125cb76d10b", "a6cf0576-e40f-402d-a3b5-c51cd15420d0", "b9aa1c3a-579b-4159-b7e1-3f4af3dce093", "badfd69f-bbdd-4f63-ab55-946184e8922a", "bafcfe76-e52e-4598-b95a-e893cd2e2995", "c2207671-a597-4332-880a-25a4900eb50e", "d9ea978b-06ce-4779-af55-7419870e37f2", "ebda2bdb-db7d-4d1e-919e-ffba108b12e1", "fd212aa2-47d5-4274-ae3f-7f2f4971311f"], "title": "Design patterns for decentralised coordination in self-organising emergent systems", "venue": "", "year": 2006, "id": "72232409-509b-4012-9cbf-afbe88126887"}
{"authors": ["Scott R. Kohn", "G Kumfert", "Jeffrey F. Painter", "Calvin J. Ribbens"], "n_citation": 138, "references": [], "title": "Divorcing Language Dependencies from a Scientific Software Library.", "venue": "", "year": 2001, "id": "fb1f82a1-b0d3-4ff6-8764-46db0c3cec9b"}
{"abstract": "A study of the problems experienced by twelve software companies in their requirements process is discussed. The aim of the work is to develop a more holistic understanding of the requirements process, so that companies can more effectively organise and manage requirements. The findings suggest that most requirements problems are organisational rather than technical, and that there is a relationship between companies' maturity and patterns of requirements problems.", "authors": ["Tracy Hall", "Sarah Beecham", "Austen Rainer"], "n_citation": 198, "references": ["ec36af7d-6be5-4a09-9158-23c51f2ed41c"], "title": "Requirements problems in twelve software companies: an empirical analysis", "venue": "Iee Proceedings-software", "year": 2002, "id": "54cb1313-650f-45f7-91b2-216494cd1586"}
{"abstract": "Motivated by evidence that coordination and dependencies among engineering decisions in a software project are key to better understanding and better methods of software creation, we set out to create empirically testable theory to characterize and make predictions about coordination of engineering decisions. We demonstrate that our theory is capable of expressing some of the main ideas about coordination in software engineering, such as Conway's law and the effects of information hiding in modular design. We then used software project data to create measures and test two hypotheses derived from our theory. Our results provide preliminary support for our formulations.", "authors": ["James D. Herbsleb", "Audris Mockus"], "n_citation": 127, "references": ["1ef9cc2b-fd41-4e89-b594-58b5478d1cf8", "23e01944-f663-4695-b1a7-2d01aeec7354", "2a0d5376-b235-49ee-afad-aa1112cd71fc", "3653e103-1d86-40c2-a938-4ee9187211a1", "3b15b0a1-c6a2-4660-8b7a-e44a74c6783d", "64ad49c9-b2cc-43fe-8802-e0cc93faa9d5", "66cef6b7-e77b-48b9-9367-23db29a03d3b", "7e8c868b-c75f-48e3-8b95-7e73544ba49c", "9f141f8a-d30b-4151-964b-c29aa5fefb0a", "9f6dfbd6-c3cf-40c2-9187-ac2460ca2b19", "c6ff8fa0-642f-42e9-a930-5f976d31e74c", "e3ca3686-b725-4f9e-b82d-4e7006c40fc4", "f0055425-1f0a-49e3-b69b-fef9cce3c525"], "title": "Formulation and preliminary test of an empirical theory of coordination in software engineering", "venue": "foundations of software engineering", "year": 2003, "id": "25287a4a-9da0-4e0e-9e2d-c65d2872898f"}
{"abstract": "A one-to-one marketing paradigm has emerged that suggests organizations will be more successful if they concentrate on obtaining and maintaining a share of each customer rather than a share of the entire market, with information technology (IT) being the enabling factor. This paper presents four key elements that provide the necessary steps that allow an organization to position its people, business processes, and information systems to establish and take advantage of this emerging paradigm. The key elements are: (1) business process analysis, (2) integration and redesign of customer data, (3) IT-enabled customer interaction, and (4) accessibility/transmission of organizational information. Further, this paper discusses the importance of integrating these four IT elements for achieving effective customer interaction.", "authors": ["John D. Wells", "William L. Fuerst", "Joobin Choobineh"], "n_citation": 95, "references": ["3bccbeba-4d0e-44f7-be2d-15995c61b655", "405801cc-7dd8-47e5-bdbf-c722cdf02bfa", "4c823121-531d-4b01-befc-cf141bfaacd4", "64e7b606-abdf-4ecd-b4f1-6dbd77212ca0", "68b97903-f61a-4499-affd-986f41b186d5", "88f375be-08df-4850-b154-ce48b07baf46", "9627348b-70e9-4a9d-a0af-4fcdb9584378", "ae64d0b4-6835-477a-bd79-3c3558302355", "c01d3648-0382-4fa5-b825-b1ad41b4181f", "ebdf54ea-2b15-4892-9b40-beb335708321"], "title": "Managing information technology (IT) for one-to-one customer interaction", "venue": "Information & Management", "year": 1999, "id": "9e0324ec-48ce-4d2b-8f3b-ec9205d94a4f"}
{"abstract": "Recent theoretical and experimental work suggests a temporal structure of neuronal spike activity as a potential mechanism for solving the binding problem in the brain. In particular, recordings from cat visual cortex demonstrate the possibility that stimulus coherency is coded by synchronization of oscillatory neuronal responses. Coding by synchronized oscillatory activity has to avoid bulk synchronization within entire cortical areas. Recent experimental evidence indicates that incoherent stimuli can activate coherently oscillating assemblies of cells that are not synchronized among one another. In this paper we show that appropriately designed excitatory delay connections can support the desynchronization of two-dimensional layers of delayed nonlinear oscillators. Closely following experimental observations, we then present two examples of stimulus-dependent assembly formation in oscillatory layers that employ both synchronizing and desynchronizing delay connections: First, we demonstrate the segregati...", "authors": ["Peter K\u00f6nig", "Thomas B. Schillen"], "n_citation": 347, "references": ["31eb6d36-f80d-4f60-8cbd-f01e6949ea43", "4df5f225-04eb-498f-b568-d6f8c46845fb", "4ffc908e-c7fa-4697-8636-cf56f6b91779", "8666b87c-3885-4a73-b6f5-7a4021b7485d", "d1f54eca-faf6-4a20-8f2b-d4cf3e582bc8"], "title": "Stimulus-dependent assembly formation of oscillatory responses: II. desynchronization", "venue": "Neural Computation", "year": 1991, "id": "27f22f48-aedc-4ca0-89e3-99cfb6be29b5"}
{"abstract": "In this paper we describe NaCIN, an Eclipse plug-in that records a developer's code navigation activity and produces sets of elements potentially implementing different concerns relevant to the current task. It performs an analysis of the navigation paths and structural dependencies of the recorded elements and clusters the results in groups potentially associated with high level concepts. NaCIN partially automates the process of relating source code with high-level abstractions and enables knowledge about the implementation of different concerns to be reused in future investigations. We present the architecture and a preliminary assessment of NaCIN.", "authors": ["Imran Majid", "Martin P. Robillard"], "n_citation": 19, "references": ["118d3afc-32c9-49ad-a25b-2ea688d2018e", "22cba7e6-658b-4785-89b7-3658575dcb2d", "4df004e1-b013-4da9-8157-0999add3a12b", "5c1825a2-fde0-4f16-8072-0e4e45aa5f75", "6b650238-1701-4088-bf7c-9135aa114934", "a514b518-d203-49fa-9ba0-4d09ce3ff32b", "a806bf78-4d4c-49a3-8425-666da3b08b73", "d6de6797-c97f-4579-a3b1-8e0675a7eae9", "fe1c3535-c0e9-43b8-a1d9-78c8108eea64"], "title": "NaCIN: an Eclipse plug-in for program navigation-based concern inference", "venue": "eclipse technology exchange", "year": 2005, "id": "9e20b2d2-f71d-4afe-b314-e417e433987f"}
{"abstract": "Today's telecommunication systems are enhanced by a large and steadily growing number of supplementary services, each of which consists of a set of service features. A situation where a combination of these services behaves differently than expected from the single services' behaviors, is called service interaction. This interaction problem is considered as a major obstacle to the introduction of new services into telecommunications networks. We present a survey of the work carried out in this field during the last decade (1988-98). After a brief review of classification criteria that exist for feature interactions so far, we use a perspective called the emergence level view. This perspective pays respect to the fact that the sources for interactions can be of many different kinds, e.g., requirement conflicts or resource contentions. It is used to rationalize the impossibility of coping with the problem with one single approach. We also present a framework of four different criteria in order to classify the approaches dealing with the problem. The general kind of approach taken, a refinement of the well known detection, resolution, and prevention categories, serves as the main classification criterion. It is complemented by the method used, the stage during the feature lifecycle where an approach applies, and the system (network) context. The major results of the different approaches are then presented briefly using this classification framework. We finally draw some conclusions on the applicability of this framework and on possible directions of further research in this field.", "authors": ["Dirk O. Keck", "Paul J. Kuehn"], "n_citation": 114, "references": ["0cafc849-676c-486c-8437-5f6a29ec35d4", "18c465cd-bcc2-4a16-9968-07d0217ebaee", "1b143b08-5ad0-4052-9cc1-c152c080bbeb", "1c8195aa-6872-4070-bec4-c1d09a14eff6", "1ede5056-236a-45b6-a168-e94d9411cb66", "2190cb3b-f1b2-436a-9e07-93c922c97750", "413587e6-bbbc-4b60-83a1-5b08b7cf7005", "48e25da2-49e7-41e7-bc1c-99ea3f0f3600", "4b8ba461-74ea-4290-a8ff-2ff280d826cc", "4f97a007-a789-4d3c-aec6-8faa6118c4f9", "5129fab9-96fe-490c-916f-277b0ec79a3a", "54b641bb-9b71-440f-98c2-979e0204d201", "560a6ef5-c239-4f4b-826b-b2d88b8094f5", "618fcd84-eae8-44f3-8366-f840deaf5bd0", "6227edb6-a48a-4dcb-8508-851a674de75d", "63a7011a-6edb-4a2d-bd20-0e74748aed42", "66502ac4-c8a1-43bb-a000-a24c924d189e", "66ab8b02-9caa-4e86-a2a5-c2009e7e908f", "6d8e5f37-38f3-4aa2-8614-95fc7b1ad130", "7055598d-d6e7-495e-9656-ba80fdfe0f0c", "74298a77-cb6a-4465-9ed7-b25fe180cae4", "781385b0-82f8-4daa-9cb3-0a2185ce94f4", "8805cb6f-0893-447a-87aa-7efab8ca183b", "90b44fb1-04c6-4591-8de9-67f03b55a839", "91ee1755-33f5-4977-8122-21f805ff329a", "93edc71e-3458-4174-b335-e32e5753ace8", "9d4f9084-6e5f-4517-ade7-f77d43ba193c", "9d66be74-10e5-4066-b43d-31542716a6ee", "ab7a2cec-5100-4e4e-9046-fbff82f5e2d4", "ad8fa4ce-91fc-4bcc-a530-4023be633fb8", "afe02ebd-55da-4692-b25a-34117420e9e4", "ba4b7593-18a1-45f6-a3fb-285a47a79492", "cad3c351-18b0-4602-99b5-26e66b622099", "df9fd67b-8d6b-4459-a246-3ccca020dc13", "e45a94eb-aef7-4bf5-9010-218f05e6012d", "e879688b-7010-412c-b32b-e84b529f6b3f", "f4125600-d705-4f46-9e2b-6f1bdcc9cb51", "fa7cc045-0161-48c8-a508-02067b4e0953", "fb7c84cc-dd9e-4a1b-9bd3-7acc27f3ab34", "fe7cd341-1192-4cad-ac8b-1781c2c0af98"], "title": "The feature and service interaction problem in telecommunications systems: a survey", "venue": "IEEE Transactions on Software Engineering", "year": 1998, "id": "61722ead-e030-4faf-a5f2-154ecfe7b1dc"}
{"abstract": "The difference in code size between RISC and CISC processors appears to be a significant factor limiting the use of RISC architectures in embedded systems. Fortunately, RISC programs can be effectively compressed. An ideal solution is to design a RISC system that can directly execute compressed programs. A new RISC system architecture called a Compressed Code RISC Processor is presented. This processor depends on a code-expanding instruction cache to manage compressed programs. The compression is transparent to the processor since all instructions are executed from cache. Experimental simulations show that a significant degree of compression can be achieved from a fixed encoding scheme. The impact on system performance is slight and for some memory implementations the reduced memory bandwidth actually increases performance.", "authors": ["Andrew Wolfe", "Alex Chanin"], "n_citation": 366, "references": ["03acbc54-f4e2-4c95-bf5d-a153c914740e", "96ff09f7-e819-4de9-aaf8-9eac2f5fa751", "f76d9ea3-9e6f-4676-9f27-f213710b31bb"], "title": "Executing compressed programs on an embedded RISC architecture", "venue": "international symposium on microarchitecture", "year": 1992, "id": "5872f6fd-db58-4a1c-abf8-1e781b000647"}
{"abstract": "A software requirements specification (SRS) contains all the requirements for a system-to-be. These are typically separated into functional requirements (FR), which describe the features of the system under development, and the non-functional requirements (NFR), which include quality attributes, design constraints, among others. It is well known that NFRs have a large impact on the overall cost and time of the system development process, as they frequently describe cross-cutting concerns. In order to improve software development support, an automated analysis of SRS documents for different NFR types is required. Our work contains two significant contributions towards this goal: (1) A new gold standard corpus containing annotations for different NFR types, based on a requirements ontology, and (2) a Support Vector Machine (SVM) classifier to automatically categorize requirements sentences into different ontology classes. Results obtained from two different SRS corpora demonstrate the effectiveness of our approach.", "authors": ["Abderahman Rashwan", "Olga Ormandjieva", "Ren\u00e9 Witte"], "n_citation": 50, "references": ["407309f8-ade1-41b0-9672-06b37a0504d8", "5977b570-0675-472c-bae2-6cc3f43f32fc", "5addfa59-9e85-4c60-9c39-a50af0b69b67", "67d9d31d-7ecd-42ad-97d6-d04f5fb93f8f", "6aea0481-7877-4e79-9bf1-5137d6b663f2", "7cb128e8-0634-417f-b2c9-f5d4794c21dd", "8026f56a-a93e-4933-8ead-c9aa9e3f0498", "834cf2f0-08e2-49ac-98fb-ff4228665ab8", "df46e027-1961-4c39-a568-880cc84f8390"], "title": "Ontology-Based Classification of Non-functional Requirements in Software Specifications: A New Corpus and SVM-Based Classifier", "venue": "computer software and applications conference", "year": 2013, "id": "291d6300-26a7-4cdc-ac32-f09a26d96ac8"}
{"authors": ["Tatsuya Akutsu", "Hisao Tamaki", "Takeshi Tokuyama"], "n_citation": 82, "references": ["5e58010e-caeb-4c75-a4e1-3c63498e5ed8", "6b686b1c-e6ed-4fbd-b6e0-d461aaea1a1d", "6d45b14b-3b67-4cb2-81df-6a6ad699ecac", "79645ebb-563c-469c-b98a-a5451e1ebaa9"], "title": "Distribution of distances and triangles in a point set and algorithms for computing the largest common point sets", "venue": "Discrete and Computational Geometry", "year": 1998, "id": "aad47232-d1e8-4644-a326-b697f6c3049f"}
{"abstract": "We have developed a scientific computing tool which we call the cycle server This tool enables Monte Carlo computations on the Condor cycle scavenging system. The tool presents users with a graphical Web interface which hides the complexity of distributed computing from users. Users need only upload codes and download results via the Web GUI anywhere there is Web access. Parallel random number support (via SPRNG random number library), running tasks on heterogeneous platforms (via the remote compiler), and using Condor to migrate jobs from busy or dead machines to idle ones, are all integrated seamlessly with the tool and are transparent to the user. At the same time, the cycle server acts as a gate-keeper for the workstation pool. No user accounts are needed on pool computers, and jobs only run at otherwise idle times without accessing local file systems. We show the utility of the cycle server on a large Monte Carlo computation from biochemical physics.", "authors": ["Mike Zhou", "Michael Mascagni"], "n_citation": 50, "references": ["5dfca62b-5d53-4d1e-9a16-9ccc6009af81", "df36b6d1-fc51-4bc6-be5d-854685e608c0", "ee99bc0b-a282-47b1-8cc0-6b5ab210632d"], "title": "The cycle server: a Web platform for running parallel Monte Carlo applications on a heterogeneous Condor pool of workstations", "venue": "", "year": 2000, "id": "cd6f1774-713c-4592-a150-fb756b57d06a"}
{"abstract": "On-line learning or \"relevance feedback\" techniques for multimedia information retrieval have been explored from many different points of view: from early heuristic-based feature weighting schemes to recently proposed optimal learning algorithms, probabilistic/Bayesian learning algorithms, boosting techniques, discriminant-EM algorithm, support vector machine, and other kernel-based learning machines. Based on a careful examination of the problem and a detailed analysis of the existing solutions, we propose several discriminating transforms as the learning machine during the user interaction. We argue that relevance feedback problem is best represented as a  biased classification problem , or a (1+ x )- class classification problem. Biased Discriminant Transform  (BDT) is shown to outperform all the others. A kernel form is proposed to capture non-linearity in the class distributions.", "authors": ["Xiang Sean Zhou", "Thomas S. Huang"], "n_citation": 137, "references": ["0e2a0680-d99c-4ece-927b-dabfb28b3bb2", "10c713eb-0b9b-4911-9f41-0d1373569b52", "11c22d16-f2c8-4c90-b220-56a9922b97ee", "13b91eb0-0857-4556-b32a-0f85a1cf43f6", "1c3f63fb-91e9-4147-99b3-2dffdde20341", "2430d105-9797-43da-ae3f-85eb05580219", "2c1c7fb1-f6d6-4a5c-8aa6-3b6c550b4bd7", "2d9d8d55-0c15-473b-a3c5-d0becc375775", "33da0355-a2af-4185-8234-02e054eb7fdc", "4c9c8b06-b2b9-4cbd-975e-b296e153bca1", "5634e3fa-2958-400e-a54a-f1ed2bd77ce4", "5afe32d9-e991-41f9-ae82-ac8bdde6a4b6", "6e4ecc92-bf51-4a12-a2df-15f0da3d8e14", "6f1fb770-adef-43f1-ad18-1f21519f24e6", "77975ed0-05d3-40bc-b179-41e734271c4d", "7c7b46d7-9a1f-4da8-94c6-e9b090820349", "7e7d82ae-865f-46eb-9a38-ad180c1d1d60", "977d5066-11f7-473e-befe-b140db86c3ce", "c6256bb1-c877-4c04-8d0e-ca59a415facd", "f2281d46-788e-4c45-a594-81634febabb6", "f815f346-6707-4036-b766-0a0ca290809f", "fdd18096-827d-414b-b512-fd1d4ef3bfc4"], "title": "Comparing discriminating transformations and SVM for learning during multimedia retrieval", "venue": "acm multimedia", "year": 2001, "id": "e89f8604-804a-443c-ba24-0061bb9c1bb0"}
{"authors": ["Andrew W. Fitzgibbon", "Robert B. Fisher"], "n_citation": 234, "references": ["2022caaf-c3c5-421f-a493-37a0dd9fb8e2", "32f9a283-def8-4fb1-958e-df425f170d03", "3a1d758e-8456-44d8-81b7-e66535254b6c", "b473ac83-0715-4ecc-8198-665fcb94356e", "e57c4c97-04a2-4010-9e7b-e9c8bc8b58e9", "efb34985-fd3e-4393-a957-af6c487f36fe"], "title": "A buyer's guide to conic fitting", "venue": "british machine vision conference", "year": 1995, "id": "74c89dd1-5239-4f46-bf5f-1e0249367e76"}
{"abstract": "A distributed architecture for the support of programs written in the persistent programming language Napier is described. The architecture consists of a central server containing the stable persistent store and a collection of clients, each executing Napier processes. Since each client has a cache of objects, some of which may be shared with other clients, a protocol is required to ensure that the caches are coherent and that any access of an object will be to the most up-todate copy. This architecture is explicated by following the lifecycle of an object from its \u2018birth\u2019 inside a client, through its life in the persistent store and its migration into other clients. Using this vehicle, the coherency protocol and client/server architecture are illustrated and explained.", "authors": ["Bett Koch", "Tracy Schunke", "Alan Dearle", "Francis Vaughan", "Chris D. Marlin", "Ruth Fazakerley", "Chris J. Barter"], "n_citation": 44, "references": ["0ce74249-8be4-45f5-96de-c5fb2c69c2e9", "4f55c76e-bac6-4c88-a82d-a01d9944dfb8", "82e4b875-7a25-46ce-9e8f-1726d50697a2", "90b71c48-d604-425f-9ef9-a63b49c88ab7", "9dc7ccfb-9771-40cb-9e77-436398d337cc", "b71ce37f-7d4e-47d1-95a0-3953928c025a", "b81e551a-1b21-437b-abba-40e3026b51a9", "d17c4f06-3399-4c3b-a709-fdbe9205fc58"], "title": "Cache Coherency and Storage Management in a Persistent Object System.", "venue": "", "year": 1990, "id": "e086025d-0cfc-4783-9cd4-cdea26a59e78"}
{"authors": ["Murray Shanahan"], "n_citation": 46, "references": ["19070519-b440-4860-801a-c4757095cb86", "26f9737e-b150-43cc-8ce1-c5fd67f9ef25", "5fe8b0bd-a552-4ede-8b43-f2c56a6e067f", "6f1fbe0f-1101-4f8a-8109-d34e05601a6b", "b62a32f3-eb04-429f-93ca-f20dadf916a5", "d3e8057d-579e-4a06-bc9c-1504f41ffcfa"], "title": "A Logical Account of Perception Incorporating Feedback and Expectation.", "venue": "principles of knowledge representation and reasoning", "year": 2002, "id": "b0c3fa7e-736b-4ccd-b919-d73df5a0b571"}
{"authors": ["Mahadev Satyanarayanan", "Jason Flinn", "Kevin R. Walker"], "n_citation": 50, "references": ["2ebde61f-7761-409f-8ec7-842de39b4331", "778edfdc-6bfc-42a7-90d5-24284cc852dd", "7da6afbd-aa52-47f9-b6ca-9e7f709fb9c4", "8b7fba8e-479b-40e5-bd7e-d09adcb86aaf", "a49af0d8-9c3c-4b89-9322-55471deaa9f9", "b87860ce-71bf-4dea-a751-180eb22a8ff4", "cfe5590e-dd0a-417b-a008-b5c4ce8a63e2"], "title": "Visual proxy: exploiting OS customizations without application source code", "venue": "Operating Systems Review", "year": 1999, "id": "15134934-983c-464c-8a2b-1840dfaf6c65"}
{"abstract": "Modern multi-core architectures offer Dynamic Voltage and Frequency Scaling (DVFS) that can dynamically adjust the operating frequency of each core for energy saving. However, current parallel programming environments and schedulers for task-based programs do not utilize DVFS and thus suffer from energy inefficiency in multi-core processors. To reduce energy consumption while keeping high performance, this paper proposes an Energy-Efficient Workload-Aware (EEWA) task scheduler that is comprised of a workload-aware frequency adjuster and a preference-based task-stealing scheduler. Using DVFS, the workload-aware frequency adjuster can properly tune the frequencies of the cores according to the workload information of the tasks collected with online profiling. The preference-based task-stealing scheduler can then effectively balance the workloads among cores by stealing tasks according to a preference list. Experimental results show that EEWA can reduce energy consumption of task-based programs up to 29.8% with a slight performance degradation compared with existing task schedulers.", "authors": ["Quan Chen", "Long Zheng", "Minyi Guo", "Zhiyi Huang"], "n_citation": 50, "references": ["00280e62-7a13-41d0-bb10-068b11e68f53", "0334579b-9a23-4d98-a2fa-4770573320f3", "045e5da5-39f3-46c7-bb51-a1aeae7d3e18", "2878c3bd-a86f-4c4b-ba2d-1ad4c467fd5a", "2c179433-d07a-4e2b-86f8-6606f8cfe30a", "364f0ad1-065d-4674-a098-1b980ec40525", "4872edf4-5694-44ad-978e-4109cfef6907", "6032e07b-d786-46b3-b6bc-89e44862a141", "61a79524-1ae6-487b-b1a0-df66c72f28b6", "66d86606-27a5-4b17-9a15-66fb987be6b2", "74167588-3005-4523-abca-9cb4ed400155", "7a83e1e5-5097-4c73-8afb-4615dfa14d01", "8045aaff-241c-4c29-bcb5-8e8d2d59c974", "84aac5f8-86d2-4582-9745-583735162fe5", "858c2b6f-f36f-4a1f-8809-5c37b5f6638c", "94d16bf8-ed41-4cf3-85c8-5bb60ba5cb8f", "cd8f7664-1e1d-48a8-9ca5-d960754dd558", "d244e7e0-e0f0-4cef-990a-24dc9706badb", "d3b2c3b2-5b25-4266-8ac2-bd3b062ba993", "dbe5fe23-3842-41bd-aaea-2144a55b7d7a", "e071cf6b-b4c7-4b6a-8cae-2ccffe139ecc", "e1adc85b-cfe9-4646-8ecf-b138c0359633", "ebd2bad4-5324-42f8-8170-e325620ed2c2"], "title": "EEWA: Energy-Efficient Workload-Aware Task Scheduling in Multi-core Architectures", "venue": "international parallel and distributed processing symposium", "year": 2014, "id": "1581bf0a-cd94-4329-aa93-5674ea45e63f"}
{"abstract": "Summary We propose a computer system called Cellsecu that maintains the anonymity and the confidentiality of each cell containing sensitive information in medical database. Cellsecu attains this by automatically removing, generalizing, and expanding information. It is designed to enhance data privacy protection so a data warehouse can automatically handle queries. In most cases, health organizations collect medical data with explicit identifiers, such as name, address and phone number. Simply removing all explicit identifiers prior to release of the data is not enough to preserve the data confidentiality. Remaining data can be used to reidentify individuals by linking or matching the data to other database, or by looking at unique characteristics found in the database. A formal model based on Modal logic is the theoretical foundation of Cellsecu. As well, a new confidentiality criteria called \u2018\u2018non-uniqueness\u2019\u2019 is defined and implemented. We believe modeling this problem formally can clarify the issue as well as clearly identify the boundary of current technology. Base on our preliminary performance evaluation, the confidentiality check module and the confidentiality enhancing module only slightly degrade system performance.", "authors": ["Yu-Cheng Chiang", "Tsan-sheng Hsu", "Sun Kuo", "Churn-Jung Liau", "Da-Wei Wang"], "n_citation": 23, "references": ["24290f50-77cf-4935-89ea-919661b26586", "25c8cc83-7c57-4071-b21b-5218ac9b2d9f", "3b86307d-ca4a-4bfd-8244-a880a4fbe0f5", "5c8731e9-e0d3-4ab8-ad1c-813d504dd8a7", "60fba235-2730-4fb0-997b-117ceed695a4", "aaf903a7-0431-4855-b3d5-f92d0d766641", "efe2dd1d-706c-4ab6-bd9b-90d35a81d04f", "fb733d35-ff61-449f-aa05-d8614cbc761b", "ff2793b9-3a58-4076-aff0-31721ac12255"], "title": "Preserving confidentiality when sharing medical database with the Cellsecu system.", "venue": "International Journal of Medical Informatics", "year": 2003, "id": "339741bd-9b13-4b66-9ca8-cf63ea8c294a"}
{"abstract": "The gene-duplication problem is to infer a species supertree from acollection of gene trees that are confounded by complex histories of gene duplicationevents. This problem is NP-complete and thus requires efficient and effectiveheuristics. Existing heuristics perform a stepwise search of the tree space, whereeach step is guided by an exact solution to an instance of a local search problem.A classical local search problem is the NNI search problem, which is based onthe nearest neighbor interchange operation. In this work we (i) provide a novelnear-linear time algorithm for the NNI search problem, (ii) introduce extensionsthat significantly enlarge the search space of the NNI search problem, and (iii)present algorithms for these extended versions that are asymptotically just as efficientas our algorithm for the NNI search problem. The substantially extendedNNI search problem, along with the exceptional speed-up achieved, make thegene-duplication problem more tractable for large-scale phylogenetic analyses.", "authors": ["Mukul S. Bansal", "Oliver Eulenstein"], "n_citation": 50, "references": ["2923ba31-e5c5-4130-8558-ebfd1f60dea0", "3ae23893-7751-4ba7-967d-f70ca68f4361", "4b364b99-37f3-4bfc-81d8-aea4c069ddb7", "538a6e55-c0a3-4120-913e-b1e2238698b1", "5e593712-4f16-4542-a2af-95dd6213302a", "8559019b-05c6-4435-bf93-8f1e017c7f6d", "85efcff2-4359-47ab-9037-e68ff4a8a327", "8a9a5557-a600-4258-8a1f-42720106c986", "8b1e4009-68f1-4bc7-b095-1a1fd05c0d90", "8f3bae28-2a73-49b7-8b5e-9851cd25b13b", "a2c6aa44-7d1a-4442-9819-c28afc828c2f", "b1a4fda0-2f4f-4156-af93-19499101a371", "be39ea8c-5475-47ed-8c04-baa80293ad63", "c76cb2b8-75e0-4d1f-93a4-b02e6f3c3fa1", "dcc12966-b536-46ea-9126-5fbb59d58d2a", "eb74ab9f-4940-4962-a00e-61b3ba63120e", "f0e22dc5-a48a-4ccd-a5e3-8a0bebbeb16d"], "title": "The gene-duplication problem: near-linear time algorithms for NNI based local searches", "venue": "international symposium on bioinformatics research and applications", "year": 2008, "id": "4ee39e80-2ea4-4b98-b520-742cf8a0464f"}
{"abstract": "The recognition community has long avoided bridging the representational gap between traditional, low-level image features and generic models. Instead, the gap has been artificially eliminated by either bringing the image closer to the models, using simple scenes containing idealized, textureless objects,,or by bringing the models closer to the images, using 3-D CAD model templates or 2-D appearance model templates. In this paper, we attempt to bridge the representational gap for the domain of model acquisition. Specifically, we address the problem of automatically acquiring a generic 2-D view-based class model from a set of images, each containing an exemplar object belonging to that class. We introduce a novel graph-theoretical formulation of the problem, and demonstrate the approach on real imagery.", "authors": ["Yakov Keselman", "Sven J. Dickinson"], "n_citation": 50, "references": ["29439b01-f273-40ef-8dca-78fa4a7a5a86", "2ea16f6a-9fb7-4cbb-b632-4297abca8665", "32f9a283-def8-4fb1-958e-df425f170d03", "34ab16ee-97db-4520-992e-f92aca3386d8", "5d5a71eb-bf78-4083-bea1-47adb54e6be4", "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c", "87c6d06a-66ed-4867-b789-2d114525063c", "8d26e52c-b697-4e69-bb07-6a63ddeae5e4", "8fd827e4-e11b-4fea-bdfb-690d453e6ee1", "9259a1ac-8f82-4a05-b273-b90d3694f3f9", "ccdefe89-9b16-4c22-8bb8-bd314ccad6e1", "dfc13c0e-d6f7-440b-a33a-dc8a598bb180"], "title": "Generic model abstraction from examples", "venue": "computer vision and pattern recognition", "year": 2001, "id": "77b77528-2217-4dde-b9de-93b1538e6941"}
{"abstract": "A fuzzy control strategy is described which is utilized to control the rigid body and the first flexural mode of vibration in a single link robotic arm. Both simulated and experimental results are presented and show that the rigid and flexible modes can be adequately controlled with the proposed technique. The results are shown to provide some improvement over those obtained by more conventional means. >", "authors": ["Eric Kubica", "David Wang"], "n_citation": 37, "references": [], "title": "A fuzzy control strategy for a flexible single link robot", "venue": "international conference on robotics and automation", "year": 1993, "id": "fbe96500-16c8-4309-8aae-3436adf9bf3c"}
{"abstract": "It is now widely acknowledged that analyzing the intrinsic geometrical features of the underlying image is essential in many applications including image processing. In order to achieve this, several directional image representation schemes have been proposed. In this paper, we develop the discrete shearlet transform (DST) which provides efficient multiscale directional representation and show that the implementation of the transform is built in the discrete framework based on a multiresolution analysis (MRA). We assess the performance of the DST in image denoising and approximation applications. In image approximations, our approximation scheme using the DST outperforms the discrete wavelet transform (DWT) while the computational cost of our scheme is comparable to the DWT. Also, in image denoising, the DST compares favorably with other existing transforms in the literature.", "authors": ["Wang-Q Lim"], "n_citation": 337, "references": ["036a19f8-fdca-4e84-a237-e54f2108dcb4", "22c09b2c-4645-482e-8604-2a5a8df9eb88", "2bc5d0f1-16b5-4a2b-968e-66ad5ace0c8a", "4a4cdb63-5e57-4011-84d0-d18f851962aa", "8ab8211d-6358-47b4-b4cb-578a914e4a86", "a5c84fbe-a3ed-469d-b086-3fff56342144", "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474", "f5cb6a0f-3955-4f0d-b7b3-611e6f8996ed"], "title": "The Discrete Shearlet Transform: A New Directional Transform and Compactly Supported Shearlet Frames", "venue": "IEEE Transactions on Image Processing", "year": 2010, "id": "4a64ab2f-4ec4-4725-a444-ca82f2ea7910"}
{"authors": ["Mikhail Moshkov"], "n_citation": 5, "title": "OPTIMIZATION PROBLEMS FOR DECISION TREES", "venue": "Fundamenta Informaticae", "year": 1994, "id": "ecd09077-7679-46e7-9628-58a0a265bc80"}
{"abstract": "Abstract : A program annotated with inductive assertions is said to be verification decidable if all of the verification conditions generated from the program and assertions are formulas in a decidable theory. The Presburger array theory, is defined, containing two logical sorts: integer and array-of-integer. Addition, subtraction, and comparisons are permitted for integers. Array contents and assign functions, and, since the elements of the arrays are integers, array accesses may be nested. The first result is that the validity of unquantified formulas in Presburger array theory is decidable, yet quantified formulas in general are undecidable.", "authors": ["Norihisa Suzuki", "David Jefferson"], "n_citation": 72, "references": ["cf8ea253-b2c3-44cc-81dd-2e92903325b1"], "title": "Verification Decidability of Presburger Array Programs", "venue": "Journal of the ACM", "year": 1980, "id": "fa0da3ae-fca7-4653-8d38-04cbb5700d2a"}
{"abstract": "An image segmentation method is proposed, which combines mathematical morphology tools and active contours in two stages. First, contours are coarsely approximated by means of morphological operators. Second, these initial contours evolve under the influence of geometric and grey-level information, owing to the model of active contours. The performance of the method is evaluated according to the noise and is compared to the watershed algorithm. Then an application is finally presented for biomedical images of tumour tissue.", "authors": ["Abderrahim Elmoataz", "Sophie Sch\u00fcpp", "R\u00e9gis Clouard", "Paulette Herlin", "D. Bloyet"], "n_citation": 50, "references": ["1c63e1d5-b963-455b-829d-e4f3eb63a36a", "2ccb01b5-e59c-4ff4-b627-a76a72c9738c", "425141eb-a755-434c-9c1a-16e8893134be", "59f527c2-f4aa-4e39-9b0e-23951f82ed58", "73e6f6ab-a277-414b-9b36-35eed6c12a89", "87e3d6b4-7225-4b44-b149-b0f092aef379", "b2de99a5-01d1-4359-be11-10c2ce130a05"], "title": "Using active contours and mathematical morphology tools for quantification of immunohistochemical images", "venue": "Signal Processing", "year": 1998, "id": "38c64ccb-c99b-4328-aa93-2dc8bd2c0cf7"}
{"abstract": "Abstract#R##N##R##N#New classes of large-scale distributed applications will have to deal with unpredictable communication delays, with partial failures, and with networks that partition. In addition, sophisticated applications such as teleconferencing, video-on-demand, and concurrent software engineering require a group communication abstraction. These paradigms are not adequately addressed by CORBA. CORBA mainly deals with point-to-point communication and offers no support for the development of reliable applications that exhibit predictable behavior in distributed systems. In this article, we present extensions to CORBA which provide group communication, reliability, and fault tolerance. We also describe Orbix+Isis and Electra\u2014two CORBA object request brokers that support the implementation of reliable distributed applications and groupware. \u00a9 1997 John Wiley & Sons, Inc.", "authors": ["Sean Landis", "Silvano Maffeis"], "n_citation": 168, "title": "Building reliable distributed systems with CORBA", "venue": "Theory and Practice of Object Systems", "year": 1997, "id": "870b655d-408c-4e98-87be-8a83bf1e27e0"}
{"authors": ["D. Ribot", "Bongard Ba", "Claude Villermain"], "n_citation": 5, "references": ["a7edd9d0-dc70-4c1a-b1a3-f8f8d2cffa60", "c68af099-1392-479a-a21c-725d67051988"], "title": "Development life-cycle WITH reuse", "venue": "acm symposium on applied computing", "year": 1994, "id": "33facf9a-e34d-47ca-9b45-174381fbe975"}
{"abstract": "I explore some of the issues that arise when trying to establish a connection between the underspecification hypothesis pursued in the NLP literature and work on ambiguity in semantics and in the psychological literature. A theory of underspecification is developed `from the first principles', i.e., starting from a definition of what it means for a sentence to be semantically ambiguous and from what we know about the way humans deal with ambiguity. An underspecified language is specified as the translation language of a grammar covering sentences that display three classes of semantic ambiguity: lexical ambiguity, scopal ambiguity, and referential ambiguity. The expressions of this language denote sets of senses. A formalization of defeasible reasoning with underspecified representations is presented, based on Default Logic. Some issues to be confronted by such a formalization are discussed.", "authors": ["Massimo Poesio"], "n_citation": 96, "references": ["02e26332-ffd2-4d0c-bae6-38e80f88cf79", "282f75b0-08c2-45a0-9b5d-057e3880dbda", "6930c930-bb13-4d09-bfff-9be5c1bb1d61", "993bfdff-77de-4114-961e-79c68af2cf3f", "9b46a309-21cc-452e-b890-8f5f3e3293c4", "a0e8d6dd-1820-4101-abb1-6eb7d6d36fcb", "a8f37f28-e6be-45c9-a48f-e4f86eea1a46", "aed86e55-844b-49ca-9e5c-e46874be9780", "d365ef26-224f-4e55-9074-fcafd3c96dbf", "db797171-461e-497c-842d-6170df727e3d"], "title": "Semantic Ambiguity and Perceived Ambiguity", "venue": "arXiv: Computation and Language", "year": 1995, "id": "6d6de6c7-1657-4a89-82d4-a428bb6ef8ed"}
{"abstract": "This paper investigates the two main and seemingly antagonistic approaches to broadcasting messages reliably in fault-tolerant distributed systems: the approach based on reliable broadcast, and that based on view synchronous communication (or VSC for short). While VSC does more than reliable broadcast, this has a cost. We show that this cost can be reduced by exploiting the difference between input-triggered and output-triggered suspicions, and by replacing the standard VSC broadcast primitive by two broadcast primitives, one sensitive to input-triggered suspicions, and the other sensitive to output-triggered suspicions.", "authors": ["Bernadette Charron-Bost", "Xavier Defago", "Andr\u00e9 Schiper"], "n_citation": 50, "references": ["0677c9dc-8269-4d3e-8cc5-a89a10401d0f", "128ce11d-fffe-478d-9ea0-9b720f5a258a", "4b4c2f4d-3c81-488b-977e-b32c2093ad17", "4cfbdeed-1f59-4ea2-bd89-5bc516fe6adf", "575215ab-dad7-430d-9434-0f19c3928931", "57be5ce7-27d9-4175-8a45-b5c1cd9a2247", "619d91f3-6ae2-4c6c-8c31-60aad0390847", "680d48b5-66e6-496c-b4fd-b47208f91035", "7ffec2f8-420b-43cf-8ad5-550e332f5d6d", "ab84e26f-aa43-4000-9eaa-8a73e7a178d0", "d9c271a7-a67d-4fb4-940d-012282c83b79", "eaa340b0-5c17-4462-b64e-937249e40bfe"], "title": "Broadcasting messages in fault-tolerant distributed systems: the benefit of handling input-triggered and output-triggered suspicions differently", "venue": "symposium on reliable distributed systems", "year": 2002, "id": "b7145433-8d07-402e-a5c5-ec64d77dfb97"}
{"abstract": "This paper describes SMES, an information extraction core system for real world German text processing. The basic design criterion of the system is of providing a set of basic powerful, robust, and efficient natural language components and generic linguistic knowledge sources which can easily be customized for processing different tasks in a flexible manner.", "authors": ["G\u00fcnter Neumann", "Rolf Backofen", "Judith Baur", "Markus Becker", "Christian Braun"], "n_citation": 146, "references": ["0e1d46f1-0879-486b-a349-17cab36b8034", "4132b728-4b5a-4d3f-94e3-add400f11b8a", "4cdb7a67-970a-46c5-952d-b03c5bd4aeee", "5d4e6544-9fc4-4de1-ad9e-c819fffa1c39", "6f5fc79b-8228-40e9-9ae1-49dabf54e192", "7a841f6e-809e-40c3-b03c-9bf3e03a3509", "a0ae5911-0fde-4e8d-81d4-30c151d42907", "a2659ef0-cdff-44c5-9542-4a0dd0a12715", "c1450b40-8661-4593-90c7-26359241f4eb", "cc3f2ceb-d5f4-4c2e-a5af-84b1980f70ca", "dc8906f4-fd35-43b2-9fe3-b816d0f7c7b0", "f3ee1bc7-3a3b-4169-92c2-2a6e962070ee"], "title": "An Information Extraction Core System for Real World German Text Processing", "venue": "arXiv: Computation and Language", "year": 1997, "id": "44ba8e80-f9b7-4b9f-816e-756d785b9a18"}
{"abstract": "We provide a subclass of parametric timed automata (PTA) that we can actually and efficiently analyze, and we argue that it retains most of the practical usefulness of PTA for the modeling of real-time systems. The currently most useful known subclass of PTA, L/U automata, has a strong syntactical restriction for practical purposes, and we show that the associated theoretical results are mixed. We therefore advocate for a different restriction scheme: since in classical timed automata, real-valued clocks are always compared to integers for all practical purposes, we also search for parameter values as bounded integers. We show that the problem of the existence of parameter values such that some TCTL property is satisfied is PSPACE-complete. In such a setting, we can of course synthesize all the values of parameters and we give symbolic algorithms, for reachability and unavoidability properties, to do it efficiently, i.e., without an explicit enumeration. This also has the practical advantage of giving the result as symbolic constraints between the parameters. We finally report on a few experimental results to illustrate the practical usefulness of our approach.", "authors": ["Aleksandra Jovanovic", "Didier Lime", "Olivier H. Roux"], "n_citation": 10, "references": ["08992f78-91a2-4fae-8729-46ad6e8a9847", "0d4f32fe-2bfb-4f19-9ce9-63d74b2dca1f", "12c9fc70-d3ed-4079-9a3a-b662d5cb3f7c", "148b796a-f1bb-4393-8202-70bb576ca2b9", "2383e70b-0513-4e40-9719-a4c3eb46589c", "2423370f-1d7e-457e-9b01-decb42d39b28", "378cb17b-15da-4608-a3a4-adbcf75f548f", "3b321585-52cb-4757-b697-5711f4f20dea", "615d943c-9eb4-4478-9cb0-cfdb4077824c", "756b4570-813b-486f-b38a-b55b050065e7", "78292753-9ae6-437d-a460-eebd15322e7a", "78b797a4-08bf-47b9-891e-f289eec0d017", "80e4b7d3-5d13-4aa2-af65-5a28b7dc14f0", "844da467-67a6-45a4-b2bc-7827c677aabe", "88374ada-5a62-46f8-9056-47682ff33289", "88e266bb-8331-4722-80ad-b4b5db1a09e1", "8c9621d8-93e9-4b4a-ae5f-e689202a1e32", "98d0c1d8-ada3-4fda-bde5-f123b6e8a389", "99a9d7be-0c36-4a00-b0e7-3c2043c3afae", "9b9ce728-4fab-4459-9fbf-984911a818e1", "9be69b2a-20e8-4073-a996-523c8ed2e035", "9c4c8417-cd0d-46bb-b29f-afa22dea755e", "9f3cea46-627e-40a2-8b2c-912b7457eec0", "baf71cfc-f44d-47ea-9941-2bffdbcaad3d", "bb391a8d-069f-476c-b941-63c2a03a8dca", "c87146f7-b74f-4d58-82b6-064272d662ab", "c9721e32-74ba-4489-b787-8049210a410d", "dc99a09f-f60e-4edc-a279-2deda2387781", "e5f69e73-b189-42ab-a7e4-e92510857f88", "f28d549f-0c60-4fa2-9f6e-0e01c5aad25d", "fafc3751-a363-4c4d-9008-b6fcf15d6de4", "fe02b062-a092-4f80-b021-2c20ba0e9270"], "title": "Integer Parameter Synthesis for Real-Time Systems", "venue": "IEEE Transactions on Software Engineering", "year": 2015, "id": "198b6f5f-6b82-47a4-bcd0-177c9f36b507"}
{"abstract": "Two lapped transforms for subband/transform coding of signals are introduced: a version of the lapped orthogonal transform (LOT), which can be efficiently computed for any transform length; and the modulated lapped transform (MLT), which is based on a modulated quadrature mirror (QMF) bank. The MLT can also be efficiently computed by means of a type-IV discrete sine transform (DST-IV). The LOT and the MLT are both asymptotically optimal lapped transforms for coding an AR(1) signal with a high intersample correlation coefficient. The coding gains of the LOT and MLT of length M are higher than that of the discrete cosine transform (DCT) of the same length; they are actually close to the coding gains obtained with a DCT of length 2M. An MLT-based adaptive transform coder (ACT) for speech signals is simulated; the code is essentially free from frame rate noise and has a better spectral resolution that DCT-based ATC systems. >", "authors": ["Henrique S. Malvar"], "n_citation": 628, "references": ["0fe42d07-30d7-46f6-acae-f7d0f778a126", "1bf916f7-f2fe-4ebb-b510-de6bc385d46c", "1e3b8158-ef99-49ea-932a-e08fa37a0fb3", "31667b5f-0507-4d94-99d5-193d12169010", "40c8cc69-75b9-4fbc-bc57-3ae522920a20", "744b15cd-a639-4760-a74b-7ad671fe1f8c", "938b98e9-7c7e-4d9e-9d26-53f5f9c44c25", "99c259fc-4f3b-4ca9-a449-f19425bd2867", "db4611fc-a014-465b-bfad-317e9696aae3"], "title": "Lapped transforms for efficient transform/subband coding", "venue": "IEEE Transactions on Acoustics, Speech, and Signal Processing", "year": 1990, "id": "7c803f70-1b85-491e-b621-93a832a1c15c"}
{"abstract": "We present nonlinear delayed feedback stimulation as a technique for effective desynchronization. This method is intriguingly robust with respect to system and stimulation parameter variations. We demonstrate its broad applicability by applying it to different generic oscillator networks as well as to a population of bursting neurons. Nonlinear delayed feedback specifically counteracts abnormal interactions and, thus, restores the natural frequencies of the individual oscillatory units. Nevertheless, nonlinear delayed feedback enables to strongly detune the macroscopic frequency of the collective oscillation. We propose nonlinear delayed feedback stimulation for the therapy of neurological diseases characterized by abnormal synchrony.", "authors": ["V. D. Popovych", "Christian Hauptmann", "A. Tass"], "n_citation": 149, "references": ["045ad1c8-1f89-441b-b487-954e41b8c6be", "0b15e6fc-5040-4e89-85a6-e1db96f4f73a", "13295d91-c637-4028-9f0d-4ef7292498e2", "314e3e13-6513-442c-93e1-e80e7ede0b07", "7acfc6ff-dcce-4cea-9ad9-c9209198ce4f", "cfb31636-9176-4d28-ae16-4b44ebaa71bc", "d84c1276-3d59-4bc1-ba84-73b7f8167047"], "title": "Control of Neuronal Synchrony by Nonlinear Delayed Feedback", "venue": "Biological Cybernetics", "year": 2006, "id": "0fe5f1c9-7af2-4cc3-8fae-8890bf548ca9"}
{"abstract": "The notion of a  program slice , originally introduced by Mark Weiser, is useful in program debugging, automatic parallelization, and program integration. A slice of a program is taken with respect to a program point  p  and a variable  x ; the slice consists of all statements of the program that might affect the value of  x  at point  p . This paper concerns the problem of interprocedural slicing\u2014generating a slice of an entire program, where the slice crosses the boundaries of procedure calls. To solve this problem, we introduce a new kind of graph to represent programs, called a  system dependence graph , which extends previous dependence representations to incorporate collections of procedures (with procedure calls) rather than just monolithic programs. Our main result is an algorithm for interprocedural slicing that uses the new representation. (It should be noted that our work concerns a somewhat restricted kind of slice: rather than permitting a program to be sliced with respect to program point  p  and an  arbitrary  variable, a slice must be taken with respect to a variable that is  defined  or  used  at  p .)  The chief difficulty in interprocedural slicing is correctly accounting for the calling context of a called procedure. To handle this problem, system dependence graphs include some data dependence edges that represent  transitive  dependences due to the effects of procedure calls, in addition to the conventional direct-dependence edges. These edges are constructed with the aid of an auxiliary structure that represents calling and parameter-linkage relationships. This structure takes the form of an attribute grammar. The step of computing the required transitive-dependence edges is reduced to the construction of the subordinate characteristic graphs for the grammar's nonterminals.", "authors": ["Susan Horwitz", "Thomas W. Reps", "David Binkley"], "n_citation": 1320, "references": ["012684bd-4559-4c84-940c-736834718cef", "0cc1c991-39f1-4e19-9fd1-3b625fbb23c4", "1819c128-54ff-49a9-b312-0956bce57488", "2c08d317-3848-40af-9dfa-20c8ce584ce9", "35bfbf7f-ce7a-47e6-8ac2-7d80baeaee6a", "405cbb0f-242c-4678-842e-f15549e3f23f", "4ecf3181-858b-409d-95f1-d3cfb882dd08", "5e442872-26ff-4315-ab1b-14320bf62ddb", "73c1dcb8-e5c5-4c5d-9d79-b6561266c69d", "74f487b8-5648-4891-bf7f-84ea9fd6dc0f", "75e854e6-e252-47ee-b88e-0595b63bcaf7", "8136f742-fabf-4dde-84c5-cca4c71d1057", "a06e2b30-85f3-4dba-bb18-04daa37807a7", "abde5ea1-99dc-4812-aa90-50f17478138f", "c3ffb05e-167d-4ad5-ae3c-34cf8b17d103", "c407fa93-c2ae-4b48-9b56-7feb0134352d", "de22b6a0-28b4-433a-ad0c-cf234a6e63a8", "e04f4c93-0b35-4b63-b9f2-3594485f6a4e"], "title": "Interprocedural slicing using dependence graphs", "venue": "ACM Transactions on Programming Languages and Systems", "year": 1990, "id": "f9fbe00e-2980-4c0e-a9b1-4e62fd5fa383"}
{"abstract": "A lightweight tool is proposed to aid in the development of operational semantics. To use LETOS an operational semantics must be expressed in its meta-language, which itself is a superset of Miranda. The LETOS compiler is smaller than comparable tools, yet LETOS is powerful enough to support publication quality rendering using LaTeX, fast enough to provide competitive execution using Haskell, and versatile enough to support browsing of execution traces using Netscape. LETOS can be characterised as an experiment in creative laziness, showing how far one can get by gluing existing components together. The major specifications built using LETOS to-date are a smart card version of the Java Virtual Machine, a deterministic version of the -calculus, and an electronic payment protocol. In addition, we have specified the semantics of many small programming languages and systems, totaling over 9000 lines of formal text. LETOS is unique in that it helps to check that a specification is operationally conservative.", "authors": ["Pieter H. Hartel"], "n_citation": 50, "references": ["0f785058-a24b-4945-835a-b15f7fd8825f", "112eeff7-c265-4808-aef5-55f592540e40", "1b8fa31c-e439-49a2-9c13-52bb85416b30", "1c64b1fa-1703-403b-8e91-d3b4caeb71bb", "3023929a-c93e-49c5-b03f-7fb0414d94df", "4484f54d-ea17-47ae-823c-31f2fd735da8", "4c5923dd-0888-4aae-8754-618b98dae46e", "52391e5d-c3cb-4313-b139-5d60a38f480e", "6580fbcd-7526-4466-a196-0c3ae7b13213", "6f45828a-82d4-4306-bc4f-f7fb31d4298e", "7eadd44c-ac31-41dd-86e9-ab16f2c56454", "8523ed37-a096-4951-9c24-d60999508dba", "9de92955-bc28-4323-8953-54894738f732", "aac3f983-fb53-4399-85dc-7add9854e8da", "b55f972a-1c84-492d-a32e-987d0560e637", "be9cd3ac-8836-4de2-918d-87752acb6cb3", "c19d02fc-3ba0-4a42-a260-2e12b3c43c2c", "d3d44f28-77c9-48c5-b5c5-16b0ee03a1d9", "eb129db8-490d-4b1b-b702-6e6f7cf9dd78", "edb7a8e6-909c-42eb-9a92-b3653fbefa83", "f6b1027b-360e-4d18-94de-8ec80884a3ef"], "title": "LETOS \u2014 a lightweight execution tool for operational semantics", "venue": "Software - Practice and Experience", "year": 1999, "id": "ad8d3c87-c15a-48f1-8348-ddc37f138d3a"}
{"abstract": "This paper presents a method for reducing the cost of test generation. A spanning set for a coverage criterion is a set of entities such that exercising every entity in the spanning set guarantees exercising every entity defined by the coverage criterion. The central notion used in constructing a minimum spanning set is subsumption relation. An entity subsumes another entity if exercising the former guarantees exercising the latter. We develop a method for finding subsumption relations which can be uniformly applied to a family of control flow and data flow oriented coverage criteria by reducing the problem of determining whether an entity subsumes another entity to the model checking problem of the linear temporal logic LTL.", "authors": ["Hyoung Seok Hong", "Hasan Ural"], "n_citation": 50, "references": ["0c5994e2-2de6-4125-87f6-7366a70c7ed3", "190d21f3-7b6b-40c0-925f-18bb21e3b7f4", "1f499201-9dfe-45cd-b235-e71067be2dc5", "2ac5fedd-db52-4207-ac12-b527da60b604", "37e2c154-8139-4b1d-9ba4-79180298b613", "3eaeed58-c8b0-47f7-b005-72923125c87c", "5d5369e2-6fc2-4742-938a-18d9aa61b773", "663ed9bc-878a-4800-98f3-131663c4f117", "7385de60-bc08-49a2-a9dd-739d68937b88", "7fb255cd-234a-4e6c-82ff-c1adc0935d85", "82f91b5f-7f5e-429b-821d-5a1cd3aaeba9", "9849d9c4-a97f-452f-882c-42a8c6cab0b5", "a89da70a-3054-4513-b4ec-66cd1b97ae9b", "aa53709a-972b-47be-a10f-b76259fc3978", "c5ec1c87-2aa7-4178-a048-53a43de44145", "e2803feb-511d-4fd1-8553-e47212d48f98", "f1d6f16f-e017-4d04-8581-420dd1f03770", "fcc366e1-ddca-43df-ae8e-0b068926dc2f"], "title": "Using model checking for reducing the cost of test generation", "venue": "", "year": 2004, "id": "48cce511-ed6a-4981-8e6d-9f706c483d71"}
{"abstract": "This paper describes the transition control in an integrated automated bus system for Bus Rapid Transit. Employing two lateral sensing technologies, magnet markers and DGPS/INS systems for enhanced reliability and extended operating range, this integrated automatic system involves both the manual-automatic transition and the transition between the magnet-based control and the DGPS/INS-based control. This paper proposes a unified transition method, in which an open-loop dynamic initial conditioning is added to the existing high-gain closed-loop automatic steering control systems to provide suitable references to the high-gain automatic steering controllers. Designed as a lower-gain (softer) regulation controller, this open-loop dynamic initial conditioning smoothly drives the lateral and heading angle errors to zero during transitions. Experimental results with a 40ft bus demonstrate that the proposed method achieves smooth and immediate transitions between manual and automatic control as well as between the two control systems.", "authors": ["Jihua Huang", "Han-Shue Tan"], "n_citation": 4, "references": ["893d8784-ced2-43f7-a067-08ac17a83e42", "966ac4c7-8b4e-47c4-a02b-4a3a20b22d29"], "title": "Immediate transitions for an automated bus using magnetic and DGPS sensing systems", "venue": "", "year": 2011, "id": "3b894512-db2d-4b57-8cf1-e5ff27959998"}
{"authors": ["Carlos Mart\u00edn-Vide", "Gheorghe P\u0103un"], "n_citation": 50, "title": "Duplication grammars", "venue": "", "year": 1999, "id": "548cb367-4afd-4db0-9606-45b9fb2f1e40"}
{"abstract": "We present a novel dynamic analysis technique that finds real deadlocks in multi-threaded programs. Our technique runs in two stages. In the first stage, we use an imprecise dynamic analysis technique to find potential deadlocks in a multi-threaded program by observing an execution of the program. In the second stage, we control a random thread scheduler to create the potential deadlocks with high probability. Unlike other dynamic analysis techniques, our approach has the advantage that it does not give any false warnings. We have implemented the technique in a prototype tool for Java, and have experimented on a number of large multi-threaded Java programs. We report a number of previously known and unknown real deadlocks that were found in these benchmarks.", "authors": ["Pallavi Joshi", "Chang-Seo Park", "Koushik Sen", "Mayur Naik"], "n_citation": 163, "references": ["11b47a34-e765-4ba7-ad20-2be49b46e7fe", "136c4780-2f25-4068-90a5-aed6afaf2890", "1537517e-9304-4350-b290-144dd68d64ad", "308d5af9-fcd6-4645-b834-4a3148de4700", "3ad0693d-69cc-415a-81ae-283d89696a63", "41cf9713-ed76-43a6-8e9f-538abc2f787c", "4afb35e7-b7a0-4349-b190-e656c2cdeb06", "518d18af-423b-4e71-9892-9f46600ad8e6", "6615ef10-1218-474c-9ba3-96dcf6358a26", "7a1120eb-5924-4be3-89a7-04fb2d638e6c", "7c2e630e-9fdc-466a-b89b-21861dd54586", "84d6b71c-7e30-41c0-9d8c-fcd5e44b2550", "935d20db-edc9-4994-b8db-9f6a94949358", "9464be88-80de-463e-af0c-83562b7744ff", "9832548c-2102-46c7-a1af-c0f3f96b3676", "aed2d24e-fe61-401b-952f-7bb97915430e", "b5894e8e-1774-45b2-9b34-23d2330878d0", "b9894e2c-f1d9-423d-9334-8df9f9619aff", "c6087348-c3a1-470c-982f-e7c5e6def02d", "cb07a6bc-7acc-4eb5-964f-c8ece4a6ed65", "d3b5fca6-b494-473d-8ff4-2dbc8ca4d154", "dd60ab27-3d87-447e-a95e-f36ac1970ab0", "df6f4bea-409a-4bf4-a3b6-061c763d2c92", "f74ecedd-207a-4e39-8ccc-4a01be328147"], "title": "A randomized dynamic program analysis technique for detecting real deadlocks", "venue": "programming language design and implementation", "year": 2009, "id": "4fc5dfcc-f896-4fbc-b3b8-0a5636213d88"}
{"abstract": "We address the recently recognized  privatization   problem  in software transactional memory (STM) runtimes, and introduce the notion of  partially   visible   reads  (PVRs) to heuristically reduce the overhead of transparent privatization. Specifically, PVRs avoid the need for a \"privatization fence\" in the absence of conflict with concurrent readers. We present several techniques to trade off the cost of enforcing partial visibility with the precision of conflict detection. We also consider certain special-case variants of our approach, e.g., for predominantly read-only workloads. We compare our implementations to prior techniques on a multicore  Niagara1  system using a variety of artificial workloads. Our results suggest that while no one technique performs best in all cases, a dynamic hybrid of PVRs and strict in-order commits is stable and reasonably fast across a wide range of load parameters. At the same time, the remaining overheads are high enough to suggest the need for programming model or architectural support.", "authors": ["Virendra J. Marathe", "Michael F. Spear", "Michael L. Scott"], "n_citation": 71, "references": ["13620a7a-77f0-4044-a611-e76d52e12268", "1ae125df-f966-4582-b55a-f971e3887179", "2a1a717b-356a-44f6-a7cb-749ebcece1ef", "3111b32f-5bb5-4660-9183-a98f25f275dc", "325d0149-0179-40ab-a05f-88cab9a89d79", "4498fa9a-5539-4959-ae95-565282e25389", "53f4f3b5-fe34-41a1-9dc2-7f6a4644aa15", "7d5bb803-38e1-416a-b933-30b3dda8ab3c", "b817817d-6c9d-4925-920b-eb23f2d3deca", "bc0137f1-44f5-47c7-b8d9-048b4b50485b", "eb35749e-7487-47cd-a961-68819b084d89", "fd5aa677-6a9a-48b3-a820-175f9f9b3c7d", "ff36a292-7603-4b90-a7b5-7d8fa9df32f8"], "title": "Scalable Techniques for Transparent Privatization in Software Transactional Memory", "venue": "international conference on parallel processing", "year": 2008, "id": "2ceb5e2d-db91-4eaa-94ba-8e21eff6e9aa"}
{"abstract": "An important property of programming language semantics is that they should be compositional. However, unstructured low-level code contains goto-like commands making it hard to define a semantics that is compositional. In this paper, we follow the ideas of Saabas and Uustalu to structure low-level code. This gives us the possibility to define a compositional denotational semantics based on least fixed points to allow for the use of inductive verification methods. We capture the semantics of communication using finite traces similar to the denotations of CSP. In addition, we examine properties of this semantics and give an example that demonstrates reasoning about communication and jumps. With this semantics, we lay the foundations for a proof calculus that captures both, the semantics of unstructured low-level code and communication.", "authors": ["Nils J\u00e4hnig", "Thomas G\u00f6thel", "Sabine Glesner"], "n_citation": 2, "references": ["0c2ca83d-f789-4412-9b79-cb8429a2bb2d", "23634361-c27f-4cd6-b795-c933e1a41c84", "3f611783-533e-45fd-ba8a-08b94b3a9d66", "49ce657c-8ce3-4890-865b-6a98b3037f50", "9519205f-2384-4196-839d-c8d8b812d3c2", "decf92cc-325f-4021-a9c1-7edb84032c99", "fa5884d1-3716-411a-acfc-767113386469"], "title": "A Denotational Semantics for Communicating Unstructured Code", "venue": "Electronic Proceedings in Theoretical Computer Science", "year": 2015, "id": "8f809bea-7583-47ea-a0d7-7571594b8de5"}
{"abstract": "Code tuning is a well-known technique for improving the run-time performance of software. There are several widely used profilers available that show the heavily used functions. Other profilers provide fine grain profiling detail such as basic block counts. The difficulty in using fine grain profilers is coping with the large volumes of data that they generate.We describe a visualization technique that enables us to display and analyze line count profile data. Our technique is to make a reduced picture of code with the line execution counts identified with the color. We show \"hot spots\" in red, \"warm spots\" in orange, and so on. We are also able to identify nonexecuted code and nonexecutable code such as declarations and static tables.", "authors": ["Stephen G. Eick", "Joseph L. Steffen"], "n_citation": 50, "references": ["1b64964e-7aa5-45b1-998c-c75d7917bfaf", "a3039605-5311-4cdf-b462-efa42ca26116", "b65b1177-f376-421b-9097-16d71017de91", "f91d9054-6c4f-431d-bcc7-83f85c006bec", "fa73fc4f-2a96-48d1-9bef-599c5dffa78c"], "title": "Visualizing code profiling line oriented statistics", "venue": "ieee visualization", "year": 1992, "id": "499f05ed-a463-4e5f-9161-7939e98739b0"}
{"abstract": "A boosting algorithm, based on the probably approximately correct (PAC) learning model is used to construct an ensemble of neural networks that significantly improves performance (compared to a single network) in optical character recognition (OCR) problems. The effect of boosting is reported on four handwritten image databases consisting of 12000 digits from segmented ZIP Codes from the United States Postal Service and the following from the National Institute of Standards and Technology: 220000 digits, 45000 upper case letters, and 45000 lower case letters. We use two performance measures: the raw error rate (no rejects) and the reject rate required to achieve a 1% error rate on the patterns not rejected. Boosting improved performance significantly, and, in some cases, dramatically.", "authors": ["Harris Drucker", "Robert E. Schapire", "Patrice Y. Simard"], "n_citation": 270, "title": "Boosting performance in neural networks", "venue": "International Journal of Pattern Recognition and Artificial Intelligence", "year": 1993, "id": "eca46fc4-e594-461f-83b8-aa5247e440ca"}
{"abstract": "This article outlines the overall strategy and summarizes a few key innovations of the team that won the first Netflix progress prize.", "authors": ["Robert M. Bell", "Yehuda Koren"], "n_citation": 458, "references": ["37c97bee-d5e0-43e1-abf2-c2ade9573199", "8f9d1aa4-7169-47c3-94de-7ca5ce7f7531", "98b23182-8f51-428a-a4af-a91d280471ca", "e2c7ab52-ab10-4d0a-9a91-31a7479a88b8", "ed4c0d5d-5152-4915-b9bd-d0bd25f82674", "ffd46ed3-82a0-4b1f-b85c-b13663d9a34b"], "title": "Lessons from the Netflix prize challenge", "venue": "knowledge discovery and data mining", "year": 2007, "id": "bd62aacb-5037-43d3-926a-af4d38ec3bfc"}
{"abstract": "Over the last two decades FPGAs have become central components for many advanced digital systems, e.g., video signal processing, network routers, data acquisition and military systems. In order to protect the intellectual property and to prevent fraud, e.g., by cloning a design embedded into an FPGA or manipulating its content, many current FPGAs employ a bitstream encryption feature. We develop a successful attack on the bitstream encryption engine integrated in the widespread Virtex-II Pro FPGAs from Xilinx, using side-channel analysis. After measuring the power consumption of a single power-up of the device and a modest amount of off-line computation, we are able to recover all three different keys used by its triple DES module. Our method allows extracting secret keys from any real-world device where the bitstream encryption feature of Virtex-II Pro is enabled. As a consequence, the target product can be cloned and manipulated at the will of the attacker since no side-channel protection was included into the design of the decryption module. Also, more advanced attacks such as reverse engineering or the introduction of hardware Trojans become potential threats. While performing the side-channel attack, we were able to deduce a hypothetical architecture of the hardware encryption engine. To our knowledge, this is the first attack against the bitstream encryption of a commercial FPGA reported in the open literature.", "authors": ["Amir Moradi", "Alessandro Barenghi", "Timo Kasper", "Christof Paar"], "n_citation": 160, "references": ["033ebb72-0119-4cc9-89b8-f011c55ddd79", "288cade3-dc17-4ea0-9d57-c0d3b3adfd92", "374ddc6b-7c61-475b-8438-9783869a6911", "3b7bf1b3-be72-4d78-8245-50db0f34961c", "476c1082-46cb-4cad-8cd1-4a2bbfc586cd", "5ef0558c-74e6-4d74-a55c-5392031ee81d", "674988a0-d753-4725-9fc5-1c144d3c3627", "70d1e6c7-09f2-4d5c-8277-7152fd894999", "a1980ea9-8a6e-4341-a726-a3ef0e141941", "a41c7380-68e1-4158-9e31-b7f2fd022d36", "b0787ca6-7611-44f3-9a70-ffe777e51e9f", "e2645ae7-83a8-4d58-8a79-380098e2506a"], "title": "On the vulnerability of FPGA bitstream encryption against power analysis attacks: extracting keys from xilinx Virtex-II FPGAs", "venue": "computer and communications security", "year": 2011, "id": "6c2387a5-e98a-4ce5-90e5-68fba59ecac9"}
{"abstract": "This paper presents experiments on formal validation of Java applets. It describes a tool that has been developed at the Gemplus Re- search Labs. This tool allows to formally prove Java classes annotated with JML, an annotation language for Java that provides a framework for specifying class invariants and methods behaviours. The foundations and the main features of the tool are presented. The most innovative part of the tool is that it is tailored to be used by Java programmers, without any particular background in formal methods. To reduce the difficulty of using formal techniques, it aims to provide a user-friendly interface which hides to developers most of the formal features and provides a \"Java style view\" of lemmas.", "authors": ["Lilian Burdy", "Antoine Requet", "Jean-Louis Lanet"], "n_citation": 136, "references": ["3ad0693d-69cc-415a-81ae-283d89696a63", "3d400399-dbe9-4fb5-98b4-68d8a0ba7932", "41ebe032-a94b-4b8a-93c7-8cc7865fb2cc", "7f1dc63a-9064-4768-a30d-3383d52aa81e", "80ab79c1-34a0-4a15-b85b-37fdf063a4d4", "8ecfb76e-ed30-436f-890e-2a96b61a97fc", "b336afaf-d16b-49ff-97b9-aa1b044f7fc3", "c3d48eec-b5f0-4959-9a32-432992566ea0", "e6ff4ec6-19d1-426b-8850-20bd45da66ed", "fb531518-ae7a-4d2d-ac04-a848cd588692", "fd3c0d46-0bfd-4635-bf91-21eb295a9fb2"], "title": "Java Applet Correctness: A Developer-Oriented Approach", "venue": "formal methods", "year": 2003, "id": "0deeb479-f124-422b-93f6-0b9057f8d04b"}
{"abstract": "A robust controller which is designed by employing variable-structure control and linear-quadratic method is presented for a permanent-magnet synchronous motor (PMSM) position control system. It is to achieve accurate control performance in the presence of plant parameter variation and load disturbance. In addition, it possesses the design flexibility of the conventional state feedback control. It is applied to the position control of a PMSM. Simulation and experimental results show that the proposed approach gives a better position response and is robust to parameter variations and load disturbance.", "authors": ["Kuo-Kai Shyu", "Chiu-Keng Lai", "Yao-Wen Tsai", "Ding-I Yang"], "n_citation": 49, "references": ["5caaffba-f196-487d-8c9e-7302242fb081", "694342bd-b4af-4b40-917f-a94fbce208bc", "b9b7d12b-6ce4-4cc8-b10a-a30a47b7aba1"], "title": "A newly robust controller design for the position control of permanent-magnet synchronous motor", "venue": "IEEE Transactions on Industrial Electronics", "year": 2002, "id": "f8a71dd4-50e0-4c1f-a780-453e5325223a"}
{"abstract": "We propose a generalization of the notion \"deterministic\" to \"l-r-deterministic\" for descending tree automata (also called root-to-frontier). The corresponding subclass of recognizable tree languages is characterized by a structural property that we name \"homogeneous.\" Given a descending tree automaton recognizing a homogeneous tree language, it can be left-to-right (l-r) determinized and then minimized. The obtained minimal l-r-deterministic tree automaton is characterized algebraically. We exhibit a formal correspondence between the two evaluation modes on trees (ascending and descending) and the two on words (right-to-left and left-to-right). This is possible by embedding trees into the free monoid of pointed trees. We obtain a unified view of the theories of minimization of deterministic ascending and l-r-deterministic descending tree automata.", "authors": ["Maurice Nivant", "Andreas Podelski"], "n_citation": 50, "title": "Minimal Ascending and Descending Tree Automata", "venue": "SIAM Journal on Computing", "year": 1997, "id": "459b7de1-60e6-4a5c-ad89-2c5d07323799"}
{"abstract": "This paper concerns the study, the development and the synthesis of mechanisms for guaranteeing the security of complex systems, i.e. systems composed of several interacting components. A complex system under analysis is described as an open system, i.e. a system in which an unspecified component (a component whose behaviour is not fixed in advance) interacts with the known part of the system. Within this formal approach, we propose techniques that aim at synthesize controller programs able to guarantee that, for all possible behaviours of the unspecified component, the system should work properly, e.g. it should be able to satisfy a certain property. For performing this task, we first need to identify the set of necessary and sufficient conditions that the unspecified component has to satisfy in order to ensure that the whole system is secure. Hence, by exploiting the satisfiability procedures for temporal logic, we automatically synthesize an appropriate controller program that forces the unspecified component to meet these conditions. This will ensure the security of the whole system. In particular, we contribute within the area of the enforcement of security properties by proposing a flexible and automated framework that goes beyond the definition of how a system should behave to work properly. Indeed, while the majority of the related work focuses on the definition of monitoring mechanisms, we also address the synthesis problem. Moreover, we describe a tool for the synthesis of secure systems which is able to generate appropriate controller programs. This tool is also able to translate the synthesized controller programs into the ConSpec language. ConSpec programs can be actually deployed for enforcing security policies on mobile Java applications by using the run-time framework developed in the ambit of the European Project S3MS. Copyright \u00a9 2010 John Wiley & Sons, Ltd.#R##N##R##N#(This work is an expanded and revised version of [1\u20133].)", "authors": ["Fabio Martinelli", "Ilaria Matteucci"], "n_citation": 9, "references": ["130306cc-803c-417c-bd44-7b0ee1b16a52", "24c999a9-0c3b-4338-81f1-36cc4370b27f", "35f2fad0-0a88-4e6e-a5de-caa8dc64e00b", "4b9a003e-c300-459e-82a3-6ca0fa8f08c4", "4d0b0b30-90a0-49fb-9d54-9d878c80801c", "56ab7838-a49b-4f3e-a084-7f8a435d710b", "5a28dd59-c7e4-48db-8bfa-d85c04aadd7d", "5d7ab74c-ba1d-43b5-a025-40fffdfa04a5", "6ffd8ed5-1305-41f4-a669-2936b94a3c21", "724da1f7-6c57-4942-bec8-f98761fc9e14", "7b13b0d2-4a43-434e-85f8-e26f87973039", "86718b68-beb2-4201-8bce-845a80302bd2", "89ef13db-4c93-48c3-87a8-30600e955b49", "8c49fd4e-b4fc-433a-a050-edf8a2abfa62", "9a4984f9-27d4-47eb-8bc8-0469bf540f94", "9aaca070-af6c-4460-a396-03ba81799243", "a9d71333-3241-4460-bc79-84fed06867cc", "af99af8c-a898-486e-934c-82de92f91a9c", "b0de63af-9bc9-4557-af92-3056f8b0ecf5", "b7500424-466c-4429-9c8c-e83a54031230", "bfe9d0d4-492c-4815-ac3b-85567ab41bbb", "c18eb103-3eea-4ee6-946e-95af3ad83a6d", "c7284886-836a-47c5-b343-611d4ea532f6", "ca37d88f-ae2e-44e1-9c78-eaf476749627", "cb32e862-55ac-4180-834b-876506e0f52e", "e4f43f27-9313-43da-a96c-f8548a27354f", "e860743c-f94a-4a04-ac44-7b49929a7a4e", "f63c5365-3994-4f0c-8770-c3b4dd2c9181"], "title": "A framework for automatic generation of security controller", "venue": "Software Testing, Verification & Reliability", "year": 2012, "id": "6a12118b-5b5b-4de8-8569-6ff034b3ea64"}
{"abstract": "Organizations require security systems that are flexible and adaptable in order to combat increasing threats from software vulnerabilities, virus attacks and other malicious code, in addition to internal attacks. Network intrusion detection systems, which are part of the layered defense scheme, must be able to meet these organizational objectives in order to be effective. Although signature based network intrusion detection systems meet several organizational security objectives, heuristic based network intrusion detection systems are able to fully meet the objectives of the organization. Through a comparative theoretical study, this paper analyzes several organizational security objectives in order to determine the network intrusion detection system that effectively meets these objectives. Through conclusive analysis of the study, heuristic based systems are better served to meet the organizational objectives than signature based systems. The analysis was based on which system provided definitive security objectives and offered the flexibility, adaptability, and reduced vulnerability that an organization requires.", "authors": ["Moses Garuba", "Chunmei Liu", "Duane Fraites"], "n_citation": 24, "references": ["a7b7eca3-2d80-4bcf-a48d-1e46f57b88e1", "c94c69b0-8d30-4cf7-86da-5c182b18f924", "f222d31c-dce0-4d19-9e03-3175fa30f898"], "title": "Intrusion Techniques: Comparative Study of Network Intrusion Detection Systems", "venue": "international conference on information technology new generations", "year": 2008, "id": "53d99803-b15c-4459-8bd5-2116fa18f64c"}
{"abstract": "This paper presents a logic framework for the incremental inductive synthesis of Datalog theories. It allows us to cast the problem as a process of abstract diagnosis and debugging of an incorrect theory. This process involves a search in a space, whose algebraic structure (con- ferred by the notion of object identity) makes easy the denition of algo- rithms that meet several properties which are deemed as desirable from the point of view of the theoretical computer science. Such algorithms embody two ideal renement operators, one for generalizing incomplete clauses, and the other one for specializing inconsistent clauses. These algorithms have been implemented in INCR/H, an incremental learning system whose main characteristic consists of the capability of ex- tending autonomously the search to the space of Datalog : clauses, when no correct theories exist in the space of Datalog clauses. Experimental results show that INCR/H is able to cope eectively and eciently with the real-world task of document understanding.", "authors": ["Giovanni Semeraro", "Floriana Esposito", "Donato Malerba", "Nicola Fanizzi", "Stefano Ferilli"], "n_citation": 71, "references": ["08213afd-f109-477a-9dd7-8b81d79d13ca", "281d9e8b-6902-41f1-b2a8-3041af701cb8", "2dad12e2-ec1d-4c04-a9f8-ed7286d006a7", "3af1db81-ea45-4174-a65c-3c086556150a", "3f66153d-7110-423d-8f02-34864da451dc", "4df95d78-48e5-45f2-910b-895358e20b40", "61a01e8d-3212-443e-95d6-913ae1a7cba3", "69692d49-5f0b-4178-b439-12d32824f41f", "9cbc5ce4-78c6-455c-9a04-833088586b4a", "9cf007b8-94c5-4482-8f37-c6549339aa5e", "ba35be38-02bc-4218-af09-c8b38fbd22b7", "c24278c4-5209-47b5-b2b8-11f0684f1d64", "d30043be-1ab4-4730-b9fa-da79deefd52f", "ddd16b4c-926d-4fbe-a90e-322f5a1312cf", "f9bb0c0c-ef66-46b1-9781-be57b8033f59"], "title": "A Logic Framework for the Incremental Inductive Synthesis of Datalog Theories", "venue": "logic-based program synthesis and transformation", "year": 1997, "id": "10014d81-712e-4758-83a6-c50a04513f5e"}
{"abstract": "In this article, we have shown how to design energy-based and passivity-based control laws that exploit the existence of passive walking gaits to achieve walking on different ground slopes, to increase the size of the basin of attraction and robustness properties of stable limit cycles, and to regulate walking speed. Many of the results presented in this are the compass gait are equally applicable to bipeds with knees and a torso. Practical considerations such as actuator saturation, ground reaction forces, and ground friction need to be addressed. The problem of foot rotation introduces an underactuated phase into the walking gait, which greatly challenges the application of energy shaping ideas. For walking in 3D, finding purely passive limit cycles, which is the first step in applying our energy control results, may be difficult. It was shown how ideas of geometric reduction can be used to generate 3D stable gaits given only 2D passive limit cycles.", "authors": ["Mark W. Spong", "Jonathan K. Holm", "Dongjun Lee"], "n_citation": 117, "references": ["281e1afa-a95a-4437-828f-9cb2e490cbcc", "407c79d0-e00a-46a6-95cf-4e1989b5ab11", "5a9474e7-6561-4ad9-81fc-5d8acf242d19", "7d12740e-fe0b-44fd-9dd6-7c7b2e33503e", "8c06c095-7f24-4a74-811d-e2aaad4e3944", "9b3318ac-f8b6-4d64-8d7d-45a79d8a93b0", "c68d14f7-1121-4892-8f80-877c8ebb422f", "d77f1985-a41a-489e-a0a4-0e5fe9548dcc", "e32de27b-fb6c-4cde-b467-8eea7808b4cb"], "title": "Passivity-Based Control of Bipedal Locomotion", "venue": "IEEE Robotics & Automation Magazine", "year": 2007, "id": "2348dbcf-051d-4081-bc7b-97433f987efe"}
{"abstract": "The growth and popularity of online social networks has created a new world of collaboration and communication. More than a billion individuals around the world are connected and networked together to create, collaborate, and contribute their knowledge and wisdom. Despite the importance of online social networks, there is relatively little theory-driven empirical research available to address this new type of communication and interaction phenomena. In this paper, we explored the factors that drive students to use online social networks (e.g., Facebook). Specifically, we conceptualized the use of online social networks as intentional social action and we examined the relative impact of social influence, social presence, and the five key values from the uses and gratification paradigm on We-Intention to use online social networks. An empirical study of Facebook users (n=182) revealed that We-Intention to use online social networks is strongly determined by social presence. Among the five values, social related factors had the most significant impact on the intention to use. Implications for research and practice are discussed.", "authors": ["Christy M. K. Cheung", "Pui-Yee Chiu", "Matthew K. O. Lee"], "n_citation": 1193, "references": ["48d40790-c3e6-4dac-bd4a-167cb3f78b47", "88990235-d5af-43db-b102-bc57e7a8f7e2", "aecc6cb7-ffc1-493d-85a9-3d0a081626b6", "c7050b88-eef5-4eca-be04-0555d4e68e73", "cd02b957-e8e1-4bbe-bba7-94ba113fe15a", "cec06e44-c673-4075-aa0b-92dfee680bf7", "cf0f8130-4dc3-47c3-b5f8-288dd49bdc85", "e2fcb2a3-edaf-46ec-acfb-9e4cee43e1f8", "ee934bfe-63f6-4366-8e03-3f3461b911ff", "ff2270c4-e647-4e8a-9e49-8b3564d71f61"], "title": "Online social networks: Why do students use facebook?", "venue": "Computers in Human Behavior", "year": 2011, "id": "ba52cdbf-79f5-4245-a7f8-81c6d97820ff"}
{"abstract": "The large amounts of software repositories over the Internet are fundamentally changing the traditional paradigms of software maintenance. Efficient categorization of the massive projects for retrieving the relevant software in these repositories is of vital importance for Internet-based maintenance tasks such as solution searching, best practices learning and so on. Many previous works have been conducted on software categorization by mining source code or byte code, which are only verified on relatively small collections of projects with coarse-grained categories or clusters. However, Internet-based software maintenance requires finer-grained, more scalable and language-independent categorization approaches. In this paper, we propose a novel approach to hierarchically categorize software projects based on their online profiles across multiple repositories. We design a SVM-based categorization framework to classify the massive number of software hierarchically. To improve the categorization performance, we aggregate different types of profile attributes from multiple repositories and design a weighted combination strategy which assigns greater weights to more important attributes. Extensive experiments are carried out on more than 18,000 projects across three repositories. The results show that our approach achieves significant improvements by using weighted combination, and the overall precision, recall and F-Measure can reach 71.41%, 65.60% and 68.38% in appropriate settings. Compared to the previous work, our approach presents competitive results with 123 finer-grained and multi-layered categories. In contrast to those using source code or byte code, our approach is more effective for large-scale and language-independent software categorization.", "authors": ["Tao Wang", "Huaimin Wang", "Gang Yin", "Charles X. Ling", "Xiang Li", "Peng Zou"], "n_citation": 18, "references": ["0133fa4c-45d8-4943-9510-e10d79a09115", "0374156b-708a-4296-a8f8-7f6dbd9079e7", "060ca620-ecbd-43fc-a1da-88d8f07373d7", "2cada2e2-9708-4fb8-91a4-6280aa9a3b8b", "2eebfc86-9431-49c8-8364-b10ac91066a7", "3c36910e-5da0-4882-9de5-d770074e16ba", "3ffc1324-128b-4ab9-8252-a9780fc98390", "449fac8e-5c8f-4e86-bee2-4c380948f42e", "47238f62-1a6e-4cae-9ca3-8b6e9eb73ad3", "51872c44-8c91-4d0e-8736-183bfdcf33e4", "64b4cb46-46a5-4231-8dbe-0a95c3235601", "656ac119-7099-4ac3-9615-caedc0a0d5b2", "844f1e0e-82a0-4a9e-ab00-f2965c7eff6c", "9cdcc877-def2-4dd7-8278-2aaeb4286a06", "9e16b034-59a7-41f6-aef4-09dda8062eae", "a081fcf2-4f80-44b7-be3e-07dbe1a1e5a1", "a1853113-dd04-44ae-9e76-a0ddfbf49084", "a90bb910-a129-46c1-845d-b5b432c2127b", "b716345b-2a0f-4d52-ac9b-20b6a1cb1588", "b824a970-49c2-4462-9752-bfbea05e2e3e", "b82c44e8-455a-4683-81bb-169364bb8654", "c197dc6d-2d95-42f7-ac6c-b98936932a7b", "d5d69c6d-15d0-4549-9f53-9e840bf5f001", "e5827e9c-9414-425c-8246-587461c5c230", "e8f78807-bd41-4a7e-8aa8-f46b0947b5d2"], "title": "Mining Software Profile across Multiple Repositories for Hierarchical Categorization", "venue": "international conference on software maintenance", "year": 2013, "id": "fb9a6a24-7ea0-4534-9d1d-8a8de868de24"}
{"abstract": "The well-known Krylov subspace methods for model order reduction of large-scale lumped parameter systems are generalized such that they can be applied directly to a large class of linear infinite-dimensional systems including distributed parameter systems as well as delay systems. The proposed approach allows to derive finite-dimensional approximations of these infinite-dimensional systems without recourse to a large-scale lumped parameter approximation. The resulting finite-dimensional model has the usual property that prescribed moments of its transfer function coincide with the moments of the infinite-dimensional system. As in the finite-dimensional case the approach allows for a numerical efficient implementation. The results of the article are demonstrated by means of a simple example.", "authors": ["Christian Harkort", "Joachim Deutscher"], "n_citation": 6, "references": [], "title": "Krylov Subspace Methods for Linear Infinite-Dimensional Systems", "venue": "IEEE Transactions on Automatic Control", "year": 2011, "id": "af7b10ce-1ea3-45e8-9a61-a2858061bca5"}
{"abstract": "The Ensembl (http://www.ensembl.org/) database project provides a bioinformatics framework to organise biology around the sequences of large genomes. It is a comprehensive source of stable automatic annotation of human, mouse and other genome sequences, available as either an interactive web site or as flat files. Ensembl also integrates manually annotated gene structures from external sources where available. As well as being one of the leading sources of genome annotation, Ensembl is an open source software engineering project to develop a portable system able to handle very large genomes and associated requirements. These range from sequence analysis to data storage and visualisation and installations exist around the world in both companies and at academic sites. With both human and mouse genome sequences available and more vertebrate sequences to follow, many of the recent developments in Ensembl have focusing on developing automatic comparative genome analysis and visualisation.", "authors": ["Michele Clamp", "Dan Andrews", "Daniel J Barker", "Paul Bevan", "Graham Cameron", "Yan Chen", "Louise Clark", "Tara K. Cox", "James Cuff", "Val Curwen", "Thomas A. Down", "Richard Durbin", "Eduardo Eyras", "James Gilbert", "Martin Hammond", "Tim Hubbard", "Aleksander Kasprzyk", "Damian Keefe", "Heikki Lehv\u00e4slaiho", "Vishwanath R. Iyer", "Craig Melsopp", "Emmanuel Mongin", "Roger Pettett", "Simon Potter", "Alistair G. Rust", "Edward E. Schmidt", "S. Searle", "Guy Slater", "Jacqueline Smith", "William Spooner", "Arne Stabenau", "James Stalker", "Elia Stupka", "Abel Ureta-Vidal", "Imre Vastrik", "E. Birney"], "n_citation": 263, "references": ["781db89d-91bf-4c48-9d35-35d44647daf6", "d1493bbd-4951-4f09-8769-dd73c23e3368"], "title": "Ensembl 2002: accommodating comparative genomics", "venue": "Nucleic Acids Research", "year": 2003, "id": "3728701e-e61a-4e95-8125-2ae8a234cb35"}
{"authors": ["David K. Lewis"], "n_citation": 260, "references": ["a1237567-1820-40a4-a0ca-348c16d4cb53", "a9d1ad4d-b477-4231-a6cc-76043301b976"], "title": "Ordering semantics and premise semantics for counterfactuals", "venue": "Journal of Philosophical Logic", "year": 1981, "id": "d60b9d67-60fd-4ae0-8a90-e20c966f3274"}
{"abstract": "Erroneous string manipulations are a major source of software defects in C programs yielding vulnerabilities which are exploited by software viruses. We present  C   S tring  S tatic  V erifyer (CSSV), a tool that statically uncovers  all  string manipulation errors. Being a conservative tool, it reports all such errors at the expense of sometimes generating  false alarms . Fortunately, only a small number of false alarms are reported, thereby proving that statically reducing software vulnerability is achievable. CSSV handles large programs by analyzing each procedure separately. To this end procedure  contracts  are allowed which are verified by the tool.We implemented a CSSV prototype and used it to verify the absence of errors in real code from EADS Airbus. When applied to another commonly used string intensive application, CSSV uncovered real bugs with very few false alarms.", "authors": ["Nurit Dor", "Michael Rodeh", "Mooly Sagiv"], "n_citation": 301, "references": ["099937ce-3cf3-4408-8d0f-6a0a791d4a5c", "1115992d-241b-4c42-afe7-a2598b12f851", "115768ce-b495-45b6-a09f-9399dad79042", "13154e26-af7c-40de-b743-76ebddfa791c", "16de10af-0723-4411-9f12-78af39a010c1", "1819c128-54ff-49a9-b312-0956bce57488", "262fdaa3-06d5-46c0-b157-7a2c8e806cbd", "288f0bfc-1543-4d26-b277-1dacb7c5938a", "2c4956a7-8a69-4f43-9f79-7618b35e5780", "4de0bb84-e07c-4b25-83af-cb92b112fa27", "51ec1efd-db82-4dd1-b104-e4a8ba774d39", "62ea2256-8334-46fa-8ca1-aac92c4f5818", "7536e748-8c88-4550-8927-9c4f6d3c0521", "76a113a8-4191-477b-a23b-34cd2bdcf8bd", "7bb71afa-91b8-46e7-9008-da84e0427b93", "838976cc-558c-4ebe-9489-793fedaa51d9", "8e64727f-e1c8-4774-9ec7-da7f1c6c03a3", "9086a437-bdde-48ba-963b-e9e6991d46f5", "c590588b-1ae4-4ff4-a1b4-04381e2d36c6", "c6626bb5-a96e-42b0-b1d1-7bc3ecb69b31", "cc320b41-f230-4fe9-95ad-fca697550477", "cd662ddd-659f-4075-a415-e45c9a9d94c9", "cf2b5da2-f2e0-4803-b772-e51ac576e7b4", "fd6f7935-8739-4d67-8b9f-3317fcee16cc", "ff14fee1-234a-440c-a724-e27227441581"], "title": "CSSV: towards a realistic tool for statically detecting all buffer overflows in C", "venue": "programming language design and implementation", "year": 2003, "id": "436e9234-5a25-4c27-93cd-545080494b47"}
{"abstract": "Support from top management and others is agreed to be an important factor in information systems success and failure, but little is written about how it has its effect and how it might be managed to a project's advantage. A recently developed conceptual framework is described. It covers the nature and forms of support, the way support affects project outcomes, the bases on which support is provided, and the strategies by which support may be managed. The framework is used to analyse a case study in several stages. At the end of the analysis of each stage, the framework's utility is assessed in terms of its explanatory value and the practical advice it suggests. Areas for further research are identified.", "authors": ["Chris Sauer"], "n_citation": 9, "references": ["5c9460a0-cdd6-4c8d-8c27-29292be0c373", "d63bd07b-956e-497a-91ba-d551fdc5644e"], "title": "UNDERSTANDING SUPPORT - LESSONS FROM A CASE STUDY", "venue": "Australasian Journal of Information Systems", "year": 1993, "id": "19b9fe15-8a9e-4728-b00a-f832d3ec1cf5"}
{"abstract": "A new incremental learning algorithm is described which approximates the maximal margin hyperplane w.r.t. norm p \u2265 2 for a set of linearly separable data. Our algorithm, called ALMAp (Approximate Large Margin algorithm w.r.t. norm p), takes O((p-1)X2/\u03b12 \u03b32) corrections to separate the data with p-norm margin larger than (1 - \u03b1)\u03b3, where \u03b3 is the p-norm margin of the data and X is a bound on the p-norm of the instances. ALMAp avoids quadratic (or higher-order) programming methods. It is very easy to implement and is as fast as on-line algorithms, such as Rosenblatt's perceptron. We report on some experiments comparing ALMAp to two incremental algorithms: Perceptron and Li and Long's ROMMA. Our algorithm seems to perform quite better than both. The accuracy levels achieved by ALMAp are slightly inferior to those obtained by Support vector Machines (SVMs). On the other hand, ALMAp is quite faster and easier to implement than standard SVMs training algorithms.", "authors": ["Claudio Gentile"], "n_citation": 256, "references": ["12fa9885-b0a9-4ea3-a0de-e020c333c3f0", "17f811d8-8607-4270-bbec-1cc7883edd68", "18517405-939f-49c6-ba79-3aa563e8998f", "18cd339d-ab10-440b-9486-e3ef6e2613ea", "1f73723c-b904-4d93-8045-d8de3772fb27", "2190c590-c037-4170-9a93-a9d0c4468077", "24627c32-96e9-4f6d-8193-059b20e2f57e", "363abd1d-63a6-483c-a4fa-2b76b005c522", "3b39396a-6308-403c-a1ee-0d9b3199c6c1", "50dd56db-151d-4d62-8576-65f0ef6f381b", "543ffcba-cac1-422b-b2a1-19963094fb15", "5cd74e0b-f25c-4aaf-8327-7ec949c7d098", "63d4b428-2210-499e-88f1-a9edfbce3370", "6b4b8d67-f962-4922-a3cb-08ddc8d730fc", "6fe13464-786c-4668-8c16-5b0461042e78", "77dc5843-fb8b-4dd6-a230-63b67f1aff18", "8b2c0aff-4589-4e0f-aae4-4f84a4413406", "9340b059-91ef-4c27-8e05-df59a65a610b", "ae3e7593-586f-495f-9416-4b50ed1fcd10", "b25d230c-cf98-48d6-a351-a208f7c9ee07", "cdbd2ef9-d4b1-4dff-9037-3ea84627424d", "e11b9db9-0e10-41d9-80a5-e4f1e90a2801", "e75dbcdc-7eba-4275-b558-3cfd97885563", "ebea33c6-68f6-450d-9d79-65507040d3cf", "ec508672-6090-4ac3-8939-69e27e9cb977", "f00fc370-0854-4967-bc6a-83b6c49da8bf", "f15b056f-a577-4391-9724-a5be885e2bd2"], "title": "A New Approximate Maximal Margin Classification Algorithm", "venue": "neural information processing systems", "year": 2001, "id": "dca75c19-9f9c-4db0-95aa-61e5efefcfda"}
{"abstract": "The performance of Release 4 of TSS/360 at the T. J. Watson Research Center was dramatically improved in the three-month period from November, 1969, through January, 1970. The improvements consist of an increase in system responsiveness by a substantial factor together with an increase in throughput. This was achieved by methodically adjusting the parameters of the TSS/360 Table-Driven Scheduler in accordance with the Principles of Balanced Core Time and Working Set Size.", "authors": ["Walter J. Doherty"], "n_citation": 50, "references": ["26fa0f8f-9052-4231-a3ee-27bce700c2e0", "503e5292-a89d-4602-8580-ed531434de3e"], "title": "Scheduling TSS/360 for responsiveness", "venue": "", "year": 1970, "id": "9e1bcdbb-669a-467a-af45-248ce5093e82"}
{"abstract": "This work addresses the problem of enabling a single human operator to individually inspect targets for a fixed amount of time in a reconnaissance mission. The task of the operator is to classify the targets as friends or foes in real time, as they appear in video feeds from multiple UAVs. In order to account for cognitive limitations, the human is modeled as a single processing unit that can only execute one task at a time. A task is defined as a target inside the field of view of a given UAV, that needs to be inspected. Under the assumptions of this model, a linear program (LP) formulation is used to optimally find each task's arrival time and latency in the system such that the human operator can inspect each target individually for some time \u0394t. Previous work by the authors investigated the idea of using UAV velocity modifications to meet the timing schedule specified by the LP solution. In this paper, the idea of UAV trajectory changes is introduced by modeling the UAVs as Dubins vehicles. Modifications to the bounds on the LP constraints are derived based on Dubins trajectories. The new bounds ensure that the LP solution returns a timing schedule achievable via maneuvers that combine velocity and trajectory changes to the UAVs' flight plans. An on-line algorithm is developed that constructs and commands these velocity and trajectory changes in real time when conflicts arise. Correctness properties of this algorithm are analyzed and discussed for mission scenarios where the location of the targets is unknown and targets are discovered by the UAVs in real time.", "authors": ["Andres E. Ortiz", "Derek Kingston", "Cedric Langbort"], "n_citation": 50, "references": ["9336601f-39fb-429f-b6bf-1c20ac858c14", "afcbfb19-7b9c-461d-a02c-7d2ee31a02cc", "ec70c332-ec64-4d07-bc89-488594f8166b", "eca38a08-71bc-4d65-a9ac-49362a3511ec", "ffc91d2e-ea0b-482f-a596-ba6c9069cebe"], "title": "Multi-UAV Velocity and Trajectory Scheduling Strategies for Target Classification by a Single Human Operator", "venue": "Journal of Intelligent and Robotic Systems", "year": 2013, "id": "acc2aadc-215c-4ae7-9137-d56af7014445"}
{"authors": ["Magid Igbaria", "Laku Chidambaram"], "n_citation": 11, "references": ["20c20d82-d1b3-4a5d-b961-d7af19936821", "4cd67c9b-3008-4ab6-9f17-0e08855c954f", "8d136b91-99b0-4e33-92a4-151a821f379a"], "title": "Examination of gender effects on intention to stay among information systems employees", "venue": "", "year": 1995, "id": "24f15916-b80c-4ac3-af61-6aa04e543d8d"}
{"abstract": "Higher education is a sector entering an era of IT-enabled modernization in which it may have to cope with an influx of unfamiliar corporate concepts and practices. This paper analyzes one of the first Enterprise Resource Planning implementation projects within the academic administration of an Ivy League university. We contribute to existing qualitative literature in information systems by developing the theme of temporality within actor\u2013network theory to support our analysis. This enables us to extend process-oriented ERP research by focusing on the identification of temporal zones and creation of durable work times designed to re-order priorities between competing visions for the future of higher education. We analyze detailed negotiations during periods of controversy to reveal how standard work practices come to be created and recreated. We consider how the ERP that emerges is affected by progressive trials of strength during the project and analyze the achievement of order as an on-going process. Our findings highlight the distinctive contribution that a \u2018temporal turn\u2019 can bring to longitudinal research studies by providing insight into the technical agency of ERP packages and how its temporal inscriptions shaped the emergence of a socio-technical information system. This reordered organizational work life and created a hybrid temporality that still needs to be negotiated into the working rhythms of the University\u2019s actors.", "authors": ["Susan V. Scott", "Erica L. Wagner"], "n_citation": 60, "references": ["01e2b3fa-7b6c-4c86-8126-53960ddd7502", "1b821353-9adb-4a67-b44b-efb9c519aca8", "6d3d6ddb-c02b-4339-a108-1e2e880bca3b", "9ee326d4-3c1f-43a6-9f3b-9641a7c7b521", "a2400db6-c06f-41d3-bf1f-a0af8c514516", "afd63c47-1b9b-4ca0-8693-e8f3efd61b64", "c14f7b4c-2df5-4ee9-b095-f738174dcda3", "c2ebe301-f877-44be-8c5c-bc175d21f3ed", "e6e833e4-352d-48fc-a495-1f86e75008db", "fa5f8274-1f79-4690-9b81-5c3923687cd4"], "title": "Networks, negotiations, and new times: the implementation of enterprise resource planning into an academic administration", "venue": "Information and Organization", "year": 2003, "id": "5cb29967-1680-4482-83e6-420a022d2d47"}
{"abstract": "Aliasing occurs in Web transactions when requests containing different URLs elicit replies containing identical data payloads. Conventional caches associate stored data with URLs and can therefore suffer redundant payload transfers due to aliasing and other causes. Existing research literature, however, says little about the prevalence of aliasing in user-initiated transactions, or about redundant payload transfers in conventional Web cache hierarchies.This paper quantifies the extent of aliasing and the performance impact of URL-indexed cache management using a large client trace from WebTV Networks. Fewer than 5% of reply payloads are aliased (referenced via multiple URLs) but over 54% of successful transactions involve aliased payloads. Aliased payloads account for under 3.1% of the trace's \"working set size\" (sum of payload sizes) but over 36% of bytes transferred. For the WebTV workload, roughly 10% of payload transfers to browser caches and 23% of payload transfers to a shared proxy are redundant, assuming infinite-capacity conventional caches. Our analysis of a large proxy trace from Compaq Corporation yields similar results.URL-indexed caching does not entirely explain the large number of redundant proxy-to-browser payload transfers previously reported in the WebTV system. We consider other possible causes of redundant transfers (e.g., reply metadata and browser cache management policies) and discuss a simple hop-by-hop protocol extension that completely eliminates all redundant transfers, regardless of cause.", "authors": ["Terence Kelly", "Jeffrey C. Mogul"], "n_citation": 75, "references": ["259ff48c-d0b9-4fd4-8275-8169c6152224", "36f0f3cb-6b32-4284-8e08-0972ee67074f", "3a16db1e-368b-49dd-937b-f14575a164c4", "3adf03d7-1fde-4893-a70e-39fa62066c0f", "41cabf8c-c1a8-494b-bcd5-27db8a659f9a", "4efb9d27-5652-4d40-b40f-3fe0f33070f3", "537d266a-952c-4d06-840b-8abd29ee0de5", "694993a7-da6d-4b37-8742-1341a25f8974", "6b64058c-5de2-4050-86a9-32518b3e8259", "80230489-ae23-4e11-96d5-c7e6196f719d", "8504c16f-faca-4ee7-bde5-7bc961e4a314", "a792462b-c9bb-438e-a68c-2dd27feeb790", "b5314950-0f11-43e7-be75-0e132b6a6c7f", "ba7b9b81-a05e-4648-9ca2-efcd40344672", "be23df9d-eee9-4db4-8e88-55c3b9dd0481", "c940e462-1199-4bab-89d4-df0bab6ba45d", "ca498e1b-5b65-489e-b21b-79e1df5b310e", "d26d2739-f50b-4b9b-9620-1f4ffd316114", "e6c5c8ec-8887-47f8-82b2-f426c2db9cd2", "ea2cf8b6-a198-462c-893a-c2ed555718c6"], "title": "Aliasing on the world wide web: prevalence and performance implications", "venue": "international world wide web conferences", "year": 2002, "id": "366369d1-9952-4e43-a67d-38a878443dbc"}
{"abstract": "We present a validation model for the dynamic source routing (DSR) protocol. This model includes a formal specification of the protocol and a set of scenarios. The scenarios test the conformance of a given implementation to some targeted system functionalities. The DSR protocol has been specified following the IETF draft [D.B. Johnson, et al., (2003)]. The formal specification has been performed using the SDL language and the scenarios have been generated from the specification using a method and a tool developed at INT [A. Cavalli, et al., (1999)]. The test generation method is based on a set of test purposes that express specific system properties and is completely automated. We also present the experimentation results of the application of our tool to the DSR protocol.", "authors": ["Ana R. Cavalli", "Cyril Grepet", "Stephane Maag", "Vincent Tortajada"], "n_citation": 24, "references": ["0b69b579-6ca1-4ae0-a9b1-0d6d1e366827", "58a8043f-0111-47ba-8784-ef6117e0f81e", "7c9f8cd8-d0ef-4954-b4db-4a6c803459c2", "a6bf7165-9c93-4f12-8b4d-3ef4f7bf85aa"], "title": "A validation model for the DSR protocol", "venue": "international conference on distributed computing systems", "year": 2004, "id": "762a90e9-bb67-4d13-b7c8-b041e0adfe87"}
{"abstract": "In this paper, we propose a novel approach for robust skin segmentation and face similarity measurement. The proposed skin segmentation is a method for integrating the chrominance components of any color model. The goal of the skin detection method is to select the appropriate color model for verifying the skin pixels under different lighting conditions and various types of skin color. An enhanced Hausdorff distance, called the robust automatic minimum Hausdorff distance (RAMHD), is used to measure the similarity between the face edge and an elliptical model in the skin area. This method is very robust to occlusions of the face edge. Finally, the results of face similarity measurements are improved by updating the elliptical model. We show the performance of skin segmentation and face similarity measurements with real images.", "authors": ["Sanun Srisuk", "Werasak Kurutach"], "n_citation": 87, "references": ["3872a36a-9a82-4b71-9f90-b532bdc4f89e", "39991024-ff88-46ad-a6aa-0ef737d7a55b", "45387579-6cdf-4e12-9baf-88563886dc7a", "4f5f023e-bc99-41c9-8614-290ca3b88c83", "55fa440a-2b98-4e8e-bb45-fa09598b4eca", "5ffac6f9-2456-42cf-830c-9049ce37c899", "66143cd6-c4ce-4c85-ae52-4ffa0c1cd8bc", "88c1bb03-ae47-48f6-a8f7-2d0d11e7fa0c", "a65986d5-174f-480f-b68d-593bd0a7b43c", "b88e82ed-5123-4d1c-86a1-2e7c6f8aff90", "bec76d54-02fb-4e7e-8a9c-c058f780194d", "c13da71d-2869-400b-bb02-8961c399fcc1", "d5e5a24d-f80e-4f1a-b48b-22403b653276", "d6e37fb1-5f7e-448e-847b-7d1f1271c574", "d9752a5a-1603-45cc-9a21-7997750d429f", "f855673e-279b-4aa7-8c40-25cd48b8ebdd", "fd5aeb78-196f-4770-92cf-5e1696ade176"], "title": "A new robust face detection in color images", "venue": "ieee international conference on automatic face and gesture recognition", "year": 2002, "id": "460a1449-243d-42cc-b3b6-7f9e15aeba28"}
{"abstract": "Unification is a basic concept in several traditional symbolic formalisms that should be well suited for a connectionist implementation due to the intuitive nature of the notions it formalizes. It is shown that by approaching unification from a graph matching and constraint satisfaction perspective a natural and efficient realization in a structured connectionist network can be found.", "authors": ["Andreas Stolcke"], "n_citation": 26, "references": ["257082ce-f351-4401-8ccb-7ba6f4650cb6", "3c821bbb-c501-428d-b62e-cc45ea740333", "707098ea-dc14-494d-a10f-ae329750cc6f", "c2fcbf87-4baf-4f15-aabb-cd857898382e", "d6ede40e-7ad9-477e-bb3a-2c0bbae93131"], "title": "Unification as constraint satisfaction in structured connectionist networks", "venue": "Neural Computation", "year": 1989, "id": "e08452dc-33c7-4aff-b48a-cc0990b7c880"}
{"authors": ["Amy P. Felty"], "n_citation": 50, "references": ["0bae3849-767e-416c-b90f-e54f989df8c4", "20928433-60ff-4ee3-aef9-1c9ded04a38a", "292a67ec-8f14-4f62-bbf4-1f7316c2ea05", "37cb495b-44dd-49d2-90f7-257628e0e8ac", "3eeb409d-6600-4a86-b272-4f36626876e2", "3fca2601-6e10-463d-9741-87d3c18718e6", "4624f586-1364-4a90-a342-16aeb6287fc7", "591988c7-c80f-40b9-b267-51ecd4f1a92e", "6c5aa4ae-a495-485e-886c-8e93ca17ce02", "94b4608b-8487-43df-bec1-ffd4a52d9624", "b1d1d8af-9345-4257-9079-13ecded0cdab", "be9bd168-a5a8-4c1a-948f-a55eb578acbc", "d8c958a5-e203-4c92-87b5-505b2715c5e5"], "title": "A Logic Programming Approach to Implementing Higher-Order Term Rewriting", "venue": "", "year": 1991, "id": "da99cc01-ca50-4148-b519-4e5beec96692"}
{"abstract": "Combinatorial optimization problems are ubiquitous in numerous practical applications. Yet most of them are challenging, both from computational complexity and programming standpoints. Local search is one of the main approaches to address these problems. However, it often requires sophisticated incremental algorithms and data structures, and considerable experimentation. This paper proposes a constraint-based, object-oriented, architecture to reduce the development time of local search algorithms significantly. The architecture consists of declarative and search components. The declarative component includes  invariants , which maintain complex expressions incrementally, and  differentiable objects , which maintain properties that can be queried to evaluate the effect of local moves. Differentiable objects are high-level modeling concepts, such as constraints and functions, that capture combinatorial substructures arising in many applications. The search component supports various abstractions to specify heuristics and meta-heuristics. We illustrate the architecture with the language  Comet  and several applications, such as car sequencing and the progressive party problem. The applications indicate that the architecture allows for very high-level modeling of local search algorithms, while preserving excellent performance.", "authors": ["Laurent Michel", "Pascal Van Hentenryck"], "n_citation": 94, "references": ["0d0232f7-a334-41e5-9e29-cd312b333b17", "1a3e04a8-38e8-4df9-9e2f-caf25d2922c0", "2fb3bd66-88e0-4769-b0ae-3fbdc59cbbef", "38d3c30c-c691-4e1f-99e8-7058ff86907d", "48ffd7f0-4a94-461d-8ca7-6040426a6a16", "59dea681-33b0-421e-a8e3-16aa07a948a4", "5c634eb8-843d-4f7c-9c8b-b1812ad32e2b", "963a4775-0169-4433-8d8c-f7e8babea788", "9e2afd42-05ac-4fae-8fcf-a72499cc4028", "aa819fd8-0779-4cb2-84c2-7ceddffd9dd1", "c3cfcd80-9919-466a-a602-9612c24cc23a", "d1463051-8db5-4cf5-ae51-0975960180ab", "d84fe9e1-732c-4408-84ac-3e07d5f90790", "e47a7c32-555d-4050-9013-516f8de1ca8b", "e8df1a74-0e2f-475a-ad50-33d398d89150"], "title": "A constraint-based architecture for local search", "venue": "conference on object-oriented programming systems, languages, and applications", "year": 2002, "id": "c50dba60-60cc-4865-a83d-2c5bbf90797c"}
{"authors": ["Amarnath Gupta", "Terry E. Weymouth", "Ramesh Jain"], "n_citation": 178, "references": ["23a28597-5676-4f25-8e14-b5ba8248f4fc", "708eed6a-6744-44c8-9329-582afbf57ec7", "93a8a123-f5b7-4bc6-8e84-1a714bc5836f", "a3c1ae36-c8e6-4478-abe4-152e55ba165a", "add11656-b2e2-4070-859a-3bbb7afa0a03", "b93f1493-e332-485b-9d75-f302872c22fe", "c157db84-adc4-44a4-aff4-cdb5d3255dda", "d84c4ddc-5e55-42e1-bc38-fb11d73cb4b3", "e7d875ac-e3bf-4100-92a9-21642569614d", "eb430105-9adc-4cbd-977b-c166465f976d", "ed155ba7-b3c8-422f-9986-8c8188cccb7a", "f52a60a7-07eb-4053-b967-32f1d2b74fc1"], "title": "Semantic Queries with Pictures: The VIMSYS Model", "venue": "very large data bases", "year": 1991, "id": "aa10a17d-c080-4e82-9fa1-42dbafce7567"}
{"abstract": "A bibliography of 370 references of books, papers in serial journals, and conference papers, on convexity in relation to computer science is presented. The subject is divided into five topics: (1) convexity and straightness in digital images; (2) convex hull algorithms and their complexity; (3) other computational problems related to convexity; (4) miscellaneous applications; and (5) general mathematical sources. These references range in time from 1961 to September 1988. >", "authors": ["Christian Ronse"], "n_citation": 56, "references": ["00b7cfe0-4ff4-47a4-80c4-afcd478893d8", "01da6032-cd22-4069-8f36-4d07a52b1fa7", "06048a17-94fa-4f02-9797-6540cec0e26d", "06bd3803-02f0-426b-8f43-5d0013b60a60", "09fda625-fe38-4191-8476-2cf5c7362fdb", "0c2f8ab8-d01f-4542-b73b-c96d63fddb1b", "0efe49d1-9a4d-4139-ab4c-34643196c2b2", "10b31b66-ddf9-4a40-b83f-58d79501edda", "124d8763-7644-4ac3-afdf-bb2a747e81a7", "13052c42-7be1-4ee1-be3a-b43c0786c8a9", "13680b4b-e4d4-4ad8-aa11-7a695ac24029", "13f16594-607a-4b3e-85c3-7377588e9622", "149c7c0b-f272-4c96-871c-a4d1d6026dd1", "168c9897-18bb-4685-8441-930e934673b4", "1a0a46d6-b282-4835-9a55-0f4db6725220", "1a8b3707-868e-468e-a87c-838d4c54853a", "1afa4c49-e1e6-4d77-8257-20ea3cb1ae22", "1b3c60fa-8490-45e2-aa76-a15f5fa48abe", "1ba1b82a-698b-4cdb-985f-3bf57296db57", "1bdc793c-32e5-4ed6-a825-6c4590c6b783", "1c0e512f-bd7c-47d2-b18c-28efd1041c8a", "1c0e9fa9-4edb-4b25-b252-d23a9c307ea8", "1c3238f4-99cb-48b5-ac1c-e3e029acbe37", "1ea4f4ed-857e-41f2-9da6-22c641eb9edb", "1f2c3980-c76e-4b77-b3b8-d8724eeff852", "20c631c1-9b8a-449b-b8b0-bc644cdb0142", "20e3beba-a471-4149-a1b0-8f832d9561bb", "211ba9c1-57cc-4e8e-a891-a2015fe3a2dc", "2273ced0-f8a0-4f33-9c76-4faf2c9ac20b", "22bb92ac-532d-422e-b243-a713141f7661", "22ee442d-843a-48a3-8f52-53bf80464481", "230cb5e3-1210-4277-8452-da48c312f634", "23dd120b-3160-4b0d-a9de-c6defb4d6c2b", "243d73da-ee19-4f0b-b9b6-d5836c41a413", "251096c5-96a9-46b5-982e-210c0fe5374d", "253a9aab-8a35-4576-8abc-f58b7c520eb5", "26903456-c594-4e20-9762-ac2eee0a538c", "2724888a-946c-4d44-a7d1-3877a8b216de", "2afff740-a8d0-4114-aab2-0cc2e830932f", "2be6ae14-b4f8-42ad-82fd-fe84fd05bf3b", "2dac33c5-288d-4bb9-a71d-9cef8fc0919a", "2e625482-f10a-46e1-bafd-fcafb7ca71a5", "2e8fcaeb-4bc5-4160-a6df-72d76255f9f6", "2ef44418-b566-4d14-a70f-538b69c47a7e", "2f910104-7c04-4d90-8ed5-22fa8653041f", "35ac0119-59c4-4695-bd80-682b6b9c17a8", "36a577e5-98f6-4cad-bbfe-2c41d98f8151", "38be3f02-3b4b-433a-947d-fd1c609fa411", "39202f3c-0c19-46b4-ae39-a7e23619ec71", "39e6f07f-c046-42be-ad01-00055304c0b9", "3ad48fab-bd98-48c3-85f3-ca9df6bf6661", "3da9b087-a81b-4b55-8258-1f76aac7b739", "3dd9a336-1c98-46e8-b992-1cd7e6790743", "3e7dc60a-f732-4915-b09b-29708a5b593b", "3f1323cb-140d-40d6-8635-92d5b9107de9", "40d44f3a-61ea-4364-bbf6-9c97f3475de8", "41600a4f-9c72-4214-9315-0eeab8c40430", "416b8d5f-8859-43b1-9215-78a1ec0c48dc", "417639ad-e756-4b20-8c91-caab08be1606", "431ae6aa-79b0-45c0-8c90-f414529d39ef", "459d5366-2667-4796-925f-eb99eba6a979", "479bd459-b90f-4c77-baa2-ba06f998b809", "4a50301e-9f80-45db-a679-f37c75eb5ef9", "4b23e80f-e2dd-4945-a799-8b2f11388501", "4b5f9ea3-8c39-4e34-b107-f2007211b0d9", "4c8892c5-eb38-475f-aa99-4038af035906", "4d40bbf1-8601-4581-bd77-277c7da79b6e", "4db33a1d-6081-466a-a4dc-65872235584a", "4ec69f5d-74fe-4868-9936-d684c2fc96df", "4f441b8f-ab67-4e5e-9f77-fc71c0dfd378", "510eec1d-f82c-4b19-b116-b8fd4c66531a", "517dd3f4-11d6-4f09-a898-6891820f66dc", "53913b61-0377-475c-9034-4faa444c47e9", "53c19359-dcd6-4cf3-bb6e-b14fa91f09f7", "5581c810-1b67-4d28-be77-d82af988d09b", "5705a46a-ec19-41f2-a8ec-1c6cb4c8e353", "57713c13-d125-4e9b-92e8-1bee43925005", "58835104-1d0b-4c3d-8c2a-38bb354d09c9", "593a7087-a716-40ee-af9f-caa3d41a1b6e", "5ca6988f-8bec-4bb7-a320-a68604ba653c", "5eba9f30-7cc1-423a-b509-8782de4a9cd1", "5f4834b6-973f-4ef8-aefc-8c8289cbfabd", "60e80bd9-014d-44ce-a79a-a649e36ce06c", "624b7084-f890-4968-beb6-92ebed0d448e", "63d3290a-3ad6-42e7-a642-427a3e851053", "66b1fe28-4f57-4309-9947-77ef49ad564d", "66e4d5d7-4c87-44f0-9983-707e23359e9e", "68132fe0-cadb-440e-9c57-a0248c94b164", "6834a46b-0db7-4efb-8fca-99aeef4f3841", "6867a27b-4b3c-4bfc-8dd1-286630cb69cd", "699a11b8-782b-4eb3-bd49-940d790ace41", "6c459c3d-ed52-4d04-9e37-5e31918b7aa4", "6c787587-303f-46e2-bc3b-032cfd31ec36", "6dadc188-85b1-4565-9907-2be6e100827f", "6debbdc5-2862-4fe1-8b07-61e5efdd2b3f", "6ec89f77-f189-40c0-9b7c-87152f9d4e09", "6fc3a569-f944-4870-ba1e-8f1c41c0fb73", "7801b468-bfac-4d39-83ea-468a0c5c2096", "78168ee7-f582-44f8-ba95-569b18be3d49", "7931b644-6f3c-4002-8dce-c52edac74f05", "7998bf6e-40e2-4d8a-bfb5-954fa7e64eb6", "7afe8dfd-d474-40d9-9132-8dc19c082354", "7e151bc3-7e69-41bc-85dc-186c5b84eefb", "7e74ee40-25ad-461b-95e7-14ed7e1e9755", "7eed0097-fa72-4dd6-b566-3a92ee9fce18", "806dc538-82d2-439c-8d38-8eea13032b8a", "81665c3e-232b-4422-8dd3-7b6b81cefed7", "8303c3ee-4842-4fce-9593-d827ec9635ea", "86806e85-64ec-4346-8d19-9929035657ba", "8a857c5c-5b00-4882-a6ae-aa793853f5fe", "8b2ac1c3-a581-4e2d-80de-f80e6b16d67f", "8c310420-33d3-4933-ba28-80e0a2c53a70", "8dbe7a0a-2dc5-47f6-b543-4b5b1f03d527", "90c1729f-6d7f-419c-8a96-f6741e3a9cff", "91d0c7b6-7cfe-4835-9432-cfcdf2bf420f", "949fd566-92f6-4ed6-ab15-5102c95617d1", "983a7530-9f92-40f5-ad44-b21a4cee5243", "9954de7c-a116-4310-be81-d111796281bd", "995af965-38ea-42fc-acae-e02781804d4a", "99b4bb40-adc1-47d2-bd32-4efbde944e00", "9bf17465-1650-4428-8560-189c80144621", "9c4f5fe8-aea0-4191-8240-9615fc6a41d5", "9e4507bd-8925-4462-b626-04f9a334f391", "9e727d02-9930-4bb5-b4c2-b0a153f19f3f", "9ed9dbb4-a740-4635-96e1-e778f80697fb", "9f0ac5d0-0c1e-4057-a55b-7fdbc84fe91e", "9f445cfd-9a8e-4f04-809e-aa1b4a236d78", "a06bdc09-5f13-4a78-a0b0-9531e9ea20bf", "a0d6a12d-556c-4701-982c-9130f911db37", "a0fe9125-d7c8-427e-81e5-e749efb02cb0", "a2305851-21a4-43d2-aacd-b5537ff2d812", "a2d62f95-b2ca-48e4-9056-a61c95c655f5", "a4bdfc5b-6b02-41a0-bad9-8404e9829959", "a9fdd475-1b76-4f29-8334-e19f9e1f1884", "aa6f3fc7-6a7b-4fa5-8932-5b0e4614cc51", "ab356e19-a1c0-43f8-802c-8c563dc1d474", "ab4e5f70-7eb5-4bcc-950c-a15dd21b1dc2", "ab5e0260-0eaf-4ca2-9721-53b7ebd99cd5", "aca01528-c578-4394-a126-4c60bfeca376", "afc1b3b4-de42-4ba4-be3f-1905459dc5a5", "b08ef5fb-1833-43aa-993d-5e2d990b0c0a", "b1da07d1-4c00-4ca1-a547-0b19b2c0ceb5", "b377f538-523d-44e3-b52e-a301cffae62d", "b4522a34-acde-4869-8154-d8a6875b1e10", "b5ad5b0c-45a0-4714-a68e-f4ddf5f5e726", "b5b46253-c1b0-42fe-9880-b2eb59e6c47f", "b7937762-13d1-46f5-b000-2f99cea7cd1d", "ba1bd053-b2fe-4d08-942d-d26cfd460b93", "bb06f880-55b6-49dc-ad69-98bfcd92116a", "bc204502-18e5-49d9-ae4e-ce9576135c13", "bda45c60-bb84-42d0-b227-da383ddd68bb", "bdebc285-b811-4e96-b3d3-21658cbe378e", "bebd76af-370b-4c14-bfe5-c99df8d1cd64", "bf2e42b6-e444-4ae1-909c-8d0957bb08db", "c3abfe15-6f9f-4979-b7cf-81356030de75", "c5076f72-5ec6-454b-b035-198ed57cf2bc", "c7b3c72d-2bff-43b0-a273-06be751fe81c", "c930c020-eb27-466c-bd52-3fe8718c7b54", "cb0679bd-99b2-4912-b9a5-18c7fbe1ca63", "cb441602-7d3b-46fb-a29b-741c0b2d86f0", "cd71d07a-3f2d-4916-aa15-a97a821c855b", "cebd2cf9-66e0-4650-a729-e431efb47c2a", "d1f93e56-fe2e-44f8-ae2c-14d389231a40", "d2da5cc2-6f7e-4979-94af-715d0eb5b756", "d3695223-7db8-4aea-a2ec-faf51b009ad0", "d552915b-ef9c-40d6-aa6a-21b61c4e9ef6", "d7beda31-08b9-4df1-a67f-652e4ac6f03a", "d800e7f0-9859-4280-abb2-c1366b66c055", "da0de502-0403-4d27-9bfa-2c80e7e15eb4", "dbf429fb-7770-4f0a-bd94-518141365f85", "dbf7b44d-39ad-4a60-8fef-260880717cef", "df5c7d52-012c-4056-98c9-f3faad431d66", "dfc4d78f-6482-4aa4-a876-30778b7c8037", "dfd8f3c4-fab3-4b7c-90a9-1978f11be189", "e12074ca-a27e-434c-86cd-d77ee645caf7", "e2606500-36b6-4df6-b1a9-e60d662d6091", "e4447755-77f6-4529-a4c0-93d44cb74b2f", "e4fa9a99-a23b-457b-b40d-255a20c25438", "e53b167f-27d0-46f6-921a-2101231821c6", "e6a09007-6b9b-4c7b-9f95-ba5496e04a3b", "e6c8f401-0fe9-4510-98bd-06622b17675a", "e9e4f92b-71db-4b20-9b48-0760d5e2f7ef", "ea47fe08-8e87-4082-ada2-003e825e7444", "eac96e41-b0e5-45b3-8f67-34e221c3bbf5", "ebb77214-9092-4681-bedd-81592d665160", "ecb95f27-c09a-4739-8227-e8c87843e580", "ecc94fbf-ad7c-4c17-b649-ea6eddac22c3", "ecf4e68f-284e-42b2-bbdf-6ed83150d3c5", "eec49db8-a7b4-4f11-b95a-f0c20e5d1f2c", "f37ceddf-6cab-485a-af05-920838317551", "f4552c6f-bb1c-4d14-9e8c-b4a5eca032ae", "f74dbfe4-c07a-4146-bec7-601db759aa1b", "fa6febd2-897d-4324-905a-6e31c012c47e", "fcc71c3d-465f-45a6-b007-45380eb72c94", "fe753553-161c-43bc-89fd-aeaf4ac8e567", "fe9456e6-b718-4b74-828a-793158e1798b", "ff84537e-6241-4101-81e8-7c4062d093f3"], "title": "A bibliography on digital and computational convexity (1961-1988)", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 1989, "id": "fb009e65-addd-4f35-9f45-2420211a6236"}
{"abstract": "This paper applies Chance Discovery to the analysis of ac- cident or incident reports to find hidden factors associated with these accidents or incidents. Recently, it has been recognized that medical risk management is very important both for hospitals and hospital patients. Consequently, risk-management experts check accident or incident re- ports. In addition, data mining methods have been applied to these re- ports. However, they can only find generalized reasons for frequently occurring accidents or incidents. Finding reasons for rare accidents or incidents is more important because they tend to be missed by experts. We have, therefore, developed an analysis method for such cases by using the concept of Chance Discovery.", "authors": ["Akinori Abe", "Kiyoshi Kogure", "Norihiro Hagita"], "n_citation": 8, "references": [], "title": "Nursing Risk Prediction as Chance Discovery", "venue": "", "year": 2004, "id": "9286a859-6d50-4795-8495-d13a460b01f7"}
{"authors": ["G\u00e9za K\u00f3s", "Ralph Robert Martin", "Tam\u00e1s V\u00e1rady"], "n_citation": 89, "references": ["0aba23e8-eb3a-4423-b3fb-c29e6f20fbfd", "0badf7be-7f89-40c4-b53a-8c4fc90f4247", "29be2e6b-44d1-471c-b794-a0d03bc4b524", "5148c68c-5af5-437a-bf8e-ba827ce010a2", "911fa894-b276-4c6b-82ac-328f3c7db9b8", "b87cce6a-7915-4dcd-b387-d13bf9fd626d", "d65b7704-8e46-41ed-9cac-2aec458ce837", "d970fa22-4ef3-48f8-97f6-ede84caf24dd", "dbcdafef-ebca-4a4e-894a-f5d6ec2e1b07"], "title": "Methods to recover constant radius rolling ball blends in reverse engineering", "venue": "Computer Aided Geometric Design", "year": 2000, "id": "2922ed4d-f075-4862-899b-9faf3e0a4d0e"}
{"abstract": "Abstract   Much has been written and high expectations have been placed over the last decade on enterprise modeling and integration. Applicable results are more modest. This paper first recalls challenges and rationale for enterprise modeling and integration. It then points out substantial results achieved so far as well as potential difficulties and pitfalls to make them a reality.", "authors": ["Fran\u00e7ois B. Vernadat"], "n_citation": 44, "references": ["598262fa-aa3d-4b51-a653-d1d46ea9a992"], "title": "Enterprise modeling and integration (EMI): Current status and research perspectives", "venue": "Annual Reviews in Control", "year": 2002, "id": "658342b8-7588-427b-95f4-cfd2cb83e1cb"}
{"abstract": "A new low voltage charge pump is developed to help start up a step-up converter in energy harvesting applications. The proposed charge pump is the first to utilize both backward control scheme and two branches of charge transfer switches (CTSs) to direct charge flow. The backward control scheme uses the internal boosted voltage to dynamically control the CTSs' gate, and the two branches utilize both NMOS and PMOS to implement their switching structure. The combination of backward control scheme and two-branch operation allows the CTSs to be completely turned on and off. Thus, the reverse charge sharing phenomenon and switching loss are significantly reduced, which effectively improves pumping efficiency. The last stage is specially designed to improve the charge pump's charge and capacitance drivability. Using subthreshold operation and body-bias technique, the charge pump and its clock generator can operate under a low voltage supply. The proposed charge pump circuit is designed in a standard 0.18   $\\mu$   m CMOS process. It consists of 6 stages, each with a 24 pF pumping capacitor (total 288 pF pumping capacitance area). Under a 320 mV supply, the measured output voltage of the proposed charge pump can rise from 0 to 2.04 V within 0.1 milliseconds.", "authors": ["Huan Peng", "Nghia Tang", "Youngoo Yang", "Deukhyoun Heo"], "n_citation": 50, "references": ["2d867443-cb13-4561-a859-e3cd307d2533", "5960e5c4-fe63-4761-9d1c-dd799930a541", "e0a7a08f-ade6-4356-8b34-8b916c157ec4", "e3859fc9-b45d-4edd-bc32-26c435fb44f1", "fa982281-b15c-492b-9d93-338fd946d52a"], "title": "CMOS Startup Charge Pump With Body Bias and Backward Control for Energy Harvesting Step-Up Converters", "venue": "IEEE Transactions on Circuits and Systems I-regular Papers", "year": 2014, "id": "449faf1a-aa34-4fa7-ad9e-0d967c7e078d"}
{"abstract": "A software system interacts with third-party libraries through various APIs. Using these library APIs often needs tofollow certain usage patterns. Furthermore, ordering rules (specifications) exist between APIs, and these rules govern the secure and robust operation of the system using these APIs. But these patterns and rules may not be well documented by the API developers. Previous approaches mine frequent association rules, itemsets, or subsequences that capture API call patterns shared by API client code. However, these frequent API patterns cannot completely capture some useful orderings shared by APIs, especially when multiple APIs are involved across different procedures. In this paper, we present a framework to automatically extract usage scenarios among user-specified APIs as partial orders, directly from the source code (API client code). We adapt a model checker to generate interprocedural control-flow-sensitive static traces related to the APIs of interest. Different API usage scenarios are extracted from the static traces by our scenario extraction algorithm and fed to a miner. The miner summarizes different usage scenarios as compact partial orders. Specifications are extracted from the frequent partial orders using our specification extraction algorithm. Our experience of applying the framework on 72 X11 clients with 200K LOC in total has shown that theextracted API partial orders are useful in assisting effective API reuse and checking.", "authors": ["Mithun Acharya", "Tao Xie", "Jian Pei", "Jun Xu"], "n_citation": 249, "references": ["08d0a1e1-e5f4-4116-920f-293692d80974", "0a25a3c5-daf8-4525-9846-69d727d29810", "2756c2a6-10f4-4f46-bd49-13ca4392d6b6", "34b7e270-80d7-46d5-a6f1-e50087a8d045", "4f98d1f1-296f-4ae8-8a82-8d8082cd77e2", "4fae7aa2-96a8-48e7-9a1e-5a6a379c8de9", "509473ba-ad2f-4706-89fc-4e537252a8b8", "54fe2662-f4fe-4b27-903b-c9c84b1dc732", "58bde0a6-18ff-4d37-b4c2-f877f69d3e49", "6cb0ec0f-927f-4c79-81de-b5cf85d90de9", "795b3c5c-deeb-4281-b4de-d0f1b2d8478d", "9b3cc1cd-00f1-4cec-b153-8a0e895f3507", "a110c0cb-4851-45ac-8a40-4a29e47f50f0", "a37bac2e-5ffb-4607-b163-c26d23d30af6", "cafdd5d8-c349-46ce-a4cb-68d974309d3f", "cc6883a2-a922-42df-99a8-c94f82d82255", "e7766b0e-0ec0-4151-bfd3-3d0aee7050a5", "eb08e815-7648-45b4-923f-12b9014cd2c4", "eb2fc594-c64a-4f91-b6f3-68d64f6ffc8c"], "title": "Mining API patterns as partial orders from source code: from usage scenarios to specifications", "venue": "foundations of software engineering", "year": 2007, "id": "578677eb-74e6-4f83-9c30-a5426587abc3"}
{"abstract": "Generational collection has improved the efficiency of garbage collection in fast-allocating programs by focusing on collecting young garbage, but has done little to reduce the cost of collecting a heap containing large amounts of older data. A new generational technique, older-first collection, shows promise in its ability to manage older data.This paper reports on an implementation study that compared two older-first collectors to traditional (younger-first) generational collectors. One of the older-first collectors performed well and was often effective at reducing the first-order cost of collection relative to younger-first collectors. Older-first collectors perform especially well when objects have queue-like or random lifetimes.", "authors": ["Lars Thomas Hansen", "William D. Clinger"], "n_citation": 13, "references": ["08d2e6d9-489a-4be6-9eac-e0292ca3f613", "17b88562-8017-49d4-9159-060b336ff87e", "38803a5a-8f09-484a-8940-ee0af8777032", "48c19612-c038-4785-8b19-0bbf8a3919c9", "4a9518be-73f1-4a63-8edc-4731dd8f7e07", "6d1c21a7-93b3-4e2b-b8bd-c165a5e7f4d3", "731baba7-9be0-4e32-afb7-8eb939fdbf9e", "7417cd00-cd20-44c7-aebd-ba05d7173051", "7d2c2207-47c6-4cfe-9201-3ab480a06f7b", "81d5fbdd-5030-4505-92d2-e0a16cf93919", "af621d6c-236b-4273-9263-c278d96e1592", "cbab4032-8339-48f8-a440-b89379a0ee96", "cd8b5158-c374-4e64-96aa-7b5e5986e681", "d17c4f06-3399-4c3b-a709-fdbe9205fc58", "d627acb8-2536-4770-ba8d-9df134c96909", "db35ba98-2678-4920-86a5-022798b7e9b1", "dbbe75f5-be94-4929-86b9-a0a1a7eb5567", "ea0dba66-b557-48c2-b5cb-9869f43b5e70", "f3a77bc9-de39-4f28-8b03-efe4a6f0f61a"], "title": "An experimental study of renewal-older-first garbage collection", "venue": "international conference on functional programming", "year": 2002, "id": "9cf15c03-7c44-439c-b012-64e1dc83a0fe"}
{"abstract": "Computer programs are operational schemes. Many programmers design, describe, and justify their programs while solely thinking \"operationally\". Yet, an operational perspective is insufficient. For many years, the important role of an assertional perspective is advocated. However, this perspective is debated [5]. Many are deterred from employing it, possibly because it is displayed with formal notations and mathematical logic. The objective of this paper is to offer the elaboration of this perspective through a natural, informal embedment of assertions in the design process. The essential, revealing, and instructive role of informal, yet concise and accurate assertions is motivated and elaborated; first through three stimulating illustrations, and then with a general instructional approach.", "authors": ["David Ginat"], "n_citation": 50, "references": ["091233d3-8c9b-479e-b714-5036ccddc00a", "26331918-7147-4e8e-bd8d-a3164709248c", "8bf32b34-bf22-49d0-8668-29c560ffa93d", "b2ee7edb-9765-4260-af39-0a5e372a9189", "e98b99a8-bceb-4010-b60e-d075d35769fc", "ecec68f9-d881-4913-b1be-0e13dc7f555f"], "title": "Embedding instructive assertions in program design", "venue": "technical symposium on computer science education", "year": 2004, "id": "297391de-3bd9-4c8e-974a-61778f0c38d1"}
{"abstract": "This paper studies various algorithmic issues in reconstructing a species tree from gene trees under the duplication and the mutation cost model. This is a fundamental problem in computational molecular biology. Our main results are as follows. #R##N#A linear time algorithm is presented for computing all the losses in duplications associated with the least common ancestor mapping from a gene tree to a species tree. This answers a problem raised recently by Eulenstein, Mirkin, and Vingron [J. Comput. Bio., 5 (1998), pp. 135--148]. The complexity of finding an optimal species tree from gene trees is studied. The problem is proved to be NP-hard for the duplication cost and for the mutation cost. Further, the concept of reconciled trees was introduced by Goodman et al. and formalized by Page for visualizing the relationship between gene and species trees. We show that constructing an optimal reconciled tree for gene trees is also NP-hard. Finally, we consider a general reconstruction problem and show it to be NP-hard even for the well-known nearest neighbor interchange distance. A new and efficiently computable metric is defined based on the duplication cost. We show that the problem of finding an optimal species tree from gene trees is NP-hard under this new metric but it can be approximated within factor 2 in polynomial time. Using this approximation result, we propose a heuristic method for finding a species tree from gene trees with uniquely labeled leaves under the duplication cost. Our experimental tests demonstrate that when the number of species is larger than 15 and gene trees are close to each other, our heuristic method is significantly better than the existing program in Page's GeneTree 1.0 that starts the search from a random tree.", "authors": ["Bin Ma", "Ming Li", "Louxin Zhang"], "n_citation": 148, "references": ["09581af8-91c1-4364-8ca7-7cc17f3fda05", "25fcf6b4-99ee-433c-9608-aef1316f7087", "5e02c3f9-4b76-4c02-9f6b-d9b59abdfa68", "7573cccd-6494-4b8b-ac7c-92d4f3d28e3b", "7aea6ffa-f7b9-4fbb-a14a-d3ff83a6b28b", "ba68ff70-dc46-4ac8-af34-1ee91c365b3b"], "title": "From Gene Trees to Species Trees", "venue": "SIAM Journal on Computing", "year": 2000, "id": "8559019b-05c6-4435-bf93-8f1e017c7f6d"}
{"abstract": "Distributed computing is one of the major trends in the computer industry. As systems become more distributed, they also become more complex and have to deal with new kinds of problems, such as partial crashes and link failures. While many middleware architectures have emerged to answer the growing demand in distributed technologies, most of them do not provide any kind of fault tolerance mechanisms. In this paper, we discuss the addition of object group support to CORBA. We describe three approaches: integration, interception, and service, and we argue is favor of the latter. We present the architecture of an Object Group Service (OGS) that provides for fault tolerance and high availability through object replication. This service enables the application developer to deal with invocations to replicated objects in a completely transparent way. We describe the major components of OGS: messaging, monitoring, consensus, group membership, and group multicast. We finally discuss the implementation of the service and its performance.", "authors": ["Pascal Felber", "Rachid Guerraoui", "Andr\u00e9 Schiper"], "n_citation": 53, "references": ["0240b226-7413-4850-92b3-bc9648f30a77", "1e2939c6-44c8-4354-b474-76067b60050e", "7ffec2f8-420b-43cf-8ad5-550e332f5d6d", "82df4d2b-e9b2-458a-bf78-5878176d927e", "8d45a1cd-cc10-41f1-925e-e6ff4e0d9fab", "923f1234-4c9f-47f8-990a-d6c8fc482bf2", "9bcc0ae8-9033-4156-b85b-592bd01ae91e", "9eac8f56-e6ce-4d57-89ba-6f1119209b9a", "b5635a67-86ea-4fb1-93ba-c9b198344628", "e7857381-83eb-4350-baad-3d12decd3cb7"], "title": "Replication of CORBA Objects", "venue": "Advances in Computers", "year": 1999, "id": "a4b2199b-27db-46e3-b43c-b57cb240d287"}
{"abstract": "There have been several document ranking methods to calculate the conceptual distance or closeness between a Boolean query and a document. Though they provide good retrieval effectiveness in many cases, they do not support effective weighting schemes for queries and documents and also have several problems resulting from inappropriate evaluation of Boolean operators. We propose a new method called Knowledge\u2010Based Extended Boolean Model (kb\u2010ebm) in which Salton's extended Boolean model is incorporated. kb\u2010ebm evaluates weighted queries and documents effectively, and avoids the problems of the previous methods. kb\u2010ebm provides high quality document rankings by using term dependence information from is\u2010a hierarchies The performance experiments show that the proposed method closely simulates human behaviour.", "authors": ["Joon Ho Lee", "Myoung Ho Kim", "Yoon Joon Lee"], "n_citation": 139, "references": ["21b6c69e-542d-49ad-8155-9b6e0d837021", "27d4f80f-3e8c-46cd-b81b-bf5f7014eb3b", "3044c9a1-2e77-4238-9c81-19ac3a548704", "395fad59-f1c9-4376-8b62-ad605d09d64b", "4667e1ee-db37-48ef-9c7e-5a733fb7027b", "5a5dabe5-fd5e-4b5c-a199-3d39e541a052", "6527b4c1-dbff-4964-9343-4fd409b276ff", "a0ee28c2-25b9-4c41-b9f8-c4eabc7e1e1e", "bed2c8c8-1dc3-4631-b8e2-746ba766a9ae", "cb391b0e-83d0-4fb5-ab04-45ed254f5219", "cbc32474-bb22-4892-a46d-7d1315ce6636", "f0c983e5-26cd-4311-a6c2-56021d04456b"], "title": "INFORMATION RETRIEVAL BASED ON CONCEPTUAL DISTANCE IN IS\u2010A HIERARCHIES", "venue": "Journal of Documentation", "year": 1993, "id": "e7636309-1fa3-4a69-a270-daeb344c2333"}
{"abstract": "In this paper, the general formulation of periodically time-varying state-feedback controllers with memory is considered for the first time. New analysis and synthesis conditions for robust stability are proposed. The flexibility of these new results allows the user to freely add degrees-of-freedom to the control law which appears to effectively reduce the conservatism of the synthesis condition and to increase the stability domain of the closed-loop system in the presence of uncertainties. Furthermore, it is shown that for a particular structure of controllers a more efficient version of the design theorem can be derived by enriching the matrix of slack-variables.", "authors": ["Jean-Francois Tregouet", "Yoshio Ebihara", "Denis Arzelier", "Dimitri Peaucelle", "Christelle Pittet", "Alexandre Falcoz"], "n_citation": 8, "references": ["00b22b00-ac80-4406-ae0b-a40cb4ecaa16", "4470002e-a11a-4e7b-b10b-fd0652562cc9", "5c2eebce-e505-40cd-86eb-5d9351358680", "a63c1225-1e2f-43af-a8cf-f19c7c0346a4", "d6565fe2-39ad-4e86-b0dd-88b9d6e7b018"], "title": "Robust Stability of Periodic Systems with Memory: New Formulations, Analysis and Design Results", "venue": "", "year": 2012, "id": "a6a5af98-1866-45ed-b45c-7f42d847f0ab"}
{"abstract": "Research groups in both academia and industry have developed prototype systems to demonstrate the benefits of pervasive computing in various application domains. Unfortunately, many first-generation pervasive computing systems lack the ability to evolve as new technologies emerge or as an application domain matures. To address this limitation, the University of Florida's Mobile and Pervasive Computing Laboratory is developing programmable pervasive spaces in which a smart space exists as both a runtime environment and a software library. Service discovery and gateway protocols automatically integrate system components using generic middleware that maintains a service definition for each sensor and actuator in the space. The Gator Tech Smart House in Gainesville, Florida, is the culmination of more than five years of research in pervasive and mobile computing. The project's goal is to create assistive environments such as homes that can sense themselves and their residents and enact mappings between the physical world and remote monitoring and intervention services.", "authors": ["Sumi Helal", "William C. Mann", "Hicham Elzabadani", "Jeffrey King", "Youssef Kaddoura", "Erwin Jansen"], "n_citation": 998, "references": ["081b1c58-3040-4c57-9758-d213c6646b83", "122e7056-5555-470a-9b93-0fcbaabe97a4", "6e4c03fd-2b38-4e9d-8fdb-12f2686023b2", "98e7405c-74a2-410c-b852-ea634425ca9f", "9acb8245-7945-4433-a654-f7bbdef73bed", "9b2d9694-154e-4250-b81c-5fac7ddcbb17", "b6e1a580-fa3b-4c8e-adaf-1f945d6ad99f", "c59ff661-9bbc-4ff4-aa5a-83a47273f3c8", "e245b8b9-a754-454c-96bb-233c9f7047e8"], "title": "The Gator Tech Smart House: a programmable pervasive space", "venue": "IEEE Computer", "year": 2005, "id": "6ec52c29-fc7f-43cd-90c6-441da0341e74"}
{"abstract": "When building dependable systems by integrating untrusted software components that were not originally designed to interact with each other, it is likely the occurrence of architectural mismatches related to assumptions in their failure behaviour. These mismatches, if not prevented during system design, have to be tolerated during runtime. This paper presents an architectural abstraction based on exception handling for structuring fault-tolerant software systems. This abstraction comprises several components and connectors that promote an existing untrusted software element into an idealised fault-tolerant architectural element. Moreover, it is considered in the context of a rigorous software development approach based on formal methods for representing the structure and behaviour of the software architecture. The proposed approach relies on a formal specification and verification for analysing exception propagation, and verifying important dependability properties, such as deadlock freedom, and scenarios of architectural reconfiguration. The formal models are automatically generated using model transformation from UML diagrams: component diagram representing the system structure, and sequence diagrams representing the system behaviour. Finally, the formal models are also used for generating unit and integration test cases that are used for assessing the correctness of the source code. The feasibility of the proposed architectural approach was evaluated on an embedded critical case study.", "authors": ["Patrick H. S. Brito", "Rog\u00e9rio de Lemos", "Cec\u00edlia M. F. Rubira", "Eliane Martins"], "n_citation": 21, "references": ["018a82fb-f73e-478a-8466-80a19992f2ea", "071b05d5-e139-404b-aa98-5c682526cfb9", "15b87b24-f97f-4144-90ea-998c72f6eade", "31c24837-c43f-4b12-98f4-0cec1087ee4a", "32289a54-aa0b-4054-8b3b-958ba221399e", "3a138aca-60f4-4d9c-a622-60b4c2f52339", "3cfd3eae-d49e-44e8-bda8-026d23f7e9b1", "47d0e8d9-79e9-4584-bffb-35937bcd29d3", "6596102f-303a-4d21-bb9a-88682607fb10", "66592562-bb37-4fb5-ac1a-9253a5044a8c", "72d5e9d9-b319-4ee1-abaf-add1950f9f92", "77f86ef1-9f20-4c29-a1d3-3c75e35a7041", "809f0c9d-dc19-4ec0-b48d-3c6ee4ca872a", "84db22b8-af6f-4dcc-b45c-6075003440a5", "88ada972-9f9c-44c4-9410-0f1e5a316e69", "9152db9b-6e40-47ef-bff0-261f06ba0a6b", "a13a126e-37f7-4fad-8cfe-a3184320d64a", "ad86538c-7030-47cb-8448-4a6ccf439644", "b6dba649-3614-4073-8ca4-0f84b73ca1bf", "becfd318-8941-4714-a547-9f4a58c79e79", "c8c85d77-fcef-41ee-bf2a-48695dbed953", "e090ea31-58dd-466c-bd71-43179e7ab064"], "title": "Architecting fault tolerance with exception handling: verification and validation", "venue": "Journal of Computer Science and Technology", "year": 2009, "id": "df3f159e-4133-4227-9e1a-14c5e6976ab9"}
{"abstract": "For the generic specification of protocols, goals, or workflows, many approaches to agent-oriented modeling provide a concept of role. Roles abstract from the concrete agents involved in an interaction. They provide means for the evolution of agents and serve as components of agent design. Despite the widespread usage of roles in agent-oriented modeling, a systematic analysis of the different aspects and properties of this concept is still missing. In this paper, we perform such an analysis and identify requirements for a general role concept. We develop such a role concept for a modeling approach based on the UML and graph transformation systems and exemplify its use for the specification (and application) of protocols. Finally, we provide a run-time semantics for roles based on concepts from the theory of graph transformation.", "authors": ["Ralph Depke", "Reiko Heckel", "Jochen Malte K\u00fcster"], "n_citation": 50, "references": ["01f6a3b8-eef1-4de2-af44-e0cef74f2f82", "3023929a-c93e-49c5-b03f-7fb0414d94df", "365ac4aa-5611-41ad-8018-6dba33f27ada", "36fc4e93-027d-4e70-938e-f0fd455f6586", "3e52fae4-b750-47f7-9a2a-29fd2b81e5c4", "4b8d5647-b891-4bd0-b974-010bb0a27d6f", "4f5e8e4f-1a68-4689-90ca-f46f30065f6b", "6a572193-3412-4186-97fc-058bd37eb658", "72ba85e1-3ddd-40f2-a657-b8bb8bf097b8", "82d07e7b-c616-4023-b69a-a11ef9cd9520", "9d7792fb-cf3b-4e04-9bf9-3eec9ad5336c", "ba7c943a-7582-4cc7-98e8-77f7633fa668", "c8d1d9a6-e071-4cf4-841f-3f4839586b76", "fc059222-1246-459a-8095-ba01fee89ded"], "title": "ROLES IN AGENT-ORIENTED MODELING", "venue": "International Journal of Software Engineering and Knowledge Engineering", "year": 2001, "id": "c86648da-35b0-4db5-ab23-6ccc03209d2f"}
{"abstract": "We consider robust feedback control of time-varying, linear discrete-time systems operating over a finite horizon. For such systems, we consider the problem of designing robust causal controllers that minimize the expected value of a convex quadratic cost function, subject to mixed linear state and input constraints. Determination of an optimal control policy for such problems is generally computationally intractable, but suboptimal policies can be computed by restricting the class of admissible policies to be affine on the observation. By using a suitable re-parameterization and robust optimization techniques, these approximations can be solved efficiently as convex optimization problems. We investigate the loss of optimality due to the use of such affine policies. Using duality arguments and by imposing an affine structure on the dual variables, we provide an efficient method to estimate a lower bound on the value of the optimal cost function for any causal policy, by solving a cone program whose size is a polynomial function of the problem data. This lower bound can then be used to quantify the loss of optimality incurred by the affine policy.", "authors": ["Michael J. Hadjiyiannis", "Paul J. Goulart", "D. Kuhn"], "n_citation": 28, "references": ["005683be-ebd6-4d9c-b865-1ee6fdf57838", "101b6cc0-9d90-4da4-92f7-7e9f5799d72f", "1dfddb0a-c28f-4852-af75-d6c8f3c971a4", "235994f5-492a-4416-8446-dc9a7edcd443", "314320d8-01d5-4085-8cad-a833db4f2dea", "3d9ef755-d0b7-41c0-931f-96e1330bfc6d", "4f232f2e-f9f6-4b0e-954a-37faa426d13a", "63acdae8-a308-4d06-8457-41eb71247946", "708d867d-3639-46ee-bc07-de92020b8a23", "835ed5b1-8168-4716-a892-12f3a5ceb63e", "83f6fbfd-f1db-43b0-bce3-aee1b7fd9099", "88263832-baaa-48af-9862-eb97aca15458", "c334482f-89f0-4382-85d2-18941b56853a", "c52cd708-8d75-4c5b-8b8f-14fd8e7815a3", "d9fdb798-2a97-4418-8d79-4878e77df403", "f36fa851-af64-4053-b42f-6b92b5d7afe4"], "title": "An Efficient Method to Estimate the Suboptimality of Affine Controllers", "venue": "IEEE Transactions on Automatic Control", "year": 2011, "id": "8463b239-8519-45e3-adad-1a537df0bd7c"}
{"abstract": "Since their introduction as a means of front propagation and their first application to edge-based segmentation in the early 90's, level set methods have become increasingly popular as a general framework for image segmentation. In this paper, we present a survey of a specific class of region-based level set segmentation methods and clarify how they can all be derived from a common statistical framework.#R##N##R##N#Region-based segmentation schemes aim at partitioning the image domain by progressively fitting statistical models to the intensity, color, texture or motion in each of a set of regions. In contrast to edge-based schemes such as the classical Snakes, region-based methods tend to be less sensitive to noise. For typical images, the respective cost functionals tend to have less local minima which makes them particularly well-suited for local optimization methods such as the level set method.#R##N##R##N#We detail a general statistical formulation for level set segmentation. Subsequently, we clarify how the integration of various low level criteria leads to a set of cost functionals. We point out relations between the different segmentation schemes. In experimental results, we demonstrate how the level set function is driven to partition the image plane into domains of coherent color, texture, dynamic texture or motion. Moreover, the Bayesian formulation allows to introduce prior shape knowledge into the level set method. We briefly review a number of advances in this domain.", "authors": ["Daniel Cremers", "Mikael Rousson", "Rachid Deriche"], "n_citation": 1007, "references": ["02663c32-3dc1-4b9b-b654-9b535b7b5535", "07e5be80-8da5-44a2-9bda-986025ed040a", "088d00cf-ed12-4552-8958-8b550401f355", "090af1dd-85e1-49f1-ae85-9928df7f709f", "0ba0f1a4-bc98-4490-95a2-03d5092c230a", "0c69eba9-85c8-4d16-87ff-0ba39ffbc88e", "19ed6837-d377-4cdf-9912-1f9ee9797dc9", "1a684c02-4e06-4885-b0e7-b8e45504f7d6", "1aab6663-cc0a-425c-83b4-2ac5d8b5e052", "1c2ae954-40dc-4b7f-abf8-08bf6fc85f0c", "1c63e1d5-b963-455b-829d-e4f3eb63a36a", "1d419b36-3ad6-4bb8-9277-4df969c9db05", "1d445a00-3877-43d7-831d-32c3cce863b8", "1ec7dd64-c9f0-4f25-ba7a-b021de36d5c5", "23cc8d35-1189-4210-b97e-cf13c6248d6e", "2623a9d8-6577-415b-9354-bb089798f77a", "26ca0239-2be5-402a-bed2-53f5caeaa859", "28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb", "29add150-3502-432d-8d3c-78b83500007c", "2b52ed50-4449-4360-9388-c008639a33fe", "2ccb01b5-e59c-4ff4-b627-a76a72c9738c", "32d0d580-9e53-4e2d-bcc4-f46c700d3901", "35e4e50e-fe14-4da5-8888-ca800c74d224", "3795d05f-b420-4d43-a364-35c60045f425", "37a2d0a5-2490-411e-83b6-d127d3210c52", "38ca9c1e-d584-41e1-b892-708a46dd971f", "3b2a0cc4-ac07-469e-9778-6770a801fb72", "3c0e138e-0465-4abd-b713-47ca068e9e11", "3c863691-dd3b-432c-91db-53e4905ad30b", "3e12b621-bfc7-4463-bd41-41d4ca536d91", "3f4cc95c-5f47-4031-8671-e23ff4fe2ed2", "42bffc17-bd5a-486a-adf2-6790a1661aff", "443fb8d3-09ba-45a2-98a6-597799c3e63c", "5bb4c9b8-f646-4ffe-b0f3-9b228918d345", "6445f129-25df-4d9f-9bd5-1ed88bf244a4", "6f40821b-857a-4e6a-a97d-27c3d71aac3b", "7e207d95-0c77-4dd2-99fa-9c9628ed6c3a", "81c13bb3-fe4c-4a7a-b04c-079f9d34f8d1", "82eb55e6-39a8-4968-8be6-e2bfbb439a40", "919ef2b1-f3bc-470c-801a-1a10a1b93b3d", "93824d65-e5b7-4321-ac44-e26ffbb51f3b", "981e8691-d7e2-4d13-956a-15f56ecf40b6", "98cfeac3-9abb-4f5b-9705-158c3b7b9d3a", "9a2e8adb-9c59-4b7f-b553-67ee26f91aaa", "9dee56d9-8fd5-414c-83ae-31551b20ae88", "9e55de80-587a-4826-a476-0dd11b79f14b", "aabd3fe1-94b6-4f7d-8afe-57f5ff1daec0", "ab0460de-358e-4712-ad8a-4814c1d70bd8", "acff6aaf-4307-4441-b44c-57fee4c1773d", "ad23ca01-fa76-4f9a-ba68-27dc2c51784f", "ad30c242-5f32-4003-a914-ec5ffc72611b", "adea8b77-d86f-45c3-85f2-50a7a2dcbe7c", "b03b1f45-deac-423c-9eac-578989601923", "b8a86432-fff7-474e-9d72-046c5189e6dc", "ba6724b0-e9a1-4379-b8f4-b729ec80d296", "c54f5e9b-8ee1-4c6d-934f-84c1f2413015", "c94db35c-9a3c-4f7f-818c-b94016a5f2c5", "dfe52bc9-09a5-4981-b706-28fa27352a54", "e068d506-2794-4b94-9fc8-b1e72f6130d6", "e22e6515-b2fc-4fad-989b-2dbb38a8e0f9", "e48bfbb8-0aea-479d-b33e-1946a631443b", "e500049d-e42e-43a5-8e0c-4f57cdf91fa7", "ea153145-d877-4893-acc2-b9c7f48ab005", "ee51b885-3527-4a95-92b1-78432c2d0dca", "fd1e24ca-8100-441a-8750-d7f53a67e9e7"], "title": "A Review of Statistical Approaches to Level Set Segmentation: Integrating Color, Texture, Motion and Shape", "venue": "International Journal of Computer Vision", "year": 2007, "id": "c7694773-a305-4a5b-98d2-3440ef780ee7"}
{"abstract": "Code completion is a widely used productivity tool. It takes away the burden of remembering and typing the exact names of methods or classes: As a developer starts typing a name, it provides a progressively refined list of candidates matching the name. However, the candidate list usually comes in alphabetic order, i.e., the environment is only second-guessing the name based on pattern matching, relying on human intervention to pick the correct one. Finding the correct candidate can thus be cumbersome or slower than typing the full name.#R##N##R##N#We present an approach to improve code completion based on recorded program histories. We define a benchmarking procedure measuring the accuracy of a code completion engine and apply it to several completion algorithms on a dataset consisting of the history of several systems. Further, we use the change history data to improve the results offered by code completion tools. Finally, we propose an alternative interface for completion tools that we released to developers and evaluated.", "authors": ["Romain Robbes", "Michele Lanza"], "n_citation": 58, "references": ["0dd0fef3-5fe6-4158-a803-6e8eb3788b5e", "26133209-51d3-4565-ac62-c1193a558dcd", "4a7429d0-c3f1-44fe-abf3-f9f9e2c9480f", "56547466-7134-409f-bcfd-480232b990a6", "6284c750-0da9-4e87-b1e6-611b43c92cdf", "64ae4179-ed47-4a71-bee0-5e2fbf93fec7", "73fca154-36d4-460b-a683-ca4a6ee68b44", "807e4a1c-e46c-4cca-a0e6-eb1605eddeba", "8f89efa9-acb0-416f-8c25-3474cfb7e210", "9192693f-db6f-438e-8d98-5a18048bd6c8", "ada1e9d2-03ee-4dc7-b4b7-335c242fa462", "cdd80a29-cd6d-4caa-98cc-cdda16c89431", "e2e8ebf0-3981-4496-9d96-6637e61292d0", "f2f586a2-5791-49e8-86e6-a5479b809310"], "title": "Improving code completion with program history", "venue": "automated software engineering", "year": 2010, "id": "ba2dbd36-ce70-4c58-9096-c905b81c7fa8"}
{"authors": ["Vittorio Brusoni", "Luca Console", "Barbara Pernici", "Paolo Terenziani"], "n_citation": 50, "references": ["2dcf1d8c-58a0-4b1d-9a11-b8c711806faf", "5ba7c798-6a41-48ff-9699-d184ef745c93", "60885145-b83f-4478-8e12-29e10da9ac53", "73727f2c-f049-4ce1-96fc-68e5e3c0c3ab", "77a15b75-b836-443d-9b29-95fc81427aad", "995b150c-6522-4960-a45b-6c5cb8bb3299", "a52c089c-9222-4085-91c7-93b217adc8a8", "a74fa265-9bb7-4bf4-855f-0a83e114affd", "dbe5ae2e-bbc0-4508-8df5-3ec95c784fa8"], "title": "LaTeR: a general purpose manager of temporal information", "venue": "international syposium on methodologies for intelligent systems", "year": 1994, "id": "0225a7be-bd89-46c8-8e20-c6a35601d7c1"}
{"abstract": "This paper examines the current status of standardization efforts concerning mobile agent technology and presents five Java-based mobile agent platforms. Standards directly relating to mobile agent technology are presented first, followed by an overview of other standardization efforts that while not directly relating to mobile agent technology, can still contribute significantly to its success. This is followed by a detailed presentation of five Java-based mobile agent platforms. The description of each platform examines its communication mechanisms, its architecture and the services that it offers to a developer. The presentation of the platforms ends with a comparative overview of their features accompanied by a brief presentation of some performance results. The paper concludes with some general remarks on the future of this technology.", "authors": ["Menelaos K. Perdikeas", "Fotis G. Chatzipapadopoulos", "Iakovos S. Venieris", "Gennaro Marino"], "n_citation": 107, "references": ["1700b9f8-b8f4-4b6d-85a3-15f9225cc9c7", "3df02e7b-67df-4f8e-9031-5cf7d7f54a69", "6e317f97-b46c-4158-bed1-8a87aaf50a6d", "a5c23dd0-0762-46f3-bf71-48703cf17e64", "b75c31b4-53d4-4f73-a4ea-734e7ee023e3", "bf4922e2-02f5-4f1c-9390-19b289dd508f", "d6e944ff-550c-44a6-b069-61704fd8f5c5", "d9c7cc6d-0067-4dae-848b-fcbe35b4aec9"], "title": "Mobile agent standards and available platforms", "venue": "Computer Networks", "year": 1999, "id": "5a77a8b0-d2ed-4559-9240-9c11792b9d3d"}
{"abstract": "Event-Driven Software (EDS) can change state based on incoming events; common examples are GUI and Web applications. These EDSs pose a challenge to testing because there are a large number of possible event sequences that users can invoke through a user interface. While valuable contributions have been made for testing these two subclasses of EDS, such efforts have been disjoint. This work provides the first single model that is generic enough to study GUI and Web applications together. In this paper, we use the model to define generic prioritization criteria that are applicable to both GUI and Web applications. Our ultimate goal is to evolve the model and use it to develop a unified theory of how all EDS should be tested. An empirical study reveals that the GUI and Web-based applications, when recast using the new model, show similar behavior. For example, a criterion that gives priority to all pairs of event interactions did well for GUI and Web applications; another criterion that gives priority to the smallest number of parameter value settings did poorly for both. These results reinforce our belief that these two subclasses of applications should be modeled and studied together.", "authors": ["Ren\u00e9e C. Bryce", "Sreedevi Sampath", "Atif M. Memon"], "n_citation": 120, "references": ["188276e0-6a5b-4c7a-a407-28f3978ea36b", "1cf39c60-a6ee-4fea-8190-c00c9c27e973", "1d79213f-ba17-4cb7-90fb-59132ae38391", "30521aed-580e-4260-8074-24f470294419", "325673f0-f019-4708-8fe2-114fc2b159ea", "45798797-cd28-46a6-9e89-f8e3b5ebb1d8", "4849c8ca-d637-4e0c-97eb-f675f9392aa5", "577746cf-a769-44dd-a6c4-e0b788bce5ed", "622609cf-fae8-4fd4-a021-989a064dd77d", "6cd7a1a2-cc4f-45ab-986d-5c8f9ce4309f", "78ebac1e-f31a-4312-a6ee-dd8f5645c22a", "8a8065c7-24d8-49f1-bc4d-a56730685f5c", "902967b4-0c7f-49cf-927e-72182bcbccaf", "94275226-20e9-429e-b64a-d15730f205fd", "a2d4f1ca-ef95-4a55-93ae-034831b8ddb5", "a951b823-ef07-46a8-821b-54d6b573a636", "b300bb34-feb9-43a5-9f73-4c1b4db355b9", "f0d0263e-d29d-418e-b15a-2a58e1e05d1d", "f43d87d4-f6c6-4e55-a7b4-5655841a3832", "fae6805c-b379-4d11-972d-76644b22601c", "fed3e232-a3ad-418a-bcce-f7db283ee614"], "title": "Developing a Single Model and Test Prioritization Strategies for Event-Driven Software", "venue": "IEEE Transactions on Software Engineering", "year": 2011, "id": "047426f5-9f91-44e4-87cb-4ee106b826d2"}
{"abstract": "We consider a class of algorithms for classification, which are based on sequential greedy minimization of a convex upper bound on the 0 - 1 loss function. A large class of recently popular algorithms falls within the scope of this approach, including many variants of Boosting algorithms. The basic question addressed in this paper relates to the statistical consistency of such approaches. We provide precise conditions which guarantee that sequential greedy procedures are consistent, and establish rates of convergence under the assumption that the Bayes decision boundary belongs to a certain class of smooth functions. The results are established using a form of regularization which constrains the search space at each iteration of the algorithm. In addition to providing general consistency results, we provide rates of convergence for smooth decision boundaries. A particularly interesting conclusion of our work is that Logistic function based Boosting provides faster rates of convergence than Boosting based on the exponential function used in AdaBoost.", "authors": ["Shie Mannor", "Ron Meir", "Tong Zhang"], "n_citation": 59, "references": ["310cbba4-d88d-4bf4-a4f2-738f91b5f8c8", "7b970a9e-bdb4-45c0-8723-a62d1b69b97f", "aadbc173-cbac-4ab9-ace5-c6709e1b9c0a", "b426e597-0025-4486-bad2-3337be16a439", "d969927f-ce36-4536-ae18-8eca00636374", "db26488d-78be-44b1-a343-e896f43c5d29", "fc603eb6-d237-4584-842c-c80805f31370"], "title": "The Consistency of Greedy Algorithms for Classification", "venue": "computational learning theory", "year": 2002, "id": "e6cc9d76-8dc7-4de7-bdf2-08ee202918e9"}
{"abstract": "This paper assumes a parallel RAM (random access machine) model which allows both concurrent reads and concurrent writes of a global memory.The main result is an optimal randomized parallel algorithm for INTEGER_SORT (i.e., for sorting n integers in the range $[1,n]$). This algorithm costs only logarithmic time and is the first known that is optimal: the product of its time and processor bounds is upper bounded by a linear function of the input size. Also given is a deterministic sublogarithmic time algorithm for prefix sum. In addition this paper presents a sublogarithmic time algorithm for obtaining a random permutation of n elements in parallel. And finally, sublogarithmic time algorithms for GENERAL_SORT and INTEGER_SORT are presented. Our sub-logarithmic GENERAL_SORT algorithm is also optimal.", "authors": ["Sanguthevar Rajasekaran", "John H. Reif"], "n_citation": 174, "references": ["115a7199-5efa-472d-bdfa-92883c7eb039", "14168ec2-3625-4d73-81af-ed74aaae3d0e", "3e86a210-8d95-4023-baa5-062126efa43a", "60ceda9c-f2ad-4371-92c3-502569a98b05", "69b48620-6547-477c-9e97-579513947eb4", "8036c87e-ab7e-4545-a943-e2a138d68b89", "98db48cc-68f2-4464-ac90-a02fcfc37e48", "9fc52d0d-7ce7-4c0d-9a61-3d93d5332479", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "a6f068e3-5131-439c-ab90-91bf32367e77", "b39ebd07-a487-4651-81f7-d044fe17ac65", "cad73d87-5e37-4c18-8c13-f08069ba5437"], "title": "Optimal and sublogarithmic time randomized parallel sorting algorithms", "venue": "SIAM Journal on Computing", "year": 1989, "id": "74545c96-0833-4ef6-b239-6e50365e0c8a"}
{"abstract": "The actuator failure compensation problem is addressed in this brief. It is considered an uncertain linear plant, which is supposed to undergo unknown failures causing the plant input components to be stuck at some uncertain but bounded time functions. A sliding-mode-based control policy is presented, guaranteeing the detection of the fault and the identification of the failed component by means of a suitable test input. Once the failed component has been identified, the control law is reconfigured, redistributing the control activity among the controllers still working. The proposed controller has been tested by simulation on a benchmark problem", "authors": ["Maria Letizia Corradini", "Giuseppe Orlando"], "n_citation": 23, "references": ["6b80456f-40d5-408c-9ca0-a0d616ba9acc", "90b35567-d92b-409a-a18a-732634dfc797", "9d41a5bf-f4fa-4da8-b4c5-6b16652adbbc", "a379d4a0-bb13-4a75-be1e-d50d1fc79225"], "title": "Actuator Failure Identification and Compensation Through Sliding Modes", "venue": "IEEE Transactions on Control Systems and Technology", "year": 2007, "id": "61f1e0ae-f80d-4581-b3bb-219f2bf989dc"}
{"abstract": "We address the average-consensus problem for a distributed system whose components (nodes) can exchange information via unreliable interconnections (edges) that form an arbitrary, possibly directed topology (digraph). We consider a general setting where heterogeneous communication links may drop packets with generally unequal probabilities, independently between different links. We develop a distributed linear-iterative algorithm in which nodes maintain and update certain values based on the corresponding values they successfully receive from their in-neighbors. We demonstrate that, even when communication links drop packets with unequal probabilities, the proposed algorithm allows nodes to asymptotically reach average-consensus almost surely, as long as the underlying (possibly directed) communication topology forms a strongly connected digraph. Additionally, we provide a bound on the algorithm convergence rate.", "authors": ["Christoforos N. Hadjicostis", "Alejandro D. Dominguez-Garcia", "Nitin H. Vaidya"], "n_citation": 10, "references": ["19b48a17-88c6-4a0e-b1ee-59aa27ae33e4", "5ae53fea-9ac4-42d4-832e-274ab11a9896", "74220ea8-4d43-495d-8faa-b3999d7cd605", "83065027-2abb-44b4-934e-e48686f7751f", "85c4f8fc-fbcd-45f3-b53c-7ebbe980c691", "860a3efc-800e-4e62-8200-7acf3f8d2b8d", "d9162547-fd7f-4605-855d-0a3173c4b08e"], "title": "Resilient average consensus in the presence of heterogeneous packet dropping links", "venue": "conference on decision and control", "year": 2012, "id": "908f0bb7-e545-4e95-841b-3fbb302d772a"}
{"authors": ["Gareth Nicholls", "Derrick G. Kourie", "Tinus Strauss"], "n_citation": 2, "title": "Sensitivity analysis of voronoi-based sensor deployment and reconfiguration algorithms", "venue": "South African Computer Journal", "year": 2009, "id": "8a162f64-c04f-4237-ae4d-a857fde8ea68"}
{"authors": ["Shuji Yamamura", "Akira Hirai", "Mitsuru Sato", "Masao Yamamoto", "Akira Naruse", "Kouichi Kumon"], "n_citation": 9, "references": ["2880a6a6-fb72-4239-b439-09a48712e560", "b3378314-5f33-4f1d-8f29-f82d923324f2"], "title": "Speeding Up Kernel Scheduler by Reducing Cache Misses", "venue": "usenix technical conference", "year": 2002, "id": "b1e0a2a8-e5fc-4b3f-893c-f0e020ce65f1"}
{"authors": ["Mitsuru Ohba"], "n_citation": 672, "references": ["1cf5646a-8046-4b85-b1fe-d89ff7785350", "8011feb7-177d-4e69-93c9-5e4ee0c21958"], "title": "Software reliability analysis models", "venue": "Ibm Journal of Research and Development", "year": 1984, "id": "f8ac536a-4fb9-4dee-8132-7d5930e90f84"}
{"abstract": "In this paper we present an extension of PROLOG using modal logic. A new deduction method is also given based on a rule closer to the classical inference rule of PROLOG.", "authors": ["L. Fari\u00f1as Del Cerro"], "n_citation": 135, "references": ["1df09b2f-b123-4ada-9345-85ce2da90299", "4120a1f1-f55e-4085-8900-7a5f910adcf5", "5279f677-3dcb-4463-a54e-b29f8f54c3d9", "b4bece4f-da6f-44b0-9e1e-5a662226edf5", "c2e54a08-5059-43dc-a4c1-a1c8572a1247", "eafea9c0-c5bf-4c99-976a-578e7335eebc"], "title": "MOLOG: A system that extends PROLOG with modal logic", "venue": "New Generation Computing", "year": 1986, "id": "82297db3-1b58-4432-ae58-7d93d18c2ab9"}
{"abstract": "Merging the virtual World Wide Web with nearby physical devices that are part of the Internet of Things gives anyone with a mobile device and the appropriate authorization the power to monitor or control anything.", "authors": ["Roy Want", "Bill N. Schilit", "Scott Jenson"], "n_citation": 131, "references": ["122fd30d-c2de-47c5-9547-18619054bfba", "83da4728-c6b6-4df2-9862-e4a0f909c8d2", "8ff8493c-77d6-4ccc-a0bf-b1f6dc4b17a7", "d5ec4f5c-2304-4286-8724-c8caf17ff69d", "d8a23e50-4fd9-40c0-b64e-f71f6c254621", "fc13a4dc-37dd-440d-bd35-2ec46ce9c8b6"], "title": "Enabling the Internet of Things", "venue": "IEEE Computer", "year": 2015, "id": "c2b34e3f-e6e3-4002-b98e-65703762b3e1"}
{"abstract": "A passive system with positive definite storage function is not only stable but is intrinsically robustly stable with respect to a wide class of feedback disturbances. For linear time invariant systems, passivity can be characterized either in time domain or in frequency domain from positive realness. This paper aims to generalize this concept to continuous-time switched linear systems. Analysis is performed by taking into account state dependent and arbitrary time dependent switching functions with a prescribed dwell time. A control design problem related to the determination of a switching strategy, based upon output measurements, that renders a switched linear system passive is also considered. The methods introduced in the paper can be effectively applied to the control of the duty cycle and passivation of switched circuits.", "authors": ["Jos\u00e9 Claudio Geromel", "Patrizio Colaneri", "Paolo Bolzern"], "n_citation": 34, "references": ["0fd94cd6-3702-47e8-be09-b6525c95e335", "1450f701-7037-4afb-96b7-6b55e01e0164", "158914a1-2368-4da3-a06c-e64eded8dd83", "3c08dfb3-dd2a-40bf-9626-14797c3b32de", "4727ecce-8b21-40ee-b703-9e16ae5f06b0", "485a8485-2e88-4e49-8dff-cdcec121fec6", "759caabd-d4f2-4ef0-9a87-ab28b5ca2433", "93135584-ab8f-4f79-b842-063b6589cbaa", "b5b282bc-6c4f-4cff-84fb-d50c1f685f30", "dcc1de50-9890-44e0-9c25-d0a1a3bef43f", "fe3b2b0c-ca95-4d58-9762-96a6386f39c0"], "title": "Passivity of switched linear systems: Analysis and control design", "venue": "Systems & Control Letters", "year": 2012, "id": "422f323e-ecba-4f81-98b7-3a5badcc2e6d"}
{"abstract": "In this paper, an approach for establishing and managing trust among the interaction partners (i.e. users, nodes and/or services) in a service-oriented Grid environment is presented. The approach is based on a flexible trust model and system architecture for collecting and managing multidimensional trust values. Both identity and behaviour trust of the interaction partners are considered, and different sources are used to determine the overall trust value of an interaction partner. A proposal for establishing the first trust between interaction partners is made, and the possibility to continuously monitor the partners\u2019 behaviour trust during an interaction is provided. The proposed trust architecture can be configured to the domain specific trust requirements by the use of several separate trust profiles covering the entire lifecycle of trust establishment and management.", "authors": ["Elvis Papalilo", "Thomas Friese", "Matthew Smith", "Bernd Freisleben"], "n_citation": 50, "references": ["08fe04a7-0e83-470e-bff7-88849510d72e", "2e1009a7-6f94-4cc5-b336-7f5668a0debd", "31596285-5e90-4a05-819e-ab19aca4fd41", "5280c6a1-fa36-428b-9dc8-a98bd3e64a0b", "69bc1570-39d9-4d00-a367-b97d2e4411d8", "6db11795-8fcf-4063-903a-1462ed757725", "c2f67467-3138-4d37-a743-10340dc3ea44", "e5628785-8f40-4d70-87c1-ab3b7d0ff0f9"], "title": "Trust shaping: adapting trust establishment and management to application requirements in a service-oriented grid environment", "venue": "grid and cooperative computing", "year": 2005, "id": "1b9e5851-fdf3-4967-951e-634e061e94d0"}
{"abstract": "In Computer Science, we have developed a vibrant conference culture, which has served us well thus far. However, with the growth of our field, the number of submissions to many conferences has sky-rocketed, leading to a downward spiral in reviewing quality and author satisfaction. This article proposes to break this downward spiral for the database community through JDMR, a journal for short \"conference style\" papers with rapid turn-around. An initial step toward this vision has been taken by VLDB.", "authors": ["H. V. Jagadish"], "n_citation": 50, "references": ["854cc9bc-819d-45be-b839-61ef9ad7afe0", "f69a53e1-fafd-47ae-9c19-37d79ae52870"], "title": "The conference reviewing crisis and a proposed solution", "venue": "international conference on management of data", "year": 2008, "id": "4c8644ed-2677-4c48-97a7-0f5421094bd3"}
{"abstract": "A mobile robot exploring an unknown environment has no absolute frame of reference for its position, other than features it detects through its sensors. Using distinguishable landmarks is one possible approach, but it requires solving the object recognition problem. In particular, when the robot uses two-dimensional laser range scans for localization, it is difficult to accurately detect and localize landmarks in the environment (such as corners and occlusions) from the range scans.#R##N##R##N#In this paper, we develop two new iterative algorithms to register a range scan to a previous scan so as to compute relative robot positions in an unknown environment, that avoid the above problems. The first algorithm is based on matching data points with tangent directions in two scans and minimizing a distance function in order to solve the displacement between the scans. The second algorithm establishes correspondences between points in the two scans and then solves the point-to-point least-squares problem to compute the relative pose of the two scans. Our methods work in curved environments and can handle partial occlusions by rejecting outliers.", "authors": ["Feng Lu", "Evangelos E. Milios"], "n_citation": 858, "references": ["0be3b6cd-1652-425a-a9d1-313f7a2847cf", "127220e0-97ac-4c89-8f0c-fdad93cad593", "275f6cb0-519b-4b52-b25c-763d56458657", "2a796cad-be72-4da5-ba29-189974f6f408", "3cb8ca46-0e98-4736-8d99-6f181cb2f7d9", "52bccc7d-ea2e-41ad-8357-2dd532191fea", "91630a3c-69ae-45bd-8097-08a9d7d6e1e8", "a7a01782-8e14-4dd6-9336-60718abbfc0b", "afb56c94-0a99-4b26-9ba1-da74571342d9", "b7980aaa-989f-4133-8a28-5d4c1385bdd7", "c1e9ee00-1f45-4857-b748-4651fe741741", "d247d6d1-bc44-4a3f-8149-9c4ef550af09", "f83224dc-6d77-4797-81fa-c641905da575"], "title": "Robot Pose Estimation in Unknown Environments by Matching 2D Range Scans", "venue": "Journal of Intelligent and Robotic Systems", "year": 1997, "id": "12fff395-a82d-4dee-901d-92588447b389"}
{"abstract": "In this paper, we examine the problem of robust nonblocking supervisory control. In the problem considered here, the exact model of the plant is not known but is assumed to be among a finite set of possible models. For each plant model a legal marked behavior is assumed given. We extend previous results for the case of control with full observation to the case of control under partial observation where only a subset of events are observable. Furthermore, we remove the limitations of previous results on ensuring the nonblocking property of the plant under supervision. We characterize the entire set of solutions of the robust control problem and obtain a set of necessary and sufficient conditions for the existence of a solution for the problem. As an illustrative example, we use our results on robust control to solve a fault recovery problem.", "authors": ["Anooshiravan Saboori", "Shahin Hashtrudi Zad"], "n_citation": 50, "references": ["7450e41b-e72e-429c-b230-c219ee7fb046", "9083b7f3-845c-4712-9ff2-f2d601866683", "93eb35f7-5ef5-403a-a3b0-d4833c8ecad9"], "title": "Robust nonblocking supervisory control of discrete-event systems under partial observation \u2606", "venue": "Systems & Control Letters", "year": 2006, "id": "b1a95fe3-f5a2-4df6-930f-05d6152482ef"}
{"abstract": "We introduce a new approach to computing answer sets of logic programs, based on concepts from constraint processing (CSP) and satisfiability checking (SAT). The idea is to view inferences in answer set programming (ASP) as unit propagation on no-goods. This provides us with a uniform constraint-based framework for the different kinds of inferences in ASP. It also allows us to apply advanced techniques from the areas of CSP and SAT. We have implemented our approach in the new ASP solver clasp. Our experiments show that the approach is competitive with state-of-the-art ASP solvers.", "authors": ["Martin Gebser", "Benjamin Kaufmann", "Andr\u00e9 Neumann", "Torsten Schaub"], "n_citation": 393, "references": ["09c19ddd-b0a4-477d-bc0b-025882bca35a", "110d9d01-b501-4b68-88cd-2848da1174f5", "185f7384-2349-4b98-9c48-c366b846689a", "29e114a8-9242-4ba4-ae98-417fc5f9b11a", "349b4cb0-7d84-4aa8-bd0c-055804f8db1f", "4d4ebe56-acba-49f8-aaa6-14ece5133c9f", "4f502ef8-9230-4364-abfe-1f1d5b442b27", "57206df8-7b58-47ef-ae53-92f89db91a50", "5c50a384-c52c-4389-bee4-fc0b4cee9c7b", "725a98f5-1d13-441e-9792-60abba5f4e0b", "81768cb8-9fec-482f-afed-539ffcfb3bb6", "8dc19c25-ebd9-4179-a13f-ebc3fa0f789b", "95b95bb7-512e-4092-a105-665c62433331", "983de3bb-1318-4cc3-b945-91b9096beac2", "9d826763-53f1-4bfd-a7f9-6a27fc26a8ae", "e0b006b1-c755-4c64-9b28-b06245e269a8"], "title": "Conflict-driven answer set solving", "venue": "international joint conference on artificial intelligence", "year": 2007, "id": "2ee67768-863c-4c2b-99a7-ab341676ec37"}
{"abstract": "The GQM+Strategies approach extends the goal/question/metric paradigm for measuring the success or failure of goals and strategies, adding enterprise-wide support for determining action on the basis of measurement results. An organization can thus integrate its measurement program across all levels.", "authors": ["Victor R. Basili", "Mikael Lindvall", "Myrna Regardie", "Carolyn B. Seaman", "Jens Heidrich", "J\u00fcrgen M\u00fcnch", "H. Dieter Rombach", "Adam Trendowicz"], "n_citation": 150, "references": ["15c08d0f-e31f-4c00-a028-e80a966055ff", "367c0852-c2d9-4555-8331-4afe2e96a910"], "title": "Linking Software Development and Business Strategy Through Measurement", "venue": "IEEE Computer", "year": 2010, "id": "6891735d-1664-4f04-9a41-cfb233f9b378"}
{"abstract": "Our research addresses the problem of error correction in speechuser interfaces. Previous work hypothesized that switching modalitycould speed up interactive correction of recognition errors(so-called multimodal error correction). We present a user studythat compares, on a dictation task, multimodal error correctionwith conventional interactive correction, such as speaking again,choosing Tom a list, and keyboard input. Results show thatmultimodal correction is faster than conventional correctionwithout keyboard input, but slower than correction by typing forusers with good typing skills. Furthermore, while users initiallyprefer speech, they learn to avoid ineffective correctionmodalities with experience. To extrapolate results from this userstudy we developed a performance model of multimodal interactionthat predicts input speed including time needed for errorcorrection. We apply the model to estimate the impact ofrecognition technology improvements on correction speeds and theinfluence of recognition accuracy and correction method on theproductivity of dictation systems. Our model is a first steptowards formalizing multimodal (recognition-based) interaction.", "authors": ["Bernhard Suhm", "Brad A. Myers", "Alex Waibel"], "n_citation": 87, "references": ["0f05efa4-1183-4c0a-9c3d-47b17ffacafa", "40962eb0-a08b-49d5-a10b-4a9540a28c10", "5cf3ca44-3fc7-4e3a-82e8-fb88bb2c02f9", "89341842-7f66-4add-90b9-ed52e120f546", "a25e0d38-9a3b-4c9d-b0cd-2b895c9dea62", "c0cc908b-c799-46b2-84ab-8bf81aaba439", "cdc024d3-d60a-4942-aa4d-b955fa507297", "e9a3b1ae-3e77-4db7-8ca6-ddfca50b8366"], "title": "Model-based and empirical evaluation of multimodal interactive error correction", "venue": "human factors in computing systems", "year": 1999, "id": "3a8f866d-b291-44dc-b61c-987f8f73463d"}
{"abstract": "Dynamic migration of lightweight threads supports both data locality and load balancing. However, migrating threads that contain pointers referencing data in both the stack and heap remains an open problem. We describe a technique by which threads with pointers referencing both stack and non shared heap data can be migrated such that the pointers remain valid after migration. As a result, threads containing pointers can now be migrated between processors in a homogeneous distributed memory environment.", "authors": ["David Cronk", "Matthew Haines", "Piyush Mehrotra"], "n_citation": 50, "references": ["553e719c-81cd-4191-9c68-f0adf7c15361", "7102c105-9ebc-435a-9b21-5324245562cc", "b40c2a5e-1107-402f-ab8b-9df3b971b7d1", "c1f612c2-1906-4787-8206-b8447cdac4f7", "cfbcc46b-765c-4e3a-82fd-cb602cbf71db", "ea5e27a1-5205-4e02-a9b8-569b1fbc3891"], "title": "Thread migration in the presence of pointers", "venue": "hawaii international conference on system sciences", "year": 1997, "id": "ef72a2b9-cae3-439d-bbb9-f0939beded78"}
{"authors": ["Mario S\u00fcdholt"], "n_citation": 7, "title": "The Transformational Derivation of Parallel Programs using Data-Distribution Algebras and Skeletons", "venue": "", "year": 1997, "id": "c79aaf44-44ab-4f3c-9615-4823018d2c36"}
{"abstract": "Estimating the values of the parameter estimates of econometric functions (maximum likelihood functions or nonlinear least squares functions) are often challenging global optimization problems. Determining the global optimum for these functions is necessary to understand economic behavior and to develop effective economic policies. These functions often have flat surfaces or surfaces characterized by many local optima. Classical deterministic optimization methods often do not yield successful results. For that reason, stochastic optimization methods are becoming widely used in econometrics. Selected stochastic methods are applied to two difficult econometric functions to determine if they might be useful in estimating the parameters of these functions.", "authors": ["Max E. Jerrell", "Wendy Campione"], "n_citation": 4, "references": ["9b80e173-2d0d-4e2d-8cd0-0fcfe230fd81"], "title": "Global Optimization of Econometric Functions", "venue": "Journal of Global Optimization", "year": 2001, "id": "f4d7d98a-02f6-440e-92ef-08169d4b09f7"}
{"authors": ["Bryan Carpenter", "Yuh-Jye Chang", "Geoffrey C. Fox", "Donald Leskiw", "Xiaoming Li"], "n_citation": 78, "title": "Experiments with \u2018HP Java\u2019", "venue": "Concurrency and Computation: Practice and Experience", "year": 1997, "id": "9e5bb85a-9faa-4ff5-b809-6c7ace599c62"}
{"abstract": "This paper presents an approach to object view management for relational databases. Such a view mechanism makes it possible for users to transparently work with data in a relational database as if it was stored in an object-oriented (OO) database. A query against the object view is translated to one or several queries against the relational database. The results of these queries are then processed to form an answer to the initial query. The approach is not restricted to a \u2018pure\u2019 object view mechanism for the relational data, since the object view can also store its own data and methods. Therefore it must be possible to process queries that combine local data residing in the object view with data retrieved from the relational database. We discuss the key issues when object views of relational databases are developed, namely: how to map relational structures to sub-type/supertype hierarchies in the view, how to represent relational database access in OO query plans, how to provide the concept of object identity in the view, how to handle the fact that the extension of types in the view depends on the state of the relational database, and how to process and optimize queries against the object view. The results are based on experiences from a running prototype implementation.", "authors": ["Gustav Fahl", "Tore Risch"], "n_citation": 109, "references": ["041c95ec-5cbb-4783-aa7b-54b763ccf4ed", "0e235074-291c-4cd9-a8ab-bf7a61543d40", "0fb6eb2a-acdb-4c52-a989-2895ed0d1231", "205a0c61-09b0-4cda-a646-f6273d9df8b9", "25ec851b-cec3-46a2-b4e5-45d214ed8c50", "2a8c3a66-9500-4104-8af0-29bcadf2d620", "2a9a8d22-7889-4a1c-988d-30e54b42bb7d", "35af9e2f-71b6-4431-b60b-4c12d8954b48", "3a07e7e1-87eb-451c-bfcf-f7fe28637b0a", "41519ed3-096f-46d2-8b16-964747e00d71", "4c57590f-ddc3-4758-a82e-5cae5a39131a", "4d0b2c80-d6aa-4119-93b2-cbf18c8a1738", "53b4c61c-2a7a-41f3-80e9-09d114412fbb", "555341e5-00a1-42f2-8a84-3ecb3e7b027a", "5582c634-3ff1-4afd-acbd-e8f52a8f182d", "59a405f9-d274-4d56-9627-e0eeed360d58", "5e44f1c2-61c0-4f63-b0e8-a25742731049", "61bed672-52fc-4377-8f79-d2baf0911b3a", "626243a7-eb16-4150-918d-bacfdb5c95d9", "646cfa80-435c-4c23-87b7-134ffc5390a3", "6787a5d1-2f1d-4453-be93-94b2dcd752a8", "6afc7790-4048-4822-8944-a37ea12042e5", "6c11fe7d-af64-464a-ada5-91f85d668138", "6fe5bf24-41bd-4631-80ae-a607e4c40e5d", "8292e051-b7df-4679-b1a0-079a612537f8", "856cf967-3d05-4b08-8154-313960562932", "88eff688-2f66-4c24-834e-da035f2265fd", "9c45cf69-2577-4982-a362-64a3ec3df9db", "e904055a-c6b3-4f88-a11e-27cd5eb7984c", "e9b71d47-cc8f-433d-a2cf-8bbdecd268da", "f0926b94-87ac-4fb7-8086-9143bdc10fe9", "ff58ac14-d0ce-4212-b47e-910789b1e3e3"], "title": "Query processing over object views of relational data", "venue": "very large data bases", "year": 1997, "id": "6c7dd1a2-fdb7-4f44-9e5a-c766aa906dfa"}
{"abstract": "Domain-specific languages and models are increasingly used within general-purpose host languages. While traditional profiling tools perform well on host language code itself, they often fail to provide meaningful results if the developers start to build and use abstractions on top of the host language. In this paper we motivate the need for dedicated profiling tools with three different case studies. Furthermore, we present an infrastructure that enables developers to quickly prototype new profilers for their domain-specific languages and models.", "authors": ["Alexandre Bergel", "Oscar Nierstrasz", "Lukas Renggli", "Jorge Ressia"], "n_citation": 50, "references": ["089c6d15-0363-4b1a-9f64-d2566a1879a3", "1b549fb0-6a2a-412c-87d7-55da8b49d89b", "35cffa61-95ae-4485-8401-eb86dda3e79d", "55aed14e-b9e3-4b03-9637-5b0ae22f88b5", "75d04460-f916-4e4a-a5bf-ba4c5cbb6048", "a419b38c-6e78-4517-b612-c8e7212f895e", "c308e58e-2ebf-42b7-a99f-b3ebf0c7ac8f", "c65c869b-7322-475f-bfdf-77bcd1f96348", "d511bd82-5589-41bf-893b-8292c1846722", "d82dc4e9-c08d-41b0-8a67-dc05c6220b26", "dc9aef9a-ad3a-40a2-92e5-edd9861daaa6", "e0681651-916b-43ab-b57d-aec19ec79a0e", "fd08e60a-2a13-4131-b644-557b12fd4e79"], "title": "Domain-specific profiling", "venue": "", "year": 2011, "id": "44f8bc9d-641b-4ae7-8892-7dacbaf61d28"}
{"authors": ["Gert Smolka"], "n_citation": 7, "title": "Concurrent Constraint Programming Based on Functional Programming (Extended Abstract)", "venue": "european symposium on programming", "year": 1998, "id": "d0ca7d10-55a4-4824-b73c-c61d0c0d7e6c"}
{"abstract": "Abstract   The paper derives a set of fundamental issues from a definition of collaboration, introduces two major approaches to human-computer collaboration, and surveys each approach, showing how it formulates and addresses the issues. It concludes by proposing some themes that should characterize a unified approach to human-computer collaboration.", "authors": ["Loren G. Terveen"], "n_citation": 161, "references": ["01075977-f6ea-4319-9200-74e4e56c7a8e", "0b40caee-5770-4118-a9f2-ff464948f7d1", "11a3323a-c98d-48b9-8641-993ce5e02b36", "163818e1-a586-4a6b-9b4f-4eb6a99adac1", "1ab49cb1-1c31-416f-9b5a-f129cc2476c8", "1c562c40-a64d-454b-90c1-9b0800effc50", "225a4c96-9ee9-4303-8464-cd8f76e115c0", "22b8a74a-a8b1-4268-a7cb-726ceae5da50", "253352f4-6f25-4ad7-bee4-c76107b3fa5e", "26fef6f9-b352-4266-a01b-90ba8eadff5b", "2e37a399-5479-44f4-90c3-16417ffc78e4", "2f71fdf4-e3fb-4d44-b519-a672dd9fe8b1", "2fac1450-0358-4e5a-b3d3-f0e923049021", "300c92a4-8f19-43f0-99ba-98886bde5e39", "3099a1d7-f898-4238-b7fd-0828c34788cc", "359bd98a-79e3-4a8a-96d0-517276d79102", "4e5ce721-e114-4e34-8d18-21ab0e368315", "5bd96bfc-e506-4f29-8688-6d5bce029feb", "66fe0285-64b2-466e-96ba-fbf5642ef1fe", "6b0cc20a-98fc-48e1-92a9-8ba48631a40b", "6b82909a-5438-43c1-8b05-6b890f787eab", "6fc12b1e-e8b8-42bc-bddb-5daed65b2c8a", "83bea0dc-8682-453b-a4c8-f37648a5a00b", "85b6f5fe-b8ae-459a-9887-3e30c7b4f39e", "886333bd-38b4-4816-a658-a3ab02825006", "8f6c698c-e643-4a6f-902a-63ed999f45e8", "8fd9aa19-5b11-48a2-a8dc-4cc75c36d8eb", "925d2faa-856e-4fbb-9ab3-4eab481fae59", "99353927-870f-4029-80e9-cc37473491fc", "994af976-7a52-4968-8067-cf96184c9fe5", "9b356229-f03a-467a-b9ce-6f586e33d61d", "a089f1f1-8a15-47ec-82c8-ab2b15c660ce", "a6d82d35-65cc-492a-ae41-57961eea38ea", "a7aaf86c-020b-405c-b415-6682fb78e4fc", "b75c0b61-7d06-4587-be47-10ca339751c8", "c025faeb-6f41-4fe7-9789-d62428a31647", "c73deff3-44f6-453c-b273-ff3238fd59f1", "cae415fb-b541-4b8f-8ce8-a69554b4481f", "cb07e5d7-ea22-422c-b507-82ea3f87ca4c", "dddec493-2b56-4ac1-853d-203f0ba812d1", "df5af344-3a10-417b-8f9a-1cc7fdf2039c", "e181b2a4-fcd4-4137-a96d-479b7c83a71a", "e85b46cd-c77f-4d96-9682-2f0b50732ff0", "e927699f-c24e-49fa-9cff-db1e77776285", "e9a506de-f3d4-4154-9ecc-84f5b6e7588c", "eb5be311-c7ba-4fc9-94c7-64e7cd4dd4bf", "f0a5e86a-36b0-4c47-b085-0d35f15e9e8e", "f6c19602-030d-4285-86d6-be2a017c442b", "f77bd319-32b8-4e2d-9d42-f765b0d7d694", "f96f8277-b658-4d7b-9f9b-9f66e8692ec6", "fab24135-f4e2-44c5-ab9f-676b726f598d", "fbca8108-2171-4212-b479-23c3837bc28e", "fddc36b2-908a-4c3c-bb3d-1884e8afc93a"], "title": "Overview of human-computer collaboration", "venue": "Knowledge Based Systems", "year": 1995, "id": "15437b86-a607-481e-ba01-7c0fa1e0df6e"}
{"abstract": "In this paper we introduce the concept of privacy preserving data mining. In our model, two parties owning confidential databases wish to run a data mining algorithm on the union of their databases, without revealing any unnecessary information. This problem has many practical and important applications, such as in medical research with confidential patient records.#R##N##R##N#Data mining algorithms are usually complex, especially as the size of the input is measured in megabytes, if not gigabytes. A generic secure multi-party computation solution, based on evaluation of a circuit computing the algorithm on the entire input, is therefore of no practical use. We focus on the problem of decision tree learning and use ID3, a popular and widely used algorithm for this problem. We present a solution that is considerably more efficient than generic solutions. It demands very few rounds of communication and reasonable bandwidth. In our solution, each party performs by itself a computation of the same order as computing the ID3 algorithm for its own database. The results are then combined using efficient cryptographic protocols, whose overhead is only logarithmic in the number of transactions in the databases. We feel that our result is a substantial contribution, demonstrating that secure multi-party computation can be made practical, even for complex problems and large inputs.", "authors": ["Yehuda Lindell", "Benny Pinkas"], "n_citation": 1818, "references": ["242b68c8-afc6-4f8c-b807-06f3cd248603", "2616922c-ee50-4f59-a5b1-9feb67f3d2d3", "429ba40e-39fc-477f-9d75-0b7325f09ea5", "689a1bfb-3ce0-483e-9db6-f4514ee2c600", "7a1624d7-9b8e-44fd-a778-e0d3179b509a", "b49c1e2b-0cd0-4950-a724-00c698e5b49d", "fbf7f7bc-ac0a-4ce5-b21c-553c86d76380"], "title": "Privacy Preserving Data Mining", "venue": "international cryptology conference", "year": 2000, "id": "5fda66d7-3834-4c0d-b2e3-e2b02bb9b318"}
{"abstract": "Different structures are used in peer-to-peer networks to represent their inherently distributed, self-organized, and decentralized memory structure. In this paper, a simple range-queriable distributed data structure, called RAQ, is proposed to efficiently support exact match and range queries over multi-dimensional data. In RAQ, the key space is partitioned among the network with n nodes, in which each element has links to O(log n) other elements. We will show that the look-up query for a specified key can be done via O(log n) message passing. Also, RAQ handles range-queries in at most O(log n) communication steps.", "authors": ["Hamid Nazerzadeh", "Mohammad Ghodsi"], "n_citation": 16, "references": ["0dbba6d8-e395-4cc1-8139-d1b4fd7673d4", "198673ec-2687-42ba-bd7b-4009117d4204", "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4", "51a6374f-d139-4705-8670-1f78d096b890", "6e6cac85-1ca8-4d49-8e16-aa3d353fc20a", "80f9e322-d38f-44cd-859c-9067aa4a2dee", "9c0f911c-c9ca-483b-9b35-06ae4ce7c121", "d06f8723-1b89-4684-99c9-c1045ddfb85c", "dc784ca2-3a02-40a2-a311-e9dd3e2c91e6", "e1263ada-afda-498c-a37d-9b545293118a", "f14df1ed-e3e9-4348-9040-fc06e3411b95"], "title": "RAQ: a range-queriable distributed data structure", "venue": "conference on current trends in theory and practice of informatics", "year": 2005, "id": "91bc601c-f99a-448c-987e-99ec475e2dfa"}
{"abstract": "On February 2, 1999, we completed the factorization of the 140-digit number RSA-140 with the help of the Number Field Sieve factoring method (NFS). This is a new general factoring record. The previous record was established on April 10, 1996 by the factorization of the 130-digit number RSA-130, also with the help of NFS. The amount of computing time spent on RSA-140 was roughly twice that needed for RSA-130, about half of what could be expected from a straightforward extrapolation of the computing time spent on factoring RSA-130. The speed-up can be attributed to a new polynomial selection method for NFS which will be sketched in this paper.", "authors": ["Stefania Cavallar", "Bruce Dodson", "Arjen K. Lenstra", "Paul C. Leyland", "W.M. Lioen", "Peter L. Montgomery", "Brian Murphy", "Herman J. J. te Riele", "Paul Zimmermann"], "n_citation": 158, "references": ["029a7ade-69b7-4d78-b49b-a0307ac10e9d", "11d55af6-7b59-4e13-9b17-d22f08e46c26", "1bf85389-f72f-40c4-8fb8-e7dacd1dd462", "3fb43b00-905c-4a08-934d-198ea4eb66c3", "41620def-efb3-4031-af9a-9c983818efbc", "6661fd97-92fc-4378-9320-9450ef654afb", "9a625a62-a627-4eb1-8e21-f983da5d577c", "a8760d3d-649e-4947-bd4a-153a9265312e", "d759a7b9-433c-4bc5-8b1d-fbb114bd527c", "d8a4ee81-1b94-470b-923c-8f1005735e58", "ddb3c5ff-cbe6-42d1-a2ea-6499f84fd40e", "ed883afd-539d-4671-beb4-2f4bd304fee4"], "title": "Factorization of RSA-140 Using the Number Field Sieve", "venue": "international cryptology conference", "year": 1999, "id": "5b18767e-41df-4a56-aea5-6bf69575b1fd"}
{"abstract": "Building systems such as heating, air quality control and refrigeration operate independently of each other and frequently result in temporally correlated energy demand surges. As peak power prices are 200\u2013400 times that of the nominal rate, this uncoordinated activity is both expensive and operationally inefficient. We present an approach to fine-grained coordination of energy demand by scheduling the control systems within a constrained peak while ensuring custom climate environments are facilitated. The peak constraint is minimized for energy efficiency, while we provide feasibility conditions for the constraint to be realizable by a scheduling policy for the control systems. The physical systems are then coordinated by the scheduling controller so as both the peak constraint and the climate/safety constraint are satisfied. We also introduce a simple scheduling approach called lazy scheduling. The proposed control and scheduling strategy is implemented in simulation examples from small to large scales, which show that it can achieve significant peak demand reduction while being efficient and scalable.", "authors": ["Truong X. Nghiem", "Madhur Behl", "Rahul Mangharam", "George J. Pappas"], "n_citation": 52, "references": ["17e99a9e-4979-47b1-83f9-65c427d08c42", "1dfddb0a-c28f-4852-af75-d6c8f3c971a4", "3e684879-1598-4cfe-b4be-0cb7b2d5df90", "9130421e-5ead-41b2-9d1f-1aa250e44a30", "91809d56-c8cf-47ed-8b62-bf767c8cc790"], "title": "Green scheduling of control systems for peak demand reduction", "venue": "conference on decision and control", "year": 2011, "id": "25e05223-a31e-441a-88e2-c6ba81b9ccb5"}
{"abstract": "In this paper we develop a graph-oriented model for dealing with broadcasting in radio networks. Using this model, optimality in broadcasting protocols is defined, and it is shown that the problem of finding an optimal protocol is NP-hard. A polynomial time algorithm is proposed under which a channel is assigned to nodes from global, multiple-source broadcasting considerations. In particular, nodes participating in the broadcast do not interfere with each other's transmissions, but otherwise simultaneous channel reuse is permitted. Protocol implementations of this approach by frequency division and by time division are given. It is shown that, using these protocols, bounded delay for broadcasted messages can be guaranteed.", "authors": ["Imrich Chlamtac", "Shay Kutten"], "n_citation": 365, "references": ["9fd17ea2-2c88-45ea-881e-37942eab4206", "ac834e53-2ae6-480e-a10a-80a9191fbcd1", "b9148319-f08f-46cf-8f97-f88c636f7550", "eff1b427-33d8-47e6-994c-e4f7340df81f"], "title": "On Broadcasting in Radio Networks--Problem Analysis and Protocol Design", "venue": "IEEE Transactions on Communications", "year": 1985, "id": "af8c297b-aa44-4bad-94c7-049b17301fc4"}
{"abstract": "The medical milieu is an open environment characterized by a variety of distributed, heterogeneous and autonomous information resources. Coordination, cooperation and exchange of information is important to the medical community. Efficient storage and acquisition of medical knowledge requires structured and standardized organization of data. We design a new ontology, called Generic Human Disease Ontology (GHDO), for the representation of knowledge regarding human diseases. The concepts of the GHDO ontology are organized into the following four 'dimensions': Disease Types, Symptoms, Causes and Treatments. We align and merge existing ontologies against the four dimensions of GHDO. The designed ontology makes our query system suitable for different user categories. The process of problem decomposition into smaller sub-problems within a multi-agent system becomes much easier as well. We also design a multi-agent system framework over different information resources. The multi-agent system uses the common GHDO ontology for query formulation, information retrieval and information integration. This intelligent dynamic system provides opportunities to collect information from multiple information resources, to share data efficiently and to integrate and manage scientific results in a timely manner.", "authors": ["Maja Hadzic", "Elizabeth Chang"], "n_citation": 24, "references": ["482bf419-1fcf-4fed-b042-e0229faa8488", "4939cf70-8688-4c62-8b33-3cf306a30c62", "d1f0c7b0-57ee-4d0f-9798-9cb8f23731fe", "d29f54d3-28f6-4bb8-a8f9-e847ce323ff1", "d31bda8c-4ae3-4fdd-a386-88c8b6579d4d", "d58cbe65-2411-4e55-b92e-67201b6e9c1d", "da1b42c0-4d79-4ad0-9b3f-8965e9486874", "ef3b30a6-5e79-4e5f-9e00-c62bf80e0dee", "f2bcf168-865a-4a8b-b80f-66bf3ba07854"], "title": "Ontology-based Multi-agent Systems Support Human Disease Study and Control", "venue": "", "year": 2005, "id": "21b1fa63-95cb-48ae-9c15-3744b7f11485"}
{"abstract": "Modern networked computing systems follow scenarios that differ from those modeled by classical Turing machines. For example, their architecture and functionality may change over time as components enter or disappear. Also, as a rule their components interact with each other and with the environment at unpredictable times and in unpredictable manners, and they evolve in ways that are not pre-programmed. Finally, although the life span of the individual components may be finite, the life span of the systems as a whole is practically unlimited. The examples range from families of cognitive automata to (models of) the Internet and to communities of intelligent communicating agents.We present several models for describing the computational behaviour of evolving interactive systems, in order to characterize their computational power and efficiency. The analysis leads to new models of computation, including 'interactive' Turing machines (ITM's) with advice and new, natural characterizations of non-uniform complexity classes. We will argue that ITM's with advice can serve as an adequate reference model for capturing the essence of computations by evolving interactive systems, showing that 'in theory' the latter are provably more powerful than classical systems.", "authors": ["Jan van Leeuwen", "Jir\u00ed Wiedermann"], "n_citation": 57, "references": ["0ccf5cf4-f364-4fd7-a4a7-48251a231e28", "5cbdc1f4-1d73-4d7e-9a3e-cb85323feb92", "7ab1d2d4-4003-49dd-9560-fa9d537ebed3", "89253643-14dd-4793-b95a-a54bc59e72ff", "9abd9936-3022-4a10-9aad-2937c08fb892", "d38f2f4c-3436-4f14-a76b-f96aa46f5d51", "efb74327-de5f-4c62-a171-6bd90464e071", "ffa5c31d-4e7e-4327-9ed1-462d76d91429"], "title": "Beyond the Turing Limit: Evolving Interactive Systems", "venue": "conference on current trends in theory and practice of informatics", "year": 2001, "id": "b7025e3a-c929-4449-bcac-22481c48386f"}
{"abstract": "Speech recognition is formulated as a problem of maximum likelihood decoding. This formulation requires statistical models of the speech production process. In this paper, we describe a number of statistical models for use in speech recognition. We give special attention to determining the parameters for such models from sparse data. We also describe two decoding methods, one appropriate for constrained artificial languages and one appropriate for more realistic decoding tasks. To illustrate the usefulness of the methods described, we review a number of decoding results that have been obtained with them.", "authors": ["Lalit R. Bahl", "Frederick Jelinek", "Robert L. Mercer"], "n_citation": 1171, "references": ["6488423a-bf2b-4108-9a85-0b076f516b4a", "6c3aaece-f11a-40bd-a0ff-143dfd080b04", "9850401b-e764-4138-834a-47adc3fa3186", "b00b8256-8309-46b8-90da-af167e69551c", "c487851e-0635-41a0-975d-4059a479d3ae", "ce87b171-daac-448a-9844-5169a017a172"], "title": "A Maximum Likelihood Approach to Continuous Speech Recognition", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 1983, "id": "067692a8-da25-4aab-844b-8c164ecdd3e1"}
{"abstract": "We investigate the decidability and complexity of various model checking problems over one-counter automata. More specifically, we consider succinct one-counter automata, in which additive updates are encoded in binary, as well as parametric one-counter automata, in which additive updates may be given as unspecified parameters. We fully determine the complexity of model checking these automata against CTL, LTL, and modal \u00b5-calculus specifications.", "authors": ["Stefan G\u00f6ller", "Christoph Haase", "Jo\u00ebl Ouaknine", "James Worrell"], "n_citation": 50, "references": ["0a0d8927-5e54-4716-bf66-7c654e432159", "0bdc62cf-ca60-495c-b3be-9ea4ae44ff61", "252b9e3e-4e30-426b-b4fc-2859b4e5503c", "4138a093-adda-4611-930f-fac07e2177f8", "47c9336f-9b26-409b-8630-d4d835d9ec79", "585f1202-6edd-4b39-a16d-84076d494ac6", "63b1abab-8743-49f0-9c21-45622d243557", "680a7e26-b85b-4603-afd6-c8b21926879d", "6855b4aa-f300-413a-b1f7-cd634ce42c56", "79c92a70-6a00-401a-a62b-18649e48d490", "8080b041-a0ae-4303-a808-7c2cbce418bf", "933797ff-58cd-4d68-afd4-0572a7cad0ec", "99303c22-6ab5-4980-9294-c96a030d32b1", "ae3fa5fd-a9c0-4a72-92e9-963b328640b6", "c079ab37-9fb4-4c06-aff5-d13a9a854984", "cd192c55-ae65-4c98-9345-4b6dc79af008", "ecef7deb-9477-4847-8893-6fdd9aa45faa", "eec17aff-5016-4af3-a006-5249f2e9b422"], "title": "Model checking succinct and parametric one-counter automata", "venue": "international colloquium on automata languages and programming", "year": 2010, "id": "f80b96f3-a257-4b71-ad57-baba996876f7"}
{"abstract": "Ensembles of learnt models constitute one of the main current directions in machine learning and data mining. Ensembles allow us to achieve higher accuracy, which is often not achievable with single models. It was shown theoretically and experimentally that in order for an ensemble to be effective, it should consist of base classifiers that have diversity in their predictions. One technique, which proved to be effective for constructing an ensemble of diverse base classifiers, is the use of different feature subsets, or so-called ensemble feature selection. Many ensemble feature selection strategies incorporate diversity as an objective in the search for the best collection of feature subsets. A number of ways are known to quantify diversity in ensembles of classifiers, and little research has been done about their appropriateness to ensemble feature selection. In this paper, we compare five measures of diversity with regard to their possible use in ensemble feature selection. We conduct experiments on 21 data sets from the UCI machine learning repository, comparing the ensemble accuracy and other characteristics for the ensembles built with ensemble feature selection based on the considered measures of diversity. We consider four search strategies for ensemble feature selection together with the simple random subspacing: genetic search, hill-climbing, and ensemble forward and backward sequential selection. In the experiments, we show that, in some cases, the ensemble feature selection process can be sensitive to the choice of the diversity measure, and that the question of the superiority of a particular measure depends on the context of the use of diversity and on the data being processed. In many cases and on average, the plain disagreement measure is the best. Genetic search, kappa, and dynamic voting with selection form the best combination of a search strategy, diversity measure and integration method.", "authors": ["Alexey Tsymbal", "Mykola Pechenizkiy", "P\u00e1draig Cunningham"], "n_citation": 256, "references": ["062f88ba-61e0-4ade-9614-0ea76925905b", "0813ad74-7670-4761-8699-59f5c25dfa9b", "21707c14-f7f1-4cbd-b1aa-4179835e9944", "2231eba9-c735-4f8e-ab36-6c97dda6140f", "23d48a88-26c0-45a8-ba55-c98e200c090c", "3639f4b8-00f6-4bb5-9811-a00c9b0eb072", "3ae9664a-bf6f-45d2-852f-bba9b47e2b8a", "42e0cffb-e875-439f-a8b2-8434fbbda827", "43e502f4-87f2-4672-9217-823cf6c56e56", "646a69c2-a190-4440-a94c-2118ffd79a80", "7a2d1bce-9275-4b3b-9ad7-542af7571618", "7b83f4cb-200a-4e81-8b39-ae4243e9fa86", "8b5e5f59-877d-43ac-9e99-3d4fe55cc8d4", "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c", "becc43bc-a7b6-46e1-817e-553c84a4a6dd", "cc7460a3-38a7-4bcd-b4b4-06fa456b025a", "dc62a90f-d241-420c-839b-ca3b732e5cb4", "dc66de16-cd5c-4c03-9f22-f4ec4ac5c8be", "f98f3e2b-d93b-4c34-bb55-f2acc0cddab6"], "title": "Diversity in search strategies for ensemble feature selection", "venue": "Information Fusion", "year": 2005, "id": "374c479c-b403-4a10-9a3f-58323c5e8fc7"}
{"abstract": "Graph Laplacians and related nonlinear mappings into low dimensional spaces have been shown to be powerful tools for organizing high dimensional data. Here we consider a data set  X  in which the graph associated with it changes depending on some set of parameters. We analyze this type of data in terms of the diffusion distance and the corresponding diffusion map. As the data changes over the parameter space, the low dimensional embedding changes as well. We give a way to go between these embeddings, and furthermore, map them all into a common space, allowing one to track the evolution of  X  in its intrinsic geometry. A global diffusion distance is also defined, which gives a measure of the global behavior of the data over the parameter space. Approximation theorems in terms of randomly sampled data are presented, as are potential applications.", "authors": ["Ronald R. Coifman", "Matthew J. Hirn"], "n_citation": 50, "references": ["05bbaec3-7980-4941-8638-2bbfa4ac8be0", "14349c74-b4bd-4df2-8587-73b9a86e8914", "19db8aaf-440b-42a1-bea0-8b147deb8aa1", "2a5b2817-d318-4716-97fe-a6ab6d898257", "36a77fd9-c63f-43d4-86cd-1755becd34c9", "ecaafaf6-4caa-41d9-aded-1efcb6e35260"], "title": "Diffusion maps for changing data", "venue": "Applied and Computational Harmonic Analysis", "year": 2014, "id": "0fa567a3-65f1-44d2-9371-398e115bd6f7"}
{"abstract": "Combinatorial auctions have recently attracted the interests of many researchers due to their promising applications such as the spectrum auctions recently held by the FCC. In a combinatorial auction, multiple items with interdependent values are sold simultaneously and bidders are allowed to bid on any combination of items. This paper presents a method for implementing several secure combinatorial auction protocols based on our newly developed secure dynamic programming protocol. Dynamic programming is a very effective, widely used technique for tackling various combinatorial optimization problems, including several types of combinatorial auctions. Our secure dynamic programming protocol utilizes secret sharing techniques and can obtain the optimal solution of a combinatorial optimization problem, i.e., result of a combinatorial auction, without revealing the inputs of the problem, i.e., bidding prices. We discuss the application of the method to several combinatorial auctions, i.e., multiple-unit single-item auctions, linear-goods auctions, and general combinatorial auctions.", "authors": ["Koutarou Suzuki", "Makoto Yokoo"], "n_citation": 64, "references": ["08def3f0-5c3e-4b6a-8df4-20c1416698f0", "0a69e3ab-2c22-4e7e-85b4-3746b65e4e6a", "1a92e09c-d351-4133-9220-4300c714166c", "1b46e1b0-61d4-407d-a44b-e3b842b4ff84", "298da8ae-1c88-49df-8afe-5937fa13ee0d", "4d679c7a-7dd8-450b-a5da-2af5703d44cd", "67e41f2f-f41c-422b-b82d-9a8c691955eb", "7225aced-64d3-4dc6-b491-7eb2739b8828", "7498bab7-9aae-463b-a479-2c82ecd4f74b", "7ad86ed1-8ea9-4425-a57a-bc712934166c", "90d79daa-a77a-4924-b056-7c26e5828b0c", "949ac630-202e-4cb1-be17-f1b5ca380dcd", "9565f951-462d-40cb-bc5a-ba23ce88aaf2", "9847ee29-b9f6-45f5-a54f-5a7189652620", "98f543e3-d61c-4099-ae96-237816472592", "99debae8-a5da-4ec6-8309-a904cdaa9880", "9e2a1935-19b2-447a-a77e-c142a90e455e", "abf2376e-46a0-449c-8322-acf3df7c6a38", "af9b6b75-7d53-4502-9acb-70c70165ff3d", "b8fa7154-0cc3-4790-8bd1-840e00ed5ce6", "ce32a078-9262-4d6a-96c2-85bcc2b8e421", "d9d5bc87-8280-4578-931c-f699d95830c1", "f483fec2-b8ee-42bc-9a4e-d46c3bbf5b1f", "fb6cc8fa-1dd0-4902-8d98-70d28318fb43"], "title": "Secure combinatorial auctions by dynamic programming with polynomial secret sharing", "venue": "financial cryptography", "year": 2002, "id": "3fb0dbe0-94ca-41cf-8a07-9f3840fe4078"}
{"abstract": "Although potential benefits are frequently mentioned in the literature, empirical evidence is missing to concretize the costs and benefits of clone management. Without precise estimation of the expected gain, clone management will hardly ever become a self-evident part of serious software development, as for example version control systems are. A study on clones in our own code showed a complex relationship between costs and benefits, which, in addition, differs between individual clones. We conclude that empirical evidence, that adheres the diversity of clones, is needed to support the adoption of clone management in practice.", "authors": ["Jan Harder", "Nils G\u00f6de"], "n_citation": 50, "references": ["12e563d2-4f59-4fd5-a2db-779b05d16538", "1d13b9ed-e8e6-422f-9ffa-59ae5a182949", "51154562-31e0-4e9b-b1e8-95b282288abd", "566d5ab3-e1d3-4228-a4e0-b8e449c42937"], "title": "Quo vadis, clone management?", "venue": "", "year": 2010, "id": "8cc82c74-eb96-448e-bed9-6a026e39ec08"}
{"abstract": "Presuppositionis a pervasive feature of human language. It involves many interesting interactions between the utterances of a discourse and the contextof the discourse. In this paper we focus on issues of logical form connected with the interaction of presupposition and discourse context, and illustrate our theory with some implementational work using the active logicframework. After reviewing some of the major issues in presupposition theory we turn to a largely successful unified approach of Heim. We show how the main principles of this theory can be implemented in active logic. But we also find two serious difficulties. These consist in (a) a straightforward counterexample and (b) a type of discourse that we call a garden-path discourse. We maintain that both the counterexample and the garden-path type of discourse can be handled by our active-logic version of Heim's theory. This requires us to reformulate and extend Heim's theorey. Although this work is largely theoretical, both Heim's theory and ours have important things to say about the incremental processing of the utterances that make up discourse. And we present our theory as a specification of a processing device that takes logical form of a sentence along with current discourse context as input and delivers an updated discourse context as output. As an experiment, we have implemented portions of this device.", "authors": ["John Gurney", "Donald Perlis", "Khemdut Purang"], "n_citation": 34, "title": "Interpreting Presuppositions Using Active Logic: From Contexts to Utterances", "venue": "computational intelligence", "year": 1997, "id": "1a47ce5b-e174-4b72-a851-a4521da98baf"}
{"authors": ["Antonio Si", "Hong Va Leong", "Rynson W. H. Lau"], "n_citation": 213, "references": ["0a08897f-11fd-451c-b287-3373693d872b", "19ff308e-4ebb-4bee-8801-cec7e3472378", "2387df5f-08ee-41ae-9c4c-5cde2a5a3829", "48720bfd-818c-400f-a197-a4cea8b1e54d", "55f4933e-56af-4807-b466-0ec19261d023", "6340032a-8a88-4e5b-9d2d-d4c82ed4f66a", "65e9d883-cc87-4505-ab64-99a181371d6f"], "title": "CHECK: a document plagiarism detection system", "venue": "acm symposium on applied computing", "year": 1997, "id": "09251d59-a162-4df2-a961-77e5ffa298f3"}
{"abstract": "Biometric recognition offers a reliable solution to the problem of user authentication in identity management systems. With the widespread deployment of biometric systems in various applications, there are increasing concerns about the security and privacy of biometric technology. Public acceptance of biometrics technology will depend on the ability of system designers to demonstrate that these systems are robust, have low error rates, and are tamper proof. We present a high-level categorization of the various vulnerabilities of a biometric system and discuss countermeasures that have been proposed to address these vulnerabilities. In particular, we focus on biometric template security which is an important issue because, unlike passwords and tokens, compromised biometric templates cannot be revoked and reissued. Protecting the template is a challenging task due to intrauser variability in the acquired biometric traits. We present an overview of various biometric template protection schemes and discuss their advantages and limitations in terms of security, revocability, and impact on matching accuracy. A template protection scheme with provable security and acceptable recognition performance has thus far remained elusive. Development of such a scheme is crucial as biometric systems are beginning to proliferate into the core physical and information infrastructure of our society.", "authors": ["Anil K. Jain", "Karthik Nandakumar", "Abhishek Nagar"], "n_citation": 1037, "references": ["031bfc7c-d3c7-41a8-928e-819323c61206", "049e5b48-a410-4d48-bb37-4fc8fea09282", "145f3040-9150-412b-9a2f-52734adf287c", "1df1e558-631b-4e01-9953-f972d8c7ae13", "233426d1-b192-4834-9b2d-c6e68ae996f5", "2bc21ce6-91e1-42f7-adc4-0a0403441081", "316faf2f-9d68-4b97-ae80-6947d4dfd9dd", "3d84d44c-6f51-4104-93f2-080de0d213ed", "3e819891-06ac-4853-8c64-7a400bd9e557", "49f1cd0a-9d2f-4d0f-b369-07f909042d51", "4c737d90-a341-4243-ab0c-d23c2af8e831", "4df067d0-a414-4bc5-b02a-9bd404d408c0", "5320bde4-af8a-4846-a36a-22b090628986", "56f4b72a-ec39-47ac-8220-899296e7fb18", "5a65ea4a-935e-4fbd-bdd4-c9b5dec1f47a", "622628d5-8e1a-4232-8af6-758d92faae90", "62cc2e88-0884-4676-84e2-0daa40f0baaa", "641c0d2a-678b-4da4-b90a-a9944af30b98", "6580b670-3219-4ed8-b9e9-ce4fa613819d", "688dbaf9-9990-484a-8ea9-8e80474d6a1b", "69190718-b4c0-4175-b16f-22abfc8086c3", "6925557f-e1b7-45eb-bc5b-36209b1d1e2a", "6b27840d-0f06-4de4-903e-f9cbe2ab3cc6", "73ce1033-d5e4-4ce8-b53f-1dbc032a7243", "73f1f71e-0499-4172-bf46-2291b51b3846", "75915e95-17bf-42ea-9983-885f0476dd10", "81bb90e5-c2c7-40c1-99bf-844913bd5908", "85d69ae6-04d8-4dc6-a405-16806893171d", "8eb417e4-3fd4-4054-bf3d-48280978697a", "9490aea9-e707-4616-8f2e-a4f4ed68dd8b", "990c79a7-5838-442e-99cd-7559b3f691be", "a60a30b5-755c-4454-941f-03f9dbc784f6", "a7c011eb-e184-47d8-8629-747125092d3a", "a89d9f88-cfcf-48fb-9c29-995e69310270", "abf003a2-6485-41f0-a111-88b80412d539", "bbf98b35-b712-4b86-a921-ac29b3d621e9", "caa1e142-8eb8-4368-9c23-e63f4dba8106", "cdefa654-2b5c-40a5-8ea4-272c0c5251dc", "d34278d4-21b0-4bca-88f8-3a5da727f17d", "d46a75b4-cd90-4bfe-85d6-b1b2cf512b09", "d8754256-4311-4081-9969-2e8560566679", "d9ca590a-8553-4b24-b170-6024b5284999", "de36b276-0347-49e1-97b3-442b1144d145", "e0055a89-9122-455d-aff3-b4976bbf60ae", "e18923c6-1cff-41c9-b642-83692bcf4e90", "e48c7dd9-e078-48de-990a-e8fc95529eb1", "e673217d-2bd8-4933-81c9-966205aef2a6", "e737dc46-e96e-470b-8f53-f576ae2c2e03", "e809a541-de8c-4d7a-a5a9-941c2fa0ab4f", "e8e7660e-8286-4c63-a9ee-4edface45f74", "ea6808a0-7bc5-407d-8c35-f10d41ff4db5", "ebb535be-f27c-4842-96ee-f6b5e9b79cdd", "eddfa2f8-32db-4cea-9fe5-b78bda6c4958", "f1d5a43c-2391-4cab-98a0-bc6aa4124f1c", "f5e0bb5b-1818-4cc0-9a75-8ac5a8012f56", "fbac2138-ab49-41ab-9f6e-3748de9415ff"], "title": "Biometric template security", "venue": "EURASIP Journal on Advances in Signal Processing", "year": 2008, "id": "c189b62d-6266-4c2e-bf49-1c0be435b7e3"}
{"abstract": "In this paper, the synchronization problem is investigated for a class of nonlinear delayed dynamical networks with heterogeneous impulsive effects. The intrinsic properties of heterogeneous impulses are that impulsive strengths are inhomogeneous in both time and space domains, i.e., the impulsive effect in each node is not only nonidentical from each other, but also time-varying at different impulsive instants. The purpose of the addressed problem is to derive synchronization criteria such that, the nonlinear delayed dynamical networks with heterogeneous impulses can be synchronized to a desired state. By means of a time-dependent Lyapunov function and the comparison principle, several sufficient conditions are established under which nonlinear dynamical networks with heterogeneous impulsive effects are exponentially synchronized to a desired state. An example is given to show the effectiveness of the proposed results.", "authors": ["Wenbing Zhang", "Yang Tang", "Xiaotai Wu", "Jian-an Fang"], "n_citation": 101, "references": ["13bd3bcd-8511-4608-8046-f567fb6aaf52", "142b00cf-5111-4eda-ac42-5fd5ef3f58b5", "15b8d3f3-f8db-4e7e-8ba1-afa6461703b3", "2768199c-b9d6-4001-94d3-e6429c93bc5f", "287541d5-570f-4789-b10d-f3aa4a8c91f6", "2e83a86b-38ad-40f6-9a9a-f36035d6d360", "2fefaed6-c836-4d8a-abe8-78acb2483773", "3ff10b29-cc40-4b43-bc89-fa04a0a1a017", "423ffd43-917a-429f-bfee-bd31a7b1351e", "4ebc10c1-d618-4cf9-83d3-c1d5a205bd0e", "53f35a56-20ff-4b60-a779-ba0abc19a376", "598fa8e8-c928-4ce2-a1b7-b4acb976991f", "5c0c8097-625d-4715-87f5-a1cbff4248d2", "5c9cb047-02c0-46fb-b8a5-08c2931add59", "62815e7c-3a55-497c-ae19-bd76795b264e", "6a278b40-cdf0-4a96-87dc-2e8c212af508", "79de0212-6f83-4fec-8e76-acd564ffcaf7", "81c30719-1814-4d0a-b44f-c10ca8e290d9", "9b86381f-0904-437e-bb83-898dd7a0d261", "ad2d8f90-42b0-4bc7-aef0-0b02f3d692e2", "c15365b4-fe2f-4a83-a75b-2a730a2759f4", "c67f8412-0fd8-4bd5-b498-0e9ca5136c64", "c7f51377-be74-47a1-9988-6c4be5529263", "c7fa9607-9db5-415c-9f42-b3042f3eb040", "cce5314c-ed38-425f-a2fe-de425c397aa0", "cf0b602e-6b04-4a6b-8e28-394d1c62c67a", "debfea24-1d49-4513-9e5b-fd87ac98f111", "e508a6a3-1738-40f4-a810-b55ff6132173", "ebd0c5fd-21de-41cc-983c-15c03ef1cbfc"], "title": "Synchronization of Nonlinear Dynamical Networks With Heterogeneous Impulses", "venue": "IEEE Transactions on Circuits and Systems I-regular Papers", "year": 2014, "id": "115af5dd-13e5-47ab-a043-f6c6b6837438"}
{"abstract": "In order to prepare for the upgrade of the German national scientific network to gigabit capacity in the year 2000, two testbeds have been set up. One of them, the 'Gigabit Testbed West', uses a 2.4 Gbit/s ATM link to connect the Research Centre Julich and the GMD-National Research Center for Information Technology in Sankt Augustin. The testbed is the basis for several application projects, ranging from metacomputing to multimedia. This paper gives an overview of the infrastructure of the testbed and its applications. As an example, the real-time analysis and visualization of functional MRI measurements of the human brain are described in detail.", "authors": ["Thomas Eickermann", "Wolfgang Frings", "Stefan Posse", "Gernot Goebbels", "R. V\u00f6lpel"], "n_citation": 5, "references": ["2047bcc7-a5f7-4d3c-bf69-5705174f8081", "432a75f0-4a68-4700-954b-56a8eb920dab", "8375242a-bd61-4297-858f-0f78108bb6ea", "91e445e4-bca3-4d9a-b723-c8d759655e99"], "title": "Distributed applications in a German gigabit WAN", "venue": "high performance distributed computing", "year": 1999, "id": "c4614128-831f-49b0-9c58-d27c3130d7e9"}
{"abstract": "Mobile computing has the potential for managing information globally.  Data management issues in mobile computing have received some attention in recent times, and the design of  adaptive braodcast protocols  has been posed as an important probllem. Such protocols are employed by database servers to decide on the content of bbroadcasts dynamically, in response to client mobility and demand patterns. In this paper we design such protocols and also propose efficient retrieval strategies that may be employed by clients to download information from broadcasts. The goal is to design  cooperative  strategies between server and client to provide access to information in such a way as to minimize energy expenditure by clients.  We evaluate the performance of our  protocols both analytically and through simulation.", "authors": ["Anindya Datta", "Debra E. VanderMeer", "Aslihan Celik", "Vijay Kumar"], "n_citation": 164, "references": ["0b20695c-e17c-4801-9c15-baf45c7efc0f", "252ff9de-9155-40bf-98c9-906056b3a726", "28300f5c-101b-4a59-bf01-ef3f3785e3e6", "2b02cc9c-4d97-41ca-94b7-503df0e53134", "2e4e507b-bf78-45ae-889f-27a3d7296ae4", "38ba7e7b-315a-4617-80fd-0556ee730c5d", "46b8bf8d-c608-4706-a161-e5c2bd7aec12", "473fbc24-1de8-4238-ace2-fa6a1b0af8c3", "4dc72d1a-79b0-426e-9e58-c886e4d40dc9", "5a1ded12-77ad-4d92-b5f1-e7d0ce7768c1", "5c850afa-135f-4cc4-8f8b-0f00b90d63d4", "634dd7f2-b88d-45a5-aa78-c6249d4488b8", "6356236c-cccc-4d0b-af5d-4ea51e7b4675", "65592b6b-8b86-4f02-9334-3da92352b29d", "8d77fce8-9496-4963-a963-3175ba183bb2", "97167de2-b936-4ad4-86c7-687e7df11bb1", "9ada4e4d-dfeb-4ed6-b7b7-1e9464a771b3", "ad460af7-e50d-4c66-8bdf-ef01f0255989", "b5d21013-af60-4667-b061-b69d709fa67b", "c01425d3-9eca-4320-b25f-195c486797ba", "fe8a4997-1db5-4359-8f4a-c06bc37fd270"], "title": "Broadcast protocols to support efficient retrieval from databases by mobile users", "venue": "ACM Transactions on Database Systems", "year": 1999, "id": "77086361-1614-442a-a07d-d8a924b6f357"}
{"abstract": "The combinatorial design method substantially reduces testing costs. The authors describe an application in which the method reduced test plan development from one month to less than a week. In several experiments, the method demonstrated good code coverage and fault detection ability.", "authors": ["David M. Cohen", "Siddhartha R. Dalal", "Jesse Parelius", "Gardner C. Patton"], "n_citation": 420, "references": ["14b65ac1-f631-43cc-99cc-81cbf5e6aab6", "46b00d36-de3f-475e-91f4-03a8edb7c060", "ca068947-71bc-41e3-acab-225f0c4270a5", "eeb48257-2159-4e37-bebf-60234df9b2fd"], "title": "The combinatorial design approach to automatic test generation", "venue": "IEEE Software", "year": 1996, "id": "47401977-9e91-4187-b4b2-53cfd999e62e"}
{"abstract": "During collaborative development, individual developers can create conflicts in their copies of the code. Such conflicting edits are frequent in practice, and resolving them can be costly. We present Crystal, a tool that proactively examines developers' code and precisely identifies and reports on textual, compilation, and behavioral conflicts. When conflicts are present, Crystal enables developers to resolve them more quickly, and therefore at a lesser cost. When conflicts are absent, Crystal increases the developers' confidence that it is safe to merge their code. Crystal uses an unobtrusive interface to deliver pertinent information about conflicts. It informs developers about actions that would address the conflicts and about people with whom they should communicate.", "authors": ["Yuriy Brun", "Reid Holmes", "Michael D. Ernst", "David Notkin"], "n_citation": 50, "references": ["040a4856-25ea-4a3a-abd4-0ba13ffb0272", "3144b99a-8adf-4c11-9d1c-c28faf635d6d", "46da286c-6776-40a7-bc9b-ab629105bc78", "5e255053-3b23-4f8c-a951-2d6ca4dea91f", "656bdd59-be88-42cb-bdcb-ad09bfcd43ab", "65d1ad8e-f19e-4563-8cac-cf7bb9633d84", "7d57c7e1-6355-4d2a-aef2-ebdc200ad727", "8f2706a0-027c-4685-8614-cbcb4b2776b3", "aba2e4e2-ef14-4fc7-a8dd-c0d4c907c555", "b5690787-4d97-4e5c-9409-4d9bd9537ed7", "c2f414b5-f64a-45fb-92c1-2ecaa527d59d", "c3ffb05e-167d-4ad5-ae3c-34cf8b17d103", "f064a973-8489-41ee-97c7-b65035db011c"], "title": "Crystal: precise and unobtrusive conflict warnings", "venue": "foundations of software engineering", "year": 2011, "id": "0f3394e2-15be-4087-884b-df2b01ef4b5c"}
{"abstract": "A complete mathematical characterization, for linear costs, is given of a two-path transportation network model, whose descriptive minimal OD travel cost per unit islower before the paths are joined by a transversal link thanafterwards. Necessary and sufficient conditions, in terms of the link costs, are obtained for the existence of such paradoxical flows, along with their critical range, if they exist. These results are then generalized for a broad class of single OD (origin\u2014destination nodal pair) networks.", "authors": ["Marguerite Frank"], "n_citation": 128, "references": [], "title": "The Braess paradox", "venue": "Mathematical Programming", "year": 1981, "id": "74923aae-575e-4cf7-bf69-643b9264d55d"}
{"abstract": "This paper reports on a visual simulation system that supports GIS-based realistic modeling and real-time rendering of forest scenes. Geometric models of trees are automatically generated according to inventory database and pre-designed template models. A combined image and geometry representation method for 3D tree model is given with a specific level of detail algorithm for ensuring real-time frame rates. We have tested and evaluated the system in applications of walkthrough simulation and forest fire visualization.", "authors": ["QizhiYu", "Chongcheng Chen", "ZhigengPan", "Jianwei Li"], "n_citation": 6, "references": ["33a9037e-3bdf-4a65-8da5-470b4201b126", "72010afe-5868-47f6-9ec9-eb1239dce0aa", "c6ec0947-f2d2-47f2-880d-4a75b49eb333", "dd613c56-32b5-41c2-beba-2bc21388f786"], "title": "A GIS-based forest visual simulation system", "venue": "international conference on image and graphics", "year": 2004, "id": "6af9240a-e6ce-418c-ab8e-42d04c66a436"}
{"abstract": "We prove the correctness of a sliding window protocol with an arbitrary finite window size n and sequence numbers modulo 2n .W e show that the sliding window protocol is branching bisimilar to a queue of capacity 2n. The proof is given entirely on the basis of an axiomatic theory, and was checked with the help of PVS.", "authors": ["Wan Fokkink", "Jan Friso Groote", "Jun Pang", "Bahareh Badban", "Jaco van de Pol"], "n_citation": 57, "references": ["11708e2c-15a3-4af6-af97-2cde446f6228", "1765a4c8-f347-4ee7-b001-f7169d2f1415", "3023929a-c93e-49c5-b03f-7fb0414d94df", "41ca9505-65f2-4441-a9be-ae80a09a4dfb", "41cf9713-ed76-43a6-8e9f-538abc2f787c", "583ec73f-668e-4f83-a350-df73d9b13bbd", "6cf056d5-09d3-42c8-b6db-25c0335fa3be", "6d4458b3-1a92-4f84-b4ed-556be7407c05", "745f4da6-15e8-4d54-bd60-7f1b9a18553a", "7dc3d6e8-85f1-4b9b-8aff-ae0415b1ea67", "804cd3a5-ad06-4ac7-826f-ea97c93a04dc", "85db41de-cbf5-4ef3-9742-bc4ea0e86593", "86718b68-beb2-4201-8bce-845a80302bd2", "8950b275-ae2e-4c09-a62c-9e46265995b3", "89e68dd7-4718-4770-8293-3448ba3ba078", "922dedbd-dde0-4fdb-8b5a-1e44bdae286c", "99f331e4-7b02-41fc-ac5b-89f69affbd92", "a2aae58b-957a-45b0-a4f8-73d9cbea2802", "a613c83e-f195-4e4e-bc94-269e4b92f196", "c4f516b9-edcb-46f3-8eea-a38647c10ae8", "cbfcf009-b487-47cf-9f83-6eebddf94640", "e3a5dabe-4d49-4e24-b885-695bda04d7d1", "eac1c0cb-beaa-46f9-ac77-56961ddf420a", "f849dbeb-d519-4796-af1c-9a5596c11c33"], "title": "Verifying a sliding window protocol in \u00b5CRL", "venue": "algebraic methodology and software technology", "year": 2004, "id": "2d165c53-21a4-4289-9276-26007454c878"}
{"abstract": "Abstract: The security of computation at the level of a specific programming language and the security of complex systems at a more abstract level are two major areas of current security research. With the objective to integrate the two, this article proposes a translation of a timing-sensitive security property for simple multi-threaded programs into a more general security framework. Interestingly, our notion of security for programs is bisimulation-based while the security framework is trace-based. Nevertheless, we show that the translation is sound and complete in the sense that the trace-based specification which results from the translation of a multi-threaded program is secure if and only if the original program is secure. The translation is presented as a two-step process where the first step is independent from the concrete programming language.", "authors": ["Heiko Mantel", "Andrei Sabelfeld"], "n_citation": 59, "references": ["0ac916bf-8746-49ed-8ca2-2cebfbc1cd53", "14d27c61-8776-4346-91e6-6f4b77a69cc8", "16d386b0-fbe6-4df6-b1c2-db63aab8e1fa", "1baeeaaf-052d-4fa9-873f-4f6528389e30", "2ddddbb7-0136-4c16-9917-c84ed9a1548a", "3c4d15f5-7743-43df-8f5c-9b9caaa4f8fc", "3f18a5c3-849e-4cef-9f6c-0c99d9918253", "4271f7e3-98fb-413b-abc2-b5981c8e985a", "44288c69-47f8-4ff3-9174-860ea31334b5", "4836ed82-8f70-4bd0-be8c-c536a462efe2", "488451b9-147b-472b-859f-76a07540d81e", "5d684962-bf36-49cc-bd7c-abcde710d402", "65cb8b4d-b4ff-4db8-9852-18f78138eaaa", "706da441-c9f3-47b8-a952-f8665b1514fc", "802c473f-9db8-49ce-93f0-8ca645ecc5d6", "90ef3832-5c00-42ad-a2f8-9cbeba5e7b0c", "b62a2f03-8c81-42a8-92e6-79a6994780d3", "b634b58b-7c58-4894-bbce-135d53637547", "c89f8d87-19b1-4a34-bf90-ba7ca8ad2602", "ccfc8e8c-ecbf-413c-9d5a-2aba96b74a19", "d0eca5dc-9d59-4584-8777-8b91fd8a069d", "dc00be8b-9bd0-4ebe-bc16-fa6b440c8839", "e03cb036-2728-4f79-a0a1-45dc108f4dd6", "e1630f39-05cd-45f6-a712-14b96dab6ef9", "f3eee849-48ce-480c-a8ac-69030264c772", "f861eec0-3232-4363-9362-52518851d6d9", "fe9d2177-5770-40ec-acd2-2fc1ce394947"], "title": "A generic approach to the security of multi-threaded programs", "venue": "computer security foundations workshop", "year": 2001, "id": "52a168cc-03c9-49da-af9f-66dc3a31ee36"}
{"authors": ["Gerhard Weikum", "Hans-J\u00f6rg Schek"], "n_citation": 390, "title": "Concepts and applications of multilevel transactions and open nested transactions", "venue": "", "year": 1992, "id": "f4348e83-e5f5-456e-8f7f-5cca1e0a02e4"}
{"abstract": "The design and implementation of a national computing system and data grid has become a reachable goal from both the computer science and computational science point of view. A distributed infrastructure capable of sophisticated computational functions can bring many benefits to scientific work, but poses many challenges, both technical and socio-political. Technical challenges include having basic software tools, higher-level services, functioning and pervasive security, and standards, while socio-political issues include building a user community, adding incentives for sites to be part of a user-centric environment, and educating funding sources about the needs of this community. This paper details the areas relating to Grid research that we feel still need to be addressed to fully leverage the advantages of the Grid.", "authors": ["Jennifer M. Schopf", "Bill Nitzberg"], "n_citation": 114, "references": ["13ef1961-a2a2-437e-9dc4-e5c03c400333", "26243630-8e1c-4b2e-9bb8-28a8c784ebaf", "2b47a917-42eb-41a0-b168-c38347631edf", "432a75f0-4a68-4700-954b-56a8eb920dab", "4f4498ee-ed1e-4e3a-ad12-ea64f27a5068", "740d054f-67e6-4e6e-a54d-f09e4ab41bb7", "83f5624b-031a-4104-8e39-26e5b214cc02", "914e0245-e455-45da-88f5-c623aa1a320d", "9cdc54f0-f1a0-4422-ac16-d9164d9371ee", "9d438476-9e4a-49a7-b43f-e0518d394e04", "bde20f29-30c1-410f-9e2d-6c29c980bd8d", "bf8dfe61-d18a-4480-85e0-a1a3327612b5", "c8311815-4163-4e5c-8a25-c4a3205cb6d9", "cacd54ff-0a7a-4c10-ad1a-aacdce98fd93", "d4128520-65e4-429b-9ccb-e930c148f12e", "e74c3a21-cf9c-4ed0-bacb-3327d998e0ff", "fab067d8-f705-4ea2-bf87-61dedfea2682"], "title": "Grids: The top ten questions", "venue": "Scientific Programming", "year": 2002, "id": "a1936fec-f402-4ff5-8a8c-14a68973bbc3"}
{"abstract": "Peer-to-Peer (P2P) applications and services are very common in today's computing. The popularity of the P2P paradigm prompts the need for specialized security services which makes P2P security an important and challenging research topic. Most prior work in P2P security focused on authentication, key management and secure communication. However, an important pre-requisite for many P2P security services is secure admission, or how one becomes a  peer  in a P2P setting. This issue has been heretofore largely untouched.This paper builds upon some recent work [11] which constructed a peer group admission control framework based on different policies and corresponding cryptographic techniques. Our central goal is to assess the practicality of these techniques. To this end, we construct and evaluate concrete P2P admission mechanisms based on various cryptographic techniques. Although our analysis focuses primarily on performance, we also consider other important features, such as: anonymity, unlinkability and accountability. Among other things, our experimental results demonstrate that, unfortunately, advanced cryptographic constructs (such as verifiable threshold signatures) are not yet ready for prime time.", "authors": ["Nitesh Saxena", "Gene Tsudik", "Jeong Hyun Yi"], "n_citation": 114, "references": ["0067011d-0ba8-4987-9aa3-cc4f5fa4f83a", "1e69d2fd-cfc8-4d7c-a864-341d9c4b6eec", "3799ab6c-37be-441a-88f4-d812770286ec", "3b7bb035-afef-49bf-9c51-7aa67de99947", "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4", "50de5f13-c4ef-4c70-882e-7b6586f0c09a", "51af4708-b81c-4362-b4ee-7bdf7ace609f", "53c68640-50a6-4377-9ebe-5b187e0df0d5", "79f1e2ad-315a-4246-87e5-c20d421d1989", "825b9662-df5c-4a29-ad10-b3c2e8062014", "90295c5c-f4ab-454c-b414-fb9d50c09232", "98830427-b74e-4873-9223-5c1d9358643a", "a964da6f-eaf8-494d-9f7b-c3d1208d71f2", "c0ea675b-2479-48ae-817e-3ecedd175ecf", "d240119d-940d-4c54-a4fa-fe14424c3de9", "e1263ada-afda-498c-a37d-9b545293118a", "ed593eae-0e70-4fff-b6b9-8c7ff529f001", "f14df1ed-e3e9-4348-9040-fc06e3411b95", "f4e11c1a-bcb0-4a4a-939a-3d4e95ece4ff"], "title": "Admission control in Peer-to-Peer: design and performance evaluation", "venue": "security of ad hoc and sensor networks", "year": 2003, "id": "89087194-1489-483b-83d1-0baa77262fee"}
{"abstract": "The classic problem of finding the shortest path over a network has been the target of many research efforts over the years. These research efforts have resulted in a number of different algorithms and a considerable amount of empirical findings with respect to performance. Unfortunately, prior research does not provide a clear direction for choosing an algorithm when one faces the problem of computing shortest paths on real road networks. Most of the computational testing on shortest path algorithms has been based on randomly generated networks, which may not have the characteristics of real road networks. In this paper, we provide an objective evaluation of 15 shortest path algorithms using a variety of real road networks. Based on the evaluation, a set of recommended algorithms for computing shortest paths on real road networks is identified. This evaluation should be particularly useful to researchers and practitioners in operations research, management science, transportation, and Geographic Information Systems.", "authors": ["F. Benjamin Zhan", "Charles E. Noon"], "n_citation": 608, "references": ["01d20c9d-3094-4a97-b684-bd61686acf4d", "0925943c-3f4c-4727-b570-9b60627c949a", "1b41d9a0-3857-4fb6-b7ba-d39da73c04dd", "409159cc-0393-4021-99ee-654018eb0fa4", "8a055c26-9336-43e5-8d1c-01c8a12a1870", "8c943d53-806d-4f16-a135-0262f73b32ae", "bd4877a6-7131-454a-833e-34c06d4b638f", "bf6de372-28d7-4d1d-8051-fe16977a9433", "c5a4bbd2-72ee-4aa9-a785-8eeb6ef69edc", "d829c352-820e-4b21-8eb0-c9a3186be294", "ed4259cc-d6c2-4413-a7cd-702fd819f2d2"], "title": "Shortest Path Algorithms: An Evaluation Using Real Road Networks", "venue": "Transportation Science", "year": 1998, "id": "10acff66-80c8-4d0e-ab9a-047ca1eb8837"}
{"abstract": "The key point of this article is that, in frequent pattern mining, the most appropriate way of exploiting monotone constraints in conjunction with frequency is to use them in order to reduce the input data; this reduction in turn induces a stronger pruning of the search space of the problem. Following this intuition, we introduce ExAMiner, a breadth-first algorithm that exploits the real synergy of antimonotone and monotone constraints: the total benefit is greater than the sum of the two individual benefits. ExAMiner generalizes the basic idea of the preprocessing algorithm ExAnte (Bonchi et al. 2003(b)), embedding such ideas at all levels of an Apriori-like computation. The resulting algorithm is the generalization of the Apriori algorithm when a conjunction of monotone constraints is conjoined to the frequency antimonotone constraint. Experimental results confirm that this is, so far, the most efficient way of attacking the computational problem in analysis.", "authors": ["Francesco Bonchi", "Fosca Giannotti", "Alessio Mazzanti", "Dino Pedreschi"], "n_citation": 50, "references": ["045de08a-a1ef-416e-8e6a-9227f402e2a3", "087e4a7c-b0c5-40af-9817-866878f30e38", "1232fee4-0fa0-481b-aba7-9e204e9138a7", "2aa08d07-07b4-4913-87b6-008cda71aa93", "34b7e270-80d7-46d5-a6f1-e50087a8d045", "441ac3e2-bed5-4d1b-8569-f789884e2920", "55f49573-e389-4e80-b036-925b38c5d49a", "6487b9d5-8289-4383-8ac3-fc6a7e0f1324", "740771e3-184d-4bb3-b0d1-8122abf0d6a2", "74124cdf-4269-4256-a3a6-04e14437e201", "7482cc04-8a43-4494-b41a-e6e42259b30f", "74bb0f31-1de1-4c21-8b44-d8c420aede81", "82c534c6-c89d-4856-b6fc-e1cad5be4482", "88d69a2b-48c8-4118-b342-1e1ed647fec3", "c83d10cb-3cc4-4c8a-ad85-1eb92e76b337", "db7cf8e8-5d4b-47c5-9b89-26ec300cbbf0", "ecd6a845-8439-49b0-abe8-f71fff81da23", "f5147c9a-4029-4e34-a95c-77e2aa34ccc5"], "title": "Efficient breadth-first mining of frequent pattern with monotone constraints", "venue": "Knowledge and Information Systems", "year": 2005, "id": "89d8f464-511d-4e56-94eb-1c66bd797d4f"}
{"abstract": "The emergence of order in natural systems is a constant source of inspiration for both physical and biological sciences. While the spatial order characterizing for example the crystals has been the basis of many advances in contemporary physics, most complex systems in nature do not offer such high degree of order. Many of these systems form complex networks whose nodes are the elements of the system and edges represent the interactions between them. #R##N#Traditionally complex networks have been described by the random graph theory founded in 1959 by Paul Erdohs and Alfred Renyi. One of the defining features of random graphs is that they are statistically homogeneous, and their degree distribution (characterizing the spread in the number of edges starting from a node) is a Poisson distribution. In contrast, recent empirical studies, including the work of our group, indicate that the topology of real networks is much richer than that of random graphs. In particular, the degree distribution of real networks is a power-law, indicating a heterogeneous topology in which the majority of the nodes have a small degree, but there is a significant fraction of highly connected nodes that play an important role in the connectivity of the network. #R##N#The scale-free topology of real networks has very important consequences on their functioning. For example, we have discovered that scale-free networks are extremely resilient to the random disruption of their nodes. On the other hand, the selective removal of the nodes with highest degree induces a rapid breakdown of the network to isolated subparts that cannot communicate with each other. #R##N#The non-trivial scaling of the degree distribution of real networks is also an indication of their assembly and evolution. Indeed, our modeling studies have shown us that there are general principles governing the evolution of networks. Most networks start from a small seed and grow by the addition of new nodes which attach to the nodes already in the system. This process obeys preferential attachment: the new nodes are more likely to connect to nodes with already high degree. We have proposed a simple model based on these two principles wich was able to reproduce the power-law degree distribution of real networks. Perhaps even more importantly, this model paved the way to a new paradigm of network modeling, trying to capture the evolution of networks, not just their static topology.", "authors": ["R\u00e9ka Albert", "Albert-L\u00e1szl\u00f3 Barab\u00e1si"], "n_citation": 20075, "references": [], "title": "Statistical mechanics of complex networks", "venue": "Reviews of Modern Physics", "year": 2001, "id": "60ef3852-fa16-44bf-9434-9909268ba5d8"}
{"abstract": "An  intelligent module  is proposed in this paper which is capable of performing a joint recursive planning/control operation which propagates through the  intelligent module  at all planning/control levels simultaneously. Each of the actuators is equipped by an  intelligent module , and all of these modules are working independently and concurrently. The model of the world is being constantly updated based upon vision and a multiplicity of other available sensors, and at various resolutions is submitted to each of the  intelligent modules  as applied to particular properties of the link being controlled by this module. Together these intelligent modules are working as a  team of the actuators controllers , and all decisions are constantly negotiated among the members of the team. Each of the resolutional levels within the actuator intelligent modules is using the following set of planning/control tools: learning rule base, learning heuristic search, and situational decision generator which are first applied simultaneously, and then one of them takes over. A neural network is collecting information about the progress and the results of planning/control processes, and is modifying heuristics, as well as enriching the system of rules. The same neural network is used for supplying the provisional analytical model required for the lowest levels of execution control. Provisional analytical models are applied in a simple form which allows for simple real-time controller operation, and the parameters of this provisional model are constantly being updated by the neural network.", "authors": ["Alex Meystel"], "n_citation": 50, "references": ["14d42025-2009-40da-a2a8-f8de35c71cf7", "15812a6d-34c5-4ad1-ac96-ecabe01c2fa5", "47dbdfb4-5969-4c68-a8c5-70ee64e2a120", "4eb8a709-7279-4429-9277-90c638023f0f", "585cad54-6e38-4932-8f35-3b3e1c2bf65c", "5a8311bb-9291-4d99-b194-82ccfcd9a16f", "615a50f3-4cc1-4add-a824-dca5fcb16570", "8f78e0c6-8b4d-4805-ad21-7565912ff320", "e18b68bc-9a58-44cb-83b8-5d8e3a1143df"], "title": "Intelligent module for planning/control of master-dependent systems", "venue": "industrial and engineering applications of artificial intelligence and expert systems", "year": 1988, "id": "d3ef330f-42aa-41f9-a3cd-32e0d81a1958"}
{"authors": ["Christian Br\u00e4uer-Burchardt", "Klaus Voss"], "n_citation": 50, "references": ["1aba91b5-6a0e-4ef2-82d7-81e5a9148073", "4b78a087-39d4-435e-8830-2074224f82e8", "9ef66ebf-124f-4c63-a0c2-bf0062e623d5"], "title": "Automatic Lens Distortion Calibration Using Single Views", "venue": "", "year": 2000, "id": "25eab25f-0d35-445f-819d-f8ffc71eedd2"}
{"authors": ["Raymond Reiter"], "n_citation": 65, "title": "Sequential, Temporal GOLOG.", "venue": "principles of knowledge representation and reasoning", "year": 1998, "id": "fab23e32-d568-4f3f-af6d-1b8d46fb6693"}
{"abstract": "An association rule generation algorithm usually generates too many rules including a lot of uninteresting ones. Many interestingness criteria are proposed to prune those uninteresting rules. However, they work in post-pruning process and hence do not improve the rule generation efficiency. We discuss properties of informative rule set and conclude that the informative rule set includes all interesting rules measured by many commonly used interestingness criteria, and that rules excluded by the informative rule set are forwardly prunable, i.e. they can be removed in the rule generation process instead of post pruning. Based on these properties, we propose a direct interesting rule generation algorithm, DIG, to directly generate interesting rules defined by any of 12 interestingness criteria. We further show experimentally that DIG is faster and uses less memory than Apriori.", "authors": ["Jiuyong Li", "Yanchun Zhang"], "n_citation": 50, "references": ["02720fd2-be9a-4e0a-b3ed-c20b90df5ae0", "07f57c70-0572-4daa-ab9d-c07a1df9dd15", "34b7e270-80d7-46d5-a6f1-e50087a8d045", "3f7cfad1-2ef7-4193-a2d9-95789c64b207", "4122c7d4-d40b-4fb2-baca-ae9e728958f9", "5ab0756f-b081-4fc0-aa3d-de810e502a01", "66d187d9-e2cf-4f98-aba1-a0f15d4d6e2b", "67b811d2-2db3-486f-8046-8ee09037da70", "6f9732f6-df67-41a7-bad3-8e63bbfad0a1", "7482cc04-8a43-4494-b41a-e6e42259b30f", "7f60f284-50e8-4bf3-92c5-db7ef4975434", "82c534c6-c89d-4856-b6fc-e1cad5be4482", "8a6a4c08-fdc8-49c4-8e73-23e7fdb466d6", "9054b15d-a1d5-4326-93a1-01d759993e56", "94a6b637-9fd7-472a-8c60-fefd4abea3e8", "c4710c73-497d-44f0-ae10-64613eca18d4", "c4d0992b-d678-4ce7-b6b5-cce3701090f6", "c732ddac-d337-4149-b55f-3e717e3859eb", "ecd6a845-8439-49b0-abe8-f71fff81da23", "fa2e01a5-a3f2-4931-b737-93ef04ff8f21", "fecef8e6-3a71-4101-9df7-498287c49eb7", "ff9e63a5-c40a-4113-958c-0a86033ac430"], "title": "Direct interesting rule generation", "venue": "international conference on data mining", "year": 2003, "id": "b8772bbd-3538-45ba-be29-f50f4048c394"}
{"abstract": "This paper proposes an innovative control strategy for a voltage-regulated dc hybrid power source employing polymer electrolyte membrane fuel cell as the main energy source and supercapacitors as the auxiliary power source for a distributed generation system. This strategy is based on a standard dc link voltage regulation, which is simpler than standard state machines used for hybrid source control, and free of chattering problems. Its originality lies in using only the storage device for supplying the energy required to achieve the dc link voltage regulation. Therefore, the main source of the hybrid system is considered as a standard load, working only in regenerative braking, to keep the storage device charged. The general structure of the studied system, the control principle of the hybrid source, the realization of the experimental bench, and the experimental validation are all presented.", "authors": ["Phatiphat Thounthong", "Stephane Rael", "Bernard Davat"], "n_citation": 327, "references": ["8355e39a-f760-4983-8090-8e08968f151b", "b59736dc-b0ad-462a-a4ec-8fd0484fe54f", "c29fb240-3977-43be-893d-60df49eb7300", "d822cd90-4953-44e7-9d7e-3eb1908ad9b4"], "title": "Control Strategy of Fuel Cell and Supercapacitors Association for a Distributed Generation System", "venue": "IEEE Transactions on Industrial Electronics", "year": 2007, "id": "3ca35fcf-e124-4db6-aba3-c100a551c08d"}
{"abstract": "A procedure is described for the segmentation, content-based coding and visualization of videoconference image sequences. First, image sequence analysis is used to estimate the shape and motion parameters of the person facing the camera. The foreground object is segmented in a number of subobjects, in order to identify the facial region. For this purpose, we propose the novel procedure of K-Means with connectivity constraint algorithm as a general segmentation algorithm combining several types of information including intensity, motion and compactness. In this algorithm, the use of spatiotemporal regions is introduced since a number of frames is analyzed simultaneously and as a result the same region is present in consequent frames. Based on this information, a 3D ellipsoid is adapted to the person's face using an efficient and robust algorithm. The rigid 3D motion is estimated next using a least median of squares approach. Finally a VRML file is created containing all the above estimated information; this file may be viewed by using any VRML 2.0 compliant browser.", "authors": ["Ioannis Kompatsiaris", "Michael G. Strintzis"], "n_citation": 50, "references": ["0907df46-3b6e-426d-850f-e23fc3f228bc", "0cac217b-02bd-4edf-ac43-04d3b070bfed", "19e16ec8-a32d-488c-a94a-8489977df7e4", "1c63e1d5-b963-455b-829d-e4f3eb63a36a", "42e47d91-84a5-47c0-af5a-8d89d20359e5", "4aeab978-6667-4744-926d-710b31d9f127", "4cc695ac-1bb4-49a7-ad53-426dffeeebfe", "5a2c55a4-a53b-431e-9edd-dabfac3eb22d", "5fadd790-4d5c-4a63-9d0c-39661713cf69", "62cea645-dfc7-4d22-b168-fdfdf9c56e4c", "6d077438-049e-4272-914b-f8ab0cabff6c", "87125b11-a5e2-4489-b442-2b6144c93758", "87c16587-6c41-4d12-ab2e-dde3a3972542", "8859baf1-a021-4832-9a3f-72e52aa10fc7", "925a447b-2d6f-46f6-a529-b0c29c6f9a48", "95a4fce7-82c8-4bb9-a7cf-e6cea308ac56", "988e51d5-75de-4102-8659-b2d9a87db947", "9a09b515-2ba1-4a8e-a4fe-d81bdca1ef74", "9a1967e7-a302-4f6d-bc3d-6457f086e8a5", "a39db4f3-548c-4c77-81f4-8888d6c4bc8b", "b608af66-6368-44dc-a670-2a3e42561ee1", "c7753682-b4da-421f-8e64-838f71e71c46", "cc893d0d-11ba-4c2a-9c87-328e15028ddd", "dd7a9a2d-65e4-4f94-bd5e-82e62b4d8606", "e12669f5-205b-4208-a379-1ed67fb33405", "e265d8be-11cf-4b4e-ad11-9e51441f4547", "e86127d8-1fb2-4fc0-b850-14754824745f", "ef087d1e-986b-4faf-a9d6-30f281f0604b"], "title": "Spatiotemporal segmentation and tracking of objects for visualization of videoconference image sequences", "venue": "international conference on multimedia computing and systems", "year": 1999, "id": "10902ad2-51a3-4f64-bb33-4323be5dc34e"}
{"abstract": "The paper presents a new way to reduce the size of the training set without significantly decreasing the classification quality. The effectiveness of the proposed algorithm is examined for the class sensitive neural network (CSNN) presented in WCNN93 by Chen and You (1993) although the same approach can be applied also to other kinds of classifiers. Ten different experiments with a very large remote sensing data set were performed to verify the proposed approach.", "authors": ["Chi Hau Chen", "A. J\u00f3\u017awik"], "n_citation": 61, "references": ["7de100e1-5e54-4e4a-918f-d78f90339939"], "title": "A sample set condensation algorithm for the class sensitive artificial neural network", "venue": "Pattern Recognition Letters", "year": 1996, "id": "06d3fe2b-7920-4504-a8a9-f4ea00eaf0a5"}
{"abstract": "Predicting currency movements has always been a problematic task as most conventional econometric models are not able to forecast exchange rates with significantly higher accuracy than a naive random walk model. For large multinational firms which conduct substantial currency transfers in the course of business, being able to accurately forecast the movements of exchange rates can result in considerable improvement in the overall profitability of the firm. In this study, we apply the General Regression Neural Network (GRNN) to predict the monthly exchange rates of three currencies, British pound, Canadian dollar, and Japanese yen. Our empirical experiment shows that the performance of GRNN is better than other neural network and econometric techniques included in this study. The results demonstrate the predictive strength of GRNN and its potential for solving financial forecasting problems.", "authors": ["Mark T. Leung", "An Sing Chen", "Hazem Daouk"], "n_citation": 215, "references": [], "title": "Forecasting exchange rates using general regression neural networks", "venue": "Computers & Operations Research", "year": 2000, "id": "905cccc0-ead2-4bd0-a396-933a26a32b1c"}
{"abstract": "An architecture that provides personalised filtering and dissemination of news items is presented. It is based on user profiles and it provides mechanisms that allow the user to control and tailor to his own needs the interaction between three different sources of relevance judgements: the existing newspaper categorisation by sections, basic information retrieval on user selected keywords, and an additional operation of automatic categorisation against an alternative hierarchy of categories. These three tiers cover some of the most promising access methods for digital libraries. The proposed architecture has been implemented and evaluation results are presented, covering user response, system efficiency, and user preferences regarding the set of methods made available to them.", "authors": ["Alberto D\u00edaz Esteban", "Pablo Gerv\u00e1s G\u00f3mez-Navarro", "Antonio Garc\u00eda Jim\u00e9nez"], "n_citation": 20, "references": ["33d6dabd-c086-4a6e-939a-c322b6ada724", "3e8efda4-231d-446a-8ab6-8c543f4dec23", "3f394e9d-c50a-4505-9b76-458f5e8be345", "55b0f4a4-b8c2-45e9-8979-cf5510efa59b", "bb74ee29-c9bd-4ed8-978c-295045e24594"], "title": "Evaluating a User-Model Based Personalisation Architecture for Digital News Services", "venue": "european conference on research and advanced technology for digital libraries", "year": 2000, "id": "49555560-4905-4472-a723-781c6b7fdec1"}
{"abstract": "This paper proposes a technique to synthesize parametric rate values in continuous-time Markov chains that ensure the validity of bounded reachability properties. Rate expressions over variables indicate the average speed of state changes and are expressed using the polynomials over reals. The key contribution is an algorithm that approximates the set of parameter values for which the stochastic real-time system guarantees the validity of bounded reachability properties. This algorithm is based on discretizing parameter ranges together with a refinement technique. This paper describes the algorithm, analyzes its time complexity, and shows its applicability by deriving parameter constraints for a real-time storage system with probabilistic error checking facilities.", "authors": ["Tingting Han", "Joost-Pieter Katoen", "Alexandru Mereacre"], "n_citation": 55, "references": ["486eba99-d4c6-4e0f-950a-d7b87b700955", "78b797a4-08bf-47b9-891e-f289eec0d017", "9a7e8549-bc5a-4fac-bba9-c4951f655a31", "a8502fed-22df-4101-b84e-d225a390161d", "c9721e32-74ba-4489-b787-8049210a410d", "daa1ac1c-a8d1-4fce-a80b-930bfb3d08d8", "e0c3960f-9453-4ef8-9bbd-0815421fb8b2", "ef63e495-2f17-427d-9ee2-bcf72e9ddb9d", "ef9f727a-b8d9-4c44-9a4c-91a3ab4f0dad"], "title": "Approximate Parameter Synthesis for Probabilistic Time-Bounded Reachability", "venue": "real-time systems symposium", "year": 2008, "id": "4b670723-c39d-46ef-b7cd-cb2cd2ea3e9a"}
{"abstract": "This paper addresses the blind separation of convolutive and temporally correlated speech mixtures, through the use of a multichannel blind deconvolution (MBD) method. In the proposed method (NGA-LP) spatio-temporal separation is achieved by entropy maximization using the natural gradient algorithm (NGA), while a temporal prewhitening stage, based on linear prediction (LP), preserves the original spectral characteristics of each source contribution. It is further shown that a parameterized optimal nonlinearity derived from the generalized Gaussian density (GGD) model, increases the overall separation performance. Experiments with convolutive mixtures illustrate the merits of the proposed method.", "authors": ["Kostas Kokkinakis", "Asoke K. Nandi"], "n_citation": 9, "references": ["43a3517e-3402-4b2f-aace-a3fb9432a62f", "5fdeb3e0-3dd8-4699-9da9-5b1deeebcde0", "6f339396-22e8-41d0-a2f7-ff4f78665b45", "77097061-8578-4b9f-aca8-22f6a48c101b", "7ccac9f1-f310-45b1-9c15-7ff32f1052c7", "7d150afa-0bd6-495e-8755-47bea06395bc", "ef67d40f-76f0-482c-ae69-18a7a73deb83"], "title": "Optimal blind separation of convolutive audio mixtures without temporal constraints", "venue": "international conference on acoustics, speech, and signal processing", "year": 2004, "id": "6fed4a98-b052-40c5-b2d6-57c4ba395a2b"}
{"abstract": "The performance engineering of distributed applications requires models that capture contention for both hardware and software resources. Layered queueing models have been proposed for modeling distributed applications but they require model parameters that can be difficult to measure directly. In particular, measures of resource demand must be found for each of the services provided by application processes.We consider two approaches for collecting the resource demands of services. The first is a measurement-based approach where resource consumption is specifically allocated to each service. The second makes use of performance measures available from operating systems and distributed application performance monitors but employs statistical techniques to estimate the resource demands of each of the services. This paper discusses the trade-off between these two approaches and presents results from the statistical analysis.", "authors": ["Jerome A. Rolia", "Vidar Vetland"], "n_citation": 51, "references": ["044f7926-4248-4ae0-b3d0-f41546505a75", "39662e53-83bc-419a-991d-d1ef624d7c33", "42878fab-552a-4692-abe6-07e675b108cc", "53fd103a-efc2-435b-a55b-a57b19a79754", "937702cd-0326-44b6-a9a5-ad1e48316458", "b5f6eb33-8b71-4101-aca2-45ee502748ab", "c83534a5-9f23-4d17-a2e1-cb1efdb9e515", "c85754d5-6a45-4254-a5f1-91b429dd893d"], "title": "Parameter estimation for performance models of distributed application systems", "venue": "conference of the centre for advanced studies on collaborative research", "year": 1995, "id": "77e6fe10-5c0b-495b-8f85-7f7178abb6e9"}
{"abstract": "Clustering algorithms have been applied in several disciplines successfully. One of those applications is the initialization of Radial Basis Functions (RBF) centers composing a Neural Network, designed to solve functional approximation problems. The Clustering for Function Approximation (CFA) algorithm was presented as a new clustering technique that provides better results than other clustering algorithms that were traditionally used to initialize RBF centers. Even though CFA improves performance against other clustering algorithms, it has some flaws that can be improved. Within those flaws, it can be mentioned the way the partition of the input data is done, the complex migration process, the algorithm's speed, the existence of some parameters that have to be set in order to obtain good solutions, and the convergence is not guaranteed. In this paper, it is proposed an improved version of this algorithm that solves the problems that its predecessor has using fuzzy logic successfully. In the experiments section, it will be shown how the new algorithm performs better than its predecessor and how important is to make a correct initialization of the RBF centers to obtain small approximation errors.", "authors": ["Alberto Guill\u00e9n", "Ignacio Rojas", "Jes\u00fas Gonz\u00e1lez 0001", "H\u00e9ctor Pomares", "Luis Javier Herrera", "Olga Valenzuela", "Alberto Prieto"], "n_citation": 50, "references": ["329f591b-bfd4-4dad-b198-add712639016", "35305b9b-c2e5-4e40-af23-00402c2748e6", "3b939907-d596-4223-b1f2-b54a8e259d0d", "8e5657aa-53c8-4483-bf24-1e86867eb47b", "9ba74674-2280-4b06-883e-a3b43d3c67ce"], "title": "Improving clustering technique for functional approximation problem using fuzzy logic: ICFA algorithm", "venue": "international conference on artificial neural networks", "year": 2005, "id": "33a9cc70-0c46-4893-a173-55d9141d7d45"}
{"abstract": "We study the setting in which a user stores encrypted documents (e.g. e-mails) on an untrusted server. In order to retrieve documents satisfying a certain search criterion, the user gives the server a capability that allows the server to identify exactly those documents. Work in this area has largely focused on search criteria consisting of a single keyword. If the user is actually interested in documents containing each of several keywords (conjunctive keyword search) the user must either give the server capabilities for each of the keywords individually and rely on an intersection calculation (by either the server or the user) to determine the correct set of documents, or alternatively, the user may store additional information on the server to facilitate such searches. Neither solution is desirable; the former enables the server to learn which documents match each individual keyword of the conjunctive search and the latter results in exponential storage if the user allows for searches on every set of keywords. We define a security model for conjunctive keyword search over encrypted data and present the first schemes for conducting such searches securely. We propose first a scheme for which the communication cost is linear in the number of documents, but that cost can be incurred offline before the conjunctive query is asked. The security of this scheme relies on the Decisional Diffie-Hellman (DDH) assumption. We propose a second scheme whose communication cost is on the order of the number of keyword fields and whose security relies on a new hardness assumption.", "authors": ["Philippe Golle", "Jessica Staddon", "Brent Waters"], "n_citation": 574, "references": ["1c6f3989-6c2d-4fd0-b9d8-783c1532ae98", "303de912-ad33-4803-a1bb-6e460b4ab449", "45d56db9-7547-4c37-98be-5da5546144dd", "69867d3d-c55b-4665-8ea2-865ed050f411", "85a76c63-c431-4ad4-9bf9-1829bcfe38f0", "893a5aed-c5c0-459e-94ee-4dd3ae3a96b6", "aeac2476-6970-4b54-8ec2-6d83fac61ae6", "d08767f9-7722-43fc-979a-3928a91cb1ea", "ed804c0f-dad5-4ce5-9da3-f69da43f137a", "fe9f9568-35a4-4abe-a469-a37d8fb43947"], "title": "Secure Conjunctive Keyword Search over Encrypted Data", "venue": "applied cryptography and network security", "year": 2004, "id": "406bfd32-2d17-48b0-834b-8420b725fe45"}
{"abstract": "Multiagent learning literature has investigated iterated two-player games to develop mechanisms that allow agents to learn to converge on Nash Equilibrium strategy profiles. Such equilibrium configuration implies that there is no motivation for one player to change its strategy if the other does not. Often, in general sum games, a higher payoff can be obtained by both players if one chooses not to respond optimally to the other player. By developing mutual trust, agents can avoid iterated best responses that will lead to a lesser payoff Nash Equilibrium. In this paper we work with agents who select actions based on expected utility calculations that incorporates the observed frequencies of the actions of the opponent(s). We augment this stochastically-greedy agents with an interesting action revelation strategy that involves strategic revealing of one's action to avoid worst-case, pessimistic moves. We argue that in certain situations, such apparently risky revealing can indeed produce better payoff than a non-revealing approach. In particular, it is possible to obtain Pareto-optimal solutions that dominate Nash Equilibrium. We present results over a large number of randomly generated payoff matrices of varying sizes and compare the payoffs of strategically revealing learners to payoffs at Nash equilibrium.", "authors": ["Sandip Sen", "St\u00e9phane Airiau", "Rajatish Mukherjee"], "n_citation": 34, "references": ["1797a9c0-5d78-4643-a608-05d54cc3da0e", "1e13f910-e5b8-4f1c-89fc-d3b9c70d6b6b", "2bb876dc-4219-49f0-8f35-2ba057e12dea", "42f10be9-da7b-4d94-baec-d02efbb0815e", "4f71a9f0-28b0-4589-a1f5-559858a63d8c", "6d7a35a0-9d26-4052-abdc-1ba8c9c9133a", "7d4aa8eb-58cc-4a7c-8f54-8498c9e309b5"], "title": "Towards a pareto-optimal solution in general-sum games", "venue": "adaptive agents and multi-agents systems", "year": 2003, "id": "02daf4eb-8065-4d23-9a7d-e7d1c129845e"}
{"abstract": "This paper provides fast algorithms to perform independent component analysis based on the mutual information criterion. The main ingredient is the binning technique and the use of cardinal splines, which allows the fast computation of the density estimator over a regular grid. Using a discretized form of the entropy, the criterion can be evaluated quickly together with its gradient, which can be expressed in terms of the score functions. Both offline and online separation algorithms have been developed. Our density, entropy, and score estimators also have their own interest.", "authors": ["Dinh-Tuan Pham"], "n_citation": 85, "references": ["0ddbfee1-8cc2-49f6-be79-59276f496884", "0e2afba3-c7e5-4af4-9ea3-d2ec3742cbd9", "5ea8b0c0-b15b-471d-9137-109b77cd3312", "69711a3b-db28-493e-ba84-523c8c22803d", "7d150afa-0bd6-495e-8755-47bea06395bc", "bbb3f3b9-e7fa-49c8-b563-f287aa82288f", "bf818cbf-01ee-4fd8-baa0-e2f1c5fd73be", "f0bd3fd0-dea7-479d-9c15-6a6cc770bf38"], "title": "Fast algorithms for mutual information based independent component analysis", "venue": "IEEE Transactions on Signal Processing", "year": 2004, "id": "1ab37fa4-8ab0-456d-8819-4597158d16b2"}
{"abstract": "This paper introduces a sensor-based planning algorithm that uses less sensing information than any others within the family of bug algorithms. The robot is unable to access precise information regarding position coordinates, angular coordinates, time, or odometry, but is nevertheless able to navigate itself to a goal among unknown piecewise-analytic obstacles in the plane. The only sensor providing real values is an intensity sensor, which measures the signal strength emanating from the goal. The signal intensity function may or may not be symmetric; the main requirement is that the level sets are concentric images of simple closed curves, i.e. topological circles. Convergence analysis and distance bounds are established for the presented approach.", "authors": ["Kamilah Taylor", "Steven M. LaValle"], "n_citation": 33, "references": ["0925faa3-b550-4032-a5e2-d63d20825609", "13bccaf8-54ac-4e0c-86fd-8426fbc53d50", "17ae8acf-2133-498e-964c-0b16524443e3", "2272db89-65c2-43c4-ad2d-fa015eb1c556", "35f6acb8-6ffc-47b1-b8a4-4764d5200685", "4ffd8857-ccf9-45eb-bd75-562ace919d09", "6403ec6b-30fd-44db-916c-11dd3355033d", "94276c9e-30e2-40fb-81cf-bf694cf7a327", "97ce3b24-a0a0-41d6-a402-5d81276c00d0", "b5376d41-2b04-4e03-aa99-381475780e15", "cb606d03-970e-41f2-8d73-911989874285"], "title": "I-Bug: An intensity-based bug algorithm", "venue": "international conference on robotics and automation", "year": 2009, "id": "e338706d-a275-4678-a5aa-1f811ff47cf1"}
{"abstract": "Signal separation for a general system of an arbitrary number of signals is investigated. The signal separation research area deals with the problem of separating unknown source signals that are mixed in an unknown way when only these mixtures are available. A criterion, based on second-order statistics, is formulated to be used in estimating the mixing system. This estimate of the mixing system is used in a separation structure with a parameterization that minimizes the number of parameters to be estimated. Formulae for the gradient and Hessian of the criterion are derived. A formula for the lower bound for the variance of the estimated parameters of the mixing matrix is derived. This lower bound is the asymptotic (assuming the number of data samples to be large) Cramer-Rao lower bound (CRLB). The proposed algorithm is tested with simulations and compared with the CRLB.", "authors": ["Henrik Sahlin", "Holger Broman"], "n_citation": 50, "references": ["05836f0a-514e-4dc0-bcbe-d5d0b196a9c4", "0ddbfee1-8cc2-49f6-be79-59276f496884", "0f2aaeda-6cad-4837-8be4-f2a169ec380b", "2b85f1f2-9be8-4b74-8305-ac2b699768cc", "5847e2de-ecff-4b0e-9c68-56b29e1c2657", "7474b8db-3d96-47db-8db7-a4df84ef94ff", "90af885e-4af3-4a13-9a76-6e7cd7fce265", "a4a65bf5-7fbe-4d2d-bca4-b98fcc638d3f", "ce43295c-4243-45fa-890b-a31f172f20d9", "d4a1eec5-1efe-4096-b13f-8031ab0cfbb5", "e336396f-cc15-4035-a36f-ac93f870fb10", "e981ce7f-106d-453b-a438-123cfa05ec60"], "title": "MIMO signal separation for FIR channels: a criterion and performance analysis", "venue": "IEEE Transactions on Signal Processing", "year": 2000, "id": "a30161aa-8026-4af5-a3ab-31cd2de5ca55"}
{"abstract": "Experimental verification of a recently developed algorithm, sliding mode control with perturbation estimation (SMCPE), is performed, a two-axes planar SCARA type robot is used as the test platform. The controller is a PC-based microprocessor with transducer and actuator interfaces. The objective of trajectory tracking is achieved by directly controlling the joint torques, despite the modeling deficiencies and unknown disturbances. Two major practical issues are considered. One of them is the measurement noise and the other is the hard/software limitations on the control loop closure speed. Both of these issues affect the parametric selections with the SMCPE algorithm. A sample test result is presented, to compare the performance of SMCPE with the classical SMC.", "authors": ["Hakan Elmali", "Nejat Olgac"], "n_citation": 135, "references": ["0f64abff-fe48-4ffb-a752-536d6e8f085a", "b66c9603-ec10-41ee-ad9e-27f18a271d8b"], "title": "Implementation of sliding mode control with perturbation estimation (SMCPE)", "venue": "IEEE Transactions on Control Systems and Technology", "year": 1996, "id": "cac4c3b0-5eec-4765-bccf-ae9f6d3dc7dd"}
{"abstract": "DCPS is a connectionist production system interpreter that uses distributed representations. As a connectionist model it consists of many simple, richly interconnected neuron-like computing units that cooperate to solve problems in parallel. One motivation for constructing DCPS was to demonstrate that connectionist models are capable of representing and using explicit rules. A second motivation was to show how \u201ccoarse coding\u201d or \u201cdistributed representations\u201d can be used to construct a working memory that requires far fewer units than the number of different facts that can potentially be stored. The simulation we present is intended as a detailed demonstration of the feasibility of certain ideas and should not be viewed as a full implementation of production systems. Our current model only has a few of the many interesting emergent properties that we eventually hope to demonstrate: It is damage-resistant, it performs matching and variable binding by massively parallel constraint satisfaction, and the capacity of its working memory is dependent on the similarity of the items being stored.", "authors": ["David S. Touretzky", "Geoffrey E. Hinton"], "n_citation": 445, "references": ["7581d7a3-6fee-4875-85c8-f1e20c7f6997", "991bb85a-f14e-418e-9155-305684f02c77", "a490560f-05e2-4c2f-8b1f-0e9392eb9715", "b32fe4ac-a592-405f-8b59-11a478e895bb", "c2fcbf87-4baf-4f15-aabb-cd857898382e", "ebd2e2fa-20f6-4e39-85d5-fe4fdc316f23"], "title": "A Distributed Connectionist Production System.", "venue": "Cognitive Science", "year": 1988, "id": "ead3ffd5-dea8-49cd-8cf4-b31617c7c23a"}
{"abstract": "Animations express a sense of process and continuity that is difficult to convey through other techniques. Although interfaces can often benefit from animation, User Interface Management Systems (UIMSs) rarely provide the tools necessary to easily support complex, state-dependent application output, such as animations. Here we describe Player, an interface component that facilitates sequencing these animations. One difficulty of integrating animations into interactive systems is that animation scripts typically only work in very specific contexts. Care must be taken to establish the required context prior to executing an animation. Player employs a precondition and postcondition-based specification language, and automatically computes which animation scripts should be invoked to establish the necessary state. Player\u2019s specification language has been designed to make it easy to express the desired behavior of animation controllers. Since planning can be a timeconsuming process inappropriate for interactive systems, Player precompiles the plan-based specification into a state machine that executes far more quickly. Serving as an animation controller, Player hides animation script dependencies from the application. Player has been incorporated into the Persona UIMS, and is currently used in the Peedy application.", "authors": ["David Kurlander", "Daniel T. Ling"], "n_citation": 55, "references": ["036be3f9-d3a4-4436-a5b4-14dec87f9d1a", "0c7bb8fe-f930-44ba-bf95-eb327ed3fe04", "20b186a7-48fb-4136-a481-7f20c41feba9", "47b867a5-4b3b-4ede-a296-14d013923bb8", "5a7cfe4e-f729-4304-901b-f7ac97cb2c07", "6016c104-5e77-48aa-ad48-399de21c1a38", "678a991e-50ae-447d-836a-b6965c5e5242", "7cc24776-ccae-473d-9bf5-83ab7e5fdfdb", "9636f9cd-0a36-44a3-a04a-b33ec8fc6ea0", "f31e08c4-32c3-4e61-8893-ac6c2ac2c951", "f4992e4b-6afb-45fb-8927-7d997be23bc0"], "title": "Planning-based control of interface animation", "venue": "human factors in computing systems", "year": 1995, "id": "02991e3c-1273-4a3e-80c6-ef9bc90f6dc0"}
{"abstract": "We introduce the  BiBa signature  scheme, a new signature construction that uses one-way functions without trapdoors. BiBa features a low verification overhead and a relatively small signature size. In comparison to other one-way function based signature schemes, BiBa has smaller signatures and is at least twice as fast to verify (which probably makes it one of the fastest signature scheme to date for verification). On the downside, the BiBa public key is large, and the signature generation overhead is higher than previous schemes based on one-way functions without trapdoors (although it can be trivially parallelized).One of the main challenges of securing broadcast communication is source authentication, which allows all receivers to verify the origin of the data. An ideal broadcast authentication protocol should be efficient for the sender and the receiver, have a small communication overhead, allow the receiver to authenticate each individual packet, provide perfect robustness to packet loss, scale to large numbers of receivers, and provide instant authentication (no buffering of data at the sender or receiver side). We are not aware of any previous protocol that satisfies all these properties. We present the BiBa broadcast authentication protocol, a new construction based on the BiBa signature, that achieves all our desired properties, with the tradeoff that it requires a moderate computation overhead for the sender to generate the authentication information, and that it requires loose time synchronization between the sender and receivers.", "authors": ["Adrian Perrig"], "n_citation": 359, "references": ["09756c4e-2414-4dd1-8e35-c1410d3511b6", "0ab8c0f9-fdba-428d-81a3-da79d759598e", "0e1c9c62-343a-447a-9b47-9b3012656cdb", "28fa59f0-eca3-4c79-a2e8-2a60a9180b1c", "3fb43b00-905c-4a08-934d-198ea4eb66c3", "48a829fd-7c8f-4bb7-b481-ae23d55570a2", "5b1e835f-1448-486d-8b09-e1777e5297c9", "6ad1cf29-4770-4689-8e68-7e5cfd51d6ee", "745f0f29-0489-4906-b625-fd0efa9f85aa", "76461566-399b-4e4b-a8d4-ee73f2d6105b", "86ddec47-506e-4876-9c52-4599095cdf41", "8f75301b-6064-44dd-b934-6723bbb82144", "aba5c11b-37c4-4ec2-86ec-34d66d2b572b"], "title": "The BiBa one-time signature and broadcast authentication protocol", "venue": "computer and communications security", "year": 2001, "id": "14fad69f-ca65-4a1e-aa27-1650cecb6561"}
{"abstract": "We describe an image based rendering approach that generalizes many current image based rendering algorithms, including light field rendering and view-dependent texture mapping. In particular, it allows for lumigraph-style rendering from a set of input cameras in arbitrary configurations (i.e., not restricted to a plane or to any specific manifold). In the case of regular and planar input camera positions, our algorithm reduces to a typical lumigraph approach. When presented with fewer cameras and good approximate geometry, our algorithm behaves like view-dependent texture mapping. The algorithm achieves this flexibility because it is designed to meet a set of specific goals that we describe. We demonstrate this flexibility with a variety of examples.", "authors": ["Chris Buehler", "Michael Bosse", "Leonard McMillan", "Steven J. Gortler", "Michael F. Cohen"], "n_citation": 742, "references": ["0ff7c995-1ad2-4b55-9a38-ab8a1192313c", "1040dc99-1987-496b-b467-aa116e7faf25", "121f1ba8-08de-42f7-9225-b6eda43a4e6b", "2bbcd656-eb94-49a1-b533-bff1fab0abab", "4197f8df-52d8-427c-8067-c024ff9e3e72", "70e017b3-5711-4eae-aaa5-099139440342", "79423898-0d78-4492-863e-0cabc2dd1cd7", "87a3e0c6-9219-41ee-8638-ea7a86fb8ef3", "9d2f01af-98af-4e6a-966c-45378fdae334", "a57f95ca-0d35-453a-a821-9c42a827d3f7", "ab0671ba-b9af-414a-ad8b-59751ae03019", "c18f4630-af32-42b6-aa66-810d275b2981", "e61b9dd4-bc17-4f5a-a5b3-a6f5e480dd8e", "e7306777-27d9-4f43-965d-7a234da5d972", "f8708445-57ea-4604-9aac-53054ffe4ecc"], "title": "Unstructured lumigraph rendering", "venue": "international conference on computer graphics and interactive techniques", "year": 2001, "id": "c56e8155-8636-4c28-9b6d-a879582c63fa"}
{"abstract": "Many interesting examples in view maintenance involve semijoin and outerjoin queries. In this paper we develop algebraic change propagation algorithms for the following operators: semijoin, anti-semijoin, left outerjoin, right outerjoin, and full outerjoin.", "authors": ["Timothy G. Griffin", "Bharat Kumar"], "n_citation": 24, "references": ["484223ff-4b36-4804-b7f9-5c61202efa2c", "76babdfa-c9e3-473f-98ca-9218625a9c7e", "d9b15916-c439-437e-bc2c-a34443124f2a", "fa0ac91f-6dcf-4ddd-ac9e-e192111cdcae"], "title": "Algebraic change propagation for semijoin and outerjoin queries", "venue": "international conference on management of data", "year": 1998, "id": "a2ae82a9-949f-4c81-b017-02b65e47dc9e"}
{"abstract": "We consider an extension of Datalog with mechanisms for temporal, nonmonotonic, and nondeterministic reasoning, which we refer to as Datalog++. We show, by means of examples, its flexibility in expressing queries concerning aggregates and data cube. Also, we show how iterated fixpoint and stable model semantics can be combined to the purpose of clarifying the semantics of Datalog++ programs and supporting their efficient execution. Finally, we provide a more concrete implementation strategy on which basis the design of optimization techniques tailored for Datalog++ is addressed.", "authors": ["Fosca Giannotti", "Giuseppe Manco", "Mirco Nanni", "Dino Pedreschi"], "n_citation": 50, "references": ["0f2423fd-c991-4dfa-838c-d4a7a3c2fb16", "0fd06548-03f5-4476-98e5-96e9e62a84b9", "2af84dd2-1b9e-4aa2-9013-f9774e7d8f2a", "349b4cb0-7d84-4aa8-bd0c-055804f8db1f", "3a66ddb7-a3fa-498f-8fdb-2814cec8ec53", "3e197d90-edd2-4bd8-a357-6da1eea43a46", "493cda6b-a010-41f7-b507-9057e846001f", "6ebb37de-4861-49a1-8eab-e386862c695a", "6f400c81-0e0f-4e1a-ae78-384e260228fa", "7cb0ee0e-401b-45af-9f77-ea771a464f3f", "8483a4c0-0f41-4f24-a5fa-d2c05e32421d", "8d6430dc-a8ca-40ed-bead-a523aa31850c", "9e0be164-e7eb-4d96-8101-fdabbd09c4cc", "9e79f0c9-cbdb-45f9-9296-48d06f3c35ed", "b4b66f8c-95b4-4891-a868-3e0e0f81a646", "b7c4b24c-3ed2-44ac-a5a6-df631af67438", "c577545d-17b0-4949-9076-8a4a20810fec", "cbd48263-9e04-45bb-a0e3-9ea0fe26e772", "d8734a6f-e74a-4db0-808b-6c89cf556fa0", "db348c25-fd66-4f91-b676-6d9402cefaa2", "e22908da-10e5-49ec-93ed-2d7b1e1e8da3", "e7158ef7-6b5f-491b-b9a8-fb274fc61512"], "title": "Nondeterministic, nonmonotonic logic databases", "venue": "IEEE Transactions on Knowledge and Data Engineering", "year": 2001, "id": "1a83fb9e-7246-4f82-b752-7e41894820d5"}
{"authors": ["Oswin Aichholzer", "Franz Aurenhammer", "Hannes Krasser"], "n_citation": 72, "title": "Enumerating Order Types for Small Point Sets with Applications.", "venue": "Order", "year": 2002, "id": "506ba7c2-68a3-4e9f-b46e-703f1b160aa2"}
{"abstract": "Sensorless control technology has been a hotspot in the area of BLDCM control. In this paper, a speed controller of BLDCM based on MC56F8013 was researched using BEMF-crossing-zero-detecting method, including hardware circuit and software design. Experiments were implemented and it shows that the BEMF method for detecting rotor position signal is accurate and reliable, BLDC motor can commute and run correctly.", "authors": ["Yuanlou Gao", "Yongliang Liu"], "n_citation": 50, "title": "Research of sensorless controller of BLDC motor", "venue": "", "year": 2012, "id": "6ab64117-a8fd-4bef-8a69-0564aeb6bd9a"}
{"abstract": "Accurate and less invasive personalized predictive medicine can spare many breast cancer patients from receiving complex surgical biopsies, unnecessary adjuvant treatments and its expensive medical cost. Cancer prognosis estimates recurrence of disease and predict survival of patient; hence resulting in improved patient management. To develop such knowledge based prognostic system, this paper examines potential hybridization of accuracy and interpretability in the form of Fuzzy Logic and Decision Trees, respectively. Effect of rule weights on fuzzy decision trees is investigated to be an alternative to membership function modifications for performance optimization.#R##N##R##N#Experiments were performed using different combinations of: number of decision tree rules, types of fuzzy membership functions and inference techniques for breast cancer survival analysis. SEER breast cancer data set (1973-2003), the most comprehensible source of information on cancer incidence in United States, is considered. Performance comparisons suggest that predictions of weighted fuzzy decision trees (wFDT) are more accurate and balanced, than independently applied crisp decision tree classifiers; moreover it has a potential to adapt for significant performance enhancement.", "authors": ["Umer Khan", "Hyunjung Shin", "Jong Pill Choi", "Minkoo Kim"], "n_citation": 7, "references": ["25df3114-b226-40b1-b1ee-321f7b1d901d", "2aea0eff-604e-4f3b-9f74-b5c21b7fcc32", "3484ad55-2cd4-4de5-8cec-70dfb2faa7cb", "70ad8af1-7a3e-4428-95f2-4ebd9a8bafc2", "73f7e31b-c9d8-478e-bc30-6a61313e1373", "787e5d56-abc1-41ff-91cd-bd99fddfb752", "b49c1e2b-0cd0-4950-a724-00c698e5b49d", "f1412aa2-5177-4649-8f49-df95a579127c", "fa7c2640-4660-48b4-bf41-086b80be0f1b", "fcb41378-32f7-4aab-8458-fc5a99d74f92"], "title": "wFDT: weighted fuzzy decision trees for prognosis of breast cancer survivability", "venue": "australasian data mining conference", "year": 2008, "id": "46cc1198-2f43-4cc4-970b-d0ee0c3450a0"}
{"abstract": "Most existing workflow management systems (WFMSs) are based on a client/server architecture. This architecture simplifies the overall design but it does not match the distributed nature of workflow applications and imposes severe limitations in terms of scalability and reliability. Moreover workflow engines are not very sophisticated in terms of data management. Forgetting the fact that workflow is, to a great extent, data flow. In this paper we propose a novel architecture to address the issue of data management in a WFMS. This architecture is based on a fully distributed workflow engine for control flow, plus a set of loosely synchronized replicated databases for dataflow. The resulting system offers greater robustness and reliability as well as much better data handling capabilities than existing approaches. To better illustrate this novel architecture and its implications, two commercial systems are employed in this paper: FlowMark, as the workflow engine, and the replication capabilities of Lotus Notes, as the support system for distributed data management.", "authors": ["Gustavo Alonso", "Berthold Reinwald", "C. Mohan"], "n_citation": 50, "references": ["0d7b6cdd-49ce-4b56-87e2-d89117bc4485", "5a3d25d4-7f7f-4578-bcc7-cac7e5478785", "6e7a0fb7-be9f-4da1-9865-fa3c90afd491", "765a5f62-24d9-4ae0-a6d9-79c143d6d5eb", "77885af1-2abe-42b3-9f35-8a8e88e2c1d6", "822c95f0-5df9-4219-ad70-b44ca6b4c23d", "832acb23-caba-4e3a-99ea-34345fff1fe4", "e80c452f-aaa0-4913-9594-fdc0d383e6e4", "f24fa5e5-549f-4df8-ad55-060f9b39c92a"], "title": "Distributed data management in workflow environments", "venue": "", "year": 1997, "id": "d38dc950-53a2-42e4-89e8-0ccee09039b0"}
{"abstract": "NewsStand is a Web-based mapping application that we have developed to enable searching for spatially-referenced information by using a map query interface. Previously, we adapted the Web version to execute on mobile devices such as smartphones where the main issue that was confronted was how to deal with the considerably smaller display screen while retaining access to the application through the browser. In the current work we discuss the issues that we encountered in converting the Web-based application to a native App primarily on the iPhone and iPod Touch. These issues involve how to compensate for the absence of a hovering action as well as how to integrate an interaction restriction to one hand coupled with use of the thumb as the pointing mechanism. In addition, a significant effort is devoted to the implementation of an intuitive mechanism for undoing the most recent actions. Other issues include the formulation of navigation shortcuts to avoid excessive traffic with the supporting database.", "authors": ["Hanan Samet", "Marco D. Adelfio", "Brendan C. Fruin", "Michael D. Lieberman", "Benjamin E. Teitler"], "n_citation": 30, "references": ["0cae9a8f-fc03-4423-b0e3-c53ac4cea1e9", "20940852-cbca-41a7-8332-caeb9624ea21", "557ff47b-48d5-43fe-b55d-ba061ccf3b05", "5c0a33a7-518a-4b98-9b1b-d9f68f4c4ed3", "6e363316-cee2-467b-b536-1fd80f0df945", "769414cd-d66f-4db0-aa0f-c1bfbef9ba89", "83d51bf8-5f36-48b9-8ca3-945a92877a37", "b69b7975-c914-42a9-aa9d-57447d9aa1c2", "dc620c13-dedb-400e-8102-bfb209cf156e"], "title": "Porting a web-based mapping application to a smartphone app", "venue": "advances in geographic information systems", "year": 2011, "id": "ba470224-5162-493e-ade5-ce1a5fc2f7d9"}
{"abstract": "Many applications, such as telecommunication, process control, and virtual reality, require real-time access to database. Main-memory DBMS, which becomes feasible with the increasing availability of large and relatively cheap memory, can provide better performance than disk-based systems for real-time applications. This paper presents an overall architecture of M/sup 2/RT, a main-memory real-time DBMS, and an object-oriented design of its storage system called M/sup 2/RTSS. M/sup 2/RTSS provides classes that implement the core functionality of storage management, real-time transaction scheduling, and recovery. Implemetation-specific information is encapsulated in these classes and extensions can be made by inheritance. With object-oriented features, M/sup 2/RTSS can easily incorporate new development in application requirements and the result of ongoing research in real-time systems.", "authors": ["Sang Kyun Cha", "Byoung Dae Park", "S. J. Lee", "Song Sh", "Jang Ho Park", "Lee Js", "S.Y. Park", "Dae Young Hur", "G. B. Kim"], "n_citation": 50, "references": ["15648551-4401-4829-bca7-55ca112dc196", "1f54cf21-37b6-450b-8a69-0778e43ed5a2", "3bc19a45-4283-4aee-88e8-00475cd99a09", "4c28f3ad-c690-4675-8268-2c338a869e69", "502156d9-d444-49f4-a632-b57a337be5fb", "81ad8d98-8e9c-492c-9f0e-dc4b1e6d3d8b", "882904d1-0cea-4b64-8dc9-7d89064047a6", "9be8a55c-4e0b-4f30-9558-cb847b4d05ac", "9e11ddb5-feb9-4a1e-8d2f-adae6bd35770", "9f1f4645-ec07-43c5-b10c-0599f6b59a1a", "a0db6c33-ee9b-4f61-b4f9-75a6010dbb09", "b9405c92-9996-43bc-bfd7-4576b85437e0", "c8dce7b4-2ac1-4bcd-bc11-8f5e0508aa0a", "eb8eb90e-b7e2-4989-babe-a695bef8d349", "f88e7e8c-0ef5-44c5-a731-96e86e59a584"], "title": "Object-oriented design of main-memory DBMS for real-time applications", "venue": "embedded and real-time computing systems and applications", "year": 1995, "id": "66e834e2-b4cb-4212-8df2-d7964d9a5ce5"}
{"abstract": "This paper adds the handling of negative information to a functional-logic deductive database language. By adopting as semantics for negation the so-called CRWLF, wherein the negation is intended as 'finite failure' of reduction, we will define Herbrand algebras and models for this semantics and a fix point operator to be used in a new goaldirected bottom-up evaluation mechanism based on magic transformations. This bottom-up evaluation will simulate the top-down one of the original program; in fact, it will carry out a goal-directed lazy evaluation.", "authors": ["Jes\u00fas Manuel Almendros-Jim\u00e9nez", "Antonio Becerra-Ter\u00f3n", "Jaime S\u00e1nchez-Hern\u00e1ndez"], "n_citation": 6, "references": ["05ed276f-59ad-4172-9540-8282441dd482", "09c19ddd-b0a4-477d-bc0b-025882bca35a", "1b6b7687-f13f-4c39-b928-556c7556cfd6", "1c59442a-9530-4717-9f91-aaee3e7a70db", "32a2c669-8fc4-47f2-97e7-9027674444a0", "5422e6ed-4a06-4e1b-a624-0b3acfbe9fc7", "88ae3b67-86c1-4fa5-b195-0404604c58e2", "9450d088-e14a-47db-af10-da1807eaaa8d", "9d644bad-a5a0-47e6-9ced-3526ef43d034", "b76160ce-757a-44ae-966b-c08be91b4706", "ba2e9901-86c5-4813-83ea-cd173cf2553b", "baa61d39-39ba-442b-b93f-45832344240f", "c1dbe3ac-2aee-4330-b559-bfaf35d78c1d", "d622cd8b-9a88-4a3b-83de-ce18e45ef320", "e22908da-10e5-49ec-93ed-2d7b1e1e8da3", "f5a71c38-cade-42d9-b699-7dcf28bbbfcf"], "title": "A Computational Model for Functional Logic Deductive Databases", "venue": "international conference on logic programming", "year": 2001, "id": "936ce58f-30b2-458f-b2d7-fe9fac9724fc"}
{"abstract": "In this paper we present a real-time distributed optimization algorithm based on Alternating Directions Method of Multipliers (ADMM) for resilient monitoring of power flow oscillation patterns in large power system networks. We pose the problem as a least squares (LS) estimation problem for the coefficients of the characteristic polynomial of the transfer function, and combine a centralized Prony algorithm with ADMM to ex- ecute this estimation via distributed consensus. We consider the network topology to be divided into multiple clusters, with each cluster equipped with a local estimator at the local control center. At any iteration, the local estimators receive Synchrophasor measurements from within their own respective areas, run a local consensus algorithm, and communicate their estimates to a central estimator. The central estimator averages all estimates, and broadcasts the average back to each local estimator as the consensus variable for their next iteration. By imposing a redundancy strat- egy between the local and the global estimators via mutual coordination, we show that the distributed algorithm is more resilient to communication failures as compared to alternative centralized methods. We illustrate our results using a hardware-in-loop power system testbed at NC State feder- ated with a networking and cyber-security testbed at USC/ISI.", "authors": ["Jianhua Zhang", "Prateek Jaipuria", "Aranya Chakrabortty", "Alefiya Hussain"], "n_citation": 6, "references": ["7bed3605-5f0e-49e3-93e5-56270ab5e2d9", "be74ee6d-7ffd-42ce-b158-36dfeabeab32", "e537d143-155e-4ca0-8ae8-66b777a77fea"], "title": "A Distributed Optimization Algorithm for Attack-Resilient Wide-Area Monitoring of Power Systems: Theoretical and Experimental Methods", "venue": "", "year": 2014, "id": "672d4cd2-8579-4637-8a81-20f901e6dc90"}
{"abstract": "The purpose of this article is to define optic flow for scalar and density images without using a priori knowledge other than its defining conservation principle, and to incorporate measurement duality, notably the scale-space paradigm. It is argued that the design of optic flow based applications may benefit from amanifest separation between factual image structure on the one hand, and goal-specific details and hypotheses about image flow formation on the other.#R##N##R##N#The approach is based on a physical symmetry principle known as gauge invariance . Data-independent models can be incorporated by means of admissible gauge conditions, each of which may single out a distinct solution, but all of which must be compatible with the evidence supported by the image data. The theory is illustrated by examples and verified by simulations, and performance is compared to several techniques reported in the literature.", "authors": ["Luc Florack", "Wiro J. Niessen", "Mads Nielsen"], "n_citation": 85, "references": ["0f3f889d-417c-466a-acdc-8e5c2d23f01d", "11fcc40f-35d1-4915-8d06-c9749eae3563", "14582bca-c63d-4f41-8e8e-dedffb742728", "1d7adf37-d57f-4f8b-b25a-c5d288d554d7", "2627623e-f1d5-418e-900d-3881d648a8ed", "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5", "32148a0b-6ce4-4a1e-a1d2-98a96b27b24f", "475e0c5b-7620-464f-b7df-70c2af901725", "497e3634-6d30-49d5-b10e-a84036394e14", "5c0dc59e-043e-4f0a-af9c-907306684456", "5c9b1df4-f013-469d-8074-0b636194e7d9", "64ea7b13-0a46-4d89-925f-8ffd2578690c", "75b8038a-7a64-4118-922e-c794c31e4161", "7cf3da44-b16b-4f1b-b790-f1cf1a7e5ff6", "80a9b6da-20d5-4c69-b9bb-7b26e3e4e8e3", "83e76bdd-72d1-473b-bbcc-16ee400d534b", "83e7f895-4622-45d4-ba94-05999b1b5be3", "84997f76-8c4c-4ee2-b088-6e1e8b882062", "899de8c7-9cd9-4dd5-82f1-ad9acb801f8e", "93a5ad9b-7ab6-49ae-86d8-16f8137be7c6", "a0f22d81-4c66-4774-83b5-1c4bc39c6a85", "ad1b2368-35b0-4b36-8e01-a95924af75da", "b8c18817-9946-4f69-941d-c1c59d85179b", "c8866dd1-97b1-4cad-a41a-4407461ec7c8", "c9fa31f7-f6ce-49ea-b42c-8d03ae59dbe4", "cbc43100-dbde-468f-b2f1-e73a20d5b5bc", "cc9ddd15-4595-4bc1-a44a-79327d19aaa3", "da4ad8b3-5257-487d-9102-5672be35d3f9", "ec35fe29-01e2-4229-8f36-3e68b69736c2", "eff4229a-5c33-47a9-bc20-6ebea2570a6f", "fd99a7a7-0aa2-4607-91bd-975285af5ad1"], "title": "The Intrinsic Structure of Optic Flow Incorporating Measurement Duality", "venue": "International Journal of Computer Vision", "year": 1998, "id": "4d4aae61-7932-4ebe-bb62-2538bf2e8723"}
{"abstract": "Investigates the performance of transport control protocol (TCP) connections over ATM networks without ATM-level congestion control and compares it to the performance of TCP over packet-based networks. For simulations of congested networks, the effective throughput of TCP over ATM can be quite low when cells are dropped at the congested ATM switch. The low throughput is due to wasted bandwidth as the congested link transmits cells from \"corrupted\" packets, i.e., packets in which at least one cell is dropped by the switch. The authors investigate two packet-discard strategies that alleviate the effects of fragmentation. Partial packet discard, in which remaining cells are discarded after one cell has been dropped from a packet, somewhat improves throughput. They introduce early packet discard, a strategy in which the switch drops whole packets prior to buffer overflow. This mechanism prevents fragmentation and restores throughput to maximal levels. >", "authors": ["Allyn Romanow", "Sally Floyd"], "n_citation": 668, "references": ["0ce4877b-6e18-455c-9ee5-7ca93715a88f", "0fa6e3c7-3964-4a6a-a70b-c4cd36489e88", "3a4257ae-9cdb-46fb-a5af-70255dfb9d48", "5d7d8304-f78d-4332-aefd-4f4d8d78f0e1", "61d5d0e8-a896-42b8-88bd-268b6dde1852", "6f1bb20f-25f0-4d0b-a7a5-f31e3fa66bdd", "740922e7-d26a-4801-8cda-49e58ad65f1b", "c274a612-da61-4b92-a77a-421e6ed9dd14", "d2b7db5d-bc47-48c7-a173-865fed9bff96", "f0d226e1-216f-47f5-9f4c-818d6ec0d5d3", "fc237dcd-8266-4009-9cfe-f30867ad135d"], "title": "Dynamics of TCP traffic over ATM networks", "venue": "IEEE Journal on Selected Areas in Communications", "year": 1995, "id": "7d8f9f8f-c900-40d4-8f73-07e8e0e19f8d"}
{"abstract": "Triangulations, which play an important role in approximation theory, finite-element methods, numerical analysis, and computer-aided geometric design (CAGD), are defined. Triangulations in the plane, in space, and on the surface of a sphere are discussed. The storing and construction of triangulations are also discussed. >", "authors": ["Larry L. Schumaker"], "n_citation": 89, "references": ["1aba8852-9e82-4fc1-b0cf-771c0a1e8abe", "510eec1d-f82c-4b19-b116-b8fd4c66531a", "682c3ca2-7797-4eb2-babb-d154a87a6375", "c601a650-e374-4e64-b8e7-299ed09f47c5"], "title": "Triangulations in CAGD", "venue": "IEEE Computer Graphics and Applications", "year": 1993, "id": "1cc585ba-3011-4e5e-8bd2-18db68d3cc92"}
{"abstract": "This paper describes an algorithm for deriving data and computation partitions on scalable shared memory multiprocessors. The algorithm establishes affinity relationships between where computations are performed and where data is located based on array accesses in the program. The algorithm then uses these affinity relationships to determine both static and dynamic partitions for arrays and parallel loops. Experimental results from a prototype implementation of the algorithm demonstrate that it is computationally efficient and that it improves the parallel performance of standard benchmarks. The results also show the necessity of taking shared memory effects (memory contention, cache locality, false-sharing and synchronization) into account-partitions derived to minimize only interprocessor communications do not necessarily result in the best performance.", "authors": ["Sudarsan Tandri", "Tarek S. Abdelrahman"], "n_citation": 28, "references": ["154d9356-3da1-4fb8-b493-0bd407c0aed7", "35446c6a-14dc-4711-a265-3eec5b42a8bb", "52633dba-a758-4947-854e-00f0e93086be", "61f2f7f2-4737-4fb8-b191-bbaad8b3f31d", "636b41f6-a46b-4d90-81e8-9bea29c3db50", "8c1f96ee-b573-429f-a2e6-96e89429d6bb", "a20e8553-72fc-4cb3-8488-4b3acc2c49a5", "ab14f900-a15c-45d4-bd90-f412fb075ad4", "ac4d54ca-ba29-49ab-9c8d-ed9e3d7a7eaa", "af204ce5-6202-4de3-9c61-71a58a2c0dc2", "bc7220f4-e7b6-403c-bedb-2977c11e360f", "ca8fd3e5-4334-4040-b478-a6d498be72ec", "dbe8443e-0bb8-407a-96a0-59e4f5dcdde0", "f5cf6a74-73ee-43b5-a37d-b4fc290768ac"], "title": "Automatic partitioning of data and computations on scalable shared memory multiprocessors", "venue": "international conference on parallel processing", "year": 1997, "id": "794b6a58-b3b1-4444-b4f8-89fd63d908ad"}
{"abstract": "Action refinement is an essential operation in the design of concurrent systems, real-time or not. In this paper, we develop an action refinement technique in a real-time non-interleaving causality-based setting, a timed extension of bundle event structures that allows for urgent interactions to model time-out. A syntactic action refinement operation is presented in a timed process algebra based on the internationally standardised specification language LOTOS. We show: (1) that the behavior of the refined system can be inferred compositionally from the behavior of the original system; (2) from the behaviors of the processes substituted for actions with explicitly represented start-points, that the timed versions of a linear-time equivalence (pomset trace equivalence) and a branching-time equivalence (history-preserving bisimulation equivalence) are both congruences under our refinement; and (3) that the syntactic and semantic action refinements we developed coincide under these equivalence notions with respect to a metric and a CPO (complete partial order) based denotational semantics. Therefore, our refinement operations behave well. They also meet the commonly expected properties.", "authors": ["Mila E. Majster-Cederbaum", "Jinzhao Wu"], "n_citation": 50, "references": ["0498ab12-eff4-4975-8b34-093870aa772d", "0b525551-dc89-427c-9838-25cbaa87f06d", "0ed00fbf-2845-4872-b1d7-ef42f2249156", "3023929a-c93e-49c5-b03f-7fb0414d94df", "560a6ef5-c239-4f4b-826b-b2d88b8094f5", "65ee1196-fa0a-4080-b533-82c2599e56ce", "78b4dbe5-d92d-439f-991b-2924b44217ae", "8d25f8ed-1eef-48b6-8c78-8fe68e168efe", "a7457439-6bde-4a2a-a5c3-1249c647665b", "a9e33f27-e4da-4069-9964-fcb2b2c0535d", "b1a4e18b-5634-4a43-b73c-77c1a687b22a", "b59c23ee-e861-433d-be23-a9673f9cdc70", "c91b6d57-94d8-4b47-8c87-4f459e7bc891", "d51767f0-885a-43fa-b19f-a493cd846f02", "f3eba696-462a-4d0a-a999-fb9e099d0e06", "f7fbe75b-dc4a-494b-adf9-b2decc81be20"], "title": "Action refinement for true concurrent real time", "venue": "international conference on engineering of complex computer systems", "year": 2001, "id": "d270d2e6-4c56-4ae0-b0c9-45c98d8cd1d3"}
{"abstract": "We present some existing and some new formulations for the Steiner tree and Steiner arborescence problems. We show the equivalence of many of these formulations. In particular, we establish the equivalence between the classical bidirected dicut relaxation and two vertex weighted undirected relaxations. The motivation behind this study is a characterization of the feasible region of the dicut relaxation in the natural space corresponding to the Steiner tree problem. 0 7993 by John Wiley & Sons, Inc.", "authors": ["Michel X. Goemans", "Young-Soo Myung"], "n_citation": 155, "references": ["090a55a8-73b0-4f07-9467-fadeac63cc44", "15d60847-f6d4-4227-8c6f-cee5fb9ef3fa", "2a6efb51-0118-4785-9a9f-cc57a17b42aa", "45f0b3cc-4d66-4db3-8401-f5676a695944", "533fab3d-907a-4abb-bb20-a28a68f53278", "554cce31-6758-45f4-acc2-fd8b87b98a05", "57c17ce0-dd79-43a9-a8a5-19fff0dde3bb", "6dd4c2b2-5aea-4f2c-8e23-9acf7aa4a5bc", "6ea63fee-1a84-4d57-8557-2611acce1a14", "73287e35-f743-4e15-b775-88b524a3265b", "8dc94d6c-4f46-4225-badd-9b07ba950c19", "9765134a-eed3-4def-a34e-6f4b66ff4ecb", "9d0394d4-8382-4b61-a141-50e8f1b7f60f", "b89d3dae-abf8-45e1-b702-17eff570e286", "ea14b9d8-8355-4ef4-ac1a-11a7477b5291", "ffbd9b62-f51c-4d34-817d-87a16f606ee5"], "title": "A catalog of steiner tree formulations", "venue": "Networks", "year": 1993, "id": "512fcdee-cfc2-4dd2-aa1a-b21cbc76f0c4"}
{"abstract": "Graph-matching is a task of pivotal importance in high-level vision since it provides a means by which abstract pictorial descriptions can be matched to one another. This paper describes an efficient algorithm for inexact graph-matching. The method is purely structural, that is to say it uses only the edge or connectivity structure of the graph and does not draw on node or edge attributes. We make two contributions. Commencing from a probability distribution for matching errors, we show how the problem of graph-matching can be posed as maximum likelihood estimation using the apparatus of the EM algorithm. Our second contribution is to cast the recovery of correspondence matches between the graph nodes in a matrix framework. This allows us to efficiently recover correspondence matches using singular value decomposition. We experiment with the method on both real-world and synthetic data. Here we demonstrate that the method offers comparable performance to more computationally demanding methods.", "authors": ["Bin Luo", "Edwin R. Hancock"], "n_citation": 50, "references": ["0636682f-b563-4cda-b48a-212db0865832", "08683b46-e544-4abe-9c8f-39d157c68445", "0ec7497c-1d9a-4e42-81b3-c6949d23dfc4", "110d4ac1-9abd-4678-882c-56933790933c", "2a082569-b03f-474a-8e45-dfd713557277", "5b2f70c5-ac67-4944-9e51-5f6bcc6b9da5", "896652ad-84ae-4384-a6a9-7a05d97c579b", "91219529-e922-4519-8e0d-19481c40c178", "af62d4eb-cc7e-4521-949e-efb9ca61df3e", "df759052-c6e6-44a8-a95f-b38983a1aa48"], "title": "A robust eigendecomposition framework for inexact graph-matching", "venue": "international conference on image analysis and processing", "year": 2001, "id": "785d0e21-931f-4dc1-8800-cf02c329b077"}
{"abstract": "Optimal control problems with partial differential equations lead to large scale nonlinear optimization problems with constraints. An efficient solver which takes into account the structure and also the size of the problem is an inexact sequential quadratic programming method where the quadratic problems are solved iteratively. Based on a reformulation as a mixed nonlinear complementarity problem we give a measure of when to terminate the iterative quadratic program solver. For the latter we use an interior point algorithm. Under standard assumptions, local linear, superlinear, and quadratic convergence can be proved. The numerical application is an optimal control problem from nonlinear heat conduction.", "authors": ["Friedemann Leibfritz", "Ekkehard W. Sachs"], "n_citation": 72, "references": ["2493e8e2-56ff-4644-a192-f3ccccb8a3cd", "2d01ec75-51dc-4461-b727-2b778245f82f", "3a72d730-ade3-4683-b48e-3b418770d64c", "3c878dd1-ba36-4065-9d07-8bda3896977d", "4e6361f0-9d6f-4482-afce-c4fbae0525a3", "6b9ae915-a63c-4187-aa9b-980109de9e48", "765039b2-e568-4eb9-9c97-a03dd7554ecf", "b4c8fd7b-31d1-44c9-82eb-7e79cef41b1a", "fb76cf84-0fbb-4d51-b2f9-4e6534111d67"], "title": "Inexact SQP Interior Point Methods and Large Scale Optimal Control Problems", "venue": "Siam Journal on Control and Optimization", "year": 1999, "id": "ba1f65ca-1885-4dbc-a75e-8d891c5e5fba"}
{"abstract": "We propose an appearance-based face recognition method called the Laplacianface approach. By using locality preserving projections (LPP), the face images are mapped into a face subspace for analysis. Different from principal component analysis (PCA) and linear discriminant analysis (LDA) which effectively see only the Euclidean structure of face space, LPP finds an embedding that preserves local information, and obtains a face subspace that best detects the essential face manifold structure. The Laplacianfaces are the optimal linear approximations to the eigenfunctions of the Laplace Beltrami operator on the face manifold. In this way, the unwanted variations resulting from changes in lighting, facial expression, and pose may be eliminated or reduced. Theoretical analysis shows that PCA, LDA, and LPP can be obtained from different graph models. We compare the proposed Laplacianface approach with Eigenface and Fisherface methods on three different face data sets. Experimental results suggest that the proposed Laplacianface approach provides a better representation and achieves lower error rates in face recognition.", "authors": ["Xiaofei He", "Shuicheng Yan", "Yuxiao Hu", "Partha Niyogi", "Hong-Jiang Zhang"], "n_citation": 2932, "references": ["01329570-deab-438a-8fde-9240e3e5bb4b", "1bfa187e-2966-4a8f-ad71-f62a12204971", "359d12c2-6fb5-42f3-8504-d949eac3475c", "374196c1-6e90-4dd7-93fd-93a65dd8ea59", "4ff3e7c9-937f-476f-b109-c01fddaaa57f", "54a5822c-e405-44ad-84e3-cea51e7349c2", "56f4b72a-ec39-47ac-8220-899296e7fb18", "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c", "61e615e7-f78f-4f1e-b604-343ecf4b2ec9", "6e8cc926-79a1-4676-a2bd-f9d49f3144cf", "6f79bf94-39e6-47df-b0c7-ffca294e5053", "70db8fde-faac-4198-beb8-01a00e535b18", "810f7115-00c6-42b2-bf8c-142b2a35ed57", "830450bd-b8f2-40fd-872f-e44a8e33bfd3", "876d9f73-86e8-4af2-87cc-adaf94b2912f", "9525e6d6-3b5d-4cd1-ad74-6157590c3cba", "b02cf316-e36b-4fa5-9dfd-ad86fee4cfca", "c5d73f15-467c-4824-8784-4bf66630fe94", "c8cc88b8-d971-49e9-8810-e784c856872f", "cbff2ff2-6b8f-425d-a5ef-aff0de9be3e5", "cd8746da-59d4-44ec-8367-8902cd89a8bc", "d7373bad-b40f-470d-bdab-2206f6801e96", "df9806f6-77cb-4073-b322-b2a2da1ce212", "e00a9c90-5303-4e93-a7a6-cd3c8d1e412e", "e4a703c9-5406-413d-9d26-db9daa6a69ea"], "title": "Face recognition using Laplacianfaces", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2005, "id": "494b497b-836b-445a-8bcb-095600835d89"}
{"abstract": "We consider the general problem of learning from labeled and unlabeled data, which is often called semi-supervised learning or transductive inference. A principled approach to semi-supervised learning is to design a classifying function which is sufficiently smooth with respect to the intrinsic structure collectively revealed by known labeled and unlabeled points. We present a simple algorithm to obtain such a smooth solution. Our method yields encouraging experimental results on a number of classification problems and demonstrates effective use of unlabeled data.", "authors": ["Dengyong Zhou", "Olivier Bousquet", "Thomas Navin Lal", "Jason Weston", "Bernhard Sch\u00f6lkopf"], "n_citation": 2818, "references": ["06ba5345-fa5d-417a-92b8-11879854f1f5", "3549c862-c615-4f80-ac53-f562d3e2b846", "3c13a267-57c7-4079-bb10-1078184e8c64", "3e5fd33f-1fd0-4815-a47a-3c41a26a538a", "5aed5d4c-77c0-480e-878a-9b76e410d02e", "5fc7c376-5895-490a-8ea2-989442940c7b", "93a14c23-d227-41fd-ad18-7de38817cb52", "9db5c445-2caa-4129-a277-368dc375689b", "d158edc8-c996-4141-b56b-d54344f635cf", "d6104d9a-faaa-4db4-8c4e-748176157ef2", "ea8cd3d8-17ae-4a1e-8f83-1609469087af"], "title": "Learning with Local and Global Consistency", "venue": "neural information processing systems", "year": 2004, "id": "c472bfe1-9ef6-43c6-89b5-a86b22c9f5df"}
{"authors": ["Joseph A. Goguen", "Jos\u00e9 Meseguer"], "n_citation": 323, "title": "EQLOG: Equality, Types, and Generic Modules For Logic Programming.", "venue": "Journal of Functional and Logic Programming", "year": 1986, "id": "5efdf9b2-a2e2-4929-9728-00fbca01e604"}
{"abstract": "We encounter new types of security problems in ad hoc networks because such networks have little or no support infrastructure. In this paper we consider one such problem: a group of people in a meeting room do not have access to public key infrastructure or third party key management service, and they do not share any other prior electronic context. How can they set up a secure session among their computers? We examine various alternatives and propose new protocols for password-based multi-party key agreement in this scenario. Our protocols may be applicable in other scenarios, too. We also present a fault-tolerant version of a multi-party Diffie-Hellman key agreement protocol which can be of independent interest.", "authors": ["N. Asokan", "Philip Ginzboorg"], "n_citation": 595, "references": ["0b868c0b-2b01-4732-abfb-06a8773783cb", "34e8e9be-8a65-4aeb-a1b8-b6e0feb2ef50", "600c5c3b-57dd-477c-9037-76129b1fcde6", "a5e476d8-edfe-443d-9566-75caec8a208c", "b6155657-d652-4df2-be18-9c203c02e98d", "ca394e6a-59e0-466c-a66a-d976555db689", "cef4b1b3-d027-4b06-89cb-6ec680170cbc", "fd51d78a-e2f5-46b6-b041-4dae9aebdc76"], "title": "Key agreement in ad hoc networks", "venue": "Computer Communications", "year": 2000, "id": "0d81e074-d360-4bf2-b575-50848f4f61ce"}
{"authors": ["James Harland"], "n_citation": 27, "title": "A Proof-theoretic Analysis of Goal-directed Provability", "venue": "Journal of Logic and Computation", "year": 1994, "id": "8c4f81b6-97bb-4908-ad87-1d4fd14ee740"}
{"abstract": "The lack of consideration of organizational issues in systems development can lead to project failure. A review of the literature and a pre-test survey suggested classifying organizational issues into five categories and examining how these are considered by IT managers. A postal survey with responses from 64 senior IT specialists over a cross section of industry and commerce showed that there is a general awareness of the importance of organizational issues but there was little consensus on how they should be addressed in the development process. These IT managers were consistent in spending most effort on the issues perceived as most important from the list of 14 issue provided, but there was considerable variation in which specific issues they rated most important. In general those organizational issues with a 'technical' aspect were given more prominence than those which are less tangible, but which may be more critical to a system's success.", "authors": ["Neil F. Doherty", "Malcolm King"], "n_citation": 100, "references": ["08fbcf99-e634-4cca-92ac-38069dee999b", "371ccd13-f6cd-4724-9a7d-c7ce1b17f760", "726e5f6e-cae4-4041-87c6-4a0eebd9e258", "b7690237-3d76-4865-a956-0c06529fa4be", "b8c9f6d6-5147-4d5e-b633-e9c17ad30ab9", "dfac57a3-5031-49b7-a985-54743ecdbe7a"], "title": "The consideration of organizational issues during the systems development process: An empirical analysis", "venue": "Behaviour & Information Technology", "year": 1998, "id": "d0325817-3cb7-4701-9125-830a9261dfeb"}
{"abstract": "A game theoretic pricing mechanism for statistically guaranteed service in packet-switched networks is proposed. The mechanism provides congestion control, differentiated qualities of service, and efficient resource allocation. For users, the mechanism offers better quality and lower price. Service providers can base new service and revenue models within the mechanism. We apply this mechanism to the Internet.", "authors": ["Jun Shu", "Pravin Varaiya"], "n_citation": 132, "references": ["2e6dd8f0-5ab6-44e0-a542-98d7da6ebf47", "58080470-4efe-4499-97c2-5712ecf10c7d", "5c7f2104-3fd2-4698-9f28-3b7644b13c97", "6518a415-85da-4f1f-af3e-e4aa0d51d7c7", "cbcbb71e-7f2f-4a7b-92f3-c29586323423", "e5adad34-86d4-40af-9ebe-2013b5f88a92", "f0960be2-9efd-4ed9-8e5f-7bcb30b3805b"], "title": "Pricing network services", "venue": "international conference on computer communications", "year": 2003, "id": "5fd623cb-c865-4d44-ad8f-2a06e5ec0271"}
{"abstract": "This technical note studies global asymptotic state synchronization in networks of identical systems. Conditions on the coupling strength required for the synchronization of nodes having a cyclic feedback structure are deduced using incremental dissipativity theory. The method takes advantage of the incremental passivity properties of the constituent subsystems of the network nodes to reformulate the synchronization problem as one of achieving incremental passivity by coupling. The method can be used in the framework of contraction theory to constructively build a contracting metric for the incremental system. The result is illustrated for a network of biochemical oscillators.", "authors": ["Abdullah O. Hamadeh", "Guy-Bart Stan", "Rodolphe Sepulchre", "Jorge Goncalves"], "n_citation": 47, "references": ["0b4c7d30-6d1a-4af0-9732-e4bdea94ddbe", "1748ec2f-9b30-4eaa-82cf-aa21f8223eb5", "25179d12-e933-4da4-b61e-0281ed7c2126", "2768199c-b9d6-4001-94d3-e6429c93bc5f", "30d07754-19d9-43d4-870a-0a98ff962736", "37db215e-b493-472f-9f57-e38316ed57fb", "47b7262a-5719-4fe2-bb6e-1e351d159097", "578c0a14-e208-4e72-bee6-97c7d8b4a31b", "65442964-6b88-41fb-aed0-c7991ffc73b1", "83269965-ffdd-48a4-b8e6-f36c0b1dcec2", "933f4aff-a283-4592-95e1-e934dd1ce2d8", "ea815a90-cc4d-4f03-bcaf-80f8ab9fe02c"], "title": "Global State Synchronization in Networks of Cyclic Feedback Systems", "venue": "IEEE Transactions on Automatic Control", "year": 2012, "id": "9f64a354-2283-4709-8317-73ba8e4fc039"}
{"abstract": "Vector directional filters (VDF) for multichannel image processing are introduced and studied. These filters separate the processing of vector-valued signals into directional processing and magnitude processing. This provides a link between single-channel image processing where only magnitude processing is essentially performed, and multichannel image processing where both the direction and the magnitude of the image vectors play an important role in the resulting (processed) image. VDF find applications in satellite image data processing, color image processing, and multispectral biomedical image processing. Results are presented here for the case of color images, as an important example of multichannel image processing. It is shown that VDF can achieve very good filtering results for various noise source models. >", "authors": ["Panos E. Trahanias", "Anastasios N. Venetsanopoulos"], "n_citation": 422, "references": ["25a2516c-3e49-49f2-8abf-2816774b1d4b", "34d1defc-1a1b-4d6d-9d63-7fbd2117c8a4", "40871d72-1e11-4a10-9930-6754dc167ce1", "7b0d9d21-5b34-4b4f-bd6b-02e5d8ea3807", "cf366e9e-f9ac-4cea-b0cf-6310478f8345"], "title": "Vector directional filters-a new class of multichannel image processing filters", "venue": "IEEE Transactions on Image Processing", "year": 1993, "id": "70b9fb83-6f51-492c-bd36-55cd0a8eaa81"}
{"abstract": "An overview of the hardware and philosophic context in which the Hydra design was done is discussed. The construction methodology is discussed together with some data which suggests the success of this methodological approach.", "authors": ["William A. Wulf", "Roy Levin", "C.T. Pierson"], "n_citation": 63, "references": ["0fbc4380-4190-4205-8d8a-929b294775bb", "3b44e784-c356-45a8-af90-64e926577870", "4f9859b9-f22e-4dd2-810f-b0f5293f953b", "78d07c73-7bc3-4ae7-998b-adf367e746d3", "8e0da402-4528-4b27-ab1b-1f668e7f02f6", "93e617b9-2640-4741-ae41-b0811edd4748", "95ea36f8-e20f-4c28-bf21-a859223cb28b", "a66f3edc-abf0-4056-a631-5bbad18e3abe", "bb247b49-07e0-47ef-bf1b-f63fe5e1d3c4", "bbf212ab-2f42-4084-b26b-bad61d4f1f33", "bc328964-b2d8-4c18-a11e-6d3e17bd409e", "c5b1ee6b-55a6-4e97-85ef-b85bb01e176e", "e808c7bd-d2c6-4bff-85c2-dee0f1ee9dec"], "title": "Overview of the Hydra Operating System development", "venue": "symposium on operating systems principles", "year": 1975, "id": "a9b2655a-d28c-44cf-be10-219054894230"}
{"abstract": "Fifty years ago, control and computing were part of a broader system science. After a long period of separate development within each discipline, embedded and hybrid systems have challenged us to re-unite the, now sophisticated theories of continuous control and discrete computing on a broader system theoretic basis. In this paper, we present a framework of system approximation that applies to both discrete and continuous systems. We define a hierarchy of approximation metrics between two systems that quantify the quality of the approximation, and capture the established notions in computer science as zero sections. The central notions in this framework are that of approximate simulation and bisimulation relations and their functional characterizations called simulation and bisimulation functions and defined by Lyapunov-type inequalities. In particular, these functions can provide computable upper-bounds on the approximation metrics by solving a static game. Our approximation framework will be illustrated by showing some of its applications in various problems such as reachability analysis of continuous systems and hybrid systems, approximation of continuous and hybrid systems by discrete systems, hierarchical control design, and simulation-based approaches to verification of continuous and hybrid systems.", "authors": ["Antoine Girard", "George J. Pappas"], "n_citation": 75, "references": ["03028353-cf47-4d8f-85e7-4535d57d0290", "0861cda3-bae4-4f1b-b782-b78cadc480f0", "0d39c716-e1ec-43ae-856c-26489c60fdc9", "10da8594-0e10-4731-8b22-df9e9cd6b0e9", "127a5da6-6943-4130-89cb-3ec6509d0b26", "1b429e8a-1871-4ed4-bd60-b8b81b91fea0", "2525b40a-1d5d-42bc-ab38-93222f28fa84", "2ba88e31-8bac-4db0-a41e-9874f919459e", "2d06526f-36c8-4c2e-bfba-17a2352edcb1", "3023929a-c93e-49c5-b03f-7fb0414d94df", "392d4f28-3bc2-4fc5-a98b-fa8facb4934e", "3c1797ab-1cda-43a1-9044-030abc84b6a5", "41c19566-772b-4474-aa26-97692ee4f0f9", "47b7262a-5719-4fe2-bb6e-1e351d159097", "54a47030-22c9-4028-9480-5c3bf31f0a75", "592c23bd-6ba9-47bc-9d5e-7f52053e6e4d", "5df8d4f6-2dbd-437c-b45d-ea117de18086", "626a7c0d-46ca-4579-8fff-4a5b3381eedf", "638f28d4-4ed2-4edf-88e7-3a8cffa21cb7", "642827d0-b554-43c9-82ac-864b28bf25c3", "7065355b-7c07-4d37-98d7-f3ee620eee6c", "7f62bbcf-a630-4b80-af6d-3962e6757c32", "84df5f57-a43d-4d4f-a088-ca4a2572efa6", "8795e1e5-6057-4a38-8df9-a31f5c088d84", "8b2f0d19-4930-43cc-ad53-7f35493c1f62", "8efff4b7-f4f0-4c0c-866c-7479e6419894", "8fb151f8-26d0-46eb-8788-4209d11a5331", "9ba34966-0ce1-42be-bcdd-ce2adfdc3f59", "9c3d15e4-100a-4136-9ccc-c1ee48d4fb42", "a8ff9ccf-ba07-429b-ace7-957b7b01cc7c", "bb1d7ccb-0cdc-47aa-9f99-27e3ac0d224b", "c00bbb49-6e29-4103-8883-55acd23c248b", "d1e74609-c210-458d-8e3d-5f460c86c3d4", "d5252b76-9ae2-4599-af2d-b09733584157", "d6383543-b872-4023-b5cb-502000023c7c", "dfefce0c-94c4-4412-b48a-c99063641fc3", "ea20ed7f-722c-4ef7-8102-18327a13d650", "f5f21e70-8661-4c06-81a0-1b345f069221", "f6ab13df-375e-447b-934b-d5b4082cd80d", "f7b95734-9e63-401e-b8ea-35734cd20b72", "feada91f-c276-48c2-9072-fbf09334c09d"], "title": "Approximate Bisimulation: A Bridge Between Computer Science and Control Theory", "venue": "European Journal of Control", "year": 2011, "id": "4114b10a-baa5-4d7d-bb13-ea9788533107"}
{"abstract": "It is generally acknowledged that any Knowledge Base (KB) should be able to adapt itself to new information received. This problem has been extensively studied in the field of belief change, the dominating approach being the AGM theory. This theory set the standard for determining the rationality of a given belief change mechanism but was placed in a certain context which makes it inapplicable to logics used in the Semantic Web, such as Description Logics (DLs) and OWL. We believe the Semantic Web community would benefit from the application of the AGM theory to such logics. This paper is a preliminary study towards the feasibility of this application. Our approach raises interesting theoretical challenges and has an important practical impact too, given the central role that DLs and OWL play in the Semantic Web.", "authors": ["Giorgos Flouris", "Dimitris Plexousakis", "Grigoris Antoniou"], "n_citation": 111, "references": ["09636474-b71d-4962-8e3f-cf7e47446959", "4402ceb3-cec8-498c-95a8-ac8cfbed88b7", "4d311e5d-6579-4d11-93b1-300875da3644", "6828a96c-210a-4d4b-94fc-01f127080bbd", "7d4a73a2-6fde-432c-a489-d73e5e8d4c33", "a23f6724-718f-485f-a90c-6edbaf82f340", "a57fe40f-34c5-4ded-bd6a-860aa2aeca7d", "b0593d3f-5bad-431c-b7b6-13fea2534e2a", "b3a6f742-8207-4274-b7d6-cdbefa3e8938", "d0b92591-b828-42ff-9c2a-90280b5a7944", "e2eaa562-935f-4b14-95c8-4e60e01b4e05", "f4a3d985-57e2-469a-9075-b256c5f8fc1c", "fd06f21c-8626-4965-8fbf-6d274da2fcf1"], "title": "On applying the AGM theory to DLs and OWL", "venue": "international semantic web conference", "year": 2005, "id": "da0220f4-24a4-49ff-86c0-85f8d88e68ed"}
{"abstract": "The paper describes a new approach to image segmentation. It accepts the inherent deficiencies occuring when extracting low-level features and when dealing with the complexity of real scenes. Image segmentation therefore is understood as deriving a rich symbolic description useful for tasks such as stereo or object recognition in outdoor scenes. The approach is based on a polymorphic scheme for simultaneously extracting points, lines and segments in a topologically consistent manner, together with their mutual relations derived from the feature adjacency graph (FAG) thereby performing several grouping steps which gradually use more and more specific domain knowledge to achieve an optimal image description. The heart of the approach is (1) a detailed analysis of the FAG and (2) a robust estimation for validating the found geometric hypotheses. The analysis of the FAG, derived from the exoskeleton of the features, allows to detect inconsistencies of the extracted features with the ideal image model, a cell-complex. The FAG is used for finding hypotheses about incidence relations and geometric hypotheses, such as collinearity or parallelity, also between non-neighbored points and lines. The M-type robust estimation is used for simultaneously eliminating wrong hypotheses on geometric relationships. It uses a new argument for the weighting function. >", "authors": ["Claudia Fuchs", "Wolfgang F\u00f6rstner"], "n_citation": 50, "references": ["37faaeae-4698-4ef5-8054-224d61dc2505", "508e6e6d-221c-4914-8e09-4a062a7342dd", "58d0cc4d-9deb-4188-98d2-7ca475ca7221", "732e611c-6996-4765-af4f-f9aaa80ff258", "79050acb-3012-4d4b-af60-66040a28043d", "9a09b515-2ba1-4a8e-a4fe-d81bdca1ef74", "b2c8824c-706b-4436-af76-c82e9c93bfdc", "cf9bea98-7ab0-43f7-b26c-dedc0834edf3", "d4f7c278-074c-45fb-9ba7-bba77df6680e", "de00787d-1ee4-48a7-ad67-281f28f08829", "f09f62b7-dde5-4fb7-8ce7-108eb14649b4", "f86769d4-8e09-4a34-9fcc-144ff31e2e13"], "title": "Polymorphic grouping for image segmentation", "venue": "international conference on computer vision", "year": 1995, "id": "3e0ffc54-eaeb-49ab-b38e-99cadab74239"}
{"abstract": "We study scheduling problems in battery-operated computing devices, aiming at schedules with low total energy consumption. While most of the previous work has focused on finding feasible schedules in deadline-based settings, in this article we are interested in schedules that guarantee good response times. More specifically, our goal is to schedule a sequence of jobs on a variable-speed processor so as to minimize the total cost consisting of the energy consumption and the total flow time of all jobs.   We first show that when the amount of work, for any job, may take an arbitrary value, then no online algorithm can achieve a constant competitive ratio. Therefore, most of the article is concerned with unit-size jobs. We devise a deterministic constant competitive online algorithm and show that the offline problem can be solved in polynomial time.", "authors": ["Susanne Albers", "Hiroshi Fujiwara"], "n_citation": 158, "references": ["0e975a27-fb5e-493e-a3c6-f51b25477a99", "210bfca2-6aa4-412a-9582-f2d6c012030c", "37f87e74-3ee2-495a-890b-2a14ce9ea24c", "50795a0d-6df4-471f-8124-598ed3c8d376", "71ff6f75-8078-4c80-8970-aa53a88c4e95", "76e8161d-f4c2-4672-837f-2b0fd48905cb", "77d4fa0f-ec24-44b2-926e-a0ab76d3f0c6", "7c7b0955-1509-4916-9cf9-be8cfbf738be", "977745c4-804e-424a-b093-b21fbd89757f", "a7f00548-f19e-4b67-b824-ec6c92f68c38", "f01d62e6-364d-4ce1-8b2c-783908bed1d2"], "title": "Energy-efficient algorithms for flow time minimization", "venue": "ACM Transactions on Algorithms", "year": 2007, "id": "a533b658-1e7a-4fad-98e8-34e193a7b709"}
{"abstract": "Purpose \u2013 The purpose of this paper is to present a narrative review of studies on the citing behavior of scientists, covering mainly research published in the last 15 years. Based on the results of these studies, the paper seeks to answer the question of the extent to which scientists are motivated to cite a publication not only to acknowledge intellectual and cognitive influences of scientific peers, but also for other, possibly non\u2010scientific, reasons.Design/methodology/approach \u2013 The review covers research published from the early 1960s up to mid\u20102005 (approximately 30 studies on citing behavior\u2010reporting results in about 40 publications).Findings \u2013 The general tendency of the results of the empirical studies makes it clear that citing behavior is not motivated solely by the wish to acknowledge intellectual and cognitive influences of colleague scientists, since the individual studies reveal also other, in part non\u2010scientific, factors that play a part in the decision to cite. However, the results of t...", "authors": ["Lutz Bornmann", "Hans-Dieter Daniel"], "n_citation": 766, "references": ["013699f9-6c06-4c8e-a140-a90d407a198b", "0bbef311-c8e1-453b-ab24-34df5b6c05d3", "0bfdfa8f-b0f1-4d97-9dd8-6cee14b78341", "0c1a137c-78c1-41aa-8b25-e51eedc8489d", "0db92dc0-5eff-4dba-a669-82488bedb973", "133843fd-322c-424c-8903-c3dd87493f96", "14090c6b-ad2b-4e23-80eb-f06b797c68d7", "16f10a45-0acd-48ad-8352-96a6d6c0b83b", "1e872c1e-ac71-47fa-a0fd-db25fa67e99d", "219f382e-6cf5-4a77-91e2-0cd3e8777f44", "221bb5ae-c373-4c3e-afeb-9c0a90ea5f8b", "265fbda9-9426-46e1-add6-1430c33df4e5", "2a077bd9-1ddd-4094-9115-7c294a7a1e15", "2cc89c24-c192-4726-bf75-791c94a85e84", "2e3e083e-ba65-4127-8e2d-a4d33d64bc14", "3464ac72-cb54-43cf-9a7a-20f9223b2d26", "36c652ad-6ad1-465e-8a22-9122b07b4563", "3712c40e-9695-4ddd-bc96-ba45bedea987", "407f6981-1664-42b3-a8ad-4df4c7b655bf", "471c6b4f-c4dd-478a-b5b8-b14de9722247", "48161e0b-63e2-4b75-bbe4-c43f17d740c2", "53a67471-9c85-4fb2-9616-12ca02838ec9", "58dc5d35-2b6e-4abc-881d-229a9352de99", "5ba31fd6-e51e-49ac-9b8f-8a002fed22ae", "5d80c2aa-8ded-40ff-92a3-6b3c8ecf9173", "6196b7fa-1cfb-4ced-b3fe-bad810cbbedd", "635d322e-eb98-4ad3-b1f3-67ac3d3b5e21", "6627e7bc-63f3-4e8a-ac1d-27d92ae191a0", "667f36ee-e47a-457e-b149-1ce70dab6ed4", "68102970-026f-4c37-83d9-95782880f6eb", "6c6fabb2-9897-4e0e-9ed0-9c0fb5b78ddb", "6ff8251c-6647-4fd1-b869-5f5285fb7676", "70368a71-f309-4c17-9ea2-131ddd524421", "74a8766f-0fa4-474b-bf46-424ba3692793", "78f81495-e2ab-4fd1-8525-10af628d867a", "7cc89b96-0377-4c4a-91fd-230892635ca6", "85b3a22b-f4d4-4390-bf18-b550c25d9d33", "92720607-f37d-494a-922b-86c7425c7e6f", "9b8e1611-9b6a-4651-8c57-2a1615de51dc", "9ec0be7b-1fa3-4507-90df-bedb1dffcdf6", "a172d569-513b-4109-a313-ad94e3ef9e19", "b206b935-cfc3-45ed-9ac5-485e3e2fbdaf", "b6cfcbf1-4639-4485-bbfb-9a3a1202a13b", "b740af6f-a04b-4dfe-9036-62c90aba6f18", "bfc6c508-593e-4f4f-adb3-a13da60617a0", "c2a66a94-6ba3-4aca-9742-59a7c5703020", "c575cd95-e29d-43be-b575-9b5ef1726f28", "cf43e532-678a-4862-a467-031ce799cbdd", "d255d977-cd8d-4575-bada-af717204b2d8", "d49b6836-f244-4a32-ba95-48f7b1b93b3e", "dc2a4edd-6897-4895-a187-c9341b3e16e8", "e2a97ffb-90b0-4f1a-b01d-b15a77a820de", "e53e932e-5233-4c4e-846d-d4a8755f4e3f", "e585bf37-6179-433f-81de-c46bedbac5f8", "ed54996c-1c69-47b1-a33c-44882a020080", "f59aa11b-f133-4416-b86e-75ced8aeb07c", "f68e682b-db7d-4e23-8c65-60753c55c4f9", "f7eda5e5-6c14-4f52-8665-fc52b5e48f64", "f9d99a65-7c5d-4840-969d-99ea7d48020c"], "title": "What do citation counts measure? A review of studies on citing behavior", "venue": "Journal of Documentation", "year": 2008, "id": "6d0959e0-384d-4cdc-a3a9-dac4fde27756"}
{"abstract": "Consumers' lack of trust has often been cited as a major barrier to the adoption of electronic commerce (e-commerce). To address this problem, a model of trust was developed that describes what design factors affect consumers' assessment of online vendors' trustworthiness. Six components were identified and regrouped into three categories:  Prepurchase Knowledge, Interface Properties  and  Informational Content.  This model also informs the Human-Computer Interaction (HCI) design of e-commerce systems in that its components can be taken as trust-specific high-level user requirements.", "authors": ["Florian N. Egger"], "n_citation": 47, "references": ["cfc24bb0-31dc-432e-a7c7-0c43280eefd9"], "title": "\"Trust me, I'm an online vendor\": towards a model of trust for e-commerce system design", "venue": "human factors in computing systems", "year": 2000, "id": "66c927a0-4584-4512-bad3-106b3b1c607c"}
{"abstract": "A class of impulsive control systems with time-varying delays is considered. By establishing an impulsive delay differential inequality, we analyze the global exponential stability of the impulsive delay systems and estimate the exponential convergence rate. On the basis of the analysis, a design procedure of impulsive controller is presented. The designed impulsive controller not only can globally exponentially stabilize the time delay systems, but also can control the exponential convergence rate of the systems. Two numerical examples are given to illustrate the effectiveness of the method.", "authors": ["Zhichun Yang", "Daoyi Xu"], "n_citation": 227, "references": ["1ba84711-763a-4172-b5e8-a62aa1d0377f", "36b1e02b-04f5-4f53-bcab-c907bb28e3fa", "4f679b02-e951-4250-89ae-aad76addaa5a", "8ee5af33-ce4a-47e0-9b57-5ec359580e6d", "8f1dccba-f317-40f1-9ef0-fa8fc6b7e96a", "a820c9c1-87ce-4241-8706-eca4aa9094e8", "b0128ce5-5b60-46c4-9fa2-bc20539fa216", "c2da4d26-363d-42a6-a6ec-ad0b70b9aa88"], "title": "Stability Analysis and Design of Impulsive Control Systems With Time Delay", "venue": "IEEE Transactions on Automatic Control", "year": 2007, "id": "c7fa9607-9db5-415c-9f42-b3042f3eb040"}
{"abstract": "This paper is about the development of systems whose end users are professional people working in a specific domain (e.g., medicine, geology, mechanical engineering); they are expert in that domain, but not necessarily expert in nor even conversant with computer science. In several work organizations, end users need to tailor their software systems to better adapt them to their requirements and even to create or modify software artifacts. These are end-user development activities and are the focus of this paper. A model of the interaction between users and systems, which also takes into account their reciprocal coevolution during system usage, is discussed. This model is used to define a methodology aimed at designing software environments that allow end users to become designers of their own tools. The methodology is illustrated by discussing two experimental cases.", "authors": ["Maria Francesca Costabile", "Daniela Fogli", "Piero Mussio", "Antonio Piccinno"], "n_citation": 105, "references": ["01498160-3298-441e-8569-278ec8f10150", "05b30c37-e8f3-4671-abc3-5469ede13f04", "07222a92-4c8e-480d-b68d-d097806dc087", "0c18926f-a6ef-4951-98e9-c150799b0ff1", "20548f6b-8474-4431-b16e-1e6847070577", "3188cfd0-aace-469e-be01-f30cc9133a5d", "39c8815a-3ee7-4db6-8800-87bb4dcd9151", "3f6293af-191a-4637-b074-c970e633a9d9", "42ef7bbd-7370-4e33-bfef-776b94137618", "47448f94-6fe5-48db-87eb-a42e95283ad0", "482e0656-5bc6-41cf-99ee-ed098da61d97", "50c19b4c-8b6a-4cf8-8b33-eba9cc835773", "5956f405-7d4c-4f55-8432-7abede5c643c", "5e25fc10-1197-4573-8865-5032246707fb", "5e4d789b-6c6d-4535-96f1-705bd221401e", "72532c9c-efdd-491f-807e-8a4b6fe7c007", "77f92670-a89e-4e12-b2eb-1c11684d35ba", "79f6becc-5eea-48a4-b967-6d50cb490a5a", "7dd6c17e-35df-40cf-a140-93f6f252a90d", "86424897-2797-4c2e-8e72-74d202288eb6", "8baf2298-4af1-4eab-a3a9-8a99658b4bee", "8f28f289-2d3c-42d5-a516-27c7c9e58337", "9b842adf-3d19-4016-9944-f1e66478ba30", "a0139ea8-e86c-4ca9-890a-bdc71cf489d1", "a48ab5eb-728b-4ec2-8d46-54244896e422", "ab63b761-a778-4681-bd78-ae83ed3c1500", "b90ab08c-61c6-4910-af17-b9d97ec9daec", "c32786ae-dddc-40af-b7d7-26906d941734", "c38d06a0-ab9c-4804-a121-074ee1f332f8", "c6a07580-98a4-49a1-bb58-01d4feeaa7dd", "cf0dbd6f-4960-4ffd-9969-1aa98e1b977a", "f8046e47-744d-4737-b2ae-b5388af3054a"], "title": "Visual Interactive Systems for End-User Development: A Model-Based Design Methodology", "venue": "systems man and cybernetics", "year": 2007, "id": "484202b5-9ad1-44cc-8fda-29d96459c394"}
{"abstract": "Time pressure and quality issues are two main challenges facing today's Web development professionals. To achieve quick development of high-quality systems, a lot of methods and techniques have been proposed. A widely recognized strategy in current practice is to emphasize early quality assurance techniques, as the late detection of defects are well known to be expensive and time-consuming. We take robustness as a critically important quality attribute, and propose a general framework for conducting early robustness analysis for Web-based systems, based on Jacobson's analysis method and FMEA (failure mode and effect analysis).", "authors": ["Jianyun Zhou", "T. Stalhaane"], "n_citation": 7, "references": [], "title": "Using FMEA for early robustness analysis of Web-based systems", "venue": "computer software and applications conference", "year": 2004, "id": "97cf3907-e3cd-4cec-9118-3c75222fbf9a"}
{"abstract": "This paper describes an underwater glider motion control system intended to enhance locomotive efficiency by reducing the energy expended by vehicle guidance. In previous work, the authors derived an approximate analytical expression for steady turning motion by applying regular perturbation theory to a realistic vehicle model. The analysis results suggested the use of a well-known time-optimal path planning procedure developed for the Dubins car, an often-used model of a wheeled mobile robot. For underwater gliders operating at their most efficient flight condition, time-optimal glide paths correspond to energy-optimal glide paths. Thus, an analytically informed strategy for energy-efficient locomotion is to generate sequences of steady wings-level and turning motions according to the Dubins path planning procedure. Because the turning motion results are only approximate, however, and to compensate for model and environmental uncertainty, one must incorporate feedback to ensure convergent path following. This paper describes the dynamic modelling of the complete multi-body control system and the development and numerical implementation of a motion control system. The control system can be combined with a higher level guidance strategy involving Dubins-like paths to achieve energy-efficient locomotion.", "authors": ["Nina Mahmoudian", "Craig A. Woolsey"], "n_citation": 25, "references": ["839cab3f-a94b-4bda-8152-d0197106f1b8"], "title": "Underwater glider motion control", "venue": "conference on decision and control", "year": 2008, "id": "5cc0defb-2974-492e-b0ea-0a49dca3207b"}
{"abstract": "Context: Refactoring is a maintenance task that refers to the process of restructuring software source code to enhance its quality without affecting its external behavior. Inspecting and analyzing the source code of the system under consideration to identify the classes in need of extract subclass refactoring (ESR) is a time consuming and costly process. Objective: This paper explores the abilities of several quality metrics considered individually and in combination to predict the classes in need of ESR. Method: For a given a class, this paper empirically investigates, using univariate logistic regression analysis, the abilities of 25 existing size, cohesion, and coupling metrics to predict whether the class is in need of restructuring by extracting a subclass from it. In addition, models of combined metrics based on multivariate logistic regression analysis were constructed and validated to predict the classes in need of ESR, and the best model is justifiably recommended. We explored the statistical relations between the values of the selected metrics and the decisions of the developers of six open source Java systems with respect to whether the classes require ESR. Results: The results indicate that there was a strong statistical relation between some of the quality metrics and the decision of whether ESR activity was required. From a statistical point of view, the recommended model of metrics has practical thresholds that lead to an outstanding classification of the classes into those that require ESR and those that do not. Conclusion: The proposed model can be applied to automatically predict the classes in need of ESR and present them as suggestions to developers working to enhance the system during the maintenance phase. In addition, the model is capable of ranking the classes of the system under consideration according to their degree of need of ESR.", "authors": ["Jehad Al Dallal"], "n_citation": 50, "references": ["01f0d6d0-9e4c-4685-b8a2-ecbe52e66bc2", "16681632-81f5-42df-9808-3cf4e24a375e", "283a47a0-f895-4185-b433-fe7a35408aca", "331106b0-c7b7-4e97-8659-7c3132f44e7f", "403207af-4b61-4e36-ab9a-11bb6e3ad4ce", "412981c8-979b-4353-a466-6030181cecab", "4417076b-b530-4390-ab00-4364a827c16e", "462669ee-4096-4034-b693-97e324dc4b01", "485807fa-2f99-4a71-8b91-caa15de9938c", "496ab767-e172-4c28-98a3-343e33c34094", "49a0cd67-ab53-4fe3-88f1-744dceda55df", "5ad27b4d-8750-42f0-bbbf-5001155e65d8", "5d4f95ea-3887-4d26-b66a-ab44636a0d89", "5e2f4681-6dfa-48ff-8773-7d5ce6f940bb", "613fe1a1-b6ad-48b0-8d6a-85d974939ad0", "62af4743-9b30-41c2-9696-511bf6a24bcb", "63e16fd8-f25e-4e4b-8e42-615dcf993282", "6c7ecc48-8b20-47d0-aa60-4025401dc7bd", "6e6202cd-6dbe-4bba-b198-326f2168c517", "70c54e0c-adb3-4120-87d7-4ae10da9b0b0", "7291ae96-1749-4c69-8b6e-0abdf1de301c", "7335e3e8-eac1-4e7b-aabf-c972e4f41474", "73eef376-4704-49dc-be6e-1cd1e7f2fc42", "764916d5-4fec-4f42-a79e-170c006ae44b", "7df36a4f-6f16-4457-9198-a5df121e7786", "7e8e2acb-6ec9-4fe1-8460-131ff5a8db88", "820b208a-4da2-4b87-b8d3-be31a013309c", "870db3d2-2156-455d-8d12-9902da9863b6", "88136067-5c6a-4d47-9552-acebac993fdd", "9704001a-a026-4109-9021-ce7853cd7e63", "9900b357-12bd-4672-b872-861eb08b383f", "9a109d37-391a-42a4-8727-f1b291441803", "a2841161-6610-416e-aa69-b8b71757d106", "a9152214-c13b-4518-bc24-5db9a19b941e", "b35d8748-76f7-470d-ade6-e1ebfe15e72f", "b62d4859-62c2-4bba-b896-5b8a8bdc6089", "b6fffffc-2b3f-42d3-bb60-7c26336649eb", "b9e8ee1d-cfe9-4d5a-a823-8a83c3abd0ff", "c28cf51b-79cf-4b24-9234-8b304f11e6ca", "ca3d2512-6776-47d8-afd5-7ab56f014e3f", "ce6ed156-caa9-4941-8dbc-a9f571abc1b7", "d32786fc-ea8d-41f0-a803-5d00e550329c", "d52b6b91-b922-4118-b45a-ed486a3591b5", "e4e652dc-43dd-4d24-811c-5d402d24be26", "e580b2d9-3e7c-4122-9932-f2cf985040cd", "ed59bfc1-0640-409f-a767-2de840f621ef", "f4ff67c0-d703-4b47-bb9b-bb073d4fdc1a", "f6a9a06d-35b8-4152-b6fe-9031b8e775d5", "f7ec634a-8fe5-48bf-9b35-1749d563c82d", "fa9860fc-d5c8-42e9-82be-01a83c44b0de", "fcf11b61-a2f4-4b64-9f77-f2e3d8177b15"], "title": "Constructing models for predicting extract subclass refactoring opportunities using object-oriented quality metrics", "venue": "Information & Software Technology", "year": 2012, "id": "18ca3a0b-aab3-4c9e-a281-43e128023012"}
{"abstract": "A general geometrical framework for image processing is presented. We consider intensity images as surfaces in the (x, I) space. The image is thereby a two dimensional surface in three dimensional space for gray level images. The new formulation unifies many classical schemes, algorithms, and measures via choices of parameters in \"master\" geometrical measure. More important, it is a simple and efficient tool for the design of natural schemes for image enhancement, segmentation, and scale space. Here we give the basic motivation and apply the scheme to enhance images. We present the concept of an image as a surface in dimensions higher than the three dimensional intuitive space. This will help us handle movies, color, and volumetric medical images.", "authors": ["Ron Kimmel", "Ravi Malladi", "Nir A. Sochen"], "n_citation": 45, "references": ["2e95fcbe-c995-423f-9ab9-74740000f0b4", "31f9d7a2-651f-48b7-a350-793ab4f2816e", "3f4cc95c-5f47-4031-8671-e23ff4fe2ed2", "45d81869-b49a-4984-8099-8e5755036bc7", "48f96b76-c862-4f13-ae7d-fd7e5bc1938d", "5aa4eef9-8da3-4619-b412-c164551ee472", "7bda3def-639b-47b7-a882-1a5c35ab9693", "ab7a7f45-d368-41e5-b728-bbbc0e35d579", "ad23ca01-fa76-4f9a-ba68-27dc2c51784f", "b608af66-6368-44dc-a670-2a3e42561ee1", "f7a03c48-3575-4766-85bc-24c5f5c9f0c8"], "title": "Images as embedding maps and minimal surfaces: movies, color, and volumetric medical images", "venue": "computer vision and pattern recognition", "year": 1997, "id": "ccd05f5a-0291-4c3d-82ef-dd832f3dd266"}
{"abstract": "This paper describes an unsupervised approach for efficient extraction of grid-structured urban roads from airborne LIDAR data. Technically, the approach consists of three major components: 1) terrain separation from DSM and classification of ground features, 2) road centerline extraction from generated road candidates images, and 3) completion and verification of complete road networks. A ground-height mask is produced by removing elevated objects from depth image. Then from the mask-superimposed intensity image, road features are segmented out by EM algorithm. This is followed by road centerline extraction from the segmentation image using total least square line fitting approach, during which we develop a Radius-Rotating method to detect road intersections. After that, missing roads inference is executed on road centerline vector map according to gestalt laws. To facilitate inference process, a direction-based cumulative voting technique is developed to evaluate reliability of each road segment. Finally, inferred road features are back projected onto depth and intensity image to test their validity.", "authors": ["Jiaping Zhao", "Suya You", "Jing Huang"], "n_citation": 22, "references": ["72dfdcd6-402f-4a33-bf76-0e7c50190249", "9830326a-c9af-4bdc-b45d-02d8fb430a67", "9da798fc-13c2-47fa-9ae8-1b387074e542", "a379e1a9-7293-487b-bd31-e4a68423daae", "c9e249f0-9a25-4616-8ab9-7c394be00643", "ec24191b-c59b-490a-abbf-bf1695ce1d2a"], "title": "Rapid extraction and updating of road network from airborne LiDAR data", "venue": "", "year": 2011, "id": "41e5c2ba-698b-49bd-a717-44a121d39264"}
{"abstract": "Pattern discovery in unaligned DNA sequences is a fundamental problem in computational biology with important applications in finding regulatory signals. Current approaches to pattern discovery focus on monad patterns that correspond to relatively short contiguous strings. However, many of the actual regulatory signals are composite patterns that are groups of monad patterns that occur near each other. A difficulty in discovering composite patterns is that one or both of the component monad patterns in the group may be \u201ctoo weak\u201d. Since the traditional monad-based motif finding algorithms usually output one (or a few) high scoring patterns, they often fail to find composite regulatory signals consisting of weak monad parts. In this paper, we present a MITRA (MIsmatch TRee Algorithm) approach for discovering composite signals. We demonstrate that MITRA performs well for both monad and composite patterns by presenting experiments over biological and synthetic data. Availability: MITRA is available at http://www.cs.columbia.edu/compbio/mitra/", "authors": ["Eleazar Eskin", "Pavel A. Pevzner"], "n_citation": 441, "references": ["1552a53d-6c82-4d57-ae26-e881e3f96a44", "30475162-4382-4ea4-8cd8-52ccba4b329b", "33834a31-132a-409b-b646-c8918a85afb0", "4983b03a-b47c-4cff-a43f-f21810662185", "4e719a80-248f-4465-9aba-69033b3d2ba0", "8fefe4ad-ec38-47cb-a88d-1c56173d27fb", "aef5160f-3112-4484-8743-f6790d4006d1", "b151f18a-159c-4228-a7e7-f5bd05806178", "b34bd636-9222-4eeb-af7e-b03d59ca7311", "bbce5914-7834-4f5c-8a0e-ea397053f934", "c719c146-58bb-4315-a5be-4ad1712ccdc2", "d5e0d7dd-a278-4582-9d65-621aed183c37", "f55a5c57-e056-4962-bc5c-25feb195ae28"], "title": "Finding composite regulatory patterns in DNA sequences", "venue": "intelligent systems in molecular biology", "year": 2002, "id": "6c781b27-964c-407f-afda-645907209baf"}
{"abstract": "Clustering with constraints is a powerful method that allows users to specify background knowledge and the expected cluster properties. Significant work has explored the incorporation of instance-level constraints into non-hierarchical clustering but not into hierarchical clustering algorithms. In this paper we present a formal complexity analysis of the problem and show that constraints can be used to not only improve the quality of the resultant dendrogram but also the efficiency of the algorithms. This is particularly important since many agglomerative style algorithms have running times that are quadratic (or faster growing) functions of the number of instances to be clustered. We present several bounds on the improvement in the running times of algorithms obtainable using constraints.", "authors": ["Ian Davidson", "S. S. Ravi"], "n_citation": 78, "references": ["17256e55-24e3-4607-869d-ba2c9bcb9f51", "17419b6f-249c-4eb7-a212-8bf73346348c", "284f32d0-8650-40a4-8208-5afc143d930c", "2ed6410f-16a4-4ef9-9cac-ca676077f86e", "40e0d8cf-cda8-4d08-aa1e-121fdeac6128", "42f811cb-51e9-4041-acd4-7e1aae06f40c", "47f728b9-85b0-44c4-ab88-b46eb3b88d4d", "54af12e6-ada8-4707-8bc2-8c7f8879508d", "6180baff-6c1b-4467-9ee4-783e136773a5", "807b8ea8-a82a-46ae-87d4-387ea795fa7a", "9d074996-b71b-4ec9-9be9-2b63d2b62158", "bf00f07c-c3fb-4ad9-9974-f9cba537055f", "bf107197-bf6a-4368-a27a-a16482225aa7", "c264419a-fb65-4ac8-93e4-258b259bf01f", "c7faa44b-6e05-427c-956a-a8e46e055efe", "e1f31f18-09bf-4d3c-877d-faa248822847", "e53362a1-93b8-409e-b85f-5032d0595432", "e720ae55-5e05-419c-a587-32cc875001f6", "ecdc9a8c-9d2a-46c2-be36-184cb67e2ef4", "fab8e3bc-2c2b-4671-bec9-56ea8cf7b12b", "fe81612e-f699-467b-97ff-9e86560a7d78"], "title": "Using instance-level constraints in agglomerative hierarchical clustering: theoretical and empirical results", "venue": "Data Mining and Knowledge Discovery", "year": 2009, "id": "78153904-cf7a-42b6-9ff6-c75dcd07ddb5"}
{"abstract": "Nowadays, large service centers provide computational capacity to many customers by sharing a pool of IT resources. The service providers and their customers negotiate utility based Service Level Agreement (SLA) to determine the costs and penalties on the base of the achieved performance level. The system is often based on a multi-tier architecture to serve requests and autonomic techniques have been implemented to manage varying workload conditions. The service provider would like to maximize the SLA revenues, while minimizing its operating costs. The system we consider is based on a centralized network dispatcher which controls the allocation of applications to servers, the request volumes at various servers and the scheduling policy at each server. The dispatcher can also decide to turn ON or OFF servers depending on the system load. This paper designs a resource allocation scheduler for such multi-tier autonomic environments so as to maximize the profits associated with multiple class SLAs. The overall problem is NP-hard. We develop heuristic solutions by implementing a local-search algorithm. Experimental results are presented to demonstrate the benefits of our approach.", "authors": ["Danilo Ardagna", "Marco Trubian", "Li Zhang"], "n_citation": 106, "references": ["27e70a45-4cf7-405a-87bb-46ee1f9bcb5d", "2f3de382-30ea-45e4-84b8-0b4af1e19c67", "33dee00a-f7e3-4be9-b06c-a8e1af5a3f6f", "352838dd-9583-402f-be39-52df4810a25f", "3fb39cdb-6b48-4fc6-983b-7964f9025da8", "48207cd2-55fb-4f50-b178-476a645cd4e4", "4aaa4916-ca14-4284-ae78-93bc49bc6c49", "643288f8-5a36-4fc4-9889-bbd27644f2ac", "674aaacb-4f77-4e31-9975-1ca429694604", "6b31966f-09d6-4a5a-aa50-4d5bd1f6c034", "78693c03-a574-4915-a489-7e60d3b827cc", "78991392-db9c-45a4-86a2-b4ce93ab0ec0", "81105daa-e84c-4c2c-bf26-a07cf78578ec", "937702cd-0326-44b6-a9a5-ad1e48316458", "b302e702-cd32-4c9e-a81b-d1380aeb3da9", "c9db4760-1b18-4fef-8fd3-9991879ea0e0", "d789c1d3-543c-4fd0-96ba-3f5734fdf23b", "de989c44-03d4-430d-b090-f05a5f4f9316", "e74bd2a5-74c5-4685-b901-cc9810fa58bd"], "title": "SLA based resource allocation policies in autonomic environments", "venue": "Journal of Parallel and Distributed Computing", "year": 2007, "id": "ab6d5422-9c83-4cb4-8ddd-99881e912785"}
{"authors": ["Marten van Dijk"], "n_citation": 161, "references": ["2d22ea79-c8cf-46d1-a6f0-582ccd7cdd63", "4e07d28c-58e5-499a-95a0-e055bfafc840", "689d7281-bf2d-4a2b-8254-a19bddf369d4", "771b056e-9207-4c71-8628-59b30387dbed", "84966fdb-eb16-4455-b64c-fe5b28d48a7e", "8ead2c8a-143e-47d4-ac70-598901eafb85", "96bac912-1985-4900-a002-d3716c2cf156", "98f543e3-d61c-4099-ae96-237816472592", "f156b91f-4858-47cb-bacc-8844c704b8ae", "fc4a5205-3910-4c93-b844-0bbc35bfde8e"], "title": "On the information rate of perfect secret sharing schemes", "venue": "Designs, Codes and Cryptography", "year": 1995, "id": "5367997e-87f9-4a1b-bcf7-f368805ffa58"}
{"authors": ["Hung-Yang Chang", "Miron Livny"], "n_citation": 31, "title": "Distributed Scheduling under Deadline Constraints: A Comparison of Sender-Initiated and Receiver-Initiated Approaches.", "venue": "real-time systems symposium", "year": 1986, "id": "49d38b19-80b4-4ac5-a1fc-7456082d6b3d"}
{"abstract": "We discuss some important data structures and computer science techniques, and their applications to operations research problems. The purpose of our discussion of applications, some of which are novel, is to stimulate further reading, for which adequate references are given. The techniques that we discuss are among the most important, but many valuable ones had to be omitted.", "authors": ["Bennett L. Fox"], "n_citation": 68, "references": ["072847d1-f7e2-4239-8f0b-d300b82cdee1", "0e3f4b93-05f8-4601-bb68-13d1450520d3", "1c95e88b-ba26-4e93-8c74-c351c56f92f3", "224ab868-2c68-4041-a533-a46fdad013b0", "24f70640-7ce4-433d-b591-74df213252e9", "3d216434-22c5-43af-a807-d2315565025a", "48165101-a81c-4134-825f-8555b70394fd", "58ea2ca9-93e2-4784-8056-86e77e30aeed", "6f0c1591-b41d-486f-b335-4f84bbac754e", "7cde2b22-6d01-49a7-bd56-8e159d712552", "85cf50e1-54e0-4193-9a4f-e59ffa445c50", "8edd40b7-76b6-4ed7-9dac-e383ac1cf31c", "94cca363-18d3-49ed-bda4-cbd05a3176b5", "9a041e6a-2067-41f6-9306-1fa5814f6f17", "9d3b4be7-4080-4102-91c3-810af4f85a08", "a1bbfdfe-18f9-498d-9e33-80af9b0fd393", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "ac215917-463c-4e36-97de-66afec003981", "b3a30d94-91bf-484b-8b01-4924cfe06079", "c8c98b65-25e1-4046-9a20-c84f00270e83", "cf2cac6c-be5b-4892-9f20-ed2d4e489cd5", "d6f59786-7b2d-4349-8fd4-45a135acad5f", "ddef7e23-2bd2-4949-b59b-5999e6d06505", "fe2f599b-f8ff-4bc7-8e09-f93383a1ce60"], "title": "Data Structures and Computer Science Techniques in Operations Research", "venue": "Operations Research", "year": 1978, "id": "e2b49d3e-7851-4b1c-89cd-2cf557749df8"}
{"abstract": "Abstract   This work proposes a procedure to design adaptive and self-learning fuzzy controllers in real time, requiring only a limited prior knowledge of the plant to be controlled, both in terms of the quantity and precision of this information. The algorithm does not need a mathematical model of the plant, or its approximation by means of a Jacobian matrix. Neither is it necessary to know the response desired at each instant of time, nor need there be previously available data. Auxiliary fuzzy controllers accomplish simultaneously the adaptation of the output scale factor (which is essential in the first steps of the control process) and learning of the parameters within the principal fuzzy controller (fuzzy rules). To verify the validity of the algorithm, real control problems were used: the stabilization of the temperature of a thermostat and level control within a liquid-filled tank. An analysis of the stability and robustness of the proposed algorithm is performed for different initial configurations of the fuzzy systems required by the algorithm and for abrupt changes in the plant to be controlled.", "authors": ["Ignacio Rojas", "H\u00e9ctor Pomares", "Francisco J. Pelayo", "Mancia Anguita", "Eduardo Ros", "Alberto Prieto"], "n_citation": 50, "title": "New methodology for the development of adaptive and self-learning fuzzy controllers in real time", "venue": "International Journal of Approximate Reasoning", "year": 1999, "id": "8988fbe6-ced1-48d1-b05f-189e735e2720"}
{"abstract": "A family of nonorthogonal polynomial spline wavelet transforms is considered. These transforms are fully reversible and can be implemented efficiently. The corresponding wavelet functions have a compact support. It is proven that these B-spline wavelets converge to Gabor functions (modulated Gaussian) pointwise and in all L/sub p/-norms with 1 >", "authors": ["Michael Unser", "Akram Aldroubi", "Murray Eden"], "n_citation": 361, "references": ["2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5", "3f0bc2c9-a5c2-4e4c-a4e9-7631e36bc6a3", "7ccbdf09-a84e-4ad2-ab20-cb28b6c41155", "7d5e97d2-5ebe-4be2-ac67-3c15fcde2c8d", "7fcf67fc-e0be-4a0e-a80e-a742e36c257f", "de4f789c-28fe-42e1-bbdb-3bbdfbd156f6", "fde7e6db-a925-440e-b27f-3f162da5f793"], "title": "On the asymptotic convergence of B-spline wavelets to Gabor functions", "venue": "IEEE Transactions on Information Theory", "year": 1992, "id": "d284f023-95da-4aa0-8505-5cbe6dc934a0"}
{"abstract": "A verifiable image secret sharing scheme, which is based on the Thien-Lin scheme and the intractability of the discrete logarithm, is proposed in this paper. The new scheme can identify the cheaters no matter if she/he is the original secret image holder or the participant; because each participant chooses her/his own secret shadow by her/himself, the new system doesn't need a security channel; Due to the same fact, the secret shadow of each participant can be reused. In addition, the size of each shadow image, same as the Thien-Lin scheme, is smaller than that of the original secret image.", "authors": ["Rong Zhao", "Jianjie Zhao", "Fang Dai", "Fengqun Zhao"], "n_citation": 84, "references": ["678f5495-637e-4a87-8ed0-875abb56caf4", "98f543e3-d61c-4099-ae96-237816472592", "bfb47454-2d6c-47d0-8896-a242d7409da3", "d5ec4f5c-2304-4286-8724-c8caf17ff69d"], "title": "A new image secret sharing scheme to identify cheaters", "venue": "Computer Standards & Interfaces", "year": 2009, "id": "d078d5f3-e6af-4bd4-850d-7995ce027043"}
{"abstract": "Computing systems often deliberately release (or declassify) sensitive information. A principal security concern for systems permitting information release is whether this release is safe: is it possible that the attacker compromises the information release mechanism and extracts more secret information than intended? While the security community has recognised the importance of the problem, the state-of-the-art in information release is, unfortunately, a number of approaches with somewhat unconnected semantic goals. We provide a road map of the main directions of current research, by classifying the basic goals according to what information is released, who releases information, where in the system information is released, and when information can be released. With a general declassification framework as a long-term goal, we identify some prudent principles of declassification. These principles shed light on existing definitions and may also serve as useful \"sanity checks\" for emerging models.", "authors": ["Andrei Sabelfeld", "David Sands"], "n_citation": 270, "references": ["01af64eb-32dd-4b9e-a1cc-938f4a04b532", "054c8cad-6c85-4cdd-8548-a20e61852a93", "16d386b0-fbe6-4df6-b1c2-db63aab8e1fa", "1a913fea-6e50-4a50-a946-8126314460c0", "1baeeaaf-052d-4fa9-873f-4f6528389e30", "25f97be0-1f2a-42ce-af73-cf266b281000", "2ddddbb7-0136-4c16-9917-c84ed9a1548a", "2fb8732a-fff1-4940-9bdf-fc5d9ab86e2e", "331c6e5e-7f03-4ab1-9c5a-d70595d90c26", "3b04d35f-7971-423e-b4f7-acfc17a842f9", "3c4d15f5-7743-43df-8f5c-9b9caaa4f8fc", "3f36c36e-53f5-4a84-98f9-c253be61e60a", "41ae9910-e098-4739-bd97-e3e8dfc435d4", "52a168cc-03c9-49da-af9f-66dc3a31ee36", "52cabc51-03b2-4485-87bd-9500810b4bea", "54d8d700-ff71-4715-8263-2cce56444a40", "5817a459-aba0-4fbc-b9f5-b1a7f40523d9", "584c4923-0adf-4945-a5e6-e3c51cc38668", "59e08cae-80f9-4eb2-9b8e-74f0aa688e5f", "5a163d65-b532-441e-818e-a8e4d96d5e6a", "5cb891ce-3658-404e-9ce5-5a7853038234", "5fa6044e-2f69-4411-8a81-0343958d6999", "738768e2-9615-4fd3-ad14-1383af452a4e", "793a919a-eed2-4385-a63f-f6950a53ea15", "7aa9ff9d-3163-4387-9895-d250330c5515", "8e4748df-2b84-4039-a1f5-74de6584142c", "8ec12050-960b-45b6-8421-3dc2e518c708", "90611d77-4246-4565-8f28-54f33961fb8f", "a431b297-2203-43b1-9aa9-7df71141552f", "b107dc5b-6234-47fd-8393-72c50ce26b64", "b229e7d3-7c6a-4192-9de2-434e20ffb809", "b62a2f03-8c81-42a8-92e6-79a6994780d3", "ba6a7fc6-d07b-4bdc-a75b-1032c8576c12", "bcdb8e71-914f-45e0-bbce-3186455c1012", "c4d008e9-6374-43a6-a13c-74a4715adf58", "c565043d-0d12-48ee-9a6a-7fc685cfc72c", "c89f8d87-19b1-4a34-bf90-ba7ca8ad2602", "ceaebc72-b8cc-40ae-9a4f-0a1e68271313", "d0b15cdd-9842-4716-b267-5834aaa5d722", "d9c030cb-d9d6-4d4b-82af-e69b0d25cb00", "e03cb036-2728-4f79-a0a1-45dc108f4dd6", "e12b4e09-4b13-49de-9278-6d337939778f", "e38f5822-ccd2-4fce-aca1-4bd838724dea", "e5a3d5c8-ed2e-4228-a473-50fb3560eacc", "ec51fd74-6be0-4066-a618-bf78b8cd8ced", "f3eee849-48ce-480c-a8ac-69030264c772", "f5e80a67-a0c8-41ef-a39d-2b74db452e05", "f861eec0-3232-4363-9362-52518851d6d9"], "title": "Dimensions and principles of declassification", "venue": "computer security foundations workshop", "year": 2005, "id": "44e65a36-6b6a-49df-a885-f19c86e0edd2"}
{"abstract": "A number of laws are derived which establish relationships between throughput, response time, device utilization, space-time products and various other factors related to computer system performance. These laws are obtained by using the operational method of computer system analysis. The operational method, which differs significantly from the conventional stochastic modeling approach, is based on a set of concepts that correspond naturally and directly to observed properties of real computer systems. Except for measurement errors, the operational laws presented in this paper apply with complete precision to all collections of observational data, and they are similar to fundamental laws found in other areas of engineering and applied science.", "authors": ["Jeffrey P. Buzen"], "n_citation": 50, "references": [], "title": "Fundamental laws of computer system performance", "venue": "measurement and modeling of computer systems", "year": 1976, "id": "ecabd42d-189c-4c7e-b14f-c53f08c6a7c4"}
{"abstract": "This paper presents a new study on the relative degrees of single-input and single-output T\u2013S fuzzy systems in general noncanonical forms, and proposes a feedback linearization-based control design method for such systems. The study extends the system relative degree concepts, commonly used for the control of nonlinear systems, to general T\u2013S fuzzy systems, derives various relative degree conditions for general T\u2013S fuzzy systems, and establishes the relative degree dependent normal forms. A feedback linearization-based control design framework is developed for general T\u2013S fuzzy systems using its normal form, to achieve closed-loop stability and asymptotic output tracking under relaxed design conditions. A new adaptive feedback linearization-based control scheme for T\u2013S fuzzy systems in general noncanonical forms with parameter uncertainties is designed and analyzed. Some extensions of relative degrees and their possible application to robust adaptive control for noncanonical form T\u2013S fuzzy systems are also demonstrated. An illustrative example is presented with simulation results to demonstrate the control system design procedure and to show the effectiveness of the proposed control scheme.", "authors": ["Yanjun Zhang", "Gang Tao", "Mou Chen"], "n_citation": 4, "references": ["03f72f18-e658-4e7b-bde7-0f4192491a00", "051e4eac-aafc-4d26-a218-d1fa203e6c28", "06b056d7-0637-4180-88e8-602e5d3dde74", "100a1ddc-ccd6-4e4f-8fe0-39e68afdb4e7", "21434adf-9175-4f11-83fe-2d4fc944cc21", "21c5d131-6111-40c5-9b77-ecadd65c2cfb", "226de359-c8b1-4609-b218-f1adab2ca82b", "24cc216b-7544-42ee-b31d-a44d7ff8777c", "50c6fbe1-842f-4748-b2ab-70509e369f0e", "564a9d46-4fb4-4a83-a349-733711ef8298", "64eefd18-582c-4e82-a154-f98de2defe78", "7402b7f4-9298-41d8-9bbc-4a608934d3f3", "75f88c7d-7bce-47c3-82fa-55ff74155022", "81098e98-f1ea-4ab2-858c-0be91f55c217", "826da568-d1fa-41b0-bd71-9fbe2c9453c6", "89db0574-0344-4d12-b024-1fbd11108ceb", "8a7c2ce1-e628-4483-8bab-e42a6fb9ce4b", "9aa54650-2674-46f1-a5cc-06ad2fd917c3", "9b53aa79-8e48-4fb5-9cf2-6966ee7dfedc", "b1458a1c-7482-4e92-8406-b2d20d18b793", "be602781-8e6f-4d4a-82b5-c6a1a729e073", "c6808f7e-9890-43ca-a899-3e6dbce6e9f0", "d7712409-b59c-4422-9cd7-d5d45116d66a", "e07c17af-995e-477a-9808-cb8ef7f8d7e1", "e6507898-4039-452a-8ddb-1894da52b310", "ea112733-a167-440b-81d0-b4db354acd6a", "efa2b6a1-50c3-4683-9269-0c8c3ab7a6ee"], "title": "Relative Degrees and Adaptive Feedback Linearization Control of T\u2013S Fuzzy Systems", "venue": "IEEE Transactions on Fuzzy Systems", "year": 2015, "id": "397b6f5a-d4e2-49a9-a60b-13e91a6fe361"}
{"abstract": "Research on virtual environments VE produced significant advances in computer hardware graphics boards and i/o tools and software real-time distributed simulations. However, fundamental questions remain about how user performance is affected by such factors as graphics refresh rate, resolution, control latencies, and multimodal feedback. This article reports on two experiments performed to examine dextrous manipulation of virtual objects. The first experiment studies the effect of graphics frame rate and viewing mode monoscopic vs. stereoscopic on the time required to grasp a moving target. The second experiment studies the effect of direct force feedback, pseudoforce feedback, and redundant force feedback on grasping force regulation. The trials were performed using a partially-immersive environment graphics workstation and LCD glasses, a DataGlove, and the Rutgers Master with force feedback. Results of the first experiment indicate that stereoscopic viewing is beneficial for low refresh rates it reduced task completion time by about 50% vs. monoscopic graphics. Results of the second experiment indicate that haptic feedback increases performance and reduces error rates, as compared to the open loop case with no force feedback. The best performance was obtained when both direct haptic and redundant auditory feedback were provided to the user. The large number of subjects participating in these experiments over 160 male and female indicates good statistical significance for the above results.", "authors": ["Paul Richard", "Georges Birebent", "Philippe Coiffet", "Grigore C. Burdea", "Daniel Gomez", "Noshir A. Langrana"], "n_citation": 97, "references": ["0db2eea7-73d9-4136-bf20-e089a7c9d731"], "title": "Effect of frame rate and force feedback on virtual object manipulation", "venue": "Presence: Teleoperators & Virtual Environments", "year": 1996, "id": "bfe35dd0-077a-443c-8b29-08a59209895d"}
{"abstract": "We describe a statistical method to detect highlights in a baseball game video. The input video is first segmented into scene shots, within which the camera motion is continuous. Our approach is based on the observations that (1) most highlights in baseball games are composed of certain types of scene shots and (2) those scene shots exhibit special transition context in time. To exploit those two observations, we first build statistical models for each type of scene shots with products of histograms, and then for each type of highlight a hidden Markov model is learned to represent the context of transition in the time domain. A probabilistic model can be obtained by combining the two, which is used for highlight detection and classification. Satisfactory results have been achieved on initial experimental results.", "authors": ["Peng Chang", "Mei Han", "Yihong Gong"], "n_citation": 189, "references": ["00566c0e-d665-45d7-8aee-34a69c895c8d", "a0e6452c-c7ee-4bc1-817d-cb8f4abb2bff", "a13da1fe-9d4e-465f-9215-b453e4adab26", "c6b7029f-50f9-4ac9-83ab-6fd7b8596827", "e188235c-5396-4f0a-908e-89cbce992aa5"], "title": "Extract highlights from baseball game video with hidden Markov models", "venue": "international conference on image processing", "year": 2002, "id": "6c10fc33-7649-4949-bc2b-9c05be6890e6"}
{"abstract": "Controller area networks (CANs) are widely used in real-time automobile control and are gaining wider acceptance as a standard for factory automation. This paper discusses the applicability of earliest-deadline-first (EDF) techniques to the scheduling of CAN messages. EDF can guarantee higher network utilization than fixed-priority schemes like deadline- or rate-monotonic (DM, RM), but it is difficult to implement in local area networks or local buses. The reason is the need for updating the deadlines (priorities) at each scheduling round and the limited number of priority levels offered by the arbitration protocol. This deadline encoding problem results in an additional priority inversion factor when considering the schedulability analysis of hard real-time messages. This paper describes an effective deadline encoding method and discusses its implementation and its effects on the guarantee analysis. In spite of a limited processor overhead (less than 5% of CPU time), the proposed EDF implementation allows an increase (up to 20%) in the feasible network workload. This tradeoff will be made more convenient as controller technology evolves.", "authors": ["M. Di Natale"], "n_citation": 115, "references": ["0e83336d-d2f7-449f-bae7-8ec1bf1d0a07", "3633a6cc-58d1-45c0-a746-44b3a2993177", "5585a965-f94c-4314-864b-1d83a2c5c511", "595e9aed-e36f-47d0-8a96-856eb6a25b47", "9a0d9ce5-5d3c-498f-8151-0e8d28b9f95d", "c3302d0a-4a20-4cac-ab6a-5306eadcd538"], "title": "Scheduling the CAN bus with earliest deadline techniques", "venue": "real-time systems symposium", "year": 2000, "id": "55f02c97-8233-4644-9571-ed9d64637c1b"}
{"abstract": "Abstraction is one of the cornerstones of software development and is recognized as a fundamental and essential principle to be taught as early as CS1/CS2. Abstraction supposedly can enhance students' ability to reason and think. Yet we often hear complaints about the inability of CS undergraduates to do that. Do we supply students with the tools they need to reach their potential to think carefully and to reason rigorously about software behavior? Typically we do not, but as educators there are techniques we can use to help our students develop such skills starting in CS1/CS2.", "authors": ["Paolo Bucci", "Timothy J. Long", "Bruce W. Weide"], "n_citation": 39, "references": ["bf8679d5-25b4-4ccd-87e5-2e4f0561c37e", "d8e2f437-f74d-4bd9-aec2-e947e38e2105"], "title": "Do we really teach abstraction", "venue": "technical symposium on computer science education", "year": 2001, "id": "b2ba9c75-97a6-4f0a-88fc-68966ac791b9"}
{"abstract": "Context#R##N#Software defect prediction has been widely studied based on various machine-learning algorithms. Previous studies usually focus on within-company defects prediction (WCDP), but lack of training data in the early stages of software testing limits the efficiency of WCDP in practice. Thus, recent research has largely examined the cross-company defects prediction (CCDP) as an alternative solution.#R##N#Objective#R##N#However, the gap of different distributions between cross-company (CC) data and within-company (WC) data usually makes it difficult to build a high-quality CCDP model. In this paper, a novel algorithm named Double Transfer Boosting (DTB) is introduced to narrow this gap and improve the performance of CCDP by reducing negative samples in CC data.#R##N#Method#R##N#The proposed DTB model integrates two levels of data transfer: first, the data gravitation method reshapes the whole distribution of CC data to fit WC data. Second, the transfer boosting method employs a small ratio of labeled WC data to eliminate negative instances in CC data.#R##N#Results#R##N#The empirical evaluation was conducted based on 15 publicly available datasets. CCDP experiment results indicated that the proposed model achieved better overall performance than compared CCDP models. DTB was also compared to WCDP in two different situations. Statistical analysis suggested that DTB performed significantly better than WCDP models trained by limited samples and produced comparable results to WCDP with sufficient training data.#R##N#Conclusions#R##N#DTB reforms the distribution of CC data from different levels to improve the performance of CCDP, and experimental results and analysis demonstrate that it could be an effective model for early software defects detection.", "authors": ["Lin Chen", "Bin Fang", "Zhaowei Shang", "Yuanyan Tang"], "n_citation": 47, "references": ["02118a50-4be5-401e-8840-75a8d36700f7", "05a640f0-f422-44ed-a744-2918344881af", "10498bec-04d6-40b8-8fa6-f7a9f857fd31", "12d0dbd4-4dd9-42b7-a321-14270882a619", "1eb3a4e4-e6a5-49ab-bb53-06c09eeda046", "21a861b9-c5bd-4071-8333-406d8cf20344", "21ffae8e-2406-4e5e-b1e1-e6a0f9a82bf1", "38f68332-6bc9-4998-a344-759cfda2fba0", "4e0d2792-5f82-4e13-812c-781172f92e40", "4fa57dac-0285-4c03-bddc-193a0e0b35ae", "576af68e-a45d-4114-a52e-efa6a5d2161d", "5880d47f-8b99-416d-a743-28d6b49f7ba9", "5aee6db3-7c39-4721-89f3-3a8c637b9d2f", "688d96cf-89c7-4d8f-b882-ae07ded70bbd", "6c3b836b-1fc7-4e16-85d7-16ee9aa34845", "70c9373c-7997-4901-baf4-6dcf5bf80ed4", "75ec0b95-65c5-48c9-ae1b-a44c6c378bec", "788ed717-995a-431d-939a-4405e6e352f2", "8afc4f24-0abe-437f-977e-375ec3ec907d", "97816301-b8f3-4859-bf28-319e4193b885", "a05b8bcf-789e-4538-8f43-86e6d7bb4285", "a1853113-dd04-44ae-9e76-a0ddfbf49084", "af647f42-0b8d-480b-a36e-c7f351a95473", "bb24d529-ae23-4491-bf13-74ba7a116080", "bd032c77-f860-4a1c-9a8a-f048f86a2fc1", "d20df5c3-667b-42d4-a128-d5f0b649cc32", "d696d708-a6fb-49b9-a976-798f858ab380", "d7ba244b-ff90-49e2-b7e5-860c54a1c5dd", "da236a5b-d7a4-423c-a344-a5afe9b444a0", "db26488d-78be-44b1-a343-e896f43c5d29", "e9f5e156-5766-4494-ae9a-33ffbc4ef53b", "f165d960-af33-4588-8319-b90fce361d80", "fe66f0e4-c015-4152-b6b3-5a13e427e6c0"], "title": "Negative samples reduction in cross-company software defects prediction", "venue": "Information & Software Technology", "year": 2015, "id": "c36d9687-6a86-408c-875f-9ad0bdedf151"}
{"abstract": "In this paper, we propose a stochastic version of a general purpose functional programming language as a method of modeling stochastic processes. The language contains random choices, conditional statements, structured values, defined functions, and recursion. By imagining an experiment in which the program is \"run\" and the random choices made by sampling, we can interpret a program in this language as encoding a probability distribution over a (potentially infinite) set of objects. We provide an exact algorithm for computing conditional probabilities of the form Pr(P(x) | Q(x)) where x is chosen randomly from this distribution. This algorithm terminates precisely when sampling x and computing P(x) and Q(x) terminates in all possible stochastic executions (under lazy evaluation semantics, in which only values needed to compute the output of the program are evaluated). We demonstrate the applicability of the language and the efficiency of the inference algorithm by encoding both Bayesian networks and stochastic context-free grammars in our language, and showing that our algorithm derives efficient inference algorithms for both. Our language easily supports interesting and useful extensions to these formalisms (e.g., recursive Bayesian networks), to which our inference algorithm will automatically apply.", "authors": ["Daphne Koller", "David A. McAllester", "Avi Pfeffer"], "n_citation": 110, "references": ["172d4027-bbd6-454b-a1bc-4ea4b6c6d406", "1867bb41-553e-4da2-888f-086e994dd161", "1eaf6185-cb7e-4e23-9c93-1252e0eb559b", "3cc7d99b-2563-47ab-a83a-3555a2bf2736", "6a8bdbb0-f1e4-483d-9ac2-07d7749b4055", "8044c1c4-99dd-4229-a82d-70e67ad36e06", "919dd587-162e-42e3-8403-bd19193170cd", "9a7a30b9-1c56-43e8-91b1-0d60fd22ca44", "ad3a4ba4-5b88-4d61-9ba5-263cda996e9c", "c9f070c0-7896-4c2c-8552-5e8be792d0ad", "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706", "e7a4dfe5-dd09-4984-9213-3449c71cb93a", "f6a63193-3b6e-4ba3-9bd9-492282fd0248"], "title": "Effective Bayesian inference for stochastic programs", "venue": "national conference on artificial intelligence", "year": 1997, "id": "f7fbd108-98fc-4f3e-8c29-002720625e01"}
{"authors": ["Christian Vogler", "Dimitris N. Metaxas"], "n_citation": 149, "references": ["64eec0c9-2f98-4d93-83d3-24927ce04bf3", "67cfb6a4-846a-4f7d-9fca-1fc9337663cd", "73993e82-42b3-4a68-925a-f106fd5a51e0", "a8faaff5-99a1-4724-91ae-a8bcaaf63954", "ac89f3b0-40fb-4eb9-b101-a3fbd2eebb06", "cf38bc3f-50b2-4045-a74f-ab6058c0594e", "fc2db386-5dc3-4073-87dd-95e5f233459c"], "title": "Handshapes and Movements: Multiple-Channel American Sign Language Recognition", "venue": "", "year": 2003, "id": "b3cadc31-8938-474b-8127-4e7032c69f28"}
{"abstract": "This paper presents a novel distributed estimation algorithm based on the concept of moving horizon estimation. Under weak observability conditions we prove convergence of the state estimates computed by any sensors to the correct state even when constraints on noise and state variables are taken into account in the estimation process. Simulation examples are provided in order to show the main features of the proposed method.", "authors": ["Marcello Farina", "Giancarlo Ferrari-Trecate", "Riccardo Scattolini"], "n_citation": 115, "references": ["09cb8412-837f-46d3-942e-b77398063643", "0aef08a4-9fb6-41df-a465-94dd331e7825", "1cb63979-852f-4a31-8555-ed2e995b745f", "3b23bd1e-89f8-469d-a07e-3ac4e1b62a8a", "645668bc-d1f1-4c3e-85ac-2625119a9413", "815d35d8-14e4-412d-92cb-177d248a8383", "8a16a7e0-5a0e-4e1a-a388-2aa2b0cc9ec0", "8e7a16f2-a585-4b21-824b-94be5b5bbac2", "903bc60a-02a0-4bc3-a25e-81b07e74332d", "98281539-8bc6-4bff-956d-b3c181a9f9d6", "9deb3f03-b508-4863-8582-24a08e03bd7f", "a0179476-0f19-45bc-a32d-33562ab5517f", "a68e698d-be3d-4add-a303-587322790af2", "aa506b39-3952-491f-9042-31672dc4c2f4", "c0be8771-8920-448e-9b84-e94295dc1859", "cc259597-c637-451f-96ae-dd92d7f697c9"], "title": "Distributed Moving Horizon Estimation for Linear Constrained Systems", "venue": "IEEE Transactions on Automatic Control", "year": 2010, "id": "aaf2fd52-8422-403f-8727-fea923f8e780"}
{"authors": ["Michal Haindl", "Stanislava \u0160imberov\u00e1"], "n_citation": 5, "title": "A scratch removal method.", "venue": "Kybernetika", "year": 1998, "id": "f0c137eb-1eaf-4595-a8e2-cd97ab291df3"}
{"abstract": "A local, second-order (truncated) approximation is applied to the Hubbard model in three dimensions. Lowering the temperature, at half-filling, the paramagnetic ground state becomes unstable towards the formation of a commensurate spin-density-wave (SDW) state (antiferromagnetism) and sufficiently far away from half-filling towards the formation of incommensurate SDW states. The incommensurate-ordering wave vector does not deviate much from the commensurate one, which is in accordance with the experimental data for the SDW in chromium alloys.", "authors": ["Michael R. Birch", "Christopher M. Boroni", "Frances W. Goosey", "Samuel D. Patton", "David Keith Poole", "Craig M. Pratt", "Rockford J. Ross"], "n_citation": 50, "references": ["2a933244-84bb-4d24-a79f-75ad659cae01", "33910b4f-c36e-41e7-9530-6c50fb25081d", "35ee83af-44b0-4299-92b2-8e8b1cf197b5", "813b9916-3353-4346-bc72-62aae297a3d7", "85274ad1-4718-482c-879a-0e352e2eb08c", "8d45e6f6-e68f-4c8e-a319-f561966e4bbe", "8dff4977-44eb-4de8-804f-51788a50ad73", "c90a7a3f-6ac5-4597-b31e-4b4c4186a540", "d9145d08-d00e-4443-a09a-dbefc0ef71c2", "e34be42a-558d-4a68-9118-34652dfb0678"], "title": "DYNALAB: a dynamic computer science laboratory infrastructure featuring program animation (abstract)", "venue": "technical symposium on computer science education", "year": 1995, "id": "07e32ccf-49dd-474c-a5d0-0db3e6cd8699"}
{"authors": ["Francesco Curatelli", "Chiara Martinengo", "Francesco Bellotti", "Riccardo Berta"], "n_citation": 6, "references": ["0706021c-1253-481a-acb6-dded9a9a9570", "1dbf4516-33a5-4cd5-83bf-008f31cae21d", "3ef82bb1-372e-4402-a0ad-a26627d4b90c", "638135c3-708d-4cd4-b23c-8fb896237124", "6a0a3773-96fd-43b7-acf2-2104093b3d64", "78927167-6441-4f58-9b8e-b16d3850864a", "928f9ef2-645e-4351-9b3a-2632e8d90ce7", "99d88276-f4a1-4794-b6cb-83e9c66f9b80", "9a8e4acc-c5b9-4517-8119-1c376a8b2a55", "e8158cd9-a768-4129-9589-5cbe0aec7c77"], "title": "Paths for Cognitive Rehabilitation: From Reality to Educational Software, to Serious Games, to Reality Again", "venue": "", "year": 2013, "id": "087d87b2-2bc3-4d20-a189-9c940ebe8045"}
{"abstract": "We study an approach to quality-of-service (QoS) that offers end-users the choice between two service classes defined according to their level of transmission protection. The fully protected (FP) class offers end-users a guarantee of survivability in the case of a single-link failure; all FP traffic is protected using a 1:1 protection scheme at the wavelength-division multiplexing (WDM) layer. The best effort protected (BEP) class is not protected; instead restoration at the IP layer is provided. The FP service class mimics what Internet users receive today. The BEP traffic is designed to run over the large amounts of unused bandwidth that exist in today's Internet. The goal is to increase the load carried on backbone networks without reducing the QoS received by existing customers. To support two such services, we have to solve two problems: the off-line problem of mapping logical links to pairs of disjoint fiber paths, and an on-line scheduling problem for differentiating packets from two classes at the IP layer. We provide an algorithm based on a Tabu Search meta-heuristic to solve the mapping problem, and a simple but efficient scheduler based on weighted fair queueing for service differentiation at the IP layer. We consider numerous requirements that carriers face and illustrate the tradeoffs they induce. We demonstrate that we can successfully increase the total network load by a factor between three and ten and still meet all the carrier requirements.", "authors": ["Antonio Nucci", "Nina Taft", "Chadi Barakat", "Patrick Thiran"], "n_citation": 50, "references": ["0019362a-1f6f-4607-afaa-5f514e72aad7", "001ad4f2-2e3e-472f-833c-2d9dab055fa3", "09024120-ea26-415c-8ef9-d6d3c355f6bf", "23d44639-190f-4c0c-b60e-ceead16ddacb", "58f43ee6-4683-4ec3-9d2a-14923c32770f", "5e52aa09-c334-4bf2-b73b-d0607b16efcd", "64e69c21-72da-44f8-8b0d-2a6851b46e87", "7398f3eb-b3b2-4567-b955-171825aad912", "774d95bd-7e12-4310-9141-13844829e299", "7d2a7592-1f24-4e68-b027-9da60b467386", "9d64fbe8-3f56-4607-94ff-2eb0080839b3", "a1fb7d8f-4b56-4dc0-9d42-652f67d6db65", "a29630f9-df4e-4f58-b066-423b90e2b4e7"], "title": "Controlled use of excess backbone bandwidth for providing new services in IP-over-WDM networks", "venue": "IEEE Journal on Selected Areas in Communications", "year": 2004, "id": "2b0db366-fbc2-4617-ba79-54e2a2c010d3"}
{"authors": ["Seung Bae Park", "Moon Seol Kang", "Sang Jun Lee"], "n_citation": 3, "references": ["2c33bdb1-6f8e-4453-8e10-5153056ae70f", "34e8e9be-8a65-4aeb-a1b8-b6e0feb2ef50", "3fb43b00-905c-4a08-934d-198ea4eb66c3", "48458faa-9c30-4f32-a0a3-8405bdcee7d1", "8ae6fc4f-4230-42a4-8677-587f470517a2", "ca394e6a-59e0-466c-a66a-d976555db689", "cef4b1b3-d027-4b06-89cb-6ec680170cbc", "e90bf43b-9eae-4432-85bc-9b3ca3ae2e32", "ee54526b-4d3e-4981-89b9-8d42ca40de07"], "title": "Authenticated Key Exchange Protocol Secure against Offline Dictionary Attack and Server Compromise", "venue": "grid and cooperative computing", "year": 2003, "id": "526ba945-4b9f-4716-b4ec-ba4d8657a5b4"}
{"abstract": "We address how the XML Topic Map (XTM) 1.0 standard can be used to develop an analytical knowledge base comprised of multiple ontologies to support intelligence assessments. Termed the MultiOntology Analytical Knowledge Organizational (MAKO) framework, it incorporates a Multidimensional Ontology Model (MOM) that organizes subjects into separate conceptualizations based upon common-sense groupings. Topic, association and occurrence elements are temporally serialized, according to the Temporal Layer Model (TLM), to accommodate, and historically preserve, modifications to the knowledge base as world events change.", "authors": ["A.R.Y. Morikawa", "Larry Kerschberg"], "n_citation": 50, "references": ["079f338c-4e96-4d71-b5e3-b1c9d3ce30ff", "1aee9969-cfdb-4bd1-8a2f-3a4a9fcda840", "4635b3f1-b5f0-402d-bfae-bc1d112f79db", "48a31150-e17c-4ded-a124-f1fbca300338", "d62a412e-8583-45e4-b59d-1f3534086dd0"], "title": "MAKO: Multi-Ontology Analytical Knowledge Organization based on topic maps", "venue": "database and expert systems applications", "year": 2004, "id": "e9e7a96a-9afb-466f-9039-7abbaabbf72c"}
{"abstract": "As private transport concerns, the global challenge of this millennium is the reduction of carbon dioxide emissions from passenger cars by improving fuel economy without sacrificing the vehicle performance. Hybrid electric vehicles powertrain, combining electric motor with an auxiliary power unit, can improve effectively the vehicle performance and fuel economy, reducing at the same time the effects of the use of private cars on the air quality of the cities. These advantages can be achieved only if the design of the powertrain is inspired to the minimisation of the main figures of merit holding in consideration many general aspects and variables. As supporting methodology in developing this difficult activity, a genetic-based sizing methodology will be presented. It will be aimed to minimise a function objective which takes into account not only technical specifications but also environmental, social, and economic aspects. Some interesting simulation results will be reported to prove the validity of the methodology, which will contribute to a substantial reduction of the pollutant emissions from hybrid electric vehicles.", "authors": ["Vincenzo Galdi", "Lucio Ippolito", "Antonio Piccolo", "Alfredo Vaccaro"], "n_citation": 55, "title": "A genetic-based methodology for hybrid electric vehicles sizing", "venue": "soft computing", "year": 2001, "id": "ff8fc8e7-57ac-424b-b3b0-49720c28a161"}
{"abstract": "Phishing emails are semantic attacks that con people into divulging sensitive information using techniques to make the user believe that information is being requested by a legitimate source. In order to develop tools that will be effective in combating these schemes, we first must know how and why people fall for them. This study reports preliminary analysis of interviews with 20 non-expert computer users to reveal their strategies and understand their decisions when encountering possibly suspicious emails. One of the reasons that people may be vulnerable to phishing schemes is that awareness of the risks is not linked to perceived vulnerability or to useful strategies in identifying phishing emails. Rather, our data suggest that people can manage the risks that they are most familiar with, but don't appear to extrapolate to be wary of unfamiliar risks. We explore several strategies that people use, with varying degrees of success, in evaluating emails and in making sense of warnings offered by browsers attempting to help users navigate the web.", "authors": ["Julie S. Downs", "Mandy B. Holbrook", "Lorrie Faith Cranor"], "n_citation": 279, "references": ["042dd086-682e-4935-89e7-beb140146da5", "4158c9f6-6a1f-4cb9-a8c9-ba0692a8a8ce", "5b50cca9-85e6-4ee8-b733-d8fe0ba8dcba", "7931f530-7f0c-454d-a30b-5f3fcd870c7e", "7a97a670-11d5-408c-bf98-bc8f88b44379", "7ac5a842-ffc2-45c8-8515-3bb7fde8e5cc", "e37c1230-2220-43d7-a166-6d5699cc57a1", "e90ba45e-058a-49b1-b74d-4ba772d8481b"], "title": "Decision strategies and susceptibility to phishing", "venue": "symposium on usable privacy and security", "year": 2006, "id": "808ed828-2799-4103-bf46-f4871ec4c768"}
{"authors": ["John L. Pfaltz", "Azriel Rosenfeld"], "n_citation": 283, "references": ["0f8d373b-1312-44fd-97c4-a9926ebb29cc", "d9a4d4e3-7c91-4135-aa05-159fc7bc9a29"], "title": "Web grammars", "venue": "international joint conference on artificial intelligence", "year": 1969, "id": "90916498-f5bd-4ce3-b612-b1804a9e01ef"}
{"abstract": "The increasing complexity of computer-based technical systems require new ways to control them. The initiatives  Organic Computing and  Autonomic Computing address exactly this issue. They demand future computer systems to adapt dynamically and autonomously to their environment. In this paper we propose a new approach based on automated planning to realise self-organising capabilities for complex distributed computing systems. The user/administrator only defines objectives describing the conditions which should hold in the system, whereas the system itself is responsible for meeting them using a planning engine. As many planning algorithms are known to be sound and complete, formal guarantees can be given. Thus we aim at building trusted self-organising distributed computer system which are suitable to control real technical systems. Our approach is demonstrated and evaluated on the basis of a simulated production cell with robots and carts. We propose and evaluate two optimisations.", "authors": ["Benjamin Satzger", "Andreas Pietzowski", "Wolfgang Trumler", "Theo Ungerer"], "n_citation": 50, "references": ["060ff5cc-9cfc-45c4-a1af-a3773107fbe8", "0f336213-459f-4293-85c5-4c6c1acdb084", "19e5de6d-ba1f-4833-80f3-6bda24f3a43a", "31e036db-1c09-48a1-8bf9-7bda3392586d", "352838dd-9583-402f-be39-52df4810a25f", "5f0782f1-e19d-46c3-80ad-a904ed4c41a0", "6fd89d5f-66b9-4bad-8bc9-84bf5a0ed5ec", "a68e48e2-ff78-41d8-95b1-d153c88dc4f7", "b35f49cd-7503-4add-af99-79850702e600", "cd6d3bbe-94d0-46cb-bc46-43fbfc442f84", "dc4f0715-5d9a-4449-916c-db04dbf0625d", "e5d0eb15-1678-4ea0-8fb3-51d647926e86"], "title": "Using Automated Planning for Trusted Self-organising Organic Computing Systems", "venue": "autonomic and trusted computing", "year": 2008, "id": "9f6f5699-70fd-4c9d-8a16-fe2dc33cec8a"}
{"abstract": "The scheduling of tasks and the allocation of resource in medium to large-scale development projects is an extremely hard problem and is one of the principal challenges of project management due to its sheer complexity. As projects evolve any solutions, either optimal or near optimal, must be continuously scrutinized in order to adjust to changing conditions. Brute force exhaustive or branch-and-bound search methods cannot cope with the complexity inherent in finding satisfactory solutions to assist project managers. Most existing project management (PM) techniques, commercial PM tools, and research prototypes fall short in their computational capabilities and only provide passive project tracking and reporting aids. Project managers must make all major decisions based on their individual insights and experience, must build the project database to record such decisions and represent them as project nets, then use the tools to track progress, perform simple consistency checks, analyze the project net for critical paths, etc., and produce reports in various formats such as Gantt or Pert charts.#R##N##R##N#Our research has developed a new technique based on genetic algorithms (GA) that automatically determines, using a programmable goal function, a near-optimal allocation of resources and resulting schedule that satisfies a given task structure and resource pool. We assumed that the estimated effort for each task is known a priori and can be obtained from any known estimation method such as COCOMO. Based on the results of these algorithms, the software manager will be able to assign tasks to staff in an optimal manner and predict the corresponding future status of the project, including an extensive analysis on the time-and-cost variations in the solution space. Our experiments utilized Wall's GALib as the search engine. The algorithms operated on a richer, refined version of project management networks derived from Chao's seminal work on GA-based Software Project Management Net (SPMnet). Generalizing the results of Chao's solution, the new GA algorithms can operate on much more complex scheduling networks involving multiple projects. They also can deal with more realistic programmatic and organizational assumptions. The results of the GA algorithm were evaluated using exhaustive search for five test cases. In these tests our GA showed strong scalability and simplicity. Its orthogonal genetic form and modularized heuristic functions are well suited for complex conditional optimization problems, of which project management is a typical example.", "authors": ["Carl K. Chang", "Mark J. Christensen", "Tao Zhang"], "n_citation": 133, "references": ["6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "76b3b4a0-0c2a-46fa-9e04-f0e1307db2af", "f01bf5e8-2f44-4536-997f-9d88e1b0876f"], "title": "Genetic Algorithms for Project Management", "venue": "Annals of Software Engineering", "year": 2001, "id": "541d5f53-f0de-4e6b-a36d-d753e26c71dc"}
{"abstract": "Multivalued logics have a long tradition in the philosophy and logic literature that originates from the work by \u0141ukaszewicz in the 1920s. More recently, many AI researchers have been interested in this topic for both semantic and computational reasons. Multivalued logics have indeed been frequently used both for their semantic properties and as tools for designing tractable reasoning systems. We focus here on the computational aspects of multivalued logics. The main result of this paper is a detailed picture of the impact that the semantic definition, the synthactic form and the assumptions on the relative sizes of the inputs have on the complexity of entailment checking. In particular we show new polynomial cases and generalize polynomial cases already known in the literature for various popular multivalued logics. Such polynomial cases are obtained by means of two simple algorithms, sharing a common method.", "authors": ["Marco Cadoli", "Marco Schaerf"], "n_citation": 57, "references": ["08a5f7a3-8d22-4454-ae2c-6c58530a64ad", "09c19ddd-b0a4-477d-bc0b-025882bca35a", "0e646938-e772-45da-9cff-68004c4763ff", "20febe51-4c49-42ec-aa2e-6d43437637ca", "2ab69e40-4585-403e-9aaa-72c122eb3372", "35891d8b-5769-428b-8d18-7e9f71a17c4d", "426acbcb-7c46-42f3-bf95-4dd441c622cc", "4d996c8b-b144-410a-a8c5-97e6ec25b289", "56bc9229-1471-4cbb-bf4c-e54e2b368910", "5b751be4-f299-43bb-aeaa-62b5c4cbc8a5", "5dff42ad-e16b-4b6a-bce3-fe808d109177", "686c7c7e-6654-4d1f-ae1a-537865f4b649", "6a0e7811-6d86-4f58-802e-d866b66193d0", "8d09527f-b5ad-4902-ba34-5583f6759d3b", "b14e6a89-9b85-4869-a087-9d70acd19c96", "c3051e0f-302b-4137-a757-9a670b5a2073", "f7c6a142-4bc4-43d8-8991-b9ad3677ecc8", "fc5e77b6-d149-4c56-b11f-5aa8bbe65a94"], "title": "On the complexity of entailment in propositional multivalued logics", "venue": "Annals of Mathematics and Artificial Intelligence", "year": 1996, "id": "6372e99b-6b50-44af-8675-c2113dec09f8"}
{"abstract": "The computer systems security arms race between attackers and defenders has largely taken place in the domain of software systems, but as hardware complexity and design processes have evolved, novel and potent hardware-based security threats are now possible. This paper presents a hybrid hardware/software approach to defending against malicious hardware. We propose BlueChip, a defensive strategy that has both a design-time component and a runtime component. During the design verification phase, BlueChip invokes a new technique, unused circuit identification (UCI), to identify suspicious circuitry\u2014those circuits not used or otherwise activated by any of the design verification tests. BlueChip removes the suspicious circuitry and replaces it with exception generation hardware. The exception handler software is responsible for providing forward progress by emulating the effect of the exception generating instruction in software, effectively providing a detour around suspicious hardware. In our experiments, BlueChip is able to prevent all hardware attacks we evaluate while incurring a small runtime overhead.", "authors": ["Matthew Hicks", "Murph Finnicum", "Samuel T. King", "Milo M. K. Martin", "Jonathan M. Smith"], "n_citation": 146, "references": ["0a0b2cba-3605-4a9b-8179-b3132aa7976a", "1194bfcd-564a-436c-942f-f3ce1ab14724", "16d50cc3-ea4b-4b53-baa6-a0801772ede0", "47172258-af45-4cb6-b6fb-869ebb48ec90", "5a8181f1-5c80-4150-abbb-44996c3354bd", "5f5fca73-1987-4b42-8995-349c0ae524e7", "61bcb3b2-2855-416c-bd95-41a0b80fc3e3", "71c47dd0-a7ff-4b97-a640-1186dd9ac968", "758cf7ad-c8bc-4e8c-b60f-60dd444ab5e9", "797c2912-8bc8-45a6-a926-d2087ffd7611", "7ac26f1d-9cfb-48af-b5dc-0a7cbb588de2", "7c816204-72a6-43ca-a55e-5d1bfc4c4890", "87d961bb-422e-4aae-b5b1-f6841a3725a9", "a8080fa3-8df0-4d8d-aa0b-8dd9c268904a", "ba625ec8-770e-4c87-b7ef-0e1c8a5d4c79"], "title": "Overcoming an Untrusted Computing Base: Detecting and Removing Malicious Hardware Automatically", "venue": "ieee symposium on security and privacy", "year": 2010, "id": "59d55c4a-4251-43cc-a677-95ffdd553743"}
{"abstract": "We review the concepts of hypertree decomposition and hypertree width from a graph theoretical perspective and report on a number of recent results related to these concepts. We also show \u2013 as a new result \u2013 that computing hypertree decompositions is fixed-parameter intractable.", "authors": ["Georg Gottlob", "Martin Grohe", "Nysret Musliu", "Marko Samer", "Francesco Scarcello"], "n_citation": 71, "references": ["01c215a9-9ec5-44a4-803d-6c4b695ad777", "1cb000ce-696d-4284-a105-e44d17220f3c", "1f12651b-4f9b-43b2-964f-9497f852633f", "48f2700a-16d5-403e-b60b-b6f480b0bd50", "574d13a2-deeb-485e-8693-ecebcd21e5ca", "5dd6d489-ec60-4e6b-859e-a572b3ab70c1", "75523088-6e3c-4b16-aa92-4bede52d5c28", "7a94f7d3-ae09-4845-b1aa-2ee8bd1dd063", "89f378b3-916e-4ab4-be5f-105d971484c5", "8b8b4761-f641-44ff-8b6c-57cb637cc78a", "9fe151f0-42d0-47f1-bd06-74bc2aa782ca", "a3894c1b-f7b4-4074-99db-e983dc0526b5", "ad885470-aef7-4151-afb2-def8e446aa45", "be657e8b-f27a-4917-a31e-cafe79f4f286", "c3032835-07ed-4bdd-bda3-83482371713a", "de03f8d2-f24d-491d-8835-fee34a4312b7", "e2295dd4-cac6-472b-bb2f-0a0835f5ecc3", "e2ee282f-3edf-48c6-bdc3-5a56fa92e409", "ef90df7a-bd95-4518-b2ff-2ff8ab885bb0"], "title": "Hypertree decompositions: structure, algorithms, and applications", "venue": "workshop on graph theoretic concepts in computer science", "year": 2005, "id": "a0cda4a1-138c-45e4-86c0-26a5972b951c"}
{"abstract": "We give a deterministic polynomial-time method for finding a set cover in a set system (X, ?) of dual VC-dimensiond such that the size of our cover is at most a factor ofO(d log(dc)) from the optimal size,c. For constant VC-dimensional set systems, which are common in computational geometry, our method gives anO(logc) approximation factor. This improves the previous ?(log?X?) bound of the greedy method and challenges recent complexity-theoretic lower bounds for set covers (which do not make any assumptions about the VC-dimension). We give several applications of our method to computational geometry, and we show that in some cases, such as those arising in three-dimensional polytope approximation and two-dimensional disk covering, we can quickly findO(c)-sized covers.", "authors": ["Herv\u00e9 Br\u00f6nnimann", "Michael T. Goodrich"], "n_citation": 191, "references": ["0259fbe3-b190-46bc-a6e7-890f4384c922", "0f46310b-455f-4f97-9bb4-182962c0d619", "11ed3b24-e20f-42e9-a102-99fed764a567", "172f9f68-8417-43bb-8fe5-b377d569f6b6", "1bb7e651-6703-413c-b8d1-10f8e8867205", "251815a3-8350-4b1c-993d-20bcd8ce4788", "4ed6d76e-d0b7-41fd-b647-70ef9a23edc2", "510eec1d-f82c-4b19-b116-b8fd4c66531a", "513ef136-d6cf-4d7b-bd8c-68328c18aa91", "53b15ca7-6765-44eb-8661-21a2b99a2447", "5b8e9cbc-4c60-4f1c-b37e-b59e58b472bc", "6fe13464-786c-4668-8c16-5b0461042e78", "7bd3392d-10c3-46c6-869d-88cf2394bb38", "a4ce104f-f2e1-49c6-8a35-315436b370f5", "a6da9172-035e-480d-b9c5-2b56e4c5bc0f", "abe8077f-63f8-49f7-a27b-0ee07bd7561e", "b9672e51-ce47-452c-8704-06330289c174", "bcfeec21-3a64-4fb5-9a86-d917777cec50", "c2e7260c-9b47-434d-ab40-f1fa76eaec88", "c61bad33-aa9f-4a6e-ab8b-8e7eaa835492", "c9893d06-344b-4b96-9954-753535b00fad", "cd1f4a53-5ab5-408b-bb60-55b67e81d8d7", "d1ab1171-4a06-4b1b-ad3a-983f484fcbbe", "d708230a-d2a9-4380-8f13-ad88b54582b2", "dd8721ac-7a6f-4faa-9bd7-9b96185401cc", "f1a850b6-f5e4-4cc0-ae94-3d325a020766"], "title": "Almost optimal set covers in finite VC-dimension", "venue": "Discrete and Computational Geometry", "year": 1995, "id": "72b08f5c-a93e-41c3-b446-da5f64363c74"}
{"abstract": "We study the impact of multiple access strategies on the diversity-multiplexing tradeoff (DMT) performance in wireless multi-user relay networks. The networks contain multiple independent sources, multiple half-duplex decode-and-forward (DF) relays, and one common destination. Instead of separately retransmitting each source message, the relays employ a class of spectrally efficient finite field network codes to assist the sources. It is shown that fully orthogonal or fully non-orthogonal transmission among sources/relays does not necessarily provide optimized DMT performance. We propose a novel transmission protocol that divides the sources and relays into individual clusters. The nodes within one cluster transmit non-orthogonally while the transmissions of different clusters span orthogonal channels. We provide the method to calculate the achievable DMT for each clustering strategy. The network DMT performance can thus be optimized by properly clustering the multiple sources and relays.", "authors": ["Chao Wang", "Ming Xiao", "Mikael Skoglund"], "n_citation": 21, "references": ["0ed1d3b0-2ec5-4ecb-ac85-a1c17ce1aa99", "24173fe9-8fd0-410a-8695-414f594912a0", "29285da9-49f2-492c-b6c5-7fed5f477950", "5491e3d9-ef43-4655-b377-f3b33e1e2266", "6d25cd6f-4a67-41ed-9b6d-467c739f531e", "720f59d2-acc3-4d5a-91c2-258d137d9647", "776a7d9a-9cc0-472e-91ca-9274e44c60b8", "7ae0e791-2e2b-4504-a2fe-caa9b0589c44", "878eef89-8bd3-4925-81cb-09a4f0151328", "8a116312-ddfe-485f-bc95-861075dd2b5c", "90a424e0-d969-4c63-8ab0-fb6922d335d8", "9f68b680-a689-41c6-83cf-e0065ece0462", "e36154cf-678a-463e-9dbd-27aca4d7420f"], "title": "Diversity-Multiplexing Tradeoff Analysis of Coded Multi-User Relay Networks", "venue": "IEEE Transactions on Communications", "year": 2011, "id": "62bc051d-f566-41cb-9f2f-8bef4a5b718a"}
{"abstract": "Consideration is given to the effects of representations and operators in evolutionary algorithms. In particular, theorems are presented which establish, under some general assumptions, that no choice of cardinality of a representation offers any intrinsic advantage over another. Functionally equivalent algorithms can be constructed regardless of the chosen representation. Further, a similar effective equivalence of variation operators is shown such that no intrinsic advantage accrues to any particular one-parent operator or any particular two-parent operator.", "authors": ["David B. Fogel", "Adam Ghozeil"], "n_citation": 73, "references": ["44bcaddf-b380-45dc-b5af-44d0912930c6", "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "bac5da35-9009-41a3-b758-21aec812a9ee", "f1f569c1-d327-4225-b657-9cef07e9abb3"], "title": "A note on representations and variation operators", "venue": "IEEE Transactions on Evolutionary Computation", "year": 1997, "id": "1676f5c4-5aa2-4e1a-84a5-6183d360518b"}
{"abstract": "A new interprocedural data flow analysis algorithm is presented and analyzed. The algorithm associates with each procedure in a program information about which variables may be modified, which may be used, and which are possibly preserved by a call on the procedure, and all of it subcalls. The algorithm is sufficiently powerful to be used on recursive programs and to deal with the sharing of variables which arises through reference parameters. The algorithm is unique in that it can compute all of this information in a single pass, not requiring a prepass to compute calling relationships or sharing patterns. A lower bound for the computational complexity of gathering interprocedural data flow information is derived and the algorithm is shown to be asymptotically optimal. The algorithm has been implemented and it is practical for use even on quite large programs.", "authors": ["Jeffrey M. Barth"], "n_citation": 52, "references": ["0d54a7ee-19f5-47a1-9ecc-a9fd80e17966", "1bfa8811-7ed4-4bb5-a6fd-41a35b4f9021", "1d754838-cb9c-4788-be5f-3ad94624d40e", "3595f070-1e9f-411f-b792-5e76102638fb", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "f90e1d45-eae7-464d-99e5-cd82bf77e368"], "title": "An interprocedural data flow analysis algorithm", "venue": "symposium on principles of programming languages", "year": 1977, "id": "90f27e06-2b44-44e5-a3af-225845199117"}
{"abstract": "We witness a rapid increase in the number of structured information sources that are available online, especially on the WWW. These sources include commercial databases on product information, stock market information, real estate, automobiles, and entertainment. We would like to use the data stored in these databases to answer complex queries that go beyond keyword searches. We face the following challenges: (1) Several information sources store interrelated data, and any query-answering system must understand the relationships between their contents. (2) Many sources are not full-featured database systems and can answer only a small set of queries over their data (for example, forms on the WWW restrict the set of queries one can (3) Since the number of sources is very large, effective techniques are needed to prune the set of information sources accessed to answer a query. (4) The details of interacting with each source vary greatly. We describe the Information Manifold, an implemented system that provides uniform access to a heterogeneous collection of more than 100 information sources, many of them on the WWW. IM tackles the above problems by providing a mechanism to describe declaratively the contents and query capabilities of available information sources. There is a clean separation between the declarative source description and the actual details of interacting with an information source. We describe algorithms that use the source descriptions to prune effciently the set of information sources for a given query and practical algorithms to generate executable query plans. The query plans we generate can inolve querying several information sources and combining their answers. We also present experimental studies that indicate that the architecture and algorithms used in the Information Manifold scale up well to several hundred information sources", "authors": ["Alon Y. Levy", "Anand Rajaraman", "Joann J. Ordille"], "n_citation": 1641, "references": ["0adbcde9-46cd-4696-9274-6b9bf7072161", "0add8475-ba72-4563-9381-1bf3e0a6f05c", "10559441-7632-44a7-a873-156c9c7f0c0f", "1906952e-15ab-450a-8ad4-1b9702b14ac4", "30046f08-8350-4278-bb9d-d551dc722f1b", "4af11d5b-22ab-489a-95e7-d12d4eb797f5", "58db62cc-07af-406c-b787-bafe6fe41a1e", "5f2cefb9-5fae-4f73-8196-fa0b43b1a86f", "7ac7226c-2402-4907-9056-54511dc3eef9", "9b815fe5-41d4-4af7-8a88-219e3f91f609", "b1a3b488-d73f-493c-a324-027b5b2a2c9c", "d24c2605-869a-48a9-b325-f88d8c479784", "d7fe4e70-e33e-41dd-b00a-54ca59afaa31", "db229d9e-2e77-4110-b439-224b2551c418", "e2915bb6-41fc-4186-a0bb-fa7aeecb89d0"], "title": "Querying Heterogeneous Information Sources Using Source Descriptions", "venue": "very large data bases", "year": 1996, "id": "d5b735f0-712a-4000-9176-54d487fc7bf9"}
{"abstract": "We identify a refinement algebra for reasoning about probabilistic program transformations in a total-correctness setting. The algebra is equipped with operators that determine whether a program is enabled or terminates respectively. As well as developing the basic theory of the algebra we demonstrate how it may be used to explain key differences and similarities between standard (i.e. non-probabilistic) and probabilistic programs and verify important transformation theorems for probabilistic action systems.", "authors": ["Larissa Meinicke", "Kim Solin"], "n_citation": 50, "references": ["01ef4bb1-295f-47d3-9b44-aa104f6a73cf", "1e7651d1-2980-4eb1-960d-756bd2b2bd37", "270dd8dc-e574-498b-a752-491d9efcd27c", "2987dfdf-a93d-47bb-aada-84232297d940", "2dd0239d-50d7-4349-af9b-49f6148ad951", "34177b95-e881-4222-b814-3c2d1fdac3f6", "34314101-6217-4c4c-92d1-faed411ac997", "3e463040-e697-4c3c-a555-5635b90ef134", "3fb0faac-d13d-43c1-bfc9-9dff1b07c660", "4397f724-fa30-4db1-8fde-e267ca987890", "47aae066-0d20-4ca0-ad6d-2fcd64f84db9", "565f5085-33af-4157-8375-7799280e7203", "5983fb31-5ab4-4fd3-8281-c977ce284d23", "63ab8cab-b1f4-45a3-89d1-9a296fffe1f0", "7412b59c-a214-4543-b1c1-7e073397097f", "85a7e12e-f107-4ddd-8dbd-269a7cf8d802", "99cab49f-3acb-43c8-a46a-0404353587ad", "acbe5741-0dff-4b3f-b754-c2aa78dbd266", "b7ddff1e-3261-45a0-aac4-6196e047d76e", "caa07e86-48de-4c6c-9dd2-25d6ec29e310", "cd281d94-eb1b-400c-8ca8-04311d5810d6", "d26a4b52-45fe-4eb3-b06a-5040e79c3157", "e1752f62-251e-4cf9-b4f2-b1c754cdf5c7"], "title": "Refinement algebra for probabilistic programs", "venue": "Formal Aspects of Computing", "year": 2010, "id": "eaab1911-6f35-4846-b6c1-5a8d805d2555"}
{"abstract": "Background: The abundance of new genomic data provides the opportunity to map the location of gene duplication and loss events on a species phylogeny. The first methods for mapping gene duplications and losses were based on a parsimony criterion, finding the mapping that minimizes the number of duplication and loss events. Probabilistic modeling of gene duplication and loss is relatively new and has largely focused on birth-death processes. Results: We introduce a new maximum likelihood model that estimates the speciation and gene duplication and loss events in a gene tree within a species tree with branch lengths. We also provide an, in practice, efficient algorithm that computes optimal evolutionary scenarios for this model. We implemented the algorithm in the program DrML and verified its performance with empirical and simulated data. Conclusions: In test data sets, DrML finds optimal gene duplication and loss scenarios within minutes, even when the gene trees contain sequences from several hundred species. In many cases, these optimal scenarios differ from the lca-mapping that results from a parsimony gene tree reconciliation. Thus, DrML provides a new, practical statistical framework on which to study gene duplication.", "authors": ["Pawe\u0142 G\u00f3recki", "Gordon J. Burleigh", "Oliver Eulenstein"], "n_citation": 32, "references": ["8092293e-8c8c-4e2a-bc05-8978658bbe32", "8559019b-05c6-4435-bf93-8f1e017c7f6d", "8a9a5557-a600-4258-8a1f-42720106c986", "a822a963-dec6-49ef-a1c4-504e19575df0", "b1a4fda0-2f4f-4156-af93-19499101a371", "c11aebd6-2dd6-4a26-b401-d53737ff7232", "c292a7c3-417c-4824-a50b-fdbd69bcc15f", "c9a8cd87-535b-4ae8-9a19-9d23967c1d7c", "cec4fcc8-494f-40cd-95bc-acf69b2c13d0", "f0e22dc5-a48a-4ccd-a5e3-8a0bebbeb16d", "f8e3f9cd-90f9-401f-80f9-23aa7979ae35", "fad26003-6709-4156-9ad6-82444a6ac2eb"], "title": "Maximum likelihood models and algorithms for gene tree evolution with duplications and losses", "venue": "BMC Bioinformatics", "year": 2011, "id": "d294901a-1bcd-4ee6-bf1f-774664c91586"}
{"abstract": "This paper addresses the solution of bound-constrained optimization problems using algorithms that require only the availability of objective function values but no derivative information. We refer to these algorithms as derivative-free algorithms. Fueled by a growing number of applications in science and engineering, the development of derivative-free optimization algorithms has long been studied, and it has found renewed interest in recent time. Along with many derivative-free algorithms, many software implementations have also appeared. The paper presents a review of derivative-free algorithms, followed by a systematic comparison of 22 related implementations using a test set of 502 problems. The test bed includes convex and nonconvex problems, smooth as well as nonsmooth problems. The algorithms were tested under the same conditions and ranked under several criteria, including their ability to find near-global solutions for nonconvex problems, improve a given starting point, and refine a near-optimal solution. A total of 112,448 problem instances were solved. We find that the ability of all these solvers to obtain good solutions diminishes with increasing problem size. For the problems used in this study, TOMLAB/MULTIMIN, TOMLAB/GLCCLUSTER, MCS and TOMLAB/LGO are better, on average, than other derivative-free solvers in terms of solution quality within 2,500 function evaluations. These global solvers outperform local solvers even for convex problems. Finally, TOMLAB/OQNLP, NEWUOA, and TOMLAB/MULTIMIN show superior performance in terms of refining a near-optimal solution. Copyright Springer Science+Business Media, LLC. 2013", "authors": ["Luis Miguel Rios", "Nikolaos V. Sahinidis"], "n_citation": 486, "references": ["069707be-3681-413d-8860-51908ac56ddd", "1d92f3bb-1810-4f1c-8601-bb95b1a11119", "1ec5b66d-7bef-41e6-ab1d-e49a772908a0", "240e598d-d6f7-4e02-b298-46f6cb293ebd", "2a578f04-21f6-445a-b3ec-4a8c05c4cdd0", "317a55e3-1547-48e1-afea-0baa04a1a33c", "3203de02-84d6-42e4-9008-3079089c1027", "3c2dd6af-0684-4fe6-b3a3-e06a245fbbe2", "3c3a71de-6ad7-4e90-aa24-336e27e1a604", "3eae66cc-2c07-4eb2-b0dd-b3cc69fe153a", "42a10031-244f-45bd-8b57-e8ecc52963df", "4a4f6ac2-4442-4a36-84b1-e4b0ed8d26ec", "4f4ce365-ec48-4a05-8f1a-74a1f20f6e9a", "5b61435b-2a0f-4264-a508-a4713168645c", "6326237b-5ad4-41c1-a386-a3fa13c76306", "670f3f27-cd69-4559-9f51-65785c41e66a", "6d04515a-1292-4358-91e6-6be0a96a1965", "6fbb6b66-33e3-460f-a755-4fa9cd06e025", "7243be4b-41fb-44df-bd13-fd8e355db850", "74df99e4-519b-4293-bab0-85b153422b83", "7578278d-fd45-4b06-94d7-2be085fad521", "7599acb1-c976-45cd-aee2-81f69f7ea11a", "77198a1f-9406-494f-bbc0-f33e3596aaab", "772ef2c4-51f0-4cc6-ba05-6c85ebbc913a", "78594229-c18d-4823-9a83-e0110130aecc", "7a88e90e-2bdc-4e82-889f-4165b95b9342", "7b083389-a58b-409d-b1fa-2901eaaffed5", "82960fa9-0088-4d7a-b8cb-16e8c5b5312e", "8437f18b-3e18-45cd-bd5b-85b9020153f1", "8a230b73-886b-4993-a43e-849cb7955a27", "8f750414-caa9-47d8-862c-0d400660cc11", "ab7bfd6d-98f7-445b-8b40-0e2526b66fc3", "aea6b031-ed5b-458f-9596-98833d8c87de", "b11b55ad-8292-45ff-8d31-08910fb84780", "b6d691a6-0632-4991-847f-6f32e2eb7108", "b9b789ba-c6e7-468c-a48b-a9aae7c12151", "ba8f5f49-8ea4-4a17-92af-26d49862bbc9", "c3de9848-605d-4e2b-a457-159636679eb0", "c4a336e9-86cb-42bf-a625-e9ef8cc63ce6", "d23d9f69-416c-4a0c-bcf5-2f9246dc4810", "e01408a6-c082-446f-81f0-57424a01f3b0", "e23da16a-b334-4e63-a043-97c11c6ece6d", "e3ff9bc8-3876-4377-85d2-f8740e8288ae", "eb1ae527-ba69-4316-8899-f1a20b15884b", "f003342c-da54-4b55-8c20-6d17e60ab422", "f92f7535-9e58-4d0c-be0c-05e2baea1e27"], "title": "Derivative-free optimization: a review of algorithms and comparison of software implementations", "venue": "Journal of Global Optimization", "year": 2013, "id": "da258caa-2514-4dfe-9c33-d47788b6a52e"}
{"abstract": "In this paper, we propose a two-layer hierarchical cache architecture for enhancing TCP performance over heterogeneous networks with both wired and wireless links. A new network-layer protocol, called New Snoop, is designed. The main idea is to cache the unacknowledged packets at both the mobile switch center (MSG) and base station (BS), thus forming a two-layer cache hierarchy. If a packet is lost due to transmission errors in the wireless link, the BS takes the responsibility to recover the loss. When a handoff occurs during a TCP connection session, the packets cached in MSC can help to minimize the latency of retransmissions due to temporal disconnection. Simulation results show that using New Snoop is significantly more robust in dealing with unreliable wireless inks and handoffs as compared with the Snoop scheme (Balakrishnan et al. 1995) as well as other existing TCP enhancements.", "authors": ["Jian-Hao Hu", "Kwan L. Yeung", "Siew Chee Kheong", "Gang Feng"], "n_citation": 50, "references": ["1442c01e-d9ff-4c6d-88cc-efb2d5c5c1d4", "553db688-bb98-4ed0-a2a4-42f1e5678559", "595a60fe-9cba-4502-a848-7c2b0899769a", "7071e570-ccea-4a33-a27d-a9c33d1293ee", "b3c85a26-e239-4793-a995-bdf39d03fab3"], "title": "Hierarchical cache design for enhancing TCP over heterogeneous networks with wired and wireless links", "venue": "global communications conference", "year": 2000, "id": "ebb047fe-cf06-4cca-a8a7-c849e93bf288"}
{"abstract": "The proliferation of mobile devices and the pervasiveness of wireless technology have provided a major impetus to replicate the network-based service discovery technologies in wireless and mobile networks. However, existing service discovery protocols and delivery mechanisms fall short of accommodating the complexities of the ad-hoc environment. They also place emphasis on device capabilities as services rather than device independent software services, making them unsuitable for m-commerce oriented scenarios. Konark is a service discovery and delivery protocol designed specifically for ad-hoc, peer-to-peer networks, and targeted towards device independent services in particular. It has two major aspects - service discovery and service delivery. For discovery, Konark uses a completely distributed, peer-to-peer mechanism that provides each device the ability to advertise and discover services in the network. The approach towards service description is XML based. It includes a description template that allows services to be described in a human and software understandable forms. A micro-HTTP server present on each device handles service delivery, which is based on SOAP. Konark provides a framework for connecting isolated services offered by proximal pervasive devices over a wireless medium.", "authors": ["Sumi Helal", "Nitin Desai", "Varun Verma", "Choonhwa Lee"], "n_citation": 487, "references": ["16ab020e-2cf1-4fac-9124-7775dad0363b", "1cee42a2-8468-4362-8c8b-680b6228db7e", "d5ebd5d5-857c-4b7f-b0c6-2edae1ba9824"], "title": "Konark - a service discovery and delivery protocol for ad-hoc networks", "venue": "wireless communications and networking conference", "year": 2003, "id": "3f8ee2c4-791d-4b0c-b24d-6df9e236da2f"}
{"abstract": "It is well known, of course, that the assessment of this month's economic activity will improve with the passage of time. The same situation exists for many of the inputs to managerial and strategic decision processes. Information regarding some situation or activity at a fixed point in time becomes better with the passage of time. However, as a consequence of the dynamic nature of many environments, the information also becomes less relevant over time. This balance between using current but inaccurate information or accurate but outdated information we call the accuracy-timeliness tradeoff. Through analysis of a generic family of environments, procedures are suggested for reducing the negative consequences of this tradeoff. In many of these situations, rather general knowledge concerning relative weights and shapes of functions is sufficient to determine optimizing strategies.", "authors": ["Donald P. Ballou", "Harold L. Pazer"], "n_citation": 178, "references": ["0453024a-4d14-449d-8520-421af8e754e9", "89cc4588-b0b3-4f28-9623-b4d664cbf057", "b541380f-8e36-4fd8-91b3-04cf1f8d2736", "d43639b6-526c-4b49-a536-35a1126fedc7", "f155c3a0-9dd0-49d2-bafe-d4befc94328a", "f363054e-4ac3-4f70-9d36-bf330452314a", "f60d17df-37f8-4fc1-9855-4d33d7806a47"], "title": "Designing Information Systems to Optimize the Accuracy-Timeliness Tradeoff", "venue": "Information Systems Research", "year": 1995, "id": "373ad8ce-1a7b-4a41-8e96-84806b895f7e"}
{"authors": ["Alison Lee", "Catalina Danis", "Todd Miller", "Young-Hee Jung"], "n_citation": 20, "references": ["4dbd9490-0e50-414e-b76f-21761f04bdae", "64f37b37-1c2f-4b69-93d3-cce7255ad53b", "8002c237-52b7-4ce0-91e1-ba3c4cd414f3", "82d26ac1-2ae2-40a4-ac8e-00f5296a6c6d", "86667d77-a67c-4843-9ee1-5c9070cf07cf", "91f508da-a411-483d-a33b-07e2a0ebb968", "9b356229-f03a-467a-b9ce-6f586e33d61d", "c4ba7609-a0ff-4873-b576-62c982a99eeb", "d2f2d642-87cc-4f97-9d96-3b34a09274ec", "f3583b17-55cc-4255-b72b-7a54543fefe9"], "title": "Fostering Social Interaction in Online Spaces.", "venue": "international conference on human-computer interaction", "year": 2001, "id": "35cce900-53ae-4aa5-b89f-59bdd0a9bc5e"}
{"abstract": "In this work, we propose a model of a content-based image retrieval system by using the new idea of combining a color segmentation with relationship trees and a corresponding tree-matching method. We retain the hierarchical relationship of the regions in an image during segmentation. Using the information of the relationships and features of the regions, we can represent the desired objects in images more accurately. In retrieval, we compare not only region features but also region relationships.", "authors": ["Chiou-Shann Fuh", "Shun-Wen Cho", "Kai Essig"], "n_citation": 96, "references": ["02b3d64b-ca38-42d1-87d7-5dba60eaf7a9", "214cf2b0-4304-4821-8634-84d2d0815205", "2f4464a5-a7b6-4689-8685-b0e3302a25a9", "46e18990-7faa-47f6-8d08-be5f71c25c6a", "49bdb7c5-8896-4a89-972b-2dc55021513d", "8c08c9ef-1539-4681-aff7-2ad292817d0b", "a797b9a0-f494-43a6-8872-8642982b42c8", "abb162c8-4fae-43e7-afd7-316bbf4f1a1b", "db24cbf4-bb4a-40cf-8acb-dbb142640edd", "dda837ee-640b-48b1-bb19-a00c5894f003"], "title": "Hierarchical color image region segmentation for content-based image retrieval system", "venue": "IEEE Transactions on Image Processing", "year": 2000, "id": "b5ccde33-cb4d-406b-85d6-1795f5461d02"}
{"abstract": "The formalism of P systems is known for many years, yet just recently new derivation modes and halting conditions have been proposed. For developing comparable results, a formal description of their functioning, in particular, of the derivation step is necessary. We introduce a formal general framework for static membrane systems that aims to capture most of the essential features of (tissue) P systems and to define their functioning in a formal way.", "authors": ["Rudolf Freund", "Sergey Verlan"], "n_citation": 63, "references": ["1a55a103-b846-425a-ab36-a7315ac226ac", "1e368c7c-c541-400a-b96a-ca36276ce1b2", "7448b34b-d458-499e-90ae-803f446a4ff3", "7e92b2f1-d889-4e6e-86e5-28ba3571f72f", "994f40f2-f677-47c1-a04c-3c066b1825e7", "9bcfbf74-8e57-4b4e-8c46-ba9cada2df45", "9d17985d-9cd0-4e83-9332-ffaf867e2596", "cab6bc53-d487-4aa3-8962-7cf1012525fb", "d223e5b2-1431-4d56-9ed0-9cb15044f307", "d2a25801-40cd-4f99-8d96-8da6897609e6", "e4710fa7-2d83-40a3-a849-a5bc4f07991c", "ed02a5aa-3cd0-4394-90ac-3ecdf2519264", "ee9d9adc-3d42-4693-a21b-29cb3e38ff87"], "title": "A formal framework for static (tissue) P systems", "venue": "", "year": 2007, "id": "bc8f0d91-a7be-4f74-abea-7cb9a8c4553f"}
{"abstract": "We summarize the currently best known theoretical results for the single-source shortest paths problem for directed graphs with non-negative edge weights. We also point out that a recent result due to Cherkassky, Goldberg and Silverstein (1996) leads to even better time bounds for this problem than claimed by the authors.", "authors": ["Rajeev Raman"], "n_citation": 89, "references": ["2958ba57-fb9b-471a-ab25-052dcf5513da", "d829c352-820e-4b21-8eb0-c9a3186be294"], "title": "Recent results on the single-source shortest paths problem", "venue": "Sigact News", "year": 1997, "id": "e8e69b44-4da6-4399-bc0a-bdcb86b48716"}
{"abstract": "There is a trend to develop blind or semi-blind source extraction algorithms based on second-order statistics, due to its low computation load and fast processing speed. An important and primary work is done by Barros and Cichocki, who propose an extraction algorithm based on a time delay. The algorithm is simple and fast, but its performance is not satisfying. The paper extends their work and proposes a robust algorithm based on eigenvalue decomposition of several delayed covariance matrices. It is faster and has better performance, which is confirmed by theoretical analysis and computer simulations.", "authors": ["Zhilin Zhang", "Zhang Yi"], "n_citation": 83, "references": ["0ea82db2-59b1-479f-b92a-2cf9f69f8d9d", "1250f9de-411b-489d-a840-0a39288b13c0", "444f3415-558e-4ee3-9ad5-5423afaeb325", "9d054c72-dbe5-468c-a77f-e879fc8368ad", "9d4927ea-86b2-4c06-8721-d9e4034b81de", "a2dc8901-a9db-4b87-baf7-a0676f95e2c5", "b7b29844-daf1-40df-999f-c0442a07416c", "f5976a6d-6c0b-4be2-bfb3-4ea208d31dba", "fb994544-0cfd-44e0-8482-d1f02193ce76"], "title": "Letters: Robust extraction of specific signals with temporal structure", "venue": "Neurocomputing", "year": 2006, "id": "995a2413-2c9e-4b45-9360-c0a40e39e275"}
{"abstract": "In this paper a methodology for feature selection for the handwritten digit string recognition is proposed. Its novelty lies in the use of a multiobjective genetic algorithm where sensitivity analysis and neural network are employed to allow the use of a representative database to evaluate fitness and the use of a validation database to identify the subsets of selected features that provide a good generalization. Some advantages of this approach include the ability to accommodate multiple criteria such as number of features and accuracy of the classifier, as well as the capacity to deal with huge databases in order to adequately represent the pattern recognition problem. Comprehensive experiments on the NIST SD19 demonstrate the feasibility of the proposed methodology.", "authors": ["Luiz S. Oliveira", "Robert Sabourin", "Fl\u00e1vio Bortolozzi", "Ching Y. Suen"], "n_citation": 165, "references": ["1f7bbc73-33cf-4f70-9a8a-739a095650bd", "245e4043-ccdb-457a-9be1-e120c7a94753", "3c53f5b9-99d0-4436-b17c-4a96a26afbb9", "4f2a5d1a-5499-4276-9ce5-877d800c9185", "54eece2d-dd81-49e3-b3f1-249a53b3fb57", "6042f19b-fd38-4b83-b819-4d55048ba049", "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "70106559-6bd9-4e53-b3a5-64a22720d551", "7a2d1bce-9275-4b3b-9ad7-542af7571618", "7e6468e2-485c-4716-8d23-83ba572504de", "8427a55f-bb1e-486e-9436-6e13f637799b", "b84e6ba5-50d8-456e-abf1-cae757868b7d", "bd89104a-7f1d-4813-a93c-2a5e9842c3ba", "ce028c76-6040-4f87-b8e7-d6741ce9d1c4", "e05311b7-adbb-4dba-9701-884d510c503f", "e460a9e6-8177-4cc5-91c1-2f6ea10d7698", "effcdc42-c90f-4802-84c7-c465d332fb86"], "title": "A METHODOLOGY FOR FEATURE SELECTION USING MULTIOBJECTIVE GENETIC ALGORITHMS FOR HANDWRITTEN DIGIT STRING RECOGNITION", "venue": "International Journal of Pattern Recognition and Artificial Intelligence", "year": 2003, "id": "dc66de16-cd5c-4c03-9f22-f4ec4ac5c8be"}
{"abstract": "This paper proposes a new indicator of text structure, called the lexical cohesion profile (LCP), which locates segment boundaries in a text. A text segment is a coherent scene; the words in a segment are linked together via lexical cohesion relations. LCP records mutual similarity of words in a sequence of text. The similarity of words, which represents their cohesiveness, is computed using a semantic network. Comparison with the text segments marked by a number of subjects shows that LCP closely correlates with the human judgments. LCP may provide valuable information for resolving anaphora and ellipsis.", "authors": ["Hideki Kozima"], "n_citation": 294, "references": ["708f92bc-9eb0-4a03-9c1e-1e54b3261eb9", "c3e8c0e1-fb5a-427c-819b-e09e02520341", "ed3c087e-db35-47e8-afb0-a22a521bc505", "f0a5e86a-36b0-4c47-b085-0d35f15e9e8e"], "title": "TEXT SEGMENTATION BASED ON SIMILARITY BETWEEN WORDS", "venue": "meeting of the association for computational linguistics", "year": 1993, "id": "b263ca09-f1f0-4f8f-99d6-4153ef683d04"}
{"abstract": "This paper presents a technique for dis- parity selection in the context of camera vergence in binocular pursuit. For vergence control in binocular pursuit, it is a crucial problem to find a disparity which is corresponding to the target among multi- ple disparities generally observed in a scene. To solve the problem of the selection, we propose an approach based on histogramming the disparities obtained from a phase-based disparity estimation algorithm. The idea is to slice the scene using the disparity histogram so that only the target remains. The slice is chosen around a peak in the histogram, a peak which is found by keeping track of the peak as it moves in time, us- ing prediction of the targets disparity and location in the image. The tracking of the peak enables robustness against any dominant objects in the scene. The ap- proach is investigated through experiments and shown to work appropriately.", "authors": ["Atsuto Maki", "Tomas Uhlin", "Jan-Olof Eklundh"], "n_citation": 25, "references": ["5a0c0525-2641-4130-961d-9f2479e54baa", "7e399a77-057d-4875-a1de-7fe44910caa2"], "title": "Disparity Selection in Binocular Pursuit", "venue": "machine vision applications", "year": 1994, "id": "2fdb37f4-8f3d-403d-8e05-3ed90d2c7a0d"}
{"authors": ["A. John Power"], "n_citation": 43, "references": ["963aa615-77de-498a-82d3-3adb469d99b3"], "title": "An Abstract Formulation for Rewrite Systems", "venue": "", "year": 1989, "id": "a18faf35-2509-4dcd-8ed4-53be2a2b7536"}
{"abstract": "caT (for Context-Aware Trellis) was initially developed to support context-aware documents by incorporating high-level Petri-net specification, context-awareness, user modeling, and fuzzy knowledge handling features into Trellis, a Petri-net-based hypermedia system. The browsing behavior of documents specified in the caT model can reflect the reader's contextual (such as location and time) and preference information. Recently, to provide a framework for the authoring, browsing, and analysis of reasonably complex, dynamic documents, we added (or extended) several features in the caT system, providing hierarchical Petri net support, a structured authoring tool, browsing tools for multiple presentations of a particular document's specification, and a Petri net analysis tool. In this paper, we present the extended features of caT and give examples of using caT to define and present various documents, such as formal specification of software requirements and customized Web documents. Since caT is based on a formal model, the behavioral characteristics of developed caT models can be analyzed. Current debugging and analysis tools, integrated into the authoring tool, are also introduced.", "authors": ["Jin-Cheon Na", "Richard Furuta"], "n_citation": 37, "references": ["0d261b6a-c94a-4d5e-b44e-eb6ae46581fc", "31d196b5-a21d-4729-8bc8-3096522f641e", "39de0c61-aa19-4c36-adad-86eb148f7714", "434c6641-d180-4295-bc20-87ea8f71bd53", "492573b8-e4ed-4ed3-899c-bde9b2ad26f6", "61b5c310-375e-4b75-8854-2746edce7936", "77afdf4f-8cd8-43de-b22a-550109c27cd1", "8ab23f4b-0b87-42ed-9922-dbd10d9e845d", "92d152c4-b73c-430c-89f4-9067d1cafae0", "9c684741-b638-49e2-ab91-a2fb070a2c34", "a1b2f287-e8b2-4cf6-be25-5ccc0c81b8bb", "a54c53a4-2321-441b-8243-a37f76b2500d", "da65c07d-215e-4e4c-8514-676a7021c0e8", "dd8e3e98-a1db-490a-8d12-3e5f4c8006b7"], "title": "Dynamic documents: authoring, browsing, and analysis using a high-level petri net-based hypermedia system", "venue": "document engineering", "year": 2001, "id": "fed6ee4b-abef-4573-9114-57fe323d8300"}
{"abstract": "Effective requirements traceability supports practitioners in reaching higher project maturity and better product quality. Researchers argue that effective traceability barely happens by chance or through ad-hoc efforts and that traceability should be explicitly defined upfront. However, in a previous study we found that practitioners rarely follow explicit traceability strategies. We were interested in the reason for this discrepancy. Are practitioners able to reach effective traceability without an explicit definition? More specifically, how suitable is requirements traceability that is not strategically planned in supporting a project's development process. Our interview study involved practitioners from 17 companies. These practitioners were familiar with the development process, the existing traceability and the goals of the project they reported about. For each project, we first modeled a traceability strategy based on the gathered information. Second, we examined and modeled the applied software engineering processes of each project. Thereby, we focused on executed tasks, involved actors, and pursued goals. Finally, we analyzed the quality and suitability of a project's traceability strategy. We report common problems across the analyzed traceability strategies and their possible causes. The overall quality and mismatch of analyzed traceability suggests that an upfront-defined traceability strategy is indeed required. Furthermore, we show that the decision for or against traceability relations between artifacts requires a detailed understanding of the project's engineering process and goals; emphasizing the need for a goal-oriented procedure to assess existing and define new traceability strategies.", "authors": ["Patrick Rempel", "Patrick M\u00e4der", "Tobias Kuschke"], "n_citation": 8, "references": ["18fcb691-375a-4b2e-9cdb-82089d0535b2", "20da9d09-2a44-4744-b5dd-2d559d2827bd", "2eceebf6-aa8f-49f4-9c55-c2b690507c61", "58ed955b-d04c-405c-9f2c-3fd2482165e3", "973de0db-4784-4fef-a6bf-45fae7a449ac", "98aa53c5-80a2-4193-aa97-b442897daf5d", "9a878b27-e89d-496c-be1c-5d65b9c312ab", "b0581eaa-31da-4749-ae09-2e9c13fd1c4b", "d3a1f4be-187b-4780-9cf1-7fe130a0b11b", "e64c997b-646d-4bbc-b2e5-b1b070406be3", "ec4bf8a4-f695-46a6-b12d-d0e612eeaa6e", "ecbc3064-ec9f-4c2e-bde3-1f21461b729d", "fbd55ac7-b7af-455c-a366-1b16d0daa909"], "title": "An empirical study on project-specific traceability strategies", "venue": "workshop on hot topics in operating systems", "year": 2013, "id": "f11154bf-aacb-45c8-a265-8a3030b570fe"}
{"abstract": "Given a program Base and two variants, A and B, each created by modifying separate copies of Base, the goal of program integration is to determine whether the modifications interfere, and if they do not, to create an integrated program that incorporates both sets of changes as well as the portions of Base preserved in both variants. Text-based integration techniques, such as the one used by the Unix  diff3  utility, are obviously unsatisfactory because one has no guarantees about how the execution behavior of the integrated program relates to the behaviors of Base, A, and B. The first program integration algorithm to provide such guarantees was developed by Horwitz, Prins, and Reps. However, a limitation of that algorithm is that it only applied to programs written in a  restricted language\u2014in particular, the algorithm does not handle programs with procedures. This article describes a generalization of the Horwitz-Prins-Reps algorithm that handles programs that consist of multiple (and possibly mutually recursive) procedures.  We show that two straightforward generalizations of the Horwitz-Prins-Reps algorithm yield unsatisfactory results. The key issue in developing a satisfactory algorithm is how to take into account different calling contexts when determining what has changed in the variants A and B. Our solution to this problem involves identifying two different kinds of affected components of A and B: those affected regardless of how the procedure is called, and those affected by a changed or new calling context. The algorithm makes use of  interprocedural program slicing to identify these components, as well as components in Base, A, and B with the same behavior.", "authors": ["David Binkley", "Susan Horwitz", "Thomas W. Reps"], "n_citation": 137, "references": ["2c08d317-3848-40af-9dfa-20c8ce584ce9", "73c1dcb8-e5c5-4c5d-9d79-b6561266c69d", "9b2c14e3-9e79-4820-bc48-3a065ffec024", "9d1af739-1c53-49ce-b99f-8d6a227bc557", "a7f3ac80-bd0b-482d-a05c-1feeb7f6cec5", "abde5ea1-99dc-4812-aa90-50f17478138f", "c3ffb05e-167d-4ad5-ae3c-34cf8b17d103", "de57e29f-da26-4e1a-b90b-cba003827100", "e2e62de3-82aa-40a1-8377-c191f3dc715c", "f9fbe00e-2980-4c0e-a9b1-4e62fd5fa383"], "title": "Program integration for languages with procedure calls", "venue": "ACM Transactions on Software Engineering and Methodology", "year": 1995, "id": "fec08d3e-46fa-4e15-9728-f7d5e369afec"}
{"abstract": "This article proposes the Two-Phase Local Search for finding a good approximate set of non-dominated solutions. The two phases of this procedure are to (i) generate an initial solution by optimizing only one single objective, and then (ii) to start from this solution a search for non-dominated solutions exploiting a sequence of different formulations of the problem based on aggregations of the objectives. This second phase is a single chain, using the local optimum obtained in the previous formulation as a starting solution to solve the next formulation. Based on this basic idea, we propose some further improvements and report computational results on several instances of the biobjective TSP that show competitive results with state-of-the-art algorithms for this problem.", "authors": ["Lu\u00eds Paquete", "Thomas St\u00fctzle"], "n_citation": 130, "references": ["23dc6e53-9579-4198-bb00-dedfd3e6071b", "35e70c11-817c-40db-a0fe-42aaffad44d9", "7f03149e-aa7e-4d2f-8061-5827e9a3f065", "8aad37e1-969d-4620-8cbb-50b7f3c5e587", "8dc4ee41-fa00-4d8f-af44-ac689b057abb", "9d4bf0ab-7893-48bb-a563-4ea0a6ebf5a5", "bd161888-f901-4ae3-90a8-11776a86a84f"], "title": "A two-phase local search for the biobjective traveling salesman problem", "venue": "", "year": 2003, "id": "4698468a-9f44-4552-b4a5-99078eac02a1"}
{"abstract": "Even though in Artificial Intelligence, a set of classical logical formulae is often called a belief base, reasoning about beliefs requires more than the language of classical logic. This paper proposes a simple logic whose atoms are beliefs and formulae are conjunctions, disjunctions and negations of beliefs. It enables an agent to reason about some beliefs of another agent as revealed by the latter. This logic, called  MEL  , borrows its axioms from the modal logic  KD  , but it is an encapsulation of propositional logic rather than an extension thereof. Its semantics is given in terms of subsets of interpretations, and the models of a formula in  MEL  is a family of such non-empty subsets. It captures the idea that while the consistent epistemic state of an agent about the world is represented by a non-empty subset of possible worlds, the meta-epistemic state of another agent about the former's epistemic state is a family of such subsets. We prove that any family of non-empty subsets of interpretations can be expressed as a single formula in  MEL  . This formula is a symbolic counterpart of the Mobius transform in the theory of belief functions.", "authors": ["Mohua Banerjee", "Didier Dubois"], "n_citation": 56, "references": ["05f59ebe-6fcf-435e-ad81-a13583c94c23", "402136a0-f632-41f1-9e9c-a2f724d47497", "4b44da1c-9a1b-497b-8318-2a86d80863e0", "a0067a81-0691-403e-8845-1a73a3aa33b4", "a92213e5-a2ac-4c24-9d84-1cbb43b4c89b", "aaf903a7-0431-4855-b3d5-f92d0d766641", "dcfa8091-69ab-4e1b-a509-0c1fb02d9e89", "ff04bba0-5b32-401a-9359-5823f1f5f2a1"], "title": "A Simple Modal Logic for Reasoning about Revealed Beliefs", "venue": "european conference on symbolic and quantitative approaches to reasoning and uncertainty", "year": 2009, "id": "f608730b-b790-4232-94fe-937789140de9"}
{"abstract": "In the late 1980s, software designers introduced middleware platforms to support distributed computing systems. Since then, the rapid evolution of technology has caused an explosion of distributed-processing requirements. Application developers now routinely expect to support multimedia systems and mobile users and computers. Timely response to asynchronous events is crucial to such applications, but current platforms do not adequately meet this need. Another need of existing and emerging applications is the secure interoperability of independent services in large-scale, widely distributed systems. Information systems serving organizations such as universities, hospitals, and government agencies require cross-domain interaction. To meet the needs of these applications, Cambridge University researchers developed middleware extensions that provide a flexible, scalable approach to distributed-application development. This article details the extensions they developed, explaining their distributed software approach and the support it has provided for emerging applications.", "authors": ["Jean Bacon", "Ken Moody", "John Bates", "Chaoying Ma", "Andrew C. Mcneil", "Oliver Seidel", "Mark D. Spiteri"], "n_citation": 203, "references": ["371eb272-0ec7-4c4a-9e06-5bda53625b2a", "839b46ec-80b2-44ce-a950-11e3abc5db9a", "8f6e8f57-c16f-4031-a17b-b2debe58ab04", "b3893814-1f9d-405e-8fe4-b132f1670bd5", "d3a785fd-312d-4126-8663-9567fbcbb8d9"], "title": "Generic support for distributed applications", "venue": "IEEE Computer", "year": 2000, "id": "f907b122-8734-4876-a68d-38f71cccf3cb"}
{"abstract": "Knowledge-capturing approaches cover a wide variety of software engineering activities, and this variety impedes to find relations and integration between them. One of movements towards knowledge reuse and integration is Model Driven Architecture, a model-centric approach based on platform-specific abstractions and model transformations. We attempt to integrate knowledge captured in Analysis Patterns extended with Feature Modelling, and we propose a method for the initial steps in MDA approach.", "authors": ["Roman Filkorn", "Pavol N\u00e1vrat"], "n_citation": 5, "references": ["28c49b78-9398-4832-baa9-0207cba36e12", "e3b0069c-7e5e-443c-a347-342296aacf6a"], "title": "An approach for integrating analysis patterns and feature diagrams into model driven architecture", "venue": "conference on current trends in theory and practice of informatics", "year": 2005, "id": "66a119a0-653d-47dd-97b5-e88ab628c0ba"}
{"abstract": "Increasing attention has been paid to reinforcement learning algorithms in recent years, partly due to successes in the theoretical analysis of their behavior in Markov environments. If the Markov assumption is removed, however, neither generally the algorithms nor the analyses continue to be usable. We propose and analyze a new learning algorithm to solve a certain class of non-Markov decision problems. Our algorithm applies to problems in which the environment is Markov, but the learner has restricted access to state information. The algorithm involves a Monte-Carlo policy evaluation combined with a policy improvement method that is similar to that of Markov decision problems and is guaranteed to converge to a local maximum. The algorithm operates in the space of stochastic policies, a space which can yield a policy that performs considerably better than any deterministic policy. Although the space of stochastic policies is continuous--even for a discrete action space--our algorithm is computationally tractable.", "authors": ["Tommi S. Jaakkola", "Satinder P. Singh", "Michael I. Jordan"], "n_citation": 359, "references": ["10faea31-cb77-4a47-8ec5-42f51c56c284", "66355846-8694-42ae-a422-07a1e71c65a0", "89fee555-83c3-43fe-8e0d-5c954f26f4aa"], "title": "Reinforcement Learning Algorithm for Partially Observable Markov Decision Problems", "venue": "neural information processing systems", "year": 1995, "id": "d72b168f-3163-4314-a48e-5d6471840519"}
{"abstract": "We present efficient parallel matrix multiplication algorithms for linear arrays with reconfigurable pipelined bus systems (LARPBS). Such systems are able to support a large volume of parallel communication of various patterns in constant time. An LARPBS can also be reconfigured into many independent subsystems and, thus, is able to support parallel implementations of divide-and-conquer computations like Strassen's algorithm. The main contributions of the paper are as follows. We develop five matrix multiplication algorithms with varying degrees of parallelism on the LARPBS computing model; namely, MM/sub 1/, MM/sub 2/, MM/sub 3/, and compound algorithms C/sub 1/(/spl epsiv/)and C/sub 2/(/spl delta/). Algorithm C/sub 1/(/spl epsiv/) has adjustable time complexity in sublinear level. Algorithm C/sub 2/(/spl delta/) implies that it is feasible to achieve sublogarithmic time using /spl sigma/(N/sup 3/) processors for matrix multiplication on a realistic system. Algorithms MM/sub 3/, C/sub 1/(/spl epsiv/), and C/sub 2/(/spl delta/) all have o(/spl Nscr//sup 3/) cost and, hence, are very processor efficient. Algorithms MM/sub 1/, MM/sub 3/, and C/sub 1/(/spl epsiv/) are general-purpose matrix multiplication algorithms, where the array elements are in any ring. Algorithms MM/sub 2/ and C/sub 2/(/spl delta/) are applicable to array elements that are integers of bounded magnitude, or floating-point values of bounded precision and magnitude, or Boolean values. Extension of algorithms MM/sub 2/ and C/sub 2/(/spl delta/) to unbounded integers and reals are also discussed.", "authors": ["Keqin Li", "Yi Pan", "Si Qing Zheng"], "n_citation": 115, "references": ["1e2598d3-6587-4051-8973-1ecdde9da72b", "1f81c292-6ddf-4d05-9c35-baf635fffe26", "24624cef-e274-41ab-83e6-4f5590b346b1", "2861db06-b85c-4173-a0ec-cde7f77c7b07", "297805cd-b563-4bd0-b8c1-6ae95abeb3a0", "31d04b0c-c7ef-4fcf-a736-45958af5cc87", "39df4dc2-1529-43cc-b824-e0d5a44b61bd", "56efa805-f153-4c1b-99f3-777af4586fd0", "5f770afb-ea47-445f-ac2b-0d41f4fe8aa3", "7f9dbf4a-a908-45b7-a0e7-badaa978decb", "83711170-5f4b-47e3-9385-f93100f40823", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "a7acc6cf-2c04-480f-96b0-153f0704be02", "bfc92987-9181-4819-81a6-9145793b28a3", "f48ec395-42d7-44f6-b50e-240ba514bb0c", "f6f6da50-3fbe-4eac-9961-fcd3ca869b23"], "title": "Fast and processor efficient parallel matrix multiplication algorithms on a linear array with a reconfigurable pipelined bus system", "venue": "IEEE Transactions on Parallel and Distributed Systems", "year": 1998, "id": "edd6ccd8-7c08-44f0-950c-d267a865d250"}
{"abstract": "Through the use of conditional compilation and related tools, many software projects can be used to generate a huge number of related programs. The problem of typing such variational software is difficult. The brute-force strategy of generating all variants and typing each one individually is: (1) usually infeasible for efficiency reasons and (2) produces results that do not map well to the underlying variational program. Recent research has focused mainly on efficiency and addressed only the problem of type checking. In this work we tackle the more general problem of variational type inference and introduce variational types to represent the result of typing a variational program. We introduce the variational lambda calculus (VLC) as a formal foundation for research on typing variational programs. We define a type system for VLC in which VLC expressions are mapped to correspondingly variational types. We show that the type system is correct by proving that the typing of expressions is preserved over the process of variation elimination, which eventually results in a plain lambda calculus expression and its corresponding type. We identify a set of equivalence rules for variational types and prove that the type unification problem modulo these equivalence rules is unitary and decidable; we also present a sound and complete unification algorithm. Based on the unification algorithm, the variational type inference algorithm is an extension of algorithm  W . We show that it is sound and complete and computes principal types. We also consider the extension of VLC with sum types, a necessary feature for supporting variational data types, and demonstrate that the previous theoretical results also hold under this extension. Finally, we characterize the complexity of variational type inference and demonstrate the efficiency gains over the brute-force strategy.", "authors": ["Sheng Chen", "Martin Erwig", "Eric Walkingshaw"], "n_citation": 50, "references": ["026b77b8-3fa8-4abf-a47b-83c7b0fc77f6", "04dd7bea-cd30-441e-8269-284ce6342af2", "08745d61-5b1d-4872-b62a-d2feb9e111ab", "0bf9f8a8-6e0b-4adc-b548-460f2af27456", "0d5cb5ea-2370-4c6a-8372-46efc7d9d603", "10c94205-9930-4918-84e9-a9837dabccd7", "111894c2-d6fe-4c73-a3f8-743b5aab0dc6", "112eeff7-c265-4808-aef5-55f592540e40", "118a23b6-f26d-423a-adac-b3a1ec89c61f", "11b2ff92-1c2a-499e-9938-8674acb0630e", "125457d5-6949-4c53-b8a9-e2ca1759830f", "16fd81d0-b3ea-4487-a5d2-759d44e7f164", "184a0c12-0ed0-4d52-a608-2614fcf85026", "1dd365f1-708d-48f2-96b0-48f7744ccade", "22c664d0-7858-4e2d-b46f-7d06a5ed0c10", "23fbcf2c-a05d-47a3-8c4e-978ac433c12d", "28c49b78-9398-4832-baa9-0207cba36e12", "37143083-25b6-4686-ad5a-f5b1e40a3266", "37177354-6899-483a-bb71-23f679c3d56b", "3e2b54bd-ef7a-4d61-9ca6-1ac1572ddb77", "430bbcf6-56a0-4283-aa76-33e4d65640e8", "453be7f6-01f7-4344-bd3b-88985e688473", "476da5ad-45c8-4bd9-b359-804af6ef1aec", "48078471-5597-465b-b15b-100472326027", "50d21f72-db9d-4a19-a8a9-274d9eccc04c", "586116ee-992a-4bd4-89d9-44d98811c805", "59b3992a-1fdf-4d26-9a6b-e2bfa71985e0", "5d7b257a-148f-47b2-85b8-26559165df88", "6797d770-7d8a-4d24-bd5a-e9889773cdd4", "679c34de-0d65-4f5e-a99c-80254daf3d2f", "737de1cf-5cf6-4496-87da-3523f4228eba", "73c92ba4-5820-4f65-a40e-846556f8ee5b", "76a113a8-4191-477b-a23b-34cd2bdcf8bd", "7a46150a-7d5b-4103-8b0f-88e31987c1c5", "7eefaaf7-6996-4cb0-8293-28411fc7f4a5", "8359d527-98ce-464c-b4c5-0e62088bae71", "83cb0010-b854-4ca5-85c6-5e8619a1d4c9", "869a3d5e-c8ae-4314-b764-ba1de53dbea8", "8939a278-ab7b-4cae-a57a-62d3438786e1", "90444f5b-d478-423f-a92c-c48558565ebb", "9136eb02-832e-49c2-b35a-30100217742c", "970a11ae-ecec-485e-ba39-e6a12a08128a", "9732a9dd-a4b8-4ec3-973a-b5666de0fed7", "9a4181a5-70d2-48b7-945d-8d72d9c74874", "a6e2046a-9c0d-45dc-8781-5938d0ad41a0", "add013f1-b12e-4b0a-be41-fe746f2e6037", "b13d14b9-8d6d-4625-ad34-04064f9c7752", "bd52f3a4-3ccf-4808-a85a-ca2215e403fc", "c008403c-fecc-467b-a3e7-4240c93203cd", "cb6c94d4-bce4-4f9d-aea3-5b57a89fa322", "cd359adb-8cd4-4b86-9429-748f28cc6e94", "cd6fe0f5-0956-4bb5-8d66-0b5b564dc8e3", "ce43458e-cce7-4430-b68c-8c3d99db35b8", "d03863f5-9e88-4d6f-901d-707673ff9ea2", "d1e73d36-106c-4498-ba57-6c4b9e734d8f", "d2ec5b41-6789-439e-af00-5dfa34fdcda9", "d4258f63-4867-446c-9865-99081c5d436e", "d647fb40-8a49-466f-a3cf-22d01905a2d6", "d959427a-c8e4-419f-ae9c-a2370a63e635", "da13f3e4-3375-4766-9d90-3aab84977b7d", "e2fc7b78-4270-4d27-af5b-796469bd1540", "e435c51c-247b-4386-8238-0f4d5d754eca", "e52d38ba-159d-4f23-9067-2ef6651baa23", "e9692d04-5332-42dd-915f-5a1fe067f194", "f08cbffa-9467-4c74-a284-7db15837ac53", "f23caa6a-0118-4714-a6fc-7798bf9174db", "fbab723e-0028-4406-a3a4-dcf27dd6554e", "fdce467b-dff6-440c-9fa7-f52cfc891b39", "ff14fee1-234a-440c-a724-e27227441581"], "title": "Extending Type Inference to Variational Programs", "venue": "ACM Transactions on Programming Languages and Systems", "year": 2014, "id": "25692933-0d4f-4617-bf98-20aa547bb394"}
{"abstract": "From the Publisher:#R##N#This book presents a coherent approach to the fast-moving field of computer vision, using a consistent notation based on a detailed understanding of the image formation process. It covers even the most recent research and will provide a useful and current reference for professionals working in the fields of machine vision, image processing, and pattern recognition. #R##N#An outgrowth of the author's course at MIT, Robot Vision presents a solid framework for understanding existing work and planning future research. Its coverage includes a great deal of material that is important to engineers applying machine vision methods in the real world. The chapters on binary image processing, for example, help explain and suggest how to improve the many commercial devices now available. And the material on photometric stereo and the extended Gaussian image points the way to what may be the next thrust in commercialization of the results in this area. #R##N#Chapters in the first part of the book emphasize the development of simple symbolic descriptions from images, while the remaining chapters deal with methods that exploit these descriptions. The final chapter offers a detailed description of how to integrate a vision system into an overall robotics system, in this case one designed to pick parts out of a bin. #R##N#The many exercises complement and extend the material in the text, and an extensive bibliography will serve as a useful guide to current research. #R##N#Errata (164k PDF)", "authors": ["Berthold K. P. Horn"], "n_citation": 5783, "title": "Robot vision", "venue": "", "year": 1986, "id": "c9fa31f7-f6ce-49ea-b42c-8d03ae59dbe4"}
{"abstract": "Fault localization is a process of isolating faults responsible for the observable malfunctioning of the managed system. Previously, fault localization efforts concentrated mostly on diagnosing faults related to the availability of network resources in the lowest layers of the protocol stack. This paper focuses on end-to-end service failure diagnosis as a critical step towards multi-layer fault localization in an enterprise environment. By refining a previously proposed modeling technique, we present a universal method of modeling both availability and performance related problems associated with end-to-end services in a non-deterministic fashion. We introduce and evaluate a novel algorithm that allows an event-driven, incremental diagnosis of end-to-end service failures.", "authors": ["Malgorzata Steinder", "Adarshpal S. Sethi"], "n_citation": 51, "references": ["14872a52-6da7-456b-bb58-7104f8dab9f6", "1dac09a3-05af-4743-98af-a18218e9f713", "1e16f5c9-6098-4daa-b407-3c0714c11871", "22fcab4d-44b4-46c6-aa97-44c82b4b6aa3", "2cb1b42c-6430-43a9-9d71-b44460abefb7", "6d0c8fea-dae5-447c-9730-8004f565da41", "91fc7ab8-f125-4715-a748-2f899c96fe1e", "b1873d0c-a4b5-402a-92e4-a8a835d7a7d5", "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706"], "title": "Non-deterministic diagnosis of end-to-end service failures in a multi-layer communication system", "venue": "international conference on computer communications and networks", "year": 2001, "id": "843c871e-fb3d-49d4-a8a9-1220e8973a94"}
{"abstract": "This paper studies a theoretical problem of whether continuous state feedback and affine feedback are equivalent from the point of view of making an affine system defined on a simplex reach a prespecified facet in finite time. We show that the two classes of feedbacks are equivalent. As a byproduct, new necessary and sufficient conditions for solvability based more directly on the problem data are obtained.", "authors": ["Mireille E. Broucke"], "n_citation": 49, "title": "Reach Control on Simplices by Continuous State Feedback", "venue": "Siam Journal on Control and Optimization", "year": 2009, "id": "0b9cb2e2-44ad-4378-a3cb-c10835b2d3fd"}
{"abstract": "The NorduGrid project operates a production Grid infrastructure in Scandinavia and Finland using own innovative middleware solutions. The resources range from small test clusters at academic institutions to large farms at several supercomputer centers, and are used for various scientific applications. This talk reviews the architecture and describes the Grid services, implemented via the NorduGrid middleware.", "authors": ["O. Smirnova", "P. Eerola", "T. Ekelof", "M. Ellert", "J.R. Hansen", "Aleksandr Konstantinov", "Balazs Konya", "Jakob Langgaard Nielsen", "F. Ould-Saada", "A. Waananen"], "n_citation": 50, "references": ["d57d3d10-29af-4612-a792-5aea47b7c388"], "title": "The NorduGrid architecture and middleware for scientific applications", "venue": "international conference on conceptual structures", "year": 2003, "id": "6ff0f9af-c26a-443b-b5dc-14c8964eda2f"}
{"abstract": "In order to improve vehicle's active safety systems accurate knowledge about the vehicle's driving stability is necessary. Especially the exact determination of the side-slip angle can be of great importance, since it has major potential for improving current control algorithms. Therefore, a model-based methodology for online estimation of vehicle's lateral dynamics is presented, while generalizations of the Kalman Filter algorithm, the Extended and Unscented Kalman Filters are used due to the highly non-linear model behavior. The results of the introduced methodologies are presented for two different driving maneuvers and validated comparing to measurements taken with a VW Golf GTI. Furthermore, a qualitative comparison between Extended and Unscented Kalman Filter is realized.", "authors": ["Mark Wielitzka", "Matthias Dagen", "Tobias Ortmaier"], "n_citation": 50, "references": [], "title": "State estimation of vehicle's lateral dynamics using unscented Kalman filter", "venue": "conference on decision and control", "year": 2014, "id": "62d7cc94-1a6f-4596-be30-33c1bdfcb946"}
{"abstract": "Routing and wavelength assignment (RWA) problems in wavelength-routed optical networks are typically solved using a combination of integer programming and graph coloring. Such techniques are complex and make extensive use of heuristics. We explore an alternative solution technique in the well-known maximum edge disjoint paths (EDP) problem which can be naturally adapted to the RWA problem. Maximum EDP is NP-hard, but now it is known that simple greedy algorithms for it are as good as any of the more complex heuristic solutions. In this paper we investigate the performance of a simple greedy maximum edge disjoint paths algorithm applied to the RWA problem and compare it with a previously known solution method.", "authors": ["Pallavi Manohar", "D. Manjunath", "R. K. Shevgaonkar"], "n_citation": 98, "references": ["149d6b50-b0b2-4fc1-b4c6-3392521e876d", "2dfe24e8-79b1-4328-97ac-bf35dfa8ba98", "662639cf-63d8-49bf-b398-6d20420b224b", "dd9612bc-7e9a-4f7e-a29e-3261fe46b657"], "title": "Routing and wavelength assignment in optical networks from edge disjoint path algorithms", "venue": "IEEE Communications Letters", "year": 2002, "id": "456befc9-af96-46c3-9aa4-f77182152470"}
{"abstract": "Onion routing is an infrastructure for private communication over a public network. It provides anonymous connections that are strongly resistant to both eavesdropping and traffic analysis. Onion routing's anonymous connections are bidirectional, near real-time, and can be used anywhere a socket connection can be used. Any identifying information must be in the data stream carried over an anonymous connection. An onion is a data structure that is treated as the destination address by onion routers; thus, it is used to establish an anonymous connection. Onions themselves appear different to each onion router as well as to network observers. The same goes for data carried over the connections they establish. Proxy-aware applications, such as Web browsers and e-mail clients, require no modification to use onion routing, and do so through a series of proxies. A prototype onion routing network is running between our lab and other sites. This paper describes anonymous connections and their implementation using onion routing. This paper also describes several application proxies for onion routing, as well as configurations of onion routing networks.", "authors": ["Michael G. Reed", "Paul F. Syverson", "David M. Goldschlag"], "n_citation": 1180, "references": ["0dd2428e-9e9d-4dcd-bed7-c5638d80216d", "2e451564-e41a-41b1-9be1-0a57dbf31336", "35bb2894-3c10-4b11-acc1-709476cdf3fc", "3be1572d-1fb3-4e2a-ad7d-c1dea10b53de", "5debdfd0-1406-44ed-bd15-7c2e2b824135", "7160df0f-036a-4641-bc55-cce8d06abb73", "b68fc787-7817-421e-8e66-8a98ab9db1ad", "b9779709-b180-4d6e-b0bc-891f6fd31d27", "dcd41f70-c632-4e61-b6f4-da351c5b8612", "fa4a69b9-cdbb-47e7-8868-8f6ef24b23f1"], "title": "Anonymous connections and onion routing", "venue": "IEEE Journal on Selected Areas in Communications", "year": 1998, "id": "51d2a578-4c03-4b68-8d6d-c55c99186244"}
{"abstract": "We define, in this paper, for every n \u2265 1, n-dimensional block algebra as a set of relations, the block relations, together with the fundamental operations of composition, conversion and intersection. We examine the 13n atomic relations of this algebra which constitute the exhaustive list of the permitted relations that can hold between two blocks whose sides are parallel to the axes of some orthogonal basis in the n-dimensional Euclidean space over the field of real numbers. We organize these atomic relations in ascending order with the intention of defining the concept of convexity as well as the one of preconvexity. We will confine ourselves to the issue of the consistency of block networks which consist of sets of constraints between a finite number of blocks. Showing that the concepts of convexity and preconvexity are preserved by the fundamental operations, we prove the tractability of the problem of the consistency of strongly preconvex block networks, on account of our capacity for deciding it in polynomial time by means of the path-consistency algorithm.", "authors": ["Philippe Balbiani", "Jean-Fran\u00e7ois Condotta", "Luis Fari\u00f1as del Cerro"], "n_citation": 22, "references": ["37b7dee1-e972-4f4e-b0d1-818a78ff275c", "60885145-b83f-4478-8e12-29e10da9ac53", "84f6729f-393a-472e-8aab-2fda338d5748", "87c000f3-ac39-4a54-b625-2f220e4b49d7", "be3d045b-d915-4141-a12c-f1d6d295883f", "d4018737-0a3c-4600-b4c1-f0d08d31e60e", "dbe5ae2e-bbc0-4508-8df5-3ec95c784fa8", "e07217b1-85c2-48a5-abfe-821c5e92e353"], "title": "A Tractable Subclass of the Block Algebra: Constraint Propagation and Preconvex Relations", "venue": "portuguese conference on artificial intelligence", "year": 1999, "id": "53ca53c8-4eba-4c58-9e4b-52524a7f929c"}
{"abstract": "A method is described for set-point tracking in nonlinear systems when pointwise-in-time input and/or state inequality constraints are to be enforced. It consists of adding to a primal compensated system a nonlinear device called command governor (CG) whose action is based on the current state, set-point, and prescribed constraints. The CG selects at any time the system input via a receding-horizon strategy from a virtual sequence amongst all possible command sequences by solving a constrained quadratic optimization problem. Provided that the initial state is admissible, the overall system is proved to fulfil the constraints and have desirable performance stability properties.", "authors": ["David Angeli", "Edoardo Mosca"], "n_citation": 113, "references": ["845aa4ee-e7a3-4567-b9a4-087a1c34bd27", "c08765d0-f363-4bc6-8d5a-6a4695a11fdd"], "title": "Command governors for constrained nonlinear systems", "venue": "IEEE Transactions on Automatic Control", "year": 1999, "id": "f606b27c-871e-4e64-9acb-e352832b5624"}
{"abstract": "Traditionally, middleware technologies, such as CORBA, Java RMI, and Microsoft's DCOM, have provided a set of distributed computing services that essentially abstract the underlying network services to a monolithic \"black box.\" In a mobile operating environment, the fundamental assumption of middleware abstracting a unified distributed service for all types of applications operating over a static network infrastructure is no longer valid. In particular, mobile applications are not able to leverage the benefits of adaptive computing to optimize its computation based on current contextual situations. In this paper, we introduce the Mobile Platform for Actively Deployable Service (MobiPADS) system. MobiPADS is designed to support context-aware processing by providing an executing platform to enable active service deployment and reconfiguration of the service composition in response to environments of varying contexts. Unlike most mobile middleware, MobiPADS supports dynamic adaptation at both the middleware and application layers to provide flexible configuration of resources to optimize the operations of mobile applications. Within the MobiPADS system, services (known as mobilets) are configured as chained service objects to provide augmented services to the underlying mobile applications so as to alleviate the adverse conditions of a wireless environment.", "authors": ["Alvin T. S. Chan", "Siu Nam Chuang"], "n_citation": 193, "references": ["0366077d-7508-4502-a85c-6d08cfddb23c", "2cc7ab8a-09aa-4e20-a914-8fd2f5dda406", "5f0e3bf6-a29f-456d-81be-f4c89bd62912", "80649b46-78a4-475e-8e8d-ce2d1b4eafad", "97751b9e-23e4-4be4-ab90-3508316b82b7", "c5bde766-5de9-463b-8f16-aa4ecb59996d", "d9228aed-1289-4407-a46d-c12ce0b9a4e0", "dec1ebad-18b3-48cf-940d-13e6a5c544b7", "f7e2aa7d-34b3-40dc-b29f-e2d44b86c03b"], "title": "MobiPADS: a reflective middleware for context-aware mobile computing", "venue": "IEEE Transactions on Software Engineering", "year": 2003, "id": "fe0b29fe-2112-4aa2-ad4f-eebfc89bcc23"}
{"abstract": "Automation in outdoor applications (farming, surveillance, military activities, etc.) requires highly accurate control of mobile robots, at high speed, although they are moving on low-grip terrain. To meet such expectations, advanced control laws accounting for natural ground specificities (mainly sliding effects) must be derived. In previous work, adaptive and predictive control algorithms, based on an extended kinematic representation, have been proposed. Satisfactory experimental results have been reported (accurate to within \u00b110 cm, whatever the grip conditions), but at limited velocity (below 3 m\u00b7s-1). Nevertheless, simulations reveal that control accuracy is decreased when vehicle speed is increased (up to 10 m\u00b7s-1). In particular, oscillations are observed at curvature transition. This drawback is due to delays in sideslip angle estimation, unavoidable at high speed because only an extended kinematic representation was used. In this paper, a mixed backstepping kinematic and dynamic observer is designed to improve observation of these variables: the slow-varying data are still estimated from a kinematic representation, which is then injected into a dynamic observer to supply reactive and reliable sliding variable (namely sideslip angle) estimation, without increasing the noise level. The algorithm is evaluated via advanced simulations (coupling Adams and MatLab software) investigating high-speed capabilities. Actual experiments at lower speed (experimental platform maximum velocity) demonstrate the benefits of the proposed approach. \u00a9 2009 Wiley Periodicals, Inc.", "authors": ["Roland Lenain", "Benoit Thuilot", "Christophe Cariou", "Philippe Martinet"], "n_citation": 47, "references": ["1f1ce5fa-725c-4439-908d-94b1477510ae", "2176f770-c262-4f41-95b6-c1e5991ca5dd", "278358b1-3b6d-4dbb-84d7-2b5f42930cd4", "40a6e39f-913a-484a-8303-34d607b92e4d", "5408f191-d2d7-46fc-a3c4-8b28224e8b22", "6cd9437f-37b9-4b85-b7e1-7db93a9ebacf", "d87fef8e-54ef-4ce8-ae08-c8eaec8559fe", "ff02cdc6-32ed-4fb3-a440-be998ba9fdd6"], "title": "Mixed kinematic and dynamic sideslip angle observer for accurate control of fast off-road mobile robots", "venue": "Journal of Field Robotics", "year": 2010, "id": "7bdeff17-e151-4271-8bb4-d1cc35dc979c"}
{"abstract": "Different methods are compared for the evaluation of formulas expressing microprocessor correctness in the logic of equality with uninterpreted functions and memories (EUFM) by translation to prepositional logic, given recently developed efficient Boolean-to-CNF translations, in order to identify the best overall translation strategy from EUFM to CNF. The translation from EUFM to propositional logic is done by exploiting the property of positive equality, allowing us to treat most of the abstract word-level values as distinct constants while performing complete formal verification. For EUFM formulas from correct microprocessors, the best translation was by using the e/sub ij/ encoding of g-equations (dual-polarity equations), the nested-ITE scheme for the elimination of uninterpreted predicates, preserving the ITE-tree structure of equation arguments, and Boolean-to-CNF translation by encoding the unobservability of logic blocks by merging them with adjacent gates on the only path to the primary output. For EUFM formulas from buggy microprocessors, the best translation was by using the e/sub ij/ encoding of g-equations, the Ackermann scheme for the elimination of uninterpreted predicates, preserving the ITE-tree structure of equation arguments, and Boolean-to-CNF translation by applying optimizations to reduce the number of clauses - merging of ITE-trees with one level of their AND/OR leaves, and exploiting the polarity of gates and logic blocks to reduce the number of their clauses.", "authors": ["Miroslav N. Velev"], "n_citation": 50, "references": ["0e31d790-85db-452f-be27-9ae35a77e4fc", "0f240b6c-40a3-4fad-9352-2a554b31e5ca", "1bfe97b2-d44c-43c6-9c42-d5f7a22421aa", "1c750a3c-9296-421f-9a56-446d287a92df", "27c32374-d8a1-4992-85cc-409f54b14e21", "28a6e87d-4644-4ac3-8505-83a2416ab8d0", "3540e51d-7c0b-4de0-aed6-5dc0abc8d960", "355cf657-835e-4d29-b0e7-8894d9eeb939", "43e47041-a4df-4177-8c4d-c4784f81e79b", "46c0b79d-63fe-407e-9c9c-6686069c2e0e", "46c42998-f958-4d9f-abbe-366c8dbbd5b7", "4aa9fc3b-2421-465e-9e26-140d3c2395ed", "4b4cd2a0-e4ff-4911-9087-4b4f42f36ab3", "5a9bf89e-3584-4023-a4cc-de4a9f049971", "5bea7944-5eae-4976-a5a9-2a5100254fff", "6086c701-a855-4106-baad-d795ad27bb02", "7139a403-139d-4f92-b83a-b7b578510483", "92acd163-fd4f-41a7-8093-34f5c539defe", "9d826763-53f1-4bfd-a7f9-6a27fc26a8ae", "af945b68-12e1-432d-ace9-89a72cb20177", "be6bf4ad-d3aa-4d8f-a0a9-30561737c326", "c573413a-a4f8-460f-9b00-b319b590dd5f", "da74447e-fdaf-49da-8dea-8400c9f878f6", "ec59a0e8-5c61-4b20-8708-0a7c2a195977", "ecb6fb36-5136-4ec5-ae5d-6fc87af876bb", "f3329cc9-9afa-4c34-80a2-98748eac422c"], "title": "Comparative study of strategies for formal verification of high-level processors", "venue": "international conference on computer design", "year": 2004, "id": "adecc6bf-bf50-49a7-a650-53bf2c5f93e2"}
{"abstract": "Abstract   We describe the development and implementation of algorithms for detecting the page orientation (portrait/landscape) and the degree of skew for documents available as binary images. A new and fast approach is advanced herein whereby skew angle detection takes advantage of information found using the page orientation algorithm. Page orientation is accomplished using local analysis, while skew angle detection is implemented based on the processing of pixels of last black run-lengths of binary image objects. The experiments carried out on a variety of medical journals show the feasibility of the new approach and indicate that detection accuracy can be improved by minimizing the effects of non-textual data.", "authors": ["Daniel S Le", "George R. Thoma", "Harry Wechsler"], "n_citation": 186, "references": ["17a4fa42-d7fa-4f75-a6ee-fd09eeb7efe4", "83c6e261-e0aa-4b28-9226-6a45c425f65d"], "title": "Automated page orientation and skew angle detection for binary document images", "venue": "Pattern Recognition", "year": 1994, "id": "4a923e0b-8025-4d3a-a822-f8ba379e8b04"}
{"abstract": "Abstruct- We have compared the performance of four approaches for automatic language identification of speech utterances: Gaussian mixture model (GMM) classification; single-language phone recognition followed by languagedependent, interpolated n-gram language modeling (PRLM); parallel PRLM, which uses multiple single-language phone recognizers, each trained in a different language; and languagedependent parallel phone recognition (PPR). These approaches, which span a wide range of training requirements and levels of recognition complexity, were evaluated with the Oregon Graduate Institute Multi-Language Telephone Speech Corpus. Systems containing phone recognizers performed better than the simpler GMM classifier. The top-performing system was parallel PRLM, which exhibited an error rate of 2% for 45-s utterances and 5% for 10-s utterances in two-language, closed-set, forcedchoice classification. The error rate for 11-language, closed-set, forced-choice classification was 11 % for 45-s utterances and 21% for 10-s utterances.", "authors": ["Marc A. Zissman"], "n_citation": 498, "references": ["024c89cc-2dd9-45d2-a6e3-514437c0180a", "09bdc75a-d2e0-4584-90aa-1b7d2f46863b", "0aea1232-1289-4841-a2c1-d8d8f4508381", "26c87263-f9c3-41ec-993b-9a2796829bfe", "2a3f2bd0-9340-4dfe-b3f3-ddcdb8c32bc2", "5a305840-66d9-4c01-9197-6bd436137d1c", "63d91b6d-f822-4b02-9f0f-a2bb68394f65", "642d520c-cec9-4762-aa0f-9f9f102a282f", "6dc7d6bb-bb4b-4cc8-b57a-9aa325cc6921", "87f2c4bf-4d5f-454a-b9ea-8193ba0eafe1", "881e7596-84fe-436f-a5e6-c73e85c1b0f3", "8a00cbec-4350-49a3-9a70-71afd57f0bb5", "95c09bae-5562-4f39-98b2-cc78381f5f01", "977c43e6-8ef2-4124-8c46-4fc1ab4fe9c1", "9ae4d893-319d-4171-87c1-900cf564ee69", "9f1c57c9-ae6c-4e00-b3ee-10256adb3cb1", "abaa64b2-4b95-445d-a306-d105260ed727", "b2ef01bb-9c5b-41dd-b242-90155ed1a12b", "b39dda16-79f3-4041-88fb-cef00415ddcb", "c5aa5302-5c46-403c-afc3-aa75a91eece5", "ce2f13e5-1537-4a78-8b59-8caf9f9991b3", "dd89193e-1796-4d89-a197-f088b1452f4f", "f7a94918-a96f-4a60-9482-313e4cdf7a02"], "title": "Comparison of four approaches to automatic language identification of telephone speech", "venue": "IEEE Transactions on Speech and Audio Processing", "year": 1996, "id": "fff43fcc-8a24-4859-bd9b-2fa1aaf58fa2"}
{"authors": ["M. Masseron", "Christophe Tollu", "Jacqueline Vauzeilles"], "n_citation": 78, "references": ["0b89d1b7-2551-4206-ae03-09b504fe9edf", "34a3c793-450f-440e-b585-8866c38df1f8", "aa44dd48-8e1b-4c0e-b79e-95e3bf683345", "bdd72f1c-6df6-4069-bb3a-40a82dfc9065", "fe537d93-5826-48ec-a1c5-8728d60b2167"], "title": "Generating plans in linear logic", "venue": "foundations of software technology and theoretical computer science", "year": 1990, "id": "65a2a2eb-1ab6-4033-9a12-c467f790f0de"}
{"abstract": "This paper describes an advanced simulation environment which is used to examine, validate, and predict the performance of mobile wireless network systems. This simulation environment overcomes many of the limitations found with analytical models, experimentation, and other commercial network simulators available on the market today. We identify a set of components which make up mobile wireless systems and describe a set of flexible modules which can be used to model the various components and their integration. These models are developed using the Maisie simulation language. By modeling the various components and their integration, this simulation environment is able to accurately predict the performance bottlenecks of a multimedia wireless network system being developed at UCLA, determine the trade-off point between the various bottlenecks, and provide performance measurements and validation of algorithms which are not possible through experimentation and too complex for analysis.", "authors": ["Joel E. Short", "Rajive L. Bagrodia", "Leonard Kleinrock"], "n_citation": 105, "references": ["12141ab1-c2ff-4910-8c9d-19c5fbef7d59", "4248d0ed-5b6d-4c7b-b79f-070743c188dc", "81435071-cb68-4ceb-8ddb-7852f2b300b6", "8433b603-6cad-463f-be78-f3b1a83d8a5f", "85ff280c-81e7-4635-9a09-d7f18962ed7f", "928f881f-7451-4897-892e-ade43d50744f", "9ba570aa-92ba-4bca-9f5b-73b5d7cb976d", "a2452291-6db1-415f-b0f1-8a1d70bcc3ad", "a67d231e-b2d8-4aea-bd8b-0a2448d84622", "a980d215-6c62-4c1e-8f1c-ea78ad66b83e", "a9cb802a-c494-4a21-beb5-28aa9fc3af6e", "ae86c568-4a6e-4224-ad73-34a0778c321f", "ef4e6127-1de5-4998-a80c-571c606860a9"], "title": "Mobile wireless network system simulation", "venue": "acm ieee international conference on mobile computing and networking", "year": 1995, "id": "cb3154c2-26b3-4806-a13f-e356eada6577"}
{"abstract": "Artificial Bee Colony (ABC) algorithm is one of the most recently introduced swarm-based algorithms. ABC simulates the intelligent foraging behaviour of a honeybee swarm. In this work, ABC is used for optimizing a large set of numerical test functions and the results produced by ABC algorithm are compared with the results obtained by genetic algorithm, particle swarm optimization algorithm, differential evolution algorithm and evolution strategies. Results show that the performance of the ABC is better than or similar to those of other population-based algorithms with the advantage of employing fewer control parameters.", "authors": ["Dervis Karaboga", "Bahriye Akay"], "n_citation": 1190, "references": ["04dbe820-d1f9-4795-a570-e6c6cc3e02b3", "0de57ff0-8ade-47f1-895d-46af12c8f36a", "145213e9-fb2b-4f49-85aa-6b9462dc5e44", "240669a1-d5a8-4078-93da-34d3fe688304", "38126abb-8a4f-4a03-bc36-f7a9311f3660", "5837090d-d48e-46b7-b8f0-96638794cdfc", "5c295fde-f553-4907-9f79-4f2910c2bd16", "63988b7a-99e5-45e3-a5ff-ff4683c533fa", "675525e3-866a-4414-b4f6-4a77bfcc4054", "68bbd74f-69df-44e5-a56f-00874c9d999a", "6d882eb9-28bb-48ea-8156-213cca215014", "6e404f07-e552-4f28-848d-21ce3717556c", "82e7866d-2ae5-4d23-81e4-1942605e5a81", "84cc6efd-635f-4d0e-8cce-4d6920d97e4c", "922cb881-d9fe-4949-b662-c57217a3210c", "9b80e173-2d0d-4e2d-8cd0-0fcfe230fd81", "a0198ee7-5693-4769-9fcb-6d430687c718", "a2a0d7ee-8fa9-46fe-9e0b-a2f3702e9af4", "e4b468aa-2b23-4229-8872-f9286464a19f", "f3cfc860-c902-479c-a9bc-529da16e55e4"], "title": "A comparative study of Artificial Bee Colony algorithm", "venue": "Applied Mathematics and Computation", "year": 2009, "id": "f53162f2-504f-4527-b681-17dbe1a1c5a5"}
{"authors": ["Robert L. Constable", "Stuart F. Allen", "H. M. Bromley", "W. R. Cleaveland", "James F. Cremer", "Robert Harper", "Douglas J. Howe", "Todd B. Knoblock", "N. P. Mendler", "Prakash Panangaden", "J. T. Sasaki", "Scott Fraser Smith"], "n_citation": 1205, "references": ["0c3522bb-6a95-4634-8842-e38f061cc274", "0e5299ce-28fd-49ec-80eb-52cdf7068b03", "112eeff7-c265-4808-aef5-55f592540e40", "192a0fe0-b5ae-41a4-8e59-afbf21bd979e", "1d9e72ce-a7b4-4747-8ea3-e1871f60a564", "1dcc132c-564a-4fb0-a94c-32d87a096e53", "2c61f471-7732-4e9e-9d47-f52c868f5dc1", "2f39d0a0-98fa-4ab3-93b8-d55cd3492c6e", "36a02551-1995-42cd-91ad-39e47392c9b2", "3f4927bd-a061-4aaf-9968-d5aa13144bce", "42cfc2d0-e082-474a-8242-ae91487b5c16", "54d8d700-ff71-4715-8263-2cce56444a40", "57b95de4-ceff-4457-ae3e-80979ff5aec8", "5b5f1ff2-e5a5-4fa0-af5a-bf6fc236290a", "5edb99f2-cc75-468e-9ca0-28ce7a1e709d", "602d838d-4ba4-409e-aa4c-2775c0d5b666", "6b540c78-a46e-479d-8865-72dc1805d82e", "70fbbb54-06d6-41ce-9282-e30eb71a4a44", "732065fa-10a4-475c-86ee-f9a707f74101", "7398a640-6d89-44c5-8bb4-d823ff44481b", "75dfce4d-d72c-4c44-93e1-76910a7377f7", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "c2dae237-0642-49cd-897a-4da2c1df253d", "d4f5860d-0fa6-4ffd-b940-b0773b27b0ad", "dc21d7d2-af2f-49ae-9ed2-4ec126118eed", "dce2dd2e-9379-4a8c-9e6d-376927b6f4f3", "e520970c-da39-4a0f-b406-598c4958024d", "eb13d90f-a3f0-4099-8ff1-2d68e2b4bbe0", "f3f1bdb8-7b7a-4c83-ab78-f1f450f385b3", "f6120022-7b06-4cce-804c-7fa088bb2cfc", "f78f913a-a091-44d5-8c10-43aa0ae6394b", "feb083ed-e751-4481-8b71-931197f3d8b0", "fec0e381-cba7-429d-99c0-ea176fe3c050", "ffa4f379-dc70-4a0a-9293-bc0b72d1ae46"], "title": "Implementing mathematics with the Nuprl proof development system", "venue": "", "year": 1986, "id": "6c5aa4ae-a495-485e-886c-8e93ca17ce02"}
{"abstract": "Previous model order reduction methods fit into the framework of identifying the low-order linear subspace and using the linear projection to project the full state space into the low-order subspace. Despite its simplicity, the macromodel might automatically include redundancies.   In this paper, we present a model order reduction approach, named  maniMOR , which extends the linear projection framework to a general nonlinear projection framework. The two key ideas of  maniMOR  are (1) it explicitly separates the construction of the low-order subspace and projection operation; (2) it constructs a nonlinear manifold which captures important system responses and defines the corresponding nonlinear projection operator.   The low-order manifold subspace in  maniMOR  is identified by stitching together the low-order linear subspaces around a set of sample points on the manifold. After the manifold is determined, it is embedded into a global nonlinear coordinate system. The projection function is defined in a piece-wise linear manner, and the model evaluation is conducted directly in the manifold subspace using cheap matrix-vector product computations. As a result, a compact model is generated by precomputing all the functions and Jacobians and storing them in a look-up table.   We apply  maniMOR  on two analog circuits and a bio-chemical system to validate its correctness. Extensive comparisons with the results of the full model and other macromodels are provided. Experimental results show that  maniMOR  manages to obtain a huge reduction --  e.g. , from 52 to 5 for the I/O buffer circuit and from 304 to 30 for yeast pheromone pathway system. This is less than half of the size of the TPWL model with the same accuracy. With great promise to capture important system responses,  maniMOR  presents a novel and powerful paradigm for nonlinear model reduction, and casts inspirations for further researches.", "authors": ["Chenjie Gu", "Jaijeet S. Roychowdhury"], "n_citation": 50, "references": ["0c453ef2-3c54-4526-8ee7-6e2f80e67dbc", "28d09b46-8c08-4dc5-b359-b95c89aeef23", "5a29f139-a3f1-4935-b67e-a6b567204acf", "5ea16aa4-23bf-4f57-b9c3-289986823b10", "61dea16e-c492-47f2-85da-75ffdc179fb9", "663323e4-890f-4b25-aca4-8cc7df5cff9f", "73526c61-339e-4f0e-b301-7ab4037fb6dc", "9fa765ad-80ca-4953-8cfd-9d0aef00c897", "a921317a-a871-47bb-b5a4-f50b9aadcd3c", "bee69ebb-0a03-4386-bdd4-82ec3ae98ebc", "dea9b80d-f840-4ea6-a71d-e2bf2446a419", "f51284f5-cdf1-46bd-bad4-c03577417ae1", "f9e867af-ac76-43b1-b2d4-a4673b00061a"], "title": "Model reduction via projection onto nonlinear manifolds, with applications to analog circuits and biochemical systems", "venue": "international conference on computer aided design", "year": 2008, "id": "4c727918-e7fe-405e-99f9-6876c0a26d68"}
{"authors": ["Thomas Eiter", "Thomas Lukasiewicz"], "n_citation": 11, "references": ["143224d4-7e1c-4126-b66b-08b99f7c0ebb", "3bb0885c-8f79-48fd-9da1-b322c58b61f8", "3c22bf30-dd77-4959-bbb4-71557217f0dd", "4253a753-6e4b-48b9-8657-7f40fae10b48", "4b8e58d4-bdab-41f6-ac86-5592bea678ad", "4d4b75e8-7dc7-4a86-b154-72a298372346", "4e4c5f8b-ad6c-44e7-ab41-eb684fdaa485", "556e9aea-f599-4c89-8dc0-f4d4dcf4e396", "5832b681-79a9-4428-8ce6-f15a02fd726a", "6cb36001-d448-48cb-ad5e-19005e520d92", "6f346886-d3f5-48e4-840a-3ca68ac3fed3", "7e7dbaa7-bfc3-417d-88fd-95a84bf6f554", "8592b21a-5e13-4f1a-becb-c030716a422f", "8910b707-a15a-419f-9416-233e190df023", "8a194b5f-4e14-4e02-a514-ebeb2f1e1c35", "8b645983-91ea-4e6d-8fb1-a339490d5737", "a53821e7-5aee-43cf-a04d-65b7e8c309b6", "aafd183c-589e-4437-9bae-7e1c9aba5b7a", "ac2ce72c-856a-4f48-bc1b-ef4152a0d3a2", "b2d06442-318c-4eda-b453-d10a36da6d51", "ccf63dc9-e04b-4a7a-917d-60872e0f9551", "d1cc4aff-2655-4dd5-a8e7-8bf81eb6475b", "d3dbd7cf-a623-4b7f-acd2-890a0b8f540a", "d78f3d08-53f7-46b7-9649-a5ac44415d07", "e210c134-962d-4aa3-a89b-14971e2f5400", "f15553ca-cbcd-4504-8aae-f657bcaf4fd2"], "title": "Complexity Results for Default Reasoning from Conditional Knowledge Bases", "venue": "principles of knowledge representation and reasoning", "year": 2000, "id": "ff17635f-9959-424e-9781-552ef6e11c68"}
{"abstract": "A software energy estimation methodology is presented that avoids explicit characterization of instruction energy consumption and pre-dicts energy consumption to within 3% accuracy for a set of bench-mark programs evaluated on the StrongARM SA-1100 and Hitachi SH-4 microprocessors. The tool, JouleTrack, is available as an online resource and has various estimation levels. It also isolates the switch-ing and leakage components of the energy consumption.", "authors": ["Amit Sinha", "Anantha P. Chandrakasan"], "n_citation": 361, "references": ["119f4add-77e6-441c-9f0f-f006c90e8429", "1a13441a-b8fd-4576-8449-b6a9c0820c72"], "title": "JouleTrack: a web based tool for software energy profiling", "venue": "design automation conference", "year": 2001, "id": "8fa1fdc9-854b-4ab9-96c7-1757d9df1a2d"}
{"abstract": "In this paper, we study the dynamical behavior of a microcantilever-sample system that forms the basis for the operation of atomic force microscopes (AFM). We model the microcantilever by a single mode approximation and the interaction between the sample and cantilever by a van der Waals (vdW) potential. The cantilever is vibrated by a sinusoidal input, and its deflection is detected optically. We analyze the forced dynamics using Melnikov method, which reveals the region in the space of physical parameters where chaotic motion is possible. In addition, using a proportional and derivative controller we compute the Melnikov function in terms of the parameters of the controller. Using this relation it is possible to design controllers that will remove the possibility of chaos.", "authors": ["M. Ashhab", "Murti V. Salapaka", "M. Dahleh", "I. Mezi"], "n_citation": 10, "references": [], "title": "Brief Paper: Dynamical analysis and control of microcantilevers", "venue": "Automatica", "year": 1999, "id": "629405e0-1ba1-4c77-98e4-954efd730f6b"}
{"abstract": "This paper gives an overview over the development of a formally verified file system for flash memory. We describe our approach that is based on Abstract State Machines and incremental modular refinement. Some of the important intermediate levels and the features they introduce are given. We report on the verification challenges addressed so far, and point to open problems and future work. We furthermore draw preliminary conclusions on the methodology and the required tool support.", "authors": ["Gerhard Schellhorn", "Gidon Ernst", "J\u00f6rg Pf\u00e4hler", "Dominik Haneberg", "Wolfgang Reif"], "n_citation": 25, "references": ["0075761d-9064-446b-b938-0dfd80805b3f", "11c3a261-f14a-48a5-a4e0-1fe8434a839a", "24509558-4f4b-48f6-8581-19f8265f54b0", "255c4331-0422-4d08-ba59-88117de854a0", "2ec8757c-a088-44f2-b1f6-9e8b26a0053e", "3a52884d-6dc3-45cd-a21c-bd708c8a53c7", "4166d3a4-6497-4b8b-8bb6-c7e1d29c7172", "41e0b388-8009-4a91-90ab-8089ff576c97", "524eb45f-1b3f-4381-a0c1-3696a47c02bb", "5bac5b42-4dec-4389-9fc6-6aaa62aae4c4", "61066e1a-0b32-42b8-b565-89a1fcbc17cf", "64c2a242-3714-4b3a-880b-d8151c5981aa", "6e47785e-680a-469e-9e43-35b70d73316e", "705386cf-4a00-4ee8-9c9f-f1b3ce0bbb1f", "77814213-39c9-49dd-a7b5-7fbd84c54674", "790d40e1-b24e-478b-b39c-459bf71df735", "82b8c3ee-6502-47fb-9d26-4d683413b70b", "8c4ba77c-3fa3-4eb4-9318-3c2b37a90dbb", "995eec1a-c875-43ef-a102-6528b8b296fc", "a9432d73-3c5a-4226-904b-5493187dda6b", "b568fcd1-91ee-485c-bfd3-f71cb802545c", "c3e5b5de-1c15-409b-b787-2d1c920e65c2", "d4364703-6a71-463e-a18c-91c2faaff345", "d7b48cfb-d6c6-4662-bf88-4e960af13edb", "db92c4eb-91cb-4626-8739-6b08325b46c4", "df06ea91-4cc9-4419-9076-d257513f2171", "e10b099a-d711-4be5-b77c-0fb580ff0004"], "title": "Development of a Verified Flash File System", "venue": "", "year": 2014, "id": "0bf5f455-4c3b-4336-af8a-1024da5a1eff"}
{"abstract": "This paper analyzes the Euclidean algorithm and some variants of it for computingthe greatest common divisor of two univariate polynomials over a finite field. The minimum, maximum and average number of arithmetic operations both on polynomials and in the ground field are derived. We consider five different algorithms to compute gcd(A\"1, A\"2) where A\"1, A\"2@?Z\"2[x] have degrees m>=n>=0. Compared with the classical Euclidean algorithm that needs on average 1/2n+1 polynomial divisions, two algorithms involving divisions need on average 1/3n+O(1) and 1/4n+O(1) polynomial divisions; two other algorithms use an average of 1/2m+1/3n+O(1) and 1/4m+2/9n+O(1) polynomial substractions and no divisions.", "authors": ["Keju Ma", "Joachim von zur Gathen"], "n_citation": 14, "references": ["0644877f-3c44-4369-94fd-b44cf52613c3", "0fa6c00d-fd3a-4827-ab9d-7cde82018ea5", "3be76003-6983-40b2-b191-83e4e416b4e0", "46519e0c-2280-484a-ab75-9926f93cb856", "52884f15-38c7-4d00-8d10-3d6aab00786a", "5592465d-1742-4960-babc-97a7516eb028", "581d825e-d78e-4fb4-9277-cf31e63bd6e9", "5f478f89-b913-463a-acf2-6e2576b28969", "a608d484-0ffe-424e-8155-d586ca34ca66", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "b854029f-0279-4143-8106-62e0e87661a4", "c09ecdc5-9b14-4b73-bc3e-c213e2afa067", "ce79e2ba-2f07-46c4-a3d4-308582087a70", "d644fea0-c4a0-46b7-9f91-a97d47e3d04a"], "title": "Analysis of euclidean algorithms for polynomials over finite fields", "venue": "Journal of Symbolic Computation", "year": 1990, "id": "51b0dae7-cf63-40c2-a115-715267349735"}
{"abstract": "The safe run-time evolution of complex software-intensive systems requires that the impact of changes can be predicted at run-time. In this paper we consider the specific case of self-adaptive software-intensive systems using an example for the coordination of autonomous vehicles. We show how incremental run-time checks can verify that changes in the rule set which governs the distributed rule-based self-adaptive behavior provides the required safety properties. We demonstrate how an existing verification technique for invariant checking is turned into an incremental one. We discuss the theoretical complexity of the incremental verification checks and also present some first evaluation results.", "authors": ["Basil Becker", "Holger Giese"], "n_citation": 50, "references": ["0a4e60f3-8416-47c9-be37-24db2311855c", "0ebd8eae-1853-4f72-b655-6dc344893eff", "29d5ebae-cd6c-4905-8d37-40d4b6c9a727", "2a072158-f569-409b-bd0a-dd7890c00219", "3fcc3d73-e0a1-417d-9ead-c0df4822f567", "466aaebd-3e21-4c11-bc46-4a0bb4fa4bdd", "56d1670d-15c0-431d-b033-603ee94b3288", "5f0782f1-e19d-46c3-80ad-a904ed4c41a0", "6171bb79-42f7-4c64-9b56-3f901f1254da", "78d9753c-9cb1-4649-9862-9c80041ad817", "b6cae174-5805-4b8c-bdfb-a9884e3fec7e", "be2969c2-e275-4709-90a9-e99772d28f58", "c3ff4534-839c-4c13-886d-b0c296566716", "d18d8bdb-a283-4794-ab86-9d243b4c1448", "ed89566b-8ce9-4fcf-b143-a711a751e19a", "f2777710-441d-457e-aa2a-d86fb1ea9e04", "ff0a39dc-9b1e-4d42-9b61-9377504de900"], "title": "Incremental verification of inductive invariants for the run-time evolution of self-adaptive software-intensive systems", "venue": "automated software engineering", "year": 2008, "id": "760b2039-653a-47e1-b640-84e113170d12"}
{"abstract": "Consider a real-time system in which every task has a value that it obtains only if it completes by its deadline. The problem is to design an on-line scheduling algorithm (i.e., the scheduler has no knowledge of a task until it is released) that maximizes the guaranteed value obtained by the system. #R##N#When such a system is underloaded (i.e., there exists a schedule for which all tasks meet their deadlines), Dertouzos [Proceedings IFIF Congress, 1974, pp.\\ 807--813] showed that the earliest deadline first algorithm will achieve 100% of the possible value. Locke [Ph. D. thesis, Computer Science Dept., Carnegie-Mellon Univ., Pittsburgh, PA] showed that earliest deadline first performs very badly, however, when the system is overloaded, and he proposed heuristics to deal with overload. #R##N#This paper presents an optimal on-line scheduling algorithm for overloaded uniprocessor systems. It is optimal in the sense that it gives the best competitive ratio possible relative to an off-line scheduler.", "authors": ["Gilad Koren", "Dennis E. Shasha"], "n_citation": 156, "title": "D over : An Optimal On-Line Scheduling Algorithm for Overloaded Uniprocessor Real-Time Systems", "venue": "SIAM Journal on Computing", "year": 1995, "id": "d50f54bb-dd8c-4185-b61a-f467beef2c17"}
{"abstract": "Consider a CIA agent who wants to authenticate herself to a server but does not want to reveal her CIA credentials unless the server is a genuine CIA outlet. Consider also that the CIA server does not want to reveal its CIA credentials to anyone but CIA agents - not even to other CIA servers. We first show how pairing-based cryptography can be used to implement such secret handshakes. We then propose a formal definition for secure secret handshakes, and prove that our pairing-based schemes are secure under the Bilinear Diffie-Hellman assumption. Our protocols support role-based group membership authentication, traceability, indistinguishability to eavesdroppers, unbounded collusion resistance, and forward repudiability. Our secret-handshake scheme can be implemented as a TLS cipher suite. We report on the performance of our preliminary Java implementation.", "authors": ["Dirk Balfanz", "Glenn E. Durfee", "Narendar Shankar", "Diana K. Smetters", "Jessica Staddon", "Hao-Chi Wong"], "n_citation": 315, "references": ["062d5c6a-6725-4603-b49c-fb92c4bd0f5a", "16110fdf-3114-45a5-9445-f91ad9a6a61e", "20b1e7ee-f931-4278-8785-a3fa777f09c7", "2307d218-a49a-434f-8882-ebe1493d27a8", "299f8e42-115f-4e65-be5c-bb1b37aeb927", "39b0a663-a520-4845-b722-537bf6c63ac5", "41d72447-56a9-45d8-906d-4f3da867b0fe", "4dd32fac-1f39-44ea-bba5-7a54a5766729", "5734953d-33ce-4043-9496-0d9759997fff", "666e1ca7-8c79-43b1-8b57-6c5714301481", "711d2941-a65c-4d34-a94e-380af527a233", "8407778d-e0dc-4ba3-a91f-1bc7dac81690", "ac0db18c-141b-499a-9499-bc11ed2a61bc", "b089b6af-f280-423f-a56c-c927bf44628c", "b10fd24d-6a42-4821-9517-da6d1e14b17b", "d8ea976c-b986-429f-91bd-d1da40a9ad39", "ed804c0f-dad5-4ce5-9da3-f69da43f137a"], "title": "Secret handshakes from pairing-based key agreements", "venue": "ieee symposium on security and privacy", "year": 2003, "id": "8963694f-a5bd-41e5-be2b-64378dbf47b7"}
{"authors": ["Faron Moller"], "n_citation": 134, "references": ["011aaada-6870-4fb2-abff-b470dbf25f24", "0404d020-5bd5-4054-8dc5-a5555712319f", "077b7c87-fbd3-48ce-95ea-2bda71256b7b", "0b525551-dc89-427c-9838-25cbaa87f06d", "20f03a37-f234-403a-a71d-208f7332637a", "249a9c11-572d-4036-8116-7667a16c31fe", "2bfdf67d-ebc9-4f34-bdde-71c12ed0496c", "3023929a-c93e-49c5-b03f-7fb0414d94df", "3f9fabe6-468f-4ba3-98bb-03beeb5ce2c0", "4460b4d8-42b5-477d-a737-9bb041e52751", "576696b8-15cf-46f0-b320-30dc2f9bdd27", "62ebf987-cddf-49bf-a539-4afd6ea9cab9", "688b8c80-4b20-43af-a277-78cb1c2186f8", "86718b68-beb2-4201-8bce-845a80302bd2", "8d1688b3-232b-4c48-80f6-d7f5e1b732d8", "a28d6b5e-bdc1-40d9-875b-c00a53fc34f8", "b379698f-345a-41b2-9011-e21f113030f6", "b719e17b-f638-4d7e-8ba1-d0f78a418fec", "d36a4a0e-e91b-4749-948d-2105787e9e1b", "d909b362-759c-4dfd-8643-33f0f9d98415", "e44c5d6e-d017-4413-a8df-f4b3c1bcd47a", "eb9ab356-5fed-4dd7-b31a-80161d29dc4c", "f7e2de36-c7bd-4294-941d-a3a6ebfc65a4"], "title": "Infinite Results", "venue": "international conference on concurrency theory", "year": 1996, "id": "cf88e070-c4a1-46b3-a1d2-ef7f2522cdf1"}
{"abstract": "In this paper, we consider an Li-ion battery as a grey system. The grey prediction technique is then used to develop a grey-predicted Li-ion battery charge system (GP-LBCS). The proposed GP-LBCS is designed to replace the general constant-voltage (CV) mode using the GP mode to improve the Li-ion battery charge behavior. A GP algorithm is built in GP-LBCS to make the charge trajectories faster and safer. A 3-D Y-mesh diagram for describing the charge trajectories of the proposed GP-LBCS is simulated. A GP-LBCS prototype is designed and implemented to assess the charge performance. Experiments show that the charge speed and the charge efficiency of the proposed GP-LBCS, compared with the general constant-current-CV charge system, are increased above 23% and 1.6%, respectively. The charge speed and efficiency in the proposed GP mode are improved above 34% and 7%, respectively, compared with that in the general CV mode.", "authors": ["Liang-Rui Chen", "Roy Chaoming Hsu", "Chuan-Sheng Liu"], "n_citation": 50, "references": ["03768d78-0108-403d-a4d2-00185716909d", "0bc67a15-1ba2-4c8e-b89e-42fbd435302c", "25d8d98f-9909-4aa7-8980-c159504835c0", "424099f1-7376-4385-b597-e51239dae50d", "56624e67-05a3-411b-a720-5169ddd1c888", "91159231-9d4d-44ed-a572-93ed5518e807", "96ebd322-7f8e-4d0e-9ca3-669481353815", "b3ac06ef-e07a-4be7-8849-243073608a35", "fe7c2b12-3aba-48b9-9996-0040ea1d4558"], "title": "A Design of a Grey-Predicted Li-Ion Battery Charge System", "venue": "IEEE Transactions on Industrial Electronics", "year": 2008, "id": "064329d7-13a3-47ed-a0f5-5237865a3578"}
{"abstract": "Software product lines (SPL) can be used to create and maintain different variants of software-intensive systems by explicitly managing variability. Often, SPLs are organized as an SPL core, common to all products, upon which product-specific components are built. Following the so called grow-and-prune model, SPLs may be evolved by copy&paste at large scale. New products are created from existing ones and existing products are enhanced with functionalities specific to other products by copying and pasting code between product-specific code. To regain control of this unmanaged growth, such code may be pruned, that is, identified and refactored into core components upon success. This paper describes tool support for the grow-and- prune model in the evolution of software product lines by identifying similar functions which can be moved to the core. These functions are identified in two steps. First, token-based clone detection is used to detect pairs of functions sharing code. Second, Levenshtein distance measures the textual similarity among these functions. Sufficient similarity at function level is then lifted to the architectural level. The approach is evaluated by three case studies, one using an open source email client to simulate the initial creation of an SPL, and two monitoring existing industrial product lines from the embedded domain.", "authors": ["Thilo Mende", "Felix Beckwermert", "Rainer Koschke", "Gerald Meier"], "n_citation": 66, "references": ["0289e52b-4073-4a53-8642-89177cb1287b", "22d74c3d-6647-4e0a-ab27-331b6fe61afd", "2fe7c094-9c39-471d-9d2a-f1fc6b37e8ff", "3b9a829a-f8f2-4a1f-b0d9-71f74da84fe0", "4c6fdea1-7507-4594-893e-b0151615486b", "4f6e07de-fd69-483c-9ad1-78384a246508", "5286575c-cc94-488c-8162-baba4e878f8b", "6b650635-b9b8-4855-8da2-bceca2f218e5", "6b7b27d3-bb61-452f-85bd-fb71febbfac9", "6f1fa4e8-4597-4886-931b-9da6fbec7eff", "88dd06c7-16e0-4b9f-9e2d-27cd128b3b56", "be964af7-1447-415a-b536-34bec49b987f", "c34e7914-0aeb-49b4-b870-2c28751655fc", "ceb6c751-dbd3-4952-b242-e084430367f2", "e6077756-79a4-4dec-9312-510f8dfbb1b3", "ebe6cfe2-a8bf-44f3-9b5b-0a6e6d4690f4"], "title": "Supporting the Grow-and-Prune Model in Software Product Lines Evolution Using Clone Detection", "venue": "conference on software maintenance and reengineering", "year": 2008, "id": "4013c516-487b-41bd-8216-1579c14fa8b2"}
{"abstract": "Invariants with quantifiers are important for verification and static analysis of programsover arrays due to the unbounded nature of arrays. Such invariants can expressrelationships among array elements and properties involving array and scalar variablesof the loop.This talk presents how quantified loop invariants of programs over arrayscan be automatically inferred using a first order theorem prover,reducing the burden of annotating loops with complete invariants.Unlike all previously known methods, our method is ableto generate loop invariants containing quantifier alternations", "authors": ["Laura Kov\u00e1cs", "Andrei Voronkov"], "n_citation": 150, "references": ["61131b9d-fec8-4a60-9a90-38d3a8fc4f86", "d2867829-49d0-4db4-88a3-992431017801", "d6accf73-1eba-425f-b263-6cac10135bb5"], "title": "Finding Loop Invariants for Programs over Arrays Using a Theorem Prover", "venue": "symbolic and numeric algorithms for scientific computing", "year": 2009, "id": "8cf429c1-7217-44a3-80b6-a2031bf9ca30"}
{"abstract": "In this paper, we propose arrow decision logic (ADL), which combines the main features of decision logic and arrow logic. Decision logic represents and reasons about knowledge extracted from decision tables based on rough set theory, while arrow logic is the basic modal logic of arrows. The semantic models of ADL are pairwise comparison tables, which are useful in rough set-based multicriteria analysis. Consequently, ADL can represent preference knowledge induced from multicriteria decision tables.", "authors": ["Tuan-Fang Fan", "Duen-Ren Liu", "Gwo-Hshiung Tzeng"], "n_citation": 3, "references": ["06f19208-dc76-47cd-ae3e-ee6b9a029964", "173a4054-4ec6-4767-a6dd-4f20f751837f", "1fde774e-d4a9-4d7d-92b7-b372e9677d39", "3852f017-2e34-44af-8d95-27d9a3d25bed", "3f875071-b227-4ace-8fac-7d14e62132f8", "513ac9e6-b566-468e-b3ef-50ab4bb45270", "6546355a-8531-421c-999d-ac59e6b26818", "683a80b0-0fba-48e5-9ff9-72838a2c2baf", "6f73880b-1e16-48de-a14b-bff20dfd43ed", "97623232-94b8-4c31-8381-8b39cd7a6597", "a4589cfe-15e7-4c34-9349-d002d1d2c9df", "e3f79cc1-53b3-4924-8bee-6299504c2a02"], "title": "Arrow decision logic", "venue": "granular computing", "year": 2005, "id": "96ba3388-aff3-4410-bd35-b441be351b09"}
{"abstract": "In this paper, we present Stepping Stones and Pathways (SSP), an alternative model of building and presenting answers for the cases when queries on document collections cannot be answered just by a ranked list. Stepping Stones can handle questions like: \"What is the relation of topics X and Y?\" SSP addresses when the contents of a small set of related documents is needed as an answer rather than a single document, or when \"query splitting\" is required to satisfactorily explore a document space. Query results are networks of document groups representing topics, each group relating to and connecting (by documents) to other groups in the network. Thus, a network answers the user's information need. We devise new and more effective representations and techniques to visualize such answers, and to involve users as part of the answer-finding process. In order to verify the validity of our approach, and since the questions we aim to answer involve multiple topics, we performed a study involving a custom built broad collection of operating systems research papers, and evaluated the results with interested computer science students, using multiple measures.", "authors": ["Fernando Das-Neves", "Edward A. Fox", "Xiaoyan Yu"], "n_citation": 62, "references": ["05e19396-cda8-4539-8f99-b7118828c4ee", "11ea6b73-e0bd-4f20-914b-1c6cdcc20437", "1a076b0f-5404-445a-9f96-04d4459a5a5c", "2d1754c3-05d0-4a29-be89-fdaf670f48c8", "407ceb18-464f-4ab3-b731-68f7681fb26d", "8633324b-2af7-41e3-ad2e-28434bfdbef4", "91033314-dbcc-40d1-b49d-6a35fba616a4", "e11745bb-c9a4-437a-bbe5-fa4bf149b94a", "f246f6f3-f5c6-4cb8-a08f-1ca8d0d63cf8", "f535fa4d-7b0c-4281-ab0a-310dc1282d44", "f61585bb-9c46-4921-b12d-6090c774f6b1"], "title": "Connecting topics in document collections with stepping stones and pathways", "venue": "conference on information and knowledge management", "year": 2005, "id": "272100da-d7c0-4e47-91cc-d4a7d3eddb1f"}
{"abstract": "Excessive power dissipation can cause high voltage droop on the power grid, leading to timing failures. Since test power dissipation is typically higher than functional power, test peak power minimization becomes very important in order to avoid test induced timing failures. Test cubes for large designs are usually dominated by don't care bits, making X-leveraging algorithms promising for test power reduction. In this paper, we show that X-bit statistics can be used to reorder test vectors on scan based architectures realized using toggle-masking flip flops. Based on this, the paper also presents an algorithm namely balanced X-filling that when applied to ITC'99 circuits, reduced the peak capture power by 7.4% on the average and 40.3% in the best case. Additionally XStat improved the running time for Test Vector Ordering and X-filling phases compared to the best known techniques.", "authors": ["A. Satya Trinadh", "Seetal Potluri", "Shankar Balachandran", "Ch. Sobhan Babu", "V. Kamakoti"], "n_citation": 3, "title": "XStat: Statistical X-filling algorithm for peak capture power reduction in scan tests", "venue": "Journal of Low Power Electronics", "year": 2014, "id": "1e25fd55-5cc3-4ed0-ae09-228e37bdf5ae"}
{"abstract": "In this paper we develop new Newton and conjugate gradient algorithms on the Grassmann and Stiefel manifolds. These manifolds represent the constraints that arise in such areas as the symmetric eigenvalue problem, nonlinear eigenvalue problems, electronic structures computations, and signal processing. In addition to the new algorithms, we show how the geometrical framework gives penetrating new insights allowing us to create, understand, and compare algorithms. The theory proposed here provides a taxonomy for numerical linear algebra algorithms that provide a top level mathematical view of previously unrelated algorithms. It is our hope that developers of new algorithms and perturbation theories will benefit from the theory, methods, and examples in this paper.", "authors": ["Alan Edelman", "Tomas A. Arias", "Steven T. Smith"], "n_citation": 1988, "references": ["1d709f9b-ee64-4259-9cb8-bb3bf6380f81", "468e1ea0-9ae0-4882-9b59-128345cd1120", "48dd5180-86fe-46eb-9866-b0e8ff777f87", "4ca96047-de57-4489-99d5-6e17edf807dc", "4cb3fe83-ca15-4236-b0f4-293f1e5878d8", "519940be-351e-4a58-b620-9ae8c908995a", "60190e83-16e8-4f2c-a068-b63873a01507", "6d3e70ac-2749-4a11-9e99-feb2441ee6f6", "702bf527-7618-425f-87b4-ee44f0de6406", "985f7476-4c36-485f-b4d2-4d7e07e0c003", "9c7afac9-4cd2-4a61-b988-df5adc0397cf", "a17cc461-5100-44d5-a5ac-7e10d42301c1", "aaa484d4-abc6-4533-824b-e75373cf30cd", "b3013fe7-9e75-4537-92eb-813eebfc3729", "cfab5070-94b2-4b52-9f81-def1cfd31417", "e4229c4e-91aa-46b1-bce1-c127092ee3ad", "e68d1a6f-392b-42df-89a8-a57bbfe06604", "eef02bbb-f8cb-4c84-8919-3bbc60f8ed49"], "title": "The Geometry of Algorithms with Orthogonality Constraints", "venue": "SIAM Journal on Matrix Analysis and Applications", "year": 1999, "id": "9ef6dfb8-c568-401c-ac00-be7c6f3791ee"}
{"abstract": "Due to the potentially immense amount of frequent sets that can be generated from transactional databases, recent studies have demonstrated the need for concise representations of all frequent sets. These studies resulted in several successful algorithms that only generate a lossless subset of the frequent sets. In this paper, we present a unifying framework encapsulating most known concise representations. Because of the deeper understanding of the different proposals thus obtained, we are able to provide new, provably more concise, representations. These theoretical results are supported by several experiments showing the practical applicability.", "authors": ["Tgk Toon Calders", "Bart Goethals"], "n_citation": 76, "references": ["20703e97-806e-4a13-b3d7-fc57ac567dca", "314ee2dd-a463-43b3-9225-9765cd991c36", "5b2b5553-a2ba-420b-a679-5765726d809a", "715a9ef4-9b8a-41b8-a3fe-7fb3d85f4b58", "7482cc04-8a43-4494-b41a-e6e42259b30f", "7fbb9b17-13c5-460a-99ca-21b8f8dd55ed", "bcd04a8e-5164-479d-b55d-5dfdb4967229", "cee81592-da70-463f-a4bb-d514b78e813d", "d1dcc639-060f-419e-8ef5-16d05b290692", "ecd6a845-8439-49b0-abe8-f71fff81da23", "fd42cc9f-9882-4f11-b472-0b169b7c4c5f"], "title": "Minimal k-Free Representations of Frequent Sets", "venue": "european conference on principles of data mining and knowledge discovery", "year": 2003, "id": "68ee7672-363d-453e-b450-8707ee11e30a"}
{"abstract": "Previous studies have demonstrated that measured wide-area network traffic such as Internet traffic exhibits locally complex irregularities, consistent with multifractal behavior. It has also been shown that the observed multifractal structure becomes most apparent when analyzing measured network traffic at a particular layer in the well-defined protocol hierarchy that characterizes modern data networks, namely the transport or transmission control protocol (TCP) layer. To investigate this new scaling phenomenon associated with the dynamics of measured network traffic over small time scales, we consider a class of multiplicative processes, the so-called conservative cascades, that serves as a cascade paradigm for and is motivated by the networking application. We present a wavelet-based time/scale analysis of these cascades to determine rigorously their global and local-scaling behavior. In particular, we prove that for the class of multifractals generated by these conservative cascades the multifractal formalism applies and is valid, and we illustrate some of the wavelet-based techniques for inferring multifractal scaling behavior by applying them to a set of wide-area traffic traces.", "authors": ["Anna C. Gilbert", "Walter Willinger", "Anja Feldmann"], "n_citation": 198, "references": ["177468c5-f2fb-492b-831d-7cf1a54f5888", "2222f1f9-b357-45ef-8943-ae096e660c5f", "739981e9-e2cb-4a49-8dda-429a167bc0d2", "c87f8eba-8226-46b8-8e28-f21044936c6c", "f42e671e-7a91-499d-a7ba-05a9c276f622"], "title": "Scaling analysis of conservative cascades, with applications to network traffic", "venue": "IEEE Transactions on Information Theory", "year": 1999, "id": "5c62ace1-7b17-4a08-b944-f9757065f3bc"}
{"abstract": "Editor's note:Today's integrated circuits are vulnerable to hardware Trojans, which are malicious alterations to the circuit, either during design or fabrication. This article presents a classification of hardware Trojans and a survey of published techniques for Trojan detection.", "authors": ["Mohammad Tehranipoor", "Farinaz Koushanfar"], "n_citation": 578, "references": ["01a7400c-8f4e-4243-9f57-a79d95606dd6", "09d602e5-07d5-4a27-b74b-86560073c3ff", "0fbaf9bc-470d-4f32-b09d-d398413afdf0", "1e4f0826-ee4f-4cfe-89c2-5a91512cb5ea", "23f787b2-8006-4003-a1c8-f5d2b92dcddd", "241cddbe-e280-4005-bad2-15f2a3665629", "321abf15-92d4-4713-a6ab-6daa7dacb969", "40fff782-ee4f-46e1-9d92-fdacc678b0d9", "4be5c66e-abb0-47e9-b926-62694c42f289", "60b3b8dd-7c65-44a4-aca7-6fd3799fbd62", "7813f3d1-ddb3-4918-baa7-485fc64bdfd6", "7ac26f1d-9cfb-48af-b5dc-0a7cbb588de2", "8ab622c7-d08f-4676-9dc8-00aa0c13d74b", "9aec3e3b-bda2-487f-a1f3-ccad91a85863", "a7c4a848-4ed0-4551-a44c-d56948cd058f", "a8080fa3-8df0-4d8d-aa0b-8dd9c268904a", "b01a9d88-8189-4f1a-ac81-8512926ed562", "b0dec4c6-a23c-446e-b4fb-eeb7a7922bd7", "b8af490a-c9ee-4cdf-bc35-bfced6571b8a", "bc69320f-2ec3-4194-a686-234eae0d2cf1", "c1cd9b7f-59fb-4ad1-b892-65e606969c69", "c6320427-479f-4ec6-8d1c-83c4110b1996", "cecc8555-66d8-428a-86e8-dae759df5e4f", "d032730e-8087-41f6-8349-c0d4ef89f097", "d49fef06-f1a6-4683-a3c0-1dfae0b798ac", "dff3ff27-70a7-4cd2-8d8a-aeded0ab4e19", "ff4007b1-f078-4012-86db-ac51ba6068f3"], "title": "A Survey of Hardware Trojan Taxonomy and Detection", "venue": "IEEE Design & Test of Computers", "year": 2010, "id": "dd9c6770-1b3a-4172-9a26-7944dcf77c73"}
{"abstract": "In this work, we present an overview of recently developed methods for control and optimization of complex process systems described by multiscale models. We primarily discuss methods developed in the context of our previous research work and use examples of thin film growth processes to motivate the development of these methods and illustrate their application.", "authors": ["Panagiotis D. Christofides", "Antonios Armaou"], "n_citation": 92, "references": ["4788e91b-cd0a-4dce-9d01-6471d604f52c", "56d2f742-5ca3-4c93-9e64-293d425570c3", "794675f4-55c2-4d4c-8312-80cd2d5b9113", "83029e74-d852-4f48-8822-761d1b9c02c6", "e8553e9e-ff46-4b26-8c3e-877c56994f97"], "title": "Control and optimization of multiscale process systems", "venue": "Computers & Chemical Engineering", "year": 2006, "id": "fda4d259-01d0-4622-a40b-bccc2237ff52"}
{"abstract": "The reinforcement learning community has recently intensified its interest in online planning methods, due to their relative independence on the state space size. However, tight near-optimality guarantees are not yet available for the general case of stochastic Markov decision processes and closed-loop, state-dependent planning policies. We therefore consider an algorithm related to AO* that optimistically explores a tree representation of the space of closed-loop policies, and we analyze the near-optimality of the action it returns after n tree node expansions. While this optimistic planning requires a finite number of actions and possible next states for each transition, its asymptotic performance does not depend directly on these numbers, but only on the subset of nodes that significantly impact near-optimal policies. We characterize this set by introducing a novel measure of problem complexity, called the near-optimality exponent. Specializing the exponent and performance bound for some interesting classes of MDPs illustrates the algorithm works better when there are fewer near-optimal policies and less uniform transition probabilities.", "authors": ["Lucian Busoniu", "R\u00e9mi Munos"], "n_citation": 38, "references": ["0e3e5572-4aba-43db-a571-d87925f9128c", "1fa01f87-e82c-4f1e-883f-5728e443f76d", "3a293de2-b0f9-4f1c-a49e-22334ab46e61", "41db5408-9101-4c9e-b8d7-7b00f964af79", "42823f7b-15a9-47b0-b349-91f51f18954a", "46951dfd-b54d-4a5f-91ce-370f44b11cea", "79186b19-1988-400f-bf11-d138d6d567d6", "97e0a0a6-30d5-47a1-b58a-1f8415f427bc", "bdd72f1c-6df6-4069-bb3a-40a82dfc9065", "c30ae5f3-9e52-47f5-b979-f9c30eb2619b", "cace2e68-3469-4f02-aa05-6abb08f39bda", "d322cbe0-42a8-4cba-a05d-85b0e508b4c5", "d3f427de-f9a2-477d-808d-5d843d1562ec", "dc318003-8265-4172-bb40-656e5245742c", "f2fee27d-66bb-48f6-affa-c0826c8a8ea2", "f6b0a356-87ce-4d3b-9fbf-cc288af0cba5"], "title": "Optimistic Planning for Markov Decision Processes", "venue": "", "year": 2012, "id": "42548cfa-fa2c-498d-818b-c63184d1ee95"}
{"abstract": "Query processing is a crucial component of various application domains including information retrieval, database design and management, pattern recognition, robotics, and VLSI. Many of these applications involve data stored in a matrix satisfying a number of properties. One property that occurs time and again specifies that the rows and the columns of the matrix are independently sorted. It is customary to refer to such a matrix as sorted. An instance of the batched searching and ranking problem (BSR) involves a sorted matrix A of items from a totally ordered universe, along with a collection Q of queries. Q is an arbitrary mix of the following query types: for a search query q/sub j/, one is interested in an item of A that is closest to q/sub j/; for a rank query q/sub j/ one is interested in the number of items of A that are strictly smaller than q/sub j/. The BSR problem asks for solving all queries in Q. The authors consider the BSR problem in the following context: the matrix A is pretiled, one item per processor, onto an enhanced mesh of size /spl radic/n/spl times//spl radic/n; the m queries are stored, one per processor, in the first m//spl radic/n~ columns of the platform. Their main contribution is twofold. First, they show that any algorithm that solves the BSR problem must take at least /spl Omega/(max{logn, /spl radic/m}) time in the worst case. Second, they show that this time lower bound is tight on meshes of size /spl radic/n/spl times//spl radic/n enhanced with multiple broadcasting, by exhibiting an algorithm solving the BSR problem in /spl Theta/(max{logn, /spl radic/m}) time on such a platform.", "authors": ["Venkatavasu Bokka", "Himabindu Gurla", "Stephan Olariu", "James L. Schwing", "Larry Wilson"], "n_citation": 13, "references": ["051e8f01-0c38-49be-a3c2-2375f8bc3c3c", "10425c56-c2f3-4eae-a82a-b18badfac59e", "4e6e30be-4024-4823-aa3a-0356677c36d4", "5012cb76-c117-44b2-88a8-ff9ec9bfe53d", "5040fae4-3569-41b9-a83e-c628f07b1219", "531d4a34-e05e-4ae7-9cfa-3181f3735296", "54174430-f552-4b61-a976-a1fb1545fdf2", "55003771-2925-44ee-9c4f-5e37bb6bdbda", "590f040d-b94b-471d-bb50-668a5db31291", "5e2f8eb8-007a-4ab0-b989-ccb66443ad28", "a7b4327e-7771-45e3-bd6b-6bf0d8539b1e", "adb47feb-f3dd-4a98-9ff2-bac6585e0263", "baf4c476-a291-491d-996c-cc4256173941", "cc3b413a-3e46-4c90-a645-ac0c7f881669", "cf862fd8-9204-4e44-9639-2d067c247539", "d0dd6d83-fc40-4394-b603-660c99c16a15", "d1f43b49-e755-4ac2-b6ab-7bdaed25979f", "dcb4ab3d-b683-4efb-b085-dc39800d6202"], "title": "Time-optimal domain-specific querying on enhanced meshes", "venue": "IEEE Transactions on Parallel and Distributed Systems", "year": 1997, "id": "f7c8a0a6-4cb2-49b5-89c8-bc8f104a3dbe"}
{"abstract": "Workflow management systems (WFMSs) are becoming the basic technology for organizations to perform their daily business processes (workflows). A consistent and reliable execution of such processes is crucial for all organizations. The authors claim that this can only be achieved by integrating transactional features-especially \"workflow transactions\"-into WFMSs. Based on this idea, they discuss in detail advanced workflow recovery concepts which are necessary for the reliable and consistent execution of business processes in the presence of failures and exceptions. Additionally, they distinguish between different workflow types and present adequate recovery concepts for each of them.", "authors": ["Johann Eder", "Walter Liebhart"], "n_citation": 153, "references": ["0e13a0e3-9323-4799-b3ba-2e76b42f0477", "36f41e0a-fd07-4f07-ba75-6d1503757937", "4790bc71-e6c4-4d16-97e8-63793f1048a6", "47d0e8d9-79e9-4584-bffb-35937bcd29d3", "71c08e32-c909-4be7-8c14-c235f235a3dc", "7201eb2c-29ff-42e1-aa9f-4ba15a246e51", "8ec39a3a-4902-4250-b80e-e19cd8d5d36a", "a86f9f8e-7af5-41c9-b3b4-b66a87f0aa71", "a90198b5-ebdb-4201-adfc-c296e3a5c8ba", "ad00d1ba-eff0-4980-94fa-80dc41005afc", "bb226246-51e2-45ea-9085-bb2777a7e6a5", "f24fa5e5-549f-4df8-ad55-060f9b39c92a"], "title": "Workflow recovery", "venue": "cooperative information systems", "year": 1996, "id": "ee83c563-1733-40d1-a512-a8751e001a53"}
{"abstract": "A new recurrent neural network based language model (RNN LM) with applications to speech recognition is presented. Results indicate that it is possible to obtain around 50% reduction of perplexity by using mixture of several RNN LMs, compared to a state of the art backoff language model. Speech recognition experiments show around 18% reduction of word error rate on the Wall Street Journal task when comparing models trained on the same amount of data, and around 5% on the much harder NIST RT05 task, even when the backoff model is trained on much more data than the RNN LM. We provide ample empirical evidence to suggest that connectionist language models are superior to standard n-gram techniques, except their high computational (training) complexity. Index Terms: language modeling, recurrent neural networks, speech recognition", "authors": ["Tomas Mikolov", "Martin Karafiat", "Lukas Burget", "Jan Cernock\u00fd", "Sanjeev Khudanpur"], "n_citation": 1244, "references": ["019c1844-62ba-4248-907b-6af8bebaf939", "0e2996d5-3fbd-45ab-a092-cc888482010a", "29042545-4ddf-4bf9-ae8b-d65876c9eb41", "31b724c0-ae79-4477-ab75-3b62e2133bdb", "3946ca1b-24fa-426e-8e55-b9e75d4fae0c", "4a9dfa81-a4e6-4388-9d9d-ff62ba98e67c", "6666464e-18c5-4fa6-95f7-b8fa84a097a3", "7aa454b2-47c6-4117-b823-1df65289e8e7", "7c0b0749-183a-4884-bac6-1f67dbc7c752", "b241b294-4de6-4424-affc-f5fa268939fd", "bef405c3-0ed8-476e-890f-d7d8603535cf"], "title": "Recurrent neural network based language model", "venue": "conference of the international speech communication association", "year": 2010, "id": "cfc571c4-574d-4835-ac41-ead585c71d29"}
{"abstract": "In this article we present background, rationale, and a description of the Scalable Parallel Random Number Generators (SPRNG) library. We begin by presenting some methods for parallel pseudorandom number generation. We will focus on methods based on parameterization, meaning that we will not consider splitting methods such as the leap-frog or blocking methods. We describe, in detail, parameterized versions of the following pseudorandom number generators: (i) linear congruential generators, (ii) shift-register generators, and (iii) lagged-Fibonacci generators. We briefly describe the methods, detail some advantages and disadvantages of each method, and recount results from number theory that impact our understanding of their quality in parallel applications. SPRNG was designed around  the uniform implementation of different families of parameterized random number generators. We then present a short description of SPRNG. The description contained within this document is meant only to outline the rationale behind and the capabilities of SPRNG. Much more information, including examples and detailed documentation aimed at helping users with putting and using SPRNG on scalable systems is available at htt;//sprng.sc.fsu.edu. In this description of SPRNG we discuss the random-number generator library as well as the suite of tests of randomness that is an integral part of SPRNG. Random-number tools for parallel Monte Carlo applications must be subjected to classical as well as new types of empirical tests of randomness to eliminate generators that show defects when used in  scalable envionments.", "authors": ["Michael Mascagni", "Ashok Srinivasan"], "n_citation": 320, "references": ["0006333e-abdd-447e-a605-22ae7d6f4f81", "1153a469-03ca-4918-8141-ce61f32e5090", "57c43038-5c59-4feb-99f9-3b5e9d78c4d9", "5cd88902-4295-4ce8-b141-5ba27848a0e4", "5dfca62b-5d53-4d1e-9a16-9ccc6009af81", "5f9997cd-dd6c-4b2d-a962-563be71d75c2", "6ad4d0ac-1427-4467-808b-21daa2f947fd", "6ef0ef9f-0dcd-4ae6-a36e-4f37d2cbb64e", "8025997f-7fc0-4e48-8bf2-6544d9b97f68", "8c0603d4-b6fd-4468-8c1f-7b5e08a0342d", "9553fde5-7523-4944-abb2-ce12a6d02afc", "c3d3f5df-9482-4da9-be5e-35af419d552a", "d5ef5752-e9fd-4655-8950-0fc006b57626", "df184f71-436a-4b4f-80e8-4a517547005e", "ec6c2e7a-3f75-4c43-a4ba-482ca49a3367", "eef97634-88a3-46d5-9af9-dbe755c21662"], "title": "Algorithm 806: SPRNG: a scalable library for pseudorandom number generation", "venue": "ACM Transactions on Mathematical Software", "year": 2000, "id": "ee99bc0b-a282-47b1-8cc0-6b5ab210632d"}
{"abstract": "Creativity support tools is a research topic with high risk but potentially very high payoff. The goal is to develop improved software and user interfaces that empower users to be not only more productive but also more innovative. Potential users include software and other engineers, diverse scientists, product and graphic designers, architects, educators, students, and many others. Enhanced interfaces could enable more effective searching of intellectual resources, improved collaboration among teams, and more rapid discovery processes. These advanced interfaces should also provide potent support in hypothesis formation, speedier evaluation of alternatives, improved understanding through visualization, and better dissemination of results. For creative endeavors that require composition of novel artifacts (e.g., computer programs, scientific papers, engineering diagrams, symphonies, artwork), enhanced interfaces could facilitate exploration of alternatives, prevent unproductive choices, and enable easy bac...", "authors": ["Ben Shneiderman", "Gerhard Fischer", "Mary Czerwinski", "Mitchel Resnick", "Brad A. Myers", "Linda Candy", "Ernest A. Edmonds", "Michael Eisenberg", "Elisa Giaccardi", "Thomas T. Hewett", "Pamela Jennings", "Bill Kules", "Kumiyo Nakakoji", "F Jay Nunamaker", "Randy Pausch", "Ted Selker", "Elisabeth Sylvan", "Michael A. Terry"], "n_citation": 184, "references": ["129bc914-7d8e-474a-a70a-d58f5d8c1004", "259600d4-c2ca-4876-90b7-fc0360275209", "343f829f-4da5-4d20-9291-4dd2e2502f69", "38c37b93-4cac-4f03-bce4-68fb913cdb1e", "5bba962d-0f0b-4b7f-99e5-995963b7ae9f", "74674ffd-dee3-4588-9789-f5d061b292eb", "7d414a75-db14-4cb3-88b6-95ce14c5d9d2", "82e7cbea-1041-48c7-93a0-1ca5b5dc28e6", "86424897-2797-4c2e-8e72-74d202288eb6", "889c83a7-951c-4ba6-a63b-0d05cf46c9d3", "88cbc71f-7538-4265-9689-2b4c088f07b5", "90eae477-59dd-4775-a8db-c87233d9d1ac", "a0ceb4d6-309d-43f2-b429-abab039a42c5", "a81a94c0-bfa9-411d-aaa7-ddb208bd7b8a", "b546ba2a-d025-4f0d-bde1-7f8cc2a65b56", "c23079f0-d384-4a05-adac-83838b6fcff6", "dc838991-a9b3-4053-8cdb-ed864a135cbc", "e8c756b9-615b-4b44-946d-f9e5081a5175"], "title": "Creativity Support Tools: Report From a U.S. National Science Foundation Sponsored Workshop", "venue": "International Journal of Human-computer Interaction", "year": 2006, "id": "ca497cbf-c06e-4907-873e-1d88d608eaef"}
{"abstract": "The correct operation of computer protocols is essential to the smooth operation of the distributed systems that facilitate our global economy. Formal techniques provide our best chance to ensure that pro- tocol designs are free from errors. This invited paper revisits the class of Stop-and-Wait protocols that incorporate retransmission strategies to recover from transmission errors. This is motivated by the fact that their basic mechanisms are important for practical protocols such as the In- ternet's Transmission Control Protocol (TCP). Stop-and-Wait protocols have been shown to operate correctly over media that may lose packets, however, there has been little discussion regarding the operation of these protocols over media that can re-order packets. The paper presents an investigation of these protocols operating over a medium, such as that provided by the Internet Protocol, that does allow reordering of data. Coloured Petri Nets are used to build a model of a Stop-and-Wait Pro- tocol parameterized by its maximum sequence number and the maxi- mum value of the retransmission counter. The model is analysed using a combination of hand proofs and automatic techniques. We identify four problems. We firstly prove the counter intuitive property for a Stop-and- Wait protocol that the number of packets that are stored in the network can grow without bound. This is true for any positive values of the max- imum sequence number and the maximum number of retransmissions. We further show that loss of packets is possible and that duplicates can be accepted as new packets by the receiver. These first three properties hold even though the sender and receiver perceive that the protocol is op- erating correctly. The final problem is that the protocol does not satisfy the Stop-and-Wait service where sends and receives alternate. Finally, we provide a discussion of the relevance of these results to the Transmission Control Protocol.", "authors": ["Jonathan Billington", "Guy Edward Gallasch"], "n_citation": 50, "references": ["186b0168-bd87-4e01-a71b-4b1f93c5ec5d", "560a6ef5-c239-4f4b-826b-b2d88b8094f5", "5a1a8b26-f8bd-4bfd-8639-321790d24cd9", "5c012fda-c4f3-4878-9873-cc80caf71c84", "6d8cef2f-b8ea-44f2-aa3c-6ca085ab9a96", "6ddf62b9-920e-4937-87da-c6defe683fc7", "8a08c1b5-052a-49a3-a7df-970c71740fed", "9f3cea46-627e-40a2-8b2c-912b7457eec0", "b0340470-c739-4e86-8eae-12dec338ac20", "f61c14c4-bf0d-4330-aa23-7ceac20ff3ba", "f9f1d270-0cd0-47ae-8431-e810a109ef9b", "ff1cd3d4-3644-4592-9309-1619b3e1be51"], "title": "How Stop and Wait Protocols Can Fail over the Internet", "venue": "formal techniques for networked and distributed systems", "year": 2003, "id": "a58d115c-83ab-4c59-92d0-239263a815d6"}
{"abstract": "We provide a comprehensive study of a general class of linear-quadratic mean field games. We adopt the adjoint equation approach to investigate the unique existence of their equilibrium strategies. Due to the linearity of the adjoint equations, the optimal mean field term satisfies a forward---backward ordinary differential equation. For the one-dimensional case, we establish the unique existence of the equilibrium strategy. For a dimension greater than one, by applying the Banach fixed point theorem under a suitable norm, a sufficient condition for the unique existence of the equilibrium strategy is provided, which is independent of the coefficients of controls in the underlying dynamics and is always satisfied whenever the coefficients of the mean field term are vanished, and hence, our theories include the classical linear-quadratic stochastic control problems as special cases. As a by-product, we also establish a neat and instructive sufficient condition, which is apparently absent in the literature and only depends on coefficients, for the unique existence of the solution for a class of nonsymmetric Riccati equations. Numerical examples of nonexistence of the equilibrium strategy will also be illustrated. Finally, a similar approach has been adopted to study the linear-quadratic mean field type stochastic control problems and their comparisons with mean field games.", "authors": ["Alain Bensoussan", "K. C. J. Sung", "Sheung Chi Phillip Yam", "Siu-Pang Yung"], "n_citation": 22, "references": ["07247560-d8d1-4335-9cb1-4f362a560ab1", "08e48f66-232d-485a-9e3c-34c19ebb55b2", "22136c57-87f3-4940-b589-7f13f2e905bc", "27c2d32f-1103-4b73-b148-c34c78e54d82", "430eff5a-e74d-4149-af41-9d61bff8639b", "5ceae01b-e44a-4494-a942-7e3fc530bf77", "6b411bb1-2413-40b1-adf1-bbbd29b35e45", "7ab6d874-b756-4d82-8672-becf88368010", "81c411b7-155e-438b-9808-1805a3a7e2f8", "89740003-8cd4-43d3-8fde-73a27c7abf98", "8b2a767b-7983-41ad-96f7-e0bd05e4dbcd", "a4621f6e-43ae-4550-9b37-3cc7f5a1aa74", "afa9420a-a959-40c1-977e-248ac89467b4", "da6a6885-3766-499d-8c87-7d829aba92b5"], "title": "Linear-Quadratic Mean Field Games", "venue": "Journal of Optimization Theory and Applications", "year": 2016, "id": "0841cefb-2ed1-477e-a2c1-7320a602a2c7"}
{"abstract": "A novel wavelet-chaos-neural network methodology is presented for classification of electroencephalograms (EEGs) into healthy, ictal, and interictal EEGs. Wavelet analysis is used to decompose the EEG into delta, theta, alpha, beta, and gamma sub-bands. Three parameters are employed for EEG representation: standard deviation (quantifying the signal variance), correlation dimension, and largest Lyapunov exponent (quantifying the non-linear chaotic dynamics of the signal). The classification accuracies of the following techniques are compared: 1) unsupervised-means clustering; 2) linear and quadratic discriminant analysis; 3) radial basis function neural network; 4) Levenberg-Marquardt backpropagation neural network (LMBPNN). To reduce the computing time and output analysis, the research was performed in two phases: band-specific analysis and mixed-band analysis. In phase two, over 500 different combinations of mixed-band feature spaces consisting of promising parameters from phase one of the research were investigated. It is concluded that all three key components of the wavelet-chaos-neural network methodology are important for improving the EEG classification accuracy. Judicious combinations of parameters and classifiers are needed to accurately discriminate between the three types of EEGs. It was discovered that a particular mixed-band feature space consisting of nine parameters and LMBPNN result in the highest classification accuracy, a high value of 96.7%.", "authors": ["Samanwoy Ghosh-Dastidar", "Hojjat Adeli", "Nahid Dadmehr"], "n_citation": 358, "references": ["40952a4d-59ec-4fff-9755-76d346e6f7ff", "c0dc0698-9316-4edd-9d05-d5478b93a05d", "d1d558cd-0bca-4790-89f5-1e9d6f405ef0", "d4ef3d03-dfbd-493a-bef1-9e1c51a5d50d"], "title": "Mixed-Band Wavelet-Chaos-Neural Network Methodology for Epilepsy and Epileptic Seizure Detection", "venue": "IEEE Transactions on Biomedical Engineering", "year": 2007, "id": "3d153271-b3fc-47b4-b498-4d54064a4012"}
{"abstract": "In many sensor networks, data or events are named by attributes. Many of these attributes have scalar values, so one natural way to query events of interest is to use a  multi-dimensional  range query. An example is: \"List all events whose temperature lies between 50\u00b0 and 60\u00b0, and whose light levels lie between 10 and 15.\" Such queries are useful for correlating events occurring within the network.In this paper, we describe the design of a distributed index that scalably supports multi-dimensional range queries. Our  distributed index for multi-dimensional data  (or DIM) uses a novel geographic embedding of a classical index data structure, and is built upon the GPSR geographic routing algorithm. Our analysis reveals that, under reasonable assumptions about query distributions, DIMs scale quite well with network size (both insertion and query costs scale as O(\u221aN)). In detailed simulations, we show that in practice, the insertion and query costs of other alternatives are sometimes an order of magnitude more than the costs of DIMs, even for moderately sized network. Finally, experiments on a small scale testbed validate the feasibility of DIMs.", "authors": ["Xin Li", "Young Jin Kim", "Ramesh Govindan", "Wei Hong"], "n_citation": 551, "references": ["1545dfd3-2c25-4ff1-b43c-df4a2a501d06", "2e0c0709-138c-461c-af4f-64037b7feee4", "48958d2c-d727-4c35-86b3-186372eec8f0", "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4", "4c6518e5-9a26-4947-9fb0-24e9e9cf602c", "56a41f3c-7b53-43c4-a7f9-dfdcdb51de7c", "5bbcc50b-0f4b-4c51-8487-0630f8400f61", "5c1a7db8-6f34-46a9-9078-051b4c50548e", "6427b306-4fd2-4097-afa1-a33e5c23e063", "9c0f911c-c9ca-483b-9b35-06ae4ce7c121", "adf6fdf9-01a0-4051-9d99-965f4a5baa4d", "afc06b7c-7fb3-4f88-942b-3076ed77920e", "c075f11b-4ea0-4642-9910-17b3524667a8", "c0ea675b-2479-48ae-817e-3ecedd175ecf", "e1263ada-afda-498c-a37d-9b545293118a", "e97d9c05-854e-4bd6-9301-11affc0d103f"], "title": "Multi-dimensional range queries in sensor networks", "venue": "international conference on embedded networked sensor systems", "year": 2003, "id": "72efc167-c86c-4cbf-b487-67fd0e93f39c"}
{"abstract": "Software distributed shared memory (DSM) improves the programmability of message-passing machines and workstation clusters by providing a shared memory abstract (i.e., a coherent global address space) to programmers. As in any distributed system, however; the probability of software DSM failures increases as the system size grows. This paper presents a new efficient logging protocol for adaptive software DSM (ADSM), called adaptive logging (AL). It is suitable for both coordinated and independent checkpointing since it speeds up the recovery process and eliminates the unbounded rollback problem associated with independent checkpointing. By leveraging the existing coherence data maintained by ADSM, our AL protocol adapts to log only unrecoverable data (which cannot be recreated or retrieved after a failure) necessary for correct recovery, reducing both the number of messages logged and the amount of logged data. We have performed experiments on a cluster of eight Sun Ultra-5 workstations, comparing our AL protocol against the previous message logging (ML) protocol by implementing both protocols in TreadMarks-based ADSM. The experimental results show that our AL protocol consistently outperforms the ML protocol: Our protocol increases the execution time slightly by 2% to 10% during failure-free execution, while the ML protocol lengthens the execution time by many folds due to its larger log size and higher number of messages logged. Our AL-based recovery also outperforms ML-based recovery by 9% to 17% under parallel application examined.", "authors": ["Angkul Kongmunvattana", "Nian-Feng Tzeng"], "n_citation": 10, "references": ["051575e8-d58d-4812-9a3c-59c31b1c3c49", "26b51932-642f-437f-9856-a6d528e8d30a", "40fc2f0e-ffc9-4857-96bc-e5bde4dd363a", "43053aaf-ee92-4b3c-bf5c-bc8d8cb37262", "557a915f-e1fc-4eeb-ad67-a9008dca4499", "7996bfe6-3e9a-4925-88f5-4bc6441def90", "801f0553-588b-436e-9db6-a3dabd4dc279", "81e0c8c3-f275-4b31-926d-0a3dc185c4b8", "87d8183f-b6e5-45c5-901d-d480f272c2ab", "ad4eff53-a46e-4c95-b265-4f2e8db755ad", "b71ce37f-7d4e-47d1-95a0-3953928c025a", "be9c34ce-3d23-4261-b231-ef39547aa419", "e43f49ba-ff0d-43b0-a5b5-9b1b47bbe9c4"], "title": "Logging and recovery in adaptive software distributed shared memory systems", "venue": "symposium on reliable distributed systems", "year": 1999, "id": "c00e7aa4-1af0-4666-8477-25dede1c3bd9"}
{"abstract": "Proliferation of communication-intensive real-time applications with \"elastic\" timeliness constraints such as streaming stored video, requires a new design for end-host communication subsystems. The design should (i) provide per-flow or per-service-class guarantees, (ii) maximize the aggregate utility of the communication service across all clients, (iii) gracefully adapt to transient overload, and (iv) avoid, if possible, starving lower-priority service classes during the period of sustained overload. The authors propose a QoS-optimization algorithm and communication subsystem architecture that satisfy the above requirements. It provides each client its contracted QoS, while adapting gracefully to transient overload and resource shortage. A new concept of flexible QoS contract is introduced, specifying multiple acceptable levels of service (or QoS levels for short) and their corresponding rewards for each client. Allowing clients to specify multiple QoS levels permits the server to perform QoS-optimization and degrade client's QoS under transient overload predictable, as specified in the QoS contract. Clients receive a money-back guarantee if the contracted QoS is violated by the server. The proposed resource-management mechanism maximizes server's total reward under resource constraints. They implemented and evaluated the architecture on a Pentium-based PC platform running under The Open Group (TOG) MK7.2 kernel, demonstrating the capability of the communication subsystem in meeting its design goals.", "authors": ["Tarek F. Abdelzaher", "Kang G. Shin"], "n_citation": 134, "references": ["000bb4ca-2552-42a6-8295-0bbace66a7d4", "50d33a35-79a1-4646-8389-8b5de5321230", "79018045-303b-45d7-b2ef-257df036ed8c", "83bd6344-fa46-4640-a426-99300443f980", "944f064e-76d3-472e-9811-057d0ba5b3eb", "a7526c46-c003-4c21-a6f7-e9dcd99e9c52", "d6fe0c31-f78b-4540-b976-e9a0c2de8d32"], "title": "End-host architecture for QoS-adaptive communication", "venue": "real time technology and applications symposium", "year": 1998, "id": "1e4309bd-1f03-4a5d-bf3f-850e583bde43"}
{"abstract": "In this paper, we present a system that combines sound and vision to track multiple people. In a cluttered or noisy scene, multi-person tracking estimates have a distinctly non-Gaussian distribution. We apply a particle filter with audio and video state components, and derive observation likelihood methods based on both audio and video measurements. Our state includes the number of people present, their positions, and whether each person is talking. We show experiments in an environment with sparse microphones and monocular cameras. Our results show that our system can accurately track the locations and speech activity of a varying number of people.", "authors": ["Neal Checka", "Kevin W. Wilson", "Michael Siracusa", "Trevor Darrell"], "n_citation": 102, "references": ["28fcfd88-b1cb-4c64-9f25-a61de2ab944a", "2a40047a-5afe-485a-8909-a8b0aae9c1b6", "4388b9be-b7f0-4ee0-8cc6-7732cbc79835", "47b9294c-b421-4574-b69d-48944b5bb098", "57f9e116-89ed-4c3d-8fdf-7f96e5a9a2ec", "8c42de3b-7e52-45f2-98ca-bcde76670a1d", "988916b8-d489-4e14-8151-c9dae135e14a", "9c98c906-35e1-43a5-a142-2215ca382d41", "f2da6118-520f-4753-bb91-9f31143933e2", "f38e9236-ed11-4db2-b517-7d712ce33426"], "title": "Multiple person and speaker activity tracking with a particle filter", "venue": "international conference on acoustics, speech, and signal processing", "year": 2004, "id": "e16c8f0a-3a61-4ed8-bf21-544df27e77db"}
{"abstract": "This paper describes a secure Pay TV protocol based on a public-key distributed encryption scheme that enables the Pay TV broadcaster to robustly add or remove any subscriber without changing private decryption keys of other subscribers. In other words, the updating process is transparent to the subscribers. This feature exhibits a distinct advantage over a symmetric key based system where all subscribers share a single key and therefore it is impossible to dynamically remove a subscriber from the system.", "authors": ["Yi Mu", "Vijay Varadharajan"], "n_citation": 34, "references": ["2307d218-a49a-434f-8882-ebe1493d27a8", "2c33bdb1-6f8e-4453-8e10-5153056ae70f", "38118c07-e41c-4e20-81b2-89c9014555e7", "9f94d680-825d-490a-963f-9be63b8e32d4", "b089b6af-f280-423f-a56c-c927bf44628c", "bebcd527-5d60-4ac5-8b3a-5323c4187cfe"], "title": "Robust and Secure Broadcasting", "venue": "international conference on cryptology in india", "year": 2001, "id": "f0c91c78-c2d5-4326-8b0a-83c8b93a3381"}
{"abstract": "Mobile code offers several capabilities such as bandwidth-efficient communication, disconnected operation, and support for dynamic and flexible systems. Nevertheless, mobile code based programming paradigms have difficulty in flowing from research activities to commercial systems. The main reason seems to be the lack of integration between the language support for mobility and a familiar programming environment. The paper addresses this issue and describes the basic functionalities of Mobile RMI, a toolkit that extends Java RMI with mechanisms for creating and moving remote objects across different address spaces. A key feature of Mobile RMI is the automatic updating of remote references to mobile objects, necessary to support remote method invocation even in the presence of object mobility. The extensions to Java RMI only affect the semantics of the remote reference layer, while leaving both the transport layer and the bytecode generation process unchanged.", "authors": ["Marco Avvenuti", "Alessio Vecchio"], "n_citation": 50, "references": ["24829bb4-274a-447b-b7a6-71695fb2e28d", "3df02e7b-67df-4f8e-9031-5cf7d7f54a69", "553e719c-81cd-4191-9c68-f0adf7c15361", "a26a4446-d6ec-413f-9a72-8366cfb7e3e3", "b3c18cc2-96d1-45a8-95c1-b50b0eb78980", "bd5ba11b-272b-44ad-9ae1-afa690d3dcb7", "db8d0b79-2586-49ea-8f24-b87dd83ed406", "e2137884-496a-489c-a873-a4718cb82829"], "title": "Embedding remote object mobility in Java RMI", "venue": "", "year": 2001, "id": "4a3411e9-04f0-405d-bf6b-7d5cc9d85dac"}
{"abstract": "In this paper, we present Committee, a new multi-class learning algorithm related to the Winnow family of algorithms. Committee is an algorithm for combining the predictions of a set of sub-experts in the online mistake-bounded model of learning. A sub-expert is a special type of attribute that predicts with a distribution over a finite number of classes. Committee learns a linear function of sub-experts and uses this function to make class predictions. We provide bounds for Committee that show it performs well when the target can be represented by a few relevant sub-experts. We also show how Committee can be used to solve more traditional problems composed of attributes. This leads to a natural extension that learns on multi-class problems that contain both traditional attributes and sub-experts.", "authors": ["Chris Mesterharm"], "n_citation": 50, "references": ["2fb1b055-2eb3-4016-92e5-41e882d8bf57", "4c111e59-190e-4216-945e-b681e1e2e681", "540ef6bb-631e-4cf0-a146-3adea6e19944", "543ffcba-cac1-422b-b2a1-19963094fb15", "5cd74e0b-f25c-4aaf-8327-7ec949c7d098", "a37442ab-7d38-4f4a-811a-c9a6c1f87c5e", "cd17473b-9aec-4099-bf27-b116490b43ea", "ec508672-6090-4ac3-8939-69e27e9cb977"], "title": "A Multi-class Linear Learning Algorithm Related to Winnow", "venue": "neural information processing systems", "year": 2000, "id": "9918d27e-11fd-4c21-b8d9-f1a3c2b86fb0"}
{"abstract": "This paper presents a framework for relevance-based belief change in propositional Horn logic. We firstly establish a parallel interpolation theorem for Horn logic and show that Parikh's Finest Splitting Theorem holds with Horn formulae. By reformulating Parikh's relevance criterion in the setting of Horn belief change, we construct a relevance-based partial meet Horn contraction operator and provide a representation theorem for the operator. Interestingly, we find that this contraction operator can be fully characterised by Delgrande and Wassermann's postulates for partial meet Horn contraction as well as Parikh's relevance postulate without requiring any change on the postulates, which is qualitatively different from the case in classical propositional logic.", "authors": ["Maonian Wu", "Dongmo Zhang", "Mingyi Zhang"], "n_citation": 50, "references": ["036e28fb-05df-4a03-bdee-b5f0400ebc9c", "038ff8b3-d31d-4c0f-b0ea-926799eb07aa", "248e47cd-d7e3-4cdb-be31-58bbda058bda", "7f2f1697-f9b3-4ed9-affc-a48746407276", "8e2f42f5-d634-40c9-9903-f057f3f8b4bf", "ab528ee1-a3a0-4098-8ffa-6bc94601b961", "b01203b1-4ced-46fd-8ee6-20e6d57be391", "ed200d3a-cd12-4f71-bec1-dceeec7ded5e"], "title": "Language splitting and relevance-based belief change in horn logic", "venue": "national conference on artificial intelligence", "year": 2011, "id": "bb25ad58-a2fc-4e98-8a7c-5b332115ff00"}
{"authors": ["Benjamin C. Pierce"], "n_citation": 166, "references": ["077981f6-1760-48c2-b9db-40d7e251e2af", "1cae8c57-0f88-45b1-8ff5-7a3259fd05b4", "23c82e3b-76e3-401a-835b-7b7cc9e708c0", "6c9702db-33bb-4f8f-bb48-14f0e914848b", "6f45828a-82d4-4306-bc4f-f7fb31d4298e", "8f8dbef0-e78b-47a8-95fb-cfa712107358", "90581d89-25f9-4da1-aef4-f617a207f83b", "9801a8a7-90c9-4f54-abea-35bfaa48ecb7", "a7835f6f-b3b8-4616-bd7d-0ae9312c59e2", "b6c465ae-cc45-468a-8b2a-971bfc7af92d", "ceeedf74-d74a-4d09-8f44-2fab5922459f", "cf440f60-f718-461b-9c4f-42e05867b0f2", "ddd80f74-d275-480d-896e-7e357d0e152c", "e75d6f4b-a5a8-4e25-ad54-e64cdfd92d71", "f708a6fa-af06-4111-a029-2784ea506b25", "f7982ddc-2dbe-4d65-af11-f5cb091c3342"], "title": "Concurrent Objects in a Process Calculus", "venue": "", "year": 1994, "id": "88172515-a88b-4cde-ba2f-689c960127e8"}
{"abstract": "Networked control systems (NCSs) have, in recent years, brought many innovative impacts to control systems. However, great challenges are also met due to the network-induced imperfections. Such network-induced imperfections are handled as various constraints, which should appropriately be considered in the analysis and design of NCSs. In this paper, the main methodologies suggested in the literature to cope with typical network-induced constraints, namely time delays, packet losses and disorder, time-varying transmission intervals, competition of multiple nodes accessing networks, and data quantization are surveyed; the constraints suggested in the literature on the first two types of constraints are updated in different categorizing ways; and those on the latter three types of constraints are extended.", "authors": ["Lixian Zhang", "Huijun Gao", "Okyay Kaynak"], "n_citation": 492, "references": ["001b21ea-8483-4549-b1eb-779581341aba", "05b54b62-0b4b-49af-b2d5-69de8178404d", "0fc506c9-f623-434e-9176-99b2e921e573", "0fc799e8-8343-44ff-bc2b-9141110f64c7", "1698b85a-5393-4db0-ae13-1d10bb86d54b", "29d16c15-6298-45af-aa8e-71e916cb698f", "2c275ce0-0306-4798-90ae-d2ac7467b8f7", "2fb4e729-5244-44f8-b10f-383bf0166656", "3425075e-049c-414c-bcf9-b6f6590267b4", "3b0b6859-55d4-4fa8-b058-9499639384aa", "3e632d21-0c76-454d-a512-02d1c9902559", "3e98a7bc-3ce9-4ad6-a18f-afc8d707a1d3", "43914396-d305-4adf-8fcb-03dd9ed70e55", "475adbfa-5a57-441e-8106-4f322ccd6cbd", "4b0dfd07-61b7-499e-a6f1-d1d9c913ada5", "54354660-2923-4898-90c8-774326e74d24", "568de5a9-cea9-4abc-80e3-848f3c9e8609", "57824f11-595e-46fb-9d14-3f493c17c0c7", "58abefa2-aeec-4996-ae98-c2c1211eba92", "6f0db8f2-5ed8-4c23-a4cf-150aaef367ad", "6f80a87e-8010-4154-b89a-55aa2c994c85", "757d6f5a-7d54-43a1-b342-d42d37da02c0", "761d99d2-862b-4547-9353-253a0b37c211", "7831e4f5-0700-4703-ba18-02b97930b08b", "78b4d315-cc4f-443d-a0b1-9b5ad00b9663", "79c437e0-c819-4580-af95-08d7f5531f42", "7b6c1728-59e8-4c1f-bc73-584a57fbcadf", "7eb203f8-77ff-402c-b844-8a77eb9eb75c", "83c036b2-879c-4297-8f29-4875688147be", "854b25c0-64cf-4ba8-b188-661b608a7531", "86bd39d8-4881-47b1-93b6-22ab01e2dc59", "924b6c31-22c1-4d99-9a29-e62d3af93fbf", "973b5f7b-7374-40d1-85c0-02202965ae69", "98ab2424-e9eb-4ec3-8c3a-b071c2ae3705", "9918ef18-882a-4914-95f3-0da220b79778", "9c2663be-de2f-433a-8c93-fc7c42e48179", "9cedea68-374d-4045-8d9f-44d209a9c647", "ac2e8959-4c7b-4787-931a-34dfa0196b94", "aea18a69-1d93-4cc3-9768-802466b6f3eb", "b0d085c3-2d35-4ff1-8711-e27c0da2f9c3", "bdf424ae-5321-4238-b3a0-214c4cda39e0", "c658c150-7ca3-4dca-95f7-f5de4cfb33ae", "cd319808-b861-409f-a3a1-53b5439df662", "da34b65b-fd81-4c89-ac6f-cc94601c0839", "e3fd281f-5611-4597-8216-fb67da209464", "ecbc81ca-4f32-49cf-8f3a-b65eaf92d085", "ee276eee-ddb7-44f5-8f8a-49bb2da74b87", "eec2af3b-cebb-499d-8491-671579fe4c53", "f62244ec-3c76-449b-9673-36069e5e6f20", "f89aa2f4-478f-4016-ae9e-d6022e3d0406", "fd776ac0-9d8d-49d6-8489-4a7f94b28eaa"], "title": "Network-Induced Constraints in Networked Control Systems\u2014A Survey", "venue": "IEEE Transactions on Industrial Informatics", "year": 2013, "id": "03e9d54f-26d1-45eb-a861-64dc17b391d2"}
{"abstract": "Abstract   Given a general knowledge base about a population of individuals, we consider the problem of applying, or updating, that general knowledge to reason about a particular individual from the population about whom we have only some partial and uncertain information. We show that given an inference process for reasoning about the general knowledge, this process yields a natural and justifiable method of updating to knowledge about a particular individual. In particular, we show that in the case of the maximum entropy inference process this yields minimum cross entropy updating. We also consider several other updating procedures arising in this way.", "authors": ["Jeff B. Paris", "Alena Vencovsk\u00e1"], "n_citation": 50, "references": ["37fc8409-3ebb-4dc1-8810-415b7fad0be6", "a9eb7461-5949-450c-9c4e-94ee736ee1af"], "title": "A method for updating that justifies minimum cross entropy", "venue": "International Journal of Approximate Reasoning", "year": 1992, "id": "6735a925-5b78-4dbb-ac0d-d4327e73767a"}
{"abstract": "This paper is a discussion of the relationship between learning and forgetting. An analysis of the economics of learning is carried out and it is argued that knowledge can sometimes have a negative value. A series of experiments involving a program which learns to traverse state spaces is described. It is shown that most of the knowledge acquired is of negative value even though it is correct and was acquired solving similar problems. It is shown that the value of the knowledge depends on what else is known and that random forgetting can sometimes lead to substantial improvements in performance. It is concluded that research into knowledge acquisition should take seriously the possibility that knowledge may sometimes be harmful. The view is taken that learning and forgetting are complementary processes which construct and maintain useful representations of experience. Research on machine learning is concerned with the problem of how a system may acquire knowledge that it does not possess. It is therefore not surprising that relatively little attention has been paid to the converse problem: How may a system dispose of knowledge it already possess? This is the phenomenon that is termed forgetting when it occurs in humans, and is usually regarded as an unfortunate failure of the memory system. It is our contention that this negative view of forgetting is misplaced and that far from being a shortcoming it is a very useful process which facilitates effective knowledge acquisition. Learning is a process in which an organized representation of experience is constructed (Scott 1983). Forgetting is a process in which parts of that organized representation are rearranged or dismantled. The two processes are thus complementary and the resulting representation is the joint product of both. Mechanisms of forgetting therefore merit study alongside those of acquisition since it is the two together which constitute learning. Our notion of forgetting is fairly broad. In addition to the obvious mechanism of deletion of items of knowledge it also includes changes in the knowledge structure which render particular items relatively or completely inaccessible. It thus includes processes which weaken memory traces or isolate fragments of a knowledge base. Such changes can be viewed as partial removals with deletion as a limiting case which produces complete removal. In this paper we attempt to explore the role of forgetting in machine learning systems. We begin by discussing the circumstances in which it is better to dispose of an item of knowledge than retain it. Then we describe some experimental work we have done in order to demonstrate that even correct knowledge acquired in the course of solving similar problems can be a disadvantage to a system. 2. The Economics of Learning", "authors": ["Shaul Markovitch", "Paul D. Scott"], "n_citation": 169, "references": ["01a47b62-4fa4-443c-8559-225170f48a46", "5a23c696-de00-43f2-a742-da68cb844f1e", "ab800736-5ac6-405d-a5c9-e6f64475b98a"], "title": "The Role of Forgetting in Learning", "venue": "international conference on machine learning", "year": 1988, "id": "df02d633-aaa6-4045-9641-acc74ba1d853"}
{"authors": ["Vladimir Estivill-Castro", "Michael R. Fellows", "Michael A. Langston", "Frances A. Rosamond"], "n_citation": 86, "references": ["030610ac-1d42-42fd-ba1f-553b38f5ad1d", "09494836-ee99-4c7a-b804-be0759416a52", "0f55c41e-74c6-40f3-948a-ebd2830ebccb", "243ae37a-84b9-479d-8e53-99538476eb70", "2fe93786-dc7f-49f0-a713-dbf597be9ab0", "3a56499c-06b5-4216-a071-c13381f89558", "47a65b8d-8fac-4da7-85f0-37fcc87d297f", "63bcc0c5-3ba5-40b0-ab7f-e31f481e9bef", "72d91e0e-3cdc-4783-92fc-9235e37b294f", "7516dc8c-392f-435b-bfff-712ef401155f", "8d082bc1-e638-497d-9b4e-c0e51fe4169f", "9621bc21-00aa-491f-8b8b-369dbde315c7", "9ea38ca0-ee2f-4e9a-84a5-b2249fd1bd3a", "a981f3eb-9f3d-45c5-994c-9ab2120a7f9e", "ab41baf4-32b5-4f79-ba27-e6446c4b5923", "af193c3d-03b9-4077-a26a-c210e1f8e8f1", "c78040bd-9805-46cd-8414-50318c69e8cf", "c86a313a-674a-4f29-94b7-bb88091beea9", "ca037823-bafa-4005-becf-2d134acc5e28", "d2498840-dd83-4792-9597-5a104282d1d7", "d30059db-e520-4654-800f-0efdda5f046c", "d8fdb324-2d3e-4e4a-9597-ea3be1597e66", "faec557e-16f9-4e0e-b7ae-ceb5ccda938c", "fef1a403-7330-47d8-a577-814c69ddfd6e"], "title": "FPT is P-Time extremal structure I", "venue": "", "year": 2005, "id": "c919e29f-0a4a-4f75-b338-30ed4db658d7"}
{"abstract": "This paper introduces a new methodology to compute dense visual flow using the precise timings of spikes from an asynchronous event-based retina. Biological retinas, and their artificial counterparts, are totally asynchronous and data-driven and rely on a paradigm of light acquisition radically different from most of the currently used frame-grabber technologies. This paper introduces a framework to estimate visual flow from the local properties of events' spatiotemporal space. We will show that precise visual flow orientation and amplitude can be estimated using a local differential approach on the surface defined by coactive events. Experimental results are presented; they show the method adequacy with high data sparseness and temporal resolution of event-based acquisition that allows the computation of motion flow with microsecond accuracy and at very low computational cost.", "authors": ["Ryad Benosman", "Charles De Clercq", "Xavier Lagorce", "Sio-Hoi Ieng", "Chiara Bartolozzi"], "n_citation": 75, "references": ["0074c168-38c8-45ef-b250-1384a26460ab", "23bc1d25-1427-48a9-95e0-f91d00e3f91e", "257082ec-9556-4a49-89ea-b0b713350e8f", "2991df92-6ffd-4eca-a787-cad1836c48cb", "32148a0b-6ce4-4a1e-a1d2-98a96b27b24f", "43897c91-a8df-42f7-85c4-fc65b961b5fb", "4967f485-afb7-4886-ab15-995d3a9e9d09", "4db6c10f-b1bb-49c2-b00c-bca8425aa979", "67add682-6e29-49e6-88ac-da68d7debbf7", "732f1cb3-c0c3-40de-bdd0-40de75ec3a66", "93a5ad9b-7ab6-49ae-86d8-16f8137be7c6", "98f3a9fd-ac23-4610-9ef6-6cc1525732e9", "98f704a0-d902-4867-9944-87e9995b648b", "9bbff2e6-6f79-4fb5-84fd-4422b891e66e", "a231d0d7-312b-4cd6-87cb-7a964e326bf6", "aea6d18e-d6b0-492b-b78b-f49da1e124b5", "c349411e-b528-42ba-b046-b2598b22fff7", "e81d6315-2d55-46e1-bbaa-2b53fa8c7c76"], "title": "Event-Based Visual Flow", "venue": "IEEE Transactions on Neural Networks", "year": 2014, "id": "17adfda5-452e-4e97-8a39-d75d68cd9e57"}
{"abstract": "We propose the use of application semantics to enhance the process of semantic reconciliation. Application semantics involves those elements of business reasoning that affect the way concepts are presented to users: their layout, and so on. In particular, we pursue in this article the notion of precedence, in which temporal constraints determine the order in which concepts are presented to the user. Existing matching algorithms use either syntactic means (such as term matching and domain matching) or model semantic means, the use of structural information that is provided by the specific data model to enhance the matching process. The novelty of our approach lies in proposing a class of matching techniques that takes advantage of ontological structures and application semantics. As an example, the use of precedence to reflect business rules has not been applied elsewhere, to the best of our knowledge. We have tested the process for a variety of web sites in domains such as car rentals and airline reservations, and we share our experiences with precedence and its limitations.", "authors": ["Avigdor Gal", "Giovanni A. Modica", "Hasan M. Jamil", "Ami Eyal"], "n_citation": 109, "references": ["3b176565-386c-454c-9bcb-5cdaf9ea0218", "4a1fba97-aec4-472d-94d6-67cea70ee9d2", "57ffaea2-7fcc-4245-b9a9-59cfc77ee358", "67a6c092-2038-44d4-81a8-e026bb696c60", "71699228-335d-4a7c-b04f-8ac234641f99", "91556b20-c53e-4687-82e2-7c3c1e893f0b", "975107a3-98ae-4f72-9354-1836fb105ea5", "b0d313be-bd63-4b35-a3ac-4b1298b6a46f", "c263d514-235b-4b10-9b5e-2a5c1400382c", "cc4e331f-e03b-49e5-b438-5c0cf4af1279", "d1f0c7b0-57ee-4d0f-9798-9cb8f23731fe", "e16c8b26-95a2-431b-88c3-a4c9b42b8fc7", "e1f6913d-2d77-47e9-8f14-a78a746a7642", "e9cb4f12-f852-4a0d-bc43-822771528cbd", "ef3b30a6-5e79-4e5f-9e00-c62bf80e0dee"], "title": "Automatic ontology matching using application semantics", "venue": "Ai Magazine", "year": 2005, "id": "4f47c6fe-acc6-437f-9990-14797c953fe6"}
{"abstract": "We explain and advance Levin\u2019s theory of average case completeness. In particular, we exhibit examples of problems complete in the average case and prove a limitation on the power of deterministic reductions.", "authors": ["Yuri Gurevich"], "n_citation": 207, "references": ["0ebf628e-81af-44ed-a681-8fd42f11d954", "1f02850b-f613-4c73-a335-ad41f0e1d156", "35dc12aa-d7cf-45c8-8cf1-0ffc6d796fc2", "603f8f81-0c85-43ec-a498-cfdb77161fd3", "6af33e62-7b4b-4b56-9bea-1dfe244efe4c", "6dd4efd8-ce29-44f7-b2b9-0c076bfbde32", "701340f1-c485-478a-8536-df367c2c84af", "7c8c545b-b7c8-4b4f-b149-d24fe3e916b5", "8346b697-25a5-4a9f-9e82-34644f704d92", "d7dcf589-cefd-4efe-88e1-d1d8efc6af28", "e23701a7-f905-4b84-a672-0f265d323855"], "title": "Average case completeness", "venue": "Journal of Computer and System Sciences", "year": 1991, "id": "29666514-8f3d-4f8e-8f43-0c27c7a83dfe"}
{"abstract": "The application presented augments uncalibrated images of factories with industrial drawings. Industrial drawings are among the most important documents used during the lifetime of industrial environments. They are the only common documents used during design, installation, monitoring and control, maintenance, update and finally dismantling of industrial units. Leading traditional industries towards the full use of virtual and augmented reality technology is impossible unless industrial drawings are integrated into our systems. We provide the missing link between industrial drawings and digital images of industrial sites. On one hand, this could enable us to calibrate cameras and build a 3D model of the scene without using any calibration markers. On the other hand it brings industrial drawings, floor map, images and 3D models into one unified framework. This provides a solid foundation for building efficient enhanced virtual industrial environments. The augmented scene is obtained by perspective warping of an industrial drawing of the factory onto its floor, wherever the floor is visible. The visibility of the floor is determined using probabilistic reasoning over a set of clues including (1) floor color/intensity (2) image warping and differencing between an uncalibrated stereoscopic image pair using the ground plane homography. Experimental results illustrate the approach.", "authors": ["Nassir Navab", "Benedicte Bascle", "Mirko Appel", "Echeyde Cubillo"], "n_citation": 65, "references": ["27648d64-f108-4bf3-8ea1-68f7a6106344", "5e731786-5e3b-48a0-8e7b-0a8de213e404", "767cb406-103e-477d-8e79-7109ac74bd1a", "7851f45a-7654-4be2-ae7d-fde0aa2301ac", "a2bac56d-ee4c-45f8-ac55-0914b817cd7b", "f0887f29-b2e1-4971-a369-4df8b83b8996", "f9ae7418-accd-4513-acc3-1d256dee7242"], "title": "Scene augmentation via the fusion of industrial drawings and uncalibrated images with a view to marker-less calibration", "venue": "international symposium on mixed and augmented reality", "year": 1999, "id": "31f7a810-5bca-4e78-90ae-37d7b75af6c7"}
{"abstract": "Constructing analysis and modification tools for software assets is laborious because you first need to implement the underlying parser for the software's specific programming language. These implementations are generally not in the public domain. So, parser development for any of the 500+ languages in use today implies a major up-front investment. The authors propose a solution that will work for virtually all languages: the rapid development of renovation parsers by stealing the grammars. They also share lessons learned.", "authors": ["Ralf L\u00e4mmel", "Chris Verhoef"], "n_citation": 117, "references": ["32a7b4a3-5511-47af-99d3-876fd2129559", "4c9a55ef-9741-4c05-b0ef-30d512b52774", "510f6f7d-99c1-4899-b6e4-0a9e7d149475", "8f54a3cc-f8ea-425a-9aba-9ac131c3a370", "c0db5ed6-3dc9-420a-8a87-fe7a6ac9562b", "ca102dde-e08e-47c3-b197-52ee88681a68", "d6c72b34-4ae6-4e3e-84d8-b702784944a5", "dea40fb3-a806-4ca6-96e1-e5419f2485b2"], "title": "Cracking the 500-language problem", "venue": "IEEE Software", "year": 2001, "id": "aee56001-793e-408f-aa2c-cc42584c30d0"}
{"abstract": "Capturing data is a key part of archaeological practice, whether for preserving records or to aid interpretation. But the technologies used are complex and expensive, resulting in time-consuming processes associated with their use. These processes force a separation between ongoing interpretive work and capture. Through two field studies we elicit more detail as to what is important about this interpretive work and what might be gained through a closer integration of capture technology with these practices. Drawing on these insights, we go on to present a novel, portable, wireless 3D modeling system that emphasizes \"quick and dirty\" capture. We discuss its design rational in relation to our field observations and evaluate this rationale further by giving the system to archaeological experts to explore in a variety of settings. While our device compromises on the resolution of traditional 3D scanners, its support of interpretation through emphasis on real-time capture, review and manipulability suggests it could be a valuable tool for the future of archaeology.", "authors": ["Jarrod Knibbe", "Kenton O'Hara", "Angeliki Chrysanthi", "Mark T. Marshall", "Peter D. Bennett", "Graeme Earl", "Shahram Izadi", "Mike Fraser"], "n_citation": 253, "references": ["0e859ce5-0605-4a79-a08d-09e513149b9c", "154c4c45-37f3-4bfa-95df-66159bafa34a", "29dea5f2-0909-4e30-a1cc-37005cf5e179", "2ed612ad-6aef-4a27-bf47-2207aa019dc4", "9cbec383-358a-4d36-9851-8410842355d3", "a7a01782-8e14-4dd6-9336-60718abbfc0b", "b47382f0-d1fe-4b35-bc6a-d1f50f95f887", "c7ec0066-1183-4136-a2b5-ae501977eb5b", "f57c4a18-e6d4-4111-8d24-e0908e7e34ec"], "title": "Quick and dirty: streamlined 3D scanning in archaeology", "venue": "conference on computer supported cooperative work", "year": 2014, "id": "71d3749b-3e35-461b-86c8-920c42d5ebe8"}
{"abstract": "A protocol for maintaining replicated data that can provide both high data availability and low response time is presented. Existing protocols are designed primarily to achieve high availability by updating a large fraction of the copies, which provides some (although not significant) load sharing. In the new protocol, transaction processing is shared effectively among nodes storing copies of the data, and both the response time experienced by transactions and the system throughput are improved significantly. Also presented is an analysis of the availability of the new protocol and simulation is used to study the effect of load sharing on the response time of transactions. The new protocol is also compared with a voting-based scheme. >", "authors": ["Shun Yan Cheung", "Mostafa H. Ammar", "Mustaque Ahamad"], "n_citation": 386, "references": ["0fae30d1-2bfd-445a-8718-dcbaca4bdbab", "1c83accf-3492-42e6-a958-83e360141599", "32a58cfb-b406-4d58-b0ce-23bd33fd522c", "41729657-1b1e-4879-8cef-5ad7a37262c3", "5df86217-3171-4708-8f1a-3124c777c233", "62166fa3-20b9-434d-9d9d-cb1c38d619be", "78b926fd-bb6d-40fd-b7d5-b76620bce7dc", "816d1f5e-baf3-458b-b6f3-b7863b3164ef", "87235932-1cb6-4090-a323-5e8f8d8fbbdb", "9db9578a-6f45-4630-a7ac-854a93cd5c55", "ad6565aa-2532-46b3-be7b-a4ac13a51dec", "b48e53ac-3aad-498e-bbd6-4da43899a9a6", "bfc29e94-bfd4-4ad0-ab8a-2dd6755d42a5", "d50b5611-37df-4d50-a240-4ebb29c4aa35", "d6f6ccf7-55be-439c-9ee2-3b14c09b3937", "e324e402-24fc-47f8-a59d-aa287951719b", "f3b6d800-07fd-41ce-b05a-bc95cf93fafa"], "title": "The grid protocol: a high performance scheme for maintaining replicated data", "venue": "international conference on data engineering", "year": 1990, "id": "c54e73ac-68a3-490c-9d46-b7d9f441abe7"}
{"abstract": "A collaborative virtual environment system is described that is designed to support location-independent shared analysis of spatial data and urban planning proposals. The system seeks to extend the physical workplace of participants into the virtual environment, while preserving traditional textual and verbal communication and cooperation mechanisms. The systems aim is to improve productivity, quality and achieve more transparency in the planning process. The architecture of the Collaborative Urban Planner or CUP system is described and some experimental results that demonstrate urban development control tasks performed within this environment are presented. An application scenario offers a vision of future urban planning practice using CUP. The scenario also diagrammatically demonstrates virtual settings and scenes that could become everyday meeting places for remote planners, architects or engineers assessing proposals and discussing possible alterations to designs.", "authors": ["Tina Manoharan", "Hamish Taylor", "Paul Gardiner"], "n_citation": 50, "references": ["30ef2f4d-3217-4b89-9c36-dd6f8a7518d7", "3689c2a0-8d85-40a4-be15-5557f4b35ec7", "3d89cc71-17b3-4355-949d-5c9812180766", "46a96dee-eb18-40fb-a859-829a8c15428b", "6c2f2584-6e41-4206-8718-4b289e62e1c5", "7ec18d7e-2139-4c8f-9304-aed5932ad115", "f88b419a-5fa9-4d88-906c-5bde8c1c43b1"], "title": "A collaborative analysis tool for visualisation and interaction with spatial data", "venue": "", "year": 2002, "id": "f5e1a5e8-e783-474e-85f6-45f253e12e13"}
{"abstract": "Dynamic voltage scaling (DVS) is an effective technique for reducing the energy consumption in embedded systems. There are several advantages using DVS technique into compiler framework. This paper present a framework for reducing energy consumption in embedded processors using the dynamic compiler collaborate with DVS technique. Two algorithms are implemented in this framework, and the framework is implemented using the Intel PIN systems and is deployed in a real hardware platform. Experimental results based on the software and hardware platform, show that significant energy saving are achieved while performance loss less than 5%.", "authors": ["Qingsong Shi", "Tianzhou Chen", "Xiao Liang", "Jiangwei Huang"], "n_citation": 3, "references": ["10477099-8c17-4b35-9a19-19c10eecaf1b", "1a4c593b-83fd-4d5a-8c35-cc621dbdeda2", "1cc1d147-8fc9-41b3-84c5-08be4439900d", "3c6fd403-9384-4f80-ac7d-94834ec99f7b", "3d502b36-7ddf-4be9-ab40-74c11eb9441c", "42274007-2a9f-4c6d-940b-b278eead1c91", "64e5972e-ab46-41f8-b919-b3d5a9ba1ae0", "720c4165-574f-42b7-9cf0-29de7bf31b00", "76fa467a-07c7-40d7-9b24-ef67392f8496", "b4c7125c-a2e5-43ff-8dd8-20e0c90ef768", "b703190f-d297-4330-bdf2-68a933891c5c"], "title": "Dynamic Compilation Framework with DVS for Reducing Energy Consumption in Embedded Processors", "venue": "international conference on embedded software and systems", "year": 2008, "id": "91c87182-9e9c-44c0-951b-05698e609d37"}
{"abstract": "Sentiment analysis or opinion mining aims to use automated tools to detect subjective information such as opinions, attitudes, and feelings expressed in text. This paper proposes a novel probabilistic modeling framework based on Latent Dirichlet Allocation (LDA), called joint sentiment/topic model (JST), which detects sentiment and topic simultaneously from text. Unlike other machine learning approaches to sentiment classification which often require labeled corpora for classifier training, the proposed JST model is fully unsupervised. The model has been evaluated on the movie review dataset to classify the review sentiment polarity and minimum prior information have also been explored to further improve the sentiment classification accuracy. Preliminary experiments have shown promising results achieved by JST.", "authors": ["Chenghua Lin", "Yulan He"], "n_citation": 553, "references": ["01bcc2a0-54a1-4962-8c6a-52da3eb562c1", "1cc58f5d-a215-4512-a780-dc05fa1f525c", "2461e17d-ce6f-45fb-9e42-03bd4c1f4f62", "28903e7b-aa3b-4840-b634-916029ed6c77", "322ac31c-0476-472a-b682-2ca3678d1df1", "382c5542-314f-46a3-aa2b-27b004a96f82", "3f303c85-3658-4c4f-bd86-68d21b03be94", "51a85bc2-a059-494f-8aed-25424733854c", "5ee1e223-768e-4934-a529-14bc4afe7c21", "707ad313-8047-4f3c-84c0-90cd574aeeec", "87533c2c-baaa-42e8-a809-5640037563f2", "a5f98cb3-bb50-48d0-97c5-124dec8780f4", "c2015c4e-e204-48ca-b9f8-c11079a896cb", "c3f07344-6f34-409f-8cca-6bde4491d546", "c62aeb0e-2b20-43ac-96ef-db993d5b8ada", "c75c7b08-7264-4daa-a133-59bea66db0c7", "ddef8d03-46e5-4df7-ac2d-ce48d54ba742", "e1f560b7-5852-4b4d-b04a-b9a5da00a994", "ec9bd2b2-cab8-451b-91d1-1161c403fefd", "ed543a19-85d9-427a-a2d3-88e7c59a100e"], "title": "Joint sentiment/topic model for sentiment analysis", "venue": "conference on information and knowledge management", "year": 2009, "id": "2ad2cdc1-907f-42ac-8a42-bc4702238357"}
{"authors": ["Thomas Hardjono", "Yuliang Zheng"], "n_citation": 65, "title": "A Practical Digital Multisignature Scheme Based on Discrete Logarithms", "venue": "international conference on the theory and application of cryptology and information security", "year": 1992, "id": "1e43cee1-9ca7-4e23-a05b-779af1e66507"}
{"abstract": "Omnidirectional views of an indoor environment at different locations are integrated into a global map. A single camera swiveling about the vertical axis takes consecutive images and arranges them into a panoramic representation, which provides rich information around the observation point: a precise omnidirectional view of the environment and coarse ranges to objects in it. Using the coarse map, the system autonomously plans consecutive observations at the intersections of lines connecting object points, where the directions of the imaging are estimated easily and precisely. From two panoramic views at the two planned locations, a modified binocular stereo method yields a more precise, but with direction-dependent uncertainties, local map. New observation points are selected to decrease the uncertainty, and another local map is yielded, which is then integrated into a more reliable global representation of the world with the adjacent local maps. >", "authors": ["Hiroshi Ishiguro", "Masashi Yamamoto", "Saburo Tsuji"], "n_citation": 327, "references": ["1dc438f1-4875-4491-81a1-f70e27b22565", "a12f313b-2f8f-459b-8fa3-a4b5f7c3e85a", "b75b30a8-f2c0-49b7-9283-a2b0c0f1f7a9", "c3ec3b14-75be-4b18-af66-195537226585", "da56cc81-32de-4032-8037-14ee21f754a6"], "title": "Omni-directional stereo", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 1992, "id": "d23ae511-a8ea-4f67-afca-d7014e37687e"}
{"abstract": "I show that the World Wide Web is a small world, in the sense that sites are highly clustered yet the path length between them is small. I also demonstrate the advantages of a search engine which makes use of the fact that pages corresponding to a particular search query can form small world networks. In a further application, the search engine uses the small-worldness of its search results to measure the connectedness between communities on the Web.", "authors": ["Lada A. Adamic"], "n_citation": 625, "references": ["c7e4e04b-45da-4bae-8c8a-d17ca0087361"], "title": "The Small World Web", "venue": "european conference on research and advanced technology for digital libraries", "year": 1999, "id": "ce115523-6b89-47ad-8cf3-1cb3e2a865d3"}
{"abstract": "Pex4Fun (http://www.pex4fun.com/) is a web-based educational gaming environment for teaching and learning programming and software engineering. Pex4Fun can be used to teach and learn programming and software engineering at many levels, from high school all the way through graduate courses. With Pex4Fun, a student edits code in any browser - with Intellisense - and Pex4Fun executes it and analyzes it in the cloud. Pex4Fun connects teachers, curriculum authors, and students in a unique social experience, tracking and streaming progress updates in real time. In particular, Pex4Fun finds interesting and unexpected input values (with Pex, an advanced test-generation tool) that help students understand what their code is actually doing. The real fun starts with coding duels where a student writes code to implement a teacher's secret specification (in the form of sample-solution code not visible to the student). Pex4Fun finds any discrepancies in behavior between the student's code and the secret specification. Such discrepancies are given as feedback to the student to guide how to fix the student's code to match the behavior of the secret specification. This tool demonstration shows how Pex4Fun can be used in teaching and learning, such as solving coding duels, exploring course materials in feature courses, creating and teaching a course, creating and publishing coding duels, and learning advanced topics behind Pex4Fun.", "authors": ["Nikolai Tillmann", "Jonathan de Halleux", "Tao Xie", "Judith Bishop"], "n_citation": 50, "references": ["00a76883-9e67-45eb-8c7d-fd228642b01e", "01755b6a-1062-4337-9d91-2ae5bbc38b1f", "08ef227a-0c9b-406e-ac9d-00be835ad0cc", "13c57286-b6b5-4beb-8547-dfb7d1cf40a5", "1a7a3cb2-cf94-4d92-a0b4-b46fa61d108e", "1e2e5e8d-0579-40b6-951d-eab8afdd759a", "2daddb7c-4357-4575-8408-4a880ca870d4", "312236d2-d0ef-4802-b85b-407cd3463dc3", "47a4cd07-1a37-4e47-b303-9b43e42b39c9", "51d59e49-f79b-43aa-b1f7-1342d447aa12", "52d55727-3e35-406c-bf8f-d8113ce03528", "5398b7c0-ec5a-4685-80fd-f80d2ea7b31f", "65f69b95-cf65-48fc-9ee4-f9c182e43524", "6a64a920-6e08-4e0e-9e1c-448d67e45bd4", "73c44872-ea2a-410a-bf1c-71ffa58c0762", "7e140371-0e8a-4904-bee1-ac68b04cc02f", "7fda2ad5-4685-4a4e-8685-356729cbcc33", "8081980d-80db-48ef-a80d-7e0b73c598ff", "82ef723b-7901-4412-9b40-dde4784014f6", "aa6ef426-fd57-4094-8ea5-713f7d719955", "ac038335-678a-4410-80ea-b3a4e71b11e2", "c0605401-28e9-4faf-821a-956c9230013a"], "title": "Pex4Fun: A web-based environment for educational gaming via automated test generation", "venue": "automated software engineering", "year": 2013, "id": "bbb04ac1-0cbf-4953-bda5-090d80658c4d"}
{"abstract": "Enterprise architecture management (EAM) is a challenging task, modern enterprises have to face. This task is often addressed via heavy-weight and expensive EAM tools to collect, structure, visualize and analyze architectural information. A major problem in EAM is the mismatch between the existing unstructured information sources and the rigid information structures and collaboration mechanisms provided by today's EAM tools.", "authors": ["Florian Matthes", "Christian Neubert"], "n_citation": 18, "references": ["6f423106-1699-471d-bdb3-4d39c1662c34", "b34e9bc7-aa14-47c0-a184-2cc2ad0ec860"], "title": "Wiki4EAM: using hybrid wikis for enterprise architecture management", "venue": "", "year": 2011, "id": "b8f52782-068b-4e49-9dd7-ceea543e216b"}
{"abstract": "Recognizing faces with complex intrapersonal variations is a challenging task, especially when using small size samples. Our approach, which obtains state of the art results, is based on a new face recognition scheme: Gabor-Eigen-Whiten-Cosine (GEWC). The novelty of this paper lies in 1) the finding that the same face with complex variations, projected into the Gabor based whitened PCA feature space, is approximately angle invariance; and 2) the experimental studies that analyze the joint contribution of Gabor wavelet, whitening process, and cosine similarity measure on the PCA based face recognition. The new GEWC method has been successfully tested and evaluated using comparative experiments on 3000+ FERET frontal face images with 1196 subjects. In particular, the GEWC method achieves constant 100% accuracy on the 200-subject experiment across illuminations and facial expressions. Furthermore, its recognition rates reach up to 96.3%, 99.5%, 78.8%, and 77.8% on the FB, fc, dup I, and dup II probes respectively using only one training sample per person.", "authors": ["Weihong Deng", "Jiani Hu", "Jun Guo"], "n_citation": 50, "references": ["00909251-9935-44f3-94a1-629023b5015b", "018498c0-b975-4f7e-9b04-cd61a0f018c1", "19aceabf-951f-45b5-809a-c17cc0539729", "31694e30-f279-4014-8a46-cf76272cd058", "40f728c0-55b3-423b-aff5-a9b3ff27b7d5", "54a5822c-e405-44ad-84e3-cea51e7349c2", "56f4b72a-ec39-47ac-8220-899296e7fb18", "5eb1916a-bbf2-4413-b5ba-589c62877ac0", "6e8cc926-79a1-4676-a2bd-f9d49f3144cf", "810f7115-00c6-42b2-bf8c-142b2a35ed57", "8835551e-08fe-468f-8523-3bc1752f41f3", "9792abba-296e-4de0-ae6e-c55651a7fdaf", "bf1d8c69-aefb-4a7a-8b02-f815b754833c", "d5e5a24d-f80e-4f1a-b48b-22403b653276", "ea12798a-feaf-4f04-b494-7834146f613a", "eec9070d-65e0-43bc-b5b8-96d0a49602b1", "fec9c952-e99e-40b8-b75f-dcd8f1f2b622"], "title": "Gabor-Eigen-Whiten-Cosine: a robust scheme for face recognition", "venue": "analysis and modeling of faces and gestures", "year": 2005, "id": "bda9e91f-c368-4e77-b1d2-3052b090b87a"}
{"abstract": "This paper presents an extension of the JADE agent development framework that may be the basis for the realization of flexible agent-based grid systems. In particular, JADE framework has been enriched with two new types of agents that, on the one hand simplify the distribution of tasks inside a grid of agent platforms, and, on the other hand, facilitate the composition of tasks through the use of production rules. Moreover, the paper describes how such kinds of operations are executed through the proper authentication and authorization mechanisms.", "authors": ["Agostino Poggi", "Michele Tomaiuolo", "Paola Turci"], "n_citation": 21, "references": ["3f32b54f-c583-4821-a0f9-4057c30ea016", "77028f45-51f7-4877-8cb3-ca14f632f67d", "7e0f299d-fdf0-42b2-8470-b71ae4d95295", "87bc2daf-8d61-4e48-8c63-e98cc4a2d749", "ae1823a4-40e0-4a1f-bb45-019e955ad8b4", "c75dc919-8d9a-4dd2-90a6-e882334ae0da"], "title": "Extending JADE for agent grid applications", "venue": "workshops on enabling technologies: infrastracture for collaborative enterprises", "year": 2004, "id": "5b17503d-ac69-4202-b367-c451834684d0"}
{"abstract": "As part of a project on automatic generation of proofs involving both logic and computation, we have automatically generated a proof of the irrationality of e. The proof involves inequalities, bounds on infinite series, type distinctions (between real numbers and natural numbers), a subproof by mathematical induction, and significant mathematical steps, including correct simplification of expressions involving factorials and summing an infinite geometrical series. Metavariables are instantiated by inference rules embodying mathematical knowledge, rather than only by unification. The proof is generated completely automatically, without any interactive component.", "authors": ["Michael J. Beeson"], "n_citation": 50, "references": ["20fc1313-5321-46ed-8486-f46d2e78363e", "28b93792-f079-4da9-808d-41ca0ca51032", "2f6e1f39-3fb6-46cf-838f-496e5f5c21b6", "54cc593a-837d-4c23-a44a-488acc2b75ea", "8da5ea16-1490-49dc-b041-b8026e8be33f", "dc6634e7-28f8-4b72-8002-f7231f80262c", "ef3d1340-44f3-4a6f-a67c-cdb04931ef74"], "title": "Automatic Derivation of the Irrationality of e", "venue": "Journal of Symbolic Computation", "year": 2001, "id": "df459c79-7d9d-4185-a723-6353017f3e91"}
{"abstract": "This paper presents a decomposition method for computing the 2-edge-connected reliability of undirected networks. This reliability is defined as the probability that all the vertices of a given graph G are 2-edge-connected, when edges fail independently with known probabilities. The principle of this method was introduced by Rosenthal in 1977 [1]. For the all terminal reliability problem it consists in enumerating specific state classes of some subnetworks. These classes are represented by the partitions of the boundary sets. For the 2-edge-connected reliability problem these classes are represented by labeled forests whose nodes are the partition blocks and some ``unidentified'' blocks. Our implementation uses a vertex linear ordering. The computational complexity depends on the number of classes, which depends on the vertex separation number of a given vertex linear ordering. Our computational results show the efficiency of this method when the vertex separation number is smaller than 7.", "authors": ["Corinne Lucet", "Jean-Francois Manouvrier", "Jacques Carlier"], "n_citation": 50, "references": ["24a7e3f2-c52a-4c4b-ab1a-9c57b13eeb41", "56497ea5-0d68-47e6-bd79-d04f30a91abc", "61d25f25-8c2b-431d-95bc-4462422482fc", "62574a32-7d2c-458b-9554-25948ed1c1c2", "6883be5c-4480-4460-9161-b4ed81103638", "7fd28178-6604-4dae-8887-be260191dc6b", "7fe187ac-ddb4-475c-b40f-172e16732631", "9f94fdf6-8dbd-4944-9353-233620c51b12", "ad36caaa-b76d-473d-b527-259ed17be31e", "b9d22933-f130-48ae-8e37-278289013c1c", "ba56e820-31bd-46fd-93c1-91391aaba599", "c454bdc9-60ad-4127-84fe-abbb45ba3a76", "d6d4ad6a-37d6-4105-9000-336efe519286", "e72cad2b-f79c-4b24-a7ac-a3238cf377a6", "e7b60a53-f74d-45f4-9f42-57119578a65a"], "title": "Evaluating Network Reliability and 2-Edge-Connected Reliability in Linear Time for Bounded Pathwidth Graphs", "venue": "Algorithmica", "year": 2000, "id": "9e5857f7-096d-44fc-871f-e8ec1af9be19"}
{"abstract": "Actor-oriented languages provide a component composition methodology that emphasizes concurrency. The interfaces to actors are parameters and ports (vs. members and methods in object-oriented languages). Actors interact with one another through their ports via a messaging schema that can follow any of several concurrent semantics (vs. procedure calls, with prevail in OO languages). Domain-specific actor-oriented languages and frameworks are common (e.g. Simulink, LabVIEW, and many others). However, they lack many of the modularity and abstraction mechanisms that programmers have become accustomed to in 00 languages, such as classes, inheritance, interfaces, and polymorphism. This extended abstract shows the form that such mechanisms might take in AO languages. A prototype of these mechanisms realized in Ptolemy II is described.", "authors": ["Edward A. Lee", "Stephen Neuendorffer"], "n_citation": 39, "references": ["0ad112b1-0567-4ebc-8c2f-183e88757a0a", "77d62820-c794-4375-b531-1e3b9a2878bd", "af4cc774-cab4-4888-9bcf-f29449a58e56", "b6c465ae-cc45-468a-8b2a-971bfc7af92d", "b75e0d44-f947-4922-be73-5e1fb7512fae", "ceeedf74-d74a-4d09-8f44-2fab5922459f", "d3e62456-2206-48a2-a87d-a3aa1f26cbdb", "f5950ff8-0538-4bf0-8c4d-60157f4deadf"], "title": "Classes and subclasses in actor-oriented design", "venue": "international conference on formal methods and models for co design", "year": 2004, "id": "7a69c609-cb6b-42fb-98c4-e13e696713fc"}
{"abstract": "The objective of this paper is to determine under what circumstances individual organizations would be able to rely on cross-company-based estimation models. We performed a systematic review of studies that compared predictions from cross-company models with predictions from within-company models based on analysis of project data. Ten papers compared cross-company and within-company estimation models; however, only seven presented independent results. Of those seven, three found that cross-company models were not significantly different from within-company models, and four found that cross-company models were significantly worse than within-company models. Experimental procedures used by the studies differed making it impossible to undertake formal meta-analysis of the results. The main trend distinguishing study results was that studies with small within-company data sets (i.e., $20 projects) that used leave-one-out cross validation all found that the within-company model was significantly different (better) from the cross-company model. The results of this review are inconclusive. It is clear that some organizations would be ill-served by cross-company models whereas others would benefit. Further studies are needed, but they must be independent (i.e., based on different data bases or at least different single company data sets) and should address specific hypotheses concerning the conditions that would favor cross-company or within-company models. In addition, experimenters need to standardize their experimental procedures to enable formal meta-analysis, and recommendations are made in Section 3.", "authors": ["Barbara Kitchenham", "Emilia Mendes", "Guilherme Horta Travassos"], "n_citation": 299, "references": ["1cdbd9db-1370-453d-bed1-c984cd43166b", "526a3151-1a0f-4234-b4fa-b48c95ee13fe", "549234cb-5111-460c-bbf1-d8c134761b41", "55c89fc4-00c3-4110-9f2c-135bebbf686f", "58fb5be6-2bae-4742-b97f-eaabd11e854e", "71dccbab-f3a5-4a26-8363-b2a524f5d4bc", "8d60cba6-a96a-490e-bf0d-730de7935435", "bc1bdbe0-9a74-49b9-a497-02fdf0189fad", "cba62fd5-453c-46c1-bd1d-5830e02dded4", "d0035c55-223b-4313-9728-7e52a9555500", "da8699ff-971e-441d-adda-dab71879df56", "e3bb8912-cf4c-4fdd-bf42-b5cc607b2fba", "fa1265ec-82a4-4d58-87fe-f6cf8418035a"], "title": "Cross versus Within-Company Cost Estimation Studies: A Systematic Review", "venue": "IEEE Transactions on Software Engineering", "year": 2007, "id": "1eb3a4e4-e6a5-49ab-bb53-06c09eeda046"}
{"abstract": "The characteristics of cybercriminals, cybercrime victims, and law enforcement agencies have a reinforcing effect on each other, leading to a vicious circle of cybercrime. In this article, the author assessed the cost-benefit structure of cybercriminals. From the potential victims' perspectives, an economic analysis can help explain the optimum investment necessary as well as the measures required to prevent hackers from cracking into their computer networks. The analysis from the cybercriminal's viewpoint also provides insight into factors that might encourage and energize his or her behavior.", "authors": ["Nir Kshetri"], "n_citation": 124, "references": ["705b2b92-caef-4368-a2f4-306238f9cd01"], "title": "The simple economics of cybercrimes", "venue": "ieee symposium on security and privacy", "year": 2006, "id": "86e819dc-694c-4cff-839e-704432c8c013"}
{"abstract": "Formal AI systems traditionally represent knowledge using logical formulas. We will show, however, that for certain kinds of information, a model-based representation is more compact and enables faster reasoning than the corresponding formula-based representation. The central idea behind our work is to represent a large set of models by a subset of characteristic models. More specifically, we examine model-based representations of Horn theories, and show that there are large Horn theories that can be exactly represented by an exponentially smaller set of characteristic models.#R##N##R##N#In addition, we will show that deduction based on a set of characteristic models takes only linear time, thus matching the performance using Horn, theories. More surprisingly, abduction can be performed in polynomial time using a set of characteristic models, whereas abduction using Horn theories is NP-complete.", "authors": ["Henry A. Kautz", "Michael J. Kearns", "Bart Selman"], "n_citation": 91, "references": ["3d4e9d30-b15a-47ae-8e96-a51d34ae1187", "5dff42ad-e16b-4b6a-bce3-fe808d109177", "5fd02b86-6bb4-43f6-a169-70b4fc4b1da8", "76c0a875-0556-4af6-8564-5a4843b57bdd", "a51d4933-da3b-4c41-9937-cf0ddde36d00", "dfa85395-3891-417f-a7bb-c862821ba116"], "title": "Reasoning with characteristic models", "venue": "national conference on artificial intelligence", "year": 1993, "id": "845e5a60-eca1-45f5-9ccf-1a39682245b3"}
{"abstract": "Cloud Patterns are abstract solutions to recurrent design problems in the cloud. Previous work has shown that these patterns can improve the Quality of Service (QoS) of cloud applications but their impact on energy consumption is still unknown. Yet, energy consumption is the biggest challenge that cloud computing systems (the backbone of today's high-tech economy) face today. In fact, 10% of the world's electricity is now being consumed by servers, laptops, tablets and smartphones. Energy consumption has complex dependencies on the hardware platform, and the multiple software layers. The hardware, its firmware, the operating system, and the various software components used by a cloud application, all contribute to determining the energy footprint. Hence, even though increasing a data center efficiency will eventually improve energy efficiency, the internal design of cloud-based applications can be improved to lower energy consumption. In this paper, we conduct an empirical study on a RESTful multi-threaded application deployed in the cloud, to investigate the individual and the combined impact of three cloud patterns (e.g., Local Database proxy, Local Sharding Based Router and Priority Queue) on the energy consumption of cloud based applications. We measure the energy consumption using Power-API; an application programming interface (API) written in Java to monitor the energy consumed at the process-level. Results show that cloud patterns can effectively reduce the energy consumption of a cloud application, but not in all cases. In general, there appear to be a trade-off between an improved response time of the application and the energy consumption. Developers and software architects can make use of these results to guide their design decisions.", "authors": ["S. Amirhossein Abtahizadeh", "Foutse Khomh", "Yann-Ga\u00ebl Gu\u00e9h\u00e9neuc"], "n_citation": 3, "references": ["39d44317-7fe1-4fec-86ac-5cb68d40d269", "4b9fd198-0d7a-456a-aa05-9a33c371f1d3", "4f67e6ff-4641-4c16-9987-4bef8813b578", "50ee006f-b4d6-4bd3-bdfd-b3914a5fb889", "66d0b18e-c052-4c23-b262-73acc9d32814", "78ee470c-8ec1-4512-8ebe-7c6331c9fe70", "ac915576-1679-4d18-ae59-1194a0c60c0c", "b903f2a2-f03d-4c2c-a150-8271fb00ff88", "baa51c9a-50f7-4ef7-8c2c-ed9e2fd24d38", "bc3945b0-e3a0-44d4-8b3c-34577e621c84", "c6155a9c-bbbf-4656-b110-a7bef1d8b8e7", "f4ec9649-e944-4e20-a0cf-f7c04c11ffdd"], "title": "How green are cloud patterns", "venue": "international performance computing and communications conference", "year": 2015, "id": "a6e49f48-d093-478d-af8c-121b2f369ba6"}
{"abstract": "We describe the detrimental effects of browser cache/history sniffing in the context of phishing attacks, and detail an approach that neutralizes the threat by means of URL personalization; we report on an implementation performing such personalization  on the fly , and analyze the costs of and security properties of our proposed solution.", "authors": ["Markus Jakobsson", "Sid Stamm"], "n_citation": 81, "references": ["22e802be-a9cc-4513-b626-1e721acf2c9b", "94afd6db-521d-4506-8d18-b5551c5f0750"], "title": "Invasive browser sniffing and countermeasures", "venue": "international world wide web conferences", "year": 2006, "id": "db21af73-43a5-42a1-8ef4-167c784e8037"}
{"abstract": "Shared counters are among the most basic coordination structures in multiprocessor conputation, with applications ranging from barrier synchronization to concurrent-data-structure design. This article introduces diffracting trees, novel data structures for share counting and load balancing in a distributed/parallel environment. Empirical evidence, collected on a simulated distributed shared-memory machine and several simulated message-passing architectures, shows that diffracting trees scale better and are more robust than both combining trees and counting networks, currently the most effective known methods for implementing concurrent counters in software. The use of a randomized coordination method together with a combinatorial data structure overcomes the  resiliency drawbacks of combining trees. Our simulations show that to handle the same load, diffracting trees and counting networks should have a similar width  w , yet the depth of a diffracting tree is  O (log  w ), whereas counting networks have depth  O (log 2   w ). Diffracting trees have already been used to implement highly efficient producer/consumer queues, and we believe diffraction will prove to be an effective alternative paradigm to combining and queue-locking in the design of many concurrent data structures.", "authors": ["Nir Shavit", "Asaph Zemach"], "n_citation": 126, "references": ["084e81f9-0734-4bd0-8ea2-8c9b7db30ef1", "0a53f8ca-2b80-41f3-a189-eb463c2c2d97", "23b58bbd-08d7-4c2e-9ba3-5f301fdaf5e8", "26d52478-9962-431a-9d52-8d91698c5f3e", "35ded88b-0430-46ae-aad4-fd3c27806c03", "45c56491-f555-4956-8293-0e44bbcd977d", "4757ce83-5af8-4deb-8ba3-ceb36df4c797", "51156bcd-3300-4243-87d1-1059f26b193f", "6205e185-46e2-4839-9db6-0d78ab0f9794", "66d86606-27a5-4b17-9a15-66fb987be6b2", "794322f5-292e-42f7-bb34-8a22d7446184", "850261a0-5d60-4792-8f19-e08ee366f9a5", "8e0a5df1-b80e-4533-9e78-e7122742e142", "9148bddf-aff3-4b1e-b281-66d2ec71058f", "98db48cc-68f2-4464-ac90-a02fcfc37e48", "a2b03559-9aee-4774-914f-2a511c66d1bf", "b8b9c7f4-d047-4178-859b-be408d931bc1", "be477453-14dc-4aef-a860-8727195f46c5", "be4da927-e149-4001-86f5-57f25faa5bfe", "c3c37374-e04f-49c7-9983-e1e2c6c2aacc", "c4f8b573-cf3f-4bfd-a78d-fe00a1c33d4e", "ec452cf7-daa7-468a-81b3-5f69af655cb3", "f1c1e165-c1ca-4fe1-bae0-7079c3c137cf", "f20482cc-f6f6-45e7-bd6a-439974b0e7a8"], "title": "Diffracting trees", "venue": "ACM Transactions on Computer Systems", "year": 1996, "id": "4b6d772f-3925-457f-849f-e1f33524934e"}
{"abstract": "In this work, we propose to expand the application of model predictive control (MPC) to problems in which there are human agents involved in the sensing and actuation processes. To this end, a new configuration of a control system structure that combines centralized predictive control and local operations is presented. Additional constraints are included in the optimization problem to take into account the mobility and the role of the operators over the prediction horizon. This new type of control system structure, referred to as Mobile Model Predictive Control (MoMPC), is tested on a linear model of a large scale irrigation canal and its performance is compared to centralized MPC and manual operation.", "authors": ["J. M. Maestre", "P. J. van Overloop", "Maryam Hashemy", "Anna Sadowska", "Eduardo F. Camacho"], "n_citation": 50, "references": ["98f82fd6-6c37-4bae-8281-6158c7823b9d", "9f877cf5-69f7-4e53-9ce5-ce38a87b4498", "d77111f4-71de-414f-a6fc-9ed6affa0d5e", "f5c791aa-eded-48ea-9525-16ec05a1df6e"], "title": "Human in the loop model Predictive Control: an irrigation canal case study", "venue": "conference on decision and control", "year": 2014, "id": "e975ab7b-fd26-4c48-a7c7-d4f6202b78e0"}
{"abstract": "Indoor localization systems are undoubtedly of interest in many application fields. Like outdoor systems, they suffer from nonline-of-sight (NLOS) errors which hinder their robustness and accuracy. Though many ad hoc techniques have been developed to deal with this problem, unfortunately most of them are not applicable indoors due to the high variability of the environment (movement of furniture and of people, etc.). In this paper, we describe the use of robust regression techniques to detect and reject NLOS measures in a location estimation using multilateration. We show how the least-median-of-squares technique can be used to overcome the effects of NLOS errors, even in environments with little infrastructure, and validate its suitability by comparing it to other methods described in the bibliography. We obtained remarkable results when using it in a real indoor positioning system that works with Bluetooth and ultrasound (BLUPS), even when nearly half the measures suffered from NLOS or other coarse errors.", "authors": ["Roberto Casas", "\u00c1lvaro Marco", "Jos\u00e9 Jes\u00fas Guerrero", "Jorge L. Falc\u00f3"], "n_citation": 187, "references": ["3939cb96-d8c8-4ec4-8102-bbce2976aeee", "55ba4087-0a50-497c-8660-67eff673d7b6", "6e1f317d-1608-4e91-9cfc-d9abd67b32b1", "6e3ef5bc-bdf8-4b98-b844-3a9b91549018", "73ecfa90-e006-419e-8f13-b07e98ece218", "8c38f836-d2e2-4295-b476-118f28d97608", "8dec2619-1fcf-46be-bc2e-be3c1f75b0b9", "b72ef385-f390-497c-812d-85d77963045c", "e143a367-44c9-46e7-910a-3e9177140e0c", "ebfca554-7a3c-4597-954b-07336a2e3030", "f8a9df79-9be7-4333-a71c-327040f67fcd"], "title": "Robust estimator for non-line-of-sight error mitigation in indoor localization", "venue": "EURASIP Journal on Advances in Signal Processing", "year": 2006, "id": "19f28afa-2c56-4332-8a0d-2ba583c8b6ad"}
{"abstract": "From the Publisher:#R##N#This text provides an up-to-date treatment of the fundamental techniques and algorithms for numerical analysis of deterministic and stochastic Petri nets, a particular stochastic modelling formalism, and the application of this modelling formalism to performance analysis for parallel computer architectures.", "authors": ["Christoph Lindemann"], "n_citation": 181, "title": "Performance Modelling with Deterministic and Stochastic Petri Nets", "venue": "measurement and modeling of computer systems", "year": 1998, "id": "8f00a63e-fb1f-41be-9717-0b2749776687"}
{"abstract": "This paper discusses how to utilize both magnitude and phase information obtained from the complex directional filter bank (CDFB) for the purpose of texture image retrieval. The relative phase, which is the difference of phases between adjacent CDFB coefficients, has a linear relationship with the angle of dominant orientation within a subband. This information is incorporated to form a new feature vector called CDFB-RP. Texture retrieval performance of the proposed CDFB-RP is compared to those of the conventional transforms including the Gabor wavelet, the contourlet transform, the steerable pyramid and the CDFB. With the same number of features, the CDFB-RP method outperforms all other transforms in texture image retrieval, while keeping lower complexity and computational time.", "authors": ["An P. N. Vo", "Soontorn Oraintara", "Truong T. Nguyen"], "n_citation": 59, "references": ["09346dc3-f4d0-43a4-8f0b-27e02bcd336e", "28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb", "62a46780-e1d9-4186-babe-6179735d785e", "b5fc6aed-ae1c-4ad0-996a-b385bcb6c9fd", "b9f199fc-6ddb-4710-a12e-ed0354478e81", "def7ed5f-a675-4035-b1a3-5b7070f2dfca", "f20c15bc-b667-4415-a228-3c93e3e3be3c", "f4e766ac-f68f-4829-a5f8-bc8751f57948"], "title": "Using Phase and Magnitude Information of the Complex Directional Filter Bank for Texture Image Retrieval", "venue": "international conference on image processing", "year": 2007, "id": "ccc4a767-d478-4ef4-90e6-cc8a065dc725"}
{"abstract": "Achieving the Nash equilibria for single objective games is known to be a computationally difficult problem. However there is a special class of equilibria called evolutionary robust equilibria which can be obtained through a special type of evolutionary dynamics called the replicator dynamics. This dynamics has special properties over the simplex, which has been studied in optimization theory to solve several combinatorial problems. In this work, we consider the essentially hard combinatorial optimization problem of computing the equilibria in games with multiple objectives. We extend the notion of replicator dynamics to handle such games. We establish proofs of dynamic stability of this modified replicator dynamics and present their relation to the Pareto Nash equilibria in multi-objective games.", "authors": ["Kiran K. Somasundaram", "John S. Baras"], "n_citation": 9, "references": ["4ef16c31-5c8d-4256-84d2-9f09d38b74a3", "af3dcf0c-6e6f-4190-a9d6-9a9d2551e378"], "title": "Achieving symmetric Pareto Nash equilibria using biased replicator dynamics", "venue": "conference on decision and control", "year": 2009, "id": "f6b8299b-1b9a-4fb5-b8c9-f81b583950d6"}
{"abstract": "Parallel programmers typically assume that all resources required for  a program's execution are dedicated to that purpose. However, in local and wide area networks, contention for shared networks, CPUs, and I/O systems can result in significant variations in availability, with consequent adverse effects on overall performance. We describe a new message-passingarchitecture, MPICH-GQ, that uses quality of service (QoS) mechanisms to manage contention and hence improve performance of message passing interface (MPI) applications. MPICH-GQ combines new QoS specification, traffic shaping, QoS reservation, and QoS implementation techniques to deliver QoS capabilities to the high-bandwidth bursty flows, complex structures, and reliable protocols used in high-performance applications-characteristics very different from the low-bandwidth, constant bit-rate media flows and unreliable protocols for which QoS mechanisms were designed. Results obtained on a differentiated services testbed demonstrate our ability to maintain application performance in the face of heavy network contention.", "authors": ["A. Roy", "Ian T. Foster", "William Gropp", "Brian R. Toonen", "Nicholas T. Karonis", "Volker Sander"], "n_citation": 66, "references": ["2047bcc7-a5f7-4d3c-bf69-5705174f8081", "352caa76-f117-4f58-aa90-ea6f7f0472da", "38e075c6-7796-47a8-ac1d-9145516af456", "3f7f755b-cc31-437d-8e73-9d7ce711d33a", "456f540d-48a0-4382-a2ac-585864a336eb", "4b049725-4fde-4251-8138-71cabdede99f", "5801b85d-ea1f-4634-b861-6a02039303c3", "68414a1e-11d6-4d1e-bff0-eef3f924a691", "726a2730-1df7-4e37-906e-4226c2043207", "79018045-303b-45d7-b2ef-257df036ed8c", "802a713d-b2c8-4481-80e2-fdd4deaf54c1", "a2b3d9f4-a58d-4235-952c-d8abe38b9caf", "a335ef74-e22b-4162-93ad-10fe8a020830", "a37c8ae2-443c-4933-ac45-6ffb41354d2d", "a40c85a4-d533-4a2c-bc16-ae94591ac628", "b472a441-1c7f-48a9-90df-f03306181097", "d1503e76-7721-4fa0-bbbf-c63c15d5b033", "d825e29f-3708-41df-bc27-09752d1cb639", "e4e92e07-a222-4386-9f7b-cdcf1ddaf2f3"], "title": "MPICH-GQ: Quality-of-Service for Message Passing Programs", "venue": "supercomputing conference", "year": 2000, "id": "395ac3f5-c2b5-4fb8-b21f-318ddb2feb45"}
{"abstract": "As intermittent renewable energy penetrates electrical power grids more and more, assessing grid reliability is of increasing concern for grid operators. Monte Carlo simulation is a robust and popular technique to estimate indices for grid reliability, but the involved computational intensity may be too high for typical reliability analyses. We show that various reliability indices can be expressed as expectations depending on the rare event probability of a so-called power curtailment, and explain how to extend a Crude Monte Carlo grid reliability analysis with an existing rare event splitting technique. The squared relative error of index estimators can be controlled, whereas orders of magnitude less workload is required than when using an equivalent Crude Monte Carlo method. We show further that a bad choice for the time step size or for the importance function may endanger this squared relative error.", "authors": ["Wander Wadman", "Daan Crommelin", "Jason Frank"], "n_citation": 50, "references": ["0807682f-0232-45bc-be9d-dd31d39abe92", "6e7ec513-f152-42fb-8a02-2b6c2b9a2151"], "title": "Applying a splitting technique to estimate electrical grid reliability", "venue": "winter simulation conference", "year": 2013, "id": "e047ad13-8434-4810-8795-437523215652"}
{"abstract": "In this series of papers we set out to generalize the notion of classical analytic deduction (i.e., deduction via elimination rules) by combining the methodology of labelled deductive systems (LDS) with the classical systemKE. LDS is a unifying framework for the study of logics and of their interactions. In the LDS approach the basic units of logical derivation are not just formulae butlabelled formulae, where the labels belong to a given \u201clabelling algebra\u201d. The derivation rules act on the labels as well as on the formulae, according to certain fixed rules of propagation. By virtue of the extra power of the labelling algebras, standard (classical or intuitionistic) proof systems can be extended to cover a much wider territory without modifying their structure. The systemKE is a new tree method for classical analytic deduction based on \u201canalytic cut\u201d.KE is a refutation system, like analytic tableaux and resolution, but it is essentially more efficient than tableaux and, unlike resolution, does not require any reduction to normal form.", "authors": ["Marcello D'Agostino", "Dov M. Gabbay"], "n_citation": 108, "references": ["0bac9889-f157-4189-ba3d-4b2dbee1f69b", "38b054f9-ddb9-455d-b51d-5aaebc8569cd", "3c00f934-dd6b-4bad-b4d8-971051317ee8", "4d71f800-3995-43b3-bb54-82b989be30f5", "956ba5d3-12f5-4ded-83f5-b84df4b4c6be", "d5b5a9ea-495a-4e11-b334-efa8113b2ad4", "d64d95a1-575a-47cf-a392-35d40bddc6ce"], "title": "A generalization of analytic deduction via labelled deductive systems. Part I: Basic substructural logics", "venue": "Journal of Automated Reasoning", "year": 1994, "id": "90620859-4789-444e-9d7d-bcf70c005cc5"}
{"abstract": "This paper presents a unifying procedure, called Facet, for the automated synthesis of data paths at the register-transfer level. The procedure minimizes the number of storage elements, data operators, and interconnection units. A design generator named Emerald, based on Facet, was developed and implemented to facilitate extensive experiments with the methodology. The input to the design generator is a behavioral description which is viewed as a code sequence. Emerald provides mechanisms for interactively manipulating the code sequence. Different forms of the code sequence are mapped into data paths of different cost and speed. Data paths for the behavioral descriptions of the AM2910, the AM2901, and the IBM System/370 were produced and analyzed. Designs for the AM2910 and the AM2901 are compared with commercial designs. Overall, the total number of gates required for Emerald's designs is about 15 percent more than the commercial designs. The design space spanned by the behavioral specification of the AM2901 is extensively explored.", "authors": ["Chia-Jeng Tseng", "Daniel P. Siewiorek"], "n_citation": 698, "references": ["099ab808-c88e-47eb-98ba-57be5e6a12da", "1edfc050-3153-4557-8f83-0d165ef6d5ca", "4fc02412-972e-4969-aeb1-b48c9298bbbf", "645cf0cf-4aac-4ed6-8b6b-aa3d4ec3740f", "7d47e0d2-68c6-4e02-a483-63b779fe481a", "83c30994-bc9e-41e3-bae8-0629a33df3da", "9f8b2448-97db-40a7-9c45-56f6a239d2cf", "cf27df92-2a33-4c9c-97af-ad6d91cf1c0d", "eed9c0c5-0ef6-4a84-b0da-891d951d87a6", "f40ac54c-d315-43cf-883b-883b57cf0460"], "title": "Automated Synthesis of Data Paths in Digital Systems", "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems", "year": 1986, "id": "c24c3277-3af9-4a53-828c-c3d6448e7402"}
{"abstract": "This paper studies the load reduction potential of a prototyped \u201csmart\u201d rotor. This is, a rotor where the blades are equipped with a number of control devices that locally change the lift profile on the blade, combined with appropriate sensors and controllers. Experimental models, using dedicated system identification techniques, are developed of a scaled rotating two-bladed \u201csmart\u201d rotor of which each blade is equipped with trailing-edge flaps and strain sensors. A feedback controller based on H \u221e -loop shaping combined with a fixed-structure feedforward control are designed that minimizes the root bending moment in the flapping direction of the two blades. We evaluated the performance using a number of different realistic load scenarios. We show that with appropriate control techniques the variance of the load signals can be reduced up to 90%.", "authors": ["Jan-Willem van Wingerden", "A.W. Hulskamp", "Thanasis K. Barlas", "Ivo Houtzager", "H.E.N. Bersee", "Gijs van Kuik", "Michel Verhaegen"], "n_citation": 61, "references": ["3433ff16-3c11-4986-baf8-0a46df07714b", "9a994ade-1d0f-49d5-baea-367cb5865993", "9ad18aa0-438d-4740-8929-40c307ae1479"], "title": "Two-Degree-of-Freedom Active Vibration Control of a Prototyped \u201cSmart\u201d Rotor", "venue": "IEEE Transactions on Control Systems and Technology", "year": 2011, "id": "ef83ea6c-4e08-429f-acaa-fa909ffc0887"}
{"abstract": "In this paper we present a method for 3-D reconstruction of human bodies with application in CAD systems for garment design. The reconstruction scheme uses image information from several arbitrary views and deformable superquadrics as the models of the body parts. Two visual cues are used: occluding contours and stereo (possibly aided by projected patterns). Our preliminary experiments show that the reconstruction is more complete than in purely stereo or structured light based methods and more precise than the reconstruction from occluding contours only. From the reconstructed human body, the body measurements can be taken automatically, and used in garment design. We give an example of draping of virtual garment over the photo-realistic 3D model of the imaged human. One can easily envision the use of the described algorithms in the development of custom-fit garment retail software over the Internet, which would include the possibility of trying the garment on in virtual reality.", "authors": ["Nebojsa Jojic", "Jin Gu", "Ivan Mak", "Helen C. Shen", "Thomas S. Huang"], "n_citation": 50, "references": ["08a26993-c1db-49c2-81c6-49ea31c81848", "1850fd27-1157-4db8-bd63-4641911b7ab4", "3324e5ad-34c4-4dfd-a90f-d0166d6d9a8c", "794d9a5b-4b03-46dd-a773-503fcad0b01b", "8b314f36-5ac9-41bf-b72d-bb3d6a3deeaf", "d24e626d-ca9c-4475-9c81-40bb863b0fdb", "e44dc0fd-dcf7-43b4-8f27-4cea26c6611c"], "title": "Computer modeling, analysis and synthesis of dressed humans", "venue": "computer vision and pattern recognition", "year": 1998, "id": "7fada30b-5ab0-4746-b1fd-dd1714b37ff6"}
{"authors": ["Stephen Muggleton"], "n_citation": 146, "title": "Inductive acquisition of expert knowledge", "venue": "", "year": 1986, "id": "2740ea82-01cc-4e9f-9215-65caade448df"}
{"abstract": "This paper presents a conceptual framework to successfully integrate electric vehicles into electric power systems. The proposed framework covers two different domains: the grid technical operation and the electricity markets environment. All the players involved in both these processes, as well as their activities, are described in detail. Additionally, several simulations are presented in order to illustrate the potential impacts/benefits arising from the electric vehicles grid integration under the referred framework, comprising steady-state and dynamic behavior analysis.", "authors": ["J.A.P. Lopes", "F. J. Soares", "Pedro Almeida"], "n_citation": 855, "references": ["37985dd2-5b3b-4988-961d-4909adb52e80", "69bf79d2-af04-48d7-9593-6e31b4e6fa0b", "dd263c02-f143-4428-8ccc-6ea4c3023ef4"], "title": "Integration of Electric Vehicles in the Electric Power System", "venue": "Proceedings of the IEEE", "year": 2011, "id": "fdaed35e-f7ba-4de3-be19-89a57027f7cb"}
{"abstract": "Fault and attack management has become a very important issue for network operators that are interested to offer a secure and resilient network capable to prevent and localize, as accurately as possible, any failure (fault or attack) that may occur. Hence, an efficient failure location method is needed. To locate failures in opaque optical networks, existing methods which allow monitoring of the optical signal at every regeneration site can be used. However, to the best of our knowledge, no method exists today that performs failure location for transparent optical networks. Such networks are more vulnerable to failures than opaque networks since failures propagate without being isolated due to optoelectronic conversions. In this paper, we present a failure location algorithm that aims to locate single and multiple failures in transparent optical networks. The failure location algorithm developed in this paper can cope with ideal scenarios (i.e., no false and/or lost alarms), as well as with nonideal scenarios having false and/or lost alarms.", "authors": ["Carmen Mas", "Ioannis Tomkos", "Ozan K. Tonguz"], "n_citation": 155, "references": ["98c6e82c-4f64-4753-9c39-3760aca70577", "9b551260-4794-4660-8081-853a82927de8", "b8ab0592-860c-44ca-9264-ba3e11fe718e"], "title": "Failure location algorithm for transparent optical networks", "venue": "IEEE Journal on Selected Areas in Communications", "year": 2005, "id": "484bf54a-d71d-4787-8391-b5086532f95d"}
{"abstract": "We introduce an optimization approach for solving problems in computer vision that involve multiple levels of abstraction. Our objective functions include compositional and specialization hierarchies. We cast vision problems as inexact graph matching problems, formulate graph matching in terms of constrained optimization, and use analog neural networks to perform the optimization. The method is applicable to perceptual grouping and model matching. Preliminary experimental results are shown.", "authors": ["Eric Mjolsness", "Gene Gindi", "P. Anandan"], "n_citation": 85, "references": ["28baa713-3f4f-421b-b140-e1e46b0e7012", "3a55b343-9430-48b9-b2dc-3c28055f5624", "936e0ae4-e6e1-4b3b-9d0a-a6bff589fc7b"], "title": "Optimization in model matching and perceptual organization", "venue": "Neural Computation", "year": 1989, "id": "d6ede40e-7ad9-477e-bb3a-2c0bbae93131"}
{"abstract": "This note presents an alternative approach to classical adaptive notch filters designed to identify the frequency, magnitude, phase and offset of a biased sinusoidal signal. The algorithm takes advantages of an adaptive law for the resonant frequency of a third-order generalized integrator as a part of an orthogonal-signals generator system. The resulting estimator presents a dynamic order equal to 4. The strength of the discussed strategy results in a fast and accurate signal tracking capability and a good rejection to noise. The properties of the algorithm are verified in simulations in a range of signal conditions, such as step and sweep changes in frequency and voltage sag confirming the effectiveness of the strategy for estimation and tracking of time-varying parameters.", "authors": ["Giuseppe Fedele", "Andrea Ferrise", "Pietro Muraca"], "n_citation": 50, "references": ["07a1f0ca-8fdf-4399-b022-dc7fb16c5543", "0eaa8968-af90-4193-8f4a-426cc82696c7", "11f08939-b873-4efe-996b-e47ba7f2b6ea", "41343821-bb3d-432c-b533-cb5f53c2cf3d", "53eb436b-27a6-4497-86a9-364a7cbabbc4", "6a3e8290-a664-4120-b6f1-17ee4e70d76a", "84f4eb58-973c-4056-8c34-713cb8cf8a2b", "8ce40fec-1fc2-4a5d-96da-fbf814a7ab4c", "981a5c72-04a7-4b2c-906c-68926e4848f4", "cc1785ab-6560-4807-a1c8-6243223415ed", "e8bf3100-1048-471c-8c10-870fea116196", "f511384c-5de0-4eb2-9a25-5968a42be77c"], "title": "An adaptive quasi-notch filter for a biased sinusoidal signal estimation", "venue": "international conference on control and automation", "year": 2011, "id": "ccd37e61-8c32-4506-b490-ce08b2712889"}
{"abstract": "Abstract   Understanding actions involves inferring the goal of the actor and organizing the actions into a plan structure. The BELIEVER system is a psychological theory of how human observers understand the actions of others. The present theory is concerned with single-actor sequences and can account for goal-directed actions that may succeed or fail in accomplishing the goal, as well as actions governed by norms. After discussing how AI can be applied in psychological theory construction, the BELIEVER system is presented by specifying a plan recognition process and its knowledge sources.", "authors": ["Charles F. Schmidt", "N. S. Sridharan", "John L. Goodson"], "n_citation": 222, "references": ["0d492748-e162-42b7-889e-f05ad7ca3855", "29cc6445-b1fa-4e83-bc43-c06d13ab587b", "5818a135-7a90-4f13-b092-e211e573aaf2", "6dcdd2ad-b86b-4b4d-b031-66485f9bbece", "8b45ae09-3cb2-463f-aa0d-b3877528ef50", "91ad0982-4975-4f94-b0c6-1341d388a392", "97c37394-3041-4a05-8e96-1648778f8e07", "d12c67ad-a58c-4753-bbf7-83c33e586336", "eb04a53a-82bc-473d-9aca-a322bd5f83a4"], "title": "The plan recognition problem: An intersection of psychology and artificial intelligence", "venue": "Artificial Intelligence", "year": 1978, "id": "83c5664b-549a-4ee3-b884-f9a9681d6b70"}
{"abstract": "PROTEUS is a high-performance simulator for MIMD multiprocessors. It is fast, accurate, and flexible: it is one to two orders of magnitude faster than comparable simulators, it can reproduce results from real multiprocessors, and it is easily configured to simulate a wide range of architectures. PROTEUS provides a modular structure that simplifies customization and independent replacement of parts of architecture. There are typically multiple implementations of each module that provide different combinations of accuracy and performance; users pay for accuracy only when and where they need it. Finally, PROTEUS provides repeatability, nonintrusive monitoring and debugging, and integrated graphical output, which result in a development environment superior to those available on real multiprocessors", "authors": ["Eric A. Brewer", "Chrysanthos Dellarocas", "Adrian Colbrook", "William E. Weihl"], "n_citation": 329, "references": ["2977244f-18e6-49eb-8580-006e612e50f3", "3ba7bcdf-fc1c-4907-b7e0-05407ac73eca", "7fcc2398-d0cd-4c61-a471-6aa54b12aa81"], "title": "PROTEUS: a high-performance parallel-architecture simulator", "venue": "measurement and modeling of computer systems", "year": 1992, "id": "96dac759-56df-44b6-a6c9-59dc74f9d179"}
{"abstract": "We present a new method for clausal theorem proving, named SGGS from semantically-guided goal-sensitive reasoning. SGGS generalizes to first-order logic the conflict-driven clause learning (CDCL) procedure for propositional satisfiability. Starting from an initial interpretation, used for semantic guidance, SGGS employs a sequence of constrained clauses to represent a candidate model, instance generation to extend it, resolution and other inferences to explain and solve conflicts, amending the model. We prove that SGGS is refutationally complete and model complete in the limit, regardless of initial interpretation. SGGS is also goal sensitive, if the initial interpretation is properly chosen, and proof confluent, because it repairs the current model without undoing steps by backtracking. Thus, SGGS is a complete first-order method that is simultaneously model-based a la CDCL, semantically-guided, goal-sensitive, and proof confluent.", "authors": ["Maria Paola Bonacina", "David A. Plaisted"], "n_citation": 50, "references": ["0ad27c54-a253-4958-859e-be83b2ebaeb2", "0ded0d12-3289-4a83-93d9-5cb4a14ee80e", "0df37224-bd26-4d00-8f50-cc99848f193b", "125dde08-93db-454c-bea3-227b89e7f6a8", "1bb1a820-d8de-4567-a926-63d896f1805b", "207ee0ca-3f6b-4ca7-836a-d11e19b718c2", "25e6d39e-a87a-43f6-8943-ad9f81e4e3d6", "29299615-ba3f-4155-9512-35a6a8ea5828", "2bf36145-7b5c-4c80-80d3-f2c63b920852", "4596a908-550d-4de5-8fbf-773e8513d896", "48621202-1db2-4948-a419-823e0464878c", "501bab43-e12a-4ef3-93e6-a761359ee1a3", "52aefcca-1cc7-4e30-92ea-e0bdfc4a8a3b", "53f372f9-0d4c-48f3-91a1-a20854b41ae7", "5f2e0991-a623-451b-8108-50d5bfd1e39f", "6b84ef39-b141-48d4-bee1-93fec4204f5c", "6f0da19b-2a76-4130-90f3-3c380562e235", "71718191-b5d0-4d95-85ad-21bacb18b3d5", "744293b8-70dd-48f9-bcb6-896cc2ad5406", "756ea6e4-544e-4d99-b1f2-5b2e106d9049", "7de200dd-c8a1-4ba1-8d73-0e965121b04b", "97973452-a45c-4c36-a78b-64a540a3978f", "9d1ed045-51bd-44ee-8e2e-a370b02b4aae", "9d826763-53f1-4bfd-a7f9-6a27fc26a8ae", "b5edf6d3-9177-4c78-aaf8-6171992fafaf", "b690b5c7-b708-4eea-9266-05bdcbe36da3", "b69c3684-8957-4042-84f3-ffe374f14fc9", "b9b4a94c-651a-487e-a94c-6857e09639e8", "c0a69970-4b14-492a-adcc-6928988a9f2a", "c5a47a53-5af7-46b1-a752-9d25f8dce08b", "c9fc8de8-355d-4d1c-ad47-aaed5ad88b29", "ceb6e5de-c406-4946-bf8b-eff3566ea8b2", "d2467461-d37d-4d58-af9d-8539c6410e21", "d7a69694-31bb-4aca-8e79-3655f840849f", "e3397584-77bf-4cc6-802d-d574ca05f292", "e64c11fe-6b41-4b0a-89d8-332c195370ff", "e6578653-d98a-4c1f-b689-588cb88e7905", "f360a57b-a825-450d-87f3-075e9926e539", "f3b0607d-8239-4d17-ae63-fa71988f5390"], "title": "Semantically-Guided Goal-Sensitive Reasoning: Inference System and Completeness", "venue": "Journal of Automated Reasoning", "year": 2016, "id": "91902cfc-e097-4974-a651-099292ac0e73"}
{"abstract": "We present a framework for designing end-to-end congestion control schemes in a network where each user may have a different utility function and may experience noncongestion-related losses. We first show that there exists an additive-increase-multiplicative-decrease scheme using only end-to-end measurable losses such that a socially optimal solution can be reached. We incorporate round-trip delay in this model, and show that one can generalize observations regarding TCP-type congestion avoidance to more general window flow control schemes. We then consider explicit congestion notification (ECN) as an alternate mechanism (instead of losses) for signaling congestion and show that ECN marking levels can be designed to nearly eliminate losses in the network by choosing the marking level independently for each node in the network. While the ECN marking level at each node may depend on the number of flows through the node, the appropriate marking level can be estimated using only aggregate flow measurements, i.e., per-flow measurements are not required.", "authors": ["Srisankar S. Kunniyur", "Rayadurgam Srikant"], "n_citation": 832, "references": ["01a09d2c-f8d3-40e4-bfee-211533b3f526", "0ce4877b-6e18-455c-9ee5-7ca93715a88f", "2e8af6ad-3dae-4a03-8ede-a1373759a231", "352caa76-f117-4f58-aa90-ea6f7f0472da", "3a4257ae-9cdb-46fb-a5af-70255dfb9d48", "3c850dde-7198-4b30-8ffa-ecde496e38bf", "3df44a79-f904-456f-b093-e9e4d4980284", "406e899a-9bb1-49a1-b511-7beb182ff0e7", "4854b363-f03e-4667-abad-2de7ca3d2315", "686b1f97-3cb7-47a6-bbd2-e8ba891dc1b5", "8fd6531b-c809-4e63-895b-fb91be11759d", "95db084d-9f52-468d-839e-00be5fdea08a", "a6371486-92f0-454a-a702-83a2c043300f", "b893a5b5-0e77-44b8-9cd9-6157c96558af", "c79422f7-2acc-4fb6-b0c1-e2eeee1b2a79", "d2b7db5d-bc47-48c7-a173-865fed9bff96", "ef8a79a5-e4c7-48e1-aa6f-3426e6315442", "f0960be2-9efd-4ed9-8e5f-7bcb30b3805b"], "title": "End-to-end congestion control schemes: utility functions, random losses and ECN marks", "venue": "IEEE\\/ACM Transactions on Networking", "year": 2003, "id": "3ca6b9ba-646d-44e7-b4ac-6a1c19d6c60c"}
{"abstract": "Byzantine fault-tolerant storage systems can provide high availability in hazardous environments, but the redundant servers they require increase software development and hardware costs. In order to minimize the number of servers required to implement fault-tolerant storage services, we develop a new algorithm that uses a \"Listeners\" pattern of network communication to detect and resolve ordering ambiguities created by concurrent accesses to the system. Our protocol requires 3f + 1 servers to tolerate up to f Byzantine faults--f fewer than the 4f + 1 required by existing protocols for non-self-verifying data. In addition, SBQ-L provides atomic consistency semantics, which is stronger than the regular or pseudo-atomic semantics provided by these existing protocols. We show that this protocol is optimal in the number of servers-- any protocol that provides safe semantics or stronger requires at least 3f + 1 servers to tolerate f Byzantine faults in an asynchronous system. Finally, we examine a non-confirmable writes variation of the SBQ-L protocol where a client cannot determine when its writes complete. We show that SBQ-L with non-confirmable writes provides regular semantics with 2f + 1 servers and that this number of servers is minimal.", "authors": ["Jean Philippe Martin", "Lorenzo Alvisi", "Michael Dahlin"], "n_citation": 174, "references": ["136c4780-2f25-4068-90a5-aed6afaf2890", "243c9a34-d024-4498-b3d4-833905bb6c11", "39bfdb7e-9044-4239-87ce-22e8c3651463", "65c674fe-fc63-4ba0-a6c9-6a0153454889", "8b495c61-ea6e-4c7b-9b45-3121ab994aa8", "9aec54b9-5369-440b-93eb-daa7b5593d5b", "9aeebac9-692b-4582-ae67-f498d3d72808", "9ba64329-fb53-4018-8afd-c292f9f8860d", "a2b922ee-6ed3-4cf5-a42d-dd88272af382", "bc32b485-cf27-4ef0-94f4-e606c002b0b7", "e258cf9d-32f4-4200-999c-0194471f3720", "fc1ccfa0-6a97-4179-a58b-a8c61f0a4e61"], "title": "Minimal Byzantine Storage", "venue": "international symposium on distributed computing", "year": 2002, "id": "0f4a766c-b820-4985-9f29-9612911fb613"}
{"abstract": "A mobile robot acting in the world is faced with a large amount of sensory data and uncertainty in its action outcomes. Indeed, almost all interesting sequential decision-making domains involve large state spaces and large, stochastic action sets. We investigate a way to act intelligently as quickly as possible in domains where finding a complete policy would take a hopelessly long time. This approach, Relational Envelope-based Planning (REBP) tackles large, noisy problems along two axes. First, describing a domain as a relational MDP (instead of as an atomic or propositionally-factored MDP) allows problem structure and dynamics to be captured compactly with a small set of probabilistic, relational rules. Second, an envelope-based approach to planning lets an agent begin acting quickly within a restricted part of the full state space and to judiciously expand its envelope as resources permit.", "authors": ["Natalia H. Gardiol", "Leslie Pack Kaelbling"], "n_citation": 50, "references": ["249f1f8f-495a-41eb-bce0-f4a3bc3818ea", "38277333-a60e-406c-b3d5-09a7ba497102", "3a92d54a-94bf-4ca7-945b-71475faf7f39", "407da68c-2387-487c-abd7-a75bdbcb3b04", "648c3803-b49b-44cd-b7e4-b4eff2d1e194", "78177b8f-531b-40f0-8656-9ea74ec3e0d5", "80b24bb6-6f30-45f0-be77-140c8331a243", "a1ecd103-431c-439b-a3b7-e81cd10ec2eb", "b439cff6-2ced-42f1-8bf4-044f480a117b", "beed901e-9930-4087-ad60-e00f7f08eec2", "c466b802-f5c6-4c1f-bacf-d61b40309b9b", "f9afb789-541f-4d97-b968-6fd8ed370ffa"], "title": "Envelope-based Planning in Relational MDPs", "venue": "neural information processing systems", "year": 2004, "id": "a3548338-088c-42b6-9a6f-e936d1a61d78"}
{"abstract": "It is neither desirable nor possible to abstract sensor network software from the characteristics of the underlying hardware components. In particular the radio has a major impact on higher level software. In this paper, we review the lessons we learnt using Bluetooth radios in the context of sensor networks. These lessons are relevant for (a) application designers choosing the best radio given a set of requirements and for (b) researchers in the data management community who need to formulate assumptions about underlying sensor networks.", "authors": ["Philippe Bonnet", "Allan Beaufour", "Mads Bondo Dydensborg", "Martin Leopold"], "n_citation": 50, "references": ["1af2080f-7848-4795-a98c-6e38e7731cdc", "1dd8c68d-3b20-4171-9245-3a12c64c2838", "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b", "9e063b41-0ada-4db8-8846-6e5153a0de55", "c075f11b-4ea0-4642-9910-17b3524667a8", "d61df5a9-4438-4f79-9ecd-6584266e62f9", "e3081336-5e73-42a1-adf3-c153bdc55547"], "title": "Bluetooth-based sensor networks", "venue": "international conference on management of data", "year": 2003, "id": "6153ffd8-1ffb-49f5-b010-b26fe3167085"}
{"abstract": "The reactive power optimization is an effective method to improve voltage level, decrease network losses and maintain the power system running under normal conditions. This paper provides a method combining particle swarm optimization (PSO) with linear interior point to handle the problems remaining in the traditional arithmetic of time-consuming convergence and demanding initial values. Furthermore, since chaotic mapping enjoys certainty, ergodicity and stochastic property, the paper introduces chaos mapping into the particle swarm optimization, the paper presents a new arithmetic based on a hybrid method of chaotic particle swarm optimization and linear interior point. Thanks to the superior overall exploration ability of particle swarm optimization and the local exploration ability of linear interior point within the neighborhood of the optimal point, the new method can improve the performance of both convergence and results' precision. Tested by IEEE-30, the new method provided in this paper is proved effective and practical in the optimization of shunt capacitors and tap position of load-ratio voltage transformer.", "authors": ["Jiang Chuanwen", "E. Bompard"], "n_citation": 222, "references": ["e8594a63-aab3-4513-90ad-2a327aacc154", "ef187358-8753-42e6-8fc5-ced3770e71b1"], "title": "A hybrid method of chaotic particle swarm optimization and linear interior for reactive power optimisation", "venue": "Mathematics and Computers in Simulation", "year": 2005, "id": "bf5fe0a3-e5f8-4b85-8a32-c268d624edfe"}
{"abstract": "Voice over Internet Protocol (VoIP) technology has observed rapid growth in the world of telecommunications. VoIP offers high-rate voice services at low cost with good flexibility, typically in a Wireless Local Area Network (WLAN). In a voice conversation, each client works either as a sender or a receiver depending on the direction of traffic flow over the network. A VoIP technologically requires high throughput, less packet loss and a high fairness index over the network. The packets of VoIP streaming may experience drops because of competition among the different kinds of traffic flow over the network. A VoIP application is also sensitive to delays and requires voice packets to arrive on time from the sender to the receiver without any delay over a WLAN. To date, scheduling of VoIP traffic is still an unresolved problem. The objectives of this survey paper are to discuss fundamental principles of VoIP-related schedulers and identify current scheduler issues. This survey paper also identifies the importance of the scheduling techniques over WLANs. Related research work for real-time applications specifically for VoIP will also be highlighted.", "authors": ["Kashif Nisar", "Angela Amphawan", "Suhaidi Hassan", "Nurul I. Sarkar"], "n_citation": 4, "references": ["0001e041-1050-4456-a8fe-a0f7f2b83144", "071ba997-0710-4bae-87c9-3841298c6368", "077aa70e-b736-42af-ab8f-d41fb52c2150", "094c330a-2a29-4c7f-b1da-21f35dd85560", "0a8d9930-6270-4c59-899c-47e3176b1e94", "16742a88-3d53-4459-aa06-47f08c55e07c", "18a1ae0a-9e03-4720-8a2d-72af6a1a3d2c", "29a8608f-56ac-43b3-aa3b-6779ad246c92", "2a20660d-0335-4012-b923-987610c09a9c", "2ba774ca-6483-408f-81f1-a392e64cb30a", "2da32664-7735-4b7e-a7dc-adeecc76e574", "37d75368-d809-4df4-9222-9f0d51c095d7", "38b5fd36-0416-4b7f-a9b3-d93bfe21160f", "3b0e3970-bf7c-4ca9-a585-0a2fee6e20a1", "43e577ce-44cf-43c5-82be-604e68999cb6", "467c1c44-f36f-4f28-976f-3def6cac6006", "4b66e343-18f9-483a-8a12-73764d901192", "4b878271-44a5-41f7-b226-e2a2f80705fb", "4d47596e-0a6b-459e-b4dc-7f9a5eea7b37", "5016be97-3185-4489-b9f5-c16fda056cc0", "55215737-055a-4f97-99d0-f8482efaef24", "56029d64-41b4-47e0-8fdc-a8d13e523231", "5f08a304-a690-4189-8123-cfc795b195e9", "5f377b43-4252-4b47-8f73-e39f1f042f88", "686b1f97-3cb7-47a6-bbd2-e8ba891dc1b5", "6f2580b3-9c50-40e3-8e75-6a8aa6b904ad", "70eeb3ab-e16b-445c-84ea-7e8afd6b2762", "73e55aba-473e-45cb-81bf-3464d71167fa", "755df5b6-2336-4cc0-8039-7ff0e98347b5", "7966b1a7-c08a-4af7-9f00-0d4eee274215", "836ae95f-fb7b-49fc-8f79-2d9cb898ff5c", "866315bc-263a-4149-8ec3-616312482309", "8818ff03-ca67-40eb-a730-02d0a068bc97", "8999e499-b066-4664-8b3c-2081a485a116", "8a255721-3d67-4275-950d-fea298b02602", "8adadc77-7178-4ad9-914b-23282f4c4e16", "9086d615-ba18-4d11-bf00-b8b6bf7f683b", "9242480c-82e0-4c38-be88-d29c0c77ad15", "9315113a-a4eb-4086-a815-814cfe9367c9", "9655fc58-9464-4a32-9919-5bbc06b0c969", "9757635c-003d-44f8-87ee-d4e4ca932044", "97956b6d-c626-4954-b71b-182d998e6e3f", "97ad9e93-ec79-4a8c-84aa-4ccf5e228d45", "a0f86843-d3fd-4d0b-ab1b-d70bc4cc2850", "a8b8d89e-0aa3-41d7-b268-c0e30df184e6", "a9931d70-c01a-4e76-8349-c168cff8b413", "a9f79da7-d4bc-452e-ae76-8c2912ab0085", "af3b6710-40c7-432d-ae48-fa4a59c9c8a1", "b18f14a4-dd3b-41cf-a381-1285e10ad0b6", "b5dc09f0-38fc-419a-9622-e3c7d81c3bcc", "be9a7569-6a4a-47b3-b14e-3a15b31d754f", "ccd13f7a-fc12-4759-a7ce-4a1899e315a5", "d2b7db5d-bc47-48c7-a173-865fed9bff96", "d515523f-a419-4f04-aed3-b3d909db139c", "dbd75c53-af5a-43d8-b4d6-d6cd14224dca", "e1fa5853-69d4-4570-81c7-ff113f330e85", "fb0c8e8e-7790-4069-8d84-7b120027cd4a", "fe9232c9-360d-43f0-8854-1e602022b406", "ff69994c-ecb8-4c9a-9bd4-3ba7bd0a3d02"], "title": "Review: A comprehensive survey on scheduler for VoIP over WLAN", "venue": "Journal of Network and Computer Applications", "year": 2013, "id": "66706c63-0db9-43c6-9698-af4de2b9d1a6"}
{"abstract": "In this paper, we describe scalable parallel algorithms for symmetric sparse matrix factorization, analyze their performance and scalability, and present experimental results for up to 1,024 processors on a Gray T3D parallel computer. Through our analysis and experimental results, we demonstrate that our algorithms substantially improve the state of the art in parallel direct solution of sparse linear systems-both in terms of scalability and overall performance. It is a well known fact that dense matrix factorization scales well and can be implemented efficiently on parallel computers. In this paper, we present the first algorithms to factor a wide class of sparse matrices (including those arising from two- and three-dimensional finite element problems) that are asymptotically as scalable as dense matrix factorization algorithms on a variety of parallel architectures. Our algorithms incur less communication overhead and are more scalable than any previously known parallel formulation of sparse matrix factorization. Although, in this paper, we discuss Cholesky factorization of symmetric positive definite matrices, the algorithms can be adapted for solving sparse linear least squares problems and for Gaussian elimination of diagonally dominant matrices that are almost symmetric in structure. An implementation of one of our sparse Cholesky factorization algorithms delivers up to 20 GFlops on a Gray T3D for medium-size structural engineering and linear programming problems. To the best of our knowledge, this is the highest performance ever obtained for sparse Cholesky factorization on any supercomputer.", "authors": ["Anshul Gupta", "George Karypis", "Vipin Kumar"], "n_citation": 240, "references": ["09381ece-c2b1-4c09-b205-57d218e335b8", "0d675656-d9f8-4f3f-9752-f9296dbf32fd", "1b847324-7698-456b-ada2-d6a77b4fafa5", "1e2598d3-6587-4051-8973-1ecdde9da72b", "2bda52cd-2491-4672-8378-d7f3d186c3ab", "39129552-239c-45b6-8cec-4da15a279796", "39baa143-9430-45a4-bd48-ba6fa650d5c1", "433c7c2b-d193-47a3-b220-66b54666e432", "5c7160ae-7920-4f95-b0a8-04247534d39d", "788c737f-2a2c-45f1-a635-28b01a701311", "7d9ad9a1-1aa2-4d76-a6da-e45199b4c3ee", "9b4a7faa-1d3b-4b7e-a2ed-2d7a339699fd", "9ea9343e-1c38-4f9e-9ca4-a3bf1d82ddf3", "9eaaabe3-f5c1-4780-9014-2e755a9de9b4", "a844f5aa-0798-4a34-8d5e-3552c94191c9", "aabb0483-93c7-40d5-9a75-a0fc98ffa679", "ab264e34-c1a2-4ea1-a9aa-ccaca8d2dc29", "af3dcf0c-6e6f-4190-a9d6-9a9d2551e378", "b6979568-f79f-488d-820d-04c88b4a0c89", "bc191859-653f-49b9-8969-54d2f58989c4", "c21a5494-02e2-417c-b40f-72977758d807", "c228451a-5915-45ba-ae75-cd1c2bbbc4a7", "cede414d-501e-4247-a650-42240f00a401", "d443e0dd-11a2-4d73-96d9-93407bef7580", "e1dce736-fd24-4652-a1e5-6a4cbfb46e3d", "e8a98a90-a2ee-4a82-b796-85fcd6ffb2a2", "f5b726e9-69ef-4ef9-91d0-240b9570c4d6", "fa25343d-2fd3-4432-8e36-829d08006b01"], "title": "Highly scalable parallel algorithms for sparse matrix factorization", "venue": "IEEE Transactions on Parallel and Distributed Systems", "year": 1997, "id": "694d564c-7405-4c57-a7f1-7fd349486c57"}
{"abstract": "Use cases are believed to be a good basis for system testing. Yet, to automate the test generation process, there is a large gap to bridge between high-level use cases and concrete test cases. We propose a new approach for automating the generation of system test scenarios in the context of object-oriented embedded software, taking into account traceability problems between high-level views and concrete test case execution. Starting from a formalization of the requirements based on use cases extended with contracts, we automatically build a transition system from which we synthesize test cases. Our objective is to cover the system in terms of statement coverage with those generated tests: an empirical evaluation of our approach is given based on this objective and several case studies. We briefly discuss the experimental deployment of our approach in the field at Thales Airborne Systems.", "authors": ["Cl\u00e9mentine Nebut", "Franck Fleurey", "Y. Le Traon", "J.-M. Jezequel"], "n_citation": 321, "references": ["0b44cfd6-cbd9-408e-bf67-d035f222301b", "148e84db-9616-4bad-8e05-fc1d5715a6d0", "20732663-8b39-4f72-a043-d991d9bc2c17", "3e6f1db6-3dea-428c-b24b-6f5b0df88298", "64ec1e30-79b8-44ec-be3d-4d6e60893a2d", "685a962b-5722-4df2-b033-8b460f86ec9e", "6e74dae5-cee7-46cd-806e-8f56e1874392", "7865e2fe-028f-4871-84f0-3f471b7d1cd8", "78a779dc-4554-4af0-ac48-e9967f7288bb", "7c12c213-41af-4508-b7b3-a9e9156b41d4", "8ef3b696-006b-4755-a38a-98ec7f207f22", "9a4984f9-27d4-47eb-8bc8-0469bf540f94", "ac3d5cbf-62a9-474a-83da-708c9af951ef", "b29b58f7-ae81-42e3-ab03-0a2fdcfe68f9", "bc032656-6dcd-4c0c-8060-53e9f9da6b0c", "db680839-374a-45a2-ba65-31590b859464", "de81543e-8330-4de1-a244-f3f7a4de3163", "eb9fd8ab-6512-47b3-a690-3a1e03f817cf"], "title": "Automatic test generation: a use case driven approach", "venue": "IEEE Transactions on Software Engineering", "year": 2006, "id": "6fc784f9-1839-46b3-b2a2-828722dc81b7"}
{"abstract": "Our efforts are directed towards the understanding of the coscheduling mechanism in a NOW system when a parallel job is executed jointly with local workloads, balancing parallel performance against the local interactive response. Explicit and implicit coscheduling techniques in a PVM-Linux NOW (or cluster) have been implemented. Furthermore, dynamic coscheduling remains an open question when parallel jobs are executed in a non-dedicated Cluster. A basis model for dynamic coscheduling in Cluster systems is presented in this paper. Also, one dynamic coscheduling algorithm for this model is proposed. The applicability of this algorithm has been proved and its performance analyzed by simulation.#R##N#Finally, a new tool (named Monito) for monitoring the different queues of messages in such an environments is presented. The main aim of implementing this facility is to provide a mean of capturing the bottlenecks and overheads of the communication system in a PVM-Linux cluster.", "authors": ["Francesc Gin\u00e9", "Francesc Solsona", "Porfidio Hern\u00e1ndez", "Emilio Luque"], "n_citation": 50, "references": ["1357648a-cb58-4495-a672-a77cea4e47ee", "33682f3c-1492-42fb-b888-b2fd50049332", "8d4aed6f-d08a-420d-8d75-35a645230739", "975093f9-00c5-4315-a6a7-6ff2343dc537", "a9d24ed2-b188-4034-8122-5fda56ab15b0", "c07aeda0-e377-4b4c-b082-411ed6bf813a", "c3179742-5bcd-4612-bc55-534630763bbc", "c7194273-719f-4386-96cd-aa8655b378c7", "c76e03a0-61be-4086-84a5-af51c48ed4fd", "d9a67b80-4856-42e8-86a6-3654372091f2", "f40d97cd-6e16-4a4f-bd8f-f3f1af1b7f3a"], "title": "Cooperating Coscheduling in a Non-dedicated Cluster", "venue": "european conference on parallel processing", "year": 2003, "id": "a35a9859-4d9f-4d49-9295-461d51a64af0"}
{"abstract": "The authors present novel algorithms for selecting an elements of specified rank among N=n/sup 2/ elements on an n*n mesh-connected processor array, in a variety of settings. They give: (1) an optimal randomized algorithm for selecting the element of rank k out of N, 1 >", "authors": ["Danny Krizanc", "Lata Narayanan"], "n_citation": 16, "references": ["0974e4f7-f01a-4211-9871-f5be77c3ac45", "32b25b59-d059-4237-9b8a-14258709bdbb", "403fa7dc-5427-40eb-80da-3086b0fd316d", "51a096a4-a295-4a38-8619-d3f05d4b2dfa", "59f484f4-4f7d-4c91-bebd-b4a110a07a55", "87135a5e-627a-4e05-8f62-d92e9c6fc1db", "983491c0-ab7d-46bc-9bcb-f2608c1efd03", "9ce8d7d5-95e3-45f3-8898-b0fe40fcaa13", "f35a7e03-ad6a-4bc7-94f5-669faf72dbe7"], "title": "Optimal algorithms for selection on a mesh-connected processor array", "venue": "international parallel and distributed processing symposium", "year": 1992, "id": "208dce80-338f-4195-9573-cc1e3acd0444"}
{"abstract": "We present Heart-to-Heart (H2H), a system to authenticate external medical device controllers and programmers to Implantable Medical Devices (IMDs). IMDs, which include pacemakers and cardiac defibrillators, are therapeutic medical devices partially or wholly embedded in the human body. They often have built-in radio communication to facilitate non-invasive reprogramming and data readout. Many IMDs, though, lack well designed authentication protocols, exposing patients to over-the-air attack and physical harm.   H2H makes use of ECG (heartbeat data) as an authentication mechanism, ensuring access only by a medical instrument in physical contact with an IMD-bearing patient. Based on statistical analysis of real-world data, we propose and analyze new techniques for extracting time-varying randomness from ECG signals for use in H2H. We introduce a novel cryptographic device pairing protocol that uses this randomness to protect against attacks by active adversaries, while meeting the practical challenges of lightweight implementation and noise tolerance in ECG readings. Finally, we describe an end-to-end implementation in an ARM-Cortex M-3 microcontroller that demonstrates the practicality of H2H in current IMD hardware.   Previous schemes have had goals much like those of H2H, but with serious limitations making them unfit for deployment---such as naively designed cryptographic pairing protocols (some of them recently broken). In addition to its novel analysis and use of ECG entropy, H2H is the first physiologically-based IMD device pairing protocol with a rigorous adversarial model and protocol analysis.", "authors": ["Masoud Rostami", "Ari Juels", "Farinaz Koushanfar"], "n_citation": 379, "references": ["002305ea-7f1e-406c-8111-70e96bc45019", "021e2e04-3de1-440c-aeb3-5f5c907988e8", "0b868c0b-2b01-4732-abfb-06a8773783cb", "12af4195-d801-4fe5-b593-e28a773beb02", "36255b25-6424-4f73-bd85-85079a893aba", "532ea788-77f5-467d-90b9-b423aed07032", "69c141f2-09f7-46a8-a32e-d4ffccfc2df1", "75d65c88-da83-4528-9926-c6804842bae9", "85d69ae6-04d8-4dc6-a405-16806893171d", "94d5a674-3e53-4514-b031-b30949137776", "98830427-b74e-4873-9223-5c1d9358643a", "9fcde8cf-0902-4814-8ebf-37b9e0fd85ad", "a89a568a-2b19-4fa1-b514-5c2a66f11dd1", "aaf36b97-4bb5-4f01-bed6-76d41f8e0208", "ac75591e-7540-48c6-86a7-0bda9bff7b88", "bbafab6f-c135-45e2-bc4d-35e58bf10594", "c816b483-511d-43f2-a149-5c6e53cf2fbf", "cc4c0fbf-be84-4034-b61f-be7d6c1eda82", "cd265299-7ae5-495a-a7ed-8610a44512d8", "e07b966d-fe8c-47b2-9984-fde918e833b6", "e53e7795-caae-4d6f-b2d4-531652bce013", "eaf3e7f1-bf12-446a-bc00-4e4f6527a1cd", "ff52a476-c1b0-44ca-bdb0-712a37c7f967"], "title": "Heart-to-heart (H2H): authentication for implanted medical devices", "venue": "computer and communications security", "year": 2013, "id": "86292afb-eb15-4b3e-a49b-0674acaf045b"}
{"abstract": "In this paper, we consider an optimal control problem for a linear discrete time system with stochastic parameters in the infinite time horizon case. This paper focuses on optimal control for systems with stochastic parameters whereas the traditional stochastic optimal control theory mainly considers systems with deterministic parameters with stochastic noises. This paper extends the authors' former result on the same subject in the finite time horizon case to the infinite time horizon case. The main result is to provide a feedback controller suppressing the variation of the state and to prove stochastic stability of the corresponding feedback system by taking care of both the average and the variance of the state transient. Furthermore, a numerical simulations demonstrate the effectiveness of the proposed method.", "authors": ["Kenji Fujimoto", "Yuhei Ota", "Makishi Nakayama"], "n_citation": 7, "references": ["222859e5-5135-4d8c-8bb3-8f8fbcc36fe4", "440ab2d5-3af6-4a67-9ddb-d1a7b6693063", "45c6e23d-14a3-48c4-8105-af8a16d49068", "a7daa0b7-5613-413f-b2ef-36ff1bf8a384"], "title": "Optimal control of linear systems with stochastic parameters for variance suppression", "venue": "conference on decision and control", "year": 2011, "id": "35bef24a-edc5-4113-9319-1cfbdadb63e9"}
{"abstract": "We propose a new multilevel framework for large-scale placement called MAPLE that respects utilization constraints, handles movable macros and guides the transition between global and detailed placement. In this framework, optimization is adaptive to current placement conditions through a new density metric. As a baseline, we leverage a recently developed at quadratic optimization that is comparable to prior multilevel frameworks in quality and runtime. A novel component called Progressive Local Refinement (ProLR) helps mitigate disruptions in wirelength that we observed in leading placers. Our placer MAPLE outperforms published empirical results --- RQL, SimPL, mPL6, NTUPlace3, FastPlace3, Kraftwerk and APlace3 -- across the ISPD 2005 and ISPD 2006 benchmarks, in terms of official metrics of the respective contests.", "authors": ["Myung-Chul Kim", "Natarajan Viswanathan", "Charles J. Alpert", "Igor L. Markov", "Shyam Ramji"], "n_citation": 54, "references": ["0556eabc-2bb9-4b25-a3b0-4f4dd98149e9", "0ae0a0cd-60d2-4151-a8b3-dc1b1b729960", "1033eb3a-3d21-44db-95dd-8e10d1bcd862", "11937f8a-a5d2-4708-9bd7-dc4928d9b591", "1b8444da-3999-47fb-9065-17004fec9368", "1eba2d3e-6327-43b3-a63f-a01fb75d6250", "299d7e1f-1710-43d2-83da-aa751238de8b", "2bb16348-50a2-4de8-9a0e-e14e21b5ddde", "3de49412-7bc6-4dbd-b388-2bcc9029d8cb", "4018d2b9-922a-400b-bd22-5a2a57ab0a54", "4073ad36-a6c7-43fd-a47e-755c8241c88d", "46a38671-cea6-4ccf-bd83-d8e3679b2c39", "4ba6b061-6e55-41e6-a033-5bbb6845b46e", "4cd9c632-fc01-48eb-9d80-49ec35eaf68f", "51e46632-c6f7-4cad-bee1-ddaf310cdcd9", "674962fc-2e92-4cc3-bd73-867366f8859c", "775be305-119f-4963-bb71-78b1cb79c736", "80280234-1a3e-4ced-a6f4-03be6c5abdcd", "9b57e1bd-d213-46ef-a951-2c7b786a41c2", "b7f42337-8c7f-44d8-a57f-8df8e2a08aaf", "cb86a8cc-50ef-45e7-b43a-c8bb39ab93de", "d2a21a5e-227a-4d62-bd2d-82a4fe0cd0e6", "e8011232-526f-4f46-82f1-c7448dc58243", "ec5d487d-7602-4900-ac97-d5b23de17283", "eef09e8d-8a0b-45fa-9937-6f684b4f9a65", "f25d4a02-df0e-479f-a752-d85368533728", "f5c9a17b-5105-4c60-90d5-9dd62ed9d2a6"], "title": "MAPLE: multilevel adaptive placement for mixed-size designs", "venue": "international symposium on physical design", "year": 2012, "id": "6fe22324-eece-4a95-a00d-24f0ee54949b"}
{"abstract": "This paper presents LOGISIM, a CAD tool to simulate the temporal behaviour of hybrid circuits containing electro-mechanical, electro-hydraulic, hydro-mechanic, and digital control devices. LOGISIM combines the advantages of both qualitative and quantitative reasoning by producing a high-level description (discrete states) of the circuit behaviour while reasoning at the quantitative level (physical values). In addition, device models in LOGISIM follow a particular description methodology proposed to avoid introducing an artificial computational complexity in the simulation. LOGISIM is fully implemented in the constraint logic programming language CHIP. The constraint-solving techniques of CHIP used in LOGISIM, i.e. an incremental decision procedure for linear constraints over rational numbers, consistency techniques on domain-variables and conditional propagation, are all necessary to solve the problem efficiently. LOGISIM has been applied successfully to real-life industrial circuits from aerospace industry in the ELSA project and clearly demonstrates the potential of this kind of tool to support the design process for these circuits.", "authors": ["T. Graf", "Pascal Van Hentenryck", "Claudine Pradelles", "Laurent Zimmer"], "n_citation": 45, "references": ["2fb3bd66-88e0-4769-b0ae-3fbdc59cbbef", "67e678f2-faeb-4310-b693-4f0af74a2da7", "84f6729f-393a-472e-8aab-2fda338d5748", "8f4617fe-c246-4d76-9d69-53c963b692d4", "90a09517-844c-4a73-9a61-8e89d1b93921", "995b150c-6522-4960-a45b-6c5cb8bb3299", "cb416199-0778-456a-b7ce-becf3561588d"], "title": "Simulation of hybrid circuits in constraint logic programming", "venue": "international joint conference on artificial intelligence", "year": 1989, "id": "5d83cf0b-8c76-4e87-8167-ba396c1e1310"}
{"abstract": "The quality and effectiveness of the load following services provided by centralized control of thermostatically controlled loads depend highly on the communication requirements and the underlying cyberinfrastructure characteristics. Specifically, ensuring end-user comfort while providing real-time demand response services depends on the availability of the information provided from the thermostatically controlled loads to the main controller regarding their operating statuses and internal temperatures. State estimation techniques can be used to infer the necessary information from the aggregate power consumption of these loads, replacing the need for an upstream communication platform carrying information from appliances to the main controller in real-time. In this paper, we introduce a moving horizon mean squared error state estimator with constraints as an alternative to a Kalman filter approach, which assumes a linear model without constraints. The results show that some improvement is possible for scenarios when loads are expected to be toggled frequently.", "authors": ["Emre Can Kara", "J. Zico Kolter", "Mario Berges", "Bruce H. Krogh", "Gabriela Hug", "Tugce Yuksel"], "n_citation": 22, "references": ["095f32dc-c448-43d9-8e19-cb8660c03383", "3e6a9ae4-5b66-4351-b546-a1d55abbeff9", "583e16d7-20b6-4969-bd8c-ff37c240a8fd", "5a31a3f8-cfe2-49d5-8be5-c77a3e3eba6b", "903bc60a-02a0-4bc3-a25e-81b07e74332d", "cca6e821-0ddc-448d-b871-f6757e7e80f0"], "title": "A moving horizon state estimator in the control of thermostatically controlled loads for demand response", "venue": "", "year": 2013, "id": "5f19d922-adbb-4232-b168-fa5b07369378"}
{"abstract": "Modeling design environment with constraints instead of a traditional testbench is advantageous in a hybrid verification framework that encompasses simulation and formal verification. This movement is gaining popularity in industry and sparks research in the constraint-based environment modeling and stimulus generation problem. We present an approach, called  constraint synthesis , to this problem. Constraint synthesis falls in the general category of parametric Boolean equation solving but is novel in utilizing don't care information unique to hardware constraints and heuristic variable removal to simplify the solution. Experimental results have demonstrated the effectiveness of the proposed approach.", "authors": ["Jun Yuan", "Ken Albin", "Adnan Aziz", "Carl Pixley"], "n_citation": 40, "references": ["0a724f9f-214d-498e-8ee3-ad23656f6020", "0bb3f4ae-4600-4e70-8ce9-f1bb0c5d42c1", "13aa790c-0b37-4a38-ae4b-f1ad174c0fc3", "2c8ef0ee-778c-4531-aba3-081284bfefef", "2cc676e2-1a0d-4c66-81ab-8d443881e897", "4bdf4fee-76fa-4bec-af1b-162860fc3171", "4e0661c3-4a7d-405d-8e43-61526cfeb523", "a8dafcb7-e0be-4501-b4cb-a5b387f97b36", "e49afdf9-0448-46ca-971f-614da17ba508"], "title": "Constraint synthesis for environment modeling in functional verification", "venue": "design automation conference", "year": 2003, "id": "a9be02a3-3898-4b0b-b438-0d02a6240eea"}
{"abstract": "The k-set consensus problem requires processes to decide on at most k of their input values. The problem can be solved using only read / write operations in the presence of f crash failures if and only if f < k. One way to subvert this impossibility result is to restrict the set of possible assignments of input values to processes. This paper presents a characterization of the input restrictions that allow a wait-free solution of n-set consensus in a system with n+1 processes, using only read and write operations.", "authors": ["Hagit Attiya", "Zvi Avidor"], "n_citation": 25, "references": ["16bdc47f-a2c0-4503-ad1f-015437a7defb", "21fae11f-a34f-47fb-bece-a12915c85d57", "29ffddb2-f1fe-41bc-903d-479017709e1a", "34cad4db-60a8-4ff4-9870-226b3128ba86", "6f4eb280-d39e-4539-9516-8bc9ee5dda0b", "7063436d-94e3-4a94-a98b-7410c041b691", "76790cc7-4a8f-4294-a480-8761d529716d", "7ffec2f8-420b-43cf-8ad5-550e332f5d6d", "b547cf00-64bd-4ea9-81b4-f2871b18dc1d", "b9db1cc8-5a51-415e-9f48-d4665f979f78", "cd2c6e61-6090-4e6a-869b-f5b350802589"], "title": "Wait-Free n-Set Consensus When Inputs Are Restricted", "venue": "international symposium on distributed computing", "year": 2002, "id": "511f5325-6827-4539-9c59-8896addd2de5"}
{"abstract": "Researchers have access to large online archives of scientific articles. As a consequence, finding relevant papers has become more difficult. Newly formed online communities of researchers sharing citations provides a new way to solve this problem. In this paper, we develop an algorithm to recommend scientific articles to users of an online community. Our approach combines the merits of traditional collaborative filtering and probabilistic topic modeling. It provides an interpretable latent structure for users and items, and can form recommendations about both existing and newly published articles. We study a large subset of data from CiteULike, a bibliography sharing service, and show that our algorithm provides a more effective recommender system than traditional collaborative filtering.", "authors": ["Chong Wang", "David M. Blei"], "n_citation": 739, "references": ["0840a94d-6566-43b2-9df4-b21a1c7b9a15", "136c8788-4516-4eb1-9685-e18c0fb9825f", "3cf667e4-b285-48e6-9816-085ce9c56f8c", "554fc7d7-97c6-4ddd-a3cd-46245a3a2209", "5f6f5fb3-b316-4722-9a53-2ff9dbf378d1", "694f475e-f6c4-4105-b645-84c7d592db30", "6a6d14f3-83d4-4df4-bd27-94455c216c4f", "7874f86f-6c03-4db2-ab80-3e622fc4aac1", "853550c8-58f0-41e8-90ac-512bc6841b24", "8b04d095-b24f-495a-a706-6356f19d6176", "a776d726-fe13-4111-931c-26ef585fa41e", "afaee3cb-390a-4b89-9dbf-c053399f906a", "b07bd425-9c1d-472f-9f18-841c12d6d4a4", "ba797cd3-ecce-446d-a9ec-3d77844a1f9b", "d507592b-621b-47c8-a10d-29f9e9953393", "d77bb2de-8e9e-4f30-82a5-9604016070fb", "eb8ed3e2-7054-45e1-a225-8d4eef5b8f9d", "ed4c0d5d-5152-4915-b9bd-d0bd25f82674"], "title": "Collaborative topic modeling for recommending scientific articles", "venue": "knowledge discovery and data mining", "year": 2011, "id": "862754df-4ee0-4cc7-a02e-4005aa29b125"}
{"abstract": "General-purpose computing devices allow us to (1) customize computation after fabrication and (2) conserve area by reusing expensive active circuitry for different functions in time. We define RP-space, a restricted domain of the general-purpose architectural space focussed on reconfigurable computing architectures. Two dominant features differentiate reconfigurable from special-purpose architectures and account for most of the area overhead associated with RP devices: (1) instructions which tell the device how to behave, and (2) flexible interconnect which supports task dependent dataflow between operations.#R##N#We can characterize RP-space by the allocation and structure of these resources and compare the efficiencies of architectural points across broad application characteristics. Conventional FPGAs fall at one extreme end of this space and their efficiency ranges over two orders of magnitude across the space of application characteristics. Understanding RP-space and its consequences allows us to pick the best architecture for a task and to search for more robust design points in the space.#R##N#Our DPGA, a fine-grained computing device which adds small, on-chip instruction memories to FPGAs is one such design point. For typical logic applications and finite-state machines, a DPGA can implement tasks in one-third the area of a traditional FPGA. TSFPGA, a variant of the DPGA which focuses on heavily time-switched interconnect, achieves circuit densities close to the DPGA, while reducing typical physical mapping times from hours to seconds.#R##N#Rigid, fabrication-time organization of instruction resources significantly narrows the range of efficiency for conventional architectures. To avoid this performance brittleness, we developed MATRIX, the first architecture to defer the binding of instruction resources until run-time, allowing the application to organize resources according to its needs. Our focus MATRIX design point is based on an array of 8-bit ALU and register-file building blocks interconnected via a byte-wide network. With today's silicon, a single chip MATRIX array can deliver over 10 Gop/s (8-bit ops). On sample image processing tasks, we show that MATRIX yields 10-20$\\times$ the computational density of conventional processors.#R##N#Understanding the cost structure of RP-space helps us identify these intermediate architectural points and may provide useful insight more broadly in guiding our continual search for robust and efficient general-purpose computing structures. (Copies available exclusively from MIT Libraries, Rm. 14-0551, Cambridge, MA 02139-4307. Ph. 617-253-5668; Fax 617-253-1690.)", "authors": ["Andr\u00e9 DeHon", "Thomas F. Knight"], "n_citation": 647, "title": "Reconfigurable Architectures for General-Purpose Computing", "venue": "", "year": 1996, "id": "28f5ffcb-1076-49d0-9cf0-8a64694e2f67"}
{"abstract": "We investigate the uniqueness of driver behavior in vehicles and the possibility of using it for personal identification with the objectives of achieving safer driving, of assisting the driver in case of emergencies, and of being a part of a multi-mode biometric signature for driver identification. We use Gaussian mixture models (GMM) for modeling the individualities of the accelerator and brake pedal pressures, and focus on not only the static features, but also the dynamics of the pedal pressures. Experimental results show that the dynamic features significantly improve the performance of driver identification.", "authors": ["Kei Igarashi", "Chiyomi Miyajima", "Katsunobu Itou", "Kazuya Takeda", "Fumitada Itakura", "H\u00fcseyin Abut"], "n_citation": 64, "references": ["a14681ac-ae43-44a2-9de3-b6c699ff6879", "ab8b2cde-a942-4b69-a270-0ac1b7199726", "b627c661-bb9b-4705-bc96-de9075674562", "cec2861c-185a-45e4-ac22-c28fb4e54de3"], "title": "Biometric identification using driving behavioral signals", "venue": "international conference on multimedia and expo", "year": 2004, "id": "2e1d3aea-7508-4b0f-a470-f7286a81694a"}
{"abstract": "Software design involves translating a set of task requirements into a structured description of a computer program that will perform the task. A software designer can use design schema, collaborative design knowledge, or can reuse design artifacts. Very little has been done to include reuse of design artifacts in the software development life cycle, despite tremendous promises of reuse. As a result, this technique has not seen widespread use, possibly due to a lack of cognitive understanding of the reuse process. This research explores the role of a specific cognitive aspect, opportunism, in demand-side software reuse. We propose a cognitive model based on opportunism that describes the software design process with reuse. Protocol analysis verifies that the software design with reuse is indeed opportunistic and reveals that some software designers employ certain tasks of the reuse process frequently. Based on these findings, we propose a reuse support system that incorporates blackboard technology and existing reuse library management system.", "authors": ["Arun Sen"], "n_citation": 46, "references": ["09991de0-c00f-49cf-a88a-6515943b0843", "0f5fd389-e894-4ad9-997d-22f8095a0ef5", "116455a9-3549-4d5b-bafc-d448970cc754", "7a98a8d5-a652-44aa-86ea-cfd145035930", "7dace715-2430-48c2-9eca-f8729f128a08", "7f4872b0-d490-4ea5-9a08-514a1f7ee324", "890cefd3-2269-453b-a552-66fe69cc12b7", "8d04a41a-34b2-4c18-b15a-ea74ffbedc81", "a7edd9d0-dc70-4c1a-b1a3-f8f8d2cffa60", "ad4e5d17-79fe-49c4-82d9-eea9d917d31d", "b20f6ebd-ac7b-46c1-acb8-5f23b7c988b1", "b75c0b61-7d06-4587-be47-10ca339751c8", "c7e3223a-72bb-41a2-98cb-7a80f2433987", "de36ba59-4627-4a20-a2eb-b1d9bab2e69f", "e5710d1a-f2a7-4a3f-b3d7-6e38249be244", "ea8d8e8f-d8df-4722-935b-401665ea6fbc"], "title": "The role of opportunism in the software design reuse process", "venue": "IEEE Transactions on Software Engineering", "year": 1997, "id": "28a0768b-2fca-43f9-96ac-fbbb579c31fa"}
{"abstract": "Human identification at a distance has recently gained growing interest from computer vision researchers. Gait recognition aims essentially to address this problem by identifying people based on the way they walk. In this paper, a simple but efficient gait recognition algorithm using spatial-temporal silhouette analysis is proposed. For each image sequence, a background subtraction algorithm and a simple correspondence procedure are first used to segment and track the moving silhouettes of a walking figure. Then, eigenspace transformation based on principal component analysis (PCA) is applied to time-varying distance signals derived from a sequence of silhouette images to reduce the dimensionality of the input feature space. Supervised pattern classification techniques are finally performed in the lower-dimensional eigenspace for recognition. This method implicitly captures the structural and transitional characteristics of gait. Extensive experimental results on outdoor image sequences demonstrate that the proposed algorithm has an encouraging recognition performance with relatively low computational cost.", "authors": ["Liang Wang", "Tieniu Tan", "Huazhong Ning", "Weiming Hu"], "n_citation": 1038, "references": ["09c17ef9-5985-4c97-b67c-18d53bd21a2d", "0af61588-ee62-495b-b114-5355fed4d697", "172fd98b-1ac2-4781-b60f-2478d6bf7c57", "1a3f9254-1884-4ae2-ac64-2f16fb541ba8", "24c02267-94cd-47fa-8739-367feda86739", "51089d3a-d015-4b84-955e-e5681ffb5fed", "53379d54-b51a-4e65-8425-ce093b185d34", "6c1c8a63-e9fd-4b17-8099-d2aa1ea197bc", "6cf0caf0-1545-41dc-b890-d1c8928661bf", "7276750a-42f3-4baf-9aa3-86daad3e70f4", "83e94e08-b715-4866-a61c-609c88279fb4", "8553f82e-487e-4d57-be72-4da7b5c44dfb", "8b54f44e-46e7-4d63-81e0-f19bc23944cd", "9cab0a4f-9bbb-47cb-8ec1-9dae1d03be15", "a64f715b-97a1-4a78-ad48-e143b4618741", "a778a6f2-4eb9-4dfe-ac7d-9f3443deeca7", "ab77e492-f4f5-43ca-ac25-6e86dd3c0a57", "b409eeed-0367-45bb-a499-5a8c3e214613", "c1e5f4be-c794-41bc-b9aa-711ebd5a2749", "c77024c2-955a-44be-a2ef-471f0ce30a83", "d5aec40e-145d-44e7-a9c0-c9e71c545470", "d7265b7d-ba05-4fa5-8ac0-250ca7a63772"], "title": "Silhouette analysis-based gait recognition for human identification", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2003, "id": "b3f8d3f4-4471-4df7-aa20-ac4ea05afecb"}
{"authors": ["Jin Sa", "Brian Warboys"], "n_citation": 50, "references": ["0b9ac3a1-01af-42a5-af12-85d7189ea8eb", "4b9cbe49-04d7-4992-a000-f25d37fc01ce", "8ed5f3fe-81cc-425b-9ee6-40a84efde8a8", "9350f704-a57b-4c51-b4ad-a21600c95e4b", "9e32fb35-620d-4859-8852-be4747a49f45", "b0c6eaf3-da91-4731-a95e-58618d474c1b", "bafb5505-3661-4fcf-9b64-1353e62ac105", "be9af25c-4ee8-46d9-a3a7-41b3f8d86a50", "f56aec39-113d-4149-897a-775e1b22cc71", "f63d51b8-599d-4518-9f89-f918b4313ced", "f8c02d56-f670-4df7-a777-568c44c16c22"], "title": "A Reflexive Formal Software Process Model", "venue": "", "year": 1995, "id": "cb6de7c2-04cc-4fcc-9ed8-19616fa2fe28"}
{"abstract": "The elliptic curve primality proving (ECPP) algorithm is one of the current fastest practical algorithms for proving the primality of large numbers. Its running time currently cannot be proven rigorously, but heuristic arguments show that it should run in time O((log N) 5 ) to prove the primality of N. An asymptotically fast version of it, attributed to J. O. Shallit, is expected to run in time O((log N) 4 ). We describe this version in more detail, leading to actual implementations able to handle numbers with several thousands of decimal digits.", "authors": ["Fran\u00e7ois Morain"], "n_citation": 50, "references": ["1fab5263-5f4f-4118-963e-65d9ba55e0ac", "20e2e0be-36a0-4cb8-a060-2d5ffe89876f", "418c3344-b6e2-4820-aee1-74eddc168e83", "42dd0d47-2c0b-4a6b-aa78-2cf7d56f0d79", "55df3af3-2def-4936-9dfa-1f47d18f041f", "66776673-d4fa-49a0-b228-ab20aec5c964", "69a34e3e-0ac7-4869-ad18-15eeae541eb2", "749c602c-e871-4780-bf11-818a49b51969", "7a62d784-d56b-4484-8841-3917842a8ba8", "8474848d-830d-48cb-82f0-179ba5c83517", "84752f73-ecc8-4ac7-8fbd-6e713973f208", "cadff9a7-bdf7-41eb-b2ac-76d17aebb0fc"], "title": "Implementing the asymptotically fast version of the elliptic curve primality proving algorithm", "venue": "Mathematics of Computation", "year": 2007, "id": "bbc53a5a-0306-41e5-98d9-b45a62717e71"}
{"abstract": "We present a neurobiologically motivated model of a neuron with active dendrites and dynamic synapses, and a training algorithm which builds upon single spike-timing-dependent synaptic plasticity derived from neurophysiological evidence. We show that in the presence of a moderate level of noise, the plasticity rule can be extended from single to multiple pre-synaptic spikes and applied to e.ectively train a neuron in detecting temporal sequences of spike trains. The trained neuron responds reliably under di.erent regimes and types of noise. c", "authors": ["Christo Panchev", "Stefan Wermter"], "n_citation": 50, "references": ["0e767c4a-1e03-44f9-8910-4a2dc48a9ae3", "1ae59101-ef85-4399-b7bb-071d5280c605", "725ef7a8-7330-4da1-98d6-9e644a62cddf", "76da4d9c-e2a5-407b-89c9-a39e7f4190be", "b1187381-cc24-471e-b288-5da09c3d4ca9"], "title": "Spike-timing-dependent synaptic plasticity: from single spikes to spike trains", "venue": "Neurocomputing", "year": 2004, "id": "00b0a8ab-7769-4192-897a-7bca11792d02"}
{"abstract": "This paper is devoted to the study of watershed algorithms behavior. Through the introduction of a concept of pass value, we show that most classical watershed algorithms do not allow the retrieval of some important topological features of the image (in particular, saddle points are not correctly computed). An important consequence of this result is that it is not possible to compute sound measures such as depth, area or volume of basins using most classical watershed algorithms. Only one watershed principle, called topological watershed, produces correct watershed contours.", "authors": ["Laurent Najman", "Michel Couprie"], "n_citation": 72, "references": ["17829014-c0d0-4587-901b-15c6dd6cf2c6", "33e5c6ce-7044-46ee-b69b-40625e41ed52", "369c620f-48d0-4688-b42b-046d25f96322", "3a7e61e6-31a4-491c-a747-ef9cd41ba27d", "425141eb-a755-434c-9c1a-16e8893134be", "5fadd790-4d5c-4a63-9d0c-39661713cf69", "6d5985ab-a8a9-4473-842b-0956ba1beded", "78c995b4-f5e5-4042-b1f1-63c8db6a4cff", "7eb6c101-7409-4b2d-91df-f18fea43f76d", "80d0c1f9-e50f-4dc6-9f1a-a3248fabd707", "ab0bfb58-908b-4c56-859d-80da7ee1e6bb", "bb2a5284-797a-4ade-a05d-9359bf187f7f"], "title": "Watershed Algorithms and Contrast Preservation", "venue": "discrete geometry for computer imagery", "year": 2003, "id": "a4c9b98a-9f59-4a41-9685-bab4e01d78b5"}
{"abstract": "Abstract   Explanation-based learning (EBL) is a very powerful method for category formation. Since EBL algorithms depend on having good explanations, it is crucial to have effective ways to build explanations, especially in complex real-world situations where complete causal information is not available.  When people encounter new situations, they often explain them by remembering old explanations, and adapting them to fit. We believe that this case-based approach to explanation holds promise for use in AI systems, both for routine explanation and to creatively explain situations quite unlike what the system has encountered before.  Building new explanations from old ones relies on having explanations available in memory. We describe explanation patterns (XPs), knowledge structures that package the reasoning underlying explanations. Using the SWALE system as a base, we discuss the retrieval and modification process, and the criteria used when deciding which explanation to accept. We also discuss issues in learning XPs: what generalization strategies are appropriate for real-world explanations, and which indexing strategies are appropriate for XPs. SWALE's explanations allow it to understand nonstandard stories, and the XPs it learns increase its efficiency in dealing with similar anomalies in the future.", "authors": ["Roger C. Schank", "David B. Leake"], "n_citation": 214, "references": ["14121a9f-3b79-4972-b3c2-c0d08e0bcdd9", "5899eb6c-2e22-4d79-a2be-15fe67911177", "62aa5023-c2a0-44d7-8c82-35afb7441e20", "797343b9-4eea-4172-98e7-62a6c3537032", "d6d3ca6a-01f7-40ca-a018-305b70e901ed"], "title": "Creativity and learning in a case-based explainer", "venue": "Artificial Intelligence", "year": 1989, "id": "10baa660-b74f-4e5c-9d40-4af348b83bc5"}
{"abstract": "This paper presents a review of experiments performed by IBM to investigate the causes of soft errors in semiconductor memory chips under field test conditions. The effects of alpha-particles and cosmic rays are separated by comparing multiple measurements of the soft-error rate (SER) of samples of memory chips deep underground and at various altitudes above the earth. The results of case studies on four different memory chips show that cosmic rays are an important source of the ionizing radiation that causes soft errors. The results of field testing are used to confirm the accuracy of the modeling and the accelerated testing of chips.", "authors": ["Timothy J. O'Gorman", "John M. Ross", "Allen H. Taber", "J.F. Ziegler", "Hans P. Muhlfeld", "Charles J. Montrose", "Huntington W. Curtis", "James L. Walsh"], "n_citation": 196, "references": ["05f60f8c-dfc0-4afb-94a7-2f1e6a791bb2", "087198ef-1e92-466c-a8aa-df5420ab1469", "875ffd4b-e3e8-4759-a662-d49e3d9ef77c", "9ce4b12e-abe8-40b7-8b11-ec8d662d7947", "c2792536-d29d-43fc-bf6b-47320d903af4"], "title": "Field testing for cosmic ray soft errors in semiconductor memories", "venue": "Ibm Journal of Research and Development", "year": 1996, "id": "7083f8af-ef07-4ade-a3c0-b404444f9f74"}
{"abstract": "Isabelle/HOL has recently acquired new versions of Definitional packages for inductive datatypes and primitive recursive functions. In contrast to its predecessors and most other implementations, Isabelle/HOL datatypes may be mutually and indirect recursive, even infinitely branching. We also support inverted datatype definitions for characterizing existing types as being inductive ones later. All our constructions are fully Definitional according to established HOL tradition. Stepping back from the logical details, we also see this work as a typical example of what could be called \"Formal-Logic Engineering\". We observe that building realistic theorem proving environments involves further issues rather than pure logic only.", "authors": ["Stefan Berghofer", "Markus Wenzel"], "n_citation": 76, "references": ["0ad2b0d9-2dd8-4eb9-a81c-5c77b0524584", "11382429-e060-4570-bbf0-9183383f9092", "1c7b762c-aa50-419e-8100-2b6d6eff7d35", "328d2183-4e48-4940-baa8-fa20fb1d8d05", "3fca2601-6e10-463d-9741-87d3c18718e6", "5dc27552-7cb8-4a6e-97a5-257556895bed", "74f727fd-0899-4d16-9992-7d446600e2f6", "8868a24c-947f-457e-8e63-7c8262c6f691", "98e38bda-53b0-415e-8724-f2e76ebfb5a9", "9d80daf1-a122-4f09-92cf-881633660411", "ad9a831a-0be5-4633-8e95-75eb4cb834e0", "b1343042-c239-4718-a7f3-8747b8a9537b", "c5221ddd-db36-4a95-9273-9ab1c827773b", "d7f5bd50-e56b-4b34-b886-14469164d03d"], "title": "Inductive Datatypes in HOL - Lessons Learned in Formal-Logic Engineering", "venue": "theorem proving in higher order logics", "year": 1999, "id": "46289240-6ea8-42dc-bd3e-10fe89defacf"}
{"abstract": "Reactive applications is a wide class of software that responds to user input, network messages, and other events. Recent research on reactive languages successfully addresses the drawbacks of the Observer pattern - the traditional way reactive applications are implemented in the object-oriented setting - by introducing time-changing values and other ad-hoc programming abstractions. However, those approaches are limited to local settings, but most applications are distributed. We highlight the research challenges of distributed reactive pro- gramming and present a research roadmap. We argue that distributed reactive programming not only moves reactive languages to the distributed setting, but is a promising concept for middleware and distributed systems design.", "authors": ["Guido Salvaneschi", "Joscha Drechsler", "Mira Mezini"], "n_citation": 50, "references": ["0b27a792-995a-436c-80e5-9e7a996059f6", "166f8954-64bd-4b14-a3a0-f3c6de56e1c9", "27f1e1a2-045c-4944-a71c-8bbac426fd6e", "4c5a8503-e2e2-46d5-804a-2459b6b9d3e2", "500b6e91-92e8-456b-8b73-b12456c89a72", "56c2cc41-2ea6-4ffc-849c-08dac83eccff", "57f90850-dc98-4523-88d3-5e855d2b28ab", "5ae21162-79ec-4c93-a2c1-b77c3ad94362", "76dc35cc-8186-4280-9028-a2cee7f6a083", "7cf9ee5e-0334-4a35-a546-fc218e219671", "a94defa0-7bba-4816-9b3c-901d096400d7", "e3410e00-35ab-4c9a-b51c-8fb1c1b8e466", "e58b59fa-9c9f-432e-aa10-3a507d00c809", "f923ba1d-4801-496e-ae94-22aa94a4dd5a", "fc8d6188-25ef-425c-ad17-eb33fccf019a"], "title": "Towards Distributed Reactive Programming", "venue": "international conference on coordination models and languages", "year": 2013, "id": "077ac420-603b-4e8f-8e37-7d398cb99783"}
{"abstract": "The use of logic in identifying and analyzing inconsistency in requirements from multiple stakeholders has been found to be effective in a number of studies. Nonmonotonic logic is a theoretically well-founded formalism that is especially suited for supporting the evolution of requirements. However, direct use of logic for expressing requirements and discussing them with stakeholders poses serious usability problems, since in most cases stakeholders cannot be expected to be fluent with formal logic. In this article, we explore the integration of natural language parsing techniques with default reasoning to overcome these difficulties. We also propose a method for automatically discovering inconsistencies in the requirements from multiple stakeholders, using both theorem-proving and model-checking techniques, and show how to deal with them in a formal manner. These techniques were implemented and tested in a prototype tool called  CARL . The effectiveness of the techniques and of the tool are illustrated by a classic example involving conflicting requirements from multiple stakeholders.", "authors": ["Vincenzo Gervasi", "Didar Zowghi"], "n_citation": 180, "references": ["02ca21e7-168b-4c02-b6bf-fa5daf9775d4", "0902aa9b-eecc-491e-ba53-bf39741f5720", "14f791d7-393c-438d-9baf-b854b3977144", "2975c5d4-2edb-4037-b66b-71466c1c2612", "31e3773a-1a81-464a-be99-b2e1f47eef55", "3aa24bd7-7105-4e74-8184-e5a7bec93b8a", "3b8d8731-2b70-4454-a354-6ed9485098e2", "3c433770-8ca9-4cfe-a342-43797ed4d6eb", "41086714-5ed4-4380-9239-940f2b09c9fd", "4814eca2-167a-48bd-a7e6-60150e7a54e3", "48cb28c4-9adf-486e-9334-2b5754b1d65b", "51f1493d-ce3b-4589-8373-55940026fecd", "6dcf9f47-7a83-40b6-890b-9f6bc8585986", "731d6216-3890-4669-805e-b0982d86239e", "74b585d2-c254-432a-ad03-4711db8ec8fe", "8696e539-3052-48dd-b4a7-e7b6250ec7a0", "88d75cd6-1145-4090-bd99-5e2ce87f4a1d", "8aa5b0d3-544f-48c6-889f-4606c3002865", "8c0fbf6a-cbe4-4e8e-a3c2-0e5c5cae4a1d", "972f3420-abaf-4547-afd8-c733d22ceefa", "9c7f4a29-4f61-4dac-92bb-dd8f7ccabeef", "9d19d7dc-f39d-4464-b78c-53f3d84e5dfc", "ae5ac031-ba8e-4f10-8f65-d8d40760e8a2", "af8635a5-1963-4f8b-8346-dbfef5bb5859", "afbc632a-0c15-4e5f-a800-578a52a8152a", "b3a6f742-8207-4274-b7d6-cdbefa3e8938", "bb90565f-4f70-4ae5-9df6-ebf311ea7ba0", "bf7ea925-604f-42c3-8d18-edfa24e8efcb", "d7cd93da-108b-4d01-827f-1e09e08abbde", "ddf3daf9-27cd-41bc-badb-208f7e400a8d", "df46e027-1961-4c39-a568-880cc84f8390", "e8240312-dd04-4382-be5f-b5663b31358f", "f540b303-575d-4e31-a94b-156c50b48e36"], "title": "Reasoning about inconsistencies in natural language requirements", "venue": "ACM Transactions on Software Engineering and Methodology", "year": 2005, "id": "d273f374-3e5b-4f15-8431-8587961285f4"}
{"abstract": "This article describes a service-oriented solution framework designed for home environments. A pragmatic approach is developed to help integrate conventional home automation systems following the service oriented computing paradigm. We believe it is improbable that there will be a single dominant middleware for the home computing that would be right for different appliances. A number of middlewares have recently emerged and it is common knowledge that they haven't a sufficient degree of interoperability. Because of this, the authors show how the approach based on XML, Web services, and Internet protocols, provide a uniform and novel architecture to cope with the architecture complexity in a open standard way. Furthermore a converging layer is conceived to incorporate a high level abstraction by an XML-based home automation language.", "authors": ["Vittorio Miori", "Luca Tarrini", "Maurizio Manca", "Gabriele Tolomei"], "n_citation": 104, "references": ["09afa3dc-018f-4b79-a77a-27a022c95a6b", "3a58388c-4f75-4169-b572-11393c4eba3f", "59351ebe-e2f4-46b7-997a-8ad20ae7fc3d", "ae81c8b3-4db9-4f75-b0cb-5fd547b10883", "f0bed312-5297-4c33-b5f8-3804b5ed6818"], "title": "An open standard solution for domotic interoperability", "venue": "IEEE Transactions on Consumer Electronics", "year": 2006, "id": "b4e05347-eb88-43e0-bc9d-0eae5fe2ffe1"}
{"abstract": "In this paper we present some experiments on the use of a probabilistic model to tag English text, i.e. to assign to each word the correct tag (part of speech) in the context of the sentence. The main novelty of these experiments is the use of untagged text in the training of the model. We have used a simple triclass Markov model and are looking for the best way to estimate the parameters of this model, depending on the kind and amount of training data provided. Two approaches in particular are compared and combined:using text that has been tagged by hand and computing relative frequency counts,using text without tags and training the model as a hidden Markov process, according to a Maximum Likelihood principle.Experminents show that the best training is obtained by using as much tagged text as possible. They also show that Maximum Likelihood training, the procedure that is routinely used to estimate hidden Markov models parameters from training data, will not necessarily improve the tagging accuracy. In fact, it will generally degrade this accuracy, except when only a limited amount of hand-tagged text is available.", "authors": ["Bernard Merialdo"], "n_citation": 691, "references": ["067692a8-da25-4aab-844b-8c164ecdd3e1", "33b2232f-1504-4a45-ad39-3d29f86045af", "58d8ff4d-a21d-4df6-8cea-402df7362b41", "655238f8-a65d-4e86-bcda-4f21a78c7c2d", "80fa2024-e935-44a6-8e36-39af74a76dfe", "8a6d3334-62cd-46ac-a55e-f2701b51b07e", "8ed31ecc-a5c2-49fe-a9af-7343b4f0d97b", "a05838da-089f-4be8-a169-b0223ae4f0ac", "b2609001-4e18-4b54-8f2d-ae1f6cbd0a3d", "b50d58a8-9288-4268-a023-b1a86bb93408", "bdafaf73-ec28-4e05-b1a7-f741edf9ebb2", "c938abb6-5468-4d74-a6cf-97cfb77059c3", "e787e6b9-d48e-4a84-aa46-3277628f099a", "fb2de995-311a-4383-8936-e1e99781c9ac"], "title": "Tagging English text with a probabilistic model", "venue": "Computational Linguistics", "year": 1994, "id": "39a44489-0d56-4f78-abc6-db74c3a29d4e"}
{"abstract": "The projects described in this article all deal with network heterogeneity in the context of distributing multimedia information via multicast transmission. Multicasting significantly improves the efficiency of network resource use in situations involving one-to-many or many-to-many communication. Our work addresses application scenarios including video conferencing, remote collaboration, and video on demand.", "authors": ["Anindo Banerjea"], "n_citation": 50, "references": ["359bfefd-c7d6-4f92-a392-0164a70facdc", "8a9669b3-ebfd-4a7a-a1ea-14c90a61b7a9"], "title": "Heterogeneous networking", "venue": "IEEE MultiMedia", "year": 1997, "id": "425c81c9-d639-45a9-94c6-0cd82b9d890c"}
{"abstract": "In this paper we present a MapReduce task scheduler for shared environments in which MapReduce is executed along with other resource-consuming workloads, such as transactional applications. All workloads may potentially share the same data store, some of them consuming data for analytics purposes while others acting as data generators. This kind of scenario is becoming increasingly important in data centers where improved resource utilization can be achieved through workload consolidation, and is specially challenging due to the interaction between workloads of different nature that compete for limited resources. The proposed scheduler aims to improve resource utilization across machines while observing completion time goals. Unlike other MapReduce schedulers, our approach also takes into account the resource demands for non-MapReduce workloads, and assumes that the amount of resources made available to the MapReduce applications is variable over time. As shown in our experiments, our proposal improves the management of MapReduce jobs in the presence of variable resource availability, increasing the accuracy of the estimations made by the scheduler, thus improving completion time goals without an impact on the fairness of the scheduler.", "authors": ["Jorda Polo", "Yolanda Becerra", "David Carrera", "Jordi Torres", "Eduard Ayguad\u00e9", "Malgorzata Steinder"], "n_citation": 8, "references": ["28de8642-8362-4aa8-b6dc-e70c9f642b61", "4b8ca54a-e9b6-4b8c-b331-a971f87eaf96", "59af7e25-c0ee-4af5-acea-a58dfe4ccac4", "9558f1d8-969d-41b4-bcff-d1d0faa61595", "9e34dcae-7894-4316-81e2-679a21cecb8d", "b74201b2-05cc-48bf-afdb-4cc7c800069e", "c1f13d21-9542-4877-b2c3-28e364c68b0a", "c2534749-2d1f-48d7-a4c1-036035fa3134", "c3a2fceb-b388-4868-916b-174d03748d6a", "e428d749-c2f1-41da-a00e-ef44850bf4c3", "f4e7237a-95e1-46c6-9d38-0d3ab22e528d"], "title": "Adaptive MapReduce Scheduling in Shared Environments", "venue": "cluster computing and the grid", "year": 2014, "id": "24d9b096-6b60-4dd8-92a8-daa1e9831341"}
{"abstract": "With the discovery of insulin came a deeper understanding of therapeutic options for one of the most devastating chronic diseases of the modern era, diabetes mellitus. The use of insulin in the treatment of diabetes, especially in those with severe insulin deficiency (type 1 diabetes), with multiple injections or continuous subcutaneous infusion, has been largely successful, but the risk for short term and long term complications remains substantial. Insulin treatment decisions are based on the patient\u2019s knowledge of meal size, exercise plans and the intermittent knowledge of blood glucose values. As such, these are open loop methods that require human input. The idea of closed loop control of diabetes treatment is quite different: automated control of a device that delivers insulin (and possibly glucagon or other medications) and is based on continuous or very frequent glucose measurements. Closed loop insulin control for type 1 diabetes is not new but is far from optimized. The goal of such a system is to avoid short-term complications (hypoglycemia) and long-term complications (diseases of the eyes, kidneys, nerves and cardiovascular system) by mimicking the normal insulin secretion pattern of the pancreatic beta cell. A control system for automated diabetes treatment consists of three major components, (1) a glucose sensing device that serves as the afferent limb of the system; (2) an automated control unit that uses algorithms which acquires sensor input and generates treatment outputs; and (3) a drug delivery device (primarily for delivery of insulin), which serves as the system\u2019s efferent limb. There are several major issues that highlight the difficulty of interacting with the complex unknowns of the biological world. For example, development of accurate continuous glucose monitors is crucial; the state of the art in 2009 is that such devices sometimes experience drift and are intended only to supplement information received from standard intermittent blood glucose data. In addition, it is important to acknowledge that an \u201cautomated\u201d closed loop pancreas cannot approach the complexity of the normal human endocrine pancreas, which takes continuous data from substrates, hormones, paracrine compounds and autonomic neural inputs, and in response, secretes four hormones. Another major issue is the substantial absorption/action delay of insulin given by the subcutaneous route. Because of this delay, some researchers have recently given a portion of the meal-related insulin in an open loop manner before the meal and found this hybrid approach to be superior to closed loop control. Proportional-Integral-Derivative (PID) systems adapted from the industrial sector utilize control algorithms that alter output based on proportional (difference between actual and target levels), derivative (rate of change) and integral (time-related summative) errors in glucose. These algorithms have proven to be very promising in limited clinical trials. Related algorithms include a \u201cfading memory\u201d system that combines the proportional-derivative components of a classic PID system with time-relating decay of input signals that allow greater emphasis on more recent glucose values, a characteristic noted in mammalian beta-cells. Model Predictive Control (MPC) systems are highly adaptive methods that utilize mathematical models based on observations of biological behavior patterns using system identification and are now undergoing testing in humans. The application of further mathematical models, such as fuzzy control and artificial neural networks, are also promising, but are largely clinically untested. In summary, the prospects for closed loop control of glycemia in persons with diabetes have improved considerably. Major limitations include the delayed absorption/action of subcutaneous insulin and the imperfect stability of currently-available continuous glucose sensors. The potential for improved glycemic control in persons with diabetes brings with it the potential for reduction in the frequency of acute and chronic complications of diabetes.", "authors": ["Joseph El Youssef", "Jessica R. Castle", "W. Kenneth Ward"], "n_citation": 10, "references": ["1d1da8a8-f672-4d0f-9dc2-9c114636bec0", "1dfddb0a-c28f-4852-af75-d6c8f3c971a4", "f1f2dda9-ed17-4b4e-bbfc-53a3d1ce8572"], "title": "A Review of Closed-Loop Algorithms for Glycemic Control in the Treatment of Type 1 Diabetes", "venue": "Algorithms", "year": 2009, "id": "af2b10d3-34eb-450c-a72c-aab58de78d3f"}
{"abstract": "Applications of wireless communications networks are emerging continuously. To offer a good level of security in these applications, new standards for wireless communications propose solutions based on cryptographic algorithms working on special modes of operation. This work presents a custom hardware architecture for the AES-CCM protocol (AES-CCMP) which is the basis for the security architecture of the IEEE 802.11i standard. AES-CCMP is based on the AES-CCM algorithm that performs the Advanced Encryption Standard (AES) in CTR with CBC-MAC mode (CCM mode), plus specialized data formatting modules, providing different security services through iterative and complex operations. Results of implementing the proposed architecture targeting FPGA devices are presented and discussed. A comparison against similar works shows significant improvements in terms of both throughput and efficiency.", "authors": ["Ignacio Algredo-Badillo", "Claudia Feregrino-Uribe", "Ren\u00e9 Cumplido", "Miguel Morales-Sandoval"], "n_citation": 7, "references": ["3f46ccdc-eb5a-4a83-8870-bb13cbbae612", "4f818994-f879-437c-8171-9f5655bb420b", "85cbbf2b-a28b-48fc-8c4f-086d2716dfbf", "c8d9cc01-bac3-4d68-b14d-ef588345c0eb", "db00cab8-b227-4ed4-af56-fad75651ad39", "ef94327f-604c-490c-8128-d01a2ec32779"], "title": "Efficient hardware architecture for the AES-CCM protocol of the IEEE 802.11i standard", "venue": "Computers & Electrical Engineering", "year": 2010, "id": "b80ffaed-8c38-48df-a161-be6f056b8a85"}
{"abstract": "Programming language design benefits from constructs for extending the syntax and semantics of a host language. While C's string-based macros empower programmers to introduce notational shorthands, the parser-level macros of Lisp encourage experimentation with domain-specific languages. The Scheme programming language improves on Lisp with macros that respect lexical scope.    The design of Racket---a descendant of Scheme---goes even further with the introduction of a full-fledged interface to the static semantics of the language. A Racket extension programmer can thus add constructs that are indistinguishable from \"native\" notation, large and complex embedded domain-specific languages, and even optimizing transformations for the compiler backend. This power to experiment with language design has been used to create a series of sub-languages for programming with first-class classes and modules, numerous languages for implementing the Racket system, and the creation of a complete and fully integrated typed sister language to Racket's untyped base language.   This paper explains Racket's language extension API via an implementation of a small typed sister language. The new language provides a rich type system that accommodates the idioms of untyped Racket. Furthermore, modules in this typed language can safely exchange values with untyped modules. Last but not least, the implementation includes a type-based optimizer that achieves promising speedups. Although these extensions are complex, their Racket implementation is just a library, like any other library, requiring no changes to the Racket implementation.", "authors": ["Sam Tobin-Hochstadt", "Vincent St-Amour", "Ryan Culpepper", "Matthew Flatt", "Matthias Felleisen"], "n_citation": 141, "references": ["029a1e9b-fa5e-4709-9278-6f3ea9e3a9fc", "0f3f09bc-d75b-4e0d-81e4-389bf4d82ca6", "12d0365a-8149-44d2-97fb-75522e7dfc5b", "1d70c35a-f40f-4055-8038-419ca8228c4c", "23c82e3b-76e3-401a-835b-7b7cc9e708c0", "2e75ba41-18ac-4140-99ad-461b48f310cb", "367e9c6b-96b8-4733-aaed-7b4a7a846aeb", "4a9518be-73f1-4a63-8edc-4731dd8f7e07", "4d8d1877-21e7-4424-9478-acd64293a6e4", "5b0dfca1-5e97-438e-b6de-159ab775f5f5", "60b68afb-a5e4-468b-9842-4be3fc2f644d", "63c6ec24-cc4e-44c9-b491-5f6300ee021d", "6d802dfb-31a4-4a44-ac25-f2a4c6a8734f", "6e1ffa81-92b1-4b3b-ba29-8d0df5342208", "78d7b591-0f70-43dc-b979-86370c11b742", "824e55ba-6bad-40ab-bd1c-db0279d75e47", "866c1b17-cecb-4f9f-a120-9ad48dd86b79", "910b6285-e68c-427d-ba9a-f77981c2894d", "964c1fd4-735f-4e9d-aed3-e9f59636e2af", "9a99ff5d-fd00-429f-9f7d-087ee23b5d5b", "a1f6749f-08b1-470b-a295-ef37b2b1298e", "a78ef3f0-b442-43e1-bc8d-627713989e5e", "aaf92405-0660-480a-a2e6-31dfeeafd866", "ad6b745c-9d2d-4421-b2d2-2ed407d1c596", "b2ea4241-de4d-4815-bfe4-70a09047146a", "d4f11cb9-772e-4893-850e-fcefe1dfcdf5", "e8a36a78-5fdc-4201-b5ab-b0603da95906", "fabe3a4b-7887-4501-a95c-edc3d4749917"], "title": "Languages as libraries", "venue": "programming language design and implementation", "year": 2011, "id": "147512c4-a268-46d7-83df-7a7149a4a5b6"}
{"abstract": "In this paper, we focus our discussion on the rough set-based partitioning attribute selection. Firstly, we point out that the statement of MMR technique is an extension of Mazlack's technique is unreasonable. We prove that the mean roughness of MMR technique is only the opposite of that Mazlack's TR technique. Secondly, we observe that the suggestion of MMR to achieve lower computational complexity using the roughness measurement based on relationship between an attribute ai \u2208 A and the set defined as A-{ai} instead of calculating the maximum with respect to all {aj} where ai \u2260 aj, 1 \u2264 i, j \u2264 |A| only can be applied to a special type of information system and we illustrate this with an example. Finally, we propose an alternative technique for selecting partitioning attribute using rough set theory based on dependency of attributes in an information system. We show that the proposed technique is a generalization and has lower computational complexity than that of TR and MMR.", "authors": ["Tutut Herawan", "Mustafa Mat Deris"], "n_citation": 12, "references": ["25929c9b-6e24-4f8d-b284-1dff4358a6d5", "9fbb8fa1-a0e3-4792-a96a-31a7b8e36719", "a4589cfe-15e7-4c34-9349-d002d1d2c9df"], "title": "A framework on rough set-based partitioning attribute selection", "venue": "international conference on intelligent computing", "year": 2009, "id": "e1fa23dd-6c54-48e8-a2e4-3f6263ce05b2"}
{"abstract": "Abstract   We consider the broadcasting problem in the shouting communication mode in which any node of a network can inform all its neighbors in one time step. In addition, during any time step a number of links less than the edge-connectivity of the network can be faulty. The problem is to find an upper bound on the number of time steps necessary to complete broadcasting under this additional assumption. Fraigniaud and Peyrat proved for the   n  -dimensional hypercube that   n+  O  (  log  n)   time steps are sufficient. De Marco and Vaccaro decreased the upper bound to   n+7   and showed a worst case lower bound   n+2   for   n\u22653  . We prove that   n+2   time steps are sufficient. Our method is related to the isoperimetric problem in graphs and can be applied to other networks.", "authors": ["Stefan Dobrev", "Imrich Vr\u0165o"], "n_citation": 27, "title": "Optimal broadcasting in hypercubes with dynamic faults", "venue": "Information Processing Letters", "year": 1999, "id": "a2e929b1-5bb8-4b00-ae13-4b4143eaf963"}
{"abstract": "Display Omitted New TSPs with costs and times between cities with stay times at cities are formulated.An ACO-PSO algorithm is developed and used successively and iteratively one after another.A TSP is formulated as a profit maximization problem with crisp expenditure and return.Total tour time including travel and stay times is fixed.Behavioral studies of TSPs are presented for some numerical data with parametric study. Here a new model of Traveling Salesman Problem (TSP) with uncertain parameters is formulated and solved using a hybrid algorithm. For this TSP, there are some fixed number of cities and the costs and time durations for traveling from one city to another are known. Here a Traveling Salesman (TS) visits and spends some time in each city for selling the company's product. The return and expenditure at each city are dependent on the time spent by the TS at that city and these are given in functional forms of t. The total time limit for the entire tour is fixed and known. Now, the problem for the TS is to identify a tour program and also to determine the stay time at each city so that total profit out of the system is maximum. Here the model is solved by a hybrid method combining the Particle Swarm Optimization (PSO) and Ant Colony Optimization (ACO). The problem is divided into two subproblems where ACO and PSO are used successively iteratively in a generation using one's result for the other. Numerical experiments are performed to illustrate the models. Some behavioral studies of the models and convergences of the proposed hybrid algorithm with respect to iteration numbers and cost matrix sizes are presented.", "authors": ["Aditi Khanra", "Manas Kumar Maiti", "Manoranjan Maiti"], "n_citation": 10, "references": ["05d12364-adab-45c2-964f-1d5c9c1a2b25", "2ab7414f-4327-4539-902c-6be86947d1fb", "2d4509e6-b97c-479f-95bb-89f3e8cf5227", "3db4a24a-05a4-4a78-8805-7bdcda5b1a73", "410533da-8d76-4cc3-a931-9e73e3e63df4", "499cd7f0-d723-45ae-b140-0fca46c5a8d2", "52addf3d-5f90-4112-9321-bda23f277e5f", "564e5527-c8dc-41d2-be92-cb357e6b9cd0", "621f7668-5dd3-4e82-a903-6ac52aa0fcc7", "6ef1335e-27a8-4c41-9da0-f1c31fcbb083", "737667ea-83c6-42f4-8578-97931bc30ed4", "9b80e173-2d0d-4e2d-8cd0-0fcfe230fd81", "a12cba49-fa6b-43e6-b317-31abfe7b576a", "a1d785a6-3db4-4b10-aa82-fcc7f125772d", "ac4d7c1a-5e65-4c56-82b7-50631518f91f", "eb8a8719-de54-493f-8719-439b2b3e6c20", "ef31bbd2-7fb6-48a2-92e3-8a860f35c6be", "f5cc526f-6cd4-401e-aac1-416ac15aa146", "ff1e774d-97a6-4f57-98c0-9bb80564a681"], "title": "Profit maximization of TSP through a hybrid algorithm", "venue": "Computers & Industrial Engineering", "year": 2015, "id": "c6afe9a7-2753-4c50-9d9c-c1ff24fba9f4"}
{"abstract": "In their efforts to determine how technology affects the software development process, researchers often overlook organizational and social issues. The authors report on two experiments to discover how developers spend their time. They describe how noncoding activities can use up development time and how even a reluctance to use e-mail can influence the development process. The first experiment was to see how programmers thought they spent their time by having them fill out a modified time card reporting their activities, which we called a time diary. In the second experiment, we used direct observation to calibrate and validate the use of time diaries, which helped us evaluate how time was actually being used. >", "authors": ["Dewayne E. Perry", "Nancy A. Staudenmayer", "Lawrence G. Votta"], "n_citation": 419, "references": ["706dae66-5418-4f3e-954b-d81b3c8d06ff", "93ee40fd-dd8e-484e-af97-f80768ab9714", "998e4aad-b764-4e31-83a3-56d164cfb1e2"], "title": "People, organizations, and process improvement", "venue": "IEEE Software", "year": 1994, "id": "1ef9cc2b-fd41-4e89-b594-58b5478d1cf8"}
{"abstract": "In this paper, a new concept of invariance for saturated linear systems is presented. This new notion of invariance, denoted SNS-invariance, has a number of geometrical properties that makes its use suitable for the estimation of the domain of attraction of saturated systems. The notion of SNS-domain of attraction, that serves as an estimation of the domain of attraction of a saturated system, is introduced. It is shown that, in case of single input saturated systems, any contractive set is contained in the SNS-domain of attraction. A simple algorithm that converges to the SNS-domain of attraction is presented. Some illustrative examples are given.", "authors": ["T. Alamo", "A. Cepeda", "D. Limon", "Eduardo F. Camacho"], "n_citation": 50, "references": ["591b620f-eff6-4a64-9e1c-2ec5e5f10dac", "bec5f477-2900-4bfa-85d0-1b88f31715c8"], "title": "A NEW CONCEPT OF INVARIANCE FOR SATURATED SYSTEMS", "venue": "", "year": 2005, "id": "d54d6cea-ada6-4565-b36a-81b81aa62a90"}
{"authors": ["Xavier Fern\u00e1ndez Salgado", "Eduardo Rodr\u00edguez Banga"], "n_citation": 3, "references": ["a416ee53-db06-4b44-b5ab-20c7f8bd1983", "a996b630-dc7d-4df3-b97e-99d29bd148d4", "d2130868-9a4e-4fb5-b548-8bef70317bfc"], "title": "Segmental duration modelling in a text-to-speech system for the galician language.", "venue": "", "year": 1999, "id": "b0706c65-a28e-4583-b8b3-4e11b837a9c6"}
{"abstract": "The race condition checker rccjava uses a formal type system to statically identify potential race conditions in concurrent Java programs; but it requires programmer-supplied type annotations. This paper describes a type inference algorithm for rccjava. Due to the interaction of parameterized classes and dependent types, this type inference problem is NP-complete. This complexity result motivates our new approach to type inference, which is via reduction to propositional satisfiability. This paper describes our type inference algorithm and its performance on programs of up to 30,000 lines of code.", "authors": ["Cormac Flanagan", "Stephen N. Freund"], "n_citation": 69, "references": ["06ffefee-1eff-4644-8d0f-3d2c6563888f", "078e87d1-e29f-4f67-ae83-e533511b7563", "0f4009ac-4024-419e-b26a-e7c9b41533b4", "119162d6-0403-4980-8096-f6fa5d9fc228", "1788761f-4652-4e50-a778-9ed73b9f4828", "17d60dc9-9dc8-47c8-a6af-b5e5226589e1", "1bee2ab0-0e5d-4351-89af-fff912407ef1", "21056042-5e05-482e-8a85-0926d64f27fd", "2fad3463-c71d-4fdc-bb31-781e27b57f54", "460deb6a-fd08-43dd-aff2-1eafbad0a53b", "62b2e0fe-953b-4377-b8fd-58b6ebb41104", "6c20a4a2-0e3f-4446-b2e9-5f454d91b1c9", "8ec678d3-4fc6-4c88-9d36-21a57b3fa6ab", "9d826763-53f1-4bfd-a7f9-6a27fc26a8ae", "9e93bdbe-58fe-4bfc-b26b-f3d9e8e573f7", "a1cef084-3138-4c82-a614-5964ba0af124", "a1f625f5-8f46-4b13-9d83-059a05f5aaea", "aac2eece-00f1-4f6b-9d8f-9cd6253ddc5f", "ab5b7670-b809-4749-811d-f3cbade6bd81", "cb30469e-2689-43fd-aa0b-2d88d40a12db", "d892fa95-e02d-4f99-8591-65596bc9c22a", "e30b606d-f664-4588-a8cc-149c9476cc28", "ffd9b6a9-4273-494f-992b-e0d7694805e3"], "title": "Type inference against races", "venue": "static analysis symposium", "year": 2004, "id": "5133dd9f-fd4c-48f2-8e72-05b406204ecc"}
{"abstract": "A robust watermarking scheme for images is proposed. The proposed method can be also be easily extended to other signals like audio and video. In the proposed method an optimal solution is obtained for maximizing the detection statistic (which is an indication of the degree of certainty with which the signature or the watermark is detected), for a given permitted distortion of the host signal, and additive noise variance. Other issues for improving the security of the watermarking scheme, like key based transforms, are also addressed.", "authors": ["Mahalingam Ramkumar", "Ali N. Akansu"], "n_citation": 16, "references": ["240b7e8b-6bf3-456b-916c-c33d554201ab", "2cd57515-50e6-4ba2-afed-4e3411ffa847", "45abd8c1-38ec-44e4-bd25-2e467ef30e6e", "46d13bdf-9a55-4ecc-98d2-5f11aff87642", "8180a72e-f95f-4fed-a018-d7bca3a1b52f", "ae73d908-4791-4f4a-83cb-e91d938e41df", "af80975c-2c57-477b-b1ac-02be5303dd17", "dedb6b66-9a20-45f4-b084-b2369602f37e", "fb85d20f-8eea-46f3-bf37-c6f03c5468b4"], "title": "A robust oblivious watermarking scheme", "venue": "international conference on image processing", "year": 2000, "id": "bf4bd7bd-028b-4acc-9653-5fb577c4bafa"}
{"abstract": "The feedforward multilayer perceptron (MLP) with back-propagation of error is described. Since use of this network requires a set of labeled input-output, as such it cannot be used for segmentation of images when only one image is available. (However, if images to be processed are of similar nature, one can use a set of known images for learning and then use the network for processing of other images.) A self-organizing multilayer neural network architecture suitable for image processing is proposed. The proposed architecture is also a feedforward one with back-propagation of errors; but like MLP it does not require any supervised learning. Each neuron is connected to the corresponding neuron in the previous layer and the set of neighbors of that neuron. The output status of neurons in the output layer is described as a fuzzy set. A fuzziness measure of this fuzzy set is used as a measure of error in the system (instability of the network). Learning rates for various measures of fuzziness have been theoretically and experimentally studied. An application of the proposed network in object extraction from noisy scenes is also demonstrated.", "authors": ["Ashish Ghosh", "Nikhil R. Pal", "Sankar K. Pal"], "n_citation": 155, "references": ["03693fa8-9e5f-43e5-b47d-7ba8c88809be", "cb731238-55b6-4404-a8d7-2b386fae4623", "e247c79b-56e9-4d70-986c-214c3ece237e", "e2acd5ab-1850-4c08-b3a5-d35488f5d847", "e76554d3-43f0-4bff-bf59-551014bb1af8", "ea903e10-a042-46d2-92fb-48a269a771de", "f9013aa3-aadb-4820-a1de-c6932b0bbce6"], "title": "Self-organization for object extraction using a multilayer neural network and fuzziness measures", "venue": "IEEE Transactions on Fuzzy Systems", "year": 1993, "id": "2d412b4f-143c-4813-aa7d-27da3dd244ff"}
{"abstract": "In a navigation-oriented interaction paradigm, such as desktop, mixed and augmented virtual reality, recognizing the user needs is a valuable improvement, provided that the system is able to correctly anticipate the user actions. Methodologies for adapting both navigation and content allow the user to interact with a customized version of the 3D world, lessening the cognitive load needed for accomplishing tasks such as finding places and objects, and acting on virtual devices.This work discusses adaptivity of interaction in 3D environments, obtained through the coordinated use of three approaches: structured design of the interaction space, distinction between a base world layer and an interactive experience layer, and user monitoring in order to infer interaction patterns. Identification of such recurring patterns is used for anticipating users actions in approaching places and objects of each experience class. An agent based architecture is proposed, and a simple application related to consumer e-business is analyzed.", "authors": ["Augusto Celentano", "Fabio Pittarello"], "n_citation": 50, "references": ["01f6a3b8-eef1-4de2-af44-e0cef74f2f82", "0ac356d2-d5ed-488e-b761-afb795dd29e4", "1ade902b-e233-4d79-967d-44802f312a97", "1dd58f0c-83b5-4f1a-862f-1abdca70d72d", "20548f6b-8474-4431-b16e-1e6847070577", "2862d6db-8f5c-4959-bf1e-37e6844a3b3e", "3a9390a8-72d4-4ea9-84f5-a32fbd67d5c0", "3d81dcf1-b7a3-41ff-88c4-95195abf68c4", "5ff5401a-0dc8-4e2b-b5ad-e994b833c79c", "7467f756-9125-40f6-b276-b1d911f0ded9", "8ab23f4b-0b87-42ed-9922-dbd10d9e845d", "9ebf2cbd-ae53-487a-8410-d2a5c706f133", "a0139ea8-e86c-4ca9-890a-bdc71cf489d1", "a9f1800c-154d-453a-80f7-ba1f5f5caa8f", "af5be8d8-91fb-4577-b39d-e68f4331ce4a", "b5475a1c-4922-45de-86fb-1f73151a7ef9", "d2d52b31-2eb8-4fdd-bf9d-b0c4f82b25a8", "d642e665-4c3b-46c9-8920-f265352d9327", "e906cffb-048d-496b-b6b9-035c76d43d13"], "title": "Observing and adapting user behavior in navigational 3D interfaces", "venue": "advanced visual interfaces", "year": 2004, "id": "f735a12c-fcec-477b-acd5-4f15a35759b8"}
{"abstract": "A dynamic feedforward scheme allows measurable signal decoupling to be solved independently of other problems simultaneously present in the design of a control system like, e.g., stabilization, robustness, insensitivity to disturbances. The synthesis procedure, based on the properties of self-bounded controlled invariant subspaces, ensures the minimal complexity of the feedforward unit, in terms of minimal unassignable dynamics and minimal dynamic order, in the case of left-invertible systems and, on some specific conditions, also in the case of non-left-invertible systems. The output dynamic feedback set up to guarantee stability (or, more generally, robustness or insensitivity properties) does not affect the complexity of the feedforward unit, since the peculiar layout where the feedback unit receives an additional input from the precompensator preserves, in the extended system, exactly the same set of unassignable internal eigenvalues of the minimal self-bounded controlled invariant subspace as that defined for the original system. The overall control structure turns out to be a two-degree-of-freedom controller completely devised in the geometric context", "authors": ["Elena Zattoni"], "n_citation": 50, "references": ["29ae0897-445f-494c-bee3-5eaf58ce3c4f", "57d2035f-8ca6-4807-b479-08258976f741", "e5e8fa6e-e6b5-412a-907a-2650788cd282"], "title": "Decoupling of Measurable Signals via Self-Bounded Controlled Invariant Subspaces: Minimal Unassignable Dynamics of Feedforward Units for Prestabilized Systems", "venue": "IEEE Transactions on Automatic Control", "year": 2007, "id": "6c7e6160-c249-4107-886a-b204c4680182"}
{"abstract": "In many conventional methods for change detection, the detections are carried out by comparing a test statistic, which is computed locally for each location on the image grid, with a global threshold. These \u2018nonadaptive\u2019 methods for change detection suffer from the dilemma of either causing many false alarms or missing considerable parts of non-stationary areas. This contribution presents a way out of this dilemma by viewing change detection as an inverse, ill-posed problem. As such, the problem can be solved using prior knowledge about typical properties of change masks. This reasoning leads to a Bayesian formulation of change detection, where the prior knowledge is brought to bear by appropriately specified a priori probabilities. Based on this approach, a new, adaptive algorithm for change detection is derived where the decision thresholds vary depending on context, thus improving detection performance substantially. The algorithm requires only a single raster scan per picture and increases the computional load only slightly in comparison to non-adaptive techniques.", "authors": ["Til Aach", "Andre Kaup"], "n_citation": 240, "references": ["568a918b-5345-4a10-a66e-89a5f31bcc76", "95d5fdd6-9320-40fe-aa63-5e85d87fd671", "9bd24114-921d-4869-ba66-48e4afef2303", "b8a195a1-fcf1-4b2f-9162-5bd6c84b60a1", "cfa3f924-ec35-4d04-a99b-25979e334787", "e3dd33bb-fda1-4bd2-bba4-b19386154ce8", "eafcf027-2d78-444b-a6b7-7d0112a31833"], "title": "Bayesian algorithms for adaptive change detection in image sequences using Markov random fields", "venue": "Signal Processing-image Communication", "year": 1995, "id": "dcd33a7e-952a-474e-b5ef-9c062724d0f2"}
{"abstract": "In this paper we propose a method to design local observers for Takagi-Sugeno fuzzy models obtained from nonlinear systems by the sector nonlinearity approach. When a global observer cannot be designed, using our method it is still possible to design observers that are valid in a well-defined region of the state-space. The design is based on a nonquadratic Lyapunov function. Depending on whether or not the scheduling vector is a function of the states to be estimated, the conditions are formulated as an LMI or a BMI problem, respectively. The results are illustrated on simulation examples, for which classical observer design conditions are unfeasible.", "authors": ["Zs\u00f3fia Lendek", "Thierry-Marie Guerra", "Robert Babuska"], "n_citation": 50, "references": ["1f5a8bf5-7699-4ebf-887d-239b30cea60c", "30b04abf-9f75-4806-8f4f-50f206db9be6", "34bed7de-1f98-44de-bc1f-6f3235b579ba", "718ea777-61d7-454a-a538-fb4c477fcaf1", "852f8600-880e-4ce4-932f-e9997e9a4105", "923ee3f0-d63d-470f-856e-79e6ca45e028", "b2ed01c0-9398-4aa1-bd47-dd089289b60a", "b793a439-203f-421b-99ec-697a24e8e266", "b8214d83-f4f0-4c4d-bef5-3ce4fae13dc5", "e07c17af-995e-477a-9808-cb8ef7f8d7e1", "e1f415bc-5ccf-45d4-b92c-af63c997113e", "ed5f7287-0719-4206-aefc-b540588c7e8a"], "title": "On non-PDC local observers for TS fuzzy systems", "venue": "ieee international conference on fuzzy systems", "year": 2010, "id": "31a6a8af-67ff-470f-b41a-31b897df6b28"}
{"authors": ["Johannes Bohnet", "J\u00fcrgen D\u00f6llner"], "n_citation": 1, "title": "Visually exploring control flow graphs to support legacy software migration.", "venue": "", "year": 2007, "id": "e98a2bc5-63d0-41b4-8054-2ccd1eaaf8c3"}
{"abstract": "Purely script-based approaches to building interactive narratives have often limited interaction capabilities where variability demand exponential work. This is why Intelligent Virtual Agents (IVAs) are a transparent technique to handle user interaction in interactive narrative systems. However, it is hard to predict a sense of educational purpose in the global behavior of a group of IVAs, if no script or control is given. Efforts have been channelled to achieve such control, but are yet to achieve truly satisfactory results. These efforts are usually based on a direct connection between the control and the IVA architecture, which is a source of exponential complication. We propose a system that, based on a common ontology, can flexibly support the human authoring of educational goals independently of any specific IVA architecture. This is done by having a stage manager that follows an episodic based narrative where each episode is only specified through a set of properties and conditions that set the context for the characters. Although acting as they please, this contextualization will limit their range of action thereby facilitating the achievement of dramatic and educational goals.", "authors": ["Daniel Sobral", "Isabel Machado", "Ana Paiva"], "n_citation": 50, "references": ["30af4249-92e6-4836-902a-e12d6d6b1d6c", "43ca9d4e-ed5a-4911-bb63-3f8c769f26bf"], "title": "Machiavellian Characters and the Edutainment Paradox", "venue": "intelligent virtual agents", "year": 2003, "id": "ef8730c8-67d1-474c-8ca8-3faece75b386"}
{"abstract": "Javari is an extension of Java that supports reference immutability constraints. Programmers write  readonly type qualifiers and other constraints, and the Javari typechecker detects mutation errors (incorrect side effects) or verifies their absence. While case studies have demonstrated the practicality and value of Javari, a barrier to usability remains. A Javari program will not typecheck unless all the references in the APIs of libraries it uses are annotated with Javari type qualifiers. Manually converting existing Java libraries to Javari is tedious and error-prone.#R##N##R##N#We present an algorithm for inferring reference immutability in Javari. The flow-insensitive and context-sensitive algorithm is sound and produces a set of qualifiers that typecheck in Javari. The algorithm is precise in that it infers the most  readonly qualifiers possible; adding any additional  readonly qualifiers will cause the program to not typecheck. We have implemented the algorithm in a tool, Javarifier, that infers the Javari type qualifiers over a set of class files.#R##N##R##N#Javarifier automatically converts Java libraries to Javari. Additionally, Javarifier eases the task of converting legacy programs to Javari by inferring the mutability of every reference in a program. In case studies, Javarifier correctly inferred mutability over Java programs of up to 110 KLOC.", "authors": ["Jaime Quinonez", "Matthew S. Tschantz", "Michael D. Ernst"], "n_citation": 50, "references": ["002caa31-909c-43d4-921d-88f52de6087b", "0e98eff1-faa9-416f-9121-4b41355831c4", "115768ce-b495-45b6-a09f-9399dad79042", "2a3a3ebb-3913-419d-84f3-bd887abdb9ac", "2fc708d1-ea8b-4c80-878d-b218fafa5f2b", "3175c2a0-d694-440b-b0ea-9cc97615b55e", "4ee2e7ac-0b88-4b58-a190-b20c9d2f067a", "5133dd9f-fd4c-48f2-8e72-05b406204ecc", "531421da-3dc1-4ffd-aed1-bf13fff53bbf", "6aec0cf3-52c8-4b68-bc14-0e0c89e7416f", "73c1dcb8-e5c5-4c5d-9d79-b6561266c69d", "783a6f4c-8640-4cf8-b996-a5c420104a44", "7bcc6305-23bf-46c7-abba-19b5bc7722d1", "8cd66f52-14f5-4679-8d5a-c065bb1c32e1", "a41edb0b-6fb4-44b0-9ac0-632b8c7f9915", "a7440d6d-380f-450b-9c1a-adb360fafae5", "bf9cecbb-daea-4cda-b521-e78ed8413382", "ca7eff09-718f-473d-b18f-66009725f7c0", "d002cd75-6922-4e7b-8088-2a57bcb572ef", "e6548198-486a-4bc6-af78-3a96966afd36", "e8a36a78-5fdc-4201-b5ab-b0603da95906", "fe1c176d-4868-4d31-8889-bd8fd307d91f"], "title": "Inference of Reference Immutability", "venue": "european conference on object oriented programming", "year": 2008, "id": "0e56ae2e-0c26-432a-b6c2-d16fbe462940"}
{"abstract": "This paper explores the idea of knowledge-based security policies, which are used to decide whether to answer queries over secret data based on an estimation of the querier's possibly increased knowledge given the results. Limiting knowledge is the goal of existing information release policies that employ mechanisms such as noising, anonymization, and redaction. Knowledge-based policies are more general: they increase flexibility by not fixing the means to restrict information flow. We enforce a knowledge-based policy by explicitly tracking a model of a querier's belief about secret data, represented as a probability distribution, and denying any query that could increase knowledge above a given threshold. We implement query analysis and belief tracking via abstract interpretation, which allows us to trade off precision and performance through the use of abstraction. We have developed an approach to augment standard abstract domains to include probabilities, and thus define distributions. We focus on developing probabilistic polyhedra in particular, to support numeric programs. While probabilistic abstract interpretation has been considered before, our domain is the first whose design supports sound conditioning, which is required to ensure that estimates of a querier's knowledge are accurate. Experiments with our implementation show that several useful queries can be handled efficiently, particularly compared to exact i.e., sound inference involving sampling. We also show that, for our benchmarks, restricting constraints to octagons or intervals, rather than full polyhedra, can dramatically improve performance while incurring little to no loss in precision.", "authors": ["Piotr Mardziel", "Stephen Magill", "Michael Hicks", "Mudhakar Srivatsa"], "n_citation": 50, "references": ["053663ee-9dc3-473a-85b1-f8dcb0c79745", "0652da8e-50fd-4eac-8724-c9d3ec7bada6", "09069e93-91e2-4401-9f9a-c788fce2448d", "0a2a5d00-dc47-4f79-9bd3-b4e1e478cc89", "29c59b4a-f88b-4624-a600-3ad57359c40d", "2c8756b4-8c31-4758-9d54-570772e496f0", "2da36b09-5a3a-4048-ab4c-e6105159f2c4", "2e13b327-2499-4062-b3f5-6f6ada726bb7", "32e59ad7-e454-40f5-b8b5-c646128e6c3c", "337dd8bb-e003-4b23-8185-3de92f40abbf", "46461e73-e424-4a75-900e-2d6189ab47fc", "5158aa97-1321-40c2-a54e-63e0ef806e4b", "5480cd03-0f14-4455-804a-e22a76fddc92", "548d6335-f752-49dc-93a5-fc79d76e511d", "59d08bd3-cfe5-486b-be34-27ee2a7497dc", "5ab72b75-7ff8-4d0b-8d71-05e7ec4a814c", "5b7626f0-9946-44b8-99d1-4b06e36c6973", "635e2014-6579-4acf-9737-49593bc74701", "7bb71afa-91b8-46e7-9008-da84e0427b93", "847caee1-9f01-43a6-9c75-24691fd4d961", "84d59312-12ed-42ec-83ca-83e5a7ae74ec", "99820cfd-820b-4dde-800a-57b0554fcea4", "9a4984f9-27d4-47eb-8bc8-0469bf540f94", "a1e0ab80-941f-43a9-ad51-9ae990cf597c", "a4608624-f944-49c6-8d31-45301e1feab2", "a4e144d3-8933-474f-976a-a2fbbddfd2a0", "aa4b0d9f-7469-4a50-a424-b46d9dcf7efd", "aa991af1-7413-49bf-9b45-eab5560df4fe", "cdfec67b-f4bd-4e12-88e8-087e28ef261c", "d4afb61b-975e-499b-a7cb-baf3bacd527b", "d7527d1f-d63a-4b7f-953a-731dab206d99", "d8fc397f-7e0c-451b-ad9a-cb25fa7b3d22", "dc667ef3-91f0-400e-b405-b0844931aec5", "e8ec6719-4993-430f-a178-4877a32cd63d", "f21605f8-dd5f-4b24-96d9-3723eb17a7b6", "f4270e7e-3819-424b-9ae1-93539fd8901e", "fd2dd453-0b4a-4ba3-aed0-0c5888c0996d"], "title": "Dynamic enforcement of knowledge-based security policies using probabilistic abstract interpretation", "venue": "Journal of Computer Security", "year": 2013, "id": "1d6f2573-af5b-4f76-a699-cad65dd45551"}
{"abstract": "This paper describes an evolvable hardware (EHW) system for generalized neural network learning. We have developed an ASIC VLSI chip, which is a building block to configure a scalable neural network hardware system. In our system, both the topology and the hidden layer node functions of a neural network mapped on the chips are dynamically changed using a genetic algorithm. Thus, the most desirable network topology and choice of node function (e.g. Gaussian or sigmoid) for a given application can be determined adaptively. This approach is particularly suited to applications requiring ability to cope with time-varying problems and real-time timing constraints. The chip consists of 15 Digital Signal Processors (DSPs), whose functions and interconnections are reconfigured dynamically according to the chromosomes of the genetic algorithm. Incorporation of local learning hardware increases the learning speed significantly. Simulation results on adaptive equalization in digital mobile communication are also given. Our system is two orders of magnitude faster than a Sun SS20 on the corresponding problem.", "authors": ["Masahiro Murakawa", "Shuji Yoshizawa", "Isamu Kajitani", "Tetsuya Higuchi"], "n_citation": 50, "references": ["6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "80b202af-408f-49df-a7b7-44f5e923d336", "967a47dc-7a92-415c-b09f-426223c93fde", "d2c4b4e9-8854-492e-b3ee-fa8994cbde38", "ec41ca47-ca72-42be-b930-ddd84bc1fdf1", "eda4f852-c47c-490b-979b-9191aadb5797", "fc95b916-1e4d-4c45-862c-dd34a49e64ad"], "title": "Evolvable hardware for generalized neural networks", "venue": "international joint conference on artificial intelligence", "year": 1997, "id": "94a29b19-76e6-4bc2-a5b5-a37f017e1027"}
{"abstract": "This paper presents a simple, powerful and flexible technique for reasoning about and translating the goal-directed evaluation of programming language constructs that either succeed (and generate sequences of values) or fail. The technique generalizes the  Byrd Box , a well-known device for describing Prolog backtracking.", "authors": ["Todd A. Proebsting"], "n_citation": 50, "references": ["33bb3d3b-cf44-481b-a6a7-23c7cc2dd219", "7d4118fc-3c33-47ae-bd07-54c0f83f1c55", "bfd580d7-592d-43c5-8123-a0543e33bead"], "title": "Simple translation of goal-directed evaluation", "venue": "programming language design and implementation", "year": 1997, "id": "48072a04-817a-4c80-ba4b-1c2850c3a5fc"}
{"authors": ["Yusuke Kometani", "Keizo Nagaoka"], "n_citation": 2, "title": "Development of a Seminar Management System", "venue": "international conference on human computer interaction", "year": 2015, "id": "be5809f2-da88-48b2-aa39-2f253cdb771f"}
{"abstract": "This paper discusses two main ideas, unwinding and inference control. While both concern computer security, they are not closely related to each other. Unwinding is a verification technique for general security requirements based on noninterference assertions as in [Goguen & Meseguer 82a]. The inference control problem concerns preventing inference of unauthorized information by combining authorized information. The main result in this paper is an unwinding theorem that gives a very simple necessary and sufficient condition for a system to satisfy the MLS security policy system. A subsidiary topic is secure interfaces, which we show how to treat with noninterferce assertions.", "authors": ["Joseph A. Goguen", "Jos\u00e9 Meseguer"], "n_citation": 476, "title": "Unwinding and Inference Control", "venue": "ieee symposium on security and privacy", "year": 1984, "id": "e38f5822-ccd2-4fce-aca1-4bd838724dea"}
{"abstract": "We have derived equations relating to the cumulants of the backscattered signal to material and transducer parameters. Then, we proposed a practical method to estimate the material grain moments from estimates of the cumulants at some particular values. The proposed model and techniques are verified on some phantoms having different scatterer density and grain sizes.", "authors": ["Ram\u00f3n Miralles", "Luis Vergara", "Jorge Gos\u00e1lbez"], "n_citation": 50, "references": [], "title": "Material grain noise analysis by using higher-order statistics", "venue": "Signal Processing", "year": 2004, "id": "d30ea93e-072e-4cfa-8baa-5331afee1059"}
{"abstract": "On presente un nouvel algorithme de recherche d'un couplage maximum dans un graphe, qui se ramene essentiellement a l'inversion d'une matrice", "authors": ["Ketan Mulmuley", "Umesh V. Vazirani", "Vijay V. Vazirani"], "n_citation": 715, "references": ["1b4d1e35-1fb2-488b-b704-d29ca82ad0a4", "22669ed1-c9c9-4934-a0b1-e3291614872b", "257025f8-3fbe-4893-b740-c0738d378fdd", "5d3a01a6-31aa-4fcd-a28c-58faeb27c894", "67ab055b-9b61-4e49-afb1-c7e96f5983e6", "6818e837-26a8-4bfe-a47c-b4160c51c377", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "aa25d411-3e5c-44eb-88be-0f577d033506", "b3f953d8-d55a-4b6e-8528-1d179eb9d576", "b63918d9-5aea-4648-9536-b915bfbbdfb2", "c09ecdc5-9b14-4b73-bc3e-c213e2afa067", "e174afb4-1a76-48df-936a-62d2969f890f", "e20ba63d-f74d-4929-b3ac-bc3c0ab611f9", "ecef4837-977a-49a2-91b7-5dd61f036296", "f612b41d-1c3d-4b94-b88e-578c3c6b8fc1"], "title": "Matching is as easy as matrix inversion", "venue": "Combinatorica", "year": 1987, "id": "2d58da07-ad35-4a75-9782-7bbe43a3164a"}
{"abstract": "This paper presents the findings of a survey on quality models in practice conducted among four software companies in Germany. In the first phase of the study, 25 quality managers and users of software quality models were interviewed regarding the use of quality models, quality assurance techniques, and problems arising from the current situation in their companies. We present qualitative and quantitative findings as well as our plans for the second study phase including an international online questionnaire.", "authors": ["Stefan Wagner", "Klaus Lochmann", "Sebastian Winter", "Andreas Goeb", "Michael Klaes"], "n_citation": 50, "references": ["005cd0f2-c899-46cb-9f6f-b6cbf6af8c89", "3ab5facf-e1ee-4a15-aacc-9d1381f0e093", "3f5a2e71-163f-4b6e-aecb-73909c256881", "9ac12e7f-61e0-4223-8a36-d30e18f69e12"], "title": "Quality models in practice: A preliminary analysis", "venue": "empirical software engineering and measurement", "year": 2009, "id": "df053477-75a6-4468-a466-6e5f0a188307"}
{"abstract": "We analyze light propagation in an unknown scene using projectors and cameras that operate at transient timescales. In this new photography regime, the projector emits a spatio-temporal 3D signal and the camera receives a transformed version of it, determined by the set of all light transport paths through the scene and the time delays they induce. The underlying 3D-to-3D transformation encodes scene geometry and global transport in great detail, but individual transport components ( e.g ., direct reflections, inter-reflections, caustics,  etc .) are coupled nontrivially in both space and time.   To overcome this complexity, we observe that transient light transport is always  separable in the temporal frequency domain . This makes it possible to analyze transient transport one temporal frequency at a time by trivially adapting techniques from conventional projector-to-camera transport. We use this idea in a prototype that offers three never-seen-before abilities: (1) acquiring time-of-flight depth images that are robust to general indirect transport, such as interreflections and caustics; (2) distinguishing between direct views of objects and their mirror reflection; and (3) using a photonic mixer device to capture sharp, evolving wavefronts of \"light-in-flight\".", "authors": ["Matthew O'Toole", "Felix Heide", "Lei Xiao", "Matthias B. Hullin", "Wolfgang Heidrich", "Kiriakos N. Kutulakos"], "n_citation": 50, "references": ["1111b393-735b-4bca-98fa-3183c23a0d5b", "2e96b75f-2752-4d65-add6-0bae7d1022a5", "328801aa-80e9-4f27-925d-ef62a9d35db8", "3662d33d-e39e-4760-b427-269e5f503dd1", "38b779d8-55de-465b-8cd8-c95e5ba5eb90", "4127548b-aac6-4f81-bfaa-89bf6dab423a", "4ba624bc-bdda-4d9c-bb29-3c325f0d57e8", "4c1498c6-6c89-448f-b8b5-475feb7c8fc1", "5645757e-c125-499c-9d16-6ca1d02310d2", "58224f00-2a38-4dbf-9a6e-5a578b710ca2", "5b68a8f8-0689-4384-a0aa-744b044042e4", "722fbd8c-4953-4c54-bfa3-5d40f9cd65ba", "735e5457-480a-4ffe-ab8e-78483fe9f1fd", "7bcd260a-f4ca-49fd-aa16-2f715355be45", "7c102359-9228-4f5f-ba62-1bd1f99fe715", "8fa0a362-6522-48fc-bd5e-24de00ed6511", "bd6320a7-40c3-4d18-9841-19405fdf39a1", "be806c86-5417-44dd-ac0b-f56aa511f74c", "bf163c20-9d1e-4034-9f4c-b8a200db823b", "c1688f4a-6487-4bbc-afe8-54f98b36d6ee", "c9780e97-63fb-4896-ace3-57ae8e5bd647", "d9024533-8710-43f0-ac67-e78384a44003", "dcdd5852-d105-4e24-8f67-96b010661ad2", "e69aacac-2083-4957-beaf-32b3d5d10620", "f755c046-e4ff-4a0f-9b5b-ca56891081b3"], "title": "Temporal frequency probing for 5D transient analysis of global light transport", "venue": "international conference on computer graphics and interactive techniques", "year": 2014, "id": "27d7413e-b1e5-4e03-a8c3-2ab36163f742"}
{"abstract": "Motivation: Cancer diagnosis is one of the most important emerging clinical applications of gene expression microarray technology. We are seeking to develop a computer system for powerful and reliable cancer diagnostic model creation based on microarray data. To keep a realistic perspective on clinical applications we focus on multicategory diagnosis. To equip the system with the optimum combination of classifier, gene selection and cross-validation methods, we performed a systematic and comprehensive evaluation of several major algorithms for multicategory classification, several gene selection methods, multiple ensemble classifier methods and two cross-validation designs using 11 datasets spanning 74 diagnostic categories and 41 cancer types and 12 normal tissue types.#R##N##R##N#Results: Multicategory support vector machines (MC-SVMs) are the most effective classifiers in performing accurate cancer diagnosis from gene expression data. The MC-SVM techniques by Crammer and Singer, Weston and Watkins and one-versus-rest were found to be the best methods in this domain. MC-SVMs outperform other popular machine learning algorithms, such as k-nearest neighbors, backpropagation and probabilistic neural networks, often to a remarkable degree. Gene selection techniques can significantly improve the classification performance of both MC-SVMs and other non-SVM learning algorithms. Ensemble classifiers do not generally improve performance of the best non-ensemble models. These results guided the construction of a software system GEMS (Gene Expression Model Selector) that automates high-quality model construction and enforces sound optimization and performance estimation procedures. This is the first such system to be informed by a rigorous comparative analysis of the available algorithms and datasets.#R##N##R##N#Availability: The software system GEMS is available for download from http://www.gems-system.org for non-commercial use.#R##N##R##N#Contact: alexander.statnikov@vanderbilt.edu", "authors": ["Alexander Statnikov", "Constantin F. Aliferis", "Ioannis Tsamardinos", "Douglas P. Hardin", "Shawn Levy"], "n_citation": 795, "references": ["01570ac6-ab0a-4e78-a145-d65ff4e4ec22", "0813ad74-7670-4761-8699-59f5c25dfa9b", "089d789c-db9f-4204-8d45-9c99fa878721", "09a1b942-da7d-4d7a-9fcc-b930326ea856", "0e30a566-1fe0-4e63-b69e-21d23ba3187a", "12fa9885-b0a9-4ea3-a0de-e020c333c3f0", "17d88dfa-a5b8-47dd-9fb6-8779e5091c85", "1ed12644-d4b8-4ee3-8c55-0a78a831a1dc", "24fb8e97-1ab4-47aa-868b-a78998695e45", "2bd9968a-1e0b-4a11-85a2-19edcf0ee77d", "55b5967f-56a5-4a48-b6c7-ac795af26534", "74cf0cba-4174-4b0b-9525-52799e206829", "7e6793c0-346f-41af-b8e8-7a710171726e", "819ddbe2-86e9-4e9b-94d3-b55641de26f2", "8457955d-56be-4c1f-8e01-bc13531b3456", "8da3d3b4-16eb-45c8-a871-8887db4dca11", "9fa61eb1-0984-4492-955a-4f7aedbdc368", "c1b6b493-01ef-420f-be44-7bacfe34e846", "c70e0e14-4414-4eb0-b015-abbc682b57ca", "cdbd2ef9-d4b1-4dff-9037-3ea84627424d", "cf740e2c-f5bf-4e0c-8375-2948d6dff2c7", "da1588c5-c4e3-4c8b-89fb-b381022f088a", "e4cd8e6c-2fb9-4821-8fc8-0916964079c5", "ee0c0b66-94c4-4a58-b4c1-26296421565e", "f33acc76-f25e-446f-a834-9d898907b326", "fcb41378-32f7-4aab-8458-fc5a99d74f92", "feff8862-f47d-4591-a7cb-b62d7efc81a2", "ffd61dbb-b04b-4692-a308-4dc79ef5fdb9"], "title": "A comprehensive evaluation of multicategory classification methods for microarray gene expression cancer diagnosis", "venue": "Bioinformatics", "year": 2005, "id": "41f9433f-530a-43be-bf34-959aa43cf4b6"}
{"abstract": "Through the analysis of the different iterations of the Geometry Mobile (GEM) project, a mobile learning effort in the field of mathematics, we have identified a major architectural issue to be addressed in the design and implementation of m-learning applications. Due to the dynamic nature of the field many challenging requirements are continuously emerging. One of them relates to the possibility to support collaborative activities that demand sharing resources between students and their mobile devices in constantly changing conditions. These situations generate the need of using decentralized distributed architectures in which mobile devices can share resources to carry out the activity covering the concerns defined by the different stakeholders. This paper describes our current efforts connected to identifying a set of requirements for M-Learning activities. Thereafter, we elaborate on why a decentralized distributed system (DDS) can be used to provide a novel solution to tackle the mentioned above problems. Moreover, initial aspects related to the design of a DDS, including a self-adaptation mechanism are presented.", "authors": ["Didac Gil", "Jesper Andersson", "Marcelo Milrad", "H\u00e5kan Sollervall"], "n_citation": 50, "references": ["07f2f807-84e3-4194-b5ad-5e7c90b8c903", "4d6778de-1826-4c4c-945d-03319b320669", "5ce45927-77a4-47da-ba2c-4e2ca98c2061", "a1f83feb-f48d-4825-af6a-e5d7a53ff3e3", "b582592f-05bd-4bfa-9d53-a2e4310d0996", "b6019c9f-3e6a-4385-8229-3cc70a1cb055", "c9110a34-a671-4eb2-86a0-bf5956a71fb1", "cc3cd02c-8a8e-48ea-a0f0-44dd9f160b86", "ed179ec2-4ead-4018-8974-e85b91aa8819"], "title": "Towards a Decentralized and Self-Adaptive System for M-Learning Applications", "venue": "wireless, mobile and ubiquitous technologies in education", "year": 2012, "id": "ae5fc595-30a3-4dd1-99d3-35ebec4ee580"}
{"abstract": "Abstract   GRANT is an expert system for finding sources of funding given research proposals. Its search method-constrained spreading activation\u2014makes inferences about the goals of the user and thus finds information that the user did not explicitly request but that is likely to be useful. The architecture of GRANT and the implementation of constrained spreading activation are described, and grant's performance is evaluated.", "authors": ["Paul R. Cohen", "Rick Kjeldsen"], "n_citation": 404, "references": ["6a2ac690-570a-42e1-9494-278f0388a2ed", "8dd00fb7-b615-4340-a2dc-1c080298a2f4", "bdd72f1c-6df6-4069-bb3a-40a82dfc9065"], "title": "Information retrieval by constrained spreading activation in semantic networks", "venue": "Information Processing and Management", "year": 1987, "id": "bed2c8c8-1dc3-4631-b8e2-746ba766a9ae"}
{"abstract": "This paper presents a checkpointing scheme that was implemented in a parallel library that runs on top of CHIMP/MPI. The main goals of the checkpointing mechanism are portability and efficiency. It runs on every platform supported by MPI in a machine-independent way. The scheme allows the migration of checkpoints and offers a flexible recovery mechanism based on data-reconfiguration. Some performance results will be presented at the end of the paper together with some techniques that can be used to increase the efficiency of the checkpointing mechanism.", "authors": ["Lu\u00eds Moura Silva", "Jo\u00e3o Gabriel Silva", "Simon Chapple", "L. J. Clarke"], "n_citation": 50, "references": ["5afceaf5-ed1d-413e-88c4-2670b3468ad7", "735dedeb-a935-4e6e-b071-4f7e3edfebb8", "9a809bc8-abc8-47ec-b318-78d259854ff9", "a93f5d8f-7b6a-4d1b-91e3-5ef9cadb4937", "f7d8a294-2968-4fea-8743-ae5ff52f0d98"], "title": "Portable checkpointing and recovery", "venue": "high performance distributed computing", "year": 1995, "id": "90517db8-8941-49cd-bb06-cb886abac8c1"}
{"abstract": "The database community has produced extensive research on the concurrency control problem in the context of traditional databases. However, this traditional model is not suitable for some applications, such as software development environments and CAD/CAM systems. What is needed is an extended transaction model better suited for these newer applications. Unfortunately, there is no consensus as to which of the almost dozens of extended transaction models is appropriate.This paper posits that there is no single model which will be applicable to every application and seeks other ways to use existing database technology. Towards this end, we present PERN, a new transaction manager component which provides the flexible and tailorable support required by advanced database applications.", "authors": ["George T. Heineman"], "n_citation": 30, "references": ["0f372bc4-e122-4c4e-bef1-6e090662f070", "10f28a89-b79d-49e4-be54-19aed489fe4a", "35b671b4-5e95-4a09-bae3-f0d94e648119", "36176365-c71d-4870-8e9a-0f8849eac6f7", "6b2a4377-e07b-49e2-acc4-90f11ef0b34b", "db4234fa-9541-4f5f-b4ff-24eb3b98d36e", "ed323699-4f23-44fd-b187-7a1f6f5d1260"], "title": "A transaction manager component for cooperative transaction models", "venue": "conference of the centre for advanced studies on collaborative research", "year": 1993, "id": "bd3f0bcc-8823-401e-bac9-c1bd785e4204"}
{"abstract": "Cascades of boosted ensembles have become popular in the object detection community following their highly successful introduction in the face detector of Viola and Jones. Since then, researchers have sought to improve upon the original approach by incorporating new methods along a variety of axes (e.g. alternative boosting methods, feature sets, etc.). Nevertheless, key decisions about how many hypotheses to include in an ensemble and the appropriate balance of detection and false positive rates in the individual stages are often made by user intervention or by an automatic method that produces unnecessarily slow detectors. We propose a novel method for making these decisions, which exploits the shape of the stage ROC curves in ways that have been previously ignored. The result is a detector that is significantly faster than the one produced by the standard automatic method. When this algorithm is combined with a recycling method for reusing the outputs of early stages in later ones and with a retracing method that inserts new early rejection points in the cascade, the detection speed matches that of the best hand-crafted detector. We also exploit joint distributions over several features in weak learning to improve overall detector accuracy, and explore ways to improve training time by aggressively filtering features.", "authors": ["S. Charles Brubaker", "Jianxin Wu", "Jie Sun", "Matthew D. Mullin", "James M. Rehg"], "n_citation": 156, "references": ["17f811d8-8607-4270-bbec-1cc7883edd68", "1bd85a9c-1d7f-435c-81c7-3f98649ffc6a", "1dfea56f-ca27-4987-a060-55098d5e2a9a", "1f4152a3-481f-4adf-a29a-2193a3d4303c", "21a8e8fd-0172-4e9a-8474-7024eb0bf979", "2aba9809-4c26-44b1-8fb9-bde35b8a8d32", "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8", "3b21e456-3036-4b8e-8423-e2e99067b970", "3ff826d0-0d08-4590-a45b-80d20238c7a4", "43eada0c-49c1-434d-bef0-fb828e3bcf63", "4fb87930-7f6c-4f03-ae22-32445138ec83", "547d3ff8-e285-4466-9231-bc46f18648b4", "56cd3fdb-73ff-431e-8945-d673f9469f33", "584781c5-2a6e-4a55-b353-3479fda48474", "5bb0611f-400a-4d42-b30f-2befcdc09d41", "5f155e51-9d82-44f3-b177-36e5fe39346b", "613841ae-c925-4aee-9c2e-8675213e4bbf", "6761fea2-d38d-4c38-ae45-93efd3942709", "6f23a2d5-d822-4d55-b61b-e21e0f561b45", "8b8a2247-bd77-4736-b493-449734f56b9a", "935a43d4-c35a-42b6-9ac4-23392ed1d644", "95224672-6924-4f3b-bb3d-48bed8f1cd13", "98275713-2dbf-4199-bb14-8714d68b5f90", "a9f4d231-e11d-452d-b527-7b76cce31b73", "aa4d952f-3e8d-440e-97bb-740a090f08b1", "ad279cf6-d2b8-4bc0-ba5e-aa857ef5d11c", "b84edc2c-53ca-4757-8994-fded2d0e50b1", "b95a9ce5-193d-4a27-83f1-91626eae4b3b", "cd8746da-59d4-44ec-8367-8902cd89a8bc", "d2892445-882a-479d-a3af-125297001e91", "d5e5a24d-f80e-4f1a-b48b-22403b653276", "d6e37fb1-5f7e-448e-847b-7d1f1271c574", "db26488d-78be-44b1-a343-e896f43c5d29", "dc3867c3-946b-4f5a-8fe2-366413c33c3f", "e54bda18-5f7b-49e4-8183-5dfdd4e71f25", "e9eda99f-a7ee-459a-ad22-1fb1cbae2db6", "f94fa080-3dcf-43f7-946d-cced9dbe9d9c", "fa5ac403-3694-49e0-ab32-cfe7a5361408"], "title": "On the Design of Cascades of Boosted Ensembles for Face Detection", "venue": "International Journal of Computer Vision", "year": 2008, "id": "28c8b3ae-29e9-4729-b755-ae46c2650a1d"}
{"abstract": "We present an overview of an ongoing project to build DDDAS to use all available data for a short term wildfire prediction. The project involves new data assimilation methods to inject data into a running simulation, a physics based model coupled with weather prediction, on-site data acquisition using sensors that can survive a passing fire, and on-line visualization using Google Earth.", "authors": ["Jan Mandel", "Jonathan D. Beezley", "Lynn S. Bennethum", "Soham Chakraborty", "Janice L. Coen", "Craig C. Douglas", "Jay Hatcher", "Minjeong Kim", "Anthony Vodacek"], "n_citation": 32, "references": ["205a6ff8-caff-4743-bd0b-c23fb62ad6f5", "6c4b9370-8c4b-44b0-b6b9-f7167bf1d710", "903ef289-9f23-40a7-be35-06d76b93478d"], "title": "A Dynamic Data Driven Wildland Fire Model", "venue": "international conference on conceptual structures", "year": 2007, "id": "b49d3cc8-af03-45da-939a-7e796a2fc0e3"}
{"authors": ["Eduardo B. Fernandez", "Jim Hawkins"], "n_citation": 44, "references": ["0e64a8e5-99a5-47a8-b0d6-abd5e10b67bc", "173c2d20-9860-4685-96b9-f3743eed8300", "211a7e14-de48-40f1-b622-b36fa6f47cf8", "22b0e910-8ad4-4b75-9f12-b5ad712c17ae", "449486a9-aeb6-4148-83c3-d02b5e716d4e", "98bdcfa4-463a-460c-a300-0fb467e88ad2", "9e08ab3b-3582-42b4-91bd-fdd7c33384a0", "b491d50b-5661-4b0e-a6c7-b4584bb4d2a3", "c2b503c3-2888-4cb7-9f24-51ecd8487c0d", "cc483ebf-ab62-4de3-b212-606da29c1576", "e21857d3-0c23-409d-af65-f5f93a070c56", "ecfb2022-e18c-4e5e-8733-d8bc6f4c8fc9"], "title": "Determining role rights from use cases", "venue": "", "year": 1997, "id": "4908fbde-754b-446b-977b-b2ae65467634"}
{"authors": ["Mathias Andersen", "Heine Larsen", "Ji\u0159\u00ed Srba", "Mathias Grund S\u00f8rensen", "Jakob Haahr Taankvist"], "n_citation": 50, "references": ["05187588-ada5-47d3-ab0d-a282be6fc447", "084cf14e-db8d-49fe-ba0e-7387bd4587ef", "0d176f2f-84d9-4bfd-ba46-bc9603ef4e7f", "0e41beda-cc65-499e-b9cd-59f4395a0c9e", "26ba289c-7209-4d40-a7c3-3acc2bd88f65", "599777e3-8b89-49cf-8f44-66a31a3b1200", "8512d397-7900-4842-81eb-8a7935a772df", "979d1409-ae58-4ac9-b28e-d60b9c3021a8", "9849d9c4-a97f-452f-882c-42a8c6cab0b5", "9dbd2de5-c040-4acb-a3dd-568a3480d570", "b9406df7-db37-4dd8-83d9-90b6b1713f2d", "ecf23f31-b26e-45aa-8b56-674b89ef15f7", "f465f1e5-7ec7-431a-92ae-03ca3d00c12e"], "title": "Verification of Liveness Properties on Closed Timed-Arc Petri Nets", "venue": "", "year": 2012, "id": "ff3e5819-210a-4ada-b654-33a95105d77a"}
{"abstract": "The paper presents the gossip interactive Kalman filter (GIKF) for distributed Kalman filtering for networked systems and sensor networks, where intersensor communication and observations occur at the same time-scale. The communication among sensors is random; each sensor occasionally exchanges its filtering state information with a neighbor depending on the availability of the appropriate network link. We show that under a weak distributed detectability condition: 1) the GIKF error process remains stochastically bounded, irrespective of the instability of the random process dynamics; and 2) the network achieves weak consensus, i.e., the conditional estimation error covariance at a (uniformly) randomly selected sensor converges in distribution to a unique invariant measure on the space of positive semidefinite matrices (independent of the initial state). To prove these results, we interpret the filtering states (estimates and error covariances) at each node in the GIKF as stochastic particles with local interactions. We analyze the asymptotic properties of the error process by studying as a random dynamical system the associated switched (random) Riccati equation, the switching being dictated by a nonstationary Markov chain on the network graph.", "authors": ["Soummya Kar", "Jos\u00e9 M. F. Moura"], "n_citation": 94, "references": ["0aef08a4-9fb6-41df-a465-94dd331e7825", "12dacb28-cffe-4774-9d20-29e1b7124a13", "142a38de-8d17-4d67-91da-ed7488dab21c", "1cb63979-852f-4a31-8555-ed2e995b745f", "207c9c45-c1df-4073-abf2-dd2ba9957b7e", "2a71c985-5219-419d-8d7c-6113f50701f7", "3c7e1ef1-fa85-4b0f-8c18-d31d0a59bf30", "4a78d773-7703-4de6-9881-2bcef9e336ea", "4af2ba6d-4699-44a8-8f4a-4b62d8cec3cd", "4d3d5ff0-9654-42ae-8235-330e0d861d1a", "83fda908-ccc3-48dd-b2d4-7a1ba486d0cd", "8c27c66b-31d0-42b8-88bb-806f118fede7", "9567a5f7-66f4-4e57-afab-fb55b9391159", "b24b16e6-5eed-4798-b0d4-4cf8ae41057b", "bf40f657-d004-4b64-8fd8-25b5971a1dc4", "ee33c06d-79d1-4e04-abec-9a13d519e3ce"], "title": "Gossip and Distributed Kalman Filtering: Weak Consensus Under Weak Detectability", "venue": "IEEE Transactions on Signal Processing", "year": 2011, "id": "d07c2b15-23dd-4a3b-9d19-3a549d2ea613"}
{"abstract": "An algorithm is described to solve multiple-phase optimal control problems using a recently developed numerical method called the  Gauss pseudospectral method . The algorithm is well suited for use in modern vectorized programming languages such as FORTRAN 95 and MATLAB. The algorithm discretizes the cost functional and the differential-algebraic equations in each phase of the optimal control problem. The phases are then connected using linkage conditions on the state and time. A large-scale nonlinear programming problem (NLP) arises from the discretization and the significant features of the NLP are described in detail. A particular reusable MATLAB implementation of the algorithm, called  GPOPS , is applied to three classical optimal control problems to demonstrate its utility. The algorithm described in this article will provide researchers and engineers a useful software tool and a reference when it is desired to implement the Gauss pseudospectral method in other programming languages.", "authors": ["Anil V. Rao", "David A. Benson", "Christopher L. Darby", "Michael A. Patterson", "Camila Francolin", "Ilyssa Sanders", "Geoffrey T. Huntington"], "n_citation": 72, "references": ["0bc4e1c7-b59e-449c-87d7-af164dca1b12", "2eec8e1a-a31f-4575-8263-ff9ab672d5a3", "71ab8922-400d-40fc-904e-f1e239bb3649", "e80114ae-abab-40b0-be65-19b76b96ee80", "eae1181b-cabd-4ee3-b1c1-ac3dc424eca1"], "title": "Corrigendum: Algorithm 902: GPOPS, a MATLAB software for solving multiple-phase optimal control problems using the gauss pseudospectral method", "venue": "ACM Transactions on Mathematical Software", "year": 2010, "id": "27112238-cf22-4949-8a51-6af4b41dc9c8"}
{"abstract": "A hardware random number generator was described at CHES 2002 in [Tka03]. In this paper, we analyze its method of generating randomness and, as a consequence of the analysis, we describe how, in principle, an attack on the generator can be executed.", "authors": ["Markus Dichtl"], "n_citation": 50, "references": ["ccbc2de3-7008-48c8-b39a-fff2d0a7d678"], "title": "How to Predict the Output of a Hardware Random Number Generator", "venue": "cryptographic hardware and embedded systems", "year": 2003, "id": "fc8669d9-267d-4f71-b617-94d2411a075b"}
{"abstract": "Evolving gradient-learning artificial neural networks (ANNs) using an evolutionary algorithm (EA) is a popular approach to address the local optima and design problems of ANN. The typical approach is to combine the strength of backpropagation (BP) in weight learning and EA's capability of searching the architecture space. However, the BP's \"gradient descent\" approach requires a highly computer-intensive operation that relatively restricts the search coverage of EA by compelling it to use a small population size. To address this problem, we utilized mutation-based genetic neural network (MGNN) to replace BP by using the mutation strategy of local adaptation of evolutionary programming (EP) to effect weight learning. The MGNN's mutation enables the network to dynamically evolve its structure and adapt its weights at the same time. Moreover, MGNN's EP-based encoding scheme allows for a flexible and less restricted formulation of the fitness function and makes fitness computation fast and efficient. This makes it feasible to use larger population sizes and allows MGNN to have a relatively wide search coverage of the architecture space. MGNN implements a stopping criterion where overfitness occurrences are monitored through \"sliding-windows\" to avoid premature learning and overlearning. Statistical analysis of its performance to some well-known classification problems demonstrate its good generalization capability. It also reveals that locally adapting or scheduling the strategy parameters embedded in each individual network may provide a proper balance between the local and global searching capabilities of MGNN.", "authors": ["Paulito P. Palmes", "Taichi Hayasaka", "Shiro Usui"], "n_citation": 157, "references": ["03aa3fe4-331d-464b-a3b1-0f7066b81221", "240bec32-2417-44bf-b133-4781659b1976", "2b6f29f6-cd57-4fa1-887a-d00046a779ff", "2f5adf78-25e5-42e4-9a6c-435617f57387", "4ff605f8-290e-4430-8411-6d322087da2b", "535a0546-0ea3-4432-b40f-4f64525129c8", "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "7068d6f8-3fb4-45b0-8f16-7272e9f6491e", "72d33aae-c1a6-4928-9d0b-4d92385b148b", "7d6b2def-bfae-454b-8fa3-4b772d1f2388", "81e69d71-355c-4492-b3d7-3a6d09ae4a56", "8cad930b-98de-4cc8-97ef-25cada8a2a4e", "90297adf-13cf-4572-a2cf-c16b300f0534", "9fa51a91-8ee1-4e39-aff5-061f5157c2e6", "a93d83fc-7fdd-4d7b-a266-1a9fa01996da", "bac5da35-9009-41a3-b758-21aec812a9ee", "de3585a4-0f51-464f-9bd5-69baf7c9359d", "e2060efc-e0eb-426b-add0-41170e2ad75f"], "title": "Mutation-based genetic neural network", "venue": "IEEE Transactions on Neural Networks", "year": 2005, "id": "36f75cf9-f54b-4523-9b77-dec068978d00"}
{"abstract": "This paper examines the use of an interactive artwork that was designed by members of the research team and exhibited at the Sculpture, Objects and Functional Art (SOFA) Exposition in Chicago, USA. The paper uses audio-visual recordings of interaction with and around the work to consider how people encounter and make sense of an assembly of traditional objects and video technologies. The analysis of action and interaction is used to develop a series of 'design sensitivities' to inform the development of technological assemblies to engender informal interaction and sociability in museums and galleries.", "authors": ["Jonathan Hindmarsh", "Christian Heath", "Dirk Vom Lehn", "Jason Cleverly"], "n_citation": 79, "references": ["87f29115-06ae-455c-a4a2-5a3fd41d9c0f", "a91681bc-23ce-4e5b-b4ac-7a52796354d7", "c580bedb-17d4-4582-a388-9a9772086a79", "d84490aa-d4ef-4ddb-a6ec-8a09dcb44f01"], "title": "Creating assemblies:: aboard the Ghost Ship", "venue": "conference on computer supported cooperative work", "year": 2002, "id": "2dae7fcb-fe2d-4746-aa6b-afa21008e9bc"}
{"abstract": "The training of neural net classifiers is often hampered by the occurrence of local minima, which results in the attainment of inferior classification performance. It has been shown that the occurrence of local minima in the criterion function is often related to specific patterns of defects in the classifier. In particular, three main causes for local minima were identified. Such an understanding of the physical correlates of local minima suggests sensible ways of choosing the weights from which the training process is initiated. A method of initialization is introduced and shown to decrease the possibility of local minima occurring on various test problems. >", "authors": ["Lodewyk F. A. Wessels", "Etienne Barnard"], "n_citation": 267, "references": ["634922b1-f481-4112-9ed7-97de06590769", "8553c5a8-d187-4662-963b-bac6a75e2bae", "991bb85a-f14e-418e-9155-305684f02c77"], "title": "Avoiding false local minima by proper initialization of connections", "venue": "IEEE Transactions on Neural Networks", "year": 1992, "id": "ac490311-5ee0-4e9b-94be-b588c93cbe72"}
{"abstract": "This brief is concerned with the analysis problem of global exponential stability in the mean square sense for a class of linear discrete-time recurrent neural networks (DRNNs) with stochastic delay. Different from the prior research works, the effects of both variation range and probability distribution of the time delay are involved in the proposed method. First, a modeling method is proposed by translating the probability distribution of the time delay into parameter matrices of the transformed DRNN model, where the delay is characterized by a stochastic binary distributed variable. Based on the new method, the global exponential stability in the mean square sense for the DRNNs with stochastic delay is investigated by using the Lyapunov-Krasovskii functional and exploiting some new analysis techniques. A numerical example is provided to show the effectiveness and the applicability of the proposed method.", "authors": ["Dong Yue", "Yijun Zhang", "Engang Tian", "Chen Peng"], "n_citation": 85, "references": ["1d963557-b184-4000-9ba3-6d8b91b54b12", "1ee953e3-a405-429f-a5bf-958f4918431e", "3358de3b-a1fa-4fbb-9d53-23dd789d75d2", "38d20ba0-db8e-47db-ab6b-f2898683a0a1", "4d5cb5ae-3b26-4676-b9b3-915c25ffdef7", "4fbb03ca-79b5-4607-b280-8e83a10d2ad2", "5d450a08-efc3-40c8-83f0-3799e238109c", "5da64295-86de-4037-8dd0-8d0ee8d2ee16", "669f9f47-d6bf-462e-b2a6-8300ac07835b", "758bcb76-b6a4-415b-8403-1fcd1a8c5643", "7dc6ac69-4c1d-4cd1-9951-14c74c5e40cb", "9303c2f5-9b4f-40a2-97dc-10f11eb4dd25", "a4ab3b7d-8bad-4089-8844-596e7be06ea5", "c5e5cb6a-108d-40e4-8e46-e9a5cf236bbb", "c8779ed5-9540-4d36-aa4e-d94b1053fc03", "c8bceca2-d9b5-4958-8739-1aafd2d1616d", "d97d8392-5df7-49a4-9bc5-2546772d25c1", "e8527321-700c-4e37-bc47-6f852583ebb7", "f665128b-300d-45d5-8a7f-1a6bd844ffbb", "ff00af1d-2efd-4137-b8d3-538bf912d836"], "title": "Delay-Distribution-Dependent Exponential Stability Criteria for Discrete-Time Recurrent Neural Networks With Stochastic Delay", "venue": "IEEE Transactions on Neural Networks", "year": 2008, "id": "f56f9dc1-681f-44e2-944b-6409a53359e0"}
{"abstract": "The main purpose of this paper is to adapt the so-called Shubert algorithm for extremum seeking control of general dynamic plants. This algorithm is a good representative of the ''sampling optimization methods'' that achieve global extremum seeking on compact sets in the presence of local extrema. The algorithm applies to Lipschitz mappings; the model of the system is assumed unknown but the knowledge of its Lipschitz constant is assumed. The controller depends on a design parameter, the ''waiting time'', and tuning guidelines that relate the design parameter and the region of convergence and accuracy of the algorithm are presented. The analysis shows that semi-global practical convergence (in the initial states) to the global extremum can be achieved in presence of local extrema if compact sets of inputs are considered. Numerical simulations for global optimization in the presence of local extrema are provided to demonstrate the proposed approach.", "authors": ["Dragan Nesic", "Thang Nguyen", "Ying Tan", "Chris Manzie"], "n_citation": 37, "references": ["328417fd-738f-4525-90d9-e3f3825c09d8", "e66d73b0-abb9-4693-864e-faec07c69738"], "title": "A non-gradient approach to global extremum seeking: An adaptation of the Shubert algorithm", "venue": "Automatica", "year": 2013, "id": "71d89dff-8a43-4d48-97e0-29983357c929"}
{"abstract": "To correct geometric distortion and reduce blur in videos that suffer from atmospheric turbulence, a multi-frame image reconstruction approach is proposed in this paper. This approach contains two major steps. In the first step, a B-spline based non-rigid image registration algorithm is employed to register each observed frame with respect to a reference image. To improve the registration accuracy, a symmetry constraint is introduced, which penalizes inconsistency between the forward and backward deformation parameters during the estimation process. A fast Gauss-Newton implementation method is also developed to reduce the computational cost of the registration algorithm. In the second step, a high quality image is restored from the registered observed frames under a Bayesian reconstruction framework, where we use L 1  norm minimization and a bilateral total variation (BTV) regularization prior, to make the algorithm more robust to noise and estimation error. Experiments show that the proposed approach can effectively reduce the influence of atmospheric turbulence even for noisy videos with relatively long exposure time.", "authors": ["Xiang Zhu", "Peyman Milanfar"], "n_citation": 66, "references": ["0e7e7b49-c43e-4a4b-baab-b69a32fd7018", "5e69bfd7-95f8-4432-bad8-5ad7b6a165ae", "9e64f73b-645e-4d77-b01a-443454009e10", "cae374ce-5b99-482e-950a-0b9e304eb498", "fc1419fd-43b8-4297-a588-c2475b0b6c08"], "title": "Image Reconstruction from Videos Distorted by Atmospheric Turbulence", "venue": "Proceedings of SPIE", "year": 2010, "id": "439f1045-9dc8-4982-a5a2-72680036f82a"}
{"abstract": "Homogeneous charge compression ignition (HCCI) is a promising internal combustion engine concept. It holds promise of combining low emission levels with high efficiency. However, as ignition timing in HCCI operation lacks direct actuation and is highly sensitive to operating conditions and disturbances, robust closed-loop control is necessary. To facilitate control design and allow for porting of both models and the resulting controllers between different engines, physics-based mathematical models of HCCI are of interest. This paper presents work on a physical model of HCCI including cylinder wall temperature and evaluates predictive controllers based on linearizations of the model. The model was derived using first principles and formulated on a cycle-to-cycle basis. The resulting model was of second order with two inputs and two outputs. Measurement data including cylinder wall temperature measurements was used for calibration and validation of the model. Predictive control of the combustion phasing was then evaluated experimentally using ethanol as fuel. The control signals were the intake temperature and the inlet valve closing timing. The control performance was evaluated in terms of response time and steady-state output variance. Multi-cylinder control experiments were also carried out.", "authors": ["Anders Widd", "Kent Ekholm", "Per Tunest\u00e5l", "Rolf Johansson"], "n_citation": 40, "references": ["87b72935-1c04-4e5c-9b4a-ddfd1a787cd5", "a924b4b9-0560-4a7f-8ed4-8ccf30488a07", "b50cda6c-e32f-43c6-8ab6-7ca49562006b", "bd222237-e2d8-49e5-a98f-9d61e027a975"], "title": "Physics-Based Model Predictive Control of HCCI Combustion Phasing Using Fast Thermal Management and VVA", "venue": "IEEE Transactions on Control Systems and Technology", "year": 2012, "id": "95272712-60b9-44da-8d22-0b20783849d7"}
{"abstract": "SUMMARY TCP, the de facto standard transport protocol in today\u2019s operating systems, is a very robust protocol that adapts to various network characteristics, packet loss, link congestion, and even significant differences in vendor implementations. This paper describes a set of experiments performed on six different vendor TCP implementations using ORCHESTRA, a tool for testing and fault injection of communication protocols. These experiments uncovered violations of the TCP protocol specification, and illustrated differences in the philosophies of various vendors in their implementations of TCP. The paper summarizes several lessons learned about the TCP implementations through these experiments. \u00a91997 by John Wiley & Sons, Ltd.", "authors": ["Scott Dawson", "Farnam Jahanian", "Todd Mitton"], "n_citation": 69, "references": ["0d6e2c4c-881b-4e91-bf16-f44ac46446fa", "56999d23-90b2-49c1-a8ca-aa2317a7a925", "8b93f379-f7fd-48e6-a778-789885714c7e", "8ed0c977-c4e4-4183-8ec3-b2fc7bea41cf", "a183f61c-a503-4aab-83a3-c716a847f1c7", "c938636e-27f0-4597-ae8e-f9b3a919653c"], "title": "Experiments on six commercial TCP implementations using a software fault injection tool", "venue": "Software - Practice and Experience", "year": 1997, "id": "3d1ff270-b764-41a9-ba41-dba24aafce3d"}
{"abstract": "Iterative aggregation/disaggregation methods provide an efficient approach for computing the stationary probability vector of nearly uncoupled (also known as nearly completely decomposable) Markov chains. Three such methods that have appeared in the literature recently are considered and their similarities and differences are outlined. Specifically, it is shown that the method of Takahashi corresponds to a modified block Gauss-Seidel step and aggregation, whereas that of Vantilborgh corresponds to a modified block Jacobi step and aggregation. The third method, that of Koury et al., is equivalent to a standard block Gauss-Seidel step and iteration. For each of these methods, a lemma is established, which shows that the unique fixed point of the iterative scheme is the left eigenvector corresponding to the dominant unit eigenvalue of the stochastic transition probability matrix. In addition, conditions are established for the convergence of the first two of these methods; convergence conditions for the third having already been established by Stewart et al. All three methods are shown to have the same asymptotic rate of convergence.", "authors": ["Wei-Lu Cao", "William J. Stewart"], "n_citation": 26, "references": [], "title": "Iterative aggregation/disaggregation techniques for nearly uncoupled markov chains", "venue": "Journal of the ACM", "year": 1985, "id": "86c3daea-e393-4608-8c3c-69487fd8ad0a"}
{"abstract": "This paper presents a new integrated compiler framework for improving the cache performance of scientific applications. In addition to applying loop transformations, the method includes data layout optimizations, i.e., those that change the memory layouts of data structures (arrays in this case). A key characteristic of this approach is that loop transformations are used to improve temporal locality while data layout optimizations are used to improve spatial locality. This optimization framework was used with sixteen loop nests from several benchmarks and math libraries, and the performance was measured using a cache simulator in addition to using a single node of the SGI Origin 2000 distributed-shared-memory machine for measuring actual execution times. The results demonstrate that this approach is very effective in improving locality and outperforms current solutions that use either loop or data transformations alone. We expect that our solution will also enable better register usage due to increased temporal locality in the innermost loop, and that it will help in eliminating false-sharing on multiprocessors due to exploiting spatial locality in the innermost loop.", "authors": ["Mahmut T. Kandemir", "Alok N. Choudhary", "J. Ramanujam", "Prithviraj Banerjee"], "n_citation": 115, "references": ["08c710de-10cc-4986-84e3-67acefd9c091", "12b07073-021a-4eb2-99d3-2a87501303df", "49e6498f-4e4f-4cb6-a6ad-1082a4195aba", "502861bf-044d-42a0-bca9-5fb9d8497a58", "59881f5a-a854-4e5b-99c4-29a10913404d", "60f4db1a-0075-4fe9-8bb8-99b6a0eeca0b", "61f2f7f2-4737-4fb8-b191-bbaad8b3f31d", "784b7488-14a5-4484-8686-64f511e91a45", "99600896-0785-48b0-a025-afbdf45f712e", "d0cc855a-7de3-441c-98b3-4b260c635b0b", "da905f5d-682e-4e91-bd0d-9f7e658aa1b7", "ede08ebb-708d-4e7a-b508-60637e2be108"], "title": "Improving locality using loop and data transformations in an integrated framework", "venue": "international symposium on microarchitecture", "year": 1998, "id": "612e395b-37fe-451f-93cf-31655d0f174e"}
{"abstract": "In the Internet community there is a strong demand for platform-independent collaboration software. Java is developed with the major design goals of being a platform-independent, and Internet-oriented programming language. We show how a group of Internet users can share single-user Java applications for synchronous collaboration. Our approach is based on a replicated tool architecture in which each participant runs a copy of the application and the activity of each user is multicast to all the participants in the conference. We have developed a system called Java Collaborative Environment (JCE), on which the Java's Abstract Window Toolkit (AWT) is extended such that mouse and keyboard events are intercepted and distributed among all copies of the shared Java application. In addition we provide an infrastructure and a simple interface for session management and floor control.", "authors": ["Hussein M. Abdel-Wahab", "Bjorn Kvande", "O. Kim", "Jean Philippe Favreau"], "n_citation": 67, "references": ["ada2c7b3-4325-4213-8dcd-ce09b526fae2", "c5700f57-3fad-4434-8032-14be237a6b9a", "ec1fa00a-7ad8-4006-862f-c3a4ceb97321"], "title": "An Internet collaborative environment for sharing Java applications", "venue": "", "year": 1997, "id": "b6a05570-3e8b-46f8-aa87-30258f882304"}
{"abstract": "Novel rotation and scale invariant features are proposed in this paper using discrete wavelet packet transform. The classification performance is tested on a set of 15 Brodatz textures rotated in 12 directions and for five scales across an octave. The classification performance for different wavelet filter banks for the proposed rotation and scale invariant features is tested. An application of these features for script identification is illustrated.", "authors": ["Ramchandra Manthalkar", "Prabir Kumar Biswas", "Biswanath N. Chatterji"], "n_citation": 122, "references": ["11969b7b-b276-4a18-b250-adba956c910f", "5ffd13e9-177c-45f9-8f77-40e6e8f8378d", "746415d7-a412-4a66-8752-ce90b405fc94", "7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987", "7ccbdf09-a84e-4ad2-ab20-cb28b6c41155", "8747f12d-32f3-4156-a0b9-ad8d8c8df8f5", "8a740937-f82e-4036-94e0-ec85c07f0330", "a8d582af-d7f0-4a20-aba5-5b49f43e990a", "f4e766ac-f68f-4829-a5f8-bc8751f57948"], "title": "Rotation and scale invariant texture features using discrete wavelet packet transform", "venue": "Pattern Recognition Letters", "year": 2003, "id": "1457bd9e-8259-438a-9002-c51213d8d62d"}
{"authors": ["Ajit Singh", "Jonathan Schaeffer", "Duane Szafron"], "n_citation": 31, "title": "Experience with parallel programming using code templates", "venue": "Concurrency and Computation: Practice and Experience", "year": 1998, "id": "5c98712e-3405-4314-993f-58d8fc4d0116"}
{"authors": ["St\u00e9phane Demri"], "n_citation": 3, "title": "A Hierarchy of Backward Translations: Applications to Modal Logics.", "venue": "", "year": 1995, "id": "883d6e84-8bd0-4f1e-aaf4-f40ae3a6f609"}
{"abstract": "As a safe and feasible alternative to enriching and enhancing traditional surgical training, virtual-reality-based surgical simulators have been investigated for a long time. But it is still a challenge for researchers to accurately depict the behavior of human tissue without losing the flexibility of simulation. In this paper, we propose an improved scheme of an interactive finite element model for simulating the surgical process of organ deformation, cutting, dragging, and poking, which can maximally compromise the flexibility and reality of soft-tissue models. The scheme is based on our hybrid condensed finite element model for surgical simulation, which consists of the operational region and nonoperational region. Different optimizing methods applied to these regions make a contribution to the speedup of the calculation. Considering in a real surgical operation, dragging or poking operations are also necessary for surgeons to examine surrounding tissues of the pathological focus. The calculation within the area newly applied with forces in the nonoperational region is handled in our new scheme. The algorithm is modified accordingly in order to cope with this aspect. The design and implementation of the approach are presented. Finally, we provide two models to test our scheme. The results are analyzed and discussed to show the efficiency of our scheme.", "authors": ["Wen Wu", "Pheng Ann Heng"], "n_citation": 70, "references": ["38d3887d-0642-4434-8429-abda73d89ddd", "3d380e18-5a97-4090-a9b9-4044efa60ebd", "5b42ff0f-ca29-4314-9d71-ef31c3f5339d", "7a15e77c-ad64-420c-ab95-3698dcad7076", "8f8c93a8-7c09-4ec9-9e44-4e5606ae013d", "a7965ea9-530b-4e38-b2c7-b9e87244a2d6", "c1376eb2-12d9-4bc8-84fa-307b5736668a", "ecae11c0-d425-4661-bae8-f28c23cc788b"], "title": "An improved scheme of an interactive finite element model for 3D soft-tissue cutting and deformation", "venue": "The Visual Computer", "year": 2005, "id": "948e964e-f2db-496f-9d66-cb90a90190a4"}
{"abstract": "Abstract : A network which sorts n numbers when used to sort numbers of only two sizes, 0 and 1, can be regarded as forming the n frontal (unate) symmetric boolean functions of n arguments. When sorting networks are constructed from comparator modules they appear to require: (1) delay time or number of levels of order (log of n to the base 2) squared, (2) size or number of elements of order (log of n to the base 2) squared, and (3) formula length or number of literals of order n (log of n to the base 2). If one permits the use of negations in constructing the corresponding boolean functions, these three measures of complexity can be reduced to the orders of log of n to the base 2, n, and n to the 5th power respectively. The latter network however is incapable of sorting numbers and may be thought of as merely counting the number of inputs which are 1. One may incorporate this network, however, in a larger network which does sort and in time proportional to only log of n to the base 2. (Author)", "authors": ["David E. Muller", "Franco P. Preparata"], "n_citation": 165, "references": ["98db48cc-68f2-4464-ac90-a02fcfc37e48"], "title": "Bounds to Complexities of Networks for Sorting and for Switching", "venue": "Journal of the ACM", "year": 1975, "id": "5224fca8-e035-49a2-a2c5-354d0133200d"}
{"abstract": "Databases often inaccurately identify entities of interest. Two operations, consolidation and link formation, which complement the usual machine learning techniques that use similarity-based clustering to discover classifications, are proposed as essential components of KDD systems for certain applications. Consolidation relates identifiers present in a database to a set of real world entities (RWE's) which are not uniquely identified in the database. Consolidation may also be viewed as a transformation of representation from the identifiers present in the original database to the RWE's. Link formation constructs structured relationships between consolidated RWE's through identifiers and events explicitly represented in the database. Consolidation and link formation are easily implemented as index creation in relational database management systems. An operational knowledge discovery system identifies potential money laundering in a database of large cash transactions using consolidation and link formation.", "authors": ["Henry G. Goldberg", "Ted E. Senator"], "n_citation": 74, "references": ["1953dc63-b00d-4477-825f-a3fb7da34aa0", "1a5b0468-6628-42d0-bedd-511e69724fe5", "7325f209-c505-4071-b20f-0b6fa5ae1320", "b0ba051e-7817-4921-b3af-cb993fcafe84", "c3598633-8176-47ad-8a6a-82b5ac082b08"], "title": "Restructuring Databases for knowledge discovery by consolidation and link formation", "venue": "knowledge discovery and data mining", "year": 1995, "id": "7bae9ff3-ad5e-4e1d-b979-0afa0bd0e52c"}
{"abstract": "Dynamic linking in modern execution environments like .NET is considerably more sophisticated than in the days of C shared libraries on UNIX. One aspect of this sophistication is that .NET assemblies embed type information about dynamically linked resources. This type information implicitly represents compile-time assumptions about the resources available at run-time. However, the resources available at run-time may differ from those available at compile-time. For example, the execution environment on a mobile phone might provide fewer, simpler classes than on a desktop PC. As bytecode cannot adapt to its execution environment, component reuse is restricted and development costs are increased. We have designed and implemented a ''flexible'' dynamic linking scheme that binds bytecode as late as possible to the assemblies and classes available in a .NET execution environment. We describe the scheme's integration with the .NET linking infrastructure, review important design decisions and report on experiences with the ''Rotor'' shared source version of .NET.", "authors": ["Alex Buckley", "Michelle Murray", "Susan Eisenbach", "Sophia Drossopoulou"], "n_citation": 9, "references": ["01694f7a-29f1-41a8-b34b-d1cca410de0a", "0708f15f-8527-4585-b306-70ba535b70c3", "2ba7e6e8-8f58-49be-b789-875d5f57dbb9", "3d375d45-e7da-4fdf-84e2-89017b73a7bc", "49c80579-ced8-4f0a-81f8-b57bbc536761", "4fadaa78-936d-4bf0-b020-a82adb30c0c4", "5ee52c84-d896-4172-bfc3-1790171ce5b8", "62dc1a9f-b5db-468a-b5a8-7d94abae3d75", "63e47d22-969a-4fb0-bc90-709ab19366b5", "69610a51-8cfa-40bc-89a4-f706306f2355", "6997844d-8d5e-41e5-9011-3ff50ec42400", "74c43429-7aed-4fcf-87bf-26ba289983b8", "7fa6f354-3cc0-4f42-a137-1a518ee6bc14", "93e0cf75-f97e-45f6-96b1-28f648460ca0", "fac5f6f0-5478-4768-81c2-3bce2e79220e"], "title": "Flexible Bytecode for Linking in .NET", "venue": "Electronic Notes in Theoretical Computer Science", "year": 2005, "id": "82fff85e-1112-4136-bbe8-93009d27d850"}
{"abstract": "This work defines several control-flow coverage criteria for testing the interactions among a set of collaborating objects. The criteria are based on UML sequence diagrams that are reverse-engineered from the code under test. The sequences of messages in the diagrams are used to define the coverage goals for the family of criteria, in a manner that generalizes traditional testing techniques such as branch coverage and path coverage. We also describe a run-time analysis that gathers coverage measurements for each criterion. To compare the criteria, we propose an approach that estimates the testing effort required to satisfy each criterion, using analysis of the complexity of the underlying sequence diagrams. The criteria were investigated experimentally on a set of realistic Java components. The results of this study compare different approaches for testing of object interactions and provide insights for testers and for builders of test coverage tools.", "authors": ["Atanas Rountev", "Scott Kagan", "Jason Sawin"], "n_citation": 86, "references": ["12816160-ccb8-420e-9dff-b2e165720733", "19acecc9-e95d-4676-b703-40d626f76499", "22b436c1-900f-4a12-b613-86bf2eeb4880", "29051770-bee1-42c5-a6c3-3b11c1034cba", "3150918b-512b-4c22-a2d1-30bfd86f22bc", "3ae5c2c4-969d-41f8-9c31-2cbdf369ef78", "6aec0cf3-52c8-4b68-bc14-0e0c89e7416f", "7865e2fe-028f-4871-84f0-3f471b7d1cd8", "7af2c195-e66f-478f-8d91-74e6e30e0a9e", "8bcd5ada-dfa2-40ab-9ebc-0eaa96b34dcd", "98ea78dc-4ed1-4c9a-b560-6108053b7e4d", "a1d3c7e9-7a8e-4f09-b912-51ef52200564", "b2cf863f-1c30-474a-8c02-9f83b8576533", "c9489690-75b7-4b89-8214-4c1c4e1437c1", "ca382f5c-b36c-4f29-99d7-d1caf04724bb", "d6285e34-13fa-4327-b4f9-203181baa8c6", "df6f4bea-409a-4bf4-a3b6-061c763d2c92"], "title": "Coverage criteria for testing of object interactions in sequence diagrams", "venue": "fundamental approaches to software engineering", "year": 2005, "id": "fa47ce3f-0d2c-4f86-9a62-c52939db0179"}
{"authors": ["Maximilian Ott", "John P. Lewis", "Ingemar J. Cox"], "n_citation": 62, "references": ["9ad6f38a-e002-40c3-a80e-9550666a4530"], "title": "Teleconferencing eye contract using a virtual camera", "venue": "human factors in computing systems", "year": 1993, "id": "806c7e15-6fbc-4afc-aab1-e47e4e8efccf"}
{"abstract": "We introduce a new form of computational unit for feedforward learning networks of the backpropagation type. Instead of calculating a weighted sum this unit calculates a weighted product, where each input is raised to a power determined by a variable weight. Such a unit can learn an arbitrary polynomial term, which would then feed into higher level standard summing units. We show how learning operates with product units, provide examples to show their efficiency for various types of problems, and argue that they naturally extend the family of theoretical feedforward net structures. There is a plausible neurobiological interpretation for one interesting configuration of product and summing units.", "authors": ["Richard Durbin", "David E. Rumelhart"], "n_citation": 481, "references": ["60a33967-3cc7-4a40-a12b-2d9b3b10481c", "d3ca81fa-2930-4c68-bdea-d41bb8bd3f1d", "db3572c6-2a7e-47d7-9aec-1f57291c55d5", "ea98bd3b-fe01-4584-b5bc-4b7eacf78d47"], "title": "Product units: a computationally powerful and biologically plausible extension to backpropagation networks", "venue": "Neural Computation", "year": 1989, "id": "e3dc812e-78dd-41a6-b87b-756e5a40cb46"}
{"authors": ["Isabelle Gnaedig", "Claude Kirchner", "H\u00e9l\u00e8ne Kirchner"], "n_citation": 50, "references": ["36fc3be2-558d-435f-8251-f703122547d1", "41236602-0290-40b2-8776-c075562d5616", "5fbef801-783b-43ec-909e-b377f4a66f1f", "608d90cb-b738-44b2-9f87-8859ceec56b3", "613e2f6e-2f6e-4d7e-9d1c-49b1f5b69b54", "6fc9d62f-d0f7-4fbe-a1ff-ffd9ad952c61", "76a30389-d40a-40d8-8f16-e44623545eae", "8376c0af-6536-47fc-aa66-23e4d9347aad", "8df8b8e7-4351-4ad5-8238-09b406c3371c", "aab22dd4-aa1d-4257-8af5-330f341df1a2", "b3527ee9-e743-47dd-83b4-52fe28921ace", "b4636ebc-e022-4df9-8019-dfb77b9c8587", "bf92b477-769c-40a5-ab47-ed99dfc337f8", "c8974d31-a1de-4a8f-ba50-fc9c143f393a", "d8df051d-f0c0-41b5-a392-7f3fad8e85a1", "d9088cfc-edaa-42bc-89c0-0ffb4d06df3f", "dd206865-aa43-4c41-9d0d-52d114c99480", "ef04d288-4f63-4502-8047-c9eaeb46220b", "f81b1630-bd58-4a7f-8ebc-c030a3059b87", "f942dbc5-59fe-47d9-92fd-29a43738b430", "fec0e381-cba7-429d-99c0-ea176fe3c050"], "title": "Equational Completion in Order-Sorted Algebras (Extended Abstract)", "venue": "", "year": 1988, "id": "1b6f1b43-730b-4ece-8d00-89c250fb955a"}
{"abstract": "Integrity repair is a pragmatic alternative to integrity checking, already proposed by relational and Codasyl standards and supported by several commercial systems, although for a small number of constraint types. This paper proposes to integrate constraint languages with the declarative specifications of their integrity repair actions. We introduce a rather powerful, predicate-based language for specifying integrity constraints, then we discuss the semantics of repair actions as computations which react to constraint violations, then we establish sufficient conditions for ensuring their termination, and finally we show how repair actions can be integrated in the SQL2 standard and implemented by means of relational triggers (written in Oracle)", "authors": ["Elena Maria Baralis", "Stefano Ceri", "Stefano Paraboschi"], "n_citation": 50, "references": ["00adb70e-a87f-4483-9f06-c67aec78b617", "0a776558-c395-4bf7-8ad8-41f56e00c4c5", "19ac2523-01b1-49d5-94db-f5b824264366", "1ceb85a3-1bf2-4607-baf8-1aef806a544b", "224d9478-273a-4bfc-a8ec-464ba60d79e3", "34ab5c5a-bbb9-420e-8857-373a989524f3", "3af1db81-ea45-4174-a65c-3c086556150a", "5836b716-c9ae-4a15-b36c-474d0f8220c8", "5a7709ff-252f-48ad-aaa3-7488667cabb8", "63716086-ced0-4412-80ee-f8b856de8972", "792fa3e1-74f7-4ebd-b805-e30988edb80c", "8d405e31-f1fa-4676-80e9-f05e4d1058bc", "a271d6db-7b20-46ca-ae68-497883327349", "bcaeffd8-2b75-4d94-b5a6-9c268df866f9"], "title": "Declarative Specification of Constraint Maintenance", "venue": "international conference on conceptual modeling", "year": 1994, "id": "001dd059-7df3-4dc0-bff6-a174caaacf51"}
{"abstract": "The control of the popular magnetic levitation system is addressed from the viewpoint of adaptive control based on fast, on line, algebraic parameter estimation, exact linearization and generalized proportional integral (GPI) output feedback control. The GPI controller guarantees an asymptotically exponentially stable behavior of the controlled ball position and the possibilities of carrying out rest-to-rest trajectory tracking tasks. The online algebraic parameter estimation approach estimates, quite accurately, and in a very short period of time, the unknown parameter or the magnetic levitation system. The proposed adaptive controller is actually implemented on a laboratory prototype with excellent experimental results for, both, stabilization and trajectory tracking tasks.", "authors": ["Rafael Morales", "Vicente Feliu", "Hebertt Sira-Ram\u00edrez"], "n_citation": 65, "references": ["06e6148c-0cae-4cd9-8e29-fa0f472a6128", "0b3a99fe-7abc-4fd1-85cc-b09235fb4161", "3551839d-440a-45f4-94cd-d04537d14ff7", "39226d45-6ba9-4fb0-b1ff-3ac57dcda445", "8e5904b8-d3dc-4244-a84b-49a8439ba029", "bcc64b20-074f-4484-851c-5c5fe5166628", "bfa19434-4948-4407-ac68-0d1fdd76bb48", "d1ac9695-0af3-410d-bbd3-134aaf8b84e5", "dd2c694d-851d-4b51-9151-e0e46aab79cf", "df2cf06f-56cb-43e0-917b-7a39a60ff5ce", "ed095e55-90e4-4a56-a104-04a933655f28", "feef83eb-c692-471c-9858-2dad58c7d41d"], "title": "Nonlinear Control for Magnetic Levitation Systems Based on Fast Online Algebraic Identification of the Input Gain", "venue": "IEEE Transactions on Control Systems and Technology", "year": 2011, "id": "8f3e48a0-8c71-4b86-92f2-beaf84131f53"}
{"authors": ["Gary Y. Breitbard", "Gio Wiederhold"], "n_citation": 50, "references": ["05cba123-eac3-4277-bab9-b4017f1f4183", "8bde5129-d31a-4062-b4f9-edf40b89796d"], "title": "THE ACME COMPILER", "venue": "", "year": 1968, "id": "807a11a6-162b-40d2-9e75-c4bc2cc25cf9"}
{"abstract": "Many applications of autonomy are significantly complicated by the need for wireless networking, with challenges including scalability and robustness. Radio accomplishes this in a complex environment, but suffers from rapid signal strength variation and attenuation typically much worse than free space loss. In this paper, we propose and test algorithms to autonomously discover the connectivity area for a base station in an unknown environment using an average of received signal strength (RSS) values and a RSS threshold to delineate the goodness of the channel. We combine region decomposition and RSS sampling to cast the problem as an efficient graph search. The nominal RSS in a sampling region is obtained by averaging local RSS samples to reduce the small-scale fading variation. The RSS gradient is exploited during exploration to develop an efficient approach for discovery of the base station connectivity boundary in an unknown environment. Indoor and outdoor experiments demonstrate the proposed techniques. The results can be used for sensing and collaborative autonomy, building base station coverage maps in unknown environments, and facilitating multi-hop relaying to a base station.", "authors": ["Jeffrey N. Twigg", "Jonathan Fink", "Paul L. Yu", "Brian M. Sadler"], "n_citation": 15, "references": ["5918d041-c259-4494-8131-61fffd12fdf2", "73e43673-7790-4453-8438-ab24f7816d29", "80ef2c4c-a5d6-4492-b6a1-07437277fde2", "b72db87e-0c78-4ecd-b36e-0ba5f2254e9a", "d1e0ec5d-c01a-4db2-a519-03eb8a6edeed", "d4ba4dde-cd7f-42c4-b2a7-88bab0464351", "dad07d3b-7393-4ce0-a74e-aa0f4b541564", "e548d63b-0c12-4f11-b870-55c38e5e1e06", "f513185b-7ca9-4278-8e2c-56b84a9fd6f8", "fde22a70-bd5e-427c-bf54-cf0afb1cd044"], "title": "Efficient base station connectivity area discovery", "venue": "The International Journal of Robotics Research", "year": 2013, "id": "0ba3f3a7-2569-4529-b7e6-1290a3d02433"}
{"abstract": "Advances in nonlinear control theory have provided the mathematical foundations necessary to establish conditions for stability of several types of adaptive fuzzy controllers. However, very few, if any, of these techniques have been compared to conventional adaptive or nonadaptive nonlinear controllers or tested beyond simulation; therefore, many of them remain as purely theoretical developments whose practical value is difficult to ascertain. In this paper we develop three case studies where we perform a comparative analysis between the adaptive fuzzy techniques in Spooner and Passino (1995,1996) and some conventional adaptive and nonadaptive nonlinear control techniques. In each case, the analysis is performed both in simulation and in implementation, in order to show practical examples of how the performance of these controllers compares to conventional controllers in real systems.", "authors": ["Raul Ordonez", "Jon Zumberge", "Jeffrey T. Spooner", "Kevin M. Passino"], "n_citation": 116, "references": ["2826d482-90f4-48ee-8ba1-90450e5600d5", "3c9f64b9-ff1e-4e9f-8307-5d1243a51a90", "3faa6244-4283-4ece-b8f4-3ffe32b7653d", "a2670e26-0c7f-42ce-916f-ec1c9e008bf0", "af13dab4-91a7-49cc-af85-fa69ec068d5d", "b1458a1c-7482-4e92-8406-b2d20d18b793", "c3892076-d0c5-4225-b570-6a1e44636d55", "e07c17af-995e-477a-9808-cb8ef7f8d7e1"], "title": "Adaptive fuzzy control: experiments and comparative analyses", "venue": "IEEE Transactions on Fuzzy Systems", "year": 1997, "id": "a5ef6be0-1e6e-4f9e-87a1-de2edefde16f"}
{"abstract": "We study an active underground economy that trades stolen digital credentials. In particular, we investigate keylogger-based stealing of credentials via dropzones, anonymous collection points of illicitly collected data. Based on the collected data from more than 70 dropzones, we present an empirical study of this phenomenon, giving many first-hand details about the attacks that were observed during a seven-month period between April and October 2008. We found more than 33 GB of keylogger data, containing stolen information from more than 173,000 victims. Analyzing this data set helps us better understand the attacker's motivation and the nature and size of these emerging underground marketplaces.", "authors": ["Thorsten Holz", "Markus Engelberth", "Felix C. Freiling"], "n_citation": 215, "references": ["0012ea0d-8d41-4246-87d2-160896ae97d1", "22e802be-a9cc-4513-b626-1e721acf2c9b", "28bca8e5-1b5a-4dfd-a805-f4be80cea363", "338ecf9d-fda6-4676-99c2-2678cc5921cd", "33fac8fa-18fc-4cbb-b5bd-3f853b63ddb1", "3b3fa1a6-e33f-4345-98ae-2794994c5a80", "41eea6a1-ad9d-41ce-b408-707190ff02af", "478c8272-bef1-47c0-8853-60a5e5414b9c", "5b50cca9-85e6-4ee8-b733-d8fe0ba8dcba", "70fcde1f-e45b-4068-8b5d-2f36ad4dea3a", "7a71b66c-06aa-4176-bdcb-144fed9a0777", "7c6d97b8-f06c-4e4f-aa41-e0ffef913cd6", "8d94d8c5-ad9c-4c14-aad4-0f9caf60422d", "9109f42d-5153-4077-8bb1-a221773b9660", "913b5dd2-175e-437c-9143-ef6584addc22", "b9604331-efd9-40a1-ac07-df82982e406b", "dbd400e1-729c-40cd-9707-de6fdb6808bd", "dc585450-8169-49a6-927f-7d9baf6e43b6", "e90ba45e-058a-49b1-b74d-4ba772d8481b", "ec83d2a6-b348-4e77-ae5c-ae58b43d8330", "fb5833e1-ca68-445a-bbf5-338a847a02b4"], "title": "Learning more about the underground economy: a case-study of keyloggers and dropzones", "venue": "european symposium on research in computer security", "year": 2009, "id": "5a476714-9206-4e7a-b07c-3028b7a95460"}
{"abstract": "This paper presents the dynamic neural networks partial least squares (DNNPLS) as a strategy for open-loop identification of multivariable chemical processes that circumvent some of the difficulties associated with multivariable process control. The DNNPLS is an extension of the neural networks\u2019 partial least squares (NNPLS) developed by Qin and McAvoy (Comp. Chem. Eng. 20 (1992) 379). Here, a dynamic extension to the NNPLS algorithm is proposed in which the static neural network models in the latent space (inner relationship) are replaced by dynamic neural network models. Though this approach has previously been dismissed as being sub-optimal (Am. Inst. Chem. Eng. J. 38 (1992) 1593; Chem. Eng. Sci. 48 (1993) 3447) in terms of the outer relationship (relationship between the residuals), Lakshminarayanan et al. (Am. Inst. Chem. Eng. J. 43 (1997) 2307) have shown that this sub-optimality problem comes into prominence only when no attention is placed on the design of the plant probing signals. As illustrations, the DNNPLS identification strategy is implemented on simulations of a model IV fluid catalytic cracking unit (FCCU) and of an isothermal reactor. In both cases, it is shown that the methodology is capable of modeling the dynamics of the chemical processes and an improved performance is achieved over that of the PLS-ARMA (Comp. Chem. Eng. 20 (1996) 147) for the isothermal reactor. # 2002 Elsevier Science Ltd. All rights reserved.", "authors": ["Olufemi A. Adebiyi", "Armando B. Corripio"], "n_citation": 26, "references": [], "title": "Dynamic neural networks partial least squares (DNNPLS) identification of multivariable processes", "venue": "Computers & Chemical Engineering", "year": 2003, "id": "ba5bed32-1e96-4fc0-b7eb-96394acdd205"}
{"abstract": "We present deterministic techniques for computing upper and lower bounds on marginal probabilities in sigmoid and noisy-OR networks. These techniques become useful when the size of the network (or clique size) precludes exact computations. We illustrate the tightness of the bounds by numerical experiments.", "authors": ["Tommi S. Jaakkola", "Michael I. Jordan"], "n_citation": 83, "references": ["0f9b8b95-b358-4f5c-91f6-439050811fbc", "1c9e0295-e59f-41a2-b7ea-821efd4e65e9", "37bfba44-965a-40df-871e-5aea3eb4fefa", "45a83c74-42cf-4193-b8fc-17c1853f26e4", "50c2b314-1596-4444-ae9a-606df9899372", "586c458c-983d-46a9-93a3-702240b49d17", "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706", "e8571238-943e-46d2-920b-63013e5dd5cd"], "title": "Computing upper and lower bounds on likelihoods in intractable networks", "venue": "uncertainty in artificial intelligence", "year": 1996, "id": "df9e7880-4829-44db-8fc0-90c53657bbed"}
{"abstract": "We present a novel approach of extracting a domain ontology from large-scale thesauri. Concepts are identified to be relevant for a domain based on their frequent occurrence in domain texts. The approach allows to bootstrap the ontology engineering process from given legacy thesauri and identifies an initial domain ontology that may easily be refined by experts in a later stage. We present a thorough evaluation of the results obtained in building a biosecurity ontology for the UN FAO AOS project.", "authors": ["Raphael Volz", "Rudi Studer", "Alexander Maedche", "Boris Lauser"], "n_citation": 18, "references": ["33d6dabd-c086-4a6e-939a-c322b6ada724", "7101be81-c857-4eb5-addb-7ea92d7151c8", "b36bf23d-70b8-4104-89d5-e460a831ac9a"], "title": "Pruning-based Identification of Domain Ontologies", "venue": "Journal of Universal Computer Science", "year": 2003, "id": "23d32e5c-7e63-43dc-8c4a-cb29aa1b6401"}
{"abstract": "An active network allows applications to inject customized programs into network nodes. This enables faster protocol innovation by making it easier to deploy new network protocols, even over the wide area. We argue that the ability to introduce active protocols offers important opportunities for end-to-end performance improvements of distributed applications. We begin by describing several active protocols that provide novel network services and discussing the potential impact of these kinds of services on end-to-end application performance. We then present and analyze the performance of an active networking protocol that uses caching within the network backbone to reduce load on both servers and backbone routers.", "authors": ["Ulana Legedza", "David Wetherall", "John V. Guttag"], "n_citation": 167, "references": ["0695070f-320e-4d26-9c68-2c8faa20c944", "314f5dde-7eef-42fa-9d17-da162e9b1efb", "3facecb8-0ca9-49d4-aa90-42a144f8c33d", "5b568078-c342-461d-8a19-44ad105e74fa", "5fa0709f-7330-417f-8da7-3ab31d91da5b", "6445682d-fef3-4d89-8ecf-404891b01100", "6f1bb20f-25f0-4d0b-a7a5-f31e3fa66bdd", "774c2290-54f4-4dcb-a129-6770a2ef8ef9", "81435071-cb68-4ceb-8ddb-7852f2b300b6", "9771c887-0cd9-4416-a8ca-be5170e4246e", "ac3319ad-c1b8-4b95-a5d2-4c77f44fd224", "c1493455-f58f-4be0-9745-eaaa17dd5b44", "c8771a57-de9c-44b7-966c-1ff156d3091f", "e883ae1e-0c54-4fcb-9c38-4165bb0fcc7a", "f6fc4443-7a98-4f9f-92e8-e4e5d94521a7", "fa0e04da-e656-4506-92d4-b52ae587f145"], "title": "Improving the performance of distributed applications using active networks", "venue": "international conference on computer communications", "year": 1998, "id": "7aec1cd5-3106-4ef7-8676-01b3b8fac8c2"}
{"abstract": "Commitments among agents are widely recognized as an important basis for organizing interactions in multiagent systems. We develop an approach for formally representing and reasoning about commitments in the event calculus. We apply and evaluate this approach in the context of protocols, which represent the interactions allowed among communicating agents. Protocols are essential in applications such as electronic commerce where it is necessary to constrain the behaviors of autonomous agents. Traditional approaches, which model protocols merely in terms of action sequences, limit the flexibility of the agents in executing the protocols. By contrast, by formally representing commitments, we can specify the content of the protocols through the agents' commitments to one another. In representing commitments in the event calculus, we formalize commitment operations and domain-independent reasoning rules as axioms to capture the evolution of commitments. We also provide a means to specify protocol-specific axioms through the agents' actions. These axioms enable agents to reason about their actions explicitly to flexibly accommodate the exceptions and opportunities that may arise at run time. This reasoning is implemented using an event calculus planner that helps determine flexible execution paths that respect the given protocol specifications.", "authors": ["Pinar Yolum", "Munindar P. Singh"], "n_citation": 144, "references": ["0f045452-ed04-4aac-9089-8d335630620f", "0ff367c3-782a-4ba4-a57e-f715c7725fb6", "1e2ca34b-34fc-4a7e-923c-6e9d79dc8f56", "1f9146c5-b4e8-4543-b6ac-af714e155818", "5a4e1fe5-4060-4bac-9e5a-5cbc17640361", "71e354c6-7cec-41ed-8a17-82dea44a4022", "84455760-fd68-48c2-94a4-a212b4be2f8b", "8c7de640-e084-4034-9a0c-a57c25c2ca12", "94ebbd2d-dbba-4af9-9402-45f246bdbdf0", "96210891-6fa9-4881-bae1-cbafddbe06dc", "a1d3d835-e085-4f89-b826-96dd37d4fadd", "a8b3d9a1-4ff2-4204-9fc0-b04e5e688eee", "a9261511-cc21-4243-983a-f270c7eeeb4f", "b1a10077-957f-4c0a-9047-9cf02644aae6", "b649dc3d-5b83-4dce-af41-07f5378d3173", "c4ba86d0-ad19-42d5-b4ef-c5b33d185643", "ccbd7459-542c-400d-a098-f7dd46676c95", "ddbef653-9b06-4996-be1b-cdc047ab1f2d", "ea109d34-fb4a-4148-a3b3-402259c6c984", "f497994e-69af-40f6-8145-47f1b365f7aa"], "title": "Reasoning about Commitments in the Event Calculus: An Approach for Specifying and Executing Protocols", "venue": "Annals of Mathematics and Artificial Intelligence", "year": 2004, "id": "90b769fb-9848-4f41-b5a1-3e96837dcf70"}
{"abstract": "The paper applies the theory of communicating sequential processes (CSP) to the modelling and analysis of a non-repudiation protocol. Non-repudiation protocols differ from authentication and key-exchange protocols in that the participants require protection from each other, rather than from an external hostile agent. This means that the kinds of properties that are required of such a protocol, and the way it needs to be modelled to enable analysis, are different to the standard approaches taken to the more widely studied class of protocols and properties. A non-repudiation protocol proposed by Zhou and Gollmann (1996) is analysed within this framework, and this highlights some novel considerations that are required for this kind of protocol.", "authors": ["Steve Schneider"], "n_citation": 171, "references": ["109ebf51-e412-4f68-a55c-f71c8b26c08a", "1c81fdcb-be83-4f02-a69d-86372afa828a", "21e8de76-11b0-461d-a27e-f6ac7b68ac9b", "31820f7a-9e37-44cf-bb27-99128ea17699", "3c70b92f-ef52-443d-95a8-39870acad02c", "994fcebe-bb4f-4585-8086-8e6eb00a95e8", "bb99f34e-c264-4033-9377-ecbedd0d5194", "de30aa80-b77b-4757-b4a8-6a086906bc3a"], "title": "Formal analysis of a non-repudiation protocol", "venue": "computer security foundations workshop", "year": 1998, "id": "7f84329a-28ab-4b07-bb59-e2808ebd6482"}
{"abstract": "This paper discusses the principles of developing software components for real-time systems. The procedure is based on the fundamental concept of a real-time architecture rooted in the feedback control paradigm of control engineering. Generic design patterns for real-time software components are presented, valid for all relevant real-time architectures. Finally, a case study of an air traffic control system based on the CORBA framework is discussed. The tool support for component-based design and implementation is presented, including industry-strength commercial off-the-shelf software.", "authors": ["Janusz Zalewski"], "n_citation": 50, "references": ["81f7df80-0ee0-41d3-b282-10ebb5ba9731", "ddb2a17d-c6d6-4675-ab69-20b0c9cf0109"], "title": "Developing component-based software for real-time systems", "venue": "", "year": 2001, "id": "750d417b-3462-48bc-b63e-d09553b30d5e"}
{"authors": ["Thierry Coupaye", "Christine Collet"], "n_citation": 50, "references": ["0c5cb4ef-2c5a-45a4-a718-90536c7c33a5", "59793970-186e-4973-8ebb-cf431ca80b59", "5e3c41fb-7ab9-41af-b7f2-6fb76dce09e6", "7bcedda0-42dc-401a-a1d7-aa8ecda01d3e", "a2ef5bac-543c-48bc-bc60-5f797eddab21", "d1e73660-9287-4e9a-b5d2-5bbce248933c", "e2fdba56-ce81-434b-a939-576972c32a5e"], "title": "Denotational Semantics for an Active Rule Execution Model", "venue": "", "year": 1995, "id": "bc6ee171-9021-4c02-852e-8fd9aae9d2ef"}
{"abstract": "Information technology is playing an increasingly integral role in the competitive strategies of many organizations. As this trend continues, it is not surprising that there is growing emphasis on the ability of organizations to plan, design and implement critical information systems. A major strategy to improve the effectiveness of these processes is the use of computer-based planning and design aids. However, there is little empirical evidence that using this technology provides a significant performance impact. One factor limiting research on the impact of technology on planning and design is the manner in which this technology has been conceptualized for measuring usage behavior. This research develops a functional model of I/S planning and design support technology that distinguishes three general functional dimensions: Production Technology, Coordination Technology and Organizational Technology. An empirical analysis is used to test the robustness of the proposed model and its ability to discriminate among current design aids in a meaningful way. Implications for the use of this model in the study of I/S planning and design processes are discussed.", "authors": ["John C. Henderson", "Jay G. Cooprider"], "n_citation": 139, "references": ["030e3e34-3091-42c7-99e8-58100103d049", "1a2db107-cafb-4a18-b90f-f57d6c5d0ece", "2b249c89-fb4f-4aa2-82a3-92c72c5a4fd4", "397522cc-cb26-45fe-9a29-0fd41d9bb4e9", "54f73b80-bd14-46e1-8435-9082cc7a82f5", "64334d69-88a4-4acd-828b-ca0deaa96926", "6a7d6e71-b0a6-4dc4-99f7-5ba56a6021c9", "6b3a699e-955b-4b01-aa13-dcfa91827773", "7e7a986e-1d06-460a-bef5-44b4ea87dfbc", "866c6edc-a282-41c1-bb99-b9ede454e6da", "8f3e4df3-7c15-4029-bbf1-4496c0662e30", "aa89be80-b100-469f-b60d-b47d0d317540", "c045e432-a5af-466c-a87f-33ba639a7ded", "da71c39e-a4d4-417b-8927-0a93b64bdb82", "dea745ac-3148-4c70-b3ac-05e83e02a035", "eb284910-ca3f-44d3-8362-6d2fff451705"], "title": "Dimensions of I/S Planning and Design Aids: A Functional Model of CASE Technology", "venue": "Information Systems Research", "year": 1990, "id": "87f7d37f-b0ba-4992-bac7-46dd13b28290"}
{"abstract": "This paper presents a hybrid fingerprint matching algorithm combining two heterogeneous schemes, namely the texture-vector and minutiae-based methods. The proposed technique has been designed in order to run on a programmable smart card, with image processing and feature extraction performed on the host, and matching performed by the card device. The two matching algorithms have been carefully tuned in order to achieve an acceptable performance despite the computation and memory constraints. Given the high level of intrinsic security that smart cards already have, and the interactive nature of target applications, the complexity of the problem has been greatly reduced, making such an approach feasible. This is validated by the experimental results we show, gathered from an implementation onto a Java Card device, where acceptable false acceptance and rejection rates are achieved at the cost of a reasonable response time of the device.", "authors": ["Tommaso Cucinotta", "Riccardo Brigo", "Marco Di Natale"], "n_citation": 11, "references": ["2d2e9ec9-1512-4781-9020-4c61c058a563", "88654e63-a2b0-485c-9a07-e55c1fe6bc98", "980a76d1-a4a8-4794-9643-8a7e6a5cea80", "f12a32b8-aeab-48c2-8300-1dfd395fda17", "f85a915b-4699-4808-8921-ffce65c04f47", "fca5396b-ab30-40c9-8da3-f7b7c3e9b5c0"], "title": "Hybrid Fingerprint Matching on Programmable Smart Cards", "venue": "trust and privacy in digital business", "year": 2004, "id": "b7c4795d-49e7-4a82-8662-1a6914aabc74"}
{"abstract": "Queueing Petri nets are a powerful formalism that can be exploited for modeling distributed systems and evaluating their performance and scalability. By combining the modeling power and expressiveness of queueing networks and stochastic Petri nets, queueing Petri nets provide a number of advantages. This tutorial presents an introduction to queueing Petri nets first introducing the modeling formalism itself and then summarizing the results of several modeling case studies which demonstrate how queueing Petri nets can be used for performance modeling and analysis. As part of the tutorial, we present QPME (Queueing Petri net Modeling Environment), an open-source tool for stochastic modeling and analysis of systems using queueing Petri nets. Finally, we briefly present a model-to-model transformation automatically generating a queueing Petri net model from a higher-level software architecture model annotated with performance relevant information.", "authors": ["Samuel Kounev", "Simon Spinner", "Philipp Meier"], "n_citation": 6, "references": ["2c5cdb37-989a-4f49-b0e6-00324d454e45", "30f67738-3897-4f31-9161-b7e24355718d", "342d085a-3c46-46af-b379-51242acbfe74", "357e299e-56b9-4766-be96-bc0952dc8474", "65d3891a-84d4-4444-8102-4128d79d156a", "672d9606-56b5-4ae3-9bf2-9d44a9f1d016", "7a2d1c77-322c-406a-bc1e-27b9bbc07012", "7e2fa543-a23d-46c6-ad97-226b9096cb5b", "86089060-c440-462d-8e29-3b09ec696b4d", "ad7ef15b-d08c-43a7-9a31-dd576e7d0ec6", "b86d3fad-f4ba-4a82-96c8-a9a4838cdb21", "ccc4d2fc-4c93-4aed-9425-e5b58dd8564f", "d9bd1abb-86d1-4d6f-afd1-82cdffd20926"], "title": "Introduction to queueing petri nets: modeling formalism, tool support and case studies", "venue": "international conference on performance engineering", "year": 2012, "id": "78f509d9-2ebf-425e-a2dd-7ab6a438c0f7"}
{"abstract": "We describe LLVM (low level virtual machine), a compiler framework designed to support transparent, lifelong program analysis and transformation for arbitrary programs, by providing high-level information to compiler transformations at compile-time, link-time, run-time, and in idle time between runs. LLVM defines a common, low-level code representation in static single assignment (SSA) form, with several novel features: a simple, language-independent type-system that exposes the primitives commonly used to implement high-level language features; an instruction for typed address arithmetic; and a simple mechanism that can be used to implement the exception handling features of high-level languages (and setjmp/longjmp in C) uniformly and efficiently. The LLVM compiler framework and code representation together provide a combination of key capabilities that are important for practical, lifelong analysis and transformation of programs. To our knowledge, no existing compilation approach provides all these capabilities. We describe the design of the LLVM representation and compiler framework, and evaluate the design in three ways: (a) the size and effectiveness of the representation, including the type information it provides; (b) compiler performance for several interprocedural problems; and (c) illustrative examples of the benefits LLVM provides for several challenging compiler problems.", "authors": ["Chris Lattner", "Vikram S. Adve"], "n_citation": 3311, "references": ["0243e135-7f62-4182-8e4f-b4e4add01140", "06fdebfe-c157-4275-87f6-94f2cfa6f16c", "139a168a-ecbb-4dea-b124-340552013625", "23d00708-410e-4049-9573-57702ab606ff", "2448f6ce-230a-495c-8cab-21a8bf2865eb", "39d0867f-f7c6-47f3-99b8-a7fa7fb14197", "3f1815dd-761b-426e-8753-c4d6d275d8b8", "43047bed-6608-4811-b391-f80995a0c7ca", "6cb5e336-3480-4f7d-a864-83f5176e2922", "6f9e1a29-ac8b-45b7-862d-ade5ecfe4a07", "86d496e2-401c-4d2e-ae44-03593f3a1852", "8ec678d3-4fc6-4c88-9d36-21a57b3fa6ab", "99082c1d-8ece-4c28-a77c-6d89b4591951", "b88ed242-f6ff-4c1b-9e51-319cda08c6d0", "c1242e35-adfb-4743-bba4-5299b408c36c", "c36449f2-7926-49b0-b5e5-b98295795402", "ca3d097b-3f22-414e-8045-0f6affbaa50a", "ca7d5731-f2d9-4acc-82f8-dd85a6191b1d", "ccaf455f-7b99-4080-9619-a729e74889b3", "d3b890a0-524c-476f-94f3-f99d3ed8d914", "d54c03e2-1948-4db9-ae4c-dad7c8a7be64", "e1db7f56-ea40-4e08-97f7-5b60dc7eae82", "ebc9eff6-01aa-44e7-afab-3374571d9625"], "title": "LLVM: a compilation framework for lifelong program analysis & transformation", "venue": "symposium on code generation and optimization", "year": 2004, "id": "c036912f-ac89-48b8-85b4-ceff1d08e32a"}
{"authors": ["Ryohei Sasano", "Sadao Kurohashi"], "n_citation": 29, "references": ["2e3be853-8f46-451b-aa7f-b6b850242d71", "3a29aef8-37d6-47cc-ac52-2fee41c94875", "7d41171c-03a2-47c8-9e0e-bfcae6fef402", "7e71a44c-a239-4f9d-9678-e5f0127d17cf", "9fe588d2-07e7-405a-89bb-d8ec1359d0ea", "ddcd8284-b305-4159-a7bc-53e1664fda14", "eef872c7-38c0-444c-891b-f229dd652929"], "title": "Japanese Named Entity Recognition Using Structural Natural Language Processing.", "venue": "international joint conference on natural language processing", "year": 2008, "id": "7e6f9b51-b6af-4cef-a53c-12a946446e13"}
{"abstract": "We present a reformulation of the word pair features typically used for the task of disambiguating implicit relations in the Penn Discourse Treebank. Our word pair features achieve significantly higher performance than the previous formulation when evaluated without additional features. In addition, we present results for a full system using additional features which achieves close to state of the art performance without resorting to gold syntactic parses or to context outside the relation.", "authors": ["Or Biran", "Kathleen McKeown"], "n_citation": 24, "references": ["71c92f94-450d-49e7-afda-13062140918f", "790bb00c-6ab4-480a-91f5-6a426f057859", "7b310ff3-31d3-4262-b54d-272a80de396e", "9a4e4d3e-796b-4511-9f43-7acaf25d0c8c", "bbac52cb-1823-421f-9b86-9dc94f734ec3", "bcea6f66-316b-492e-9242-e779180d1da0", "ee2a29e0-80c2-4ec3-a657-ceefb8f4dfbd", "f9fa449b-635e-4ad7-9df2-c0ef8de90fbf", "fe537ca8-5095-4cad-951a-e0c781172b2c"], "title": "Aggregated Word Pair Features for Implicit Discourse Relation Disambiguation", "venue": "meeting of the association for computational linguistics", "year": 2013, "id": "bbd5cad9-ef50-4527-be6f-8a74ced1903f"}
{"abstract": "Abstract   The practice of measuring software is increasingly seen as a valuable tool in the overall development of high-quality software projects. Software measurement attempts to use known, quantifiable, objective, and subjective measures to compare and profile software projects and products. To compute these measures effectively, data that characterize the software project and product are needed. This paper covers aspects of data collection and software measurement as they have been applied by one particular organization, the Software Engineering Laboratory (SEL). The measurement results include the experiences and lessons learned through numerous experiments conducted by the SEL on nearly 60 flight dynamics software projects. These experiments have attempted to determine the effect of various software development technologies on overall software project quality and on specific measures such as productivity, reliability, and maintainability.", "authors": ["Jon D. Valett", "Frank E. McGarry"], "n_citation": 50, "references": [], "title": "A summary of software measurement experiences in the software engineering laboratory", "venue": "Journal of Systems and Software", "year": 1989, "id": "a10d9b48-973f-4840-ba0c-b2b7ded23a76"}
{"abstract": "Teaching group based Agile software development project courses is difficult. There are many aspects that need to be considered for a project to be successful such as a well defined scope, students working effectively together, and engaging with the customer. In this paper we present an experience report at teaching an Agile software development project course that involved teams developing web applications. The resources developed for the course and discussion about our experience will help inform others who also wish to teach group based software development courses.", "authors": ["Craig Anslow", "Frank Maurer"], "n_citation": 50, "references": ["00e8b54c-8e26-4cf9-ab4d-a5c9b51ba8bb", "0329f627-d14b-4b6b-bec6-d1be93c5df8a", "10aae0d3-3c25-43ed-ab4c-5393933be347", "3835ee2e-8db5-452c-92d1-43ca3aa9aae7", "7c1fe32c-336c-4d93-9fef-0263957f759a", "8adaba02-b28d-4c75-96b9-c3e9b02a68ce", "8f0ac674-3c08-4b8b-8a90-efa9ce2d4fd3", "94cbb3a7-5877-4002-a86a-b334a70d803c", "a144bd30-a4ed-486e-9e27-062e521b72f5", "a89eee61-617c-4ce4-844d-d4a2c295a41b", "bdc94277-8125-4aff-bbcd-b5e6e1fda167", "c28cf51b-79cf-4b24-9234-8b304f11e6ca", "f4593e9d-babb-43c6-ab3f-465df23afb55", "fbb01830-121d-42ea-8d5d-eb6752eba4a7", "fdd14d16-e871-4b5f-bce3-cd5c31a66b10"], "title": "An Experience Report at Teaching a Group Based Agile Software Development Project Course", "venue": "technical symposium on computer science education", "year": 2015, "id": "c9e61897-5a4e-4309-8a42-225e3168b87e"}
{"authors": ["Dennis F. Kibler", "Pat Langley"], "n_citation": 188, "title": "Machine Learning as an Experimental Science.", "venue": "", "year": 1988, "id": "6565053d-ddb6-4e27-967a-ea8f8021df4b"}
{"abstract": "Information flow security is that aspect of computer security concerned with how confidential information is allowed to flow through a computer system. This is especially subtle when considering processes that are executed concurrently. We consider the notion of Probabilistic Noninterference (PNI) proposed in the literature to ensure secure information flow in concurrent processes. In the setting of a model of probabilistic dataflow, we provide a number of important results towards simplified verification that suggest relevance in the interaction of probabilistic processes outside this particular framework:#R##N##R##N#PNI is shown to be compositional by casting it into a rely-guarantee framework, where the proof yields a more general Inductive Compositionality Principle. We deliver a considerably simplified criterion equivalent to PNI by \"factoring out\" the probabilistic behaviour of the environment. We show that the simpler nonprobabilistic notion of Nondeducibility-on-Strategies proposed in the literature is an instantiation of PNI, allowing us to extend our results to it.", "authors": ["Jan J\u00fcrjens"], "n_citation": 39, "references": ["0ec905cf-2eca-4a6e-b96a-aaed5a1e3789", "1baeeaaf-052d-4fa9-873f-4f6528389e30", "1cf004ef-4374-4127-b39d-2074453941db", "3f18a5c3-849e-4cef-9f6c-0c99d9918253", "4f0ad845-8bd6-4988-835f-7acd79a872b5", "66e23949-4afa-4024-a874-46e4728aeb96", "802c473f-9db8-49ce-93f0-8ca645ecc5d6", "a2e87a7f-f2a7-4219-a470-2f59ac9ffe19", "d0eca5dc-9d59-4584-8777-8b91fd8a069d", "d699f29b-1c7e-446c-bb2b-bffc1c122054", "e03cb036-2728-4f79-a0a1-45dc108f4dd6", "e12b4e09-4b13-49de-9278-6d337939778f", "e9f91548-14c3-423d-9e79-2448a0bb2469"], "title": "Secure Information Flow for Concurrent Processes", "venue": "international conference on concurrency theory", "year": 2000, "id": "2e65f84f-a210-43fc-bcc3-cc026935b689"}
{"authors": ["Chitta Baral", "Jorge Lobo"], "n_citation": 59, "references": ["19f65fe4-ae06-49de-bca8-c4590e86a80d", "1d5cb24f-0a4e-43a1-8754-8548546640c2", "244fb74d-0c8a-4d55-b5f0-dec8dd3f62ea", "33091fae-2103-4875-b572-1874f9d749d3", "3a66ddb7-a3fa-498f-8fdb-2814cec8ec53", "49954c38-aec9-41db-bee8-2b7546a26bba", "515d7bfd-fd7f-47d4-b42c-47269cc460e2", "5463cd33-7c52-43c2-9aaf-cbef43b33127", "5d20f5fa-6a82-4a5d-ae71-6930617f6acb", "6ebb37de-4861-49a1-8eab-e386862c695a", "8a1ce811-7c3b-475b-b525-33ba5a152a8a", "a543db7b-0580-4d11-af55-b0e9a1005c6a", "ba253d8e-149a-4390-9b46-d024017b0243", "d1e6db68-d3cc-404b-9085-84eaf37b730b", "e7d71113-0c36-49fb-8fb4-ed94131ceae5", "fbe97b74-258b-4a88-97e6-0089e64388ed"], "title": "Formal Characterization of Active Databases", "venue": "logic in databases", "year": 1996, "id": "2fa2bfe9-c4ee-4c37-9f20-c1732ce25e36"}
{"abstract": "System identification of physiological systems poses unique challenges, especially when the structure of the system under study is uncertain. Nonparametric techniques can be useful for identifying system structure, but these typically assume stationarity and require large amounts of data. Both of these requirements are often not easily obtained in the study of physiological systems. Ensemble methods for time-varying nonparametric estimation have been developed to address the issue of stationarity, but these require an amount of data that can be prohibitive for many experimental systems. To address this issue, we developed a novel algorithm that uses multiple short data segments. Using simulation studies, we showed that this algorithm produces system estimates with lower variability than previous methods when limited data are present. Furthermore, we showed that the new algorithm generates time-varying system estimates with lower total error than an ensemble method. Thus, this algorithm is well suited for the identification of physiological systems that vary with time or from which only short segments of stationary data can be collected.", "authors": ["Daniel Ludvig", "Eric J. Perreault"], "n_citation": 50, "references": ["2a02f249-67b0-40de-87dc-bf60d4663b4e", "3111f1c5-c8ff-4902-98b5-71f29de33ad1", "391fcd31-dfff-433e-a9c1-92d21348abd3", "59d09249-dc3b-4635-9628-74ef80a7793e", "68703d93-132d-406c-ba7e-8f736eead7bf", "9440d540-2728-4240-90d1-33452c86da2a"], "title": "System Identification of Physiological Systems Using Short Data Segments", "venue": "IEEE Transactions on Biomedical Engineering", "year": 2012, "id": "dbeeb9bd-e96d-40f0-97db-6528ecf6ae52"}
{"abstract": "We review the training problem for feedforward neural networks and discuss various techniques for accelerating and stabilizing the convergence during training. Among other techniques, these include a self-adjusting step gain, bipolar sigmoid activation functions, training on all classes in parallel, adjusting the exponential rates in the sigmoids, bounding the sigmoid derivatives away from zero, training on exemplars to which noise has been added, adjusting the initial weight set to a subdomain of low values of the sum-squared error, and adjusting the momentum coefficient over the iterations. We also examine methods to assure the generalization of the learning, which include the pruning of unimportant weights and adding noise to exemplars for training.", "authors": ["Carl G. Looney"], "n_citation": 35, "references": ["3fff50e3-6a11-415b-8c8d-6f2c651f658d", "79fd8d7a-d3c0-4ebf-b775-70432690a66d", "81192b74-501a-4814-8c61-7fb9b2cd6403", "8d7bb750-adbb-4a71-813f-09fdfab8f7d0", "b6e1e408-6f1a-421f-90e3-5f6e37da43f4"], "title": "Stabilization and speedup of convergence in training feedforward neural networks", "venue": "Neurocomputing", "year": 1996, "id": "96d66237-475c-4253-9583-faa235ab4de9"}
{"abstract": "Modern object-oriented programming languages such as C++ provide convenient abstractions and data encapsulation mechanisms for software developers. However, these features also complicate testing and static analysis of programs that utilize object-oriented programming concepts. In particular, the C++ language exhibits features such as multiple inheritance, static and dynamic typecasting that make static analyzers for C++ quite hard to implement. In this paper, we present an approach where static analysis is performed by lowering the original C++ program into a semantically equivalent C program. However, unlike existing translation mechanisms that utilize complex pointer arithmetic operations, virtual-base offsets, virtual-function pointer tables, and calls to run-time libraries to model C++ features, our translation is targeted towards making static program analyzers for C++ easier to write and provide more precise results. We have implemented our ideas in a framework for C++ called CILpp that is analogous to the popular C Intermediate Language (CIL) framework. We evaluate the effectiveness of our translation in a bug finding tool that uses abstract interpretation and model checking. The bug finding tool uncovered several previously unknown bugs in C++ open source projects.", "authors": ["Jing Yang", "Gogul Balakrishnan", "Naoto Maeda", "Franjo Ivancic", "Aarti Gupta", "Nishant Sinha", "Sriram Sankaranarayanan", "Naveen Sharma"], "n_citation": 9, "references": ["048ace17-a9d7-4000-9985-8c2d2448a0fe", "0793a9ac-7c82-4b3a-a0c1-b213612f141d", "0cf1f320-f6e1-4a32-874b-1beb7654cccc", "0f7cde81-008a-4068-afbe-90daf0292fe0", "1c1934f9-6e31-45a6-8a5e-b6d6aa9b0484", "23db07c4-8731-4518-8fd1-db2b126c3b08", "2660744d-9c55-4eb6-af3c-1d9ee904a447", "27f1e1a2-045c-4944-a71c-8bbac426fd6e", "2de19667-d52f-4bb2-ac52-4fb5565f37cf", "3e905beb-afd3-457d-a865-bf0755b59f72", "4269286a-99bb-4be7-b4da-32d346573a47", "5ab985c5-796f-420d-a52e-5a994a8de520", "6011ad88-0072-4ca5-b74f-256d832a6f7d", "623f6570-ac32-4b55-89cd-e8d5d90db186", "6aec0cf3-52c8-4b68-bc14-0e0c89e7416f", "714bfb60-ccc8-4d41-b79b-0b5c7fe559d5", "79b15730-feb1-4d01-9d19-98af0a324e32", "7bb71afa-91b8-46e7-9008-da84e0427b93", "7efae1e1-89a0-4714-9618-efd2589c7de3", "82975d94-b8c8-4720-8428-95019e0e5669", "9464be88-80de-463e-af0c-83562b7744ff", "9849d9c4-a97f-452f-882c-42a8c6cab0b5", "9a4984f9-27d4-47eb-8bc8-0469bf540f94", "9ae88951-265b-4bdb-bf8a-54e96a03ef03", "aeb3a7ed-91b0-4bd8-9ca7-6dd1a1eb1a03", "c00bbb49-6e29-4103-8883-55acd23c248b", "c036912f-ac89-48b8-85b4-ceff1d08e32a", "c5b4fa1d-7980-4cdb-9eb0-56b87a782924", "cc1b7d39-2fff-4272-b989-b9173da97f17", "f4270e7e-3819-424b-9ae1-93539fd8901e", "fb2b6126-a044-4d01-8865-c1ef75e1ab3f", "fcf993ba-c8ad-4256-acf1-1ea7e5ba7f00"], "title": "Object model construction for inheritance in c++ and its applications to program analysis", "venue": "compiler construction", "year": 2012, "id": "fa51d61f-3ce4-4c80-96cc-823687c98f8b"}
{"authors": ["Kwan-Woo Lee", "Kyo Chul Kang", "Eunman Koh", "Wonsuk Chae", "Bokyoung Kim", "Byoung Wook Choi"], "n_citation": 50, "references": ["35f24329-18e0-46a7-9bfc-3fc878d4d1ce", "97fe8ce0-cc66-4d95-a0e6-1a83f825a2d4", "b1a2a890-c9f3-4184-98a2-650971011032", "dc98562f-e69f-4522-9123-8dbab20ffb33", "dde8d7b9-5f2b-44b4-977a-9755a6484ac7"], "title": "Domain-Oriented Engineering of Elevator Control Software", "venue": "software product lines", "year": 2000, "id": "2d383bad-9ccf-4c90-b2d5-c8699efd0d02"}
{"abstract": "We investigate a class of parametric timed automata, called lower bound/upper bound (L/U) automata, where each parameter occurs in the timing constraints either as a lower bound or as an upper bound. For such automata, we show that basic decision problems, such as emptiness, finiteness and universality of the set of parameter valuations for which there is a corresponding infinite accepting run of the automaton, is Pspace-complete. We extend these results by allowing the specification of constraints on parameters as a linear system. We show that the considered decision problems are still Pspace-complete, if the lower bound parameters are not compared with the upper bound parameters in the linear system, and are undecidable in general. Finally, we consider a parametric extension of $\\mathsf{MITL}$ 0,?, and prove that the related satisfiability and model checking (w.r.t. L/U automata) problems are Pspace-complete.", "authors": ["Laura Bozzelli", "Salvatore La Torre"], "n_citation": 50, "references": ["0598fdbf-cdb6-4651-83d3-2c9730fb3261", "2383e70b-0513-4e40-9719-a4c3eb46589c", "250da18f-d636-4845-aa49-e290d7deddf0", "615d943c-9eb4-4478-9cb0-cfdb4077824c", "74e3fd8b-f955-4fde-aad8-0a705f05e27e", "78b797a4-08bf-47b9-891e-f289eec0d017", "88e266bb-8331-4722-80ad-b4b5db1a09e1", "a7127c28-8b52-4663-a96d-2a75e42a1a67", "c9721e32-74ba-4489-b787-8049210a410d", "eb35749e-7487-47cd-a961-68819b084d89", "f55caddb-9186-49a6-9098-0ea4bc7600c3"], "title": "Decision problems for lower/upper bound parametric timed automata", "venue": "formal methods", "year": 2009, "id": "378cb17b-15da-4608-a3a4-adbcf75f548f"}
{"abstract": "Work on quantum cryptography was started by S. J. Wiesner in a paper written in about 1970, but remained unpublished until 1983 [1]. Recently, there have been lots of renewed activities in the subject. The most wellknown application of quantum cryptography is the socalled quantum key distribution (QKD) [2\u20134], which is useful for making communications between two users totally unintelligible to an eavesdropper. QKD takes advantage of the uncertainty principle of quantum mechanics: Measuring a quantum system in general disturbs it. Therefore, eavesdropping on a quantum communication channel will generally leave unavoidable disturbance in the transmitted signal which can be detected by the legitimate users. Besides QKD, other quantum cryptographic protocols [5] have also been proposed. In particular, it is generally believed [4] that quantum mechanics can protect private information while it is being used for public decision. Suppose Alice has a secret x and Bob a secret y. In a \u201ctwo-party secure computation\u201d (TPSC), Alice and Bob compute a prescribed function f(x,y) in such a way that nothing about each party\u2019s input is disclosed to the other, except for what follows logically from one\u2019s private input and the function\u2019s output. An example of the TPSC is the millionaires\u2019 problem: Two persons would like to know who is richer, but neither wishes the other to know the exact amount of money he/she has. In classical cryptography, TPSC can be achieved either through trusted intermediaries or by invoking some unproven computational assumptions such as the hardness of factoring large integers. The great expectation is that quantum cryptography can get rid of those requirements and achieve the same goal using the laws of physics alone. At the heart of such optimism has been the widespread belief that unconditionally secure quantum bit commitment (QBC) schemes exist [6]. Here we put such optimism into very serious doubt by showing", "authors": ["Hoi-Kwong Lo", "H. F. Chau"], "n_citation": 491, "references": ["39602e6c-50b8-4d3f-a27b-059abad6af14", "c5bb0167-a987-45c2-9517-741fed6f6abe", "edf780f7-3122-427e-8e3d-7c609e6b26aa"], "title": "Is Quantum Bit Commitment Really Possible", "venue": "Physical Review Letters", "year": 1997, "id": "7bea8f83-9c23-4177-8b2f-2a5100307e79"}
{"abstract": "The computational complexity of the provability problem in systems of modal propositional logic is investigated. Every problem computable in polynomial space is $\\log $ space reducible to the provability problem in any modal system between K and $S4$. In particular, the provability problem in K, T, and $S4$ are $\\log $ space complete in polynomial space. The nonprovability problem in $S5$ is $\\log $ space complete in nondeterministic polynomial time.", "authors": ["Richard E. Ladner"], "n_citation": 619, "title": "The Computational Complexity of Provability in Systems of Modal Propositional Logic", "venue": "SIAM Journal on Computing", "year": 1977, "id": "d52e6118-37ec-4bd3-a3e8-1c3bacb20a3d"}
{"abstract": "This paper describes the ASP Execution Environment (EE), a prototype general-purpose active network execution environment that initiates and controls the execution of Java-based active applications. Features of the ASP EE include support for persistent active applications, fine-grained network I/O control, security, resource protection and timing services.", "authors": ["Robert Braden", "Bob Lindell", "Steven Berson", "Theodore Faber"], "n_citation": 50, "references": ["30285e8c-be82-4115-9e18-200c7b89a98e", "799bff5b-5eb6-4183-9264-2d243576c40f", "ba492bb1-9774-48ef-9d75-124c7956765b", "c8fb41aa-d974-4e42-bbfa-65e429dfdc33"], "title": "The ASP EE: an active network execution environment", "venue": "", "year": 2002, "id": "b3602b71-71d9-4274-bf7f-61a9590b3913"}
{"abstract": "To form a deep understanding of the present; we need to ?nd and engage history. We present an informal history capture and retrieval mechanism for collaborative, early-stage information design. This history system is implemented in the context of the Designers' Outpost, a wall-scale, tangible interface for collaborative web site design. The interface elements in this history system are designed to be ?uid and comfortable for early-phase design. As demonstrated by an informal lab study with six professional designers, this history system enhances the design process itself, and provides new opportunities for reasoning about the design of complex artifacts", "authors": ["Scott R. Klemmer", "Michael Thomsen", "Ethan Phelps-Goodman", "Robert Lee", "James A. Landay"], "n_citation": 189, "references": ["1d6d7e57-af95-4327-a424-320f97572255", "2a04b07f-de96-481b-82f2-a362eb40cb09", "52b78834-b552-4584-bad4-f5b9f750af8b", "673e3f5c-4ff4-4ee7-a3ab-e3e524dbcccf", "6b4e5f5c-5824-47da-aacf-6e6e1955711b", "8e708724-643a-4f2a-893a-f6b6187616c2", "a8c937fa-95cc-4df8-b691-a5ae66787ebb", "ba52eb86-0030-42e2-88f4-877459e32372", "c6de40eb-1a70-43b2-8cd3-d61b5189682b", "c71c1ebe-b786-4dd3-8fec-6476ef560330", "cab643b5-dc91-4ecc-8d36-2ca126877730", "d116e88c-f914-411e-afa3-d489f1367308", "d1852dab-8b84-4b25-8498-00983fcb357c", "f1aa9cc3-70c2-443b-b7bc-f03f5c60d3a0", "f22f33d6-19ed-4d6b-ac5f-4a573a472829", "fe757269-7cd6-468c-a054-ac50d26cfd59"], "title": "Where do web sites come from?: capturing and interacting with design history", "venue": "human factors in computing systems", "year": 2002, "id": "06e24160-2c76-4cf8-ab64-6efa19b2f465"}
{"abstract": "If we're going to have a column about evidence in software engineering, we're going to need to talk about inspections sooner or later. Inspections are among the most mature and perhaps best-studied practices in software engineering. In short, software inspection was one of those rare software engineering innovations that had the ability to effect real process change.", "authors": ["Forrest Shull", "Carolyn B. Seaman"], "n_citation": 8, "references": ["029b77ff-ae7c-4078-b22d-9bcf9dc455b4", "9d1004b7-3797-45de-82d9-45e4ed492c48", "9e6e12a6-5b5c-481a-9e14-ffc9daecd2a3", "d6ba028f-52e5-46e1-8f41-e640cea1136c"], "title": "Inspecting the History of Inspections: An Example of Evidence-Based Technology Diffusion", "venue": "IEEE Software", "year": 2008, "id": "14003db5-0064-476c-9981-feb483972239"}
{"abstract": "Abstract : In TREC-9, we participated in the English-Chinese Cross Language, 10GB Web data ad-hoc retrieval, as well as the Question-Answering tracks, all using automatic procedures. All these tracks were new for us. For Cross Language track, we made use of two techniques of query translation: MT software and bilingual wordlist lookup with disambiguation. The retrieval lists from them were then combined as our submitted results. One submitted run used wordlist translation only. All cross language runs make use of the previous TREC Chinese collection for enrichment. One MT run also employs pre-translation query expansion using TREC English collections. We also submitted a monolingual run without collection enrichment. Evaluation shows that English-Chinese cross-lingual retrieval using only wordlist query translation can achieve about 70-75% of monolingual average precision, and combination with MT query translation further brings this effectiveness to 80-85% of monolingual. Results are well above median.", "authors": ["Kui-Lam Kwok", "Laszlo Grunfeld", "Norbert Dinstl", "M. Chan"], "n_citation": 54, "references": ["037ee38c-dcbd-4ceb-87ad-7bd687cbb296", "2e04f614-7c90-4d5b-ad5f-ac32e30c1ce9", "fce0c741-8495-4f3e-bb07-6ee37132bb27"], "title": "TREC-9 Cross Language, Web and Question-Answering Track Experiments Using PIRCS", "venue": "text retrieval conference", "year": 2000, "id": "b8b6eeb8-2f9a-49b8-9bc9-abea4c12e871"}
{"abstract": "We present a new approach to clustering and visualization of the DNA microarray gene expression data. We utilize the self-organizing map (SOM) framework for handling (dis)similarities between genes in terms of their expression characteristics. We rely on appropriately defined distances between ranked genes-attributes, also capable of handling missing values. As a case study, we consider breast cancer data and the gene ESR1, whose expression alterations, appearing for many of the tumor subtypes, have been already observed to be correlated with some other significant genes. Preliminary results positively verify applicability of our approach, although further development is definitely needed. They suggest that it may be very effective when used by the domain experts. The algorithmic toolkit is enriched with GUI enabling the users to interactively support the SOM optimization process. Its effectiveness is achieved by drag&drop techniques allowing for the cluster modification according to the expert knowledge or intuition.", "authors": ["Alicja Gru\u017ad\u017a", "Aleksandra Ihnatowicz", "Dominik \u015al\u0119zak"], "n_citation": 15, "references": ["044074e8-31cb-44b6-ab74-fa21c93dd14b", "2d703863-05f6-4af5-842c-83fd164e934b", "505e693e-61f4-474b-87e4-4d2042badace", "a63a2ce2-e06d-43d0-854f-8e9b6cd77168", "abad0cf5-6b84-4c40-91a2-f6ca3ad7fbc1", "c441f0cd-8b62-487b-a09b-7e95467f8045", "fc0ea56c-91b9-467a-80e5-2bff4f29dee2"], "title": "Interactive Gene Clustering--A Case Study of Breast Cancer Microarray Data", "venue": "Information Systems Frontiers", "year": 2006, "id": "bda13293-c1f4-4575-a123-a726e418d807"}
{"authors": ["Zahir Tari", "Omran A. Bukhres", "John Stokes", "Slimane Hammoudi"], "n_citation": 50, "references": ["151b6976-c3e6-4a56-9ce8-48610dd4857e", "42f84c77-f1b0-48f3-ab11-07ab7f12b557", "4d0b2c80-d6aa-4119-93b2-cbf18c8a1738", "50cc5067-6931-4d1c-b404-a4e6dba900c9", "6c34ec7d-5895-4215-83d6-f147ed4da28b", "6cecb596-0a48-4a55-a55f-efa5a38a3630", "8136237c-5cbd-4cfd-a50a-51ccfa8ce067", "a34ec12a-abe0-4b0e-8961-c9476b0a5e56", "c58b8f2f-fd8d-4ef9-b696-0b58e33fcdaf", "f2569981-d9c8-421d-81b9-4c7ade6eee76"], "title": "The Reengineering of Relational Databases based on Key and Data Correlations", "venue": "discovery science", "year": 1998, "id": "5b10f24d-6136-49ca-aa70-e47a216e22d8"}
{"abstract": "This paper describes TEATRIX; a learning environment designed to help children, and their teachers, in the whole process of collaborative story creation. TEATRIX provides an environment where both drama and story creation are merged into one medium providing a form of collaborative makebelieve for children. While creating a story TEATRIX allows the children to interact with each other in a distributed 3D environment, by means of their chosen characters. Each character is an intelligent software agent living in the world of the story: the theatre stage. Characters that are not controlled by children act autonomously according to the actions and goals set up by their role in the story. The roles in the story are based on the work by Vladimir Propp on folk tales and can be chosen from a set that includes a villain, a hero, a princess, a helper, etc. Children not only set up the scene for the development of the play and its characters, but also do the whole performance. TEATRIX is being evaluated in a Computer Integrated Classroom (CiC) environment which is part of an EU funded project (the NIMIS project).", "authors": ["Rui Prada", "Isabel Machado", "Ana Paiva"], "n_citation": 77, "references": ["0f0960d7-72b3-4884-a2fb-301d4cb73f1c", "2d2b2d03-a913-4243-bc5f-7763632ca272", "3273c705-a15e-4540-93d8-fd7f79cc7c20", "3de42d14-5dad-42e8-86bb-aafbcf4e3dc3", "63f05a66-c4c6-4158-80ca-481f13227f0f"], "title": "TEATRIX: Virtual Environment for Story Creation", "venue": "intelligent tutoring systems", "year": 2000, "id": "ef65e418-c4a2-49c2-b7c3-7f90ff3dda36"}
{"abstract": "Sound can help us explore and analyze complex data sets in scientific computing. The authors describe a digital instrument for additive sound synthesis (Diass) and a program to visualize sounds in a virtual reality environment (M4Cave). Both are part of a comprehensive music composition environment that includes additional software for computer-assisted composition and automatic music notation.", "authors": ["Hans G. Kaper", "Elizabeth Wiebel", "Sever Tipei"], "n_citation": 31, "references": ["13d6718d-3337-4f84-844b-cd573284feda", "4dd34b19-c5a2-4675-8bab-9df9b4c0cf8a", "abdf4c17-0808-42b6-b1f6-9c8d59ee4a02", "f06914f9-89d4-4745-b5a5-d9e30e95263b"], "title": "Data sonification and sound visualization", "venue": "Computing in Science and Engineering", "year": 1999, "id": "4e1d2664-fa91-46af-ba79-7fdf6f7f0aba"}
{"abstract": "Software Defined Radio (SDR) may provide flexible, upgradeable and longer lifetime radio equipment for the military and for civilian wireless communications infrastructure. SDR may also provide more flexible and possibly cheaper multi-standard-terminals for end users. It is also important as a convenient base technology for the future context-sensitive, adaptive and learning radio units referred to as cognitive radios. SDR also poses many challenges, however, some of them causing SDR to evolve slower than otherwise anticipated. Transceiver development challenges include size, weight and power issues such as the required computing capacity, but also SW architectural challenges such as waveform application portability. SDR has demanding implications for regulators, security organizations and business developers.", "authors": ["Tore Ulversoy"], "n_citation": 59, "references": ["097d282b-beed-47c1-9e6f-07255fee1a3a", "0a05d5f9-b90d-4add-83ac-fa80cdba43c0", "0a3810b3-82d2-4f36-8d1b-20ea03b4d842", "14dd092f-656e-40ce-a9d1-8332704f7e03", "338430e4-1ddb-4629-a938-8690913c98c1", "3c2cfa9a-2843-482f-9157-c9ae99769763", "4023c439-5224-4927-984b-2c170e966aa3", "49853b10-b217-4d19-9a9b-61244ce873ba", "50f5d1c3-7889-439b-9d70-16d930a60cb9", "574341f6-b768-47ff-8752-30f06244c5be", "601a4614-5244-4188-9a78-840a3b83ecb6", "65736646-be9c-46e3-beb8-cc894de4799b", "683b051a-d769-475f-a767-a3a7b7f00efa", "79826109-0947-47c6-aaf3-faacfb8573cd", "80c8dc97-8845-4d17-8bb1-d481a57edb3a", "8a6d8e0a-3d48-4a60-aa84-fdfb435e622b", "9e4eb25f-bdb9-4881-80a7-db1c45a05872", "a2cd0e23-f184-441d-b90e-d4492a9ef508", "a3971eb0-d8bd-441f-8c4d-6278ebd00a69", "b43a0818-fda8-4ff3-be76-e35d286fb843", "b43f1560-718a-409d-b63f-9637a57242b7", "b649a499-f44a-46ec-af91-0082adb5f27e", "baa9f82c-7a29-49ce-a44b-4e09d94df936", "c59ee53f-1751-4173-bc7d-01866e716e99", "c6617559-ff8e-4066-9a64-4dc09c84c357", "d1ba534e-3f80-4366-bb83-be16006f9e18", "db2a4d8a-ae13-4f21-968c-ab90a6262215", "ee4dabe1-4f07-42a0-b303-3df805bc3698", "fa271b22-230e-406d-a4d1-60ae0f23ab5d"], "title": "Software Defined Radio: Challenges and Opportunities", "venue": "IEEE Communications Surveys and Tutorials", "year": 2010, "id": "3d634674-c5ae-433f-a452-ee69d2a1de69"}
{"abstract": "In the setting of session behaviours, we study an extension of the concept of compliance when a disciplined form of backtracking is present. After adding checkpoints to the syntax of session behaviours, we formalise the operational semantics via a LTS, and define a natural notion of checkpoint compliance. We then obtain a co-inductive characterisation of such compliance relation, and an axiomatic presentation that is proved to be sound and complete. As a byproduct we get a decision procedure for the new compliance, being the axiomatic system algorithmic. 1 Introduction. In human as well as automatic negotiations, an interesting feature is the ability of rolling back to some previous point, undoing previous choices and possibly trying a different path. Rollbacks are familiar to the users of web browsers, and so are also the troubles that these might cause during \u201cundisciplined\u201d interactions. Clicking the \u201cback\u201d button, or going to some previous point in the chronology when we are in the middle of a transaction, say the booking of a flight, can be as smart as dangerous. In any case it is surely a behaviour that service programmers want to discipline. Also the converse has to be treated with care: a server discovering that a service b ecomes available after having started a conversation could take advantage from some kind of rolling backs. However, such a server would be quite unfair if the rollbacks were completely hidden from the client. Adding rollbacks to interaction protocols requires a sophisticated concept of client/server compliance. In this paper we investigate protocols admitting a simple, though non trivial form of reversibility in the framework of the theory of contracts introduced in [4] and developed in a series of papers, e.g. [5]. We focus here on the scenario of client/server architectures, where services stored in a repository are queried by clients to establish two-sided communications, and the central concept is that of compliance. More precisely, we consider the formalism of session behaviours as introduced in [2, 1, 3], but without delegation. This is a formalism interpreting the sessio n types, introduced by Honda et al. in [7], into a subset of CCS without \u03c4. We extend the session behaviours syntax by means of markers that we call checkpoints; these are intended as pointers to the last place where eithe r the client or the server can roll back at any time. We investigate which constraints must be imposed to obtain a safe notion of client/server interaction in the new scenario, by defining a model in the form of a LTS, and by characterising the resulting concept of compliance both coinductively and axiomatically. Since the axiomatic system is algorithmic that is decidable, the compliance of behaviours with checkpoints is decidable. Before entering into the formal development of session behaviours with checkpoints, we illustrate the basic concepts by discussing a few examples. Suppose that the client is a customer willing to arrange \u2217 This work was partially supported by EU Collaborative project ASCENS 257414, ICT COST Action IC1201 BETTY,", "authors": ["Franco Barbanera", "Mariangiola Dezani-Ciancaglini", "Ugo de\u2019Liguoro"], "n_citation": 11, "references": ["3023929a-c93e-49c5-b03f-7fb0414d94df", "32b01d2c-92ea-4162-aeaa-08ea1c377f22", "46394dff-ca9a-4f80-87a1-3b5cacb891f7", "7fef6009-1079-4382-8cbf-011f6336685c", "82a5f69c-d7b0-4827-a1c2-f9c199a2f484", "947b7da7-23da-4fd2-821a-e2de424cb559", "993f7f4a-5dbd-47c4-8797-98eed583a7c4", "9c8603c8-aef3-4d77-b4d6-10f2baf586c4", "b9601ea4-3d24-4f67-a0e4-0ae64ad6f662", "c072994e-dc16-43bd-b73b-4ca60a551253"], "title": "Compliance for reversible client/server interactions", "venue": "Electronic Proceedings in Theoretical Computer Science", "year": 2014, "id": "79159077-967b-479b-a407-55a5133da4f9"}
{"authors": ["Lo\u00efc Prylli", "Bernard Tourancheau"], "n_citation": 41, "references": ["0a4d68f2-69b5-4525-90b5-b405d05bf2e4", "34e9fe9c-f9bd-4f45-82f2-1a54ad78f96c", "486d3e5e-cb71-447e-bc1d-83897f401d16", "52d470dc-7193-4650-a1bc-7ab7eee6ebf3", "57935abf-5920-4da6-8b81-e124bba352dc", "69f93317-6fd6-41f1-b621-0ce2d8bcc767", "a5e8bf28-7d46-49fa-98f0-c3d95b653607", "c5922a45-0785-4b13-b26d-8a974ae2f8bf", "dfae77b7-78b8-49cf-a5fa-e48cee278341"], "title": "Efficient Block Cyclic Data Redistribution", "venue": "european conference on parallel processing", "year": 1996, "id": "c038d073-3d63-4266-9e51-66a2d884c61b"}
{"abstract": "Scalable overlay networks such as Chord, CAN, Pastry, and Tapestry have recently emerged as flexible infrastructure for building large peer-to-peer systems. In practice, such systems have two disadvantages: They provide no control over where data is stored and no guarantee that routing paths remain within an administrative domain whenever possible. SkipNet is a scalable overlay network that provides controlled data placement and guaranteed routing locality by organizing data primarily by string names. SkipNet allows for both fine-grained and coarse-grained control over data placement: Content can be placed either on a pre-determined node or distributed uniformly across the nodes of a hierarchical naming sub-tree. An additional useful consequence of SkipNet's locality properties is that partition failures, in which an entire organization disconnects from the rest of the system, can result in two disjoint, but well-connected overlay networks.", "authors": ["Nicholas J. A. Harvey", "Michael B. Jones", "Stefan Saroiu", "Marvin M. Theimer", "Alec Wolman"], "n_citation": 827, "references": ["0d398008-1e58-4984-931e-a813703d35e9", "0dbba6d8-e395-4cc1-8139-d1b4fd7673d4", "107c6c64-e50b-476b-ae4e-196f77328ae3", "309f5d34-0bb0-4ffc-aa87-fdffb67dddf6", "3f318b5f-d239-4838-a68a-48d6d57335b7", "436b5fcd-6488-4a4c-b41a-85130718b39a", "4632bf44-a22d-4a18-ab52-f7e223dba1dd", "48740ddd-afd1-4331-8af7-224ef5d19ed7", "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4", "4ef0e696-ed0d-4801-a5f7-ae03e59f4d13", "4f7ab450-cfc2-4f73-a964-273ca6778da6", "51af4708-b81c-4362-b4ee-7bdf7ace609f", "5de99dee-6647-4ebf-b20b-fe970cfd062b", "5e354aca-2d93-43f7-8e80-6bc4eb96e7d9", "6b5a21d8-f5b5-4a78-b394-df792e4a8e3f", "6eff83a4-db80-40ea-8c9f-8bda5f506c29", "79e5de56-5bcf-4df0-a6a4-ff07f8afbaf9", "8b2d5c7a-8c22-46eb-b9ae-6a100848145c", "8f3e6124-b348-4890-9e89-603bbdc30a34", "96d371ff-5856-4864-9f29-a254b2d7b8a1", "99c18d10-a200-4e15-b8e6-669f6f7881ed", "9c0f911c-c9ca-483b-9b35-06ae4ce7c121", "b7d7ec53-f079-4bd7-a795-8b6fe77f2db6", "beab2d0f-7b44-484f-859a-f2aaa50c2ccc", "c0ea675b-2479-48ae-817e-3ecedd175ecf", "c8771a57-de9c-44b7-966c-1ff156d3091f", "caad6ed5-4878-4ac3-b820-459f8aba128f", "cbc01e36-33c2-4709-a00d-22e6d0727560", "cdbddd8c-cf27-4217-846d-7456efa609cf", "d057a535-fa3e-4636-b4c8-6a291f96eda9", "d06f8723-1b89-4684-99c9-c1045ddfb85c", "d3889ced-b97c-4037-a279-88c33451987b", "e1263ada-afda-498c-a37d-9b545293118a", "ec7d1720-3285-4729-b819-b4c58a826ec8", "f14df1ed-e3e9-4348-9040-fc06e3411b95", "fedae089-5dc7-41b8-8454-579df5a68846"], "title": "SkipNet: a scalable overlay network with practical locality properties", "venue": "", "year": 2003, "id": "198673ec-2687-42ba-bd7b-4009117d4204"}
{"abstract": "Traditional problem determination techniques rely on static dependency models that are difficult to generate accurately in today's large, distributed, and dynamic application environments such as e-commerce systems. We present a dynamic analysis methodology that automates problem determination in these environments by 1) coarse-grained tagging of numerous real client requests as they travel through the system and 2) using data mining techniques to correlate the believed failures and successes of these requests to determine which components are most likely to be at fault. To validate our methodology, we have implemented Pinpoint, a framework for root cause analysis on the J2EE platform that requires no knowledge of the application components. Pinpoint consists of three parts: a communications layer that traces client requests, a failure detector that uses traffic-sniffing and middleware instrumentation, and a data analysis engine. We evaluate Pinpoint by injecting faults into various application components and show that Pinpoint identifies the faulty components with high accuracy and produces few false-positives.", "authors": ["Mike Y. Chen", "Emre Kiciman", "Eugene Fratkin", "Armando Fox", "Eric A. Brewer"], "n_citation": 839, "references": ["1017d9d4-9a4c-423d-ad40-6d9bebbd6b31", "14872a52-6da7-456b-bb58-7104f8dab9f6", "86cb005a-ceb6-4a59-b933-5489db6a6f13", "96ff09f7-e819-4de9-aaf8-9eac2f5fa751", "9c352b5a-776e-4ac8-84b4-2404714342fc", "b0c1f4cf-b30b-4a55-ad39-76bfbbe11223", "dbb44dda-567f-4f6f-8dab-274c2be81ba9"], "title": "Pinpoint: problem determination in large, dynamic Internet services", "venue": "dependable systems and networks", "year": 2002, "id": "9ff89a6a-32dd-4a4f-9bb6-3753ae4843c8"}
{"authors": ["Yogesh Karunakar", "Alhad Kuwadekar"], "n_citation": 1, "references": ["6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "918baaeb-5ac5-4639-bf60-39bc0ee3ee7c", "a19bb331-034b-40c1-b1ca-35b467a1ec89"], "title": "An Unparagoned Application for Red Blood Cell Counting using Marker Controlled Watershed Algorithm for Android Mobile", "venue": "next generation mobile applications, services and technologies", "year": 2011, "id": "9abe10be-c528-4bef-885f-4c69041b159b"}
{"authors": ["Burak Turhan", "Ayse Basar Bener"], "n_citation": 31, "references": ["147d66ed-71a1-4744-b566-c224b484771b", "2440023d-5422-4bb6-8f2c-bd4ba3e23379", "380a079c-69a1-4390-8a11-1c193fe77d14", "53137844-fc77-43b0-a558-95665b65ffed", "57af1f08-da6a-466f-97a2-99e98a992768", "5be480f2-f2d3-4a62-b819-ad13259aa4fe", "62549bc2-e0b3-46e8-8d32-390dded105d5", "685a962b-5722-4df2-b033-8b460f86ec9e", "6c6d9618-4342-4d2c-8c6c-94960badd46e", "6cf0a34c-f6d0-4a54-9a6a-7c14969ac66e", "75ec0b95-65c5-48c9-ae1b-a44c6c378bec", "78d6540c-2f57-472f-9ad7-3b315ec7d08a", "879097eb-a012-4def-9a28-17bc79b6252e", "8b0e25ad-0fce-4658-8407-5dcf7ea742ca", "8d645747-5f86-429b-a457-073473a2bd9f", "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c", "97badbeb-818b-4d7b-863f-3d0c6c4870c7", "a4671b8d-c8a6-4cc2-942c-be8817a1305e", "bda5a484-3538-4943-8284-d5db917f37f4", "da236a5b-d7a4-423c-a344-a5afe9b444a0", "eedb44a4-f6b8-48bf-81d1-72dc3a6a96ca", "fde1a431-09f2-4ae9-9816-f82a6228d057"], "title": "SOFTWARE DEFECT PREDICTION: HEURISTICS FOR WEIGHTED NA\u00cfVE BAYES", "venue": "international conference on software and data technologies", "year": 2007, "id": "aa793d26-18bd-498d-95d6-f61fbba5cf1a"}
{"authors": ["Philippe Langlais", "Marie Loranger", "Guy Lapalme"], "n_citation": 50, "references": ["0bc3f0aa-5a3e-46a2-bca0-7bdffe879780", "45ea59ac-593d-4b14-b63e-f85537cfe17c", "5443ee2f-a083-4829-bfd3-b92e50b6d78e", "f666713b-0a93-4278-acbc-b10e583413fd"], "title": "Translators at work with TRANSTYPE: Resource and Evaluation.", "venue": "language resources and evaluation", "year": 2002, "id": "5a5a0da4-a448-4124-9eb2-04fa5c01c189"}
{"abstract": "Let H be a fixed graph with h vertices, let G be a graph on n vertices and suppose that at least /spl epsi/n/sup 2/ edges have to be deleted from it to make it H-free. It is known that in this case G contains at least f (/spl epsi/, H)n/sup h/ copies of H. We show that the largest possible function f (/spl epsi/, H) is polynomial in /spl epsi/ if and only if H is bipartite. This implies that there is a one-sided error property tester for checking H-freeness, whose query complexity is polynomial in 1//spl epsi/, if and only if H is bipartite.", "authors": ["Noga Alon"], "n_citation": 50, "references": ["0ddbeed7-f2e3-41ac-a429-54a44be76f53", "3a28e7b7-4e28-42dc-b5b9-eeb8918cf762", "3ea42300-0191-4c77-92dc-eb9626b43e82", "46e94089-1ac0-4381-ab72-aa40ba144e74", "6e94e20b-ce8f-4724-a075-bdcd880e138a", "8d7e8a7a-7713-42fc-867a-5773904cc101", "bbf275f6-fc56-4cbd-96a7-99a0ae3bba51", "cb52d62e-30c7-4d2e-87de-2fbc69fa78e8", "d3f4b3d8-918e-4c50-8ed8-db1efa099873"], "title": "Testing subgraphs in large graphs", "venue": "international conference on cluster computing", "year": 2001, "id": "30b8b491-c235-4914-9f5a-95093cae80d2"}
{"abstract": "Even such simple tasks as placing a box on a shelf are difficult to animate, because the animator must carefully position the character to satisfy geometric and balance constraints while creating motion to perform the task with a natural-looking style. In this paper, we explore an approach for animating characters manipulating objects that combines the power of path planning with the domain knowledge inherent in data-driven, constraint-based inverse kinematics. A path planner is used to find a motion for the object such that the corresponding poses of the character satisfy geometric, kinematic, and posture constraints. The inverse kinematics computation of the character's pose resolves redundancy by biasing the solution toward natural-looking poses extracted from a database of captured motions. Having this database greatly helps to increase the quality of the output motion. The computed path is converted to a motion trajectory using a model of the velocity profile. We demonstrate the effectiveness of the algorithm by generating animations across a wide range of scenarios that cover variations in the geometric, kinematic, and dynamic models of the character, the manipulated object, and obstacles in the scene.", "authors": ["Katsu Yamane", "James J. Kuffner", "Jessica K. Hodgins"], "n_citation": 219, "references": ["036be3f9-d3a4-4436-a5b4-14dec87f9d1a", "0db58b2b-7303-4c2c-af80-f3aac55a6e4a", "107f2d1b-7aa0-41c6-8361-520b1e5bc3ea", "11b5966d-eb51-4383-ae31-c84a99bf3bb5", "1cb952b3-a4b8-47f4-9951-64f53080b7ae", "3726c761-2078-41af-a573-73c0928d51c1", "397647e1-9677-4918-ace0-08b7e4d7d2d6", "3cd872b2-d996-401a-a807-90b75b7ccee5", "3e028a78-0463-4fc7-84c3-88cf6cae1c06", "4773f1f0-89a2-4cd1-849a-6f2925f0cccb", "4bafeb31-1e9a-45ca-b214-81bcef5ee70a", "5437c0a0-8f20-49c3-86e5-9d860f3e4f04", "57a01b45-ef61-49ec-85ab-62d7b490b143", "60536064-e7f8-46d3-9e6b-bcc30f0a5a8d", "6256c8ec-90e6-4f52-87a5-157fb299d602", "6f77b214-9d71-41c8-b51a-3dbff153ad5a", "ae27737c-91dc-4bec-a858-3a7bb3aeae20", "af30bb1e-ce40-496c-8d3a-c2a299bd388e", "b20e73e4-c7c9-4ecd-9773-6f0d8f7bbdb1", "bbc80ce2-554b-4e12-8a39-7ad1e57c3c6b", "c3577ff4-c18b-4bbe-be11-9701870e2571", "c377ad6b-3a6b-4d10-aae0-4379dadf365c", "e6baa5d5-84c4-4dd7-b0e8-bd89e7ffd04d", "ef5a5bc2-b457-4f44-a65e-ef8e3980c35f", "f4c1f9b5-9f15-4f37-a333-3e27c91d1c91", "f6272ea9-0360-47ed-90a5-651ea958143f", "f6846464-25f0-4f86-8b86-e4f3cde1c271"], "title": "Synthesizing animations of human manipulation tasks", "venue": "international conference on computer graphics and interactive techniques", "year": 2004, "id": "713fd05e-d90b-4500-849b-20fa22736a2e"}
{"abstract": "A Single-Database Private Information Retrieval (PIR) is a protocol that allows a user to privately retrieve from a database an entry with as small as possible communication complexity. We call a PIR protocol non-trivial if its total communication is strictly less than the size of the database. Non-trivial PIR is an important cryptographic primitive with many applications. Thus, understanding which assumptions are necessary for implementing such a primitive is an important task, although (so far) not a well-understood one. In this paper we show that any non-trivial PIR implies Oblivious Transfer, a far better understood primitive. Our result not only significantly clarifies our understanding of any non-trivial PIR protocol, but also yields the following consequences: - Any non-trivial PIR is complete for all two-party and multiparty secure computations. - There exists a communication-efficient reduction from any PIR protocol to a 1-out-of-n Oblivious Transfer protocol (also called SPIR). - There is strong evidence that the assumption of the existence of a one-way function is necessary but not sufficient for any non-trivial PIR protocol.", "authors": ["Giovanni Di Crescenzo", "Tal Malkin", "Rafail Ostrovsky"], "n_citation": 153, "references": ["120c651d-8241-4afd-82d0-c49b4b317cdf", "15aeb2b2-9ba8-4a2d-8b26-0249e115bfbc", "262d9487-d172-4f86-afcd-79156ed5ac2e", "2fe397dd-1a29-4533-b862-dba03cd7d78a", "48a829fd-7c8f-4bb7-b481-ae23d55570a2", "503823bb-6b54-44f8-bab9-a232221bb6e4", "52320a95-da60-4e65-aa1b-510945888d50", "533305f1-b4b7-481d-9280-fe1e23bcbe02", "62f92ab6-7592-4ce8-bfae-ce4f2ee17c72", "65876893-352c-4a60-9cd3-f83c2637f37e", "689a1bfb-3ce0-483e-9db6-f4514ee2c600", "6c44cc4f-6cd4-4f06-bd82-7ba88679ffd4", "84f6b537-d4c6-4037-8dc1-5c7ed09ae42d", "907a645c-70c7-4992-bd2e-27e96f05e133", "9e1e46c7-2752-4322-b191-45b4eb3115e1", "b77f7024-7cfe-4d1d-b31f-2c7c8847f6fd", "c51d0c76-4e6f-4884-9051-a6190e42de90", "d7516da5-090a-4cfa-bf4a-e235db1abb0c", "dacee560-11d1-455e-a5b3-5964463a8373", "eca0d322-f4d2-4e11-8002-13ef52b2b4ae", "f251f50e-d310-4a07-8db4-b2d35c291b50", "f4d64c4e-c5fc-4470-81eb-f84cdcca18ed", "f8ece2cf-aa4a-40a1-93bc-c946ef219875", "fe9f9568-35a4-4abe-a469-a37d8fb43947"], "title": "Single database private information retrieval implies oblivious transfer", "venue": "theory and application of cryptographic techniques", "year": 2000, "id": "155d8f31-f7ae-4d59-acd5-809bf5a29f48"}
{"abstract": "Independent component analysis (ICA) of textured images is presented as a computational technique for creating a new data dependent filter bank for use in texture segmentation. We show that the ICA filters are able to capture the inherent properties of textured images. The new filters are similar to Gabor filters, but seem to be richer in the sense that their frequency responses may be more complex. These properties enable us to use the ICA filter bank to create energy features for effective texture segmentation. Our experiments using multi-textured images show that the ICA filter bank yields similar or better segmentation results than the Gabor filter bank.", "authors": ["Robert Jenssen", "Torbj\u00f8rn Eltoft"], "n_citation": 77, "references": ["087735a7-1cb9-4911-a88b-158cf3ebde87", "09346dc3-f4d0-43a4-8f0b-27e02bcd336e", "0aec81e6-f018-41e2-ad00-22998e53c6cf", "0ddbfee1-8cc2-49f6-be79-59276f496884", "1017d9d4-9a4c-423d-ad40-6d9bebbd6b31", "11969b7b-b276-4a18-b250-adba956c910f", "1a559436-838a-4358-a97f-d260dba7783e", "1cd93c58-0e74-48b7-8533-8c53e3abad4f", "1dba1cea-38b0-4450-89ab-6e12026f0bbd", "30614910-26a5-495c-8bb7-0f723c47db69", "400c7d3d-a4e9-49a1-821c-3646904d44ed", "6040eaf4-8897-4c87-a875-b6611339b0ad", "6c8cffb5-1552-434d-8941-d5fa38cfdfec", "7d150afa-0bd6-495e-8755-47bea06395bc", "8ab89d53-88ff-447d-b20e-4d8fb7bf5b68", "984e6f85-be9b-4965-b8c0-ae5887007504", "99f2c01b-6d49-4a93-8723-155698197ed6", "9cef868f-eb6d-4189-acd1-43eac87cf81e", "9fa21f34-e706-4f0b-a750-3d676d93c461", "a520a82c-6df7-41c1-b48d-5e4a4ca6076e", "a7118e96-8f8c-4294-9abb-e12647db7127", "ac57c834-1c68-4a01-be6d-c81788614292", "acdb2a94-5de9-4191-a33c-e922a693955e", "ada27ede-4400-4e7d-aee5-1b5e62fe1800", "c3ab2007-5e26-4417-a8df-ff92f8f0d373", "c8cc4b38-f181-4b22-9315-6cac6da63ad8", "d9215ef1-ba4b-4a59-bd6f-b6900dbf8ae3", "e54244ae-4bf9-48ea-aed4-9060cdc51f7a", "e57e068c-471f-4e93-af72-ae80231ed002", "f3f1d5e7-ead9-43cd-a210-fbed039d66b1", "f4e766ac-f68f-4829-a5f8-bc8751f57948", "fc443443-416f-4fd5-ba46-17a06046711d"], "title": "Independent component analysis for texture segmentation", "venue": "Pattern Recognition", "year": 2003, "id": "cb7c0274-40b9-4f31-b004-bff2c6276d46"}
{"authors": ["Ralph Bergmann", "Wolfgang Wilke"], "n_citation": 65, "title": "Towards a New Formal Model of Transformational Adaptation in Case-Based Reasoning.", "venue": "european conference on artificial intelligence", "year": 1998, "id": "e3c75fc8-6c37-4bb4-8940-852ad54bf1a0"}
{"abstract": "Let $G = ( V,E )$ be a finite undirected graph with n vertices and m edges. A minimum edge dominating set of G is a set of edges D, of smallest cardinality $\\gamma ' ( G )$, such that each edge of $E - D$ is adjacent to some edge of D. Let $S( G )$ be the subdivision graph of G and let $T( G )$ be the total graph of G. Let $\\alpha ( G )$ be the stability number of G (cardinality of a largest stable set) and let $\\alpha _2 ( G )$ be the 2-stability number of G (cardinality of a largest set of vertices in G, no two of which are joined by a path of length 2 or less). The following results are obtained. For any $G,\\gamma' ( S ( G ) ) + \\alpha _2 ( G ) = n$ and $2\\gamma ' ( T ( G ) ) + \\alpha ( T ( G ) ) = n + m$ or $n + m + 1$. Also, for any depth-first search tree S of $G,\\gamma ' ( S )/2\\leqq \\gamma ' ( G )\\leqq 2\\gamma ' (S)$, and these bounds are tight.The edge domination problem is NP-complete for planar bipartite graphs, their subdivision, line, and total graphs, perfect claw-free graphs, and planar cub...", "authors": ["Joseph Douglas Horton", "Kyriakos Kilakos"], "n_citation": 124, "title": "Minimum edge dominating sets", "venue": "SIAM Journal on Discrete Mathematics", "year": 1993, "id": "e7ecb57c-45c5-4c07-87e8-3398ca1faad0"}
{"abstract": "1. Introduction.- 2. System Architecture and Reasoning Scheme in SIGMA.- 3. Algorithms for Evidence Accumulation.- 4. LLVE: Expert System for Top-Down Image Segmentation.- 5. Experimental Results and Performance Evaluation.- 6. Conclusion.- References.", "authors": ["Takashi Matsuyama", "Vincent Shang-Shouq Hwang"], "n_citation": 234, "title": "SIGMA: A Knowledge-Based Aerial Image Understanding System", "venue": "", "year": 1990, "id": "ca304194-9785-4853-b5e4-98aa598d5865"}
{"abstract": "The decomposition of deformations by principal warps is demonstrated. The method is extended to deal with curving edges between landmarks. This formulation is related to other applications of splines current in computer vision. How they might aid in the extraction of features for analysis, comparison, and diagnosis of biological and medical images in indicated. >", "authors": ["Fred L. Bookstein"], "n_citation": 2871, "references": ["1c63e1d5-b963-455b-829d-e4f3eb63a36a", "71a947ba-be7c-4642-b1df-e42a69bf880b", "936e0ae4-e6e1-4b3b-9d0a-a6bff589fc7b", "f45d6bd0-f1a4-4f80-b6af-5e3b12bbac3a"], "title": "Principal warps: thin-plate splines and the decomposition of deformations", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 1989, "id": "6d86ad90-fe62-40e5-b917-7e3f31350523"}
{"abstract": "Abstract   An approach is presented for treating discrete optimization problems mapped on the architecture of the Hopfield neural network. The method constitutes a modification to the local minima escape (LME) algorithm which has been recently proposed as a method that uses perturbations in the network's parameter space in order to escape from local minimum states of the Hopfield network. Our approach (LMESA) adopts this perturbation mechanism but, in addition, introduces randomness in the selection of the next local minimum state to be visited in a manner analogous with the case of Simulated Annealing (SA). Experimental results using instances of the Weighted Maximum Independent Set (MIS) problem indicate that the proposed method leads to significant improvement over the conventional LME approach in terms of quality of the obtained solutions, while requirin\u0157 & g a comparable amount of computational effort.", "authors": ["George Papageorgiou", "Aristidis Likas", "Andreas Stafylopatis"], "n_citation": 7, "references": ["2523a03b-5af6-4e63-8f96-d49976e03a25", "34c02eeb-7d76-4560-8c5d-7280c4dac8a4", "af3dcf0c-6e6f-4190-a9d6-9a9d2551e378", "cb84e41d-30d0-45fd-96b8-2ce8efa8e4e5", "d4fd86d5-d984-4527-9b5b-df3cee4ede0c", "e111115f-9014-4e67-8737-97eb94dd7d0b", "eb36928a-e393-4e12-bd2a-09b6ee44d3eb"], "title": "Improved exploration in Hopfield network state-space through parameter perturbation driven by simulated annealing", "venue": "European Journal of Operational Research", "year": 1998, "id": "7a799b31-2f3d-4f43-a106-14da42e7f77a"}
{"abstract": "Context-aware, multi-channel Web applications are more and more gaining consensus among both content providers and consumers, but very few proposals exist for their conceptual modeling. This article illustrates a conceptual framework that provides modeling facilities for context-aware, multichannel Web applications; it also shows how high-level modeling constructs can drive the application development process through automatic code generation. Our work stresses the importance of user-independent,  context-triggered  adaptation actions, in which the context plays the role of a \u201cfirst class\u201d  actor , operating independently of users on the same hypertext the users navigate. Modeling concepts are based on WebML (Web Modeling Language), an already established conceptual model for data-intensive Web applications, which is also accompanied by a development method and a CASE tool. However, given their general validity, the concepts of this article shape up a complete framework that can be adopted independently of the chosen model, method, and tool.", "authors": ["Stefano Ceri", "Florian Daniel", "Maristella Matera", "Federico Michele Facca"], "n_citation": 203, "references": ["0434718f-61c1-461e-94f0-e78d5762ad59", "39de0c61-aa19-4c36-adad-86eb148f7714", "44da6ca4-1491-41a6-a8a4-b0f1e4db0188", "481b151b-6d42-4950-b250-7ecc50975e22", "4abd7633-e75a-43c8-b8af-5e6ba474bef6", "4d6e2b43-effe-4f19-b12d-13410e7c1fe1", "4d821727-a500-4c18-b5da-212d5c8336ef", "51fa907c-b749-4215-9ed0-0e7c599cd5f4", "68788de4-fece-4703-8bca-d4b56701088b", "6b19d2db-4eac-4577-a72d-5d856a564a95", "779000e1-bfe6-40f7-ac5a-f0f9dab2f9d9", "7c576597-b4fc-4eea-b613-ead65ff96e45", "816ea88f-9788-487e-a83d-fc027806a635", "85c3e879-bca4-4df4-adaa-47be4cfa8cfc", "8ab23f4b-0b87-42ed-9922-dbd10d9e845d", "8d405e31-f1fa-4676-80e9-f05e4d1058bc", "8f0c6f39-b371-4dc0-8a92-e76bd89868bd", "953909a9-aef3-4096-ad1c-a65cbab956e9", "99d692f3-01a6-4841-908e-15466ccac628", "9ccccb07-ac0a-4e33-a484-18b8c05e5028", "9df343f9-89ad-4aa1-bc2d-21235baa5035", "a401c07d-a046-4d44-999f-20604bec7a24", "c069c256-4bb6-47f4-ab26-ad160161d03d", "c18b2bef-5eca-4afc-b3a5-2de6b4fcd113", "de8e60ab-025a-49af-9441-1f796cd0444c", "e90e04ae-b5bc-4a89-97d3-eafb5f5754f7", "f9b78cb1-6dff-4a6c-a17e-3713623dbd96", "fa29fdad-590d-4454-b4e4-47bf9916689f", "fd51d78a-e2f5-46b6-b041-4dae9aebdc76"], "title": "Model-driven development of context-aware Web applications", "venue": "ACM Transactions on Internet Technology", "year": 2007, "id": "c86dded6-45ac-4ab7-a299-4db93937f5e9"}
{"abstract": "Graphs are a fundamental data representation that has been used extensively in various domains. In graph-based applications, a systematic exploration of the graph such as a breadth-first search (BFS) often serves as a key component in the processing of their massive data sets. In this paper, we present a new method for implementing the parallel BFS algorithm on multi-core CPUs which exploits a fundamental property of randomly shaped real-world graph instances. By utilizing memory bandwidth more efficiently, our method shows improved performance over the current state-of-the-art implementation and increases its advantage as the size of the graph increases. We then propose a hybrid method which, for each level of the BFS algorithm, dynamically chooses the best implementation from: a sequential execution, two different methods of multicore execution, and a GPU execution. Such a hybrid approach provides the best performance for each graph size while avoiding poor worst-case performance on high-diameter graphs. Finally, we study the effects of the underlying architecture on BFS performance by comparing multiple CPU and GPU systems, a high-end GPU system performed as well as a quad-socket high-end CPU system.", "authors": ["Sungpack Hong", "Tayo Oguntebi", "Kunle Olukotun"], "n_citation": 236, "references": ["05fadb61-949a-4984-8559-d12a51202c8d", "23fef83d-ba52-4ca7-9837-7e1c4ddf578e", "2e55e4db-6211-4b1e-a30b-4f46901b8080", "30c529e3-c476-404c-865f-344905f12bc4", "3b1a5ad0-3754-4482-86c5-c38cf3ad7827", "4620555e-c0f1-43b6-8686-9f8b8c5c4705", "476814fd-a44a-4724-8f81-869a60e0c337", "70c7d41a-9eda-4314-b21f-c5a5207f5e47", "99c38516-e79c-4b98-86ef-571ca361bc8d", "a0ee3102-b11e-467e-be7b-1b2691d9bc7e", "a173276b-beb2-42ac-be1b-471c6b951376", "becf3803-6dcb-4b16-8f28-aa94c30eed2f", "d535b801-168a-4430-a594-bac24768890b", "dbae7bb7-6db4-45e2-b942-a07b03c538ad", "e46cdd34-03dc-49dc-8703-e1d1beab729d", "e8a213a4-a353-479c-a216-43169ff21e3b", "f9bf9c13-26f8-4da0-8a7e-22a8d4838180", "fa619312-6a30-40c5-bd8e-f09dffce0543"], "title": "Efficient Parallel Graph Exploration on Multi-Core CPU and GPU", "venue": "international conference on parallel architectures and compilation techniques", "year": 2011, "id": "b2510878-51bd-4d89-a7f6-8800dcb49b0c"}
{"abstract": "Bringing mechanically compliant joints to robots is in the focus of interest world wide, especially in the humanoid robotics community. Variable Stiffness Joints (VSJ) promise to gain a high performing and robust robotic system. The presented DLR Floating Spring Joint (FSJ) is a VSJ module designed for the first 4 axes of the anthropomorphic DLR Hand Arm System. The DLR Hand Arm System aims to match the skills of its natural archetype. For this purpose, the joints have to be extremely compact to fit into the arm. At the same time they require a high power density in order to approximate the human arm skills. The new DLR FSJ is designed completely from an energy based point of view. This addresses not only energy efficient components and low friction design, but also that the potential energy of the spring is used as good as possible. A demonstration of robustness is given by the investigation of a blunt impact to the tip of the arm.", "authors": ["Sebastian Wolf", "Oliver Eiberger", "Gerd Hirzinger"], "n_citation": 53, "references": ["01f68a0d-6be3-4dd4-b125-9470c31c9c82", "17f10095-6cd7-4ce8-8be4-62caf642aaac", "29efdd0a-26f3-4122-8aa1-6b986d9550ce", "4ac912a8-be05-4356-9eab-6673b9f1a722", "4d07a3af-cb5e-4efe-b1ca-b2df04568a0a", "5695459c-951f-4aff-9720-6ca7a9b03f6e", "6c9e81d6-da8a-4af6-acd7-b9575ba3d87c", "8520eadb-3bdf-41cb-9e57-3394610340c0", "912c282a-bbca-435d-9e38-bb9a13f14bb6", "94cf8f8e-a73e-4e31-9694-445d4e04aa6a", "9c2a61ed-7718-4c37-8448-ccaf070d118c", "bf96dc20-21c2-4f79-b078-ae4005239b33", "df82a57b-b523-4195-a03b-6ca2f619ec50", "e4e08393-feef-447b-a4a8-d06165c83183", "f12326d3-17d4-47d3-a8fd-4e8865df855a"], "title": "The DLR FSJ: Energy based design of a variable stiffness joint", "venue": "international conference on robotics and automation", "year": 2011, "id": "3c13e70f-810e-434d-9251-6535cbbd3905"}
{"abstract": "Building a summary for library code is a common approach to speeding up the analysis of client code. In presence of callbacks, some reachability relationships between library nodes cannot be obtained during library-code summarization. Thus, the library code may have to be analyzed again during the analysis of the client code with the library summary. In this paper, we propose to summarize library code with tree-adjoining-language (TAL) reachability. Compared with the summary built with context-free-language (CFL) reachability, the summary built with TAL reachability further contains conditional reachability relationships. The conditional reachability relationships can lead to much lighter analysis of the library code during the client code analysis with the TAL-reachability-based library summary. We also performed an experimental comparison of context-sensitive data-dependence analysis with the TAL-reachability-based library summary and context-sensitive data-dependence analysis with the CFL-reachability-based library summary using 15 benchmark subjects. Our experimental results demonstrate that the former has an 8X speed-up over the latter on average.", "authors": ["Hao Tang", "Xiaoyin Wang", "Lingming Zhang", "Bing Xie", "Lu Zhang", "Hong Mei"], "n_citation": 18, "references": ["02f428f6-4dd5-43db-b487-c1ccd0d795b1", "0a32ce9c-7b11-4194-b639-1cbf418734f5", "10171efd-1457-4ad9-a580-7bf797633ca0", "1b367ba9-bb9d-4c7d-9aad-28189f6c7e85", "21272ee9-f02b-4c47-8728-50a104f89ea0", "23b35118-edcf-4683-9b33-7e8725207e50", "32e079c7-fca8-4333-8790-b7748b40dcf0", "33555fb5-1cde-4458-a3a5-6e0905edf8ad", "481f6c15-1375-4462-81f5-aa9a4bfd7421", "4e9506ca-ff7c-46a7-bccc-1477e565e58d", "5bc3746e-2a41-4969-95d4-6f3d1b0f7bac", "5cced2f2-5ba2-432e-80fe-fd41c3f52b0c", "65fed9d0-afd3-43e3-b5a7-2076d6b56328", "6caa182e-35ac-426e-babd-10bbf58c5867", "74f1bc60-45c3-4999-abc9-c00372a12237", "76c66080-6e89-4001-aead-8534d0bc4a10", "7e8236b7-9fa7-41da-99cf-6c0c18531e56", "8136f742-fabf-4dde-84c5-cca4c71d1057", "8567f2b2-59ec-4170-b402-c3a51b64d265", "90ac6264-0068-47d9-a366-4ed3e02c74d5", "99b28f0e-d5f8-4db6-8196-c7aacf0c7bd8", "9b2c14e3-9e79-4820-bc48-3a065ffec024", "9c704978-1109-48b3-9f10-80f6f475a609", "a43b46a3-5a2c-4407-9692-8284ae5ac0e9", "b146fdef-c8eb-43dc-9992-d01ff423163f", "b334c2c2-5142-43b1-bd5a-f5754badbf18", "bbb51ef1-27a4-4187-8a17-c0419f0a13ee", "c155e83e-2801-4fe2-b889-814747060ba6", "c390069e-0907-48c5-b79a-b6ad1c7fe7a9", "c4b0caf0-7af5-4ce6-9ba2-305a02a1a07b", "d1c52eff-d2a2-4b7f-bca3-ddfd18fc3c6d", "e14f1c5e-73c9-454f-a761-015186f2aaa7", "e2e62de3-82aa-40a1-8377-c191f3dc715c", "e4cb1fab-6773-48f6-ad35-cd4eee762366", "e8a48be6-2e41-4977-86f0-625f991ba421", "f190832c-e721-4ec1-a7b0-66283702c29a", "ff45495d-bba7-49cd-afc6-fdece4ad8646"], "title": "Summary-Based Context-Sensitive Data-Dependence Analysis in Presence of Callbacks", "venue": "symposium on principles of programming languages", "year": 2015, "id": "8b16ecd3-50f8-4684-9881-2458aa4849bf"}
{"abstract": "A novel strategy for the dynamic managment of the load request for the Internal Combustion Engine (ICE) and the Electrical Motor (EM) in a parallel hybrid vehicle is presented. The goal is the performing of a load splitting between ICE and EM subject to the achievement of good drivability of the vehicle in terms of coherence of the torque supply with the driver request (transient performance) for every load splitting between the two motors (static performance). In particular a dynamic allocation scheme is proposed, which dynamically distribute the power demand among the two propulsion systems, using suitable characterizations of their dynamics. Its stability and convergence properties are formally proven and the effectiveness of the control scheme is illustrated via simulations.", "authors": ["Stefano Cordiner", "Sergio Galeani", "Francesco Mecocci", "Vincenzo Mulone", "Giacomo Perantoni", "Luca Zaccarian"], "n_citation": 7, "references": ["22c4bc1f-9238-42e2-a874-70a927512f15", "58fc38ad-3c55-4d6f-89a0-5ca698f50d59", "7ff42d86-fad3-4505-8d37-3c9e1a720f1e", "811cc0c8-9fd8-4a7e-9511-230486f78611", "c29fb240-3977-43be-893d-60df49eb7300"], "title": "Dynamic input allocation of torque references for a parallel HEV", "venue": "conference on decision and control", "year": 2010, "id": "3af8bad6-00a0-4f07-a55b-4f3ac5547d8f"}
{"abstract": "A power-split hybrid electric vehicle (HEV) combines the advantages of both series and parallel hybrid vehicle architectures by utilizing a planetary gear set to split and combine the power produced by electric machines and a combustion engine. Because of the different modes of operation, devising a near optimal energy management strategy is quite challenging and essential for these vehicles. To improve the fuel economy of a power-split HEV, we first formulate the energy management problem as a nonlinear and constrained optimal control problem. Then two different cost functions are defined and model predictive control (MPC) strategies are utilized to obtain the power split between the combustion engine and electrical machines and the system operating points at each sample time. Simulation results on a closed-loop high-fidelity model of a power-split HEV over multiple standard drive cycles and with different controllers are presented. The results of a nonlinear MPC strategy show a noticeable improvement in fuel economy with respect to those of an available controller in the commercial Powertrain System Analysis Toolkit (PSAT) software and the other proposed methodology by the authors based on a linear time-varying MPC.", "authors": ["Hoseinali Borhan", "Ardalan Vahidi", "Anthony Mark Phillips", "Ming Kuang", "Ilya V. Kolmanovsky", "S. Di Cairano"], "n_citation": 249, "references": ["092aca38-4e05-44c5-b224-226e8d9e71f6", "2018ecbb-405c-406e-b5fa-21cf42ae9dd7", "40c45610-94b3-479d-a311-236498567c5d", "7ff42d86-fad3-4505-8d37-3c9e1a720f1e", "dcc5ff5f-8ed2-40af-aced-edf415365049", "e79ddc1b-bc13-4c2a-836e-41a3381529b1", "fbf9c782-30f5-4d09-b608-565c53dbd96f"], "title": "MPC-Based Energy Management of a Power-Split Hybrid Electric Vehicle", "venue": "IEEE Transactions on Control Systems and Technology", "year": 2012, "id": "4c2978cd-7055-46b6-bbec-0eff608c9fc3"}
{"abstract": "Abstract#R##N##R##N#Many software maintenance and testing tasks involve comparing the behaviours of program versions. Program spectra have recently been proposed as a heuristic for use in performing such comparisons. To assess the potential usefulness of spectra in this context an experiment was conducted, examining the relationship between differences in program spectra and the exposure of regression faults (faults existing in a modified version of a program that were not present prior to modifications, or not revealed in previous testing), and empirically comparing several types of spectra. The results reveal that certain types of spectra differences correlate with high frequency\u2014at least in one direction\u2014with the exposure of regression faults. That is, when regression faults are revealed by particular inputs, spectra differences are likely also to be revealed by those inputs, though the reverse is not true. The results also suggest that several types of spectra that appear, analytically, to offer greater precision in predicting the presence of regression faults than other, cheaper, spectra may provide no greater precision in practice. These results have ramifications for future research on, and for the practical uses of, program spectra. Copyright \u00a9 2000 John Wiley & Sons, Ltd.", "authors": ["Mary Jean Harrold", "Gregg Rothermel", "Kent Sayre", "R. S. Wu", "Liu Yi"], "n_citation": 141, "references": ["039c16b7-d16c-4928-842c-5c031966d940", "12816160-ccb8-420e-9dff-b2e165720733", "3150918b-512b-4c22-a2d1-30bfd86f22bc", "6e8ea39b-5d8f-43e5-9663-84abb1b52da6", "9fe654b4-8dc2-4bc2-8fa5-e232cfac26e3", "c0bd4ff6-2f39-49a8-8b61-f59486a007cb", "d70fb3e4-1e5f-4ab3-900d-34ecb9efc841", "e24d0b26-836c-45c8-a17b-db9446e64f96"], "title": "An empirical investigation of the relationship between spectra differences and regression faults", "venue": "Software Testing, Verification & Reliability", "year": 2000, "id": "88c16efc-f450-4ffe-9e21-05186cac115a"}
{"abstract": "Replication is a powerful technique for increasing availability of a distributed service. Algorithms for replicating distributed services do however face a dilemma: they should be: efficient (low latency); while ensuring consistency of the replicas, which are two contradictory goals. The paper concentrates on active replication, where all the replicas handle the clients' requests. Active replication is usually implemented using the atomic broadcast primitive. To be efficient, some atomic broadcast algorithms deliberately sacrifice consistency, if inconsistency is likely to occur with a low probability. We present an algorithm that handles replication efficiently in most scenarios, while preventing inconsistencies. The originality of the algorithm is to take the client-server interaction into account, while traditional solutions consider atomic broadcast as a black box.", "authors": ["Pascal Felber", "Andr\u00e9 Schiper"], "n_citation": 50, "references": ["1daeaeab-0e9c-40be-8601-ad93606b2c8d", "654532b4-befb-4e13-8090-ebb447f5321d", "7ffec2f8-420b-43cf-8ad5-550e332f5d6d", "81ad8d98-8e9c-492c-9f0e-dc4b1e6d3d8b", "8b495c61-ea6e-4c7b-9b45-3121ab994aa8", "9bcc0ae8-9033-4156-b85b-592bd01ae91e", "9db9578a-6f45-4630-a7ac-854a93cd5c55", "9f271ad1-8353-41c5-896e-ae9a3bf4e82b", "c017ac96-8892-4ce2-8d7a-b837f7768872", "e80f1c3a-10a5-4a79-9b81-ac4f052732bb", "eaa340b0-5c17-4462-b64e-937249e40bfe"], "title": "Optimistic active replication", "venue": "international conference on distributed computing systems", "year": 2001, "id": "9f6e079f-4297-4215-9687-ba016b0932e4"}
{"abstract": "When a query to a knowledge-based system fails and returns \"unknown\", users are confronted with a problem: Is relevant knowledge missing or incorrect? Is there a problem with the inference engine? Was the query ill-conceived? Finding the culprit in a large and complex knowledge base can be a hard and laborious task for knowledge engineers and might be impossible for non-expert users. To support such situations we developed a new tool called \"WhyNot\" as part of the PowerLoom knowledge representation and reasoning system. To debug a failed query, WhyNot tries to generate a small set of  plausible partial proofs  that can guide the user to what knowledge might have been missing, or where the system might have failed to make a relevant inference. A first version of the system has been deployed to help debug queries to a version of the Cyc knowledge base containing over 1,000,000 facts and over 35,000 rules.", "authors": ["Hans Chalupsky", "Thomas A. Russ"], "n_citation": 50, "references": ["28476530-3b80-42d2-b0d6-f7ddd3759faf", "4a71d48b-3751-426a-8606-17a7a48be585", "5fd02b86-6bb4-43f6-a169-70b4fc4b1da8", "8f646641-4fdc-4350-9868-55afc1a80269", "d365ef26-224f-4e55-9074-fcafd3c96dbf", "d405f7e6-278e-4c40-96ac-5213c034347a"], "title": "WhyNot: debugging failed queries in large knowledge bases", "venue": "national conference on artificial intelligence", "year": 2002, "id": "d06306ba-2022-4e38-8d45-aa83c9be7bc8"}
{"abstract": "Abstract   Recent methods for mechanism reduction convert large detailed chemical reaction mechanisms into small systems of differential or differential-algebraic equations. A possible further step is the parameterization of reaction mechanisms, i.e. the description of chemical kinetics by explicit functions, obtained by numerical fitting to the numerical solution of differential equations. A new parameterization procedure, based on orthonormal polynomials, is described which is well applicable for fitting high-order polynomials having few effective parameters. A program is provided for the generation of multivariate Horner equations. The method is illustrated by the parameterization of a recent version of the Oregonator, a skeleton model of the oscillating Belousov\u2014Zhabotinsky reaction.", "authors": ["Tam\u00e1s Tur\u00e1nyi"], "n_citation": 140, "references": ["4134b978-1c60-484c-878d-041aa8673881", "d971b57c-191a-4b87-a5d7-5bf0739475fc"], "title": "Parameterization of reaction mechanisms using orthonormal polynomials", "venue": "Computational Biology and Chemistry", "year": 1994, "id": "f52a4350-d741-4263-b723-98cce7df2739"}
{"abstract": "In this paper, we present an almost-linear time algorithm for constructing Gated Single Assignment (GSA), which is SSA augmented with gating functions at o-nodes. The gating functions specify the control dependences for each reaching definition at a o-node. We introduce a new concept of  gating path , which is path in the control flow graph from the immediate dominator  u  of a node  v  to  v , such that every node in the path is dominated by  u . Previous algorithms start with o-function placement, and then traverse the control flow graph to compute the gating functions. By formulating the problem into gating path construction, we are able to identify not only a o-node, but also a gating path expression which defines a gating function for the o-node.", "authors": ["Peng Tu", "David A. Padua"], "n_citation": 61, "references": ["14c4665f-878d-4991-8b66-5d7aacca4f07", "2448f6ce-230a-495c-8cab-21a8bf2865eb", "27d3700a-f3da-46c1-a019-44df815ea113", "315bb753-e8e0-40c7-a531-340e34958650", "338f9fba-1b46-41a8-9fb1-4b37ee66bc71", "34a5fa26-7ce9-42c2-ac27-54d5f3b791fb", "34b259b2-8c1b-4df0-bd65-cbc3536bc826", "457d48ac-76f3-406e-8285-db07c07a0d6a", "4eb8a709-7279-4429-9277-90c638023f0f", "55f658eb-3aaa-4344-baa9-0a5cfc9e64b9", "5a8311bb-9291-4d99-b194-82ccfcd9a16f", "5b03270b-2d1a-45ad-b0bc-dfa4e457d61c", "6fc82622-8a84-4dd9-af71-31fec51478cf", "7499b7ef-42dd-441c-a2f5-e57e61a6a997", "89ad9d8a-654c-4870-849d-162f9d20c0f3", "f3cd8dbd-8923-4d03-aa3a-1ce4f3b7ca83"], "title": "Efficient building and placing of gating functions", "venue": "programming language design and implementation", "year": 1995, "id": "137e56d6-e9d4-4cff-8466-e71d43daaec0"}
{"abstract": "The vast majority of the project scheduling methodologies presented in the literature have been developed with the objective of minimizing the project duration subject to precedence and other constraints. In doing so, the financial aspects of project management are largely ignored. Recent efforts have taken into account discounted cash flows and have focused on the maximization of the net present value (npv) of the project as the more appropriate objective. In this paper we offer a guided tour through the important recent developments in the expanding field of research on deterministic and stochastic project network models with discounted cash flows. Subsequent to a close examination of the rationale behind the npv objective, we offer a taxonomy of the problems studied in the literature and critically review the major contributions. Proper attention is given to npv maximization models for the unconstrained scheduling problem with known cash flows, optimal and suboptimal scheduling procedures with various types of resource constraints, and the problem of determining both the timing and amount of payments.", "authors": ["Willy Herroelen", "Patrick Van Dommelen", "Erik Demeulemeester"], "n_citation": 143, "references": ["557ff192-5ab1-41de-a586-6f960aeccad6", "5a16f27e-e132-49fe-a8ec-207dbb6c2a90"], "title": "Project network models with discounted cash flows. A guided tour through recent developments", "venue": "European Journal of Operational Research", "year": 1997, "id": "b9a3db90-b0f3-4960-b6bc-3bae1f6ceaca"}
{"authors": ["Michael Siegel", "Frank A. Stomp"], "n_citation": 50, "references": ["026b656f-4393-4aaf-9b17-359bcdc3422d", "2004306e-d770-46c6-87d4-cc77feb2ef2a", "2949815b-2ca0-40a7-8ed8-c83051186109", "33b466d3-36e5-4a93-9a02-be1df4471812", "33de8856-0b19-450b-b18c-c38288e941ec", "79de76a0-072e-41a4-8353-411e4fb1c6a7", "7c6e2caf-f5cf-471a-81f4-f24ac7889a49", "9a0eaf85-af7b-44cf-9bd4-e18c884bb490", "be9af25c-4ee8-46d9-a3a7-41b3f8d86a50", "edb452e4-70e6-453e-90a1-ecaf9c434e46", "fefdc7ab-d2de-4871-9c2a-56c480a1aaf7"], "title": "Extending the limits of sequentially phased reasoning", "venue": "foundations of software technology and theoretical computer science", "year": 1994, "id": "6c8b39f0-a8c1-489a-8ce1-441f8d2ecffd"}
{"abstract": "We introduce a new computational problem related to the interpolation of group homomorphisms which generalizes many famous cryptographic problems including discrete logarithm, Diffie-Hellman, and RSA. As an application, we propose a generic undeniable signature scheme which generalizes the MOVA schemes. Our scheme is generic in the sense that we transform a private group homomorphism from public groups G to H (the order of H being public) into an undeniable signature scheme. It is provably secure in the random oracle model provided that the interpolation problem is hard and it offers the advantage of mak- ing the signature size arbitrarily short (depending on a security level). We (im)prove some security results from MOVA. We also propose a new example with complexity similar to RSA and with 3-byte signatures.", "authors": ["Jean Monnerat", "Serge Vaudenay"], "n_citation": 52, "references": ["1e756054-39bf-4670-830c-f4e20aebaf30", "22e35b6e-6dff-4af5-9caf-ee3a69010c06", "299f8e42-115f-4e65-be5c-bb1b37aeb927", "3fb43b00-905c-4a08-934d-198ea4eb66c3", "7a1624d7-9b8e-44fd-a778-e0d3179b509a", "7a1a0ab7-2434-418e-8c0b-2c19e825c6a9", "8d33b018-c738-4332-aad3-eac8d2d8e652", "9f882930-a11b-4db7-acc8-2f13a12ac246", "a1018236-0dd5-4319-a3e5-be9c42807b25", "ada326e4-c3b8-443a-87de-a4b442a49da4", "b6b1e8b1-b117-460a-b2b3-36ecc99e8fca", "c3a06227-08a1-4887-af65-86a960a80e00", "ca394e6a-59e0-466c-a66a-d976555db689", "d893a420-a00d-4756-b447-2862ed178eaa", "dbdf31ec-113e-42aa-b0db-b3d85ff40aaf"], "title": "Generic Homomorphic Undeniable Signatures", "venue": "international conference on the theory and application of cryptology and information security", "year": 2004, "id": "126ed76e-3d51-40b3-8679-5c2a5b5e19a6"}
{"authors": ["Joaquin Gonzalez-Rodriguez", "Daniel Garcia-Romero", "Marta Garcia-Gomar", "Daniel Ramos-Castro", "Javier Ortega-Garcia"], "n_citation": 21, "title": "Robust likelihood ratio estimation in Bayesian forensic speaker recognition.", "venue": "conference of the international speech communication association", "year": 2003, "id": "b9ca96e9-9e0a-4e5d-abe2-47aaa4da8252"}
{"abstract": "This paper presents a new approach to image-based guidance of a needle or surgical tool during percutaneous procedures. The method is based on visual servoing. It requires no prior calibration or registration. The technique provides highly precise 3D-alignment of the tool with respect to an anatomic target. By taking advantage of projective geometry and projective invariants, this can be achieved in a fixed number (12) of iterations. In addition the approach estimates the required insertion depth. Experiments include automatic 3D alignment and insertion of a needle held by a medical robot into a pig kidney under X-ray fluoroscopy.", "authors": ["Nassir Navab", "Benedicte Bascle", "Michael L\u00f6ser", "Bernhard Geiger", "Russell H. Taylor"], "n_citation": 50, "references": ["688eaba0-4935-41a9-a5af-0a0406e74257", "cfd26ac8-7635-4ce4-8698-f2931591d28c", "d407bef1-93e7-46d2-b0e1-7af81966235a"], "title": "Visual servoing for automatic and uncalibrated needle placement for percutaneous procedures", "venue": "computer vision and pattern recognition", "year": 2000, "id": "eec0a2e9-0e19-4bcb-a8d6-454e38b50cc5"}
{"abstract": "Language usage over computer mediated discourses, such as chats, emails and SMS texts, significantly differs from the standard form of the language and is referred to as texting language (TL). The presence of intentional misspellings significantly decrease the accuracy of existing spell checking techniques for TL words. In this work, we formally investigate the nature and type of compressions used in SMS texts, and develop a Hidden Markov Model based word-model for TL. The model parameters have been estimated through standard machine learning techniques from a word-aligned SMS and standard English parallel corpus. The accuracy of the model in correcting TL words is 57.7%, which is almost a threefold improvement over the performance of Aspell. The use of simple bigram language model results in a 35% reduction of the relative word level error rates.", "authors": ["Monojit Choudhury", "R. R. Saraf", "Vijit Jain", "Animesh Mukherjee", "Sudeshna Sarkar", "Anupam Basu"], "n_citation": 173, "references": ["10b46196-2b40-45f6-8c27-89ac24eec0ac", "176caf81-8842-461a-aa80-456424878f7a", "45e52414-5455-47d0-9782-f3bd867a3ddf", "47bb1f39-7585-43e4-a354-7791b4c1f0bf", "5443ee2f-a083-4829-bfd3-b92e50b6d78e", "6772d645-847c-49b5-99ba-1182524f80bf", "73e642f0-e13c-424b-82b9-1a9fc43175fe", "7be6da3b-c134-4802-8e5a-f39b8533b13c", "a2530144-b6fd-4659-84f5-73a470275dd4", "a3b3a87e-4d9f-4877-84e0-e5f6995a1fd1", "a43460d4-07b8-4647-bc39-602e42e46c01", "ab2c686a-7e60-4217-bbe0-5bc9cfe9a768", "addcf428-fb1b-47b5-b455-b0cf4168edd8", "b6f96238-c356-49c9-9638-53e39931954c", "c8323642-f362-4ef3-bcc6-7ed07536c658", "e41838f7-2a29-4bab-b68a-8eb1c0b5fa85"], "title": "Investigation and modeling of the structure of texting language", "venue": "international joint conference on artificial intelligence", "year": 2007, "id": "12b988e5-1397-4277-8e53-9de01949219d"}
{"abstract": "Synthesis of optimal controllers achieving finite-time consensus for multiagent networks described by fixed or periodic connectivity graphs is considered. The solution procedure involves posing a partially nested, finite-horizon decentralized control problem and converting it to a static convex optimization problem by a quadratic invariance argument. The dynamic feedback controller thus synthesized optimizes a transient performance measure and guarantees consensus within a minimal number of steps.", "authors": ["Supratim Ghosh", "Ji-Woong Lee"], "n_citation": 2, "references": ["0bf829c3-d555-4745-b1a5-7c5ce8acbff6", "0fae2e9e-a212-4546-aa4b-97146fb27577", "2768199c-b9d6-4001-94d3-e6429c93bc5f", "422dab9c-a07d-4dbf-bc15-2a3bbcb2d24c", "59fd9847-77c5-44c3-b689-8bb5c5d99daa", "6460eee0-033e-4185-8b7c-dbcb931e1b2c", "a42f7514-185f-4b1c-bbf4-776a8f70ad7f", "ab35dc68-62bd-4c54-81d3-9a8406827489", "d7b5aadf-ec30-4fb7-9224-7474169d3744", "d9162547-fd7f-4605-855d-0a3173c4b08e", "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9", "ea9e1caf-0c69-48cb-86c4-583136412b01", "ff798c53-cc5d-4f51-a0e7-1d437b3dc19b"], "title": "Optimal Finite-Time Consensus on Fixed and Periodic Graphs", "venue": "Siam Journal on Control and Optimization", "year": 2013, "id": "e4ef7d13-7ab4-427f-ab94-4be4a91a2530"}
{"abstract": "Despite the growing prominence of canonical action research (CAR) in the information systems discipline, a paucity of methodological guidance contin- ues to hamper those conducting and evaluating such studies. This article elicits a set of five principles and associated criteria to help assure both the rigor and the relevance of CAR in information systems. The first principle relates to the devel- opment of an agreement that facilitates collaboration between the action researcher and the client. The second principle is based upon a cyclical process model for action research that consists of five stages: diagnosis, planning, inter- vention, evaluation and reflection. Additional principles highlight the critical roles of theory, change through action, and the specification of learning in terms of impli- cations for both research and practice. The five principles are illustrated through the analysis of one recently published CAR study.", "authors": ["Robert M. Davison", "Maris G. Martinsons", "Ned Kock"], "n_citation": 828, "references": ["004050d0-c5b4-4721-bd2c-f13b8ca8dcb5", "0a60f560-ebb0-4a49-9551-e14ed452bdd0", "170c54b9-5fc4-42f9-a6f0-506dc8a229ef", "1c95d184-179f-44d1-88a8-5fab9e567e69", "1deb96e7-5602-4e51-8e9a-def339973aa8", "26d4730a-78ba-4fae-adb7-e24ffed0b177", "390208e7-df53-49a5-a2c7-d0b05dfd11fe", "3e55c00b-cc0e-4c83-9c20-b12f21f5cc00", "3f6eb56b-79c1-422a-a8d4-dadae7532073", "3f772750-3780-4bbd-a687-2bcd0a6e7707", "47bbe09d-d3d3-4586-a4fa-252c28d0ab27", "6d05e6fe-a3af-4e09-a8c4-8789f6e24c73", "80fe8011-0010-420c-a3c0-4868693f0bce", "90b13f8e-dc8e-4eba-ae46-5651bda314ee", "954737d3-d9bc-4450-9b6b-d6495109c08d", "a1669534-7f2a-4a12-90ee-a7b3e1f2258e", "afd63c47-1b9b-4ca0-8693-e8f3efd61b64", "b7556c30-7646-4770-85a2-f2d79775b511", "d10d8050-d416-45bc-90e9-f06f399e9d23", "d21b4e5c-0621-426f-ab06-c13aec05d2c2", "de541b93-4c8d-41ae-8c8f-d2a408124728", "ecd0e819-d765-409e-8de8-8e1d91990784"], "title": "Principles of canonical action research", "venue": "Information Systems Journal", "year": 2004, "id": "80698658-ee39-4df4-bd1a-a09150149d00"}
{"abstract": "Many aspects of time-based media\u2014complex data encoding, compression, \u201cquality factors,\u201d timing\u2014appear problematic from a data modeling standpoint. This paper proposes  timed streams  as the basic abstraction for modeling time-based media. Several media-independent structuring mechanisms are introduced and a data model is presented which, rather than leaving the interpretation of multimedia data to applications, addresses the complex organization and relationships present in multimedia.", "authors": ["Simon J. Gibbs", "Christian Breiteneder", "Dennis Tsichritzis"], "n_citation": 179, "references": ["207629c1-3462-4b32-9415-89f9426aed37", "3001c2eb-fd2f-4806-835a-3c0033a582c0", "7ce2166c-a047-4dbb-ba96-86af8e680171", "a855ec29-f56d-4f8c-bd08-f7a2dc92d6b4", "ab344689-80f8-4f1d-b8a7-d9ff7f128396", "afddd2fb-0c5d-4d08-a5c4-f66da5a6a6ea", "babbcd6f-a2d3-461f-8aba-3b0c08d7d4d1", "bc76c467-f3c7-4671-8ce0-e05c50573b47", "c6a27ea1-40f6-4280-a724-14d54fbe9d6e", "c92ee63c-7471-4e6e-9f62-f5bd83db5eba", "d225f4c6-d5b0-49b4-bf6e-b19e136f2090", "f99c3014-e522-426d-b9c2-22d3d3bb2697"], "title": "Data modeling of time-based media", "venue": "international conference on management of data", "year": 1994, "id": "ce9d5c7c-4797-4a35-9d5c-13ffde422abd"}
{"abstract": "JMS is an API specification that defines a standard way for Java applications to access messaging services. All JMS products promise good performance and to properly support the QoS attributes specified in the standard, making it hard to choose between them. Customers who want to determine which JMS product best meets their requirements need a simple, effective and fair methodology for evaluating and comparing competing implementations. This paper presents an empirical methodology for evaluating the QoS implementation of a JMS product. We present a number of test scenarios and define metrics for measuring performance and message persistence. We then illustrate this methodology by using it to evaluate two leading JMS products. Our evaluation results show differences between these products in terms of their overall performance and the impact of various QoS attributes. The case study demonstrates that our empirical methodology is an effective and practical way to test the performance of JMS and other messaging systems.", "authors": ["Shiping Chen", "Paul Greenfield"], "n_citation": 50, "references": ["22bc658f-f772-4d27-8b93-011b8e949687", "8fd6531b-c809-4e63-895b-fb91be11759d", "94c3168a-c9ca-4fde-bad9-1c1047237676", "f840df6b-dd25-4309-9989-eff98aa64589"], "title": "QoS evaluation of JMS: an empirical approach", "venue": "hawaii international conference on system sciences", "year": 2004, "id": "64ca250c-e136-43cb-85c0-7b86bace8565"}
{"authors": ["Nuria Medina-Medina", "Fernando Molina-Ortiz", "Mar\u00eda Jos\u00e9 Rodr\u00edguez-F\u00f3rtiz", "Lina Garc\u00eda-Cabrera"], "n_citation": 5, "title": "An Architecture for the Development, Evolution and Adaptation of Hypermedia Systems.", "venue": "", "year": 2003, "id": "1835f05c-f474-404b-90ea-e224a77f4bf2"}
{"abstract": "Rough sets are often induced by descriptions of objects based on the precise observations of an insufficient number of attributes. In this paper, we study generalizations of rough sets to incomplete information systems, involving imprecise observations of attributes. The precise role of covering-based approximations of sets that extend the standard rough sets in the presence of incomplete information about attribute values is described. In this setting, a covering encodes a set of possible partitions of the set of objects. A natural semantics of two possible generalisations of rough sets to the case of a covering (or a non transitive tolerance relation) is laid bare. It is shown that uncertainty due to granularity of the description of sets by attributes and uncertainty due to incomplete information are superposed, whereby upper and lower approximations themselves (in Pawlak's sense) become ill-known, each being bracketed by two nested sets. The notion of measure of accuracy is extended to the incomplete information setting, and the generalization of this construct to fuzzy attribute mappings is outlined.", "authors": ["In\u00e9s Couso", "Didier Dubois"], "n_citation": 50, "references": ["0690675d-b0ef-4117-a019-de5a8a554b23", "0bf18ddf-9a97-4e80-b969-2cc97a46fe00", "0dcfd22e-c7db-4ad5-a888-37cf7b3ef757", "1910273b-b6e8-40dd-a1bf-cc45368a3b5d", "1e21ebbe-3ca0-4ee9-88d0-9b5998cd09fb", "3769e11a-daaa-4f96-ab28-5fcd9e25223c", "384177ff-fd1d-42ee-801e-9c420554b7b5", "3c4206ca-fd9b-4f3d-af6d-e3b672908d4b", "4bf3b810-f960-4ff5-a675-8078ef11c722", "4d4ab30e-6951-4eaa-8a82-02602c81241a", "59b47def-ae93-4c2d-9a55-ef64cac0b025", "686aedd1-d00e-43f8-b835-e4209268cf68", "6c9aac4e-465d-449d-81da-a4ad1470dd42", "a4589cfe-15e7-4c34-9349-d002d1d2c9df", "f242ad48-0617-4c5f-b319-3e1afec288a7", "ff6baa6e-97dd-49c9-8e62-0b46e681cf4a"], "title": "Rough Sets, Coverings and Incomplete Information", "venue": "Fundamenta Informaticae", "year": 2011, "id": "5b80aee9-fa13-4f63-ae93-aadcd320dc60"}
{"abstract": "The recent use of graphics processing units (GPUs) in several top supercomputers demonstrate their ability to consistently deliver positive results in high-performance computing (HPC). GPU support for significant amounts of parallelism would seem to make them strong candidates for non-HPC applications as well. Server workloads are inherently parallel; however, at first glance they may not seem suitable to run on GPUs due to their irregular control flow and memory access patterns. In this work, we evaluate the performance of a widely used key-value store middleware application, Memcached, on recent integrated and discrete CPU+GPU heterogeneous hardware and characterize the resulting performance. To gain greater insight, we also evaluate Memcached's performance on a GPU simulator. This work explores the challenges in porting Memcached to OpenCL and provides a detailed analysis into Memcached's behavior on a GPU to better explain the performance results observed on physical hardware. On the integrated CPU+GPU systems, we observe up to 7.5X performance increase compared to the CPU when executing the key-value look-up handler on the GPU.", "authors": ["Tayler H. Hetherington", "Timothy G. Rogers", "Lisa R. Hsu", "Mike O'Connor", "Tor M. Aamodt"], "n_citation": 77, "references": ["01051024-ab5b-4d95-adbe-a41211145475", "101a87ca-229a-4052-838e-bb180a112634", "1f18a614-c8d8-4d34-820d-c384042ede95", "311971cc-8b6a-4b7d-b6b6-dee7de5c79d6", "34ffaac4-137c-4300-a5a3-d4067b6e3113", "3987def9-9314-46d6-b816-ff7419e43f08", "569ed5af-da0f-48d7-9e28-e7b03b40d367", "6794a250-7271-4544-9f35-eab3c167dea7", "6c3ce525-921e-449a-8609-55859415972e", "722ab3fd-21fc-42d8-ab53-add1bd0ce4cd", "7923294b-b5d3-4689-a907-1cde15be397d", "7becff4d-5c24-497e-950d-782973e15ccd", "7e2a02e7-0466-4420-9b07-00ad080a40a9", "84d82321-b384-40cf-a77d-c0b180eabf37", "d85ec414-1cf0-413b-b04d-db807e9fcacf", "e4729229-e16a-4430-9135-512dd28d44e5", "f7ec1a95-578f-484e-864d-4fb306de029d"], "title": "Characterizing and evaluating a key-value store application on heterogeneous CPU-GPU systems", "venue": "international symposium on performance analysis of systems and software", "year": 2012, "id": "b98a260b-643f-49f7-ac9c-d4a5094efca0"}
{"abstract": "Abstract   A new temporal logic and interpretation are suggested which have features from linear temporal logic, branching time temporal logic, and partial order temporal logic. The new logic can describe properties essential to the specification and correctness proofs of distributed algorithms, such as those for global snapshots. It is also appropriate for the justification of proof rules and for ascribing temporal semantics to properties such as layering of a program. These properties cannot be described with existing temporal logics. The semantic model of the logic is based on a collection of sets of interleaving sequences which reflect partial orders from the underlying semantics of the computational model. For the common partial order derived from sequentiality in execution of each process, the logic will distinguish between nondeterminism due to the parallel execution and nondeterminism due to local nondeterministic choices. The difference in expressive power is thus qualitative, and not merely due to the presence or absence of a particular temporal operator. In the logic, theorems are proven which clarify when it is possible to establish a property  P  for  some  of the interleaving computations, and yet conclude the truth of  P  for  every  interleaving.", "authors": ["Shmuel Katz", "Doron A. Peled"], "n_citation": 73, "references": ["136c4780-2f25-4068-90a5-aed6afaf2890", "1aee7582-85e7-449e-a3a2-76be40d31940", "20ac5cbf-1214-4fb1-a572-63613eab208f", "28a1a2c5-69bf-4149-913a-d65885c8d515", "296054b4-a408-4c0a-8a7b-ebaf0363d75f", "2bb33756-67db-4329-8c0d-f3c5fdab2367", "47069681-5ae1-4a8f-bb62-60de6131a56f", "4b082581-97d5-4992-adae-0e34edeeec36", "640e9f45-59dd-4a4c-8f16-ce9fca96c460", "765a5f62-24d9-4ae0-a6d9-79c143d6d5eb", "8d1688b3-232b-4c48-80f6-d7f5e1b732d8", "9263d164-aa3d-4ef0-b277-6560f605f417", "9350f704-a57b-4c51-b4ad-a21600c95e4b", "9a0eaf85-af7b-44cf-9bd4-e18c884bb490", "9ba64329-fb53-4018-8afd-c292f9f8860d", "b581d1fb-024c-43eb-80d8-ee7f4a0aaf52", "b5c09945-94f2-403c-8a54-d4094308ac56", "b6a77e7c-7cf7-472f-b848-7ce1a9f054c2", "b8a21099-3ad7-49b7-a004-aaacf728c2a7", "bfccc0cd-4c61-48b8-9e5d-5d808c96b7c1", "cddf54fd-9a76-49ec-acb4-76a47a5d8ce2", "ce608659-49cd-4be5-a580-8675ed83e133", "d5910691-522c-4ea5-ab3f-534cad986cc0"], "title": "Interleaving set temporal logic", "venue": "Theoretical Computer Science", "year": 1990, "id": "2004306e-d770-46c6-87d4-cc77feb2ef2a"}
{"abstract": "Mobile work situations within home care of the elderly require immediate and ubiquitous access to patient-oriented data. The ongoing Swedish research project \u201cTechnical support for Mobile CloseCare\u201d focuses on the development and evalua-tion of work-scenario oriented ICT support for enhanced home care of elderly citizens. The aim of the project is to pro-vide a seamless and consistent information flow between dif-ferent health care providers and to give intuitive access to information services for the elderly and their relatives. For that purpose, different independent software components are connected through a mobile communication platform. Flexible access to prioritized information for different users in different work situations will be given through a virtual health record. In order to obtain both usable and clinically relevant systems, a user centered system development approach is followed. Evaluation of the project results will be based on usability tests and quasi-experimental studies on how system implemen-tation influences quality of care and job- and life satisfaction for care providers, patients and relatives.", "authors": ["Sabine Koch", "Maria H\u00e4gglund", "Isabella Scandurra", "Dennis Mostr\u00f6m"], "n_citation": 50, "references": ["a5b229fb-0da3-42c3-bd36-ed285cec0c68", "aeec5f54-8fef-4518-9225-a0904472d5a1"], "title": "Towards a virtual health record for mobile home care of elderly citizens.", "venue": "", "year": 2004, "id": "97bed243-f8d1-4836-b945-24aa09bd476f"}
{"abstract": "The design of easy-to-use and informative visual interfaces to digital  libraries is an integral part to the advances of digital libraries. A wide range of approaches have been developed from a diverse spectrum of perspectives that focus on users and tasks to be supported, data to be modeled, and the efficiency of algorithms. Information visualization aims to exploit the human visual information processing system, especially with non-spatial data (such as documents and images typically found in digital libraries). Generally, information visualization examines semantic relationships intrinsic to an abstract information space and how they can be spatially navigated and memorized using similar cognitive processes to those that would apply during interactions with the real world. This workshop promotes the convergence of information visualization and digital libraries. It brings together researchers and practitioners in the areas of information visualization, digital libraries, human-computer interaction, library and information science, and computer science to identify the most important issues in the past and the present, and what should be done in the future.", "authors": ["Katy B\u00f6rner", "Chaomei Chen"], "n_citation": 50, "title": "Workshop 1: visual interfaces to digital libraries - its past, present, and future", "venue": "acm/ieee joint conference on digital libraries", "year": 2001, "id": "41143549-4a21-4e85-8795-2ac14df4f270"}
{"abstract": "One of the popular dynamics on complex networks is the epidemic spreading. An epidemic model describes how infections spread throughout a network. Among the compartmental models used to describe epidemics, the Susceptible-Infected-Susceptible (SIS) model has been widely used. In the SIS model, each node can be susceptible, become infected with a given infection rate, and become again susceptible with a given curing rate. In this paper, we add a new compartment to the classic SIS model to account for human response to epidemic spread. In our model, each individual can be infected, susceptible, or alert. Susceptible individuals can become alert with an alerting rate if infected individuals exist in their neighborhood. Due to a newly adopted cautious behavior, an individual in the alert state is less probable to become infected. The problem is modeled as a continuous-time Markov process on a generic graph and then formulated as a set of ordinary differential equations. The model is then studied using results from spectral graph theory and center manifold theorem. We analytically show that our model exhibits two distinct thresholds in the dynamics of epidemic spread. Below the first threshold, infection dies out exponentially. Beyond the second threshold, infection persists in the steady state. Between the two thresholds, infection spreads at the first stage but then dies out asymptotically as the result of increased alertness in the network. Finally, simulations are provided to support our findings.", "authors": ["Faryad Darabi Sahneh", "Caterina M. Scoglio"], "n_citation": 47, "references": ["08769ea7-cb1a-4873-afc2-f84f4047470d", "2be2f948-2433-486b-9ae5-6e824b2f2f4d", "38699cb5-4466-47b5-bc20-24a84848acbd", "4d858f36-1a2f-47d2-9c35-f3e6b1f1ec60", "4ffc1c2f-9057-4060-8429-67aa079543b5", "6f834439-9af6-4fff-be17-ea0316bb3323", "bf86ddf6-8594-47d4-a31a-b8603efe939c", "d0a8b7ff-a2d0-46b6-92ea-a4d23f73732c", "f99fe9a3-23e9-4b14-acfb-f57fcd613322"], "title": "Epidemic spread in human networks", "venue": "conference on decision and control", "year": 2011, "id": "20c57a52-e7bc-428e-bcc1-e1ea4af2460c"}
{"abstract": "SUMMARY#R##N##R##N#One of the most successful applications of textual analysis in software engineering is the use of information retrieval (IR) methods to reconstruct traceability links between software artifacts. Unfortunately, because of the limitations of both the humans developing artifacts and the IR techniques any IR-based traceability recovery method fails to retrieve some of the correct links, while on the other hand it also retrieves links that are not correct. This limitation has posed challenges for researchers that have proposed several methods to improve the accuracy of IR-based traceability recovery methods by removing the \u2018noise\u2019 in the textual content of software artifacts (e.g., by removing common words or increasing the importance of critical terms). In this paper, we propose a heuristic to remove the \u2018noise\u2019 taking into account the linguistic nature of words in the software artifacts. In particular, the language used in software documents can be classified as a technical language, where the words that provide more indication on the semantics of a document are the nouns. The results of a case study conducted on five software artifact repositories indicate that characterizing the context of software artifacts considering only nouns significantly improves the accuracy of IR-based traceability recovery methods. Copyright \u00a9 2012 John Wiley & Sons, Ltd.", "authors": ["Giovanni Capobianco", "Andrea De Lucia", "Rocco Oliveto", "Annibale Panichella", "Sebastiano Panichella"], "n_citation": 50, "references": ["034a7d94-fe65-4e9f-9dcf-e47fc99ac241", "0895c22d-37c5-4c8f-9202-a32ebd2cb0c0", "0bf79ef4-1a2d-4a1d-ad92-898d8ccaa9e9", "0c5da265-33c6-4ecd-bbff-c5fee610b7dc", "0d264cbf-06c2-4ce6-99d5-50a8f530059f", "0e5e87e1-c071-45d2-bf9a-e688580e3e8e", "0ffb6dae-ac4b-46da-a8f9-d995585f7fda", "1153960d-5a92-46aa-97c3-0007be7644b4", "18d170d5-8c41-49d9-b4ac-fdc29ea7599f", "292179d3-dcf1-4771-a46c-9a22d95085e3", "36769362-d5cc-438a-abf4-87912cc12166", "3c6cc30f-979e-44c8-9761-15b81c7f90cb", "3fd6eb96-c103-4d42-971f-9267a70cc14d", "4233ce65-062e-4c0a-86af-b0246dde5b40", "4438597e-1cb9-4598-b8f1-d31af85602ff", "49601194-0a44-43fa-86b3-b79c2cb4dedf", "4ac1ac19-8327-49f1-9997-93583128cf76", "4b768e94-c115-4baf-833e-f534e7d2226b", "4e5b785c-520d-4d1b-9b65-2b2f2e8dd2ce", "4e7d2e52-1e67-4cc0-baea-a78f9b7a0aed", "5b6d9828-4cdf-4746-9f1e-c2fcadc41232", "5c097a26-4f41-4dd2-8996-83ffd1e1ca3f", "5c5025e9-996e-40c2-9602-00cf423db798", "5d4f95ea-3887-4d26-b66a-ab44636a0d89", "6e198e5e-9655-418f-9abe-f2507c87ad91", "6e9f1065-4abb-4299-b578-97ed8f9549ce", "72b276fe-8d6e-4578-9819-9f828c1f95fc", "8ece8b79-6205-4901-bb9a-7cd2e12760f8", "9078ff97-8220-48e0-83a5-2fa4c220d517", "92b2e4a7-52bc-4e95-af3d-c624af0a962c", "951a3c0b-0588-45db-9ea9-f7d038f5eaa3", "97816301-b8f3-4859-bf28-319e4193b885", "9a520650-fce5-4f0e-8fe1-a8bcc00d6e14", "9fde07e1-7644-4641-a7b2-e41cb15e5f87", "a8168448-6c4e-4106-b22d-14c1eb6f6358", "abe5bd58-6d6d-48b0-bd0c-29ec7b163a2e", "ac14afe6-de4d-4056-b2ac-0f6e36f369a2", "aff93bf2-d26d-4c55-8ae2-706271f3adf8", "b0585082-67c2-4581-9bee-7d1d3119f350", "b08cb52f-8480-418a-8b83-ac8004cd508b", "b540827c-c24e-451b-ae04-be45b30740f4", "c0750866-66e3-4872-ba7c-bf48595d1c54", "c304f353-2c85-4a62-80e0-ba56d73bb9e2", "cad8d351-5900-45ea-815b-ee8900feb124", "ce4f4b12-dc05-4887-ac2d-b3183b42de35", "d01a5cbb-389b-4394-9a2d-0dcc4bad7fbf", "d10dbbd4-b74b-4df7-b39c-b0ac75ec13f1", "df1a0d04-0e77-4546-92e8-19e23c91847e", "e21d1d88-931f-478a-9547-06636fefd7c5", "e35e2b9d-1189-49a0-94f4-59f0961753b8", "e427f800-7a52-4845-a774-fd5c823634d2", "e5115d61-6459-4beb-88d1-603c9040c726", "e9abffef-c6bf-44da-a673-be480773dbbb"], "title": "Improving IR-based traceability recovery via noun-based indexing of software artifacts", "venue": "Journal of Software: Evolution and Process", "year": 2013, "id": "d65d7e8b-7f8e-4428-a166-725e57ca0e47"}
{"abstract": "Describes a case study where SofTrack (a software defect reporting and tracking system) was implemented using Internet technology in a geographically distributed organization. Four medium- to large-sized information systems with different levels of maturity are being analysed within the scope of this project. They belong to the Portuguese Navy's Information Systems Infrastructure and were developed using a typical legacy systems technology: COBOL with embedded SQL for queries in a relational database environment. This empirical software engineering pilot project has allowed the development of several techniques to help software managers to better understand, control and ultimately improve the software process. Among them are: the introduction of automatic system documentation, module complexity assessment, and effort estimation for software maintenance activities in the organization.", "authors": ["Ant\u00f3nio Silva Monteiro", "A. B. Almeida", "Miguel Goul\u00e3o", "Fernando Brito e Abreu", "Pedro Sousa"], "n_citation": 5, "references": ["02e0342a-33d3-4d3f-9f1d-b14081edbc39", "f49af7cc-1fd2-48f9-a1ad-5d50134bd611"], "title": "A software defect report and tracking system in an intranet", "venue": "conference on software maintenance and reengineering", "year": 1999, "id": "c50dae93-8e20-4789-ad41-bd36a571088c"}
{"abstract": "We give a decision procedure for the extensional equality of total Bohm trees presented by regular systems of recursion equations.", "authors": ["G\u00e9rard P. Huet"], "n_citation": 50, "references": ["1e508609-def0-4da6-bb96-5f3f61e009f5", "5b6beff3-2f97-4035-b01a-e5020008c212", "6fc9d62f-d0f7-4fbe-a1ff-ffd9ad952c61", "c9ae4b98-119f-4720-ae01-f2f62c664847", "d9085a57-35e2-4531-9eb9-815a5827f8e9"], "title": "Regular B\u00f6hm trees", "venue": "Mathematical Structures in Computer Science", "year": 1998, "id": "83d94cdc-333c-4b89-b8a5-002eb2db8652"}
{"authors": ["SangEun Kim", "William M. Lively", "Dick B. Simmons"], "n_citation": 36, "references": ["59dd769c-347b-4085-a5cc-7714999d440a", "8a671d1d-b0db-4cd3-a9c3-eb3c4e8003b6", "b8162efd-3659-4fe1-9aba-1904213ff02d", "d32786fc-ea8d-41f0-a803-5d00e550329c", "e3fb067a-1bc6-4e38-ab73-69280a783d0b"], "title": "An Effort Estimation by UML Points in Early Stage of Software Development.", "venue": "", "year": 2006, "id": "f3f01d34-7e4d-4775-be7b-5c4e0d7e75e2"}
{"abstract": "In exteroceptive automotive sensor fusion, sensor data are usually only available as processed, tracked object data and not as raw sensor data. Applying a Kalman filter to such data leads to additional delays and generally underestimates the fused objectspsila covariance due to temporal correlations of individual sensor data as well as inter-sensor correlations. We compare the performance of a standard asynchronous Kalman filter applied to tracked sensor data to several algorithms for the track-to-track fusion of sensor objects of unknown correlation, namely covariance union, covariance intersection, and use of cross-covariance. For the simulation setup used in this paper, covariance intersection and use of cross-covariance turn out to yield significantly lower errors than a Kalman filter at a comparable computational load.", "authors": ["Stephan Matzka", "Richard Altendorfer"], "n_citation": 50, "references": ["53ffb483-4072-4243-bbf8-1dadfc3b39b2", "ff7c17f9-525a-478f-b74a-ecba5e51d4a9"], "title": "A comparison of track-to-track fusion algorithms for automotive sensor fusion", "venue": "", "year": 2008, "id": "84bb62fb-1d52-401f-bbf5-036917609b18"}
{"abstract": "Pursuit-evasion games are an important problem in robotics and control, but games with many players are difficult to analyze and solve. This paper studies a game of multiple pursuers cooperating to capture a single evader in a bounded, convex, polytope in the plane. We present a decentralized control scheme based on the Voronoi partion of the game domain, where the pursuers jointly minimize the area of the evader's Voronoi cell. We prove that capturing the evader is guaranteed under this scheme regardless of the evader's actions, and show simulation results demonstrating the pursuit strategy.", "authors": ["Haomiao Huang", "Wei Zhang", "Jerry Ding", "Dusan M. Stipanovic", "Claire J. Tomlin"], "n_citation": 50, "references": ["1d32d1ad-b114-4bfa-a8ee-61861fcc5751", "45547961-fcd4-4d5d-a0b2-54e4c3c24de8", "58517286-37bb-4b47-a87f-dbfb5f77739d", "b7a95dd2-31dd-4061-8a56-3d22db6aab70", "d88ecc20-ce14-4b23-910a-1f8ccf105407", "e7376ed4-93c3-428b-9935-0130431cc960", "efed0c9f-6b90-4c0a-ba67-65d4b2bee0de"], "title": "Guaranteed decentralized pursuit-evasion in the plane with multiple pursuers", "venue": "conference on decision and control", "year": 2011, "id": "74d3db2d-44e9-4d48-b712-56f29bbde11c"}
{"authors": ["Roland Carl Backhouse", "Jaap van der Woude"], "n_citation": 68, "references": ["29ea3c4e-a8e5-4439-8eba-ec2248c370de", "455c8a3b-92aa-404e-bf87-f098a36981ed", "8b2da2f9-0f7a-4d92-8b52-9c7a43312b96", "994172c4-0bf5-4049-bcf1-181c7771af61", "a03dab96-b335-4f45-9031-0fc0c7984e50", "da0d1f24-01ca-4dc7-88eb-2d7a099fe0af"], "title": "Demonic Operators and Monotype Factors", "venue": "Mathematical Structures in Computer Science", "year": 1993, "id": "cf8f1ac2-e177-4ef1-bcbc-7f46b87fc940"}
{"abstract": "An attempt is made to relate various notions of duality used in mathematics with the denotational semantics of linear logic. The author proposes a naive semantics for linear logic that, in a certain sense, generalizes various notions such as finite-dimensional vector spaces, topological spaces, and J.-Y. Girard's (1987) coherence spaces. A game consists of a set of vectors (or strategies), a set of forms (or co-strategies) and an evaluation bracket. This is enough to interpret the connectives of full propositional linear logic, including exponentials. >", "authors": ["Yves Lafont", "Thomas Streicher"], "n_citation": 89, "references": ["1bf17d1d-52cd-48da-858b-8c9c210b5864", "39987ba1-5da1-4946-b151-44d00869624c", "69018a18-02ca-479b-8496-7e17ca432eda", "aa44dd48-8e1b-4c0e-b79e-95e3bf683345", "eff2f7a1-f9bb-47a8-be14-81a7a8548cc5"], "title": "Games semantics for linear logic", "venue": "logic in computer science", "year": 1991, "id": "4491bc5d-997f-48a7-9952-7b3ccbc197f2"}
{"abstract": "Wireless sensor and actuator networks (WSANs) bring many benefits to industrial automation systems. When a control system is integrated by a WSAN, and particularly if the network scale is large, distributed communication and control methods are quite necessary. However, unreliable wireless and multihop communications among sensors and actuators cause challenges in designing such systems. This paper proposes and evaluates a new distributed estimation and collaborative control scheme for industrial control systems with WSANs. Extensive results show that the proposed method effectively achieves control objectives and maintains robust against inaccurate system parameters. We also discuss how to dynamically extend the scale of a WSAN with only local adjustments of sensors and actuators.", "authors": ["Jiming Chen", "Xianghui Cao", "Peng Cheng", "Yang Xiao", "Youxian Sun"], "n_citation": 187, "references": ["092fdfd5-7e57-4ac6-bd34-e3eb7d0ebaa4", "0aef08a4-9fb6-41df-a465-94dd331e7825", "1d749975-9810-411f-8e0b-91e28ba990b9", "1dc65be7-f118-4b93-a36f-b6dd1e4f64e9", "250ac8cf-7f81-4e2b-82d6-5699fc66d668", "29424b9c-c448-4679-8472-044e701a11ea", "2a9a883a-f551-4929-a279-3b6843c0ae4b", "33adcea6-f2db-4f70-b46b-4f27b46eab38", "36386088-54ee-474d-9182-5dda6f772cd5", "56d78356-c4a0-4911-b3af-b3d9b52fd08e", "57824f11-595e-46fb-9d14-3f493c17c0c7", "5a8fe3a4-bb70-4b96-8064-23f4a36fe9cd", "64bcf959-0df8-40c8-8beb-306c4f869c0d", "71891347-d90a-47fa-962f-43ffcc5a41f2", "722d6fd5-629d-4c81-b802-5b99dedeaa51", "af423ee5-e6de-4a55-aa51-b0c1ab523149", "b956592d-4ba1-4fff-a3e3-49146207b817", "c0be8771-8920-448e-9b84-e94295dc1859", "c2a18866-9c45-4f30-b2e3-e0136d2a81ac", "c87e2369-88c0-4976-9d4c-3ef1879722e6", "c8ae92c9-d82a-4a8e-a817-215980e8308c", "da34b65b-fd81-4c89-ac6f-cc94601c0839"], "title": "Distributed Collaborative Control for Industrial Automation With Wireless Sensor and Actuator Networks", "venue": "IEEE Transactions on Industrial Electronics", "year": 2010, "id": "48f39f8e-eef7-45ac-9b04-dcb7b8128a90"}
{"abstract": "A modified genetic algorithm is used to solve the parameter identification problem for linear and nonlinear IIR digital filters. Under suitable hypotheses, the estimation error is shown to converge in probability to zero. The scheme is also applied to feedforward and recurrent neural networks. >", "authors": ["Leehter Yao", "William A. Sethares"], "n_citation": 283, "references": ["1900717e-7286-4695-8517-1e1e1300e90b", "41cf5b06-f56f-474b-8af8-dac3d1a2c669", "66e71d2a-01e3-4952-9c05-62675f2e8f6b", "7705dac0-64a6-433c-bcac-8b421f902918", "7e1eeb34-62a7-41b7-8c1d-9cce0b528102", "82a9cd51-eb10-4769-909f-c8f2748cc424", "91b5d025-7815-4ad2-959f-6df66e0d093b", "ae79a9fd-860c-421e-9966-928b5d4039a6", "b9778d6f-a78f-407d-9060-5345f312f9f7", "bc7e71f9-aa95-47d9-8857-9d4834a37d05"], "title": "Nonlinear parameter estimation via the genetic algorithm", "venue": "IEEE Transactions on Signal Processing", "year": 1994, "id": "c9d956e7-2125-461d-97c5-ad070c5bad36"}
{"abstract": "Knowledge discovery from software engineering measurement data is essential in deriving the right conclusions from experiments. Various data analysis techniques may provide data analysts with different and complementary insights into the studied phenomena. In this paper, two data analysis techniques \u2013 Rough Sets (RSs) and Logistic Regression (LR) are compared, from both the theoretical and the experimental point of view. In particular, the empirical study was performed as a part of the ESPRIT/ESSI project CEMP on a real-life maintenance project, the DATATRIEVE\u2122 project carried out at Digital Engineering Italy. We have applied both techniques to the same data set. The goal of the experimental study was to predict module fault-proneness and to determine the major factors affecting software reliability in the application context. The results obtained with either analysis technique are discussed and compared. Then, a hybrid approach is built, by integrating different and complementary knowledge obtained from either approach on the fault-proneness of modules. This knowledge can be reused in the organizational framework of a company-wide experience factory.", "authors": ["Sandro Morasca", "G\u00fcnther Ruhe"], "n_citation": 37, "references": ["089b17ee-58d8-4f2c-a20a-f11284da3d60", "412981c8-979b-4353-a466-6030181cecab", "5437a4d9-6389-48f4-af35-134fc38833b0", "83d54f51-723b-4ab2-9ef7-b844797dacc1", "a6ee8425-3dd3-40fd-b9bb-214632f04a1a", "e5eae26c-f083-4b75-974a-765fcf210f9c"], "title": "A hybrid approach to analyze empirical software engineering data and its application to predict module fault-proneness in maintenance", "venue": "Journal of Systems and Software", "year": 2000, "id": "4ff766be-04a7-4f1a-8cf7-d6bc0ce7912a"}
{"abstract": "The dynamics of a quadrotor are a simplified form of helicopter dynamics that exhibit the same basic problems of underactuation, strong coupling, multi-input/multi-output design, and unknown nonlinearities. Control design for the quadrotor is more tractable yet reveals corresponding approaches for helicopter and UAV control design. In this paper, a backstepping approach is used for quadrotor controller design. In contrast to most other approaches, we apply backstepping on the Lagrangian form of the dynamics, not the state space form. This is complicated by the fact that the Lagrangian form for the position dynamics is bilinear in the controls. We confront this problem by using an inverse kinematics solution akin to that used in robotics. In addition, two neural nets are introduced to estimate the aerodynamic components, one for aerodynamic forces and one for aerodynamic moments. The result is a controller of intuitively appealing structure having an outer kinematics loop for position control and an inner dynamics loop for attitude control. The control approach described in this paper is robust since it explicitly deals with unmodeled state-dependent disturbances and forces without needing any prior knowledge of the same. A simulation study validates the results obtained in the paper.", "authors": ["Abhijit Das", "Frank L. Lewis", "Kamesh Subbarao"], "n_citation": 187, "references": ["143a18d1-5910-4568-8ac9-140fce679f71", "43e2bbe7-20bc-48cf-a8ee-328b8b4392be", "4411de02-614a-46a2-bee2-d61a33b2037d", "4d18eb0d-3590-4561-8c2f-5c89fd5d45b5", "86001d57-39be-4972-a05d-8b2eb8aa82de", "8c1a9c4a-f785-4233-940b-7abadec58798", "8d7bb750-adbb-4a71-813f-09fdfab8f7d0", "9dc05797-72e5-46bc-8af0-5ed16d5565a0", "bcac4659-3dc4-4d8e-9254-440ac1ea27a7", "cdc6b4fa-787e-4064-ae88-f6433c603921", "e19cf0a1-2f62-4acd-96d0-cdda4d9838cc"], "title": "Backstepping Approach for Controlling a Quadrotor Using Lagrange Form Dynamics", "venue": "Journal of Intelligent and Robotic Systems", "year": 2009, "id": "6c1a8e12-9d27-440e-99e3-01acf90583ee"}
{"abstract": "An automated algorithm for tissue segmentation of noisy, low-contrast magnetic resonance (MR) images of the brain is presented. A mixture model composed of a large number of Gaussians is used to represent the brain image. Each tissue is represented by a large number of Gaussian components to capture the complex tissue spatial layout. The intensity of a tissue is considered a global feature and is incorporated into the model through tying of all the related Gaussian parameters. The expectation-maximization (EM) algorithm is utilized to learn the parameter-tied, constrained Gaussian mixture model. An elaborate initialization scheme is suggested to link the set of Gaussians per tissue type, such that each Gaussian in the set has similar intensity characteristics with minimal overlapping spatial supports. Segmentation of the brain image is achieved by the affiliation of each voxel to the component of the model that maximized the a posteriori probability. The presented algorithm is used to segment three-dimensional, T1-weighted, simulated and real MR images of the brain into three different tissues, under varying noise conditions. Results are compared with state-of-the-art algorithms in the literature. The algorithm does not use an atlas for initialization or parameter learning. Registration processes are therefore not required and the applicability of the framework can be extended to diseased brains and neonatal brains", "authors": ["Hayit Greenspan", "Amit Ruf", "Jacob Goldberger"], "n_citation": 235, "references": ["3630ebbb-a82a-435e-a5eb-b33d9fad26c9", "39e04ded-f269-4eb9-8621-4873a0b305e2", "5e6645e0-cec5-427e-a52b-92756b114f47", "66911338-9ddb-4b88-a911-da2690e4d3aa", "7521efc1-d7b0-4e0a-8791-785b6d72dcc7", "764c9297-d384-44c4-bc4b-cbe1caac87c8", "84bd9956-b8fb-47ae-ab6d-4e0cac4aaf17", "88c59eac-9008-426d-a294-304b73b5d0db", "897b0d64-16f8-4abe-b3a6-19cad2753449", "8cd5ecbf-bbe9-4895-a5d9-5a1b705dee76", "8d6902ea-0d4c-4e9f-930e-2ba2c6ea88ee", "c6dd1155-2ec9-4371-96dc-3ee5f42387ff", "dc24492b-616c-4a46-b5b8-57e190642a46", "dfb8bf07-b93b-44d1-bd5a-c2329aac465d", "ef326584-6d26-48be-bb42-750125182a4a", "f2f9b214-3861-4aec-8178-ce26238d386d", "f6393bf5-26fd-4bf4-965f-73fc0257cddc", "fd4e57ae-0a9e-421f-b866-fad0fe1e3c83"], "title": "Constrained Gaussian mixture model framework for automatic segmentation of MR brain images", "venue": "IEEE Transactions on Medical Imaging", "year": 2006, "id": "b79c2f92-0a7e-430c-97ac-a41f5a430394"}
{"abstract": "Introduction - benefits of object-orientation, object-oriented programming and BETA introduction to basic concepts - perspectives on programming, object-oriented programming objects and patterns - overview, reference attributes, pattern attributes repetitions - reallocation, assignment and slice, the text pattern imperatives - introduction to evaluations, for-imperative, if-imperative, labels and jump imperatives, a large example, assignment and equality, computed references and computed remote name, detailed description of evaluations, block structure and scope rules, object kinds and construction modes sub-patterns - specialization by simple inheritance, specialization of actions, enter/exit-parts for sub-patterns, the object patterns, summary, qualifications and scope rules virtual procedure patterns, continued extension of a virtual patterns, more examples of using virtual patterns, benefits of virtual patterns, summary block structure - simple block structure, class grammar, flight reservation example virtual class patterns - directly qualified virtual class patterns, general parameterized class patterns part objects and reference attributes - part objects, reference attributes pattern variables - declaration of pattern variables, example procedural programming - functional classes, higher order procedure patterns, virtual classes and genericity deterministic alternation - execution stacks, generators, components and recursive procedure patterns, abstract super-patterns concurrency - concurrent execution of components, monitors, direct communication between components, compound systems, readers and writers problem non-determinstic alternation - alternating execution of components, a distributed calendar, bounded buffer, a simple game exception handling - simple exceptions, recovery, partial recovery, handlers for procedure patterns, system exceptions, language-defined exceptions, advanced design of exception patterns modularization - fragments, separation of interface and implementation, alternative implementations, programme variants, using several libraries, visibility and binding rules (part contents).", "authors": ["Ole Lehrmann Madsen", "Birger M\u00f8-Pedersen", "Kristen Nygaard"], "n_citation": 646, "references": ["021e25cc-cb21-497b-85d0-757344ce61ac", "031cd036-b7cd-4432-adf6-e05aee97ed50", "0c5c8cf3-8767-47e6-bbdb-5dd85b0c0ef0", "182cd2f4-253a-45ed-b4b9-e7f2affbb70d", "1b42ac20-4eb4-4833-8a00-e14abbb647b1", "1d754838-cb9c-4788-be5f-3ad94624d40e", "2a0380d0-5659-4dfd-8ea9-fcfdecc7de53", "33bb3d3b-cf44-481b-a6a7-23c7cc2dd219", "35cc4d32-bfba-41b2-875c-c1deec8f07ac", "37b80aef-fa63-4f46-a82f-e0c2899a89d3", "50689679-8346-48f2-8d70-4dfd29f8b470", "5b55e079-5a57-4f49-b9a9-e328f3049d7e", "62f6b589-ed1b-4606-a286-d3202f0166e3", "7ee68c74-feaf-4a24-ad20-121af80bfee5", "8213d2e3-05cb-49f2-8cbd-2c22f373dc96", "822cdc63-a2bc-4133-abb0-19a884e061e9", "93812939-66d9-4b0b-9137-d08f62dea283", "9b7b4b4b-a5db-43f1-9e16-1ebe90152a93", "ab6b51b8-61ac-4e95-b5fa-e0c1b055ecb1", "b4e2677a-a9e6-46c8-a328-47ed4813d336", "c82b2c72-f485-4e8e-9a89-cf2f07a9a4d6", "c9daf25c-1900-4b85-be48-b81755c6486f", "cf5a5bb8-bf86-49ec-aabc-f8952f7e12c6", "e3ba6428-74ba-41c2-9bd7-148a2c6308a8", "e5c19d6e-0e69-4582-bf6b-d4b0780f2bbb", "e65d1b23-a595-4a2e-acb1-57a138d08ef1", "f1cc35e4-4f18-488a-bb4e-5ac4ea96f385", "f3f11528-372c-4e1f-9e64-29dfa3c4215d", "fbcad938-9d40-4bd7-b7c5-2cf040dc0bec", "fd9270c1-2262-419c-ba5b-920ad2f8ea0d"], "title": "Object-oriented programming in the BETA programming language", "venue": "", "year": 1993, "id": "e2285510-fd4d-4b40-89ca-627a9ce7b76c"}
{"authors": ["Jos\u00e9 Cuena", "Josefa Z. Hernandez", "Martin Molina"], "n_citation": 7, "references": ["8663d398-6253-41e1-ab73-73d593a781f5", "8c05f0b1-1800-44a6-a908-d71b84153590", "b8a5677a-128b-4bf6-98b3-5d1f80f3346d", "d55b22d6-2cf2-48c2-ba9c-ae3cf440c3ad"], "title": "An Intelligent Model for Road Traffic Management in the Motorway Network Around Barcelona", "venue": "", "year": 1996, "id": "d6bab02c-c8a3-44c8-8c5e-96a9a40ba872"}
{"abstract": "The Busy Beaver is an interesting theoretical problem proposed by Rado in 1962, in the context of the existence of non computable functions. In this paper we propose an evolutionary approach to this problem. We will focus on the representational issues, proposing alternative ways of codifying and interpreting Turing Machines, designed to take advantage of the existence of sets of equivalent Turing Machines. The experimental results show that these alternatives provide improvement over the \"standard\" genetic codification.", "authors": ["Penousal Machado", "Francisco Baptista Pereira", "Amilcar Cardoso", "Ernesto Costa"], "n_citation": 14, "references": ["e7a4742f-e39c-4271-8028-038141141a91"], "title": "Busy Beaver - The Influence of Representation", "venue": "european conference on genetic programming", "year": 1999, "id": "26a29858-92ff-4f4e-9fec-6f7e4b8160c5"}
{"authors": ["Yael Moses", "Yael Adini", "Shimon Ullman"], "n_citation": 274, "references": ["746cb9e3-7675-4a92-b2b1-ec28b70366be", "8ec028ec-a8d0-4963-9e6f-231f0d6104ed", "adda2917-0ddc-4d6e-b7b3-86c043022042", "af7a495b-16f5-443d-a7d2-b904e2ae02ab", "c7e45d01-93dc-4912-a686-9191d1a91e81", "d9215ef1-ba4b-4a59-bd6f-b6900dbf8ae3", "f374528d-0eeb-475d-9745-00290b067292"], "title": "Face recognition: the problem of compensating for changes in illumination direction", "venue": "european conference on computer vision", "year": 1994, "id": "cacef546-cc48-4fb9-814f-9c12141662d8"}
{"abstract": "We introduce a new approach to probabilistic logic programming in which probabilities are defined over a set of possible worlds. More precisely, classical program clauses are extended by a subinterval of [0,1] that describes a range for the conditional probability of the head of a clause given its body. We then analyze the complexity of selected probabilistic logic programming tasks. It turns out that probabilistic logic programming is computationally more complex than classical logic programming, More precisely, the tractability of special cases of classical logic programming generally does not carry over to the corresponding special cases of probabilistic logic programming. Moreover, we also draw a precise picture of the complexity of deciding and computing tight logical consequences in probabilistic reasoning with conditional constraints in general. We then present linear optimization techniques for deciding satisfiability and computing tight logical consequencesof probabilistic logic programs. These techniques are efficient in the special case in which we have little relevant purely probabilistic knowledge. We finally show that probabilistic logic programming under certain syntactic and semantic restrictions is closely related to van Emden's quantitative deduction, and thus has computational properties similar to calssical logic programming. Based on this result, we present an efficient approximation technique for probabilistic logic programming.", "authors": ["Thomas Lukasiewicz"], "n_citation": 107, "references": ["0405733d-d80d-4cfa-b142-3b66661ad71d", "04add8a0-e7af-47f8-a996-56109557d741", "0501ff3b-be16-4a28-bb87-2ceec73382c7", "20405b87-b1dd-445a-a8a2-1e820548f000", "2061c78a-cdb7-40d3-9e0f-905dc6635f6f", "20c92498-e000-4781-a9b5-5d49b59b6eba", "2126d68d-5e51-4a12-80d5-6b522d71a5d1", "2341982e-efab-4ddc-94e9-be4fb722d41b", "25bdb92d-0f13-4b33-a02b-8a471796c57d", "27ed4efc-5acd-4c99-8c3b-549054613d72", "3297978e-fce8-49a0-8d58-4ea87b011883", "4589bd55-00fa-4b9c-9db4-823cadf8ca56", "469c5fcb-d1d0-4edc-8b77-c4abb92e03d6", "48511e16-80f0-436e-be39-83c05cf0d8bc", "4a35cbc7-2ca5-482e-b039-1e2be9055c3e", "4a41abc2-f115-41aa-8dc9-6af04dc2735d", "4e8fb582-c37a-44b1-a482-80e5d4f83b74", "5dff42ad-e16b-4b6a-bce3-fe808d109177", "5fe8b0bd-a552-4ede-8b43-f2c56a6e067f", "6dd4230e-cd7a-4977-a594-713d52893187", "779ae1cc-cbf8-4043-87b3-8a972b173f21", "84d9ebd3-4756-4c17-b2e6-b97a64708d2c", "8b89fca4-f22c-42dd-9294-5429e1d5c7b6", "8ed7c007-dcdc-4d28-9e8b-8d9bc08e17b4", "910983ab-b4c7-4aec-8ad8-4ff49ff478dd", "9b139848-60ff-435d-838f-903010360ca6", "a25c2ac9-ac0d-4c71-a629-9a9180963a82", "a2c62e55-daee-49eb-b3aa-55e6250efee3", "af3dcf0c-6e6f-4190-a9d6-9a9d2551e378", "b14b6ef0-2c86-497a-9dcb-0f19fa73e383", "b460fca8-b82e-457f-9ddd-e3ceb772a39a", "c1cdab92-ca97-491f-a447-1452b6f31d57", "c2e54a08-5059-43dc-a4c1-a1c8572a1247", "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706", "df8c9d07-997b-4f7b-9cf0-341ec8642e75", "e5813213-5ff9-4684-bf67-98fba7f6a1ba", "ed85998f-2c49-48b7-b500-845f5b2260bd", "f5d094b3-48c6-4bc5-9753-7e3daa1342ed", "f685e111-15cf-46e2-bfaf-0536ce09ce81", "f6a63193-3b6e-4ba3-9bd9-492282fd0248", "f70e5839-8e0a-4857-9776-065a98a5199e"], "title": "Probabilistic logic programming with conditional constraints", "venue": "ACM Transactions on Computational Logic", "year": 2001, "id": "50fc7424-b2ef-441e-8396-9f52f85d70b0"}
{"abstract": "We show how the electronic cash scheme in [Fer93a] can be extended to provide n-spendable coins. Furthermore, we show how observers can be incorporated in the protocols to provide prior restraint against double spending by the user, instead of just detection after the fact.", "authors": ["Stefan Brands"], "n_citation": 44, "references": ["0067011d-0ba8-4987-9aa3-cc4f5fa4f83a", "06c7458e-aa1c-4b6b-b400-e2416cd26897", "8407778d-e0dc-4ba3-a91f-1bc7dac81690", "93b84c61-0636-4d00-8d2b-ce6353f8c8d6", "c03d2f84-d383-4ba9-a430-c943bf1f9de4", "d893a420-a00d-4756-b447-2862ed178eaa"], "title": "Untraceable Off-line Cash in Wallets with Observers (Extended Abstract)", "venue": "international cryptology conference", "year": 1993, "id": "a30a59d9-7d0d-47a2-9b9d-767ad8554ffb"}
{"abstract": "My approach to computer vision is best characterized as inverse computer graphics. In computer graphics, the world is represented in sufficient detail so that the image forming process can be numerically simulated to generate synthetic television images; in the inverse, perceived television pictures (from a real TV camera) are analyzed to compute detailed geometric models.", "authors": ["Bruce G. Baumgart"], "n_citation": 624, "references": ["02bebf6b-6365-4ad7-92e7-c9283367d102"], "title": "A polyhedron representation for computer vision", "venue": "", "year": 1975, "id": "816a534f-a386-46a0-b8b7-224d9af9c515"}
{"abstract": "The World Health Organization is using Semantic Web technologies in the development of the 11 th revision of the International Classification of Diseases (ICD-11). Health officials use ICD in all United Nations member countries to compile basic health statistics, to monitor health-related spending, and to inform policy makers. In 2010, we published a paper in the ISWC In Use track reporting on our experience in the first six months with building and deploying iCAT, a Semantic Web platform to support the collaborative authoring of ICD-11. Three years since our original publication, 270 domain experts around the world have used iCAT to author more than 45,000 classes, to perform more than 260,000 changes, and to create more than 17,000 links to external medical terminologies. During the last three years, the collaboration processes, modeling and tooling have evolved significantly, and we have learned important lessons, which we will report in this paper. We describe the benefits of using semantic technologies as an infrastructure, which proved to be critical in making support for this rapid evolution possible. To our knowledge, this effort is the only real-world project supporting the collaborative authoring of ontologies at this scale, and which, at the same time, has a high visibility and impact for the health care around the world. We believe that the insights that we gained and the lessons that we learned after four years into this large-scale project will be useful to others who need to support similar collaborative projects.", "authors": ["Tania Tudorache", "Csongor Nyulas", "Natalya Fridman Noy", "Mark A. Musen"], "n_citation": 50, "references": ["5bf9ed40-8930-4a5e-9965-6c604b336f0e", "656a895d-f6f1-488c-a070-112681aef086", "74959223-ea16-471e-a914-cc055ab05bf7", "b19c2552-33f5-41b9-9eba-a9e913cd2c42", "c2222caa-fa8c-42a7-816e-764532e67e17", "d8407fa8-c581-455c-9cd5-2ba84389fba1", "eb4e10a1-0f06-4c38-925f-1fa25a0fa775", "ee86e4d3-54a3-413f-bd6f-193165daed74"], "title": "Using Semantic Web in ICD-11: Three Years Down the Road", "venue": "international semantic web conference", "year": 2013, "id": "25053a14-aa63-4ab7-a541-5f36d93670d9"}
{"abstract": "For part I see ibid., 26-37. The evolutionary approach to multiple function optimization formulated in the first part of the paper is applied to the optimization of the low-pressure spool speed governor of a Pegasus gas turbine engine. This study illustrates how a technique such as the multiobjective genetic algorithm can be applied, and exemplifies how design requirements can be refined as the algorithm runs. Several objective functions and associated goals express design concerns in direct form, i.e., as the designer would state them. While such a designer-oriented formulation is very attractive, its practical usefulness depends heavily on the ability to search and optimize cost surfaces in a class much broader than usual, as already provided to a large extent by the genetic algorithm (GA). The two instances of the problem studied demonstrate the need for preference articulation in cases where many and highly competing objectives lead to a nondominated set too large for a finite population to sample effectively. It is shown that only a very small portion of the nondominated set is of practical relevance, which further substantiates the need to supply preference information to the GA. The paper concludes with a discussion of the results.", "authors": ["Carlos M. Fonseca", "Peter J. Fleming"], "n_citation": 426, "references": ["6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "7f903659-26c5-4f3a-827e-237913b2fdaa", "858a4272-c06a-4689-82e8-ac71be713972", "957d98db-ad29-41a6-bc3a-f8d4e704228f", "b0970783-382f-4109-93a2-3b5dc8b4f97f", "b8be5256-00f7-4d83-bd1b-f13bfcdf0673", "c061069f-29d1-46d4-9974-dede8d5461f9", "c6553383-a300-4d96-b68a-398ea1b4389a", "f81dfe60-7ce5-4a65-b43e-4b3de9f5ca54"], "title": "Multiobjective optimization and multiple constraint handling with evolutionary algorithms. II. Application example", "venue": "systems man and cybernetics", "year": 1998, "id": "8666d3c4-737c-48ef-b1bd-a65206527ba9"}
{"abstract": "In the discrimination problem the random variable \\theta , known to take values in {1 ,\\ldots ,M} , is estimated from the random vector X taking values in {\\bfR}^{d} . Ali that is known about the joint distribution of (X,O) is that which can be inferred from a sample (X_{1} , \\theta_{1}, \\ldots , (X_{n}, \\theta_{n}) of size n drawn from that distribution. A discrimination rule is any procedure which determines a decision \\hat{\\theta} for \\theta from X and (X_{1},\\theta_{1}) , \\ldots , (X_{n}, \\theta_{n}) . The rule is called k -local if the decision \\hat{\\theta} depends only on X and the pairs (X_{i}, \\theta_{i}) ,for which X_{i} is one of the k closest to X from X_{1} , \\ldots ,X_{n} . If L_{n} denotes the probability of error for a k -local rule given the sample, then estimates \\hat{L}_{n} of L_{n} , are determined for which P {| \\hat{L}_{n} - L_{n} \\geq \\epsilon} \\exp (- Bn) , where A and B are positive constants depending only on d , M , and \\epsilon .", "authors": ["Luc Devroye", "Terry J. Wagner"], "n_citation": 81, "references": ["5880d47f-8b99-416d-a743-28d6b49f7ba9", "b1d3ac8b-6490-4d2f-bce6-5e0727b3afb1", "df31160b-8480-4a39-aa8e-0242c0a1ce9e"], "title": "Distribution-free inequalities for the deleted and holdout error estimates", "venue": "IEEE Transactions on Information Theory", "year": 1979, "id": "5461d831-b487-4411-8254-b5b92c978b48"}
{"abstract": "This paper presents a new algorithm for Boosting the performance of an ensemble of classifiers. In Boosting, a series of classifiers is used to predict the class of data where later members of the series concentrate on training data that is incorrectly predicted by earlier members. To make a prediction about a new pattern, each classifier predicts the class of the pattern and these predictions are then combined. In standard Boosting, the predictions are combined by weighting the predictions by a term related to the accuracy of the classifier on the training data. This approach ignores the fact that later classifiers focus on small subsets of the patterns and thus may only be good at classifying similar patterns. In RegionBoost, this problem is addressed by weighting each classifier's predictions by a factor measuring how well that classifier performs on similar patterns. In this paper we examine several methods for determining how well a classifier performs on similar patterns. Empirical tests indicate RegionBoost produces gains in performance for some data sets and has little effect on others.", "authors": ["Richard Maclin"], "n_citation": 50, "references": ["056e5059-9864-479b-8a2a-fb1cd3d2dd32", "0f115eea-2272-431f-9f21-6d6789b2bbc9", "11685c96-7a83-48ec-af6d-8b2910ba6311", "1d05a629-80c3-486a-ade1-36fd8dda5d01", "1d48d76c-e82c-4ba5-a354-5db0b1ce05da", "3213ae6b-6091-41e6-9a25-5eeb48600d90", "3704f939-09a2-4e9f-b851-1261bcd310df", "46c4319f-e9a5-4ad2-8f9a-62c15172c250", "5880d47f-8b99-416d-a743-28d6b49f7ba9", "6c68311c-2745-446f-9c09-df4632392a78", "6f036b38-1438-4cfb-abdb-fcadd80792d6", "84806dbe-fa0e-47c0-b1f2-00fb2eed25a7", "e61b6fa6-6e08-47e2-ae77-adcde48e750e"], "title": "Boosting classifiers regionally", "venue": "national conference on artificial intelligence", "year": 1998, "id": "3576d69e-ac28-4b82-a880-13e3a13d566e"}
{"abstract": "In this paper we investigate the effect of local error recovery vs. end-to-end error recovery in reactive protocols. For this purpose, we analyze and compare the performance of two protocols: the Dynamic Source Routing protocol (DSR[2]), which does end-to-end error recovery when a route fails and the Witness Aided Routing protocol (WAR[1]), which uses local correction mechanisms to recover from route failures. We show that the performance of DSR degrades extremely fast as the route length increases (that is, DSR is not scalable), while WAR maintains both low latency and low resource consumption regardless of the route length.", "authors": ["Ionu\u0163 D. Aron", "Sandeep K. S. Gupta"], "n_citation": 45, "references": ["0d4d0363-07b5-43b6-976d-955e96044709", "60fb0dc2-bde3-4714-948e-de0ed12ab460", "7c9f8cd8-d0ef-4954-b4db-4a6c803459c2", "7f7fd004-7853-4c6c-b120-e9a9b9ea4821", "83a2eb55-b330-4e0c-8dc9-05e9466d5028", "94b8b73c-42f3-476c-9d4d-ea4ac7a4b78e", "e4cc024f-f42d-4cea-96f2-36ebf00e6724"], "title": "Analytical comparison of local and end-to-end error recovery in reactive routing protocols for mobile ad hoc networks", "venue": "modeling analysis and simulation of wireless and mobile systems", "year": 2000, "id": "fdf68450-b3ea-4d0e-9b83-35a6edb6f14c"}
{"abstract": "The bias of the finite-sample nearest neighbor (NN) error from its asymptotic value is examined. Expressions are obtained which relate the bias of the NN and 2-NN errors to sample size, dimensionality, metric, and distributions. These expressions isolate the effect of sample size from that of the distributions, giving an explicit relation showing how the bias changes as the sample size is increased. Experimental results are given which suggest that the expressions accurately predict the bias. It is shown that when the dimensionality of the data is high, it may not be possible to estimate the asymptotic error simply by increasing the sample size. A new procedure is suggested to alleviate this problem. This procedure involves measuring the mean NN errors at several sample sizes and using our derived relationship between the bias and the sample size to extrapolate an estimate of the asymptotic NN error. The results are extended to the multiclass problem. The choice of an optimal metric to minimize the bias is also discussed.", "authors": ["Keinosuke Fukunaga", "Donald M. Hummels"], "n_citation": 75, "references": ["2541f284-dca3-47d2-a2c6-75d53ff3cebc", "5880d47f-8b99-416d-a743-28d6b49f7ba9", "7a701aba-1aba-4f46-a309-961cf590d210", "86b9e434-7b8e-4948-8ce8-9bfbc1b51842", "b3f0ded2-5823-4231-9a3a-f36e2bb67427", "b53ca8a0-9d60-4911-9bfc-14f9bad19655", "f2cd892a-055d-4598-858b-7318dde08f72", "fafc0195-8180-4993-bbc7-8fab3618b392"], "title": "Bias of Nearest Neighbor Error Estimates", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 1987, "id": "2250f0e3-f301-4b59-a049-ca3bec008787"}
{"abstract": "We investigate the optimization of extended relational queries used in systems holding, for example, spatial, multimedia or constraint data. For such queries we must account for the built-in relations specific to the kind of data, and application dependent relationships between different relations. We show that the constraint database perspective and the use of constrained tuple-generating dependencies provides a general framework in which to address semantic query optimization for these queries. We establish some sufficient conditions for query transformations involving the introduction of relations, extending work in the literature for conventional databases. We introduce semantic query partition (SQP) as a useful technique for optimizing queries with expensive operations, and investigate the problem of generating subqueries, which is central to the use of SQP.", "authors": ["Michael J. Maher", "Junhu Wang"], "n_citation": 50, "references": ["01677f12-4e52-438e-aa26-33dd39ddbd7d", "2c862a7f-8b4f-46dc-ac13-ad52a8f3bcec", "4fdd4ebe-cf78-40cc-b19a-ef0a6664e236", "627c8c23-756c-471e-9f48-e243d595e1cf", "d7fe4e70-e33e-41dd-b00a-54ca59afaa31", "db3a7857-e105-495b-831f-ed80bfc885fb", "df60dee5-da2b-435a-a816-68e757153805", "e0dd644a-9fef-4d21-99f5-a77bd772b389"], "title": "Optimizing Queries in Extended Relational Databases", "venue": "database and expert systems applications", "year": 2000, "id": "2c2f5685-bd6c-4595-ae26-21ff682b750e"}
{"abstract": "The Software Engineering Initiative, process-improvement program undertaken by the Software Systems Laboratory in Raytheon's equipment division in mid-1988 is reviewed. The three phases of the program are the process-stabilization phase, in which the emphasis is on distilling the elements of the process actually being used and progressively institutionalizing it across all projects, the process-control phase, in which emphasis shifts to instrumenting projects to gather significant data and analyze the data to understand how to control the process, and the process-change phase, in which the emphasis is on determining how to adjust the process as a result of measurement analysis and how to diffuse the new methods among practitioners. It is shown that the process-improvement initiative has improved the equipment division's bottom line, increased productivity, and changed the corporate culture. Much of the savings came from reducing rework. >", "authors": ["Raymond Dion"], "n_citation": 107, "references": ["bdc94277-8125-4aff-bbcd-b5e6e1fda167"], "title": "Process improvement and the corporate balance sheet", "venue": "IEEE Software", "year": 1993, "id": "d41d379f-17e2-4c8a-99f2-c10d4f26c8dd"}
{"abstract": "This paper deals with robust synchronization of uncertain multi-agent networks. Given a network with for each of the agents identical nominal linear dynamics, we allow uncertainty in the form of additive perturbations of the transfer matrices of the nominal dynamics. The perturbations are assumed to be stable and bounded in  H  \u221e -norm by some a priori given desired tolerance. We derive state space formulas for observer based dynamic protocols that achieve synchronization for all perturbations bounded by this desired tolerance. It is shown that a protocol achieves robust synchronization if and only if each controller from a related finite set of feedback controllers robustly stabilizes a given, single linear system. Our protocols are expressed in terms of real symmetric solutions of certain algebraic Riccati equations and inequalities, and also involve weighting factors that depend on the eigenvalues of the graph Laplacian. For undirected network graphs we show that within the class of such dynamic protocols, a guaranteed achievable tolerance can be obtained that is proportional to the quotient of the second smallest and the largest eigenvalue of the Laplacian. We also extend our results to additive nonlinear perturbations with  L  2 -gain bounded by a given tolerance.", "authors": ["Harry L. Trentelman", "Kiyotsugu Takaba", "Nima Monshizadeh"], "n_citation": 119, "references": ["0bf829c3-d555-4745-b1a5-7c5ce8acbff6", "1859f437-9692-4e89-ab82-80f97933299f", "1b449c68-2b9f-48dc-8b0c-9539613fe6ef", "1ec3b3c3-1232-498c-9b58-a29726ab43f2", "25f23604-1f2f-4183-aa27-8c070a860941", "2768199c-b9d6-4001-94d3-e6429c93bc5f", "30d07754-19d9-43d4-870a-0a98ff962736", "34a6a69e-79d6-4dff-af41-81b7d08d1397", "3c395a2b-0304-41e9-807e-5de6fc4ce7e7", "63d62f10-23f6-49d2-9f3a-1c1e8102df68", "6460eee0-033e-4185-8b7c-dbcb931e1b2c", "8a370c5f-ea22-4c05-9ef6-8a2746cdfbcd", "97ca935e-6884-4ece-bd38-470eb93ae953", "994b9409-f7d2-422e-9fed-241000d95fb9", "a6c0f12a-b343-42cd-8b90-a392f7b9b6d7", "ab35dc68-62bd-4c54-81d3-9a8406827489", "ba202daa-a01c-48f0-a4b4-00a113bda1e8", "d9162547-fd7f-4605-855d-0a3173c4b08e", "da0d5bbb-7fd9-4a3c-b0cf-74d7ab89e0c4", "dd32638e-29f9-48ef-a2da-8ab31a54d387", "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9", "eb50e272-a046-40cc-80a6-4bd9344c6e37"], "title": "Robust Synchronization of Uncertain Linear Multi-Agent Systems", "venue": "IEEE Transactions on Automatic Control", "year": 2013, "id": "3b0a9ceb-cba3-4e02-84f3-d8edbb77fb46"}
{"abstract": "Abstract#R##N##R##N#Test-suite reduction techniques attempt to reduce the costs of saving and reusing test cases during software maintenance by eliminating redundant test cases from test suites. A potential drawback of these techniques is that reducing the size of a test suite might reduce its ability to reveal faults in the software. Previous studies have suggested that test-suite reduction techniques can reduce test-suite size without significantly reducing the fault-detection capabilities of test suites. These studies, however, involved particular programs and types of test suites, and to begin to generalize their results, further work is needed. This paper reports on the design and execution of additional studies, examining the costs and benefits of test-suite reduction, and the factors that influence these costs and benefits. In contrast to previous studies, results of these studies reveal that the fault-detection capabilities of test suites can be severely compromised by test-suite reduction. Copyright \u00a9 2002 John Wiley & Sons, Ltd.", "authors": ["Gregg Rothermel", "Mary Jean Harrold", "Jeffery von Ronne", "Christie Hong"], "n_citation": 186, "references": ["21968dec-82d4-40b7-ad92-0bc41c9a9c56", "43a4d168-8449-4599-b2c3-750b5c0d5ca7", "5fcfd132-e4b8-40cf-8447-db956065c4c7", "64dceff1-38f4-4f52-9946-a43efa06e323", "9fe654b4-8dc2-4bc2-8fa5-e232cfac26e3", "bf6c6d3f-980d-4b60-a863-05bcb88658bd", "c0bd4ff6-2f39-49a8-8b61-f59486a007cb", "ca068947-71bc-41e3-acab-225f0c4270a5", "d70fb3e4-1e5f-4ab3-900d-34ecb9efc841"], "title": "Empirical studies of test\u2010suite reduction", "venue": "Software Testing, Verification & Reliability", "year": 2002, "id": "392c42e1-b894-4c08-a2a2-d9f1481c5d3a"}
{"abstract": "Reducing power consumption is a challenge to system designers. Portable systems, such as laptop computers and personal digital assistants (PDAs), draw power from batteries, so reducing power consumption extends their operating times. For desktop computers or servers, high power consumption raises temperature and deteriorates performance and reliability. Soaring energy prices and rising concern about the environmental impact of electronics systems further highlight the importance of low power consumption. Power reduction techniques can be classified as static and dynamic. Static techniques, such as synthesis and compilation for low power, are applied at design time. In contrast, dynamic techniques use runtime behavior to reduce power when systems are serving light workloads or are idle. These techniques are known as dynamic power management (DPM). DPM can be achieved in different ways; for example, dynamic voltage scaling (DVS) changes supply voltage at runtime as a method of power management. Here, we use DPM specifically for shutting down unused I/O devices. We built an experimental environment on a laptop computer running Microsoft Windows. We implemented existing power management policies and quantitatively compared their effects on power saving and performance degradation.", "authors": ["Yung-Hsiang Lu", "G. De Micheli"], "n_citation": 248, "references": ["0b9c4010-5c06-4bd0-bbdb-b4b9b1319937", "23b9a18a-6e2d-4ee5-9735-de6ff94422f7", "4646bf8a-07c9-49de-894e-679be710bcc8", "689e4eef-1aa6-4f00-bc34-f558a3182378", "6dc9e7dc-b844-4e51-b520-066ac36c8210", "87acdb15-c700-4464-9a20-a358f1ef75fb", "8ddd9bd3-b269-4728-ac4d-82aebe0e825e", "8f7eebd1-c39c-4caf-b29f-07d9b9161944", "904610b3-bb97-4b93-a8df-89ea2772d0c9", "c94251ca-b695-4c29-bfe4-6537a7d6d0bc", "ec51d5be-d7f4-4c9b-8ac2-c0d5d64100b6", "f94d0f73-fed8-4110-b3e7-aeeeb07fe059", "fba15970-1b81-4a8c-90df-af68d3f77dc3"], "title": "Comparing system level power management policies", "venue": "IEEE Design & Test of Computers", "year": 2001, "id": "47127cef-3406-4147-b68b-68d6acb02b55"}
{"authors": ["Richard H. Hammack"], "n_citation": 2, "title": "A note on the complexity of computing cyclicity.", "venue": "Ars Combinatoria", "year": 2002, "id": "9694c528-592d-4b9a-b2d3-b5e3d4f4e47b"}
{"abstract": "In The Unified Modeling Language User Guide, the original developers of the UML--Grady Booch, James Rumbaugh, and Ivar Jacobson--provide a tutorial to the core aspects of the language in a two-color format designed to facilitate learning. Starting with a conceptual model of the UML, the book progressively applies the UML to a series of increasingly complex modeling problems across a variety of application domains. This example-driven approach helps readers quickly understand and apply the UML. For more advanced developers, the book includes a learning track focused on applying the UML to advanced modeling problems.With The Unified Modeling Language User Guide, readers will:Understand what the UML is, what it is not, and why it is relevant to the development of software-intensive systemsMaster the vocabulary, rules, and idioms of the UML in order to \"speak\" the language effectivelyLearn how to apply the UML to a number of common modeling problemsSee illustrations of the UML's use interspersed with use cases for specific UML features, andGain insight into the UML from the original creators of the UML.", "authors": ["Grady Booch", "James E. Rumbaugh", "Ivar Jacobson"], "n_citation": 11893, "title": "The Unified Modeling Language user guide", "venue": "Journal of Database Management", "year": 1999, "id": "d6285e34-13fa-4327-b4f9-203181baa8c6"}
{"abstract": "In this paper, we introduce an intelligent real-time traffic signal control system based on a paraconsistent logic program called an EVALPSN (Extended Vector Annotated Logic Program with Strong Negation), that can deal with contradiction and defeasible deontic reasoning. We show how the traffic signal control is implemented in EVALPSN with taking a simple intersection example in Japan. Simulation results for comparing EVALPSN traffic signal control to fixed-time traffic signal control are also provided.", "authors": ["Kazumi Nakamatsu", "Toshiaki Seno", "Jair Minoro Abe", "Atsuyuki Suzuki"], "n_citation": 19, "references": ["dd846724-0c60-4a20-af9a-70bd239680d2"], "title": "Intelligent real-time traffic signal control based on a paraconsistent logic program EVALPSN", "venue": "granular computing", "year": 2003, "id": "ceb75c21-902e-4f87-8515-f2618b1c8843"}
{"abstract": "cekwchau@polyu.edu.hk Abstract. During the past decade, the trend to couple the World Wide Web (WWW) in teaching and learning has been gaining momentum rapidly. Learning availability over the Internet is expanding and gradually constitutes a usual means of education and training. In this paper, the development and implementation of an AI-based interactive teaching package for open channel flow on Internet is depicted. The latest expert system shell and web production software are used for the development of this system. It is demonstrated that various theories on open channel flow, design, and interactive \u201cWhat-if\u201d analysis on various design parameters can be performed using this package through an active and dynamic learning environment. It is shown that, with its intrinsic advantages, the WWW has the potential for effecting fundamental changes in the design of learning processes and the education system.", "authors": ["Kwok-wing Chau", "Yiuhung Sze"], "n_citation": 50, "references": ["0364601a-a458-4562-b2ce-2fa0d23f7d20", "09991de0-c00f-49cf-a88a-6515943b0843", "2c5f6d57-05c1-449a-b261-445eb65ac9c1", "459696fe-a706-4d1d-9376-668223dab238", "51088ae9-4802-4be6-99a7-7e8a317983e8", "e4411a4d-58f5-4960-b1b4-529be96ac536", "e493003f-25de-46ac-9044-6ebd2a710d27", "e9917974-3fc8-4db7-b6a1-50448edd432d", "fc73464d-034b-42df-94ee-6320d5f96762"], "title": "AI-Based Teaching Package for Open Channel Flow on Internet", "venue": "international conference on web-based learning", "year": 2004, "id": "db78de2f-b2be-4330-8416-74c94c968522"}
{"abstract": "As the first step in an automated text summarization algorithm, this work presents a new method for automatically identifying the central ideas in a text based on a knowledge-based concept counting paradigm. To represent and generalize concepts, we use the hierarchical concept taxonomy WordNet. By setting appropriate cutoff values for such parameters as concept generality and child-to-parent frequency ratio, we control the amount and level of generality of concepts extracted from the text.", "authors": ["Chin-Yew Lin"], "n_citation": 71, "references": ["e130cf26-7ec0-400a-9330-cdd33d8e901d", "f2d9455d-9f46-4cd9-993e-25bab1ce4792"], "title": "Knowledge-based Automatic Topic Identification", "venue": "meeting of the association for computational linguistics", "year": 1995, "id": "492fd4bc-28cb-478a-b836-197e831717bb"}
{"abstract": "We began in 1967 a project to develop a haptic+display for 6-D force fields of interacting protein molecules. We approached it in four stages: a 2-D system, a 3-D system tested with a simple task, a 6-D system tested with a simple task, and a full 6-D molecular docking system, our initial goal. This paper summarizes the entire project---the four systems, the evaluation experiments, the results, and our observations. The molecular docking system results are new.Our principal conclusions are:b Haptic display as an augmentation to visual display can improve perception and understanding both of force fields and of world models populated with impenetrable objects.b Whereas man-machine systems can outperform computer-only systems by orders of magnitude on some problems, haptic-augmented interactive systems seem to give about a two-fold performance improvement over purely graphical interactive systems. Better technology may give somewhat more, but a ten-fold improvement does not seem to be in the cards.b Chemists using GROPE-III can readily reproduce the true docking positions for drugs whose docking is known (but not to them) and can find very good docks for drugs whose true docks are unknown. The present tool promises to yield new chemistry research results; it is being actively used by research chemists.b The most valuable result from using GROPE-III for drug docking is probably the radically improved situation awareness that serious users report. Chemists say they have a new understanding of the details of the receptor site and its force fields, and of why a particular drug docks well or poorly.b We see various scientific/education applications for haptic displays but believe entertainment, not scientific visualization, will drive and pace the technology.b The hardware-software system technology we have used is barely adequate, and our experience sets priorities for future development.b Some unexpected perceptual phenomena were observed. All of these worked for us, not against us.", "authors": ["Frederick P. Brooks", "Ming Ouh-Young", "James J. Batter", "P. Jerome Kilpatrick"], "n_citation": 600, "references": ["272e79fe-6317-422c-b4c0-5ca5fceeaa1c", "342a6801-8194-424c-9095-086eca326429", "65f22bdb-3717-46af-acd2-315c94206f45", "9773d04b-4cb5-4011-887e-68a8fd2619db", "d6a99a3b-9ffb-4c11-bd98-5a937309d7bb", "e5cb051d-bb71-49c1-9046-1ec4d9050ce1"], "title": "Project GROPEHaptic displays for scientific visualization", "venue": "international conference on computer graphics and interactive techniques", "year": 1990, "id": "97ca1031-fa8e-4ca4-a4aa-c54bf1a51251"}
{"abstract": "Herbrand's Theorem for G\u221e\u0394, i.e., Godel logic enriched by the projection operator \u0394 is proved. As a consequence we obtain a \"chain normal form\" and a translation of prenex G\u221e\u0394 into (order) clause logic, referring to the classical theory of dense total orders with endpoints. A chaining calculus provides a basis for efficient theorem proving.", "authors": ["Matthias Baaz", "Agata Ciabattoni", "Christian G. Ferm\u00fcller"], "n_citation": 37, "references": ["0018a063-6450-4189-90ee-9dc614f75fdf", "02fa5320-3bf8-45a1-8521-c1f18b8aa743", "0d1e6ea7-d842-4ef1-982b-2858d22cbde8", "0ea8b7e6-4a24-4abd-8653-33036dc16501", "24614ff0-8ab9-4060-9484-cb158a423420", "2d763350-2e57-4201-b4bc-dd6f4b401f46", "39bc11dd-9a7c-44ee-bee3-9c049b88d965", "3c89e304-c0d9-4859-a316-27fa3c888109", "3fe43488-b111-491b-8ffe-e728355e8f9f", "46c0b79d-63fe-407e-9c9c-6686069c2e0e", "7c88f0e4-00d5-4185-b324-fef27bdc736b", "9b91759e-447e-4b86-8a6a-d1ff72e4abcf", "bc93be00-edff-4b53-b81f-85f7eee75d05", "c668861a-2075-438a-b050-b6468879159c", "cbea454f-47c6-4c3c-aa2d-6ffc36760558", "cd359adb-8cd4-4b86-9429-748f28cc6e94", "e7177a9c-3328-4374-9bcf-944a960c8f4d"], "title": "Herbrand's Theorem for Prenex G\u00f6del Logic and its Consequences for Theorem Proving", "venue": "international conference on logic programming", "year": 2001, "id": "83effec7-74f2-4083-9581-4877f607d3fb"}
{"abstract": "Information dissemination is a powerful mechanism for finding information in wide-area environments. An information dissemination server accepts long-term user queries, collects new documents from information sources, matches the documents against the queries, and continuously updates the users with relevant information. This paper is a retrospective of the Stanford Information Filtering Service (SIFT), a system that as of April 1996 was processing over 40,000 worldwide subscriptions and over 80,000 daily documents. The paper describes some of the indexing mechanisms that were developed for SIFT, as well as the evaluations that were conducted to select a scheme to implement. It also describes the implementation of SIFT, and experimental results for the actual system. Finally, it also discusses and experimentally evaluates techniques for distributing a service such as SIFT for added performance and availability.", "authors": ["Tak W. Yan", "Hector Garcia-Molina"], "n_citation": 358, "references": ["05f5fba9-e7ca-4c46-be79-df57944a8b41", "0895c22d-37c5-4c8f-9202-a32ebd2cb0c0", "0b20695c-e17c-4801-9c15-baf45c7efc0f", "0de84aa2-2bbe-41d1-953c-c78965877363", "2e5a52b4-d728-4d15-ba61-688d7f20c02f", "32a58cfb-b406-4d58-b0ce-23bd33fd522c", "3ee60166-6483-44be-829d-30f9aec25eff", "5110c9ed-463f-44e1-b258-4a78e3cbe110", "64915f7a-f5df-47ad-a074-dfd6ca716d5c", "73c6d29d-08cd-4be4-ae13-97c9c566dbc8", "7ecdea0d-a086-42cd-ba0b-2f7ce8e60ab9", "81bac09b-624f-4ce1-9716-f84c66848a1a", "8fd9aa19-5b11-48a2-a8dc-4cc75c36d8eb", "9c185faa-562e-413b-ada5-f749cf0556e7", "aacc5207-f90f-45c9-ba04-ff13ddc1641b", "ad3a9f92-cec6-42b4-96c1-2d35c6070095", "b0031f52-dbe8-46af-b2a1-022410ed129b", "b3593e4a-622e-49eb-b375-6ce650003a05", "b58ab02e-e402-4a4f-bae0-77aa1727a090", "c2ae33d8-85e5-4d1d-8f17-b71a210b4546", "c54e73ac-68a3-490c-9d46-b7d9f441abe7", "c7e51f1b-2404-4df1-895a-f4a6a430b98a", "c7f40ba2-aa31-4507-a1c0-648c57ed9c7b", "da22867d-4d40-4ff0-abcd-f21544141e07", "e6971e83-0520-4d66-8bd3-d0ac21278c8e", "f1b2b1a3-940f-4de2-9769-ab6462a8d0e9"], "title": "The SIFT information dissemination system", "venue": "ACM Transactions on Database Systems", "year": 1999, "id": "0fd6d6d1-6155-4b67-93c2-4cae66d09091"}
{"abstract": "In this paper we introduce a technique for applying textual labels to 3D surfaces. An effective labeling must balance the conflicting goals of conveying the shape of the surface while being legible from a range of viewing directions. Shape can be conveyed by placing the text as a texture directly on the surface, providing shape cues, meaningful landmarks and minimally obstructing the rest of the model. But rendering such surface text is problematic both in regions of high curvature, where text would be warped, and in highly occluded regions, where it would be hidden. Our approach achieves both labeling goals by applying surface labels to a psilatext scaffoldpsila, a surface explicitly constructed to hold the labels. Text scaffolds conform to the underlying surface whenever possible, but can also float above problem regions, allowing them to be smooth while still conveying the overall shape. This paper provides methods for constructing scaffolds from a variety of input sources, including meshes, constructive solid geometry, and scalar fields. These sources are first mapped into a distance transform, which is then filtered and used to construct a new mesh on which labels are either manually or automatically placed. In the latter case, annotated regions of the input surface are associated with proximal regions on the new mesh, and labels placed using cartographic principles.", "authors": ["Gregory Cipriano", "Michael Gleicher"], "n_citation": 20, "references": ["048ab066-dc8e-470c-aa5c-128b4e3d2ad9", "29480954-d125-4b47-a940-ed7bffc96589", "372d5b56-ff58-4fe4-aaa4-c48dfc03e32a", "3d4c0ab6-8b6b-4d08-9a71-80d2f496bf56", "57da3853-e1ef-4cae-be04-30b460a2241d", "5af992ad-9550-4c60-a313-0b24ff314e54", "70adbc5e-5e5e-4098-9069-9f1672f675e6", "7118ab88-9879-4cb3-b771-2f746ac2e5a0", "727b7f9a-65af-43eb-abb5-b2f53cb0ade8", "7c53159f-ec88-412d-a0c6-e185cb7bb44f", "7f42444c-a0f9-468d-a541-957b2538624d", "85750bbf-a9a3-48ae-8926-0b91f5120b88", "8a2735c2-acf6-4c6e-ac43-d20bf8bc6caf", "8c62bb31-d976-4e34-991d-651ed72ee542", "8df4d043-3c9c-4bf1-8136-a2784fbb47ac", "93f755a9-bb4c-46ef-abca-3935eb73c49a", "9d737b52-f452-47e8-b85b-fad8d6442bbb", "9e9e843a-c7e3-4d77-b1b5-96f5197aaf1e", "9eca9d02-f8a1-46fe-9ca5-b52c7a525537", "adb6a482-7c41-4611-9048-eb60710716b4", "adf6fdf9-01a0-4051-9d99-965f4a5baa4d", "c4b27d83-b67d-464e-813a-440f23dcbd81", "cd84aa5d-a982-4c0a-9b56-6c618a57264e", "db1ff796-1e94-496b-a107-0a1c9da0bde8", "dfe377d1-9e27-4538-a69f-a802ead9f650", "f77f6f81-7929-4971-9529-fb6f3ba36e06"], "title": "Text Scaffolds for Effective Surface Labeling", "venue": "IEEE Transactions on Visualization and Computer Graphics", "year": 2008, "id": "074d8e3a-d8de-4b92-ae77-7d9acecc8e5a"}
{"abstract": "As part of a focus on electronic publications, we undertook an exploratory study of how people saved and used the information they encountered while reading. In particular, we wanted to understand the role of clipping and whether it would be a necessary form of interaction with electronic publications. We interviewed 20 diverse individuals at home and at work, bringing together narrative accounts and physical and digital examples to investigate how people currently collect and use clippings from their everyday reading. All study participants had examples of materials they had deliberately saved from periodicals, ranging from ads torn from newspapers and URLs received in email messages to large stacks of magazines. Participants rarely read periodicals specifically to clip but rather recognized items of interest when they were encountered. The work highlights the importance of encountering information as an activity distinct from task-focused browsing and searching and reveals design implications for online reading and clipping technologies.", "authors": ["Catherine C. Marshall", "Sara A. Bly"], "n_citation": 62, "references": ["1b8bb109-8084-4db5-82af-854359faa0f2", "2f31ab68-3b0f-41cc-b571-0a9ed985daab", "31ad4e40-9973-4046-a500-fba581fef20e", "375969d3-cbeb-4ef6-82ea-3851485d60b8", "4bdc3a37-74cc-4e32-9338-3c968afc0af7", "5a37657b-5e50-4d5d-97c7-f468a2941f34", "73f3e626-f1e3-49fa-bce5-284da2c41b5e", "8d2d62eb-e79f-45d6-b782-6c6792622512", "8da596e9-af3f-4afa-9a08-c855f2961c34", "8e3d6ae2-8b1b-40a9-a695-a86f7915742b", "9ce660dc-53cb-4fb2-ac14-379e7e96fc59", "b0ffe0ba-027c-409f-9dea-94941a66e14a", "c4fb2b92-572d-4ed4-9347-79fd883e054c", "c77ace38-7362-4bb8-b966-ef0adac33f04", "e24f6cea-ae41-4961-803f-0a658ee2adba", "e4a399b2-e6eb-42f9-9609-c624cdcb75d9", "fa20bf7b-31c8-4527-a2c7-13515bacf09d", "fe059986-8135-49ad-b2e0-4ffed5e09af9"], "title": "Saving and using encountered information: implications for electronic periodicals", "venue": "human factors in computing systems", "year": 2005, "id": "6f6214e1-53ef-4d10-85db-f11c8bc8ee10"}
{"abstract": "A computationally simpler and effective method is proposed for estimating motion in a video sequence. The paper outlines a search technique based on conjugate directions [3], [4] and another simpler technique called the one-at-a-time search [3]. Based on the comparison of the two methods, the latter technique is adopted as the basis for further research. The adopted technique is compared with brute force search, existing 2-D logarithmic search [1], and a modified version of it [2], for motion compensated prediction [5].", "authors": ["R. Srinivasan", "K. R. Rao"], "n_citation": 743, "references": ["011b2b4d-63de-4a9d-b41d-5ff8cfa07076", "54fa6480-1f00-46c6-b6be-88546025e30e", "b8a195a1-fcf1-4b2f-9162-5bd6c84b60a1"], "title": "Predictive Coding Based on Efficient Motion Estimation", "venue": "IEEE Transactions on Communications", "year": 1985, "id": "6dde00e3-cf2d-41a5-b030-531af79b5e15"}
{"abstract": "The  string-to-string correction problem  is to determine the distance between two strings as measured by the minimum cost sequence of \u201cedit operations\u201d needed to change the one string into the other. The edit operations investigated allow changing one symbol of a string into another single symbol, deleting one symbol from a string, or inserting a single symbol into a string. An algorithm is presented which solves this problem in time proportional to the product of the lengths of the two strings. Possible applications are to the problems of automatic spelling correction and determining the longest subsequence of characters common to two strings.", "authors": ["Robert A. Wagner", "Michael J. Fischer"], "n_citation": 2240, "references": ["57d97189-a148-4eb0-9559-8b1f658e62ef"], "title": "The String-to-String Correction Problem", "venue": "Journal of the ACM", "year": 1974, "id": "0cb06ffe-08d6-4163-b5c7-ca2953b8b3b6"}
{"abstract": "Introduces an algorithm for calculating steady-state solutions of DSPN models. The described method employs the randomization technique enhanced by a stable calculation of Poisson probabilities. A complete re-design and re-implementation of the appropriate components implemented in the version 1.4 of the software package GreatSPN has lead to significant savings in both computation time and memory space. These benefits are illustrated by DSPN models taken from the literature. The author considers DSPN models for an E/sub r//D/1/K queueing system and a fault-tolerant clocking system. These examples show that the model solutions are calculated with significantly less computational effort and a better error control by the algorithm described than by the method implemented in the version 1.4 of the software package GreatSPN. >", "authors": ["C. Lindemann"], "n_citation": 50, "references": ["02650dfd-11ee-494a-bcaf-a1929a9dc1a0", "241c1225-ef03-4346-bb0e-c819d012b5c0", "280037fd-63d1-47ca-ba42-ef381f030124", "34e7741e-6429-4119-88c7-d46d84d0f5e9", "4eebc8ad-4226-47a4-a521-b208cab11ead", "62e453e0-59e5-44ce-b399-2b74c35f165d", "62f3f938-2220-444a-87c7-a18be380fbb3", "7b415d99-b1a8-4086-9fb0-8f56f48b5541", "cda1f66c-f182-4d61-bb77-0f1994322126", "e1161405-6718-4983-8717-1354ecac5401", "f5c693c8-0545-46e1-82db-00a48b217b6a"], "title": "An improved numerical algorithm for calculating steady-state solutions of deterministic and stochastic Petri net models", "venue": "", "year": 1991, "id": "241eb389-7d5a-42e0-bc80-cdd087060f66"}
{"authors": ["Andrew F. Monk", "Steve Howard"], "n_citation": 185, "references": ["b866a8a8-4b7d-4737-a4c5-edf995d9fbf0", "ca824afe-bd9d-4f3a-8fdf-6b1f31a0f2d9", "df9d1854-fa68-4b6e-b71a-fe832155f77c", "efab9e24-b2f6-4b8c-9bb5-b5c58e9ee0c7"], "title": "Methods & tools: the rich picture: a tool for reasoning about work context", "venue": "Interactions", "year": 1998, "id": "2b228097-2cf8-49e7-9e01-e701d2dce462"}
{"abstract": "Preliminaries. Categories. Functors. Diagrams. Naturality and Sketches. Products and Sums. Catesian Closed Categories. Finite Discrete Sketches. Limits and Colimits. More About Sketches. Fibrations. Adjoints. Algebras for Endofunctors. Toposes.", "authors": ["Michael Barr", "Charles Wells"], "n_citation": 1091, "references": ["00bbac01-a60f-4fbd-a918-b2441f875733", "0f0aa5f7-e025-4ffc-b9fb-40b298a3e7c9", "0fdb203c-4af8-43e6-b9d2-d5c97b247492", "2c6ba557-37e1-46e8-b108-0631fe1ca4f2", "33f1e209-cd64-4247-8162-d6c23a619dcf", "34e2fac7-bdb3-478f-8e78-be691a46f06e", "388fb05c-607d-4758-b6ba-721dabea3d71", "39987ba1-5da1-4946-b151-44d00869624c", "41385c93-631e-468a-a90c-ff4a4ff693f8", "43ec488e-9fd7-4436-84ec-b8f2a31de957", "4cbd509a-d462-4393-bde9-6912691a01de", "4ea5ff9d-d1de-42d5-88c9-03af5572fce2", "54736181-c907-4512-99c0-834d28b62830", "5d81a532-2176-405d-b0ed-26cf5078cc9e", "608d90cb-b738-44b2-9f87-8859ceec56b3", "64fd8333-c35e-4484-a12d-4973b0f309b6", "699e4d26-730c-40b3-bec8-cc5ef6efabff", "6d1caff9-1bab-427c-a2c5-e9bb5be549b8", "8081d99d-4c0a-42a0-be23-44fee0fd2225", "84cd96d8-e748-4620-a752-a1a4f7f36fe5", "8bcbb8d7-727d-440f-b9e5-a2a5af76028d", "8c1e44c2-5c36-41e7-ae76-93bcf5801207", "8cfd2f8a-b07c-407d-9f08-e122b21016a5", "8fca2a06-6f10-4b35-96ee-938394fdc433", "97d858c2-003b-45ca-b1da-9b58d5363b28", "9a34ef2c-c051-4f3a-963c-51eb515b41d4", "9e8daf43-1d3b-44f4-bd6e-40fd8b457001", "aa44dd48-8e1b-4c0e-b79e-95e3bf683345", "ae94e5b4-c663-49f6-8dc7-5f1e70ed8f1c", "b104d082-cf69-46a9-bbe2-59067c240016", "b5cc3906-2ac1-45cd-bbf6-de94b8a65c1b", "be7fa144-980d-4531-bb25-de47709b68ca", "c61e1402-bf08-492b-9a95-4f8e813e831d", "c73dd89f-76b9-4a9a-9f9e-6450b01dc520", "c76f4d27-49be-4ead-ba2d-ebe81d14a094", "cc869c09-1759-4c4b-bc02-2c73703c2d98", "ccd15b1d-189f-4dab-9484-d4a0c20c7c51", "cd5715a4-ef20-4e40-b411-3e23c4a03c0c", "cdab2ed9-90f1-43aa-bc04-aa3c8eae6272", "d1d95801-14f5-4469-bfaa-aa28e2a8fd20", "e3937231-1c8b-491e-b646-ae8a22a0b92c", "f1ba3d00-89bc-4d63-bd18-46490ded9165", "fe7a9980-1b7b-423b-a7cd-fb18010e8013"], "title": "Category theory for computing science", "venue": "", "year": 1990, "id": "6ff3924b-b9b2-4ff6-be04-a4f541d6a144"}
{"abstract": "A feature model captures various possible configurations of products within a product family. When configuring a product, several features are selected and composed. Selecting features at the program level has a general limitation of not being able to relate the resulting configuration to its requirements. As a result, it is difficult to decide whether a given configuration of features is optimal. An optimal configuration satisfies all stakeholder requirements and quantitative constraints, while ensuring that there is no extraneous feature in it. In relating requirements and feature configurations, we use the description of the problem world context in which the software is designed to operate as the intermediate description between them. The advantage of our approach is that feature selection can be done at the requirements level, and an optimal program level configuration can be generated from the requirements selected. Our approach is illustrated with a real-life problem of configuring a satellite communication software. The use of an existing tool to support our approach is also discussed.", "authors": ["Thein Than Tun", "Quentin Boucher", "Andreas Classen", "Arnaud Hubaux", "Patrick Heymans"], "n_citation": 67, "references": ["003a6a94-09b7-402f-91b7-8c3397e9883c", "2134bf3b-fd89-4724-90ce-5993b4fa3218", "26b42a04-f8ba-4c3f-8169-2c08ac64124a", "28c49b78-9398-4832-baa9-0207cba36e12", "2ea16b73-aba1-4f7c-8f45-69ddf284c3f3", "3ac62a82-475e-436d-9cb2-2ff40e7c52c2", "3ad37dae-f42f-4cab-8a0a-3f21ca315b7a", "3b8d8731-2b70-4454-a354-6ed9485098e2", "40069d75-3fb5-4a86-a34f-9839fc0da6c4", "54288b37-70d2-4e8b-ad7c-a48d31e2c4ac", "5e64add6-8ca2-4c12-9062-2eac7d841db6", "64fec467-4e81-4bf1-801d-1cd9a7b07744", "6794428d-0883-41a4-980b-062c976156d9", "6e78b7a5-ea81-4607-9ad6-fd98a1552958", "8b6b8786-09ac-4afe-b0b8-cda00965aa12", "9463a1cc-5578-4253-84db-e91a281158a6", "97f3d3a1-a263-4fb2-bf82-19e65d3dcf08", "ba6e7aa2-8961-41a9-afb2-56e233a4c420", "c7f942f8-b842-4f30-992a-1cb50805a966", "caa6bf08-0a55-422d-80c2-98df3c260720", "cbba9e26-5c5e-494f-859f-8ffda6e38004", "cdb12323-f7b7-4010-9a47-22bd39bf3bcf", "dde8d7b9-5f2b-44b4-977a-9755a6484ac7", "e5abe6d8-9cd5-47b4-90d3-3a2de33b0948", "f92b2f86-9fbc-4fe9-873d-5fb2caa1dfb5", "ff6e8d24-9cfc-4af6-8d87-a0e195df0bba"], "title": "Relating requirements and feature configurations: a systematic approach", "venue": "software product lines", "year": 2009, "id": "9898957f-d409-4d33-a921-c421f58ebf5e"}
{"abstract": "Data analysis applications typically aggregate data across many dimensions looking for unusual patterns. The SQL aggregate functions and the GROUP BY operator produce zero-dimensional or one-dimensional answers. Applications need the N-dimensional generalization of these operators. The paper defines that operator, called the data cube or simply cube. The cube operator generalizes the histogram, cross-tabulation, roll-up, drill-down, and sub-total constructs found in most report writers. The cube treats each of the N aggregation attributes as a dimension of N-space. The aggregate of a particular set of attribute values is a point in this space. The set of points forms an N-dimensionaI cube. Super-aggregates are computed by aggregating the N-cube to lower dimensional spaces. Aggregation points are represented by an \"infinite value\": ALL, so the point (ALL,ALL,...,ALL, sum(*)) represents the global sum of all items. Each ALL value actually represents the set of values contributing to that aggregation.", "authors": ["James A. Gray", "Adam Bosworth", "A. Lyaman", "Hamid Pirahesh"], "n_citation": 2592, "references": ["20eb6329-c220-422c-a881-e4e043fd5fc5", "53f11f2a-36b1-404d-a1ee-e523f44870d8", "9505b840-176e-488a-bbfc-e488442e45e8", "9f907f6a-f252-4f6b-8955-ff50970d31a8", "d10f840c-1003-48b5-8aec-3ecc0957c658"], "title": "Data cube: a relational aggregation operator generalizing GROUP-BY, CROSS-TAB, and SUB-TOTALS", "venue": "international conference on data engineering", "year": 1996, "id": "196803d1-e419-4897-9dc9-b760208c802e"}
{"abstract": "The ultimate aim of the research reported on here is to develop an automatic testing system for Dutch pronunciation. In the experiment described in this paper automatic scores of telephone speech produced by native and non-native speakers of Dutch are compared with specific, i.e., temporal and segmental, and global pronunciation ratings assigned by three groups of experts: three phoneticians and two groups of three speech therapists. The goals of this experiment are to determinutee (1) whether specific expert ratings of pronunciation quality contribute to our understanding of the relation between human pronunciation scores and machine scores of speech quality, (2) whether different expert groups assign essentially different ratings, and (3) to what extent rater pronunciation scores can be predicted on the basis of automatic scores. The results show that collecting specific ratings along with overall ones leads to a better understanding of the relation between human and automatic pronunciation assessment. Furthermore, after normalization no considerable differences are observed between the ratings by the three expert groups. Finally, it appears that the speech quality scores produced by our speech recognizer can predict expert pronunciation ratings with a high degree of accuracy.", "authors": ["C. Cucchiarini", "Helmer Strik", "Lou Boves"], "n_citation": 78, "references": ["28f9d8f2-9ac1-42bc-9389-4ef22d812820", "8f1d4848-2aa3-4167-92ff-fb9f0f227eb8", "e6ff0632-f732-43a3-ac5b-018a0430410c", "fcedacda-4ee5-4f49-a606-25ac0db2b2f6"], "title": "Different aspects of expert pronunciation quality ratings and their relation to scores produced by speech recognition algorithms", "venue": "Speech Communication", "year": 2000, "id": "a9da7ee7-7301-4ea9-a278-b82319b46b68"}
{"abstract": "This paper reports on classroom experiences in software engineering coursework where students are placed in an industrial environment and given a real customer, a real project, and held to commercial practices and accountability. The experience has been largely positive on the part of the students and their customers. Successes, failures, and opportunities for improvement are reported herein.", "authors": ["Rayford B. Vaughn"], "n_citation": 22, "references": [], "title": "Teaching Industrial Practices in an Undergraduate Software Engineering Course", "venue": "Computer Science Education", "year": 2001, "id": "270e6f5c-e305-4ce2-9966-748dc9a71d62"}
{"abstract": "We propose a Generalized Nearest Prototype Classifier (GNPC) as a common framework for a number of classification techniques. Specifically we consider clustering-and-relabeling; Parzen's classifier; radial basis functions (RBF) networks; learning vector quantization (LVQ) type classifiers; and nearest neighbor rules. To classify an unlabeled point x the GNPC combines the degrees of similarity of x to a set of prototypes. Five questions are addressed for these GNPC families: (1) How many prototypes do we need? (2) How are the prototypes found? (3) How are their class labels obtained? (4) How are the similarities defined? (5) How are the similarities and label information combined? The classification performance of a set of GNPCs is illustrated on two benchmark data sets: IRIS and the 2-spirals data. We study the resubstitution error of the GNPC as a function of the number of prototypes. Our conclusions are that: (a) unsupervised selection (or extraction) of prototypes followed by relabeling is inferior to the techniques that use labels to guide them towards prototypes; (b) the edited nearest neighbor rule is a viable option for GNPC design which has not received the attention it deserves.", "authors": ["Ludmila I. Kuncheva", "James C. Bezdek"], "n_citation": 33, "title": "An Integrated Framework for Generalized Nearest Prototype Classifier Design", "venue": "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems", "year": 1998, "id": "07bfedd8-75ef-4659-9954-52c0e99d38b0"}
{"abstract": "Economic policy in Hong Kong is frequently cited as a shining example of the laissez\u2010faire model for development, with minimal government intervention. However, the government has played a bigger role in the economy than is often recognized, responding to market failures, social problems, and the needs of the business community. Information technology (IT) policy in Hong Kong has mirrored the colony's laissez\u2010faire economic strategy, with little government effort to promote the production or use of IT products and services. Hong Kong has become an advanced user of IT in several economic sectors and an assembly site for personal computer hardware. However, like much of the manufacturing sector, the computer industry is moving much of its production to China, causing concern about the future of Hong Kong's economy. While some people feel that Hong Kong can flourish as a financial and business services center, others feel that this role will be diminished as the Chinese economy liberalizes and other centers ...", "authors": ["Kenneth L. Kraemer", "Jason L. Dedrick", "Sheryl Jarman"], "n_citation": 15, "references": ["aba928d9-79ca-484b-ad8d-0a7b48eb6be6", "bd96bc6f-9c06-427c-8714-a36bf39fdab4"], "title": "Supporting the free market: Information technology policy in Hong Kong", "venue": "The Information Society", "year": 1994, "id": "4b9b3185-d7f7-4076-9877-ac1786d5692a"}
{"abstract": "This paper describes MORENA (Multimedia ORganization Employing a Network Approach), a Petri-net based platform for the description and execution of hypermedia applications. All the parts that compose the application, such as sound, video, text and buttons are described in this model and the browsing semantics are also specified. The MORENA model provides support for dynamic data, such as video or audio. It also provides structured authoring, fine-grained synchronization of media, flexibility and adaptability through message passing, user interaction, easy prototyping and simulation, and the ability to reuse logical specifications. MORENA's parent is Trellis, but it was influenced by many other systems, merging their features in a coherent and consistent framework. Applications written based on the MORENA model are compact and platform independent.", "authors": ["Rodrigo A. Botafogo", "Daniel Moss\u00e9"], "n_citation": 50, "references": ["170a48b4-55f8-4def-9a2c-5e9a5c7db33d", "29ff56e2-0fa0-48f1-9cc7-e9dc0cdeb835", "3a914e8f-f0ee-47f0-a2b1-21e6c41e8fbc", "434c6641-d180-4295-bc20-87ea8f71bd53", "717d46e2-6ac4-4c12-8a51-04d771513c95", "7db43d77-16e5-4733-b00b-586059b5ea0c", "8fec1fd2-9f66-453a-a228-4cdc783f007e", "b09795f0-bc50-4307-bec8-36af890df09a", "bb4ba0ef-0631-4e59-9f7d-8900e10814f5"], "title": "The MORENA model for hypermedia authoring and browsing", "venue": "acm multimedia", "year": 1995, "id": "9c684741-b638-49e2-ab91-a2fb070a2c34"}
{"abstract": "Noun phrases carry much of the information in a text. Systems that attempt to acquire knowledge from text must first decompose complex noun phrases to get access to that information. In the case of noun compounds, this decomposition usually means bracketing the modifiers into nested modifier-head pairs. It is then possible to determine the semantic relationships among individual components of the noun phrase. This paper describes a semi-automatic system for bracketing an unlimited number of adjectival or nominal premodifiers. Since the system is intended to start processing with no prior knowledge, it gets trained as it brackets. That is, it starts from scratch and accumulates bracketing evidence while processing a text under user supervision. Experiments show that generalizations of the structure of complex modifier sequences allow the system to bracket previously unseen compounds correctly. Furthermore, as more compounds are bracketed, the number of bracketing decisions required of the user decreases.", "authors": ["Ken Barker"], "n_citation": 31, "references": ["34355f1b-2d7f-4413-acee-728beec66f42", "7fb71be8-65ef-41b5-9b58-65e03d37dcea", "8402a9ba-6dfe-4d21-8c9e-66b11441452c", "84c584e9-c178-4033-b17a-1e716b51eb8e", "8c1262d4-a568-4399-96da-b1cb3d7c4d7e", "bef0b2c9-d2f0-45fe-b914-c7bc239a2b67", "fa58be88-0f62-45d0-a67c-af737d8a0f83"], "title": "A Trainable Bracketer for Noun Modifiers", "venue": "canadian conference on artificial intelligence", "year": 1998, "id": "277199a6-db19-43dc-8d3c-9f3c6188b239"}
{"abstract": "Using tree automata techniques, it is proven that the theory of ground rewrite systems is decidable. Novel decision procedures are presented for most classic properties of ground rewrite systems. An example is presented to illustrate how these results could be used for specification and debugging. >", "authors": ["Max Dauchet", "Sophie Tison"], "n_citation": 171, "references": ["0c3522bb-6a95-4634-8842-e38f061cc274", "28579ab8-1e43-4752-b3e8-207dc153372c", "35a96306-f612-4b94-b047-1989fe6682a8", "36375aab-0213-4cbb-91b3-5530606daf8f", "3dced4e1-26fb-498d-9eae-9303137947cc", "575263da-d9c4-4969-a40e-ed00f4580f87", "7181b1c1-c0c8-472f-a192-0abb01db9b86", "7c5824d8-1249-4d68-a21d-067cc320f979", "7cb4206d-f4b9-42f1-bf0f-294e4246e35b", "8a9f6399-7aa1-4996-858a-5431c8d4a56d", "a873fb4d-d8a7-4101-914b-acfefd91bb6b", "b6703a88-6722-46d8-9f21-eed5f20dabe4", "c008403c-fecc-467b-a3e7-4240c93203cd", "c6b8bff7-6161-446a-88df-2058573417c1"], "title": "The theory of ground rewrite systems is decidable", "venue": "logic in computer science", "year": 1990, "id": "2fbceb14-533b-4014-8711-5ef6d0e39225"}
{"abstract": "We consider several important problems for which no polynomially time bounded algorithm is known. These problems are shown to be related in that a polynomial algorithm for one implies a polynomial algorithm for the others.", "authors": ["Sartaj Sahni"], "n_citation": 26, "references": ["172f9f68-8417-43bb-8fe5-b377d569f6b6", "8d09527f-b5ad-4902-ba34-5583f6759d3b", "9eeccc0d-73be-4c55-87bc-b81114d4c93c", "dae8eef5-73e9-46c2-bc92-d8b8f00f998e"], "title": "Some related problems from network flows, game theory and integer programming", "venue": "foundations of computer science", "year": 1972, "id": "e90d20fd-7099-4352-969c-5b7ee5740f71"}
{"abstract": "Videoconferencing is going to become attractive for geo-graphically distributed team collaboration, specifically to avoid travelling and to increase flexibility. Against this background this paper presents a next generation system - a 3D videoconference providing immersive tele-presence and natural representation of all participants in a shared virtual meeting space to enhance quality of human-centred communication. This system is based on the principle of a shared virtual table environment, which guarantees correct eye contact and gesture reproduction. The key features of our system are presented and compared to other approaches like tele-cubicles. Furthermore the current system design and details of the real-time hardware and software concept are explained.", "authors": ["Peter Kauff", "Oliver Schreer"], "n_citation": 108, "references": ["15174451-1aa0-41a3-8106-7be93b7fa9a1", "2a7f95bf-1c6c-4cf6-9452-8423c296a580", "41db92d5-62f5-4ac6-95b5-b7b94c43ada6", "54650f1c-8852-420d-a766-d44449908290", "7a77349b-21ce-4f7c-85f0-dcdd7234f155", "995cbec7-ad45-4173-839c-96d77d6df6f9", "9c9b90cb-b43c-4fed-936c-7f2ce5566e13", "c98dd5e9-6259-4a45-91d4-24d7e3e435bc", "d0514aa0-e82d-449d-80c8-10dbafd48bf3", "de33ab24-2670-4403-933f-70355357ece1", "df433cf6-d328-4fa4-9e32-3040793e8c7f", "fa908970-9fa8-4275-ba40-8a07a0c493bb"], "title": "An immersive 3D video-conferencing system using shared virtual team user environments", "venue": "", "year": 2002, "id": "c0b639e6-ec7a-4c62-aa67-55a73eeff298"}
{"abstract": "We present a new theory of non-disjoint serial decomposition. We also present our new decomposition tool DEMAIN. The decomposition approach implemented in DEMAIN relies on: a partition-based representation of Boolean functions; and an effective balanced decomposition strategy that switches between the parallel and non-disjoint serial decomposition. In consequence, we applied the non-disjoint serial decomposition and parallel decomposition for efficient synthesis of FPGA-based circuits directed towards area or delay optimisation.", "authors": ["Mariusz Rawski", "Lech J\u00f3zwiak", "Miroslawa Nowicka", "Tadeusz Luba"], "n_citation": 50, "references": ["1e12577c-ec83-4420-aa69-ee4345bb5181", "21cb053c-b0b3-41eb-834a-00a37857a560", "2b70bed7-0ce2-4f86-a906-fcc7189bf7a7", "2c78b58d-b545-46e3-9c39-0e8de3670024", "809e630b-fd8b-4f51-be28-8a99728a0d4c", "93a9b0b0-7ace-4b18-89ea-156caf65e645", "affe9061-77ee-48ee-b9d9-c8454550eae7", "e1d3e587-04b4-4512-9e23-c69aa4e1911a", "ef66ec0f-1353-49f3-9252-d0a3215b91ed"], "title": "Non-disjoint decomposition of Boolean functions and its application in FPGA-oriented technology mapping", "venue": "", "year": 1997, "id": "ee57d47f-8834-4405-8aa7-c75b48feae83"}
{"abstract": "The following job sequencing problems are studied: (i) single processor job sequencing with deadlines, (ii) job sequencing on  m -identical processors to minimize finish time and related problems, (iii) job sequencing on 2-identical processors to minimize weighted mean flow time.  Dynamic programming type algorithms are presented to obtain optimal solutions to these problems, and three general techniques are presented to obtain approximate solutions for optimization problems solvable in this way. The techniques are applied to the problems above to obtain polynomial time algorithms that generate \u201cgood\u201d approximate solutions.", "authors": ["Sartaj Sahni"], "n_citation": 383, "references": ["172f9f68-8417-43bb-8fe5-b377d569f6b6", "3d8be443-b3ac-4d83-8125-d2cd0e0ef394", "7add1f76-fb40-48db-ae59-0702ffd14aa3", "7bcbc66f-45b3-4535-8d5f-3f1e7f60e581", "840486c6-787b-44ee-9fb8-c37e17cfba2b", "9eeccc0d-73be-4c55-87bc-b81114d4c93c", "f3530767-f643-469f-bc0b-e8191815fb4e"], "title": "Algorithms for Scheduling Independent Tasks", "venue": "Journal of the ACM", "year": 1976, "id": "c92cb154-090d-4b89-8826-dc28d476041e"}
{"abstract": "This paper addresses the design of a heart rate (HR) control system for a bicycle equipped with a continuously varying transmission. The control system helps the cyclist maintain a constant physical effort throughout the trip. A complete model of the entire system (bicycle, cyclist, and HR dynamics) is derived, identified, and validated using experimental data. The model is the basis for the development of two controllers. A proportional\u2013integral controller and a second-order sliding mode (SOSM) controller. The two controllers are analyzed, concluding that the SOSM controller offers better robustness against unmodeled dynamics and disturbances. The SOSM controller is finally exhaustively tested on two subjects in real-world conditions. With the proposed systems, the riders are capable of keeping their HR within 10 bpm from the desired one.", "authors": ["Matteo Corno", "Paolo Giani", "Mara Tanelli", "Sergio M. Savaresi"], "n_citation": 50, "references": ["08598296-8dac-491d-a8a0-f4c917ca993b", "0c1360f6-8955-45b5-91e7-45ceabcb2ff3", "1403656f-2f39-4bc5-9b04-26b6f71b4ad8", "58e41571-e968-4f21-866d-f69be69f78ad", "8d2515e9-d06f-492f-a259-43d5719020d2", "e6a8680b-7f3f-41ad-b0ce-4d841d0d3f4f", "fd5ddefa-3776-4cc3-aea8-53dd057295ed"], "title": "Human-in-the-Loop Bicycle Control via Active Heart Rate Regulation", "venue": "IEEE Transactions on Control Systems and Technology", "year": 2015, "id": "41f7a5aa-ff6c-4e89-9c5f-06fab3c05b28"}
{"abstract": "One of the most informative measures for feature extraction (FE) is mutual information (MI). In terms of MI, the optimal FE creates new features that jointly have the largest dependency on the target class. However, obtaining an accurate estimate of a high-dimensional MI as well as optimizing with respect to it is not always easy, especially when only small training sets are available. In this paper, we propose an efficient tree-based method for FE in which at each step a new feature is created by selecting and linearly combining two features such that the MI between the new feature and the class is maximized. Both the selection of the features to be combined and the estimation of the coefficients of the linear transform rely on estimating 2-D MIs. The estimation of the latter is computationally very efficient and robust. The effectiveness of our method is evaluated on several real-world data sets. The results show that the classification accuracy obtained by the proposed method is higher than that achieved by other FE methods.", "authors": ["Farid Oveisi", "Shahrzad Oveisi", "Abbas Erfanian", "Ioannis Patras"], "n_citation": 25, "references": ["105f2b5a-f659-4483-9c31-559f5deb1087", "1edc5f67-f243-49f2-bd0e-62217cfa8b20", "2cbf7ad2-a862-4399-b2a5-816c698134d3", "3d11baad-0e0f-4837-af8a-527a3ecb6840", "44956989-0d84-4df8-ab5e-14510bffddc0", "48f11006-94e4-4967-aac9-2ddfe6af1c91", "4f17cb85-8697-4b23-9036-6c16e5cde287", "5e27943c-0644-4962-bc75-9649f2c04113", "6640412f-97d5-4057-9c64-72fb45e88c58", "6999cd75-fd74-491e-997b-b76dc1006f46", "6c2488a5-9cf4-45de-bf52-5438e48ddb9d", "72c37796-b53a-4485-8733-d84c9d95b837", "81bcccdd-11cb-4817-b888-fb156fb4fd81", "81c7f6c5-8b63-42f0-af04-da18fa49a0de", "8947ffba-a802-4081-94f4-4bc721b14c47", "8e5c5860-5d4d-423e-936f-11f3d083d4f0", "b45bffa3-67ae-4ecd-91e7-2c606b10d6aa", "b4d3f5d2-83f9-4240-adcd-3a985b53bf48", "c174f5f8-00ef-4e40-af58-943e0e5a91b0", "dff2a755-5f0a-4313-9a55-2d320d94450d", "e621b712-f8f9-4169-b2fb-be6c905658cf", "ebef84b6-8249-4d5b-8722-bba79aa7b770"], "title": "Tree-Structured Feature Extraction Using Mutual Information", "venue": "IEEE Transactions on Neural Networks", "year": 2012, "id": "ba449b4a-1701-43e9-99e9-99d54b8253ba"}
{"abstract": "We show that although the algebraic semantics of place/transition Petri nets under the collective token philosophy can be fully explained in terms of strictly symmetric monoidal categories, the analogous construction under the individual token philosophy is not completely satisfactory, because it lacks universality and also functoriality. We introduce the notion of pre-nets to overcome this, obtaining a fully satisfactory categorical treatment, where the operational semantics of nets yields an adjunction. This allows us to present a uniform logical description of net behaviors under both the collective and the individual token philosophies in terms of theories and theory morphisms in partial membership equational logic. Moreover, since the universal property of adjunctions guarantees that colimit constructions on nets are preserved in our algebraic models, the resulting semantic framework has good compositional properties.", "authors": ["Roberto Bruni", "Jos\u00e9 Meseguer", "Ugo Montanari", "Vladimiro Sassone"], "n_citation": 50, "references": ["03fa9410-4611-4774-8872-28cb42c016df", "0d2ce1dd-3e33-4644-bd8f-4370ca1b1440", "1e108cb2-492c-40d8-8fb2-7dcd67e215b1", "356dc008-3ed7-44ac-87e7-dd02526b4652", "3b48db0b-0931-48b1-bebe-5ff6ffef1e3d", "5fd1970e-ecf4-4131-aafa-a835fd7be7d5", "72516444-05a7-48aa-9d30-1ea7a03b3dd7", "7534f8b3-1cb3-4cc8-987d-85e529477cbe", "81245a3c-4859-4224-9c00-cf5454df0d58", "814646c9-2dbd-4b64-be16-e3b04090a6f6", "8d0c36c4-d74e-4887-8754-a49b7400784a", "9c00b540-465c-4559-ad30-09c09cbea903", "9fa4e890-3dc7-4806-8208-6617d8f95e5a", "ad4a33ad-6489-4721-822d-39d428192045", "c452b580-9c62-4869-8a74-b718aa62ebe1", "edf4e388-edb9-4b7d-b4bf-4ab880f71a9a", "f3620303-8768-41e5-96ed-c6f7060c2c2a", "f3e28538-1c47-4aa6-8cb0-931bd77ce845", "f4a651c4-da5e-40bf-82ee-23a34cc5a42b", "f7937748-4a03-4d66-a770-39c88cc8320f"], "title": "Functorial Models for Petri Nets", "venue": "Information & Computation", "year": 2001, "id": "c7cd4dd7-d9cf-4c21-a370-5f79afe53ed3"}
{"abstract": "Production planning of a flexible manufacturing system (FMS) is plagued by two interrelated problems, namely 1) part-type selection and 2) operation allocation on machines. The combination of these problems is termed a machine loading problem, which is treated as a strongly NP-hard problem. In this paper, the machine loading problem has been modeled by taking into account objective functions and several constraints related to the flexibility of machines, availability of machining time, tool slots, etc. Minimization of system unbalance (SU), maximization of system throughput (TH), and the combination of SU and TH are the three objectives of this paper, whereas two main constraints to be satisfied are related to time and tool slots available on machines. Solutions for such problems even for a moderate number of part types and machines are marked by excessive computational complexities and thus entail the application of some random search optimization techniques to resolve the same. In this paper, a new algorithm termed as constraints-based fast simulated annealing (SA) is proposed to address a well-known machine loading problem available in the literature. The proposed algorithm enjoys the merits of simple SA and simple genetic algorithm and is designed to be free from some of their drawbacks. The enticing feature of the algorithm is that it provides more opportunity to escape from the local minimum. The application of the algorithm is tested on standard data sets, and superiority of the same is witnessed. Intensive experimentations were carried out to evaluate the effectiveness of the proposed algorithm, and the efficacy of the same is authenticated by efficiently testing the performance of algorithm over well-known functions", "authors": ["Manoj Kumar Tiwari", "Sahoo Subhendu Kumar", "Prakash", "Ravi Shankar"], "n_citation": 55, "references": ["0a7cda0b-d026-40bc-aa81-bf0e4c9d006e", "0d085a42-97cb-4255-9377-e88a98f18974", "4aa36e60-ea69-4708-90e6-b2883287276e", "7e1eeb34-62a7-41b7-8c1d-9cce0b528102", "97219fee-ec6e-4d2a-b7d1-a2e881c130d0", "97c16dc9-ebe3-43a2-9263-2af235c8775d", "bd7f6a97-f514-4f57-9d17-2aae02cc3f2c"], "title": "Solving Part-Type Selection and Operation Allocation Problems in an FMS: An Approach Using Constraints-Based Fast Simulated Annealing Algorithm", "venue": "systems man and cybernetics", "year": 2006, "id": "1fd82685-39d8-4296-9868-8b4674f5290f"}
{"abstract": "Most popular programming languages support situations where a value of one type is converted into a value of another type without any explicit cast. Such implicit type conversions, or type coercions, are a highly controversial language feature. Proponents argue that type coercions enable writing concise code. Opponents argue that type coercions are error-prone and that they reduce the understandability of programs. This paper studies the use of type coercions in JavaScript, a language notorious for its widespread use of coercions. We dynamically analyze hundreds of programs, including real-world web applications and popular benchmark programs. We find that coercions are widely used (in 80.42% of all function executions) and that most coercions are likely to be harmless (98.85%). Furthermore, we identify a set of rarely occurring and potentially harmful coercions that safer subsets of JavaScript or future language designs may want to disallow. Our results suggest that type coercions are significantly less evil than commonly assumed and that analyses targeted at real-world JavaScript programs must consider coercions.", "authors": ["Michael Pradel", "Koushik Sen"], "n_citation": 12, "references": ["0ede72b0-51f6-43b7-8027-96a7da478977", "1453428e-59a9-49bc-a561-60e9c8ed50bd", "2ed548cc-a319-474e-b235-3991ae1a06a9", "4647bb7d-534c-4250-8c5b-c5d359fc7394", "5a1c71de-8cc2-4b76-8c60-8a9d9f4dfb99", "5d3c1e57-2762-48c2-b5a7-edf23e52fea9", "6be6141c-2f87-4bfe-91e0-c25eac475a8d", "6e858de4-1dae-4b57-a0c1-57a74d31c5b1", "7ebd4322-5c23-493f-92f0-0028b720239e", "7f660026-0244-49dc-b719-cc778c09e003", "886e2160-0b42-43d9-8f60-7f15fa6c80e1", "9c3794c6-d8eb-40f3-97a0-1aa6989049b1", "a45c48cd-3392-44c8-8a01-352884668116", "b3d0a0c5-7978-4e96-807c-6176d46a2819", "b7c187be-95a4-46c0-a27f-3d0cd80e9170", "ca6ed2bc-fbe4-4a54-a79f-d8d2220d68b4", "cce00451-d3c8-453c-925f-fc1cff27e5c4", "dcdf965f-d02c-41ba-8f44-a325ab01965c", "eac242a5-d3ff-4979-8098-116de91d0772", "ef1e9737-f888-4388-a760-bd9af45efc51", "f0a73477-684a-4cd4-8a58-a6998d24a47d", "fa004d57-1cb7-43da-9939-910d8a053c6c"], "title": "The Good, the Bad, and the Ugly: An Empirical Study of Implicit Type Conversions in JavaScript", "venue": "european conference on object-oriented programming", "year": 2015, "id": "92e6ceeb-80e7-4cbd-aee1-4a709df2842f"}
{"authors": ["Joffroy Beauquier", "Ajoy Kumar Datta", "Maria Gradinariu", "Fr\u00e9d\u00e9ric Magniette"], "n_citation": 50, "title": "Self-Stabilizing Local Mutual Exclusion and Daemon Refinement.", "venue": "Chicago Journal of Theoretical Computer Science", "year": 2002, "id": "92a0384b-c540-49b3-97c9-bc239f13b824"}
{"abstract": "We show that the limiting state vector in the differential model of consensus seeking with an arbitrary communication digraph is obtained by multiplying the eigenprojection of the Laplacian matrix of the model by the vector of initial states. Furthermore, the eige nprojection coincides with the stochastic matrix of maximum out-forests of the weighted communication digraph. These statements make the", "authors": ["Pavel Chebotarev", "Rafig Agaev"], "n_citation": 14, "references": ["0834e24b-d006-4cd1-bedb-c4542d8ec9af", "2768199c-b9d6-4001-94d3-e6429c93bc5f", "5a79e947-2c40-4e8b-bb18-9b640fe2acbe", "6fff0e62-9812-4ea8-8f28-a2f94d571b90", "9bd798bc-1800-4f42-9f88-d7bc0d2a0d74", "b2e50ac6-2e09-4326-a89a-3f50cf6d068c"], "title": "The forest consensus theorem", "venue": "IEEE Transactions on Automatic Control", "year": 2014, "id": "ea7d1489-39aa-4af5-91b3-f22f7a786517"}
{"abstract": "This paper presents an algorithm for adapting periodic behavior to gradual shifts in task parameters. Since learning optimal control in high dimensional domains is subject to the 'curse of dimensionality', we parametrize the policy only along the limit cycle traversed by the gait, and thus focus the computational effort on a closed one-dimensional manifold, embedded in the high-dimensional state space. We take an initial gait as a departure point, and iterate between modifying the task slightly, and adapting the gait to this modification. This creates a sequence of gaits, each optimized for a different variant of the task. Since every two gaits in this sequence are very similar, the whole sequence spans a two-dimensional manifold, and combining all policies in this 2-manifold provides additional robustness to the system. We demonstrate our approach on two simulations of bipedal robots - the compass gait walker, which is a four-dimensional system, and RABBIT, which is ten-dimensional. The walkers' gaits are adapted to a sequence of changes in the ground slope, and when all policies in the sequence are combined, the walkers can safely traverse a rough terrain, where the incline changes at every step.", "authors": ["Tom Erez", "William D. Smart"], "n_citation": 31, "references": ["0aac8a90-0362-4992-9840-7826806e7e16", "281e1afa-a95a-4437-828f-9cb2e490cbcc", "3e22d2ed-14c8-4d6b-aef1-4fcda3f9050a", "4ebae243-0fc1-47a6-b41e-c80e3de7903f", "8a9d52a0-ec89-42de-87ef-77831316a087", "8eca515c-99eb-4461-9f4c-e491f2eb03ac", "a01c7ea7-2533-4836-9af9-6b78c251c111", "b04f0fe9-e882-4fe1-978f-88c16bf85748", "f0fddab2-696e-4164-b8b3-e992ea47341e"], "title": "Bipedal walking on rough terrain using manifold control", "venue": "intelligent robots and systems", "year": 2007, "id": "93a5c5ce-c788-4413-aa07-b1107bd4a5e3"}
{"authors": ["Jyrki Kivinen", "Manfred K. Warmuth"], "n_citation": 284, "references": ["06d6d936-6a8d-43ba-8d6a-f032ee0c09c3", "74a360bc-09d6-4dc9-946c-b210f4ca2e85", "8dbf796c-906c-404a-8d28-99d5845e28a8", "a8f17d49-3bef-4ccb-8e4c-6fc27d99a8db", "bd4f835b-1723-4f71-8751-4cb15483f95c", "c61bad33-aa9f-4a6e-ab8b-8e7eaa835492", "cd17473b-9aec-4099-bf27-b116490b43ea", "f006e236-59ad-4647-a59f-4f46dc2c85be"], "title": "Additive versus exponentiated gradient updates for linear prediction", "venue": "symposium on the theory of computing", "year": 1995, "id": "5cd74e0b-f25c-4aaf-8327-7ec949c7d098"}
{"abstract": "Computer system administrators are the unsung heroes of the information age, working behind the scenes to configure, maintain, and troubleshoot the computer infrastructure that underlies much of modern life. However, little can be found in the literature about the practices and problems of these highly specialized computer users. We conducted a series of field studies in large corporate data centers, observing organizations, work practices, tools, and problem-solving strategies of system administrators. We found system administrators operate within large-scale, complex environments that present significant technical, social, cognitive, and business challenges. In this paper, we describe system administrator tool use in critical, high-cost, labor-intensive work through observational, survey, and interview data. We discuss our findings concerning administrator needs for coordinating work, maintaining situation awareness, planning and rehearsing complex procedures, building tools, and supporting complicated interleaved workflows.", "authors": ["Rob Barrett", "Eser Kandogan", "Paul P. Maglio", "Eben M. Haber", "Leila Takayama", "Madhu Prabaker"], "n_citation": 205, "references": ["1444bdf9-92f7-4c42-a8e2-d8030c205e65", "352838dd-9583-402f-be39-52df4810a25f", "3695a095-0fab-4141-bdc4-2d24cb097352", "44de4ec8-abf8-4814-b879-52ad6d47e98f", "6f22b692-a06f-4c0d-b533-3110c0ad5c5d", "76dd63d9-5daa-4ac3-8ea4-2c2c4ac93f42", "a7a656c5-21f6-40f1-b59a-994c3cbd0e92", "d6f48d17-44e0-44b4-9c03-185ac2880870"], "title": "Field studies of computer system administrators: analysis of system management tools and practices", "venue": "conference on computer supported cooperative work", "year": 2004, "id": "06e82262-a980-45d6-ab17-779fcf9e84ff"}
{"abstract": "To fulfill the requirement of rapid access to huge amounts of uncompressed pixmap image data, a parallel image server architecture is proposed, based on arrays of intelligent disk nodes, with each disk node composed of one processor and one disk. It is shown how images can be partitioned into extents and efficiently distributed among available intelligent disk nodes. The image server's performance is analyzed according to various parameters such as the number of cooperating disk nodes, the sizes of image file extents, the available communication throughput, and the processing power of disk node and image server processors. Important image access speed improvements are obtained by image extent caching and image part extraction in disk nodes. With T800 transputer-based technology, a system composed of eight disk nodes offers access to three full-color 512*512 pixmap image parts per second (2.4 megabytes per second). For the same configuration but with the recently announced T9000 transputer, image access throughput is eight images per second (6.8 megabytes per second). >", "authors": ["Roger D. Hersch"], "n_citation": 50, "references": ["4b2d5bc6-f25e-4d0a-ae01-e684545cdff9", "9e4c656f-019d-4165-9d8f-f09f46d68d49", "a604756e-0870-4428-ad2d-520975453462", "ef5a4e9c-f3c5-43a3-898a-6bde1a47a5a2"], "title": "Parallel storage and retrieval of pixmap images", "venue": "", "year": 1993, "id": "fd9c8c7a-cce2-4141-b941-ace3801addf1"}
{"abstract": "While virtual machines provide significant flexibility for users and administrators to clone, snapshot, migration and rollback with unprecedented ease, it also bring forth some new problems and negative effects to the security of computing environments. The applications and operating systems are forced to run in a dynamical and unregulated computing environment, which gives rise to so radical difference that the administrator is difficult to maintain the security of computing environment. This paper summarizes and presents some types of security challenges based on existing viewpoints, then we analysis the similar challenges in Xen and discuss the potential directions and implementations for modifying it to adapt to these challenges.", "authors": ["Lei Yu", "Chuliang Weng", "Minglu Li", "Yuan Luo"], "n_citation": 5, "references": ["9c0b0b67-666b-4f7f-9d36-bf4ebcfbc83a", "a9bbc076-fa71-4bd3-8b00-42ae4b79642c", "aa03eeca-c99c-414d-86a1-2725fecc9ac0", "aa83d655-ac5b-42f6-8200-78929e22b66d", "d6349209-133c-47c5-91f3-c4d9a9bff81b", "eafbd356-d8ac-4bcf-b9ed-9d50bf806d84"], "title": "Security Challenges on the Clone, Snapshot, Migration and Rollback of Xen Based Computing Environments", "venue": "", "year": 2010, "id": "8577c111-98dc-4a6e-89a2-45497b751183"}
{"abstract": "The main challenge in using abstractions effectively is to construct a suitable abstraction for the system being verified. One approach that tries to address this problem is that of  counterexample guided abstraction refinement (CEGAR) , wherein one starts with a coarse abstraction of the system, and progressively refines it, based on invalid counterexamples seen in prior model checking runs, until either an abstraction proves the correctness of the system or a valid counterexample is generated. While CEGAR has been successfully used in verifying nonprobabilistic systems automatically, CEGAR has only recently been investigated in the context of probabilistic systems. The main issues that need to be tackled in order to extend the approach to probabilistic systems is a suitable notion of \u201ccounterexample\u201d, algorithms to generate counterexamples, check their validity, and then automatically refine an abstraction based on an invalid counterexample. In this article, we address these issues, and present a CEGAR framework for Markov decision processes.", "authors": ["Rohit Chadha", "Mahesh Viswanathan"], "n_citation": 50, "references": ["0045c5e3-9efa-4826-a712-dff6fa8068c3", "13fc85cb-0940-4d23-9bdc-2fa4ec2db9cc", "1d771ff0-5fd3-4939-b48c-7436563b4da3", "23784bd2-6351-4453-aee3-e605e3717cff", "24528701-2d54-4ed5-becd-97c46a6f5537", "2f472b61-4b22-4436-8afd-4a31c764f2ab", "46b0b064-98e7-4c97-be1a-4136b045f4e4", "63d1c97d-6dc5-460a-8a65-cdd3600ee387", "7191e7fc-b0fd-4f2b-85ad-7e56cbf675f4", "72108d4e-96c4-4166-9785-1ed0dea2fd4c", "75873a4f-cb9b-4f0a-ab0a-802537bc8dd6", "7c3d2429-a8c8-4fd0-b005-901d22c2736f", "840a656b-e6f2-41ec-8018-6535ac4ad494", "91f70349-cc00-42f6-b211-96a458fb66f7", "9335291f-0d42-4097-9794-03d386254960", "9dfbfe6e-6d2d-49ef-9cf3-ac063fb3ec2e", "a2833288-6d3f-45c5-8c14-dbe91b28567d", "b3322779-058a-4106-a0cf-cc329d3ba7d4", "b5423187-1f39-40cc-8f62-426c3a7f2b90", "be90d735-aae7-44f1-934c-713ec59f1f18", "c56344a6-7332-4d69-8bd4-910f8c458d07", "cd006cd0-c146-4e1b-8a74-01824bd720a8", "cd281d94-eb1b-400c-8ca8-04311d5810d6", "cdbcc13e-08fb-4d39-bb8e-6202bdbaf5e5", "d196ebe5-517e-4423-a021-ec7206cad311", "d274debf-f911-4969-8f36-38a795d4b75d", "d6ec8d88-3fe1-4776-bc7e-8a37e4469ccf", "e0c5479b-3e2e-47e8-85b2-ecbcfe3686f4", "e25967a9-ec9e-499d-a16b-f272a8464f4f", "ed64bd59-dab3-4010-8025-c60689f7a2c2", "f1029115-54b8-42a1-a30c-9e76a2fcc3c7", "f201c6b1-f09d-4333-8fa2-2f731df51806", "f73e7875-b391-4e9d-834c-cca495653647", "fe7ea2b8-4564-4253-b0ea-3202c6530807"], "title": "A counterexample-guided abstraction-refinement framework for markov decision processes", "venue": "ACM Transactions on Computational Logic", "year": 2010, "id": "f24352eb-1d7b-4238-9af1-18470b11c6c3"}
{"authors": ["Quan Nguyen", "Koushil Sreenath"], "n_citation": 26, "references": ["0210ba34-72ab-4909-a5e6-d307d66194bb", "293d62cd-8d8b-466d-bbbe-ffe4919e6e7a", "2bf601ae-c2fa-4891-af17-269c21c28797", "39ce8260-861e-40b2-a745-b5fb8fb1019b", "3ffc1845-eca6-4d14-8f3d-25b21c8e4edb", "4eb22d4a-6fd1-44c6-a3d5-1dc75a4ac82d", "4f57fe0d-60f8-4623-8708-5e8505fe93dc", "5acde376-67a0-42d3-903e-378401a4db80", "6c99d58b-dfbc-4c5f-af7a-7a9f6dfb9798", "84cd3237-b2ec-4e0d-89d1-ccbcd1265ff4", "c08765d0-f363-4bc6-8d5a-6a4695a11fdd", "dc6dac12-f1d0-46d3-9779-9e291e0e1830", "e01eca2e-f9ba-4dc3-8bfa-f6f9f2c4cd76", "e0a4a816-f49d-4c49-bb1f-d8fbff36dc63", "f29c5e75-7f6e-4498-9c12-e2868f74e844", "fe980343-b48e-418c-9330-a8d579e9a575"], "title": "Optimal Robust Control for Bipedal Robots through Control Lyapunov Function based Quadratic Programs", "venue": "robotics science and systems", "year": 2015, "id": "ad8b91b1-81cb-4e6b-ae3b-acb9ce028b5b"}
{"abstract": "The Perseus Project has developed a hypermedia corpus of materials related to the ancient Greek world. The materials include a variety of texts and images, and tools for using these materials and navigating the sytem. Results from a three-year evaluation of Perseus use in a variety of college settings are described. The evaluation assessed both this particular system and the application of the technological genre to information management and to learning. The evaluation used a variety of methods to address questions about learning and teaching with hypermedia and to guide the development of early versions of the system. Results illustrate that such environments offer potential for accelerating learning and for supporting new types of learning and teaching; that students and instructors must develop new strategies for learning and teaching with such technology; and that institutions must develop infrastructural support for such technology. The results also illustrate the importance of well-designed interfaces and different types of assignments on user performance.", "authors": ["Gary Marchionini", "Gregory R. Crane"], "n_citation": 135, "references": ["21e6c5b4-b587-4735-9c73-f50f6e9996e6", "34a73792-6c17-427d-bc98-3efefb698bf1", "54d1fb7b-9ed3-4ef1-b92f-e9192d9269eb", "720a176c-a787-490e-9401-2981765775ef", "b75c0b61-7d06-4587-be47-10ca339751c8", "d1d82434-f556-4e8a-a766-4ad014d50116", "f5eef670-eaea-4fdb-b49f-79ce722b1e95"], "title": "Evaluating hypermedia and learning: methods and results from the Perseus Project", "venue": "ACM Transactions on Information Systems", "year": 1994, "id": "18f18215-a725-4e90-aa3c-b9738a68b291"}
{"authors": ["Albin Bajric", "Kay Mertins", "Markus Rabe", "Frank-Walter Jaekel"], "n_citation": 50, "references": ["a1359cac-7a02-40bc-a53b-7edf476209c0"], "title": "A Success Story: Manufacturing Execution System Implementation", "venue": "", "year": 2010, "id": "df1264d3-ac95-46fb-84a4-be84328caac4"}
{"abstract": "Destination-based forwarding in traditional IP routers has not been able to take full advantage of multiple paths that frequently exist in Internet service provider networks. As a result, the networks may not operate efficiently, especially when the traffic patterns are dynamic. This paper describes a multipath adaptive traffic engineering mechanism, called MATE, which is targeted for switched networks such as multiprotocol label switching (MPLS) networks. The main goal of MATE is to avoid network congestion by adaptively balancing the load among multiple paths based on measurement and analysis of path congestion. MATE adopts a minimalist approach in that intermediate nodes are not required to perform traffic engineering or measurements besides normal packet forwarding. Moreover MATE does not impose any particular scheduling, buffer management, or a priori traffic characterization on the nodes. This paper presents an analytical model, derives a class of MATE algorithms, and proves their convergence. Several practical design techniques to implement MATE are described. Simulation results are provided to illustrate the efficacy of MATE under various network scenarios.", "authors": ["Anwar Elwalid", "Cheng Jin", "Steven H. Low", "Indra Widjaja"], "n_citation": 736, "references": ["038e6896-9a27-41cc-bacb-de3bea520f3b", "09024120-ea26-415c-8ef9-d6d3c355f6bf", "1642f59c-10a1-40da-abb1-0934ef864108", "bca0bb44-aa53-4e36-bd83-e6570150e5c7"], "title": "MATE: MPLS adaptive traffic engineering", "venue": "international conference on computer communications", "year": 2001, "id": "07baa066-d814-4452-bfc1-3c9a06f1c824"}
{"abstract": "Many irregular scientific computing problems can be modeled by directed acyclic task graphs (DAGs). We present an efficient run-time system for executing general asynchronous DAG schedules on distributed memory machines. Our solution tightly integrates the run-time scheme with a fast communication mechanism to eliminate unnecessary overhead in message buffering and copying, and takes advantage of task dependence properties to ensure the correctness of execution. We demonstrate the applications of this scheme in sparse LU and Cholesky factorizations for which actual speedups have been hard to obtain in the literature because parallelism in these problems is irregular and limited. Our experiments on Meiko CS-2 show the promising results of our approach in exploiting irregular task parallelism with mixed granularities.", "authors": ["Cong Fu", "Tao Yang"], "n_citation": 11, "references": ["03b8728f-492c-4269-9776-99275b931cfd", "2372017d-babd-4f8d-99ed-1aa8e54b552a", "274c1302-2155-4eee-ab7e-740b61686943", "29de0a7f-276e-4230-9c8a-9ecae18e54fe", "305b4647-7895-4deb-af6c-793d773bdf2b", "317d2c46-843d-43b2-af21-b6827cb57e72", "31affe4c-99d0-4353-bee4-628ba15eafe4", "39baa143-9430-45a4-bd48-ba6fa650d5c1", "5c7160ae-7920-4f95-b0a8-04247534d39d", "6eef3317-fe23-41da-94ee-3a1fca81d00d", "70d8410f-795c-41b5-b9f1-9ba2b9ead47b", "7bc828a1-f491-49a0-bbb0-d3fdcdfc1979", "80964a03-c7a2-4049-8c67-721726e1d24d", "c0b28d96-0b4d-4172-bf54-68bfacd1516b", "c67c9508-e4b3-41ea-9e3c-8b9c0a5bd211", "eab77c62-d7b5-4391-91b6-c5b1bd8283e8"], "title": "Efficient run-time support for irregular task computations with mixed granularities", "venue": "international conference on parallel processing", "year": 1996, "id": "e4ec778a-d5de-40d8-b5d5-5feed8cbe689"}
{"abstract": "We describe an algorithm for the Feedback Vertex Set problem on undirected graphs, parameterized by the size k of the feedback vertex set, that runs in time O(ckn3) where c = 10.567 and n is the number of vertices in the graph. The best previous algorithms were based on the method of bounded search trees, branching on short cycles. The best previous running time of an FPT algorithm for this problem, due to Raman, Saurabh and Subramanian, has a parameter function of the form 2O(k log k /log log k). Whether an exponentially linear in k FPT algorithm for this problem is possible has been previously noted as a significant challenge. Our algorithm is based on the new FPT technique of iterative compression. Our result holds for a more general form of the problem, where a subset of the vertices may be marked as forbidden to belong to the feedback set. We also establish \"exponential optimality\" for our algorithm by proving that no FPT algorithm with a parameter function of the form O(2o(k)) is possible, unless there is an unlikely collapse of parameterized complexity classes, namely FPT = M[1].", "authors": ["Frank K. H. A. Dehne", "Michael R. Fellows", "Michael A. Langston", "Frances A. Rosamond", "Kim Stevens"], "n_citation": 68, "title": "An O(2O(k)n3) FPT Algorithm for the Undirected Feedback Vertex Set Problem", "venue": "Theory of Computing Systems \\/ Mathematical Systems Theory", "year": 2007, "id": "0f55c41e-74c6-40f3-948a-ebd2830ebccb"}
{"abstract": "RDF-based P2P networks have a number of advantages compared with simpler P2P networks such as Napster, Gnutella or with approaches based on distributed indices such as CAN and CHORD. RDF-based P2P networks allow complex and extendable descriptions of resources instead of fixed and limited ones, and they provide complex query facilities against these metadata instead of simple keyword-based searches.In previous papers, we have described the Edutella infrastructure and different kinds of Edutella peers implementing such an RDF-based P2P network. In this paper we will discuss these RDF-based P2P networks as a specific example of a new type of P2P networks, schema-based P2P networks, and describe the use of super-peer based topologies for these networks. Super-peer based networks can provide better scalability than broadcast based networks, and do provide perfect support for inhomogeneous schema-based networks, which support different metadata schemas and ontologies (crucial for the Semantic Web). Furthermore, as we will show in this paper, they are able to support sophisticated routing and clustering strategies based on the metadata schemas, attributes and ontologies used. Especially helpful in this context is the RDF functionality to uniquely identify schemas, attributes and ontologies. The resulting routing indices can be built using dynamic frequency counting algorithms and support local mediation and transformation rules, and we will sketch some first ideas for implementing these advanced functionalities as well.", "authors": ["Wolfgang Nejdl", "Martin Wolpers", "Wolf Siberski", "Christoph Schmitz", "Mario T. Schlosser", "Ingo Brunkhorst", "Alexander L\u00f6ser"], "n_citation": 440, "references": ["1c26a829-77e9-4222-bedd-cc6133c1790e", "1f7efe61-19b7-4529-b89f-789f9dc1a35e", "33d6dabd-c086-4a6e-939a-c322b6ada724", "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4", "4c6518e5-9a26-4947-9fb0-24e9e9cf602c", "5ea35ec7-ab9f-4d0e-9a85-ef4add482ec7", "8634ae4b-69c0-4d18-af6a-ab04ab52f6cc", "bcf8abd7-10e4-4e3e-a9db-a1a0583c0568", "ce60ea5e-1cdb-415a-9c56-231db02111c4", "d06f8723-1b89-4684-99c9-c1045ddfb85c", "e1263ada-afda-498c-a37d-9b545293118a"], "title": "Super-peer-based routing and clustering strategies for RDF-based peer-to-peer networks", "venue": "international world wide web conferences", "year": 2003, "id": "584eaf3c-bebf-4951-b72a-d733e8c8a79d"}
{"authors": ["Hans-Dieter Ehrich", "Joseph A. Goguen", "Am\u00edlcar Sernadas"], "n_citation": 118, "references": ["1f2a647a-647c-4de8-99b0-64532743f80c", "20b3d6a9-4b01-467d-ad17-249ac8b2e7ff", "218e8d75-55fd-4e77-8e83-5e518adbb813", "26a37dde-eb20-4bb3-b1bc-74ffbb3fb889", "2798bd06-51eb-4263-a6f2-1b709eb740b0", "411d0a23-075b-40ed-b8c8-6517766609d0", "6714189c-b32f-40d8-b028-89aed49f0b8e", "72372cde-2406-43b0-872f-eca1a24f048b", "7641f08f-467e-483d-bcbb-bf51183b4dde", "79c05a63-4e86-46e9-881d-1a5e620c15a0", "800ae67e-9542-4cad-a957-ce0d7115a22c", "80e70c02-b50c-4459-8097-413833ce3f79", "8ed43ff5-c0db-4023-8745-d4e8b593bdcb", "af201de8-7b1a-4770-8058-52b2924f240f", "b104d082-cf69-46a9-bbe2-59067c240016", "bcab66ff-5729-458d-8820-7dd6ed8e9153", "caee913b-0b07-4006-8401-54ddc1101784"], "title": "A Categorial Theory of Objects as Observed Processes", "venue": "", "year": 1990, "id": "777c2cf5-ace6-4f7d-839b-870d2eb7d860"}
{"abstract": "The dynamic evolution of ecological systems in which predators and prey compete for survival has been investigated by applying suitable mathematical models. Dynamic systems theory provides a useful way to model interspecies competition and thus the evolution of predators and prey populations. This kind of mathematical framework has been shown to be well suited to describe evolution of economical systems as well, where instead of predators and prey there are consumers and resources. This paper suggests how dynamic systems could be usefully applied to the maintenance context, namely to model the dynamic evolution of the maintenance effort. When maintainers start trying to recognize and correct code defects, while the number of residual defects decreases, the effort spent to find out any new defect has an initial increase, followed by a decline, in a similar way to prey and predator populations. The feasibility of this approach is supported by the experimental data about a 67 months maintenance task of a software project and its successive releases.", "authors": ["F. Calzolari", "Paolo Tonella", "Giuliano Antoniol"], "n_citation": 50, "references": [], "title": "Modeling maintenance effort by means of dynamic systems", "venue": "conference on software maintenance and reengineering", "year": 1998, "id": "c6a5ffd7-d5a6-496a-a87d-e0fb105b9ad7"}
{"abstract": "This paper presents a framework that draws on Structuration theory and dialectical hermeneutics to explicate the dynamics of software process improvement (SPI) in a packaged software organisation. Adding to the growing body of qualitative research, this approach overcomes some of the criticisms of interpretive studies, especially the need for the research to be reflexive in nature. Our longitudinal analysis of the case study shows SPI to be an emergent rather than a deterministic activity: the design and action of the change process are shown to be intertwined and shaped by their context. This understanding is based upon a structurational perspective that highlights how the unfolding/realisation of the process improvement (intent) are enabled and constrained by their context. The work builds on the recognition that the improvements can be understood from an organisational learning perspective. Fresh insights to the improvement process are developed by recognising the role of the individual to influence the improvement through facilitating or resisting the changes. The understanding gained here can be applied by organisations to enable them to improve the effectiveness of their SPI programmes, and so improve the quality of their software.", "authors": ["Ian K. Allison", "Yasmin Merali"], "n_citation": 69, "references": ["1c84b497-f9c8-471c-b1c9-e9b735b952e4", "1c95d184-179f-44d1-88a8-5fab9e567e69", "1deb96e7-5602-4e51-8e9a-def339973aa8", "1ef9cc2b-fd41-4e89-b594-58b5478d1cf8", "5c3ece5e-b594-44b8-8e69-7bccfbfaf3f1", "81174ae8-fa3a-43ec-b740-1de234662386", "a2819ff8-7d98-4976-8c67-5519671434f0", "a5b1a020-571c-4731-8f9e-4ac630bf0359", "afd63c47-1b9b-4ca0-8693-e8f3efd61b64", "bdc94277-8125-4aff-bbcd-b5e6e1fda167", "c85a7430-d49b-4a85-a396-520920575478", "cfe30ec7-5f77-441c-a6f9-c27ce3945f3a", "eac7c5ab-a55d-46d0-9563-04dd49159088", "f8647e4d-8b60-440b-a7e3-3cdcbc785848"], "title": "Software process improvement as emergent change: A structurational analysis", "venue": "Information & Software Technology", "year": 2007, "id": "c3331623-bb65-49c8-85f9-1afa7527b8d4"}
{"abstract": "Abstracf- An approach to specification of requirements and verification of design for real-time systems is presented. A system is defined by a conventional mathematical model for a dynamic system where application specific states denote functions of real time. Specifications are formulas in duration calculus, a realtime interval logic, where predicates define durations of states. Requirements define safety and functionality constraints on the system or a component. A top-level design is given by a control law: a predicate that defines an automaton controlling the transition between phases of operation. Each phase maintains certain relations among the system states; this is analogous to the control functions known from conventional control theory. The top-level design is decomposed into an architecture for a distributed system with specifications for sensor, actuator, and program components. Programs control the distributed computation through synchronous events. Sensors and actuators relate events with system states. Verification is a deduction showing that a design implies requirements.", "authors": ["Kirsten Mark Hansen", "Anders P. Ravn", "Hans Rischel"], "n_citation": 109, "references": ["0d261b6a-c94a-4d5e-b44e-eb6ae46581fc", "0dda332e-b481-40a3-b8e4-a74bc1064096", "15c7d9e6-83f1-4e00-b2d5-204766d6b219", "30aed0bc-8322-49df-9dc5-cb0e87d357a9", "3426349b-13b6-4d98-be72-c280436af818", "3855d93b-5e2e-4c7a-b77f-dcd1665ccf2d", "3be27f65-400c-41d6-bad3-b5413be65fa8", "4000173b-eb96-42c7-9998-e95dee02fb67", "522d1046-3f6e-441e-a9c2-a6117cb34efe", "55f206ea-8080-4f51-a8e8-e18ccf9fcc17", "5d6b652d-9d18-46d3-a914-7bfae3c9f4bf", "7a5b1ab6-7952-452b-9b7a-3999ec123af4", "83ebc89b-26a7-4884-b9df-c8d394544365", "b3fd2552-82d3-491e-a724-04be6f7e0689", "c7669549-1837-473b-b9fd-d3029f809ebd", "dbe5ae2e-bbc0-4508-8df5-3ec95c784fa8", "ea24db4d-e146-4477-9f48-07703fab9def", "efdce74d-6508-4c20-8796-1c7c6fa0a233", "fa52584b-90c4-464d-84be-041456610ad4"], "title": "Specifying and verifying requirements of real-time systems", "venue": "ACM Sigsoft Software Engineering Notes", "year": 1991, "id": "b6be29e0-8e8a-4799-b911-80adbe617200"}
{"abstract": "A unified framework is presented in order to build lattice constellations matched to both the Rayleigh fading channel and the Gaussian channel. The method encompasses the situations where the interleaving is done on the real components or on two-dimensional signals. In the latter case, a simple construction of lattices congruent to the densest binary lattices with respect to the Euclidean distance is proposed. It generalizes, in a sense to be clarified later, the structural construction proposed by Forney (1991). These constellations are next combined with coset codes. The partitioning rules and the gain formula are similar to those used for the Gaussian channel.", "authors": ["Xavier Giraud", "Emmanuel Boutillon", "Jean Claude Belfiore"], "n_citation": 374, "references": ["0d47c93c-4c2b-420f-8b2b-1b6c58339554", "4a0bf4f3-37ab-4beb-b099-c2cd4d35c71a", "7304d3ba-add0-42b8-99af-f5e5f9b6b73b"], "title": "Algebraic tools to build modulation schemes for fading channels", "venue": "IEEE Transactions on Information Theory", "year": 1997, "id": "334d62da-9162-4f2f-bcf5-718213dc8dbe"}
{"abstract": "Chaos theory involves the study of how complicated behavior can arise in systems which are based on simple rules, and how minute changes in the input of a system can lead to large differences in the output. In this paper, bifurcation maps of the equationXt+1=\u03bbXt[1+Xt]\u2212\u03b2 are presented, and they reveal a visually striking and intricate class of patterns ranging from stable points, to a bifurcating hierarchy of stable cycles, to apparently random fluctuations.", "authors": ["Clifford A. Pickover"], "n_citation": 50, "references": ["358b841c-5a66-4774-8557-ee360264a78b", "938e6d6e-08eb-4946-9071-8b6f1e20acde", "c9e666cf-2a18-4b8b-9938-26e57eabd527"], "title": "The use of image processing techniques in rendering maps with deterministic chaos", "venue": "The Visual Computer", "year": 1988, "id": "b7762846-5407-48c3-8287-422581d85431"}
{"abstract": "IETF Mobile IPv6 and its fast handover protocols are the proposals for handling routing of IPv6 packets to mobile nodes that have moved away from their home network. To do this, each time a mobile node moves to a new location, it configures and confirms its temporal IP address. In this paper, we study the impact of the address configuration and confirmation procedures on the IPv6 handover latency. We first argue that the current procedures are unnecessarily slow, so that they hamper the use of IETF IPv6 mobility protocols for real-time traffic. We present a new scheme as a substitute of the current address configuration and confirmation procedures. The underlying objective of our scheme is to completely eliminate the latency needed for the address configuration and confirmation from the whole IPv6 handover latency. Further, a mathematical analysis is provided to show the benefits of our scheme. In the analysis, various parameters are used to compare our scheme with the current procedures, while our approach focuses on the reduction of handover latency.", "authors": ["Youn-Hee Han", "Seung-Hee Hwang"], "n_citation": 35, "references": ["4b0d1c11-eef9-4c5e-b22a-3317983c6813", "d5abed0c-ac74-43fa-b19e-2870bf98a900", "fac7dc8f-1d97-4a0e-b2d1-d0897933cf8b", "ff1eb4a0-0c6a-46e3-8ec1-b64ec8f97240"], "title": "Care-of address provisioning for efficient IPv6 mobility support", "venue": "Computer Communications", "year": 2006, "id": "bc9318ce-c4af-47c6-b55d-1acea6463126"}
{"abstract": "We describe a protocol design process, and illustrate its use by creating ATSPECT, an authentication test-based secure protocol for electronic commerce transactions. The design process is organized around the authentication tests, a method for protocol verification based on the strand space theory. The authentication tests dictate how randomly generated values such as nonces may be combined with encryption to achieve authentication and freshness. ATSPECT offers functionality and security guarantees akin to the purchase request, payment authorization, and payment capture phases of SET, the secure electronic transaction standard created by the major credit card firms.", "authors": ["Joshua D. Guttman"], "n_citation": 109, "references": ["07c0b505-8ff7-4bff-a609-f9612a521f55", "0c9685c1-e1d1-415f-8fa9-6f86ee908034", "1b4621d9-66fa-4370-8e08-c4e630369c77", "2ca2ca89-f275-46ec-83bd-73ada2d7b419", "3505deeb-d23d-46ca-821d-ae737a1e4c9b", "370a437a-5d81-48c5-ba7d-94a497a3bc35", "3ae697a8-0991-4815-9642-e7b25405eee5", "5ee86fc2-6934-40e6-a656-251b86b2026b", "642e3005-4a1d-4894-96e1-39ff1ca4a91d", "6a10d282-2b62-4dab-bcc9-a6760bffc4ee", "804cb992-d1ab-4d00-a6d4-db8f089f1c69", "8aa170a8-1e7e-4c24-a272-79fc3116f85e", "8b5f5dbe-17c6-4eaa-8e3b-f758982357a2", "aa82c324-8aa6-470d-aecb-3382d97c813a", "eb0fccc5-4903-4c48-92b7-186dc2d8645d"], "title": "Security protocol design via authentication tests", "venue": "computer security foundations workshop", "year": 2002, "id": "491dfa25-6ad1-4f4f-875c-145402474e75"}
{"abstract": "Dynamic epistemic logic describes the possible information-changing actions available to individual agents, and their knowledge pre- and post conditions. For example, public announcement logic describes actions in the form of public, truthful announcements. However, little research so far has considered describing and analysing rational choice between such actions, i.e., predicting what rational self-interested agents actually will or should do. Since the outcome of information exchange ultimately depends on the actions chosen by all the agents in the system, and assuming that agents have preferences over such outcomes, this is a game theoretic scenario. This is, in our opinion, an interesting general research direction, combining logic and game theory in the study of rational information exchange. In this article we take some first steps in this direction: we consider the case where available actions are public announcements, and where each agent has a (typically epistemic) goal formula that she would like to become true. What will each agent announce? The truth of the goal formula also depends on the announcements made by other agents. We analyse such public announcement games.", "authors": ["Thomas \u00c5gotnes", "Hans van Ditmarsch"], "n_citation": 40, "references": ["049227ad-8f2e-4edb-ba11-2ccb61e1cb35", "05031cfc-7bba-42be-b8bb-7fb908e932f0", "0d4cc186-9c63-429b-85e4-83b606481524", "239c7f02-7d44-45bc-bc4e-7f87258f063f", "26445c23-b9ec-4387-ac7e-8f1fdb5f4054", "2bc29c23-650c-4ee6-97cd-1eba1f7d4190", "376c8ea5-e798-4e65-9195-9c54d42661c8", "3fa467c8-9099-4505-a219-9368ad577e76", "5381b024-c1bf-4dc1-bf84-6613a493d1e7", "68caa047-e191-4f99-9bcc-e163140a1f8b", "68edb992-aff7-40d6-bac0-8a0ee0e7cbc5", "69e2739b-4dec-4514-8645-6df425306f50", "7383726f-ec2a-4862-a497-df7e80629527", "89f5dd76-557d-4b83-843d-bb4ffdf4bba3", "8ee223d0-fc51-4170-8bef-23c2051f5cb5", "96465a98-5bb4-494b-a194-11a6222ad688", "a50dfbe9-1dfc-445b-b788-78726e3bec26", "aaf903a7-0431-4855-b3d5-f92d0d766641", "b8be39a9-289b-46e2-a5d9-b389aab7a33d", "c7544f4d-c280-4511-8007-76c66151130a", "caaf534a-b9c6-4eca-b020-2551112cd2c7", "cc62c643-7878-4b0b-9e5c-307cd7b9e939", "ce6696a0-b83e-4170-a64f-797cd594c6bc", "d3951023-a385-4cd0-9ee4-c7f3c95b61b3", "ee8c5809-f2c5-44a2-9c42-9071557651ae"], "title": "What will they say?\u2014Public Announcement Games", "venue": "Synthese", "year": 2011, "id": "953c67a3-d968-43f3-a15c-10c3faf7a257"}
{"authors": ["Marsha J. Berger", "Shahid H. Bokhari"], "n_citation": 28, "title": "A Partitioning Strategy for PDEs Across Multiprocessors.", "venue": "international conference on parallel processing", "year": 1985, "id": "2a62094e-fd15-46ee-848e-dc478c017a4d"}
{"abstract": "Analysis of execution traces plays a fundamental role in many program anal- ysis approaches, such as runtime verication, testing, monitoring, and specication min- ing. Execution traces are frequently parametric, i.e., they contain events with param- eter bindings. Each parametric trace usually consists of many meaningful trace slices merged together, each slice corresponding to one parameter binding. For example, a Java program creating iterator objects i1 and i2 over collection object c1 may yield a trace createIterhc1i1i nexthi1i createIterhc1i2i updateCollhc1i nexthi1i parametric in collection c and iterator i, whose slices corresponding to instances \\c;i 7! c1;i1\" and \\c;i 7! c1;i2\" are createIterhc1i1i nexthi1i updateCollhc1i nexthi1i and, respectively, createIterhc1i2i updateCollhc1i. Several approaches have been proposed to specify and dynamically analyze parametric properties, but they have limitations: some in the specication", "authors": ["Grigore Rosu", "Feng Chen"], "n_citation": 28, "references": ["1afad44e-f6d5-4d99-a3ab-c4faffc2756a", "2b5d5a2a-7742-45a3-9d1d-f42d401ebfb9", "33e65595-28a8-45c1-807c-aa9167f1a4e4", "3669e808-78bb-40ee-ba79-0f61607c318c", "40bb723f-3635-4f4e-a954-3901395143ea", "5baba36d-1136-4d9c-bd24-6acb692e7bfd", "62fb3e25-0569-4641-a40d-59d2ff00f278", "75476ed6-977a-4f4d-a9f9-9753c174ec2e", "79378db1-ba0a-4f17-b51c-ade43c21f917", "7d7b0e4f-f460-47da-a245-eba06fdac481", "819da3e8-bebd-4a36-8991-b51fb011ae43", "86f7678c-106e-40bb-b734-64e959dacfe6", "9d2dabb3-0421-40fd-9001-37357f4297cf", "a4a2efcc-0756-448a-8f0f-371f70d2f02c", "b79149a3-88ce-41f6-b16e-bc8b77f157c0", "c0e224fc-3702-44f3-9b58-07fe176a13e4", "de09e92c-9b90-4024-81b6-405e329fadfb", "de9b2d20-2cf3-4b9c-b71b-ff557208b205", "e24c0545-dc00-44dd-bf7b-3b65df8d55a2", "e4afc057-44b9-4af0-ba6a-e8562bbc77eb", "eb468120-46b4-4523-a297-67f535d4f9af", "f213d201-cf2e-4031-9938-eab84cc0c597", "f6f368c9-6395-4c08-9e17-5896b04e478a"], "title": "Semantics and Algorithms for Parametric Monitoring", "venue": "Logical Methods in Computer Science", "year": 2012, "id": "01aecedc-5441-4ac1-9c4b-c9450e72d248"}
{"abstract": "In the last years two automated reasoning techniques for clause normal form arose in which the use of labels are prominently featured: signed logic and annotated logic programming, which can be embedded into the first. The underlying basic idea is to generalise the classical notion of a literal by adorning an atomic formula with a sign or label which in general consists of a possibly ordered set of truth values. In this paper we relate signed logic and classical logic more closely than before by defining two new transformations between them. As a byproduct we obtain a number of new complexity results and proof procedures for signed logics.", "authors": ["Bernhard Beckert", "Reiner H\u00e4hnle", "Felip Many\u00e0"], "n_citation": 59, "references": ["0acdab6a-a85a-4388-a83c-d896c5dad352", "20c92498-e000-4781-a9b5-5d49b59b6eba", "4ce107ea-0cee-423e-88be-8d2ba856ff47", "5dff42ad-e16b-4b6a-bce3-fe808d109177", "6dd4230e-cd7a-4977-a594-713d52893187", "80e4c79e-cf87-4ef2-a309-ce9bdf6442a1", "89545065-ebd5-4a8a-b925-bcd5db56460e", "8b89fca4-f22c-42dd-9294-5429e1d5c7b6", "8d09527f-b5ad-4902-ba34-5583f6759d3b", "9f6a783d-ead7-4d56-a870-f2e6b63f3e34", "c1cdab92-ca97-491f-a447-1452b6f31d57"], "title": "Transformations between signed and classical clause logic", "venue": "international symposium on multiple valued logic", "year": 1999, "id": "b76e8bf6-382b-4d35-a450-51697b9238bf"}
{"abstract": "Abstract   We extend polymorphic type inference with a very general notion of subtype based on the concept of type transformation. This paper describes the following results. We prove the existence of (i) principal type property and (ii) syntactic completeness of the type-checker, for type inference with subtypes. This result is developed with only minimal assumptions on the underlying theory of subtypes. As a consequence, it can be used as the basis for type inference with a broad class of subtype theories. For a particular \u201cstructural\u201d theory of subtypes, those engendered by inclusions between type constants only, we show that principal types are compactly expressible. This suggests that type inference for the structured theory of subtypes is feasible. We describe algorithms necessary for such a system. The main algorithm we develop is called MATCH, an extension to the classical unification algorithm. A proof of correctness for MATCH is given.", "authors": ["You-Chin Fuh", "Prateek Mishra"], "n_citation": 212, "references": ["0ae1bce8-7965-45f9-9a2b-f3f26a36b92c", "192a0fe0-b5ae-41a4-8e59-afbf21bd979e", "3c821bbb-c501-428d-b62e-cc45ea740333", "4ea5ff9d-d1de-42d5-88c9-03af5572fce2", "691896fa-37a8-42de-85d1-54ff1caeff51", "7e6d4457-8072-4be7-ba6f-a68e7012421d", "866ad403-33dc-4398-bb0b-f37105dc79d0", "8ae3d7fb-7cf7-4df8-abc8-a1d278f63481", "a06248a9-0de4-45e1-a3d7-96097c648b40", "b3c82c21-588a-44bf-b8cb-ea769fcf3320", "c38ddc98-cedc-4635-a8b2-cab2685b5329", "e435c51c-247b-4386-8238-0f4d5d754eca"], "title": "Type inference with subtypes", "venue": "european symposium on programming", "year": 1990, "id": "5434e88f-afe5-4e52-b302-15e819a10c02"}
{"abstract": "This paper contributes to the studies of design activities in informa- tion systems development. It provides a case study of a large agile development project and focusses on how customers and users participated in agile develop- ment and design activities in practice. The investigated project utilized the agile method eXtreme Programming. Planning games, user stories and story cards, working software, and acceptance tests structured the customer and user in- volvement. We found genuine customer and user involvement in the design activities in the form of both direct and indirect participation in the agile devel- opment project. The involved customer representatives played informative, consultative, and participative roles in the project. This led to their functional empowerment\u2014 the users were enabled to carry out their work to their own satisfaction and in an effective, efficient, and economical manner.", "authors": ["Karlheinz Kautz"], "n_citation": 50, "references": ["19ad3ebe-a280-428b-98b1-a86cb87a9c41", "205faf73-8ab4-475f-8207-a09a91ec8dfa", "28112c3d-edb4-48fe-92ae-89c165d2e490", "4cc6be42-bcf3-48cb-8eea-ad83eb58fd4e", "4ebb824c-c496-471a-9b62-ab2c15057931", "7a9bd243-6ac9-4c0d-99bb-8c100149fe46", "9232e49d-87a7-43ac-8af5-5bfe915ba7b6", "a63ce9f5-50a2-4953-9293-bbe2ef3dbaf3", "a6e39623-a582-4abf-84ba-c4bd5fbee12d", "c132f655-6e16-4689-b890-6f29efeea245", "d1948e40-c844-4384-9cf0-4d193433c1d0", "efcdee6f-c7a6-4879-866f-c3ccb9705375", "f4593e9d-babb-43c6-ab3f-465df23afb55", "fb861a3e-6d22-44cb-a80e-c5a2e0c806d8"], "title": "Participatory Design Activities and Agile Software Development", "venue": "", "year": 2010, "id": "9c5d2ec0-c8ce-413e-ae59-add7abc5cd2a"}
{"abstract": "This paper appears in the March, 1972, issue of the Communications of the ACM. Its abstract is reproduced below.   TENEX is a new time sharing system implemented on a DEC PDP-10 augmented by special paging hardware developed at BBN. This report specified a set of goals which are important for any time sharing system. It describes how the TENEX design and implementation achieve these goals. These include specifications for a powerful multiprocess large memory virtual machine, intimate terminal interaction, comprehensive uniform file and I/O capabilities, and clean flexible system structure. Although the implementation described here required some compromise to achieve a system operational within six months of hardware checkout, TENEX has met its major goals and provided reliable service at several sites and through the ARPA network.", "authors": ["Daniel G. Bobrow", "Jerry D. Burchfiel", "Daniel L. Murphy", "Raymond S. Tomlinson"], "n_citation": 50, "title": "TENEX, a paged time sharing system for the PDP-10", "venue": "symposium on operating systems principles", "year": 1971, "id": "070a0150-2221-4c6c-b5f8-76c63b1d9bc9"}
{"abstract": "An  ad hoc network  is a collection of wireless computers (nodes), communicating among themselves over possibly multihop paths, without the help of any infrastructure such as base stations or access points. Although many previous ad hoc network routing protocols have been based in part on distance vector approaches, they have generally assumed a trusted environment. In this paper, we design and evaluate the  Secure Efficient Ad hoc Distance vector  routing protocol (SEAD), a secure ad hoc network routing protocol based on the design of the  Destination-Sequenced Distance-Vector  routing protocol. In order to support use with nodes of limited CPU processing capability, and to guard against Denial-of-Service attacks in which an attacker attempts to cause other nodes to consume excess network bandwidth or processing time, we use efficient one-way hash functions and do not use asymmetric cryptographic operations in the protocol. SEAD performs well over the range of scenarios we tested, and is robust against multiple uncoordinated attackers creating incorrect routing state in any other node, even in spite of any active attackers or compromised nodes in the network.", "authors": ["Yih-Chun Hu", "David B. Johnson", "Adrian Perrig"], "n_citation": 1861, "references": ["0779e2c2-d021-48cf-8ec2-addee8eb86f1", "0ab8c0f9-fdba-428d-81a3-da79d759598e", "0b868c0b-2b01-4732-abfb-06a8773783cb", "0d4d0363-07b5-43b6-976d-955e96044709", "0e1c9c62-343a-447a-9b47-9b3012656cdb", "2f814545-7696-433e-b8fd-e680a9cc5a1f", "60fb0dc2-bde3-4714-948e-de0ed12ab460", "6f706e68-f92b-48d3-be9a-a72a0a6e9d2e", "767a0a88-930f-44f0-b65c-3055c7dd0a8b", "7c9f8cd8-d0ef-4954-b4db-4a6c803459c2", "83a2eb55-b330-4e0c-8dc9-05e9466d5028", "83b5fe2e-6156-4963-9a80-1dd52c4d71bc", "8828d2f5-0b50-4715-863d-66c787fc40e0", "b29ea294-1a6b-4d57-9b6a-507c87c05ce2", "bc3c7b56-c0cd-4762-b8f1-dd53fa3905aa", "cd7b4b1f-8614-4fab-8c33-a89394f0d6f9", "f27224a9-bd96-434b-bdcd-9b805653feb7", "ff4259bb-5b84-4f51-b975-146794715d22"], "title": "SEAD: secure efficient distance vector routing for mobile wireless ad hoc networks", "venue": "ad hoc networks", "year": 2003, "id": "d330d506-3b9b-4a0e-9b38-6b3920109219"}
{"authors": ["R. Bharat Rao", "Diana F. Gordon", "William M. Spears"], "n_citation": 3, "title": "For Every Generalization Action, Is There Really an Equal and Opposite Reaction?", "venue": "international conference on machine learning", "year": 1995, "id": "698fbe82-0960-4f43-a43c-5e538b758eaf"}
{"abstract": "Better exposing congestion can improve traffic management in the wide-area, at peering points, among residential broadband connections, and in the data center. TCP's network utilization and efficiency depends on congestion information, while recent research proposes economic and policy models based on congestion. Such motivations have driven widespread support of Explicit Congestion Notification (ECN)in modern operating systems. We reappraise the Internet's ECN readiness, updating and extending previous measurements. Across large and diverse server populations, we find a three-fold increase in ECN support over prior studies. Using new methods, we characterize ECN within mobile infrastructure and at the client-side, populations previously unmeasured. Via large-scale path measurements, we find the ECN feedback loop failing in the core of the network 40% of the time, typically at AS boundaries. Finally, we discover new examples of infrastructure violating ECN Internet standards, and discuss remaining impediments to running ECN while suggesting mechanisms to aid adoption.", "authors": ["Steven Bauer", "Robert Beverly", "Arthur W. Berger"], "n_citation": 42, "references": ["1b13691b-4539-4fdc-900b-f39805da2e43", "28999773-9697-4226-8b0a-5fbc51217708", "4c44394b-1d58-4aed-9c11-dc59a8afcf77", "4f430d57-8e5e-4b90-a148-177cc3c993af", "6c3a93cb-6f4e-4a9d-a53e-d167e0718e52", "7bf6fbac-e208-44ce-9a72-6c3b99978c2b", "982d8be7-0219-4002-ae20-6d324aea2d6e", "c1cebae5-23b7-46ec-bf5a-1e393919949b", "cd9168ef-0d99-4a27-b246-4cc95247c033", "de881047-365b-4c68-a405-1541fa2aaf65", "e584b479-5e45-488c-89e8-674d68639c3e", "e6c2d7fd-b3f1-48e8-a9fa-ecafb3fa5421"], "title": "Measuring the state of ECN readiness in servers, clients,and routers", "venue": "internet measurement conference", "year": 2011, "id": "b4f12286-7044-4c4c-a66e-7365963ba14a"}
{"abstract": "We seek to close the gap between software engineering (SE) and human-computer interaction (HCI) by indicating interdisciplinary interfaces throughout the different phases of SE and HCI lifecycles. As agile representatives of SE, Extreme Programming (XP) and Agile Modeling (AM) contribute helpful principles and practices for a common engineering approach. We present a cross-discipline user interface design lifecycle that integrates SE and HCI under the umbrella of agile development. Melting IT budgets, pressure of time and the demand to build better software in less time must be supported by traveling as light as possible. We did, therefore, choose not just to mediate both disciplines. Following our surveys, a rather radical approach best fits the demands of engineering organizations.", "authors": ["Thomas Memmel", "Fredrik Gundelsweiler", "Harald Reiterer"], "n_citation": 113, "references": ["128d427c-3888-4f89-9308-b05a1e326916", "2226bdd2-1362-41f7-b4ea-9f315c27dc2c", "284c6845-6361-4b55-b47e-5d2ef1c3b40e", "428b1b6a-dfed-4642-9622-645df6fb6c5e", "495f850f-1db7-4a5e-82a1-553d1b9d73d4", "54934f33-fd67-48c5-8f69-6d4931c4efc6", "56dec375-91b2-4edd-9f61-9d7eae3c9718", "78ab738d-1c5f-479c-b363-224444745051", "8bc3d5af-4c67-41dc-9014-641ca8a6a981", "f4dc4605-53f1-4067-ab56-f3c704273672", "f4e82155-16f6-4f51-89c6-7ff282253ba3", "fa3b225e-78a3-40ee-ab00-4f5df6f4d52d"], "title": "Agile human-centered software engineering", "venue": "", "year": 2007, "id": "c84a41f4-3e12-4580-b056-61dee3ea8220"}
{"abstract": "Fingerprint authentication for content protection in the human-machine systems, cybernetics, and computational intelligence is very popular. Because of the complex input contexts, low-quality input fingerprint images always exist with cracks and scars, dry skin, or poor ridges and valley contrast ridges. Usually, fingerprint images are enhanced by one stage in either the spatial or the frequency domain. However, the enhanced performances are not satisfactory because of the complicated ridge structures that are affected by unusual input contexts. In this paper, we propose a novel and effective two-stage enhancement scheme in both the spatial domain and the frequency domain by learning from the underlying images. To remedy the ridge areas and enhance the contrast of the local ridges, we first enhance the fingerprint image in the spatial domain with a spatial ridge-compensation filter by learning from the images. With the help of the first step, the second-stage filter, i.e., a frequency bandpass filter that is separable in the radial- and angular-frequency domains, is employed. It is noted that the parameters of the bandpass filters are learnt from both the original image and the first-stage enhanced image instead of acquiring from the original image solely. It enhances the fingerprint image significantly because of the fast and sharp attenuation of the filter in both the radial and the angular-frequency domains. Experimental results show that our proposed algorithm is able to handle various input image contexts and achieves better results compared with some state-of-the-art algorithms over public databases, and to improve the performances of fingerprint-authentication systems.", "authors": ["Ju Cheng Yang", "Naixue Xiong", "Athanasios V. Vasilakos"], "n_citation": 50, "references": ["016a3f29-6469-4ea2-8fb0-09107883bd00", "198ce3fe-6a7e-40b2-96ef-d8aecc454b2d", "2d31d7a2-01f5-44dd-aaa0-56343850e876", "3858295c-7113-4d88-89cc-e40bdc43dd4d", "3c16150c-0c74-40f4-b250-45c10e883e0a", "431968df-189e-4115-a558-1e92b9c61615", "51a89d57-e5bb-45b3-8edc-8b5ac642bd34", "5eb465d9-06da-4196-b6ae-360d9dd568b3", "5f80e068-82f1-402a-a869-e4a9d5dcae56", "6b37bf24-cd49-4938-947b-deae005e135b", "6e0780dd-ba6e-4532-a2a4-5238557483bb", "8300a308-7030-4da9-a1d3-743c2cda5008", "8bac860e-8ae3-4f6a-8c21-640725287a0c", "9a65b4a2-14d6-4b55-ae0f-57d3cb8d4ada", "9b643bd6-6a58-4bad-9687-c9d8d92eb5bb", "9f48f4aa-1303-47b2-b23e-94086ffe139a", "9f748f22-c879-4b23-a613-c3b7a03119f0", "a186613c-3204-4963-979c-ed84c2f4ceb0", "a581417e-38ff-43c3-903c-43ca02e8abfb", "a6fc7cc1-158c-4d0c-ba17-14d86ee43b1c", "c9e6a8d3-8e0f-410c-856e-d30866dd6b87", "cc6caca8-1564-4cf8-88a3-f0733c46e0dd", "cdefa654-2b5c-40a5-8ea4-272c0c5251dc", "e1a4ef3f-da73-489d-ad2a-bc6e38c66d2f", "e484def9-68e3-49b1-a6f2-83c129539011", "e5c30028-f505-4327-8ca0-3783a4ddcc42", "f2361ad4-c6ae-45c1-8228-ca48070062d3", "f9778d84-3755-4df0-9d0e-5a05ee77b0eb"], "title": "Two-Stage Enhancement Scheme for Low-Quality Fingerprint Images by Learning From the Images", "venue": "IEEE Transactions on Human-Machine Systems", "year": 2013, "id": "782ba45c-a622-47d9-bd0e-6863b01ac19a"}
{"abstract": "This paper is devoted to a unified approach to trajectory tracking control of nonholonomic port-controlled Hamiltonian systems via generalized canonical transformations. The basic strategy of this approach is to construct an error system, which describes the dynamics of the tracking error, by a passive port-controlled Hamiltonian system. This technique works for both holonomic and nonholonomic port-controlled Hamiltonian systems. A practical design procedure to derive global tracking controllers for those systems is proposed. This method is a natural extension of the conventional passivity based control.", "authors": ["Kenji Fujimoto", "Kazunori Sakurama", "Toshiharu Sugie"], "n_citation": 9, "references": ["1777dac8-53dc-4b1c-8901-1328552d2326", "6871674d-db6e-4571-b7ac-3e2952ce63fb", "6abbc483-3d99-4574-8612-abd1cb8a6b29", "7d1a163b-d4e4-440a-bd44-be4f84f1685d", "ea5d8a14-ea51-427e-bcf2-9aa32f3204ab"], "title": "Trajectory tracking control of nonholonomic hamiltonian systems via generalized canonical transformations", "venue": "European Journal of Control", "year": 2004, "id": "199b9d69-f274-482c-8e69-9b37022c7798"}
{"abstract": "Information and communication infrastructures underwent a rapid and extreme decentralization process over the past decade: From a world of statically and partially connected central servers rose an in- tricate web of millions of information sources loosely connecting one to another. Today, we expect to witness the extension of this revolution with the wide adoption of meta-data standards like RDF or OWL un- derpinning the creation of a semantic web. Again, we hope for global properties to emerge from a multiplicity of pair-wise, local interactions, resulting eventually in a self-stabilizing semantic infrastructure. This pa- per represents an effort to summarize the conditions under which this revolution would take place as well as an attempt to underline its main properties, limitations and possible applications.", "authors": ["Karl Aberer", "Philippe Cudr\u00e9-Mauroux", "Aris M. Ouksel", "Tiziana Catarci", "Mohand Said Hacid", "Arantza Illarramendi", "Vipul Kashyap", "Massimo Mecella", "Eduardo Mena", "Erich J. Neuhold", "Olga De Troyer", "Thomas Risse", "Monica Scannapieco", "F\u00e8lix Saltor", "Luca De Santis", "Stefano Spaccapietra", "Steifen Staab", "Rudi Studer"], "n_citation": 166, "references": ["068f61f0-657e-4b7c-8f13-28c2794fb09b", "0d6c97fd-edec-4b06-a509-60a45a2bb45f", "12130824-bf64-4211-954d-1bce1bb4d11d", "12a94a29-c136-4a4b-8efb-72545f74ece1", "18819165-7f73-4da1-9bf2-792c258be677", "1c26a829-77e9-4222-bedd-cc6133c1790e", "1f7efe61-19b7-4529-b89f-789f9dc1a35e", "463623d9-06f4-49b9-813f-21f78d726f3b", "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4", "4ea30b97-10cc-4250-87a9-5d3bbb3633dd", "54dd0ffa-6609-416c-8944-13c253b340b6", "57cedbea-dfcf-4c6c-b40a-b8c83077d42f", "57ffaea2-7fcc-4245-b9a9-59cfc77ee358", "60db7997-6377-4601-bd6f-5a2ae672b30f", "60ef3852-fa16-44bf-9434-9909268ba5d8", "6e75085c-5ed5-4b43-a18a-3b3378c4cf9d", "6ebcfdd5-2250-41e3-9a7a-2a023f13f410", "71699228-335d-4a7c-b04f-8ac234641f99", "73246ea8-b105-488d-8473-47af4f1ad3c1", "7a48e15b-c3b6-45e6-bb33-ecd30a49cfed", "7d3726d8-21e5-4321-833d-dfde277c3693", "800c722d-79fe-4896-9a57-3a73f4f2b492", "80f5e1ae-670a-4f3b-8a0d-7cafccc1a0ed", "8a7dd0d1-bdc4-4e4e-a499-792754b31762", "94b4c1e8-504a-4f32-a208-a359efd31057", "9b3dc074-a9c0-4ee5-bbfd-4c2c82ca3524", "9f992fca-057e-4fbf-ae64-e9119f413716", "ac805eb0-061d-499f-81c7-c82b568a8da1", "ad459c9b-6db5-4ec4-a1e8-69a585762008", "b0d313be-bd63-4b35-a3ac-4b1298b6a46f", "b4a8b781-5c87-4aaa-8130-acbceec8c2a1", "bcf8abd7-10e4-4e3e-a9db-a1a0583c0568", "bd3cf0bb-59a4-44e3-9fc4-ec4888a068f0", "be8b9dd2-4b7e-4998-8450-86738cd65521", "cb5922c5-575b-4b50-8d58-809f8256e948", "cbf7acc5-98bb-485a-bf20-5e58af3e29fc", "d8e6cba3-669c-47d3-8d81-96f860c85b81", "e1263ada-afda-498c-a37d-9b545293118a", "e38dffe7-66a9-474c-80c2-d77ba49afbbe", "f14df1ed-e3e9-4348-9040-fc06e3411b95", "f59340a6-bf25-42f1-b1dd-eef51205e3d6", "f6a4e3d8-a002-42af-9789-69e01c28a74f"], "title": "Emergent semantics principles and issues", "venue": "database systems for advanced applications", "year": 2004, "id": "a0e34766-6286-4901-9890-52f18e1d704b"}
{"abstract": "Analysis and experiments have shown that hierarchical problem solving is most effective when the hierarchy satisfies the downward refinement property (DRP), whereby every abstract solution can be refined to a concrete-level solution without backtracking across abstraction levels. However, the DRP is a strong requirement that is not often met in practice. In this paper we examine the case when the DRP fails, and provide an analytical model of search complexity parameterized by the probability of an abstract solution being refinable. Our model provides a more accurate picture of the effectiveness of hierarchical problem solving. We then formalize the DRP in Abstrips-style hierarchies, providing a syntactic test that can be applied to determine if a hierarchy satisfies the DRP. Finally, we describe an algorithm called Highpoint that we have developed. This algorithm builds on the Alpine algorithm of Knoblock in that it automatically generates abstraction hierarchies. However, it uses the theoretical tools we have developed to generate hierarchies superior to those generated by Alpine. This superiority is demonstrated empirically.2", "authors": ["Fahiem Bacchus", "Qiang Yang"], "n_citation": 147, "references": ["07f9bb7d-2f12-4c35-b0c6-3a736490faa0", "2329ae1f-1062-4504-9ef1-45d9e5c0dd2e", "23ec487b-85ae-4bfb-a85e-4684797ea643", "27c54a80-7b44-4272-8971-5e883c179786", "288dce14-855c-4502-a7d2-cbc4dee2a31e", "34b0ae72-8cfb-48e8-be83-9929e31fad50", "3735a4c9-8f88-4e3e-9d01-93903302ff36", "5540a55c-d231-4ef0-99a9-994131872a91", "58d623bf-03fe-4423-a7b2-85b8810ac3bf", "701b6533-fc68-4d22-9878-849da1226c04", "77db4f9f-ba99-4efc-b708-a03c195e8dbb", "98ab1a7a-fcfb-4a13-a0a4-9fe54444d5f9", "9bd71fb1-9234-4134-a2c6-aeba7c6f2c90", "b6eafa09-0563-4d23-8058-c4cff3f6faa3", "dbe2b764-250e-49f6-a267-195d905c2a5f", "de785736-6f18-4b87-8748-cc4a14073b2e", "e9b11de6-432c-4ffb-b95a-d4ac138ba7d4", "ea3180f5-6fc0-4a89-ab5a-41e51eefe70a"], "title": "Downward refinement and the efficiency of hierarchical problem solving", "venue": "Artificial Intelligence", "year": 1994, "id": "6c2da5d5-a3a0-4740-9533-5522d5fa1fc0"}
{"abstract": "This brief develops a systematic state-space approach to the modeling of boost type ac-dc converters and reduction of output ripples. The bridge rectifier voltage is modeled as a periodic disturbance whose harmonics have given frequencies but uncertain phases and magnitudes. These types of disturbances are described as the output of an external autonomous linear system, called an exogenous system, with uncertain initial conditions. The exogenous system is integrated with the boost converter as a whole system in state-space description. The whole system is a nonlinear system whose differential equation has a bilinear term, which is handled by an inclusion. Via a recently developed Lyapunov framework, the problem of ripple reduction is converted into a numerically efficient optimization problem, which involves linear matrix inequalities. The resulting feedback law is a simple linear state-feedback. Experimental results validate the effectiveness of the theoretical approach and design method.", "authors": ["Huong Pham", "Hoeguk Jung", "Tingshu Hu"], "n_citation": 50, "references": ["0dc96690-82c6-43ec-a323-212a0afe8701", "38e36569-6459-4c44-8e5b-8d4162a97628", "4f5b97d8-49d4-4f5c-adcb-c79bb6464c83", "57c17365-8df6-4db9-93b4-887c809e86e8", "63aa5d5c-67cc-4f18-bcc1-c0035f9205ac", "932cfa65-0c31-46d8-a7d4-e1bee2fd9dc0", "ae14d61e-c7c2-4da6-8476-d2e726f36572", "bb90a7c9-930e-454e-8bfd-d8177cad50bf", "d21b143a-374a-44fb-ac2d-b073f958f528", "d94f0fab-0087-4f43-9b76-80fafd93fbe3", "ee9b7e29-e8e2-4bb9-a43b-d56811497f96"], "title": "State-Space Approach to Modeling and Ripple Reduction in AC\u2013DC Converters", "venue": "IEEE Transactions on Control Systems and Technology", "year": 2013, "id": "45aeab8f-b5e5-431e-9840-b23d5012c6e3"}
{"abstract": "In this letter we report a new OFDM signalling format characterized by a precoder that renders the emitted signal's phase and amplitude continuous. It achieves superior out-of- band power characteristics at the price of a slightly reduced receiver sensitivity.", "authors": ["J. van de Beek", "Fredrik Berggren"], "n_citation": 121, "references": ["2cfd5ee1-e354-43d9-be00-ad6a49f602fd", "ca272544-0a14-4415-8aac-d29a6d486d93"], "title": "N-continuous OFDM", "venue": "IEEE Communications Letters", "year": 2009, "id": "6784d388-d441-4c02-90dd-2bf668851a16"}
{"abstract": "XCON is a rule-based expert system that configures computer systems. Over 7 years, XCON has grown to 6,200 rules, of which approximately 50% change every year. While the performance of XCON is satisfactory, it is increasingly becoming more difficult to change. With the goal of facilitating maintenance, DEC has developed a new rule-based language, RIME, in which the successor to XCON, XCON-in-RIME, is being written. This paper evaluates the potential for enhanced maintainability of XCON-in-RIME over XCON.", "authors": ["Elliot Soloway", "Judy Bachant", "Keith F. Jensen"], "n_citation": 198, "references": ["7dace715-2430-48c2-9eca-f8729f128a08", "8b220ded-a172-4a36-abf3-6dccccbd52a4", "917d1050-cca5-4dae-9b03-887812fb1686", "dcc1beec-619c-4cab-9e2a-dc0ea9a54ee4"], "title": "Assessing the maintainability of XCON-in-RIME: coping with the problems of a VERY large rule-base", "venue": "national conference on artificial intelligence", "year": 1987, "id": "56957d79-e577-4ff3-a561-09a20d44afd5"}
{"abstract": "In concurrent engineering, project tasks generally involve the establishment of multifunctional design teams in order to simultaneously consider various activities throughout the entire product life cycle. Team members from different functional departments of the company interact in every phase of development tasks to design the products and processes concurrently. To ensure a successful multifunctional team, it is important to understand the characteristics of team members. Three fundamental descriptors of team members are developed in this research. The first is to represent the multifunctional knowledge of team members due to the need of concurrent engineering. Second, to build a successful project team, teamwork capability of team members is needed by taking their experience, communication skills, and flexibility in job assignment into account. Multifunctional knowledge and teamwork capability ratings are captured from each member using analytic hierarchy process. Third, since the team members work closely, their collegiality directly affects team performance, regardless of their knowledge. Thus, the working relationship model is developed to provide such a metric. Personality profiling using Myers-Briggs type indicator serves as the basis of assessing each team member's abilities to work with others. Finally, we complete this paper by providing a step-by-step procedure with an example for selecting the best multifunctional team using the three ratings. This research helps establish an efficient multifunctional team because every team member will be capable of communicating to each other within the team due to their multifunctional knowledge, teamwork skills, as well as an established good working relationship.", "authors": ["Shi-Jie (Gary) Chen", "Li Lin"], "n_citation": 184, "references": ["85c5d14f-1c77-4785-be02-68889d71272a", "b8eec012-0a4b-4bb1-9638-c967af49399f", "d35484ef-6401-400a-bc4f-5f7fdaef5eec"], "title": "Modeling team member characteristics for the formation of a multifunctional team in concurrent engineering", "venue": "IEEE Transactions on Engineering Management", "year": 2004, "id": "579a8e45-fb5b-4f1d-8a9b-2a790aa047b6"}
{"abstract": "Purpose \u2013 To present the state of the arts application of semantic web technologies in web portals and corresponding achievable improvements for identifying the potential improvement made by semantic web technology.Design/methodology/approach \u2013 An evaluation scheme is proposed to investigate various web portals that make use of semantic web technologies in order to identify their strengths and weaknesses. This scheme consists of three layers: information access, information processing and grounding technologies. Two academic portals and two commercial portals are selected based on the definition of semantic web portal. Detailed evaluation based on the proposed scheme is conducted on these four select portals.Findings \u2013 Semantic web technologies can definitely increase the information consistency and the information processing quality of web portals by using ontologies to model portal structure and consensus knowledge. Furthermore, semantic web services will be acting as the key technologies to lift curren...", "authors": ["Holger Lausen", "Ying Ding", "Michael Stollberg", "Dieter Fensel", "Rub\u00e9n Lara Hern\u00e1ndez", "Sung-kook Han"], "n_citation": 135, "references": ["001e1b5f-24be-482a-a80b-e4bda93d27bb", "10b44b5f-ac3f-462d-9d12-365514f82a29", "28001524-4409-4742-bfb9-178cc4203535", "2a3fcb65-7de7-476c-b3c1-802bb748ffce", "3ff838cf-7f2d-4a16-9035-fd5b6aafae29", "4f08f1ac-978c-405c-8eb3-d0922ef02d32", "61f65644-b4ae-42a0-9578-931bf1664ffe", "acabbb5e-da63-496b-b7fb-08cb3fb16e87", "b871aca5-dedb-4698-8144-b66fb81f85ef", "bd4a9349-beee-43d4-943d-1bec493ad95a", "cea0b30a-f265-40c2-8d28-08597aeb4db3", "e9cb4f12-f852-4a0d-bc43-822771528cbd", "faa8a1f2-d51d-42be-b0e7-50efc867a15a"], "title": "Semantic web portals: state\u2010of\u2010the\u2010art survey", "venue": "Journal of Knowledge Management", "year": 2005, "id": "c52f7d9e-1139-4917-bbde-8b2dee3592dc"}
{"abstract": "Even before the advent of Artificial Intelligence, science fiction writer Isaac Asimov recognized that an agent must place the protection of humans from harm at a higher priority than obeying human orders. Inspired by Asimov, we pose the following fundamental questions: (1) How should one formalize the rich, but informal, notion of \"harm\"? (2) How can an agent avoid performing harmful actions, and do so in a computationally tractable manner? (3) How should an agent resolve conflict between its goals and the need to avoid harm? (4) When should an agent prevent a human from harming herself? While we address some of these questions in technical detail, the primary goal of this paper is to focus attention on Asimov's concern: society will reject autonomous agents unless we have some credible means of making them safe!", "authors": ["Daniel S. Weld", "Oren Etzioni"], "n_citation": 100, "references": ["0b89d1b7-2551-4206-ae03-09b504fe9edf", "17d1ecd0-224c-484d-b35c-0d6d13e89558", "199560bb-cd8d-4297-89b1-9f975643b7c3", "21edaf4d-d927-4422-9c21-cba71d2aeffd", "25493579-3017-44a5-bda7-0b8df208089c", "275c9a63-84cc-44ed-8c94-b7d8c20bcbc3", "2c390bcc-e93f-4d62-9040-58a8c5048579", "377a9ae1-66d1-40e3-98ff-8705ad58a74c", "387395e6-6712-4dda-9cb7-cf0fd7de42c7", "3922dd79-4ffe-42f5-a88e-0372385e3801", "507e9c8b-fea4-4186-b16d-a75a65f6a839", "64f09813-41c4-42cd-a50b-0df590789010", "74e3fd8b-f955-4fde-aad8-0a705f05e27e", "75c81a40-b861-4976-9a11-60bc9526405e", "84c065f3-cfc4-43c1-b651-f7695321d83a", "8ede0874-1213-4f97-a78d-63386def3aad", "95ccbfa6-3069-49e8-9761-dce4f9d76a75", "9cec6648-3964-4770-a791-1bafd59b79c4", "ac77a839-de14-472c-87a6-95fcfcd80120", "b814a9e5-fa98-4953-aa1d-3e0656324abd", "c2f3790b-f867-4bd2-a000-fb53b48075a1", "c3a93215-3741-4461-b4ac-61a0c7f89d69", "de785736-6f18-4b87-8748-cc4a14073b2e", "df7bfdcf-b724-47f1-8c2e-4b07860a5039", "e8aa2c66-b19b-4b68-b3a2-ad15f40ead9c", "ea3180f5-6fc0-4a89-ab5a-41e51eefe70a", "eceab47e-1412-4464-a4a3-a82ae96f9c56", "fe537d93-5826-48ec-a1c5-8728d60b2167"], "title": "The first law of robotics (a call to arms)", "venue": "national conference on artificial intelligence", "year": 1994, "id": "3d22019a-d38c-4306-a8e8-a47e1e0b5334"}
{"abstract": "Conversational recommender systems are commonly used to help users to navigate through complex product-spaces by alternatively making product suggestions and soliciting user feedback in order to guide subsequent suggestions. Recently, there has been a surge of interest in developing effective interfaces that support user interaction in domains of limited user expertise. Critiquing has proven to be a popular and successful user feedback mechanism in this regard, but is typically limited to the modification of single features. We review a novel approach to critiquing,  dynamic critiquing , that allows users to modify multiple features simultaneously by choosing from a range of so-called  compound critiques  that are automatically proposed based on their current position within the product-space. In addition, we introduce the results of an important new live-user study that evaluates the practical benefits of dynamic critiquing.", "authors": ["Kevin McCarthy", "James Reilly", "Lorraine McGinty", "Barry Smyth"], "n_citation": 92, "references": ["0faacab5-5d79-40ce-a8eb-16b90d2e4ee1", "3ce8a419-f8d1-4dce-9388-15904a4023e1", "4d4d414e-89b4-4105-8106-5320294c24a5", "6965f2c2-0bfd-4735-9ba5-e91a260ea6e9", "730d80a6-4b6f-4231-b8ff-b641edf8bb3e", "b3321db8-4600-4969-ae23-336c36669dae", "dec9d762-c03a-4194-bc93-d3e44142beae", "f157b050-4b7c-4fd5-a27e-2f7a59b57c3a"], "title": "Experiments in dynamic critiquing", "venue": "intelligent user interfaces", "year": 2005, "id": "1cdc716b-dfa8-4434-ae9d-02e441df35fc"}
{"abstract": "This paper introduces a novel method, GAIS, for detecting interleaved sequential patterns from databases. A case, where data is of low quality and has errors is considered. Pattern detection from erroneous data, which contains multiple interleaved patterns is an important problem in a field of sensor network applications. We approach the problem by grouping data rows with the help of a model database and comparing groups with the models. In evaluation GAIS clearly outperforms the greedy algorithm. Using GAIS desired sequential patterns can be detected from low quality data.", "authors": ["Marja Ruotsalainen", "Timo Ala-Kleemola", "Ari Visa"], "n_citation": 50, "references": ["0cb06ffe-08d6-4163-b5c7-ca2953b8b3b6", "0e99cc9a-805e-4070-923c-42954e012b9a", "293971a9-15e0-4a32-9c76-8a9704e304c2", "32242fab-2e7f-490d-8e27-9229aa62e2f8", "4d8c4a8c-f7f0-4063-a576-e28326f6ced3", "6c5e1d10-bd51-4ac6-83f8-b74efec751b2", "729f7ac5-62ac-4784-abf2-536c7b041d7b", "82f0ab5e-d562-45d3-81e2-3a636b4cafd4", "84a1df36-fe9b-41e0-9765-2c215e6b2e88", "93f958b6-b17f-45db-8e44-57e8037a4413", "9add7503-2fff-4957-809a-c12d880e7303", "f95bb313-7af5-45cf-bbd1-f52773fb280a"], "title": "GAIS: A Method for Detecting Interleaved Sequential Patterns from Imperfect Data", "venue": "computational intelligence and data mining", "year": 2007, "id": "ed5df5ea-6ce9-4a6a-b7b7-5f3d27c243ec"}
{"authors": ["Kevin Vlaanderen", "Francisco Valverde", "Oscar Pastor"], "n_citation": 50, "references": ["07f48988-142d-4674-8a64-f8bfdd507ad0", "130fa498-d741-44c4-b628-a30894d64dbb", "21931f41-1cbb-4286-b099-9317a1f6a13c", "2ad0a3a3-6817-405b-9590-4ff14afa9b5d", "2c099b2c-5810-4914-81d3-5ada14dffb9f", "3ab8c369-8fc4-47d6-850e-e10596fe4127", "47d43382-43df-45f3-8dd6-e143aa927d23", "602245ee-8c9b-4aa3-8aca-ffa0846f6120", "69e95f17-0a68-4d14-bdbb-86e37d3d0fef", "742701cf-ddef-410e-b393-483e6114e1ce", "90af0e80-8cb0-40f4-8617-3613edaf83cc", "97e91bc8-4630-4be8-846e-a5eadb736510", "a6139ee6-b91b-4e60-9170-2c32e0090abf", "fb83f6e5-e2fe-49bc-8578-5b9570c8849c"], "title": "Model-Driven Web Engineering in the CMS Domain: A Preliminary Research Applying SME", "venue": "international conference on enterprise information systems", "year": 2008, "id": "507e163b-e241-4fdb-8134-9967b283c1f4"}
{"abstract": "Delay insensitive interfacing was first demonstrated on the macromodules project in the 1960's, but globally synchronous (clocked) schemes have so far dominated the VLSI era. In deep sub-micron technologies, problems of clock skew, including excessive size and power consumption of black buffers, and heterogeneity of systems on a chip are rekindling an interest in global asynchrony. DI-Algebra is presented here as a language for the specification of modules with delay-insensitive interfaces. Such modules can be implemented either in synchronous or in asynchronous logic. A design flow is also illustrated in which specifications are automatically translated into Petri nets, validated and synthesised into asynchronous logic.", "authors": ["Mark B. Josephs", "Dennis P. Furey"], "n_citation": 13, "references": ["00046bbb-59df-4198-bf09-1e389614c00f", "0272636f-05fd-4510-9717-a1cf962605a5", "083fdded-01af-46ac-acab-756302191211", "1ebfbb3c-886b-4215-9688-c5c7c5cd1d64", "33d8ea4b-c987-47f3-a4a2-44fcbcd58a4c", "41a962aa-df4a-4c66-86c8-663ad4f94c35", "6d4458b3-1a92-4f84-b4ed-556be7407c05", "98044ef9-2b6e-4a06-a7de-732d73ac392b", "a5f1e086-d78c-4e13-9021-c59ac9904870", "aaa7c84a-7252-49b5-b26e-1f88eeae95b8", "c72a29a1-6136-4e1e-b7a7-cb71d66cbb0f", "edf84b27-ad6e-4d76-988c-5dcca3dc4887"], "title": "Delay-insensitive interface specification and synthesis", "venue": "design, automation, and test in europe", "year": 2000, "id": "eec1bbb1-e483-40fa-af82-2fc88df37b42"}
{"abstract": "Researchers have recently discovered several interesting, self-organized regularities from the World Wide Web, ranging from the structure and growth of the Web to the access patterns in Web surfing. What remains to be a great challenge in Web log mining is how to explain user behavior underlying observed Web usage regularities. We address the issue of how to characterize the strong regularities in Web surfing in terms of user navigation strategies, and present an information foraging agent-based approach to describing user behavior. By experimenting with the agent-based decision models of Web surfing, we aim to explain how some Web design factors as well as user cognitive factors may affect the overall behavioral patterns in Web usage.", "authors": ["Jiming Liu", "Shiwu Zhang", "Jie Yang"], "n_citation": 108, "references": ["05d9628f-824c-4d33-8d62-9964f9b6c658", "0ca1cbca-31af-4327-8641-5e36f9d37942", "13db07e6-105e-4ac9-9550-11a442a9e6df", "15b3a21f-7830-46cb-89fc-a213d777938d", "17f7dc2b-8858-43f8-98ee-74304b0f3de7", "18819165-7f73-4da1-9bf2-792c258be677", "1a34d746-d1b6-42b6-9e77-19e2569d9627", "259ff48c-d0b9-4fd4-8275-8169c6152224", "34596e78-20bf-473e-8ad7-01d41d918a00", "36f0f3cb-6b32-4284-8e08-0972ee67074f", "3f610d75-809b-4a12-858f-95e346c17e8c", "5a593b43-297d-4644-8b4c-288dd8e4ed4e", "6e551a7c-6769-49c1-93c5-037a06f4aaef", "714bf6ea-6a85-4c82-95f0-9164236bf8b2", "716a3f63-879a-428c-811a-3e2956a2bf79", "80230489-ae23-4e11-96d5-c7e6196f719d", "834de5c0-d266-4fd7-bcf9-f47c44dd01f2", "a3b729ca-810c-4504-80ad-7663848e0e79", "a6a83822-a71e-439f-966a-eaa4f75a7d91", "b2576f0d-c649-4e66-9a6d-54b50151d602", "b2f1d79b-d47a-4f2a-b810-ac3c837d7ee4", "e82396c7-ee73-4e88-aabc-05f31a1068ad", "ec2fb9ab-cee0-4382-971c-31089ed82dfc", "ec9530c1-ff1a-482f-8238-2024c30e36bd", "ef16821d-03cb-4b7c-8561-be78cfe62b0e"], "title": "Characterizing Web usage regularities with information foraging agents", "venue": "IEEE Transactions on Knowledge and Data Engineering", "year": 2004, "id": "5ae4f334-14ab-4f0f-8836-813eba333995"}
{"abstract": "As background, we describe frequently used feedforward wide-area discontinuous power system stability controls. Then we describe online demonstration of a new response-based (feedback) Wide-Area stability and voltage Control System (WACS). The control system uses powerful discontinuous actions for power system stabilization. The control system comprises phasor measurements at many substations, fiber-optic communications, real-time deterministic computers, and transfer trip output signals to circuit breakers at many other substations and power plants. Finally, we describe future development of WACS. WACS is developed as a flexible platform to prevent blackouts and facilitate electrical commerce.", "authors": ["Carson W. Taylor", "D.C. Erickson", "Kenneth E. Martin", "Robert E. Wilson", "Vaithianathan Venkatasubramanian"], "n_citation": 387, "references": [], "title": "WACS-Wide-Area Stability and Voltage Control System: R&D and Online Demonstration", "venue": "Proceedings of the IEEE", "year": 2005, "id": "bd9174d0-c8df-43e6-9d75-ee28d989598e"}
{"abstract": "We consider the relation of symmetries and subspace controllability for spin-1/2 networks with XXZ couplings, subject to perturbation of a single node by a local potential (Z-control). The Hamiltonians for such networks decompose into excitation subspaces. Focusing on the single excitation subspace, it is shown for single-node Z-controls that external symmetries are characterized by eigenstates of the system Hamiltonian which have zero overlap with the control node, and there are no internal symmetries. It is further shown that there are symmetries which persist even in the presence of random perturbations. For XXZ chains with uniform coupling strengths, a characterization of all possible symmetries is given which shows a strong dependence on the position of the node we control. We then show for Heisenberg and XX chains with uniform coupling strength subject to single-node Z-control that the lack of symmetry is both necessary and sufficient for subspace controllability. Finally, the latter approach is generalized to establish controllability results for simple branched networks.", "authors": ["Xiaoting Wang", "Peter Pemberton-Ross", "Sophie G. Schirmer"], "n_citation": 20, "references": ["cd4dfd04-6565-4aa3-b9b0-e829df763846"], "title": "Symmetry and Subspace Controllability for Spin Networks With a Single-Node Control", "venue": "IEEE Transactions on Automatic Control", "year": 2012, "id": "3ab8f9a7-1b36-4d13-a90d-458dc8a195aa"}
{"abstract": "Abstract   The  all nearest smaller values  problem is defined as follows. Let  A  = ( a  1 ,  a  2 ,...,  a n  ) be  n  elements drawn from a totally ordered domain. For each  a i  , 1 \u2264  i  \u2264  n , find the two nearest elements in  A  that are smaller than  a i   (if such exist): the left nearest smaller element  a j   (with  j   i ) and the right nearest smaller element  a k   (with  k  >  i ). We give an  O (log log  n ) time optimal parallel algorithm for the problem on a CRCW PRAM. We apply this algorithm to achieve optimal  O (log log  n ) time parallel algorithms for four problems: (i) Triangulating a monotone polygon, (ii) Preprocessing for answering range minimum queries in constant time, (iii) Reconstructing a binary tree from its inorder and either preorder or postorder numberings, (vi) Matching a legal sequence of parentheses. We also show that any optimal CRCW PRAM algorithm for the triangulation problem requires \u03a9(log log  n ) time.", "authors": ["Omer Berkman", "Baruch Schieber", "Uzi Vishkin"], "n_citation": 119, "title": "Optimal doubly logarithmic parallel algorithms based on finding all nearest smaller values", "venue": "Journal of Algorithms", "year": 1993, "id": "b9934f82-3cb3-442f-bad4-340a0cf850f3"}
{"abstract": "Abstract   Weak logic is a partial logic for program verification and system specification. In this article a sequent calculus for weak logic is first defined. Then the completeness theorem, a cut elimination theorem and some interpolation theorems are proved. In the proofs of the theorems, strategies from first order logic are used with some additions to adapt them to weak logic. One of the interpolation theorems is used for a deeper study of one of the main criterias for the definition of weak logic. In order to find effective strategies for doing proofs within weak logic, a resolution principle for weak logic is given. The relationship between provability in weak logic and provability in first order logic is also studied to make it possible to use all known first order logic proof methods more directly.", "authors": ["Marit Holden"], "n_citation": 50, "references": ["7de82e0b-10cb-411e-9b94-b0ae6e2cc706", "959113e1-d231-486a-8dfa-a195421b6aa7", "f3fbe270-0b20-4b88-aef3-650c11ec423e"], "title": "Weak logic theory", "venue": "Theoretical Computer Science", "year": 1991, "id": "52f16af4-46fa-47c3-93ba-ff7a5d560344"}
{"abstract": "TLA+ and B share the common base of predicate logic, arithmetic and set theory. However, there are still considerable differences, such as very different approaches to typing and modularization. There is also considerable difference in the available tool support. In this paper, we present a translation of the non-temporal part of TLA+ to B, which makes it possible to feed TLA+ specifications into existing tools for B. Part of this translation must include a type inference algorithm, in order to produce typed B specifications. There are many other tricky aspects, such as translating modules as well as let/in and if/then/else expressions. We also present an integration of our translation into ProB. ProB thus provides a complementary tool to the explicit state model checker TLC, with convenient animation and constraint solving for TLA+. We also present a series of case studies, highlighting the complementarity to TLC. In particular, we highlight the sometimes dramatic difference in performance when it comes to solving complicated constraints in TLA+.", "authors": ["Dominik Hansen", "Michael Leuschel"], "n_citation": 25, "references": ["2edcde00-45b3-4ed3-8176-01039b372bcb", "31313522-43c3-4713-862c-51f2e5e88ef5", "3f8a2f95-08e6-44f8-93ae-780cb25b228d", "624e102b-e716-44f3-8957-866f8010c4d4", "63b561c4-ed64-4a03-ac68-aebca9924fd3", "6a2233d0-d198-49a1-92bb-65cb82a87226", "809f0c9d-dc19-4ec0-b48d-3c6ee4ca872a", "8b322f87-9ddd-43be-8295-0e8bb78b1344"], "title": "Translating TLA + to b for validation with ProB", "venue": "integrated formal methods", "year": 2012, "id": "0728cd1e-e3f6-4d2d-975e-36c6a2edd909"}
{"abstract": "Many software projects are based on the integration of independently designed software components that are acquired on the market rather than developed within the project itself. Sometimes interoperability and composition mechanisms provided by component based integration frameworks cannot solve the problem of binary component integration in an automatic way. Notably, in the context of component based concurrent systems, the binary component integration may cause deadlocks within the system. In this paper we present a technique to allow connectors synthesis for deadlock-free component based architectures [2] in a real scale context, namely in the context of COM/DCOM applications. This technique is based on an architectural, connector-based approach which consists of synthesizing a COM/DCOM connector as a COM/DCOM server that can route requests of the clients through a deadlock free policy. This work also provides guide lines to implement an automatic tool that derives the implementation of routing dead-lock-free policy within the connector from the dynamic behavior specification of the COM components. It is then possible to avoid the deadlock by using COM composition mechanisms to insert the synthesized connector within the system while letting the system COM servers unimodified. We present a sucessful application of this technique on the (COM version of the) problem known as  \"The dining philosophers\".  Depending on the type of deadlock we have a strategy that automatically operates on the connector part of the system architecture in order to obtain a suitably equivalent version of the system which is deadlock-free.", "authors": ["Paola Inverardi", "Massimo Tivoli"], "n_citation": 50, "references": ["164d6ccb-15e9-4873-b8ae-523370a39514", "3023929a-c93e-49c5-b03f-7fb0414d94df", "3b3335fb-f28a-4fd2-8a69-b932809e2756", "802fa0be-9de7-47af-a724-5d19983ccc6a", "a13a126e-37f7-4fad-8cfe-a3184320d64a", "b811b9fb-4787-4e1b-a2cb-5c08a4d127a0", "ba1b9b3f-d911-4ad6-bd03-afa54de2ccee", "cb0f1186-5ef9-4504-b72b-75d1161341c2", "cdf09118-ec6c-41ad-bec2-9da6214107b3", "d2656a82-90a0-4cbd-908c-62ba1b03c64f", "dc98562f-e69f-4522-9123-8dbab20ffb33"], "title": "Automatic synthesis of deadlock free connectors for COM/DCOM applications", "venue": "foundations of software engineering", "year": 2001, "id": "9853df41-d7e7-485b-99c4-889728e16d4c"}
{"authors": ["P. Pons", "Matthieu Latapy"], "n_citation": 790, "title": "Computing communities in large networks using random walks.", "venue": "Journal of Graph Algorithms and Applications", "year": 2006, "id": "87d8ffaa-9e66-4e1f-88fd-cdfdab02fb29"}
{"authors": ["Christoph Benzm\u00fcller", "Chad E. Brown", "Michael Kohlhase"], "n_citation": 89, "references": ["1757e19f-0952-4efc-8afb-658223629faf", "32f677a8-4c6e-483e-8cc2-b661d5c41b5a", "7290d971-4e7e-452d-bc76-0c83ff7bf30a", "88f21389-b1fd-4169-989f-9426d8fb9951", "95ae0a81-4247-43dc-910d-7aed2c8bcd1a"], "title": "Higher Order Semantics and Extensionality.", "venue": "Journal of Symbolic Logic", "year": 2004, "id": "8ec40929-e5f7-4b7c-856c-5e719339cdaf"}
{"abstract": "The AI Lab at Chicago has begun development of a new set of software agents designed to manage the flood of data colloquially called the \"information superhighway\". Our approach takes its lead from case-based technology [Riesbeck and Schank, 1989; Hammond, 1989; Kolodner, 1993] in that we are building systems that emphasize the use of examples over explicit queries or questions for communicating with the user.", "authors": ["Kristian J. Hammond", "Robin D. Burke", "Steven L. Lytinen"], "n_citation": 38, "references": ["8026ab23-489b-407b-922c-ab0faf92670b"], "title": "A case-based approach to knowledge navigation", "venue": "international joint conference on artificial intelligence", "year": 1995, "id": "69b2a2a7-d707-4a6f-bbe4-5332a5eb31e5"}
{"abstract": "Developing safe multithreaded software systems is difficult due to the potential unwanted interference among concurrent threads. This paper presents a flexible methodology for object-oriented programs that protects object structures against inconsistency due to race conditions. It is based on a recent methodology for single-threaded programs where developers define aggregate object structures using an ownership system and declare invariants over them. The methodology is supported by a set of language elements and by both a sound modular static verification method and run-time checking support. The paper reports on preliminary experience with a prototype implementation.", "authors": ["Bart Jacobs", "Kaisa Leino", "Frank Piessens", "Wolfram Schulte"], "n_citation": 79, "references": ["026b656f-4393-4aaf-9b17-359bcdc3422d", "119162d6-0403-4980-8096-f6fa5d9fc228", "1407d93a-1fe5-46e2-b2a9-f951ced4faa7", "1788761f-4652-4e50-a778-9ed73b9f4828", "29679f73-c20b-4453-be97-a16bf3f00d3c", "3ad0693d-69cc-415a-81ae-283d89696a63", "3e978595-d7cc-4baa-9215-8a0b33df3a6e", "43047bed-6608-4811-b391-f80995a0c7ca", "591ad907-e143-45f6-87ca-b85ba94aa065", "6050715e-fba1-4a0a-800e-62e48ed9f36c", "66631f9e-7a16-4710-a06e-86c44780a20c", "78d07c73-7bc3-4ae7-998b-adf367e746d3", "7f1dc63a-9064-4768-a30d-3383d52aa81e", "89aa0933-6475-48fe-b965-73639eeca5a6", "b8e8d87a-b0ed-4587-b1f0-4f9a9bd1b0b4", "b95c5df3-dc47-46d9-809b-6fc4b2bac70d", "bd8ee8a8-0dce-4cbf-9908-c4c42fafe5d4", "cb07a6bc-7acc-4eb5-964f-c8ece4a6ed65", "d892fa95-e02d-4f99-8591-65596bc9c22a", "e5f20e4f-7066-4b03-9ed1-ce7c5e87dca2", "ea62b144-8fe5-4caa-8789-08eac39c36a1", "f99f88b3-6cf8-48eb-b153-1e9b4b509199"], "title": "Safe concurrency for aggregate objects with invariants", "venue": "software engineering and formal methods", "year": 2005, "id": "8fb8a1e4-1644-43f4-be80-6aecc25ee219"}
{"abstract": "This work introduces a morphological method for detecting malaria parasites in images of Giemsa stained blood slides. Generally, blood images are made up of three different kinds of cells: red, white and blood platelets. These are distinguished by their dimensions and their colour. In malarial blood the red corpuscles of vertebrates are infected by malaria parasites. The aim of our system is to detect the parasites by means of an automatic thresholding based on a morphological approach, using granulometries to evaluate the size of the red cells and the nuclei of parasites, and the regional maxima to mark the nuclei of parasites.", "authors": ["C. Di Ruberto", "Andrew G. Dempster", "S. Khan", "B. Jarra"], "n_citation": 71, "references": [], "title": "Automatic thresholding of infected blood images using granulometry and regional extrema", "venue": "international conference on pattern recognition", "year": 2000, "id": "d62325cb-27c5-4c33-b35d-a565db8f3b1a"}
{"abstract": "This paper reports an investigation on adult images detection based on the shape features of skin regions. In order to accurately detect skin regions, we propose a skin detection method using multi-Bayes classifiers in the paper. Based on skin color detection results, shape features are extracted and fed into a boosted classifier to decide whether or not the skin regions represent a nude. We evaluate adult image detection performance using different boosted classifiers and different shape descriptors. Experimental results show that classification using boosted C4.5 classifier and combination of different shape descriptors outperforms other classification schemes.", "authors": ["Qing-Fang Zheng", "Wei Zeng", "Gao Wen", "Weiqiang Wang"], "n_citation": 62, "references": ["3484ad55-2cd4-4de5-8cec-70dfb2faa7cb", "3704f939-09a2-4e9f-b851-1261bcd310df", "99f94622-f108-48a6-ae73-a2e39755698b", "d5321e41-3281-4557-ac5a-5c0389818822", "dbdee34d-e053-4d42-9709-2be5637c1677", "ffd5c756-6b5a-4d3b-a3e0-43ac880d5557"], "title": "Shape-based adult images detection", "venue": "international conference on image and graphics", "year": 2004, "id": "444f1300-669e-48ce-93ab-7d9546ccfb86"}
{"abstract": "The problem of buffer overruns, i.e., writing past the end of an array, in C programs has been known since the early seventies as one of the possible consequences of the C language data integrity philosophy. Since the late eighties, when computer security incidents started affecting the Internet, it has been clear that buffer overruns are a powerful threat to system security as they allow ordinary users to gain superuser privileges on Unix systems. Nowadays, buffer overruns are one of the most popular exploits in the hacker scene. In this paper we present a tool for the automatic detection of buffer overrun vulnerabilities in object code. It can be applied to operating system components as well as ordinary programs. The tool is aimed at helping system administrators eliminate vulnerable programs before they are exploited. A fully working prototype for HP-UX and Linux systems is currently available. Extensions are planned for other Unix versions.", "authors": ["Danilo Bruschi", "Emilia Rosti", "R. Banfi"], "n_citation": 50, "references": ["7d7dcaad-1b7c-4eff-a09e-dcef99b17dd3", "7f1dc63a-9064-4768-a30d-3383d52aa81e", "a3ae983a-a5b1-4a66-85c4-f7eaba90def6", "fa33f31a-5556-4d58-b26e-58437c190bc0"], "title": "A Tool for Pro-active Defense Against the Buffer Overrun Attack", "venue": "european symposium on research in computer security", "year": 1998, "id": "ae6929f1-7eea-41e7-958c-1cfa6312b93d"}
{"abstract": "We present a new general Bayesian formulation for simultaneously restoring and segmenting piecewise smooth images. This implies estimation of the associated parameters of the classes within an image, the class label for each image pixel and the number of classes. The intensity image is modelled by parametric models based on regularized networks. The method fits the regions (or classes) with complex spatial intensity distributions with an identifiable group of simple models. Prior information is introduced in form of a two-level Markov random field (MRF). The low\u2010level MRF models the information required to recover piecewise restorations, while the high-level MRF constraints the segmentation. The high\u2010level MRF supports a merging process of simple intensity models into classes.", "authors": ["Mariano Rivera", "James C. Gee"], "n_citation": 12, "references": ["004aa844-c144-4f34-b328-e054848d2c82", "088d00cf-ed12-4552-8958-8b550401f355", "0f550894-de85-48c7-8066-6319a618c057", "116b69da-2870-4418-b672-16f01d4bc750", "1317365d-c46d-4c09-8261-9d07404e4908", "2272406a-608e-4a84-b967-9d6c497ea627", "231d1a48-9bb7-4877-885b-2dc25c9a8b19", "4069943b-539e-45ce-aba6-bef8d1b3bd35", "7b2670a6-3713-4e06-a2f1-b07e9792e017", "89c40268-40a8-4bd2-8eec-e0989c6fc114", "b1c2251e-7b54-41e5-8130-10d9646e02da", "c611dc55-1dd1-4651-a5ba-9f5c25f6538d", "e33abe71-07fd-4486-8df0-b98614d7df4f", "f0c4481d-4a7a-45f9-9b6c-9c9369700949", "f1a977ce-9f9f-44c3-a934-392537ca7cba", "f1fd8a05-54b2-4d92-b251-09f73757416d", "f27cb993-16cd-44f9-b0c8-6bbeb3ecf297"], "title": "Two-level MRF Models for Image Restoration and Segmentation", "venue": "british machine vision conference", "year": 2004, "id": "1218be8d-30fc-4e45-b29e-79427441c9f0"}
{"abstract": "Consider a flock of birds that fly interacting between them. This flock is a hierarchical system in which each bird, at each time step, adjusts its own velocity according to its past velocity and a linear combination of the relative velocities of its superiors in the hierarchy. This linear combination has nonnegative random coefficients, including the case in which each of the birds can fail to see any of its superiors with certain probability. For this model with random interactions we prove that the flocking results, obtained for similar deterministic models, hold true.", "authors": ["Federico Dalmao", "Ernesto Mordecki"], "n_citation": 16, "references": ["1b1e9696-595f-4152-83af-11f8abc3c553", "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9"], "title": "Cucker-Smale Flocking Under Hierarchical Leadership and Random Interactions", "venue": "Siam Journal on Applied Mathematics", "year": 2011, "id": "9b3ad973-941e-406b-b23e-363d54e56bdd"}
{"abstract": "Despite initial suggestions to the contrary, open source software projects exhibit many of the fundamental tenets of software engineering. Likewise, the existence of category-killer apps suggests that conventional software engineering can draw some lessons from OSS. Open source software can elicit strongly contrasting reactions. Advocates claim that OSS is high-quality software produced on a rapid time scale and for free or at very low cost by extremely talented developers. At the same time, critics characterize OSS as variable-quality software that has little or no documentation, is unpredictable as to stability or reliability, and rests on an uncertain legal foundation-the result of a chaotic development process that is completely alien to software engineering fundamental tenets and conventional wisdom.", "authors": ["Brian Fitzgerald"], "n_citation": 21, "references": ["03292aaa-ba6a-4266-a01d-0e7a46dc6586", "3e0ded3d-6098-4603-8e0b-30685757b0d9", "3e51f69c-a204-4a99-844d-3aa3d17359f0", "3e7cf8da-e974-4840-984d-87099b1181e2", "44614476-04cb-4de9-98b2-44744a4b5ed3", "4b5a6733-ac25-442c-ba04-4b8b3d460bc6", "541641ab-a9d8-4aa8-ac1c-29d1bb1057a3", "9028af12-d61a-4657-b834-d09b467c9235", "a5948581-8445-490c-8364-ce8b4bdd3965", "aec3b978-3a42-4ba7-9b05-9fbeefbdfea8", "dc7f7c70-02ec-4ed0-a47f-103705f97876", "ff5847a0-60a3-4968-984d-2db0b2eac791"], "title": "Open Source Software: Lessons from and for Software Engineering", "venue": "IEEE Computer", "year": 2011, "id": "e3306cae-4812-4e39-8a65-6427a7195ef5"}
{"abstract": "In this paper, a novel discrete-time implementation of sliding-mode control systems is proposed, which fully exploits the multivaluedness of the dynamics on the sliding surface. It is shown to guarantee a smooth stabilization on the discrete sliding surface in the disturbance-free case, hence avoiding the chattering effects due to the time-discretization. In addition, when a disturbance acts on the system, the controller attenuates the disturbance effects on the sliding surface by a factor  h  (where  h  is the sampling period). Most importantly, this holds even for large  h  . The controller is based on an implicit Euler method and is very easy to implement with projections on the interval [-1, 1] (or as the solution of a quadratic program). The zero-order-hold (ZOH) method is also investigated. First- and second-order perturbed systems (with a disturbance satisfying the matching condition) without and with dynamical disturbance compensation are analyzed, with classical and twisting sliding-mode controllers.", "authors": ["Vincent Acary", "Bernard Brogliato", "Yury Orlov"], "n_citation": 87, "references": ["0cdb505b-6d58-4563-865f-3e66841c7984", "2313cbf2-1d1c-44cf-892b-0d6e8e22243f", "513f4b35-25f7-4430-9f7e-944d0c1e2e6a", "70451733-fee9-41ba-bd69-a15532a17dc7", "783f9ed4-1125-4eb7-a46a-f269c11bd9e0", "88d0856c-81f5-4b0f-a7ab-e0b25e1e5d1d", "9c097e1e-0d32-43af-bb73-ebec4054b947", "a642dec1-77d9-40ad-8334-353631d9a2d7", "c5e7e660-018b-4c3d-8d36-85b4fce5c8c3", "c609590f-6569-435b-b7cf-e8a33ca8992b", "c926c120-7a1f-4778-a882-0c1cc138752a", "cbe14762-f568-46c2-839c-9bb5b75443c9", "d2324885-5296-438f-b9b2-b482232a212f", "e52cc400-ef23-4ead-b56f-e6f29359b391"], "title": "Chattering-Free Digital Sliding-Mode Control With State Observer and Disturbance Rejection", "venue": "IEEE Transactions on Automatic Control", "year": 2012, "id": "ed57c2b2-46b4-48c1-89cb-bafc9945a205"}
{"authors": ["Katerina Goseva-Popstojanova", "Kishor S. Trivedi"], "n_citation": 77, "references": ["8f00a63e-fb1f-41be-9717-0b2749776687", "e1161405-6718-4983-8717-1354ecac5401"], "title": "Stochastic Modeling Formalisms for Dependability, Performance and Performability", "venue": "Performance Evaluation", "year": 2000, "id": "b18e8c5e-dc3e-4574-b310-57f9b0856b19"}
{"abstract": "The focus of the paper is on the analysis of performance effects of different security solutions modeled as aspects in UML. Aspect oriented modeling (AOM) allows software designers to isolate and separately address solutions for crosscutting concerns, which are defined as distinct UML aspect models, then are composed with the primary UML model of the system under development. For performance analysis we use techniques developed previously in the PUMA project, which take as input UML models annotated with the standard UML Profile for Schedulability, Performance and Time (SPT), and transform them first into Core Scenario Model (CSM) and then into different performance models. The contribution of this paper is in performing the composition of the aspects with the primary model at the CSM level. The input is represented by the primary model and a number of aspect models in UML+SPT, which are processed as follows: a) converted separately to CSM; b) composed into a single CSM model; c) transformed into a Layered Queueing Networks (LQN) model and d) analyzed. The proposed approach is illustrated with a case study based on two standards, TPC-W and SSL.", "authors": ["Dorina C. Petriu", "C. M. Woodside", "Dorin Bogdan Petriu", "Jianjun Xu", "Tauseef A. Israr", "Geri Georg", "Robert B. France", "James M. Bieman", "Siv Hilde Houmb", "Jan J\u00fcrjens"], "n_citation": 39, "references": ["3464a3b2-a0cd-4100-9dd2-1d80bd7f62b5", "3a345250-62be-4ec9-b571-ebb5e70f23b3", "5241398d-575f-49c2-8c82-e416ee62e9d7", "984badec-4081-46fc-aee0-114b1988b96f", "99f310eb-97db-4e20-9db7-d1d5bcdb61ac", "a4d5cb9d-c3a8-49b7-b6c8-effd7b6fa581", "af481f6f-28ed-450b-97ab-90053e681184", "c99658ac-bd8f-455e-ac3c-e48c59eb19ba", "cd7a3f02-da50-40a5-927a-9354867d2f0e", "cef2f59c-7d4c-404f-9bdd-d850906bc105", "d00afa4c-a93b-44d0-9d45-70f36f251f59"], "title": "Performance analysis of security aspects in UML models", "venue": "workshop on software and performance", "year": 2007, "id": "0702aa82-75f9-44e6-a072-ce4a9b76e3d6"}
{"authors": ["Jean Marc Couveignes", "Fran\u00e7ois Morain"], "n_citation": 54, "references": ["ee45a1f8-2526-49a0-9b7c-d4ded8445b96"], "title": "Schoof's algorithm and isogeny cycles", "venue": "", "year": 1994, "id": "c7d43463-ad8d-4606-b66b-50f1441237c8"}
{"abstract": "A novel chaotic time-series prediction method based on support vector machines (SVMs) and echo-state mechanisms is proposed. The basic idea is replacing \"kernel trick\" with \"reservoir trick\" in dealing with nonlinearity, that is, performing linear support vector regression (SVR) in the high-dimension \"reservoir\" state space, and the solution benefits from the advantages from structural risk minimization principle, and we call it support vector echo-state machines (SVESMs). SVESMs belong to a special kind of recurrent neural networks (RNNs) with convex objective function, and their solution is global, optimal, and unique. SVESMs are especially efficient in dealing with real life nonlinear time series, and its generalization ability and robustness are obtained by regularization operator and robust loss function. The method is tested on the benchmark prediction problem of Mackey-Glass time series and applied to some real life time series such as monthly sunspots time series and runoff time series of the Yellow River, and the prediction results are promising", "authors": ["Zhiwei Shi", "Min Han"], "n_citation": 204, "references": ["01b486c4-8955-403b-a0c6-1de74298b215", "1dd9b2a2-4d21-4247-b9a3-0c289562023b", "2880d3f7-e783-419f-8f03-f993d13a3599", "2cbdd97b-393f-4def-b945-b0694dea2db8", "2f5adf78-25e5-42e4-9a6c-435617f57387", "44b09589-e889-4755-ac01-fae8b5333f9e", "4d4e9cdf-0544-42ac-b1b4-85bfd7b0a688", "50dd56db-151d-4d62-8576-65f0ef6f381b", "5dedaf52-0a62-4822-b9eb-4b86acca6842", "672b1f54-d6dc-465b-90f4-afe2bf3868ac", "6f2d6b6e-d113-4c4f-981d-22d6f817feb7", "7cfdb4e6-c0c8-4944-821a-d6e0f39cf5e7", "81e69d71-355c-4492-b3d7-3a6d09ae4a56", "95849030-6387-4709-931e-c9732cfa3604", "a10295e7-57c2-4a69-82f2-112e11876a50", "a530b2e9-d9af-464a-a9ea-aea3031b5b95", "b33eea94-414c-4232-a1b8-1ffc687c1d61", "b6c50d72-c7b6-4c7e-a5a4-faca2eed1dab", "c133c299-f7f1-46d4-bf4f-d55dd76152dc", "c1f94cf8-05cf-4c5f-a8cf-c13cb0d618eb", "c7553d0c-160f-49d7-9bff-ec5d6b3fc043", "cbfaaf9a-dab7-4377-92a5-a7f39e9894f5", "d0e1baf1-53cf-4102-8f0b-832d027d1f07", "d396d014-125e-4147-89e5-c3a8a278e087", "d427d981-86f9-4d0a-83c3-a8d69e5fbcb7", "e98150ad-6f56-47b5-b15b-cd588dbee9fd", "f6a95e9f-49fe-4bac-8f00-cfb7d50ae02c", "f786c750-24fb-4439-a50f-284f9d3d1f0f", "fc9f0b78-acd3-4f2e-9675-f2576c145458", "ff3e5829-e3c0-43eb-a74b-edfe8ca2ec77"], "title": "Support Vector Echo-State Machine for Chaotic Time-Series Prediction", "venue": "IEEE Transactions on Neural Networks", "year": 2007, "id": "91d7c0ca-75d3-423e-a383-4d93473d4636"}
{"abstract": "Sensor data fusion imposes a number of novel requirements on query languages and query processing techniques. A spatial/temporal query language called /spl Sigma/QL has been proposed to support the retrieval and fusion of multimedia information from multiple sources and databases. In this paper we investigate fusion techniques, multimedia data transformations and /spl Sigma/QL query processing techniques for sensor data fusion. Fusion techniques including fusion by the merge operation, the detection of moving objects, and the incorporation of belief values, have been developed. An experimental prototype has been implemented and tested to demonstrate the feasibility of these techniques.", "authors": ["Shi-Kuo Chang", "Gennaro Costagliola", "Erland Jungert", "Francesco Orciuoli"], "n_citation": 50, "references": ["1bcea16c-bd33-4374-832f-04262b9bef11", "27fdbf24-561e-4cc2-85ed-9f2bddc20057", "55f94681-1160-437d-82d6-12ba41d3ac03", "9cf4eb54-3880-4ae0-8486-876ecd196cb9", "9e41c12c-f101-46c9-9f29-4b572e5ef8e1", "b6d7b91d-4be0-43a1-8d34-55ef817607cd", "c8ae1b5e-b86c-4dfb-9f81-d6736c343f7e", "d10f840c-1003-48b5-8aec-3ecc0957c658", "e52ca406-8e6c-434d-b81e-eb133f35c936", "f0f037c0-2ca3-4f46-9fb0-86036200dc7a"], "title": "Querying distributed multimedia databases and data sources for sensor data fusion", "venue": "IEEE Transactions on Multimedia", "year": 2004, "id": "4a35e652-ed05-4c6d-b282-ab13cf661d0c"}
{"abstract": "Schnorr's algorithm for finding an approximation for the shortest nonzero vector in an n dimensional lattice depends on a parameter k. He proved that for a fixed k \u2264 n his algorithm (block 2k-reduction) provides a lattice vector whose length is greater than the length of a shortest nonzero vector in the lattice by at most a factor of (4k 2 )  n/k . (The time required by the algorithm depends on k.) We show that if k=o(n), this bound on the performance of Schnorr's algorithm cannot be improved (apart from a constant factor in the exponent), namely there is a lattice and a basis so that if they are given as an input to the algorithm then the resulting approximating factor of the output is at least k  e n/k . (For larger integers k if Schnorr's algorithm runs in polynomial time then we have already a polynomial time algorithm for finding the shortest nonzero vector.) We also solve an open problem formulated by Schnorr about the the Korkine-Zolotareff lattice constants \u03b1 k . We show that his upper bound \u03b1 k  \u2264 k 1 + ln k  is the best possible apart from a constant factor in the exponent. We prove a similar result about his upper bound \u03b2 k \u2264 4k 2 , where \u03b2 k  is another lattice constant with an important role in Schnorr's analysis of his algorithm.", "authors": ["Mikl\u00f3s Ajtai"], "n_citation": 40, "references": ["17fec023-4dc7-4e13-9ba4-9faff42cab68", "3271f525-e147-4578-982e-4c30ccde543b", "7963923e-b1cc-4726-9909-060f62b76420", "9b0d57b5-65a7-4867-b029-bb9bdf186409", "a8ffa607-db68-488e-a90b-6e345e26719e", "b0158446-39e4-4e00-82d7-2ab092008a0d", "b72803fa-a741-404e-9ac7-d169a8d763e7", "b8305b02-352d-4279-9645-39505103d60c"], "title": "The worst-case behavior of schnorr's algorithm approximating the shortest nonzero vector in a lattice", "venue": "symposium on the theory of computing", "year": 2003, "id": "dea4e253-ee10-41ca-bc08-04551a564779"}
{"abstract": "Abstract It is generally assumed that technology assists individuals in improving the quality of their lives. However, the impact of new technologies and media on well-being and positive functioning is still somewhat controversial. In this paper, we contend that the quality of experience should become the guiding principle in the design and development of new technologies, as well as a primary metric for the evaluation of their applications. The emerging discipline of Positive Psychology provides a useful framework to address this challenge. Positive Psychology is the scientific study of optimal human functioning and flourishing. Instead of drawing on a \u201cdisease model\u201d of human behavior, it focuses on factors that enable individuals and communities to thrive and build the best in life. In this paper, we propose the \u201cPositive Technology\u201d approach\u2014the scientific and applied approach to the use of technology for improving the quality of our personal experience through its structuring, augmentation, and/or re...", "authors": ["Giuseppe Riva", "Rosa M. Ba\u00f1os", "Cristina Botella", "Brenda K. Wiederhold", "Andrea Gaggioli"], "n_citation": 159, "references": ["091ee4d2-1e9d-41c2-a3f8-48d588a6c159", "13d82dec-a4d7-4c51-8e8e-bdf3bd3374d4", "142e7454-b847-4b82-bb7e-cbf908249012", "189e8302-b2c9-4fe0-a366-60179ec7240f", "1dfe986a-8e3f-4eac-831c-0d47f4022cbe", "1e34b9cb-9e04-4408-915d-5e15e2cb68ce", "1efafce4-25bf-4e6d-9d61-e12b42e7135f", "3dfcb0b9-e822-4d14-a1d4-a2cefde687d2", "5010dd94-8999-46ef-a18a-24493893e9cf", "58a14cc0-0498-4881-8fd4-79b4d7c7ed9b", "6d1c4c3f-2bd7-40e9-bbbe-0538166d88fb", "7087bf9c-0382-4fe4-8310-25ddbe22c12b", "7c678eda-da78-4552-84ae-34c695f17cc9", "a4a3ed32-2446-423b-88f9-44079d0e79a0", "b265d51c-c2ec-4a15-826b-f2f4bbd7be43", "ceea02a8-b7d0-4871-9887-c12e725b8c4a", "d6e1d07d-ae0f-4778-835e-59d4a9c27422", "d7f07233-fe0e-4f57-8f3d-e3ba877b6cf8", "f2365779-405a-49cd-8179-ee7d867d0354", "f723c816-ae04-419e-92e1-e52b88f84677", "fa39aca8-a0c9-4b36-bb78-b1cd1e1a5cf1"], "title": "Positive Technology: Using Interactive Technologies to Promote Positive Functioning", "venue": "Cyberpsychology, Behavior, and Social Networking", "year": 2012, "id": "3db671c8-3509-49da-88f8-112d28800907"}
{"abstract": "Recently there has been a great amount of interest in Random Constraint Satisfaction Problems, both from an experimental and a theoretical point of view. Rather intriguingly, experimental results with various models for generating random CSP instances suggest a threshold-like behavior and some theoretical work has been done in analyzing these models when the number of variables becomes large (asymptotic). In this paper we prove that the models commonly used for generating random CSP instances do not have an asymptotic threshold. In particular, we prove that as the number of variables becomes large, almost all instances they generate are trivially overconstrained. We then present a new model for random CSP and, in the spirit of random \u03ba-SAT, we derive lower and upper bounds for its parameters so that instances are almost surely underconstrained and overconstrained, respectively. Finally, for the case of one of the popular models in Artificial Intelligence we derive sharper estimates for the probability of being overconstrained, as a function of the number of variables.", "authors": ["Dimitris Achlioptas", "Lefteris M. Kirousis", "Evangelos Kranakis", "Danny Krizanc", "Michael Molloy", "Yannis C. Stamatiou"], "n_citation": 194, "references": ["00d7f7a9-6c77-4d36-b60f-4ece1ed099da", "288dce14-855c-4502-a7d2-cbc4dee2a31e", "2bc39e37-d0ff-4446-89c8-0636092c8457", "3be0a8de-dd45-4878-9520-166ddfde9914", "488f691a-6dbc-447d-a409-6af945e2a611", "9023f158-a521-4f98-b624-4b62cd99eb77", "d198f89e-586d-452d-9f5e-213215defc43", "e5726643-d79f-421f-96c4-fef8ee716949", "f5996e94-8aa2-4ebd-b0f8-b2fa7ed33865", "fb9b9cd8-7da0-42a6-ada0-6d53d77c4f2b"], "title": "Random constraint satisfaction: A more accurate picture", "venue": "principles and practice of constraint programming", "year": 1997, "id": "28d7dafb-2b7a-48cc-bd37-6c5a3847645b"}
{"abstract": "The UniForM Workbench is an open ended tool integration framework for developing (formed) Software Development Environments (SDE) from the basis of pre-fabricated off-the-shelf development tools. The integration framework provides support for data, control and presentation integration as well as utilities for wrapping Haskell interfaces around existing development tools. Entire SDE's are then glued together on the basis of these encapsulations using Concurrent HciskeU as the integration language, thus allowing integration to be done at a level of abstraction that is very close to the one offered by constructive formal specifications. So far, the integration framework has successfully been used to integrate tools for Haskell program development as well cis specification and proof tools for Z specifications.", "authors": ["Einar W. Karlsen"], "n_citation": 19, "references": ["0c2efb75-728c-452c-8705-0e3d3822253c", "17dd59ad-378b-4a89-be7e-6d2b4ce9ed1f", "1d9e72ce-a7b4-4747-8ea3-e1871f60a564", "212d2b28-0aff-48e4-b0d7-20725bdb73f5", "23c82e3b-76e3-401a-835b-7b7cc9e708c0", "2d669148-939a-4a19-bfad-3492a80bcdbd", "3023929a-c93e-49c5-b03f-7fb0414d94df", "4f88d229-c13a-4cf0-ab22-2d55c8dfcff6", "52391e5d-c3cb-4313-b139-5d60a38f480e", "6140a0e3-7113-4586-ab69-551ada879894", "815396f0-0de6-4784-9014-30467e295cdb", "94060baf-db6f-438f-9310-3cb2562c94c1", "96d132e8-3185-4fc3-95de-7feca1d3fae0", "9801a8a7-90c9-4f54-abea-35bfaa48ecb7", "a4bcc061-69fa-4804-94ff-e7d3f6af77ea", "aa935a6d-ce79-4ce6-b57c-d78fa6b7f3ee", "be4e70ab-7fc3-4b20-892d-8a0e4fe88b88", "cc98554f-3e46-4e4c-9762-6a15eb775f81", "dfbf0164-0416-4728-ad22-37422110ba24", "eb3f25cf-e595-4ad6-ab3e-2f7625989dac", "f44333a1-b6b5-44dd-8f44-83f8a4761815", "fc1d63b9-24c6-4bc8-85a8-ccc2fc7f6a7d"], "title": "The UniForM WorkBench - A Higher Order Tool Integration Framework", "venue": "formal methods", "year": 1998, "id": "1a53d8bf-345b-415b-9c7d-c56ce1c3389e"}
{"abstract": "This paper is concerned with rule-based coordination of motion for rough-terrain locomotion by a hexapod walking machine. The logic for generating leg commands is written in Prolog while the simulation of the terrain and of the vehicle kinematics, as well as low-level on-board computer functions, are written in extended Common Lisp. It is found that this approach results in code that is much easier to understand and modify than previous motion coordination programs written in Pascal. We believe that the motion coordination rule set included in this paper results in better adaptation of walking machine leg sequencing to terrain constraints than any previously published means.", "authors": ["Se-Hung Kwak", "Robert B. McGhee"], "n_citation": 15, "references": ["28dc09c7-2995-4ea5-a26b-ffac3382606f", "3a6eefe9-dd8e-4f5a-9c64-eb19664076d6", "53e80315-b6e4-4194-84a3-82190c84238c", "611f6a98-d11a-4b24-8d3a-267c025d4bc2", "6e2cf53c-fcfd-4f09-aae1-ef0c2bb45fd5", "d1c3911b-2416-456d-81d2-8ef879f84f8f", "d8afd802-5d06-4648-b854-2c4549db0930"], "title": "Rule-based motion coordination for a hexapod walking machine", "venue": "Advanced Robotics", "year": 1989, "id": "1c8194a4-0f45-4b8f-a4b2-080c81774fa7"}
{"abstract": "To improve software productivity, we have to stop developing applications from scratch and make use of exiting solutions that have been applied, tested, and proven useful in successful projects. Patterns promise new design reuse benefits early in the development lifecycle. To reap the benefits of deploying these proven design solutions, we need to define systematic development approaches to construct application designs using patterns. We introduce a novel pattern-oriented analysis and design (POAD) approach that utilizes patterns as building blocks (components) at the design level. The approach glues the design structure of patterns at various levels of abstraction for the purpose of developing pattern oriented designs. We describe the development phases and steps using a purpose/process/product template. We use a running example to describe the application of each step. The POAD approach produces hierarchical traceable design models that capture interaction between patterns.", "authors": ["Sherif M. Yacoub", "Hany H. Ammar"], "n_citation": 11, "references": ["062e46cf-18b1-4b28-8937-e21af2363eab", "3ac7fef9-70b8-40d4-b881-c2a4e1ce0e93", "483fe0cb-245d-4c8d-aed5-cee587156b94", "6693238e-9cd0-4359-888a-c03d83f60afc", "b830746b-b58e-44c2-85b5-e325c13a53bb", "bbdab0a8-1b13-44ea-9b2c-f7b3ec7bc94a", "e170e25b-b5bd-4a48-9732-27b77370b352", "f970ec4b-0720-4370-abcf-bafedb54a40f"], "title": "Pattern-oriented analysis and design (POAD): a structural composition approach to glue design patterns", "venue": "", "year": 2000, "id": "c0bd02b9-311c-45fa-b567-0a086fdd3c5f"}
{"abstract": "Packet delay greatly influences the overall performance of network applications. It is therefore important to identify causes and locations of delay performance degradation within a network. Existing techniques, largely based on end-to-end delay measurements of unicast traffic, are well suited to monitor and characterize the behavior of particular end-to-end paths. Within these approaches, however, it is not clear how to apportion the variable component of end-to-end delay as queueing delay at each link along a path. Moreover, there are issues of scalability for large networks. In this paper, we show how end-to-end measurements of multicast traffic can be used to infer the packet delay distribution and utilization on each link of a logical multicast tree. The idea, recently introduced in Caceres et al. (1999), is to exploit the inherent correlation between multicast observations to infer performance of paths between branch points in a tree spanning a multicast source and its receivers. The method does not depend on cooperation from intervening network elements; because of the bandwidth efficiency of multicast traffic, it is suitable for large-scale measurements of both end-to-end and internal network dynamics. We establish desirable statistical properties of the estimator, namely consistency and asymptotic normality. We evaluate the estimator through simulation and observe that it is robust with respect to moderate violations of the underlying model.", "authors": ["Francesco Lo Presti", "Nick G. Duffield", "Joseph Horowitz", "Donald F. Towsley"], "n_citation": 315, "references": ["125299a0-d010-4913-bdd8-690ea40a7cd5", "14330801-56db-4b21-bada-858fedfcdf66", "1642f59c-10a1-40da-abb1-0934ef864108", "1cf998eb-4121-4eb5-9b07-a398a05dfd1a", "4b5c9003-da3b-4a1c-9ddd-0262278668e5", "7559c438-b897-4dc1-9766-fd77f3cf6098", "7876cae8-1f94-4611-874d-5976798cc418", "88c35cd8-dd49-44f8-9674-96974c8f3650", "961eff32-5c9c-420a-9302-ef2fbd7f7a15", "992ee36f-a6ca-48ad-9fd7-80d41bdbc16f", "bca24aff-d6ba-4f1c-b82a-ffbc52815148", "bf785568-5826-4228-998d-e21823dfc8ab", "c48d5e6b-cfc7-4d16-9dea-8de094e2aecc", "d15d70e1-c0ad-4957-92f0-c8cee7710af8", "d203eca6-41a1-4e8f-9262-77ce686366e7", "d2b7db5d-bc47-48c7-a173-865fed9bff96", "dd870fee-1d2a-495b-9f06-492e1f9e8f0c", "e4128b01-edcc-4749-b7f7-4a8798ae4f08", "ef9bd2f8-ed99-4248-b65b-b23e776757f8"], "title": "Multicast-based inference of network-internal delay distributions", "venue": "IEEE\\/ACM Transactions on Networking", "year": 2002, "id": "e03e4a46-ae12-4a07-b38c-63aa3ad1f98b"}
{"abstract": "In recent years, various mobile terminals equipped with NFC (Near Field Communication) have been released. The combination of NFC with smart devices has led to widening the utilization range of NFC. It is expected to replace credit cards in electronic payment, especially. In this regard, security issues need to be addressed to vitalize NFC electronic payment. The NFC security standards currently being applied require the use of user's public key at a fixed value in the process of key agreement. The relevance of the message occurs in the fixed elements such as the public key of NFC. An attacker can create a profile based on user's public key by collecting the associated messages. Through the created profile, users can be exposed and their privacy can be compromised. In this paper, we propose conditional privacy protection methods based on pseudonyms to solve these problems. In addition, PDU (Protocol Data Unit) for conditional privacy is defined. Users can inform the other party that they will communicate according to the protocol proposed in this paper by sending the conditional privacy preserved PDU through NFC terminals. The proposed method succeeds in minimizing the update cost and computation overhead by taking advantage of the physical characteristics of NFC 1 .", "authors": ["Hasoo Eun", "Hoonjung Lee", "Junggab Son", "Sangjin Kim", "Heekuck Oh"], "n_citation": 70, "references": ["081f5009-fed7-4ea5-b8b6-906a191c3f1b", "525cfe11-7eb9-4483-8f78-07148e31e654", "5b70e1f6-6c91-4c52-9dc8-5cc72a008c92", "9f716991-0005-489b-9c72-8fe9cfa061bb", "b78efcb9-52ed-40a5-a8d0-1a21b9e7ec64", "bd8a5be9-27bc-4997-aa6a-ef5f87f6418a", "bfec308d-5efa-4006-b4c9-da462997c5a3", "db936728-d713-49b4-88dc-b6392caba841"], "title": "Conditional privacy preserving security protocol for NFC applications", "venue": "IEEE Transactions on Consumer Electronics", "year": 2012, "id": "8268277f-6088-4406-8433-06656b79874c"}
{"abstract": "Business rules are a set of conditional operations attached to a given data result. On legacy systems, it is very difficult to extract business rules because of the inconsistency of documentation. Some techniques have been presented for extracting business rules from legacy systems. But usefulness of these methods is limited when they are applied to large complex legacy systems. Generally, large legacy systems involve large amount of code, domain variables, synonym variables and business rules, which make it more difficult to extract business rules. This paper proposes a framework, which offers distinct advantages over normal extraction solutions for large legacv systems. This framework consists of five steps: slicing program, identifying domain variables, data analysis, presenting business rules, and business validation. It has been applied to a large complex financial legacy system which has proved to be successful.", "authors": ["Xinyu Wang", "Jianling Sun", "Xiaohu Yang", "Zhijun He", "Srinivasa R. Maddineni"], "n_citation": 54, "references": ["217e9404-6537-4b1a-9a05-3f1e7e1ec04c", "2c08d317-3848-40af-9dfa-20c8ce584ce9", "7d3ea4fc-19ee-4eb3-b916-02664a640120", "83758f73-7bf2-4c4d-ba31-0e4d80cdd6b0", "84958687-74e0-4bf0-b6f5-9c36ec550442", "93c45f44-e4b0-4ed1-ac06-a81c0366de10", "aa9805b3-4f30-46ae-af5b-a2cf2e915265", "bdc1501f-8500-4637-a435-925823a383f0", "fd16f8a9-13ee-4db9-9489-f2b5a3a30d1c"], "title": "Business rules extraction from large legacy systems", "venue": "conference on software maintenance and reengineering", "year": 2004, "id": "d05fdc90-26f2-4f35-b5fb-ec9301eb96af"}
{"abstract": "Given models for healthy brains, tumor segmentation can be seen as a process of detecting abnormalities or outliers that are present with certain image intensity and geometric properties. In this paper, we propose a method that segments brain tumor and edema in two stages. We first detect intensity outliers using robust estimation of the location and dispersion of the normal brain tissue intensity clusters. We then apply geometric and spatial constraints to the detected abnormalities or outliers. Previously published tumor segmentation methods generally rely on the intensity enhancement in the T1-weighted image that ap- pear with the gadolinium contrast agent, on strictly uniform intensity patterns and most often on user initialization of the segmentation. To our knowledge, none of the methods integrated the detection of edema in addition to tumor as a combined approach, although knowledge of the extent of edema is critical for planning and treatment. Our method relies on the information provided by the (non-enhancing) T1 and T2 image channels, the use of a registered probabilistic brain atlas as a spa- tial prior, and the use of a shape prior for the tumor/edema region. The result is an efficient, automatic segmentation method that defines both, tumor and edema.", "authors": ["Marcel Prastawa", "Elizabeth Bullitt", "Sean Ho", "Guido Gerig"], "n_citation": 48, "references": ["0417d928-0c5c-4147-a5b4-d2571e255920", "120eea17-1148-4df1-b491-47064e2e6794", "2084a9d4-c322-494d-8143-14f677548d19", "33f60577-cead-426d-9c4c-88c34d750000", "568d5c5f-e617-420f-8b86-5fcffa4c1277", "897b0d64-16f8-4abe-b3a6-19cad2753449", "8cee446f-cf29-48de-a579-7c929dd686cc", "aa08d40f-2000-4828-bfc5-fba0fb064fc2", "c6dd1155-2ec9-4371-96dc-3ee5f42387ff", "dc416118-6eb8-4685-87b2-4f0f135513a7", "dfb8bf07-b93b-44d1-bd5a-c2329aac465d", "fea195f3-b673-4374-9bb7-617ac6b384f9"], "title": "Robust Estimation for Brain Tumor Segmentation", "venue": "medical image computing and computer assisted intervention", "year": 2003, "id": "ad31c123-11a4-4e9e-a956-8c44703d3715"}
{"abstract": "In this paper, a basic cell for low-power and/or low-voltage operation is identified. It is evidenced how different versions of this cell, coined as \"flipped voltage follower (FVF)\" have been used in the past for many applications. A detailed classification of basic topologies derived from the FVF is given. In addition, a comprehensive list of recently proposed low-voltage/low-power CMOS circuits based on the FVF is given. Although the paper has a tutorial taste, some new applications of the FVF are also presented and supported by a set of simulated and experimental results. Finally, a design example showing the application of the FVF to build systems based on translinear loops is described which shows the potential of this cell for the design of high-performance low-power/low-voltage analog and mixed-signal circuits.", "authors": ["R.G. Carvajal", "J. Ramirez-Angulo", "Antonio J. L\u00f3pez-Mart\u00edn", "A. Torralba", "Juan Antonio G\u00f3mez Gal\u00e1n", "Alfonso Carlosena", "Fernando Mu\u00f1oz Chavero"], "n_citation": 388, "references": ["20c72228-fa52-45e2-8df6-b1e0a98c11d4", "6ab8c9a7-a83d-4d84-ac92-16f659624542", "820f9244-b09d-457a-9067-9b4116c31d06", "90137d53-1c81-4bdd-8ae7-9ae23c701f12", "ef543e14-13a6-423a-b82a-49e190bbd89b"], "title": "The flipped voltage follower: a useful cell for low-voltage low-power circuit design", "venue": "IEEE Transactions on Circuits and Systems I-regular Papers", "year": 2005, "id": "8f556924-3ac6-45bc-bcdc-f0cad021603a"}
{"abstract": "Most extant debugging aids force their users to think about errors in programs from a low-level, unit-at-a-time perspective. Such a perspective is inadequate for debugging large complex systems, particularly distributed systems. In this paper, we present a high-level approach to debugging that offers an alternative to the traditional techniques. We describe a language, edl, developed to support this high-level approach to debugging and outline a set of tools that has been constructed to effect this approach. The paper includes an example illustrating the approach and discusses a number of problems encountered while developing these debugging tools.", "authors": ["Peter C. Bates", "Jack C. Wileden"], "n_citation": 167, "references": ["136c4780-2f25-4068-90a5-aed6afaf2890", "4fa28e30-c2ec-4330-8ecf-c0cba9124f25", "590761f7-626f-472e-93d3-959c3177fbea", "7fec773a-eb8a-44b7-9d5a-46ac2d97727d", "9cda664d-cc7f-4e93-933f-d70cd9dadf23", "c187cfb5-f826-44bc-b4cc-9dab2d80b781", "ec94ce2e-d066-4783-b7dd-ec7af6c64c6c"], "title": "High-level debugging of distributed systems: The behavioral abstraction approach", "venue": "Journal of Systems and Software", "year": 1983, "id": "4df54c43-312f-46e2-8b3b-2415a81b36e6"}
{"abstract": "A major issue in Pervasive Computing in order to design and implement context\u2013aware applications is to correlate information provided by distributed devices to furnish a more comprehensive view of the context they habit. Such a correlation activity requires considering a spatial model of this environment, even if the kind of information processed is not only of spatial nature. This paper focuses on the notions of place and conceptual spatial relation to present a commonsense formal model of space supporting reasoning about meaningful correlation. The model consists of a relational structure that can be viewed as the semantic specification for a hybrid logic language, whose formulas represent contextual information and whose satisfiability procedures enhance reasoning, allowing the local perspective typical of many approach to context\u2013awareness.", "authors": ["Stefania Bandini", "Alessandro Mosca", "Matteo Palmonari"], "n_citation": 50, "references": ["199560bb-cd8d-4297-89b1-9f975643b7c3", "37b7dee1-e972-4f4e-b0d1-818a78ff275c", "387b58e0-e492-45e2-acbb-8c949a5508fc", "9f16f8fa-193b-430e-ab21-d6a5dbfa1380", "a68ccab3-acc3-4fb1-9831-62d12e9f88f5", "bfcd175b-d3f8-4a79-8708-3bd75e62de20", "dc309c41-7182-4234-ab5a-5313b2bd2853"], "title": "Commonsense spatial reasoning for context\u2013aware pervasive systems", "venue": "location  and context awareness", "year": 2005, "id": "7f4c6925-50e3-4f49-ac85-49e519338ea2"}
{"abstract": "In this paper, we present a top down approach for integrated process modelling and distributed process execution. The integrated process model can be utilized for global monitoring and visualization and distributed process models for local execution. Our main focus in this paper is the presentation of the approach to support automatic generation and linking of distributed process models from an integrated process definition.", "authors": ["Wasim Sadiq", "Shazia Wasim Sadiq", "Karsten Schulz"], "n_citation": 39, "references": ["03fe039d-3c04-450c-83aa-c8f0627e90d4", "608a11b3-4c42-41df-b4ad-d54f9c2d41f8", "82c85eda-cea2-4acc-810d-a911cee653c3", "90812366-633a-4269-a8ea-96fdea1aa193"], "title": "Model Driven Distribution of Collaborative Business Processes", "venue": "", "year": 2006, "id": "d01484fc-bfb2-4580-828d-0914e2ffcbc1"}
{"abstract": "Bio-inspired solutions are often applied to solve optimization problems. In this paper the introduction of chaotic systems in Ant Colony Optimization (ACO) algorithms is investigated. The ACO strategy is inspired by the cooperative behavior of food retrieval shown by ants that collectively discover the shortest path between the ant colony and food sources. The optimization problem examined in this work is the well-known Travelling Salesman Problem (TSP), a standard test bench for new combinatory optimization algorithms. The simulation results show that the application of deterministic chaotic signals instead of random sequences is a possible strategy to improve the performances of ACO algorithms.", "authors": ["Flavio Cannav\u00f2", "Luigi Fortuna", "Mattia Frasca", "Luca Patan\u00e9"], "n_citation": 8, "references": ["4af52a40-5d92-40c5-a7b7-546b8f2f7ff6", "675525e3-866a-4414-b4f6-4a77bfcc4054", "772f284f-d5ef-44f0-9e33-f8c8fe25312a", "c6082f75-3e21-463c-8368-988c9012e54c"], "title": "Chaotic sequences in ACO algorithms", "venue": "international symposium on circuits and systems", "year": 2004, "id": "6c9aa00f-664c-4a78-a570-8289f81bfb9c"}
{"authors": ["Martha E. Pollack"], "n_citation": 246, "references": ["015b8db1-b997-47bb-9b26-4bfd9c4a0e75", "09203a98-6163-4c86-9fa6-c329c26f157e", "1d33b519-5dbe-4470-97b2-3ebf959be3e8", "21d91386-84de-46b1-b328-a2743b75e9f0", "3de7b94c-6ad1-49e2-a178-3e993c0e7f71", "4f93c731-1c76-4a32-bbd8-c97001c57118", "5dbcdce1-0ada-4bf7-889a-d51e278e63e9", "5e742342-3a81-4af9-b866-4ee9a93d5e87", "63263f9e-67ea-4a37-ad18-015105198304", "64d88f13-7b46-4adb-934c-2bdb2b9456b8", "655507f7-3586-432a-8dba-ecf5a0955513", "6a1082c2-62a3-4517-bd86-5c19945241e2", "6ea010b2-36e0-40b9-8388-2a931a86b262", "72a004b4-a647-495d-8d62-a6a4b5c05451", "8026ab23-489b-407b-922c-ab0faf92670b", "94b71539-753e-4424-b2bc-98f44c15cea5", "af55f019-02fd-4afa-b12c-455d42d5e758", "b3961b32-f783-47e2-845d-8a48dc9a82e2", "b5f6585d-461b-4ab6-98f8-1662131ef57c", "b5fe90fe-1846-46a5-8c98-d56d62e5a2bf", "cc1ab2f3-c10a-4eaa-9254-7fb8ceda30dc", "e5710d1a-f2a7-4a3f-b3d7-6e38249be244", "e8a06a0c-dab6-488d-8939-ee6ed0d41d49", "ee4bbc14-80ef-4bb0-9ec8-ce8f7be6d11c", "ee6e18d5-483c-43a3-b191-96402462b623", "f0a5e86a-36b0-4c47-b085-0d35f15e9e8e", "f17bdf85-6dc4-48ec-8946-c2613678abfb"], "title": "The uses of plans", "venue": "Artificial Intelligence", "year": 1992, "id": "95ccbfa6-3069-49e8-9761-dce4f9d76a75"}
{"authors": ["Mehmet Adalier", "Costas Tsatsoulis"], "n_citation": 14, "references": ["2f564159-3d7b-4a6b-a370-9a38e04b3719", "3b2a23c9-ffa0-4226-8f7d-f6bda711127f", "726930dc-2193-43d3-82e1-0a79f7139b34", "ffc76f23-9a84-487c-9aad-3f33eec38908"], "title": "Redesigning for manufacturability using REINRED", "venue": "Applied Artificial Intelligence", "year": 1992, "id": "d8d4024e-2314-4231-81b9-69c488c399d4"}
{"abstract": "We present a formalisation for employee competencies which is based on a psychological framework separating the overt behavioural level from the underlying competence level. On the competence level, employees draw on action potentials (knowledge, skills and abilities) which in a given situation produce performance outcomes on the behavioural level. Our conception is based on the competence performance approach by (Korossy 1997) and (Korossy 1999) which uses mathematical structures to establish prerequisite relations on the competence and the performance level. From this framework, a methodology for assessing competencies in dynamic work domains is developed which utilises documents employees have created to assess the competencies they have been acquiring. By means of a case study, we show how the methodology and the resulting structures can be validated in an organisational setting. From the resulting structures, employee competency profiles can be derived and development planning can be supported. The structures also provide the means for making inferences within the competency assessment process which in turn facilitates continuous updating of competency profiles and maintenance of the structures.", "authors": ["Tobias Ley", "Dietrich Albert"], "n_citation": 96, "references": ["003a91ed-2c0d-47b8-9f07-302ca743a771", "0420238e-eb12-4736-b107-0ac935c93115", "0596771c-e103-4097-9645-06ae6e2586c7", "2fa89208-874a-4fb9-9386-b6a366913fab", "8561002a-b4d4-4638-966f-90f65cb9ce17", "b59bbd30-be3f-4667-ae6e-798bde4a69da"], "title": "Identifying Employee Competencies in Dynamic Work Domains: Methodological Considerations and a Case Study", "venue": "Journal of Universal Computer Science", "year": 2003, "id": "832fa72f-3eec-40f2-b410-e2bee3528784"}
{"authors": ["Annika \u00d6hgren", "Kurt Sandkuhl"], "n_citation": 16, "references": ["48717831-ae01-4c61-81c2-881dc2778cd0", "7101be81-c857-4eb5-addb-7ea92d7151c8"], "title": "Towards a Methodology for Ontology Development in Small and Medium-Sized Enterprises", "venue": "", "year": 2005, "id": "cbd2baf5-bbe6-40f5-b6eb-fb667fc489e5"}
{"abstract": "We focus on well-behaved Adaptive Hypermedia Systems, which means the adaptation engine that executes adaptation rules always terminates and produces predictable (confluent) adaptation results. Unfortunately termination and confluence are undecidable in general. In this paper we discuss sufficient conditions to help authors to write adaptation rules that satisfy termination and confluence.", "authors": ["H Hongjing Wu", "Pme Paul De Bra"], "n_citation": 34, "references": ["056c3a13-8292-4b86-ac3e-6f16468108e3", "39de0c61-aa19-4c36-adad-86eb148f7714", "f443502d-7989-4b53-a631-a3d4a735acd4"], "title": "Sufficient Conditions for Well-Behaved Adaptive Hypermedia Systems", "venue": "web intelligence", "year": 2001, "id": "7f0a12f7-fa5f-4725-bd4b-41d883e6feec"}
{"abstract": "This paper introduces approximate analytical models to evaluate the performance of end-to-end measurement based connection admission control (EMBAC) mechanisms, devised for the setup of real time flows over the Internet. These mechanisms rely on users probing the current congestion status of their required network path using a succession of probing packets. If the probing rate measured at the end receivers is greater than a certain threshold, users are allowed to switch to a phase of data exchange; otherwise they abort the call setup attempts. In conformance with the differentiated services framework, routers are oblivious to individual flows, and only need to give higher priority to data packets than to probing traffic. Despite the approximations introduced to make the analysis tractable, our model appears to be extremely accurate for a scenario of constant rate connections. Much less accurate, but useful as a possible starting point for future work, is the extension of the model to a scenario of variable rate connections. Simulation results are also presented in the paper to gain additional quantitative insights on the effectiveness of EMBAC to provide support for tight QoS requirements.", "authors": ["Giuseppe Bianchi", "Antonio Capone", "Chiara Petrioli"], "n_citation": 175, "references": ["0da8f8c3-b2e7-4c8f-99f5-5c0d8b4c0afa", "66e2ede8-8065-4260-b3da-7a90a6360ff2", "dc4c2de3-fa2b-4c95-a965-b937e5f96837", "eb26b49d-5b24-43df-8725-b4fcae1265bd"], "title": "Throughput analysis of end-to-end measurement-based admission control in IP", "venue": "international conference on computer communications", "year": 2000, "id": "cc218b9d-8109-4e9e-88a0-eba4779255af"}
{"abstract": "In developing High-Performance Computing (HPC) software, time to solution is an important metric. This metric is comprised of two main components: the human effort required developing the software, plus the amount of machine time required to execute it. To date, little empirical work has been done to study the first component: the human effort required and the effects of approaches and practices that may be used to reduce it. In this paper, we describe a series of studies that address this problem. We instrumented the development process used in multiple HPC classroom environments. We analyzed data within and across such studies, varying factors such as the parallel programming model used and the application being developed, to understand their impact on the development process.", "authors": ["Lorin Hochstein", "Jeffrey C. Carver", "Forrest Shull", "Sima Asgari", "Victor R. Basili", "Jeffrey K. Hollingsworth", "Marvin V. Zelkowitz"], "n_citation": 108, "references": ["0932e2cc-4692-4010-8978-a9db08c83096", "89ce7f98-4710-4a90-91cb-a807b61953ae", "a8a11863-efa3-4cb5-903b-9536e57d84dd", "b0e21e11-40bb-4604-91c6-3c058a1d0352", "e4b0f98c-06cb-44b4-81d8-500cc54e7f97", "f202ac9c-e9a3-4de6-810d-d321112a8de7", "fdbc29f6-8ac6-4387-b2a9-7ca4c9f6f7f7"], "title": "Parallel Programmer Productivity: A Case Study of Novice Parallel Programmers", "venue": "supercomputing conference", "year": 2005, "id": "a3242979-68ce-442f-b6df-dd335a6e8d07"}
{"abstract": "Fractional Fourier transform(FrFT) has been proposed to improve the time-frequency resolution in signal analysis and processing. However, selecting the FrFT transform order for the proper analysis of multicomponent signals like speech is still debated. In this work, we investigated several order adaptation methods. Firstly, FFT- and FrFT- based spectrograms of an artificially-generated vowel are compared to demonstrate the methods. Secondly, an acoustic feature set combining MFCC and FrFT is proposed, and the transform orders for the FrFT are adaptively set according to various methods based on pitch and formants. A tonal vowel discrimination test is designed to compare the performance of these methods using the feature set. The results show that the FrFT-MFCC yields a better discriminability of tones and also of vowels, especially by using multitransform-order methods. Thirdly, speech recognition experiments were conducted on the clean intervocalic English consonants provided by the Consonant Challenge. Experimental results show that the proposed features with different order adaptation methods can obtain slightly higher recognition rates compared to the reference MFCC-based recognizer.", "authors": ["Hui Yin", "Climent Nadeu", "Volker Hohmann"], "n_citation": 50, "references": ["0c0c5c61-f518-45ab-9a3f-ebd4c7c74d5b", "18352507-d97b-4f8b-b4ee-68cfea475cdc", "2020ca41-4ab8-4870-89e6-e0f5a5cb8ad4", "2a21c223-5a75-48e0-8690-ec57f8b21b84", "304e5a2e-25f2-4179-a57a-fb75628e446a", "531cc25c-0439-4d90-9695-288676d2a7c7", "54948e88-a95a-4b4d-b63a-e62876fce13f", "568fa381-1e5d-4257-aac2-ae64d946f05e", "5ca7a24b-aedf-436a-a060-e963b75ab714", "605a4a59-33e8-4e0c-a451-e62c1382b0d5", "68e1b853-070f-45b4-8ad3-2f4cdd7ea20f", "78a057b1-9d3d-49bd-b1d1-97e07a8207b1", "7b26d3eb-5659-4229-b172-ba2681f91b0c", "83d689ba-1414-44e8-90ca-57b3431002cf", "8a770a36-e877-4f1b-bb05-a93181a889a0", "ccf0c837-cc95-4d6b-b83f-1298a79ad233", "d8a81996-f59e-4b7f-86ef-3146bf8a5f61", "e32f2e0a-cfa9-4380-aa14-eddb1e3c25bd", "e4ec5c8a-90c5-49ec-9da4-b9eee350eb4b", "e8279c00-6a23-4059-aa4a-1b7ea7063851", "eba20dbd-e9ab-45a6-b12f-0b2dfde270a5", "f08c6c68-2e07-4b77-a0ee-4af846400670", "f427889c-a52b-41a5-b627-c2cf9a3dbf00", "ff917d99-b536-4ddd-a3c5-bd2691cb78e8"], "title": "Pitch-and formant-based order adaptation of the fractional Fourier transform and its application to speech recognition", "venue": "Eurasip Journal on Audio, Speech, and Music Processing", "year": 2009, "id": "680262cc-2a3e-43d7-9d22-5d8cc5d16876"}
{"abstract": "It is clear that nowadays analysis of complex systems is an important handicap in Statistics, Artificial Intelligence, Information Systems, Data visualization, and other fields. Describing the structure or obtaining knowledge of complex systems is known as a difficult task. The combination of Data Analysis techniques (including clustering), Inductive Learning (knowledge-based systems), Management of Data Bases and Multidimensional Graphical Representation must produce benefits on this field. Clustering based on rules (CBR) is a methodology developed with the aim of finding the structure of complex domains, which performs better than traditional clustering algorithms or knowledge based systems approaches. In our proposal, a combination of clustering and inductive learning is focussed to the problem of finding and interpreting special patterns (or concepts) from large data bases, in order to extract useful knowledge to represent real-world domains. This methodology and its behaviour as a Knowledge Discovery has been, in fact, presented in previous papers ([3], [5], [2]...). The aim of this paper is to emphasize the reporting phase. Some tools oriented to the interpretation of the clusters are presented; automatic rules generation is presented and applied to a real research. Actually, in a KD system, data preparation and interpretation of the results is as important as the analysis itself. In this paper, missing data treatment is analysed; a statistical test, based on non parametric techniques, for comparing several classifications is presented. Also, a method for finding characteristic values of the classes is presented; this is based on the prototype of each class. Finally, these characterizations allow automatic generation of decision rules, as a predictive tool for future items.", "authors": ["Karina Gibert", "Tom\u00e1s Aluja", "Ulises Cort\u00e9s"], "n_citation": 37, "references": ["56637cdb-1d8d-47a4-bc5b-39db5ddeb30e"], "title": "Knowledge Discovery with Clustering Based on Rules. Interpreting Results", "venue": "european conference on principles of data mining and knowledge discovery", "year": 1998, "id": "72d59096-9cd7-4e00-bf45-d01f122704c6"}
{"abstract": "Executable assertions can be inserted into a program to find software faults. Unfortunately, the process of designing and embedding these assertions can be expensive and time consuming. We have developed the C-Patrol tool to reduce the overhead of using assertions in C programs. C-Patrol allows a developer to reference a set of previously defined assertions, written in virtual C, bind assertion parameters, and direct the placement of the assertions by a pre-processor.", "authors": ["Hwei Yin", "James M. Bieman"], "n_citation": 29, "references": ["0d995f1f-d3ea-4c1b-b0cc-3fa301ec010e", "bb37bed9-b620-40a3-bc3d-efa700bad817", "dfd68581-16af-4711-8e5b-d48a2b264f23", "e54d53e5-a21c-422e-b176-5ceb56dffda7", "e5507b36-d7b1-4cb2-8ad9-26cfe9e970a7", "fd21eab7-34f0-4129-88a0-2c00e7ecff13"], "title": "Improving software testability with assertion insertion", "venue": "international test conference", "year": 1994, "id": "b619ffe6-67ac-418a-8f15-2a9279133990"}
{"abstract": "Traditional database systems, particularly those focused on capturing and managing data from the real world, are poorly equipped to deal with the noise, loss, and uncertainty in data. We discuss a suite of techniques based on probabilistic models that are designed to allow database to tolerate noise and loss. These techniques are based on exploiting correlations to predict missing values and identify outliers. Interestingly, correlations also provide a way to give approximate answers to users at a significantly lower cost and enable a range of new types of queries over the correlation structure itself. We illustrate a host of applications for our new techniques and queries, ranging from sensor networks to network monitoring to data stream management. We also present a unified architecture for integrating such models into database systems, focusing in particular on acquisitional systems where the cost of capturing data (e.g., from sensors) is itself a significant part of the query processing cost.", "authors": ["Amol Deshpande", "Carlos Guestrin", "Samuel Madden"], "n_citation": 129, "references": ["009c5232-30ae-4e0d-affb-1d593b887c8e", "08068bb9-6eb9-4aad-816e-cb2ba92e73b7", "0b9095a4-4235-46be-8a21-c432f2832332", "1ef163d2-53db-4edd-9123-480080b1bf8e", "228e949d-c914-4b1b-9052-e0a149c40855", "31f4d9a0-ca47-4f39-acd5-1aafb3c08449", "32d33119-a220-47b7-88b5-2ae422a7d094", "32ed7703-e95e-457f-84d2-c8f6e15edf2c", "36f34de1-e7be-4d13-934c-59b0c2df3495", "3a21708e-b927-43f7-886c-a7b45e5b66cc", "4c3c4de5-2df8-4eaf-b9d0-09abd51de8dd", "4d8c4a8c-f7f0-4063-a576-e28326f6ced3", "4ddf4ff1-3ec7-4ad7-8a5b-550b0dc9ee88", "57280c5a-3d0b-40cf-b087-69d3fd8490c5", "64c99ab6-e4ad-476f-a92d-13686a6e1aec", "6684f7ed-f42c-4cdb-9c18-52d5642b23fd", "66981fb3-b014-4ccb-acdc-e851b2bf8615", "6bfdf9a3-6cd9-43d8-9785-0073dbe96f1b", "760a1aeb-de5f-432c-9e17-93d0b6f55fc2", "82c8abec-eaa3-4d02-a33c-c2f77619fceb", "82cde6d2-81c7-4a11-9bc5-4d691f49eb91", "85882b06-3f2d-477d-8d27-3a64ec87dd8b", "8a7ab546-8af8-425d-b9c7-ecde99811248", "92fd0328-b76d-422f-8a1c-6faf8d3298ed", "97d90be0-e704-4462-b6d9-ad93ad63c94f", "9a04d44e-e849-4107-8d0d-b4dc38780793", "bb54e87e-23b6-421e-a125-68539dbae50c", "bd363c40-6a73-40ba-a748-76d0f621697f", "bd8c46c6-3635-407f-9bd1-b90bbba3d26d", "c075f11b-4ea0-4642-9910-17b3524667a8", "c9165b64-87a5-4b9e-82b3-45da9ec29e35", "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706", "dc2e27cb-6a12-496c-b7fb-1f21317edc14", "e7a46aee-eb30-489e-a89d-69bfc8b8964d", "ed4ea231-d9c5-44fc-9a21-40feb7c136da", "f457e3db-8e12-4dc6-ac44-919c267bdf8b", "f4879943-32f8-465d-b7aa-60d44ffc4f4a", "feac5554-d6fe-4346-aa49-51914552591a"], "title": "Using Probabilistic Models for Data Management in Acquisitional Environments", "venue": "conference on innovative data systems research", "year": 2005, "id": "2cfafe9a-fb13-4acc-b3bd-d1a483d14b03"}
{"authors": ["Sunju Park", "Edmund H. Durfee", "William P. Birmingham"], "n_citation": 81, "references": ["47e8966f-761d-44ff-bd0e-f312f9986b61", "610a0312-e7b1-48c9-8dfe-57bc333e6086", "78df4efc-f9a6-490b-a5be-2de40c7c2df7", "bb9cb8c2-ce39-4b21-bd99-eceef47ac05c"], "title": "An adaptive agent bidding strategy based on stochastic modeling", "venue": "Autonomous Agents and Multi-Agent Systems", "year": 1999, "id": "5805e5b1-9921-4c17-a24b-8fc125816b7f"}
{"abstract": "We argue that heterogeneity is hindering technological innovation in the home---homes differ in terms of their devices and how those devices are connected and used. To abstract these differences, we propose to develop a home-wide operating system. A HomeOS can simplify application development and let users easily add functionality by installing new devices or applications. The development of such an OS is an inherently inter-disciplinary exercise. Not only must the abstractions meet the usual goals of being efficient and easy to program, but the underlying primitives must also match how users want to manage and secure their home. We describe the preliminary design of HomeOS and our experience with developing applications for it.", "authors": ["Colin Dixon", "Ratul Mahajan", "Sharad Agarwal", "A.J. Brush", "Bongshin Lee", "Stefan Saroiu", "Victor Bahl"], "n_citation": 70, "references": ["0aaccc75-b474-48df-842e-34728783cfc1", "0f5ee8bf-5c62-4485-8ed5-1c4fd510a178", "149b3a95-ff42-4488-9694-92fa916a2b08", "1e35b930-0d42-4659-b8fd-329af7c9691f", "1f5a68da-5bd6-4537-a9a6-5771ac5a7d1e", "204465b0-0686-4eb5-b624-2d1014f58e57", "29f08f1d-565b-47dc-90d7-b1bef4e72a4f", "485a8db9-3ed9-4203-a3bc-37306b4e7a63", "72db976e-5886-4750-a650-0ef209e3a51c", "b5e5518c-4246-4806-aeee-40ad32aa22f8", "d28d338a-cb03-46fe-96cb-6319db2ca275", "e53c8efb-d371-4e26-910a-a57bdac34982", "e80ba669-f97d-4e82-bc1f-cb41459b4ec5", "fecb93aa-c589-4fd3-a7a9-c1ef3ba0b37a"], "title": "The home needs an operating system (and an app store)", "venue": "acm special interest group on data communication", "year": 2010, "id": "e0ecbf1a-b4df-43fa-8e84-432c9263bf16"}
{"abstract": "The spatial-domain intra prediction scheme of H.264 has high computational complexity, especially for the High Profile as it incorporates the additional intra 8 \u00d7 8 prediction mode. To address this issue, we explore the hierarchy of H.264 mode decision process in this paper and adopt an approach that is in synchrony with the mode decision hierarchy. In particular, we propose a variance-based algorithm for block size decision, an improved filter-based algorithm for prediction mode decision using contextual information, and a selection algorithm for intra block decision that exploits the relation between the rate-distortion characteristic and the best coding type. Performance comparison is provided to show the improvement of the proposed algorithms over previous methods.", "authors": ["Yi-Hsin Huang", "Tao-Sheng Ou", "Homer H. Chen"], "n_citation": 99, "references": ["109f84a4-6c9e-4d63-924d-84b2239b3f61", "11df2ff4-9a77-4709-b6ec-267034e9dcff", "237a87ca-d393-4173-a89d-fd2c5c1f3d37", "2e71fa79-72e8-41ac-9b84-ea04720d7255", "33b41c47-9407-4491-aaa2-80f2ece7286c", "3c0a3558-a843-46e9-97c2-0cb467e70e61", "4468a973-3c36-4f7c-9aa6-dcf7318fdce4", "57cc6bcf-9cb4-4193-9c12-589c9b943e31", "6a0e8e00-2ad1-4fcb-95a7-1870021fa5e5", "bf61d08b-5b39-4635-adef-7c6d73d24d8e", "c70aa29e-3d40-4dec-88cf-27d91f3377db", "e15b9021-1f18-47f0-93a7-c5b317ecc156", "e21580e6-94b3-4029-86a8-68d38147ee6a", "ecf4182d-3eb4-46e5-b84b-2a48f052f064", "f0ca6928-1b96-4733-b9c3-62260da5d8cc", "fd3a8768-c30a-4da6-8028-d43a64423435"], "title": "Fast Decision of Block Size, Prediction Mode, and Intra Block for H.264 Intra Prediction", "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "year": 2010, "id": "c87dd089-5819-4775-96d6-bbaf920a6108"}
{"abstract": "Efficient routing among a set of mobile hosts (also called nodes) is one of the most important functions in ad hoc wireless networks. Routing based on a connected dominating set is a promising approach, where the searching space for a route is reduced to nodes in the set. A set is dominating if all the nodes in the system are either in the set or neighbors of nodes in the set. In this paper, we propose a simple and efficient distributed algorithm for calculating connected dominating set in ad hoc wireless networks, where connections of nodes are determined by their geographical distances. We also propose an update/recalculation algorithm for the connected dominating set when the topology of the ad hoc wireless network changes dynamically. Our simulation results show that the proposed approach outperforms a classical algorithm in terms of finding a small connected dominating set and doing so quickly. Our approach can be potentially used in designing efficient routing algorithms based on a connected dominating set.", "authors": ["Jie Wu", "Hailan Li"], "n_citation": 340, "references": ["09b8b840-7c8c-4aaf-9756-200354d1a125", "0acf822c-0856-492a-9d12-ccd40383c6b4", "0ce8149a-808a-426c-9af9-a03bec2d12c1", "13556eea-051f-487b-8c52-476314eedaa5", "1b0d9aea-0256-494f-a570-f04715825bb1", "60fb0dc2-bde3-4714-948e-de0ed12ab460", "73c02ec9-cf57-451f-83f3-b00f9acee0ab", "81a186d5-baba-4d85-9c78-663beb94b1d5", "9a08d227-ac93-447d-ac39-98079453bc94", "db2fd4e0-c411-4f82-9b03-5674b3a5eebe"], "title": "A Dominating-Set-Based Routing Scheme in Ad Hoc Wireless Networks", "venue": "Telecommunication Systems", "year": 2001, "id": "acf627e1-384b-4a35-acac-67ea223c0d33"}
{"abstract": "A calculus and a model for a first-order functional language with sharing is presented. In most implementations of functional languages, argument subexpressions in a function application are shared to avoid their repeated evaluation. Recursive functions are typically implemented using graphs with cycles. Compilers for these languages sometimes employ non-left-linear and left-cyclic rules for optimizations. A graph rewriting system (GRS) to address these concerns is developed. It is shown that a GRS without interfering rules is confluent. Along the lines of Levy's term model for the \u03bb-calculus, a semantics of such a GRS is also presented. An application of the term model to compiler optimizations is discussed.", "authors": ["Zena M. Ariola", "Arvind"], "n_citation": 58, "references": ["1a30436a-3c88-4c77-a140-a9ad91198406", "21439df2-11b1-4cb7-83ef-de3f8e1e018d", "89ef13db-4c93-48c3-87a8-30600e955b49", "96baf7dd-a805-4947-bcc8-455adfb328aa", "99a70d04-efa5-41ca-b44b-ad5c12f412b2", "9a5ee552-50ba-4b96-ad53-622cd7c84471", "b2cfb19c-58dd-4e53-89c3-8c8180b449a2", "d9a92692-de3b-4953-a9bb-6ebba46e1af5", "dfebf2ee-d3e9-45db-884f-8a5456623607", "f8f08b6c-aa38-4148-9e8f-8f11faa86bc2"], "title": "Properties of a first-order functional language with sharing", "venue": "Theoretical Computer Science", "year": 1995, "id": "472369b6-45da-4d57-85a6-74e76e17c9f2"}
{"abstract": "The Markov Reward Model Checker (MRMC) is a software toolfor verifying properties over probabilistic models. It supports PCTL and CSL model checking, and their rewardextensions. Distinguishing features of MRMC are its support for computing time- and reward-bounded reachability probabilities, (property-driven) bisimulation minimization, and precise on-the-fly steady-state detection. Recent tool features include time-bounded reachability analysis for uniform CTMDPs and CSL model checking by discrete-event simulation. This paper presents the tool's current status and its implementation details.", "authors": ["Joost-Pieter Katoen", "Ivan S. Zapreev", "Ernst Moritz Hahn", "Holger Hermanns", "David N. Jansen"], "n_citation": 320, "references": ["021232b9-059a-4dda-b855-2446cee01f64", "064b45a9-9b28-4fe3-8466-9db7c3f663ac", "10841be2-c2d1-444d-a18a-d046b8aa79a4", "13ed25be-cffe-44ee-bea2-5967595c8a2e", "1b4b76ff-2600-4ef0-95d0-4862c8d75054", "1f65e173-b91a-41cf-a5c8-caef5c5e88b2", "2bff2a48-6ca9-49f2-ad45-79d89945c34d", "4d4468ac-9e19-4a69-93d6-ad3cbb9ee3dc", "54768647-c269-4b71-8afb-f6212ccbcf88", "5d641881-20b8-492f-b025-6fcf74eb7f41", "604cb2a6-0672-42cd-8299-85a91afbc2c1", "6abc8e2a-b105-4cf6-a100-34969f2fe5f1", "6f47a29d-5292-45e6-bf45-eed276212190", "6f8c303e-e0a5-4232-aee6-9f9e5db6e98f", "73062e15-33c4-4258-8815-47a35c352994", "757a0a74-f613-4f2f-ac7e-8ad7c5c15ca1", "78ba44d3-7160-488a-989a-4cb641530e7c", "7f96511e-cfc4-43b1-bf0d-7ea75be38fc5", "840a656b-e6f2-41ec-8018-6535ac4ad494", "9a7e8549-bc5a-4fac-bba9-c4951f655a31", "9ac2e856-8d6f-4303-a4a2-411eb8122c0e", "9d9aec4c-cb82-4c5e-b5a1-f7eaaea30ddc", "b3d0222a-4782-4481-bd40-ea1bdaca4c3d", "bd663385-9b3a-41f3-b59f-eca56c678363", "c016c6ed-751c-47ae-b42d-52764f659d61", "ca7b4f42-396d-4b2b-8ae9-b4891074481f", "d686cf1b-8dc3-42b3-a26a-e4ca234d26f1", "d94e1b69-bd4c-44d2-80b5-ba9c34034b8d", "dd5f3b62-26fb-45dd-865a-779780a022e8", "e33506ac-40dc-4b54-93a6-d128e986ef01", "e7d4f300-a318-4d6e-bbd8-0a255c7d19fd", "ebf50166-9694-4671-956b-77166791001e", "ec0f47ec-b727-4301-ad01-1293292e4165", "f489b2c8-3dee-4d8d-ad7e-e7b0a5c81c46", "fd5dcd49-75de-4d07-bad2-34d3e760cf83"], "title": "The Ins and Outs of the Probabilistic Model Checker MRMC", "venue": "quantitative evaluation of systems", "year": 2009, "id": "5d93cf8b-dc24-4880-ac23-f06fa52ee4b3"}
{"authors": ["Antonio Camurri", "Riccardo Trocca", "Gualtiero Volpe"], "n_citation": 17, "references": ["349e5b8f-fd0b-4479-906d-7f2888a66377", "4b2dfb0d-8303-4a0c-8bde-0b77fc227793", "89be3151-2c2a-4707-8cce-043a3d9c3a31", "9f05ff4d-d987-42fc-bd85-867a6d43c7b4", "e62dac23-aec5-4d2a-92c2-603cb2415bbd"], "title": "Real-time analysis of expressive cues in human movement", "venue": "", "year": 2002, "id": "7a25cebe-63dc-4b08-8c00-c842ee8b57ed"}
{"abstract": "A novel routing scheme for mobile ad hoc networks (MANETs), which combines the on-demand routing capability of Ad Hoc On-Demand Distance Vector (AODV) routing protocol with a distributed topology discovery mechanism using ant-like mobile agents is proposed in this paper. The proposed hybrid protocol reduces route discovery latency and the end-to-end delay by providing high connectivity without requiring much of the scarce network capacity. On the one side the proactive routing protocols in MANETs like Destination Sequenced Distance Vector (DSDV) require to know, the topology of the entire network. Hence they are not suitable for highly dynamic networks such as MANETs, since the topology update information needs to be propagated frequently throughout the network. These frequent broadcasts limit the available network capacity for actual data communication. On the other hand, on-demand, reactive routing schemes like AODV and Dynamic Source Routing (DSR), require the actual transmission of the data to be delayed until the route is discovered. Due to this long delay a pure reactive routing protocol may not be applicable for real-time data and multimedia communication. Through extensive simulations in this paper it is proved that the proposed Ant-AODV hybrid routing technique, is able to achieve reduced end-to-end delay compared to conventional ant-based and AODV routing protocols.", "authors": ["Shivanajay Marwaha", "Chen-Khong Tham", "Dipti Srinivasan"], "n_citation": 217, "references": ["0d4d0363-07b5-43b6-976d-955e96044709", "60fb0dc2-bde3-4714-948e-de0ed12ab460", "684c8efa-7359-42c6-91e2-d39811d19cb8", "7c9f8cd8-d0ef-4954-b4db-4a6c803459c2"], "title": "Mobile agents based routing protocol for mobile ad hoc networks", "venue": "global communications conference", "year": 2002, "id": "b87bcd35-60a2-4bca-9041-8ce99478207e"}
{"abstract": "In this paper, we introduce the so-called hierarchical interaction models, where we assume that the computation of the value of a function    $m: { \\mathbb {R}^{d}}\\rightarrow \\mathbb {R}$    is done in several layers, where in each layer a function of at most    $d^{*}$    inputs computed by the previous layer is evaluated. We investigate two different regression estimates based on polynomial splines and on neural networks, and show that if the regression function satisfies a hierarchical interaction model and all occurring functions in the model are smooth, the rate of convergence of these estimates depends on    $d^{*}$    (and not on    $d$   ). Hence, in this case, the estimates can achieve good rate of convergence even for large    $d$   , and are in this sense able to circumvent the so-called curse of dimensionality.", "authors": ["Michael Kohler", "Adam Krzyzak"], "n_citation": 50, "references": ["3ae6f4a3-4012-4e21-9ed9-fbbe9a13b869", "52da91c2-0174-4d35-8527-ec6d007095bd", "6419cbff-928c-4dd3-bb9f-90766fd3de1b", "78bf672c-20ca-4bf8-9192-193eea2abd1f", "7d3e44b7-62aa-488b-b150-81e46405a73a", "eb5bfcb8-7dd1-4fef-93de-7351e27dfade"], "title": "Nonparametric Regression Based on Hierarchical Interaction Models", "venue": "IEEE Transactions on Information Theory", "year": 2017, "id": "17c5729c-f4fc-4136-907f-d766ff78b1f5"}
{"authors": ["Gabriele Taentzer", "Michael Goedicke", "Torsten Meyer"], "n_citation": 83, "references": ["0468472d-d16a-4521-b0e0-008e92fef477", "0dfb9bb7-d163-45eb-afca-40f5dd46a343", "15626c11-5c9d-4caa-87f0-97885abdeb66", "1be78e15-6f94-4e44-a082-607b6c35928a", "3350ea24-e7d9-4a1d-9e62-2104ef788a11", "5b63ebdc-01c9-4b88-983a-4f6a4bbb3df2", "75e6a17b-cd17-4386-9dd3-8730ef7a8bd5", "84eafaf6-01ad-4134-a9c4-c0745b4adc7b", "85c1de96-97f5-478f-aa27-3c8581595c15", "91e30583-e9b4-437b-82c3-2dbf8ec44bc8", "b215f194-a0ce-4699-9d46-69ad938c6c4d", "ba0ffed5-3044-4547-a891-3891007c44de", "c67dac0a-7a8e-49f0-9573-c864219e4f67"], "title": "Dynamic Change Management by Distributed Graph Transformation: Towards Configurable Distributed Systems", "venue": "", "year": 1998, "id": "a0fc34f7-60ae-46b9-8997-0d8b33dfd170"}
{"abstract": "The true value of identity management comes into play with business partners and consumers. The ability to federate identity across organizations while maintaining clear trust, liability, and cost responsibilities is a major challenge for enterprises as we continue to pursue efficiency and cost savings in cross-organizational business and customer-relationship processes.", "authors": ["Duncan A. Buell", "Ravi S. Sandhu"], "n_citation": 50, "title": "Guest Editors' Introduction: Identity Management", "venue": "IEEE Internet Computing", "year": 2003, "id": "c6b15e83-acf0-4377-84d3-558f98328098"}
{"authors": ["Riccardo Bellazzi", "Cristiana Larizza", "Paolo Magni", "Roberto Bellazzi"], "n_citation": 11, "references": ["08f67ac1-daa8-4150-807f-d1e98b6727dc", "59513cc3-9b35-40e6-8aee-de5303ee9e0a", "59efb068-0be4-45bd-8fcb-be6c7a0b1fe5", "66a1e009-0da4-43b3-9d11-4b83b6af1d87", "75ade12e-621e-4925-8c26-be6b47288876", "97fd0e44-fb11-487a-94e0-8f4a8d77ae56", "b68ac4d9-9408-4646-9d64-189c3262a7f4"], "title": "Quality Assessment of Hemodialysis Services through Temporal Data Mining", "venue": "artificial intelligence in medicine in europe", "year": 2003, "id": "1f48a932-3f3d-43dc-a8de-8ab58a937f0d"}
{"abstract": "Relational languages such as RUBY are used to derive hardware circuits from abstract specifications of their behaviour. Much reasoning is done informally in RUBY using pictorial representations of relational terms. We formalise this use of pictures in circuit design. We show that pictures naturally form a unitary pretabular allegory. Homomorphisms of pictures correspond to adding new wires or circuit comments. Two pictures are mutually homomorphic if and only if they represent equal allegorical terms. We prove soundness and completeness results which guarantee that deriving circuits using pictures does not lead to errors. We illustrate the use of pictures by deriving the ripple adder implementation from a high level, behavioural specification. >", "authors": ["C. M. Brown", "Graham Hutton"], "n_citation": 48, "references": ["0f483546-daa7-4b38-9e9a-af0ca5bcad59", "38116e57-b211-4203-8ec8-3287e5a58a1f", "4b93b9b8-99d9-4fcf-a9bd-b4aefc41184e", "894224da-20d3-48bc-b951-3956d48427cd", "c22a5c79-5cd8-47eb-857d-d366b6337d73"], "title": "Categories, allegories and circuit design", "venue": "logic in computer science", "year": 1994, "id": "a1ba59a5-0fa7-4f3d-8b32-a923d5ec1699"}
{"authors": ["habil. Boris M. Velichkovsky", "Dipl.-Psych. Andreas Sprenger", "Dipl.-Inf. Marc Pomplun"], "n_citation": 50, "references": ["19b2fc36-5656-40ca-9160-7afa4d9ab09b", "278f1d79-321b-4fb2-a53b-821581afdf82", "63f3d784-8c6c-498b-bea1-d26d0ce2044b", "f38db47a-5b50-48d7-8382-9a9372cd3114"], "title": "Auf dem Weg zur Blickmaus: Die Beeinflussung der Fixationsdauer durch kognitive und kommunikative Aufgaben", "venue": "", "year": 1997, "id": "d36fbc26-e053-4362-bfc0-36b54f267889"}
{"abstract": "Research and practice in software engineering have led to an extensive set of metrics for the evaluation of almost every aspect of software development. One of the major challenges for any quality model is the combination of metrics, which are complementary to each other. In this paper, we propose the use of Data Envelopment Analysis DEA, a non-parametric technique employed in economics, as a means of providing a unified view of selected design metrics. The proposed application of DEA aims at assessing the overall trend of quality during the evolution of software systems, by considering releases of a project as units to be ranked. An important benefit derived from the use of DEA is the ability to \"normalize\" the evaluation over the size characteristics of the examined systems, which is vital when comparing projects of different scale. Results are presented for successive versions of two open-source, one industrial and one research project, whereas validation, whereas validation is performed by comparing the findings with the results obtained by Analytic Hierarchy Process, which is an acknowledged multi-criteria decision analysis approach. According to the results, DEA enables the perception of global trends in qualitative characteristics, which would be otherwise difficult to recognize and interpret. Copyright \u00a9 2012 John Wiley & Sons, Ltd.", "authors": ["Alexander Chatzigeorgiou", "Emmanouil Stiakakis"], "n_citation": 8, "references": ["02e0342a-33d3-4d3f-9f1d-b14081edbc39", "04b3c499-bbdb-4b20-88ae-7c342fc9ff7d", "0b68caa2-5e46-4d4d-88e1-5473f023c374", "0d6e0acc-83d6-4702-9e8a-15d4f87cf6bd", "0d950e8a-1575-46f5-b748-052ba9005835", "1c27f4e3-5244-4937-9873-aaefe65509f2", "20577acc-8684-4058-a70a-dc46483dc468", "209f830c-5031-4ed2-b098-61c94368f94d", "24cbcdb6-3d6f-41fa-855a-0166b7060852", "25e0887a-d1c7-4018-be77-cfad22b30990", "283a47a0-f895-4185-b433-fe7a35408aca", "2bcd2cf2-0ec9-473f-83d5-1fae0cfa9ab3", "421ff268-70e1-4766-b9ac-0c37076f69d3", "4381cc56-cfe7-471f-a02c-fe279a00fa6f", "496ee7a3-7809-43ba-ac73-39ad2dc9d65d", "49a0cd67-ab53-4fe3-88f1-744dceda55df", "50713edd-4650-409a-a20b-fa97f9692120", "56941878-4354-4039-8b03-b8aa8cbfa6f6", "6e6202cd-6dbe-4bba-b198-326f2168c517", "7335e3e8-eac1-4e7b-aabf-c972e4f41474", "7f58ce74-1dfb-4263-a902-f4fae1d1f05c", "86d70f4c-f56d-42a2-88ff-dcb4e1e10d08", "870db3d2-2156-455d-8d12-9902da9863b6", "8cc71956-c27d-419b-b0ff-ef826e1435be", "9e79cd42-28e6-43da-b4cf-ad37752f9122", "a7549588-608e-41a5-a783-1e308d0f45a2", "b3b4c85e-6d38-41fe-9b39-823e9ae7becd", "d32786fc-ea8d-41f0-a803-5d00e550329c", "d386509a-b5a1-43c0-9c52-e4afd95f4003", "db99d024-2b7c-44c9-9644-1a7f316bfb53", "e1e577a1-e4f4-4930-9d3a-7e14489a8499", "e580b2d9-3e7c-4122-9932-f2cf985040cd", "e9f5259d-5f6b-4229-8fd3-7a464275a504", "ed44afd4-57c7-4b04-9bda-509847d1e7c1", "ef8424b4-dbf5-4184-bdcb-c569f4ba28b9", "f6a9a06d-35b8-4152-b6fe-9031b8e775d5"], "title": "Combining metrics for software evolution assessment by means of Data Envelopment Analysis", "venue": "Journal of Software: Evolution and Process", "year": 2013, "id": "01f72c41-c80b-4630-85c6-6eda9a1344b2"}
{"abstract": "The adaptation step is central in case-based reasoning (CBR), because it conditions the obtaining of a solution to a problem. This step is difficult from the knowledge acquisition and engineering points of view. We propose a knowledge level analysis of the adaptation step in CBR using the reasoning task concept. Our proposal is based on the study of several CBR systems for complex applications which imply the adaptation task. Three of them are presented to illustrate our analysis. We sketch from this study a generic model of the adaptation process using the task concept. This model is in conformity with other CBR formal models.", "authors": ["B\u00e9atrice Fuchs", "Alain Mille"], "n_citation": 30, "references": ["0f266df2-4ac1-4d93-8163-777fab0888fb", "2040c012-9a2d-47c6-90c0-39eb92360d7e", "4c035588-10c1-4596-8293-d5af92c0dd82", "66c5269e-d948-4de6-9715-1e467460592c", "6de13837-17ef-45a1-8b29-bcca89323af0", "8ac2f358-884b-44e0-bba3-3d22aa923cef", "a1eed499-7e6f-47e0-9e58-e4418d3f24c7", "b1fe3d55-0855-494d-8b2d-5499f7d15753", "b7cb46a3-c640-4ff9-bc78-455902b473b8"], "title": "A Knowledge-Level Task Model of Adaption in Case-Based Reasoning", "venue": "international conference on case based reasoning", "year": 1999, "id": "40671aee-d83f-419f-84d0-fd0e588d654e"}
{"abstract": "From a project economics point of view, the most important practices of Extreme Programming (XP) are Pair Programming and Test-Driven Development. Pair Programming leads to a large increase in the personnel cost, and Test-Driven Development adds to the development effort. On the other hand, pp can speed the project up, both pp and Tdd can reduce the defect density of the code. Can the increased cost of XP be balanced by its shorter time to market and higher code quality? To answer this question, we construct a new model for the business value of software projects. We then analyze the cost and benefit of XP by applying our model to a realistic sample project. We systematically vary important model parameters to provide a sensitivity analysis. Our analysis shows that the economic value of, XP strongly depends on how large the XP speed and defect advantage really are. We also find that the market pressure is an important factor when assessing the business value of XP., Our study provides clear guidelines for managers when to consider using XP -- or better not.", "authors": ["Matthias M. M\u00fcller", "Frank Padberg"], "n_citation": 50, "references": ["1cf96037-ecdb-4ad9-8977-4263600bea7a", "54d1c433-8229-4d9f-ad99-89b4ce3000fd", "772d744a-0df0-4c20-bace-3612c5d5c0eb", "897b9a05-730f-4bb5-b22c-973233f17f26", "a65c12e6-e0a8-428f-8d15-e694f5afd37d", "af26a993-df53-43f0-9134-593fcc127856", "bdc94277-8125-4aff-bbcd-b5e6e1fda167", "d6bab0b3-37d8-4647-9243-bf2ad8543dca", "dcce751e-4b4b-4047-950a-f1e0d8500287"], "title": "On the economic evaluation of XP projects", "venue": "foundations of software engineering", "year": 2003, "id": "0a682e8c-d8b4-4f7b-9e16-9867c97e57f8"}
{"abstract": "We implemented a continuation-passing style (CPS) code generator for ML. Our CPS language is represented as an ML datatype in which all functions are named and most kinds of ill-formed expressions are impossible. We separate the code generation into phases that rewrite this representation into ever-simpler forms. Closures are represented explicitly as records, so that closure strategies can be communicated from one phase to another. No stack is used. Our benchmark data shows that the new method is an improvement over our previous, abstract-machine based code generator.", "authors": ["Andrew W. Appel", "Trevor Jim"], "n_citation": 226, "references": ["769c0b79-1844-4418-93a7-0716844c6860", "801d79fc-df14-436f-9350-568e22ff92c3", "993bba4a-257f-4c81-bd92-d5044d5ed205", "ae94e5b4-c663-49f6-8dc7-5f1e70ed8f1c", "d17c4f06-3399-4c3b-a709-fdbe9205fc58"], "title": "Continuation-passing, closure-passing style", "venue": "symposium on principles of programming languages", "year": 1989, "id": "1e8a91e1-fbd0-4362-9131-0f730e24af9d"}
{"authors": ["Cecilia M. Ionita", "Sylvia L. Osborn"], "n_citation": 14, "references": ["00ed9c98-4a24-476a-80bb-62bf5d300385", "332a4fe3-05dd-41bc-b228-d0f0e0f32580", "9e08ab3b-3582-42b4-91bd-fdd7c33384a0", "d4d03e29-1c19-4d29-981c-c0ab87d3c55f", "f92c47d0-5e22-4d95-b51f-2fcffc226004"], "title": "Privilege Administration for the Role Graph Model", "venue": "", "year": 2002, "id": "b0e668f9-ea10-47a8-b425-963b6c8e40c9"}
{"abstract": "Abstract#R##N##R##N#Test data generation is one of the most technically challenging steps of testing software, but most commercial systems currently incorporate very little automation for this step. This paper presents results from a project that is trying to find ways to incorporate test data generation into practical test processes. The results include a new procedure for automatically generating test data that incorporates ideas from symbolic evaluation, constraint-based testing, and dynamic test data generation. It takes an initial set of values for each input, and dynamically \u2018pushes\u2019 the values through the control-flow graph of the program, modifying the sets of values as branches in the program are taken. The result is usually a set of values for each input parameter that has the property that any choice from the sets will cause the path to be traversed. This procedure uses new analysis techniques, offers improvements over previous research results in constraint-based testing, and combines several steps into one coherent process. The dynamic nature of this procedure yields several benefits. Moving through the control flow graph dynamically allows path constraints to be resolved immediately, which is more efficient both in space and time, and more often successful than constraint-based testing. This new procedure also incorporates an intelligent search technique based on bisection. The dynamic nature of this procedure also allows certain improvements to be made in the handling of arrays, loops, and expressions; language features that are traditionally difficult to handle in test data generation systems. The paper presents the test data generation procedure, examples to explain the working of the procedure, and results from a proof-of-concept implementation. Copyright \u00a9 1999 John Wiley & Sons, Ltd.", "authors": ["A. Jefferson Offutt", "Zhenyi Jin", "Jie Pan"], "n_citation": 221, "references": ["1428f757-51e1-4de7-bb58-91917c0390b5", "156e6fea-8358-47eb-a929-8a00bff82c30", "2b47a5ec-fd51-4b53-bd29-f6fc5e44da8a", "2c08d317-3848-40af-9dfa-20c8ce584ce9", "2c307115-b75d-4663-968c-765ac835c4b3", "2daddb7c-4357-4575-8408-4a880ca870d4", "3d47d8fd-6237-436a-b403-1b02a5c7aa5e", "538234eb-76cf-489d-807b-7e3b7bb42446", "538c691a-555d-498c-82a8-c024e9a2d71c", "57071747-069e-453f-b3e1-b16b417581ee", "814ffbbb-a575-4152-9c81-aaae427f7a47", "86d7fd90-13e6-4d28-a91e-53166dd2fd01", "95e41ebe-8f0b-424d-a678-e2c2e2cc86bf", "a7122806-c66c-49e6-8876-70093d70f605", "a999b6c8-79f0-49b6-b20a-df07e2413d49", "b97f40dc-edcc-47bd-906d-1c48d847b725", "baeca1db-4bac-438c-acf8-e42c7c82a5e9", "c5ec1c87-2aa7-4178-a048-53a43de44145", "fd4e53f4-99e9-4277-b820-a6f9ccfa62e0"], "title": "The dynamic domain reduction procedure for test data generation", "venue": "Software - Practice and Experience", "year": 1999, "id": "7da49e37-374f-4f4a-bb6d-e5c732a0fd01"}
{"abstract": "Analogical reasoning appears to play a key role in creative design. In briefly reviewing recent research on analogy-based creative design, this article first examines characterizations of creative design and then analyzes theories of analogical design in terms of four questions: why, what, how and when? After briefly describing recent AI theories of analogy-based creative design, the article focuses on three theories instantiated in operational computer programs: Syn, DSSUA (Design Support System Using Analogy) and Ideal. From this emerges a related set of research issues in analogy-based creative design. The main goal is to sketch the core issues, themes and directions in building such theories.", "authors": ["Ashok K. Goel"], "n_citation": 365, "references": ["20ee681d-a83e-4a84-a355-4c4401d23aeb", "747e5378-c45c-428f-b58e-f0ecc1040752", "a66b7562-5df3-4143-97b5-a9f746ce90c2", "af93e35f-a8bb-4423-8a1b-81815294ce08", "df8ce0a5-a16b-45f1-b32f-a0e09a71fafa", "e028abb7-abc7-40da-9885-bc7fe5e52b61", "e1eb7492-c795-424f-ac86-e5cd2745f70c", "fe90cf43-c60d-4900-b68d-dfce7865e67f"], "title": "Design, analogy, and creativity", "venue": "IEEE Intelligent Systems", "year": 1997, "id": "c6c4c338-f930-47f2-b910-c5ae9edf3271"}
{"abstract": "Mobile code presents a number of threats to machines that execute it. We introduce an approach for protecting machines and the resources they hold from mobile code and describe a system based on our approach for protecting host machines from Java 1.1 applets. In our approach, each Java applet downloaded to the protected domain is rerouted to a dedicated machine (or set of machines), the playground, at which it is executed. Prior to execution, the applet is transformed to use the downloading user's Web browser as a graphics terminal for its input and output, and so the user has the illusion that the applet is running on his own machine. In reality, however, mobile code runs only in the sanitized environment of the playground, where user files cannot be mounted and from which only limited network connections are accepted by machines in the protected domain. Our playground thus provides a second level of defense against mobile code that circumvents language-based defenses. This paper presents the design and implementation of a playground for Java 1.1 applets and discusses extensions of it for other forms of mobile code, including Java 1.2.", "authors": ["Dahlia Malkhi", "Michael K. Reiter"], "n_citation": 109, "references": ["002371d9-10ba-47c3-9eb7-c074fc487d46", "243c148f-0cf4-47e3-b1fc-891912ab7f68", "2ce11e04-2810-4106-982b-0d94db6316e4", "3532531b-0040-4c3d-bd79-19b408d7a76f", "5268dd27-cea9-4f6e-8d1b-24bff534d700", "9ec23b98-e7c2-4747-bbb5-dc65a48f974d", "b826aeb6-49f6-42a8-878b-4b45d69c9fbb", "cd86bea5-f2d8-4e52-a951-a077a7939e8b", "e8d42c24-fa43-4482-a10e-ee9069c04845", "ff4862a5-d73a-423c-9699-6dfbd13491c4"], "title": "Secure execution of Java applets using a remote playground", "venue": "IEEE Transactions on Software Engineering", "year": 2000, "id": "8598ad41-8d58-47b6-82ca-ce5505e69119"}
{"abstract": "A traditional input-shaping technique is adapted to control transfer maneuvers on quay-side container cranes. The controller is developed using an accurate two-dimensional four-bar-mechanism model of a container crane and accounts for maneuvers that involve large hoisting operations. A graphical representation of the phase plane of the payload oscillations is used to derive mathematical constraints to compute the switching times of a double-step acceleration profile that results in minimal transient and residual oscillations. In contrast with single-step shaped acceleration profiles which are very sensitive to frequency approximations, the proposed double-step profile is less sensitive to small variations in the frequency even for large trolley accelerations", "authors": ["Ziyad N. Masoud", "Mohammed F. Daqaq"], "n_citation": 50, "references": ["6b5e0c6d-1489-4711-a1d5-dc4732ee8330", "96d28e60-bdde-404d-854a-aacd753a2df8"], "title": "A Graphical Approach to Input-Shaping Control Design for Container Cranes With Hoist", "venue": "IEEE Transactions on Control Systems and Technology", "year": 2006, "id": "768f1c0e-ec64-4954-855f-ae2c06ebbcf3"}
{"abstract": "The automotive industry is moving aggressively in the direction of advanced active safety. Dedicated short-range communication (DSRC) is a key enabling technology for the next generation of communication-based safety applications. One aspect of vehicular safety communication is the routine broadcast of messages among all equipped vehicles. Therefore, channel congestion control and broadcast performance improvement are of particular concern and need to be addressed in the overall protocol design. Furthermore, the explicit multichannel nature of DSRC necessitates a concurrent multichannel operational scheme for safety and non-safety applications. This article provides an overview of DSRC based vehicular safety communications and proposes a coherent set of protocols to address these requirements", "authors": ["Daniel Jiang", "Vikas Taliwal", "Andreas Meier", "Wieland Holfelder", "Ralf Guido Herrtwich"], "n_citation": 515, "references": ["16edcc3b-05eb-4170-ac14-a77b9faa2b11", "269c2381-df2a-4290-b934-d0919381ecd6", "49ce37e3-5c8b-4abe-bcda-67f99d247e4c"], "title": "Design of 5.9 ghz dsrc-based vehicular safety communication", "venue": "IEEE Wireless Communications", "year": 2006, "id": "2d6258bb-5369-4115-8689-cc4a4a7ef22f"}
{"abstract": "Detecting faces in images with complex backgrounds is a difficult task. Our approach, which obtains state of the art results, is based on a neural network model: the constrained generative model (CGM). Generative, since the goal of the learning process is to evaluate the probability that the model has generated the input data, and constrained since some counter-examples are used to increase the quality of the estimation performed by the model. To detect side view faces and to decrease the number of false alarms, a conditional mixture of networks is used. To decrease the computational time cost, a fast search algorithm is proposed. The level of performance reached, in terms of detection accuracy and processing time, allows us to apply this detector to a real world application: the indexing of images and videos.", "authors": ["R. Feraund", "Olivier Bernier", "Jean Emmanuel Viallet", "Michel Collobert"], "n_citation": 496, "references": ["3b3d7569-08b1-4017-9910-2a017a00e43e", "43530fe4-10a9-4ddf-b61d-8844f0ff3f04", "44a9fc14-1bf4-489e-add7-84abc2cb3561", "4c100cbf-e979-49c3-905a-b579fc61fd69", "5dc36efd-1f4c-458e-8df8-2c915899c1f4", "5ffac6f9-2456-42cf-830c-9049ce37c899", "648675c6-6ea7-4fa5-a91d-9d3156d09692", "64fa74e8-db02-4190-87d7-bf23e9859a7c", "8d7bb750-adbb-4a71-813f-09fdfab8f7d0", "8f9a0618-8881-46a0-8527-c04b9b481a59", "98b287ef-cf9b-42b5-9647-f1288f4206a2", "a7dd6e11-211f-41c7-a800-420343fe3f8b", "b889d6ec-330d-406f-87b6-ea34804fadfd", "bef680e5-5e63-4a47-9b4c-9848ead82206", "d42f853d-12d7-416d-8b27-c314ef563eed", "d5e5a24d-f80e-4f1a-b48b-22403b653276", "d6e37fb1-5f7e-448e-847b-7d1f1271c574", "da4534a6-897c-4431-89ef-cd326bfaf9a8", "df20dd57-943e-4ac6-9d4e-c5a0ced37a01", "f4646960-d4bb-4245-9dfb-37da20915e01", "f8bfc13f-3962-4f49-8e41-ee697b312948"], "title": "A fast and accurate face detector based on neural networks", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2001, "id": "f855673e-279b-4aa7-8c40-25cd48b8ebdd"}
{"abstract": "This paper explores kernel spectral clustering methods to improve forecasts of aggregated electricity smart meter data. The objective is to cluster the data in such a way that building a forecasting models separately for each cluster and taking the sum of forecasts leads to a better accuracy than building one forecasting model for the total aggregate of all meters. To measure the similarity between time series, we consider wavelet feature extraction and several positive-definite kernels. To forecast the aggregated meter data, we use a periodic autoregressive model with calendar and temperature information as exogenous variable. The data used in the experiments are smart meter recordings from 6,000 residential customers and small-to-medium enterprises collected by the Irish Commission for Energy Regulation (CER). The results show a 20% improvement in forecasting accuracy, where the highest gain is obtained using a kernel with the Spearman's distance. The resulting clusters show distinctive patterns particularly during hours of peak demand.", "authors": ["Carlos Alzate", "Mathieu Sinn"], "n_citation": 35, "references": ["07266154-67e6-448b-87cb-d86a8d95829a", "07325fc0-4606-47c4-ac47-e3e3e25f3326", "0b9bdcf7-aab3-400f-a286-3dcf03ce8a6f", "21ad867e-f85e-4e3c-a7f2-45ee000dbc88", "3ef55dbc-49ff-4021-ac9c-9745ea1b8496", "7c90045b-63b9-4f29-82a0-bf7c914a6ef6", "ecfd5590-3f17-42d7-a165-88e7b692742d"], "title": "Improved Electricity Load Forecasting via Kernel Spectral Clustering of Smart Meters", "venue": "international conference on data mining", "year": 2013, "id": "682760fc-c7e9-4624-bdfc-b70086b01d1b"}
{"abstract": "The development of four separate, prototype expert systems to aid in software engineering management is described. Given the values for certain metrics, these systems provide interpretations which explain any abnormal patterns of these values during the development of a software project. The four expert systems which solve the same problem, were built using two different approaches to knowledge acquisition, a bottom-up approach and a top-down approach and two different expert system methods, rule-based deduction and frame-based abduction. In a comparison to see which methods might better suit the needs of this field, it was found that the bottom-up approach led to better results that did the top-down approach, and the rule-based deduction systems using simple rules provided more complete and correct solutions than did the frame-based abduction systems. >", "authors": ["Connie Loggia Ramsey", "Victor R. Basili"], "n_citation": 52, "references": ["1cb738d4-f913-48e2-8a70-b734808145c1", "5cad0949-23a7-4a7d-a624-708ff7cce16c", "83d54f51-723b-4ab2-9ef7-b844797dacc1", "85c2aa41-f6ae-434f-8a4b-7acf962ba53d", "8c6f6ef7-8ab8-441d-8cc8-c94568448279", "8c758e46-7641-4b35-86e8-48f041ae9042", "915b0aa5-e367-47fa-b9f5-1f248a3b3006", "96418430-c32e-42b4-91e1-9a3d6dde1bd5", "a6ee8425-3dd3-40fd-b9bb-214632f04a1a", "a98d7e3a-de51-4415-80b0-fa5db561b688", "c16b39cb-1c86-4664-8cac-e8c0e4871df2", "e1d84eb0-f289-460e-945d-07aed1610dbd", "fb5a53d8-1915-4da2-bc3e-52a3b1120bc6"], "title": "An evaluation of expert systems for software engineering management", "venue": "IEEE Transactions on Software Engineering", "year": 1989, "id": "3d399a4a-ee80-410e-a3ac-1ab204213802"}
{"abstract": "Source-code documentation is essential to efficiently develop and maintain large software products. Documentation is equally important for software product lines (SPLs), which represent a set of different products with a common code base. Unfortunately, proper support for documenting the source code of an SPL is currently lacking, because source code variability is not considered by current documentation tools. We introduce a method to provide source-code documentation for feature-oriented programming and aim to support developers who implement, maintain, and use SPLs. We identify multiple use cases for developers working with SPLs and propose four different documentation types (meta, product, feature, and context) that fulfill the information requirements of these use cases. Furthermore, we design an algorithm that enables developers to create tailor-made documentation for each use case. Our method is based on the documentation tool Javadoc and allows developers to easily write documentation comments that contain little overhead or redundancy. To demonstrate the efficiency of our method, we present a prototypical implementation and evaluate our method with regard to documentation effort for the SPL developers by documenting two small SPLs.", "authors": ["Sebastian Krieter", "Reimar Schr\u00f6ter", "Wolfram Fenske", "Gunter Saake"], "n_citation": 21, "references": ["1f098e13-aad0-4e12-92fc-d02fdbb561b6", "3de6d0ec-2d49-4092-b77e-73c74f7aac27", "6bb138d0-6fae-4bf3-b751-5ddae9e1dbe1", "7f4872b0-d490-4ea5-9a08-514a1f7ee324", "a22b2d59-c3b0-4c74-b237-ce4d9e347cf0", "b13b59fc-be68-496d-9872-88c20e3704f0", "b4cea9e0-370b-4f5a-92cc-ea917269fdf7", "c2e93905-6f1d-43c1-b61c-fb96ca869357", "d001bc0f-b1e6-4c28-a7ee-4c5519cfa104", "d86ada5c-ea59-4692-bc34-67df93547b20", "d959427a-c8e4-419f-ae9c-a2370a63e635", "dd676fcc-16b4-4077-bfca-6fb5573008b2"], "title": "Use-Case-Specific Source-Code Documentation for Feature-Oriented Programming", "venue": "variability modelling of software intensive systems", "year": 2015, "id": "4610fb67-ae52-4796-9abc-e73bd0bb260f"}
{"abstract": "In this paper, the stability of discrete-time linear systems subject to actuator saturation is analyzed using a saturation-dependent Lyapunov function. This saturation-dependent Lyapunov function captures the real-time information on the severity of actuator saturation and leads to less conservative estimate of the domain of attraction, which is based on the solution of an LMI optimization problem. Numerical examples are presented to show the effectiveness of the proposed method.", "authors": ["Yong-Yan Cao", "Zongli Lin"], "n_citation": 213, "references": ["591b620f-eff6-4a64-9e1c-2ec5e5f10dac"], "title": "Stability analysis of discrete-time systems with actuator saturation by a saturation-dependent Lyapunov function", "venue": "conference on decision and control", "year": 2002, "id": "d91b08bd-f12a-47f9-88c1-0d35da6ddf20"}
{"authors": ["Markus Tresch", "Neal Palmer", "Allen Luniewski"], "n_citation": 20, "references": ["1036541c-cce6-4d45-987f-a0391f464540", "27530b9c-b319-4156-9538-98aa2360f01d", "3328d1fd-485a-4605-8f72-848eea7ad8d1", "33d6dabd-c086-4a6e-939a-c322b6ada724", "5a2b034a-08a7-42b4-8e54-dbf4fc57c480", "5e8be929-7c33-4976-b583-2b41790fe4be", "6d92cc17-84df-454f-afb7-1037bc4385f5", "adf7d983-9784-4e80-b790-5340fa166d99", "b730557b-5f77-4780-8cb7-509c73d9b783", "d3ee0aa5-26b3-48fc-abe4-318063c65532", "e9abffef-c6bf-44da-a673-be480773dbbb", "ed660ea2-fad8-4bd1-8c0b-8c0679eb1657"], "title": "Type Classification of Semi-Structured Documents", "venue": "very large data bases", "year": 1995, "id": "db93c85b-f258-4e0f-ac5b-f0a8603c42fe"}
{"abstract": "Through technologies such as RSS (Really Simple Syndication), Web Services, and AJAX (Asynchronous JavaScript and XML), the Internet has facilitated the emergence of applications that are composed from a variety of services and data sources. Through tools such as Yahoo Pipes, these \u201cmash-ups\u201d can be composed in a dynamic, just-in-time manner from components provided by multiple institutions (i.e., Google, Amazon, your neighbor). However, when using these applications, it is not apparent where data comes from or how it is processed. Thus, to inspire trust and confidence in mash-ups, it is critical to be able to analyze their processes after the fact. These  trailing analyses , in particular the determination of the provenance of a result (i.e., the process that led to it), are enabled by  process documentation , which is documentation of an application's past process created by the components of that application at execution time. In this article, we define a generic conceptual data model that supports the autonomous creation of attributable, factual process documentation for dynamic multi-institutional applications. The data model is instantiated using two Internet formats, OWL and XML, and is evaluated with respect to questions about the provenance of results generated by a complex bioinformatics mash-up.", "authors": ["Paul T. Groth", "Simon Miles", "Luc Moreau"], "n_citation": 49, "references": ["00a8b42f-52cf-4f43-9bdb-bf515f100c69", "050395f3-8213-458f-86de-ba18771b8324", "0f3afa8f-a457-4a6d-92d8-262eb2312945", "108678ba-4d0b-4df6-9b1a-788716ba2f91", "136c4780-2f25-4068-90a5-aed6afaf2890", "14f0bc26-0c28-446e-aae4-0b7f57fc9aa6", "1734e4a6-7750-403e-bb94-bb430be2c68f", "1c89f064-6614-4636-b1dc-5f4c71e5e3a6", "2608f42e-69f7-4edc-aa9f-beeffa8ee1f8", "262b950b-1224-41ba-a5b7-169500e010df", "29eaafe8-1e34-48f0-98b8-2cc51ac5f3c8", "2a0834ce-a7b8-408b-b9f3-242960eabe0b", "3bc3b806-e51f-4110-818a-8fb9ea196b44", "47052a82-ce70-4a0d-9d51-ce94d392dee5", "4bb1c4d3-e9d3-4f93-ace7-2256d260c82c", "51ad38b1-6d26-43b8-8174-7d5212f525d1", "5d2a80f0-60b3-4e39-a229-7a6cc8852866", "6768d763-110d-4afc-8be0-00557d018fff", "8ae8d596-9bba-4bb2-9da7-2138b050e176", "92683362-72f1-4855-bda0-2d62fe6f0cc0", "994fb13f-1239-4977-bd31-28371c14e9dc", "9a8543e6-15c3-48c8-a33c-d180563c9fc3", "ae1823a4-40e0-4a1f-bb45-019e955ad8b4", "b0cdc8a4-f473-479d-aee2-10ec1dcf52d6", "be2e5f1b-7f9c-4b3a-b28a-a3b1e4e00242", "c01b7dff-2f4a-4c7f-b8e9-69e9a2172bca", "c09e56ad-fba8-45ea-8108-76ee231b334e", "cbf51c99-4aee-4284-b4d2-9ac53959c0ce", "cd8b5158-c374-4e64-96aa-7b5e5986e681", "d8edf26a-ed96-40e8-8ad8-94a91d048369", "e0ca6734-ffd4-40cd-be87-257d33f21fb7", "e84d8409-447f-49af-a69e-f72758f31b5b", "f078fe82-a687-49eb-941b-7d685efbaec3", "f33b9820-7d88-4742-87e8-7714731d1239", "fbd0a0eb-4686-42b8-9dc0-c35c10ed1b35"], "title": "A model of process documentation to determine provenance in mash-ups", "venue": "ACM Transactions on Internet Technology", "year": 2009, "id": "55691eee-bf23-4f87-a0fe-8d4190fffe97"}
{"abstract": "Existing approaches to template-based visual tracking, in which the objective is to continuously estimate the spatial transformation parameters of an object template over video frames, have primarily been based on deterministic optimization, which as is well-known can result in convergence to local optima. To overcome this limitation of the deterministic optimization approach, in this paper we present a novel particle filtering approach to template-based visual tracking. We formulate the problem as a particle filtering problem on matrix Lie groups, specifically the three-dimensional Special Linear group SL(3) and the two-dimensional affine group Aff(2). Computational performance and robustness are enhanced through a number of features: (i) Gaussian importance functions on the groups are iteratively constructed via local linearization; (ii) the inverse formulation of the Jacobian calculation is used; (iii) template resizing is performed; and (iv) parent-child particles are developed and used. Extensive experimental results using challenging video sequences demonstrate the enhanced performance and robustness of our particle filtering-based approach to template-based visual tracking. We also show that our approach outperforms several state-of-the-art template-based visual tracking methods via experiments using the publicly available benchmark data set.", "authors": ["Junghyun Kwon", "Hee Seok Lee", "Frank C. Park", "Kyoung Mu Lee"], "n_citation": 50, "references": ["02fec529-3d63-444e-a8d0-804828ae452a", "0687557b-043b-4ac0-ae73-dc6accea9ab2", "09c0fd57-6a96-435d-a87a-78b62ee9cb80", "0ab42581-b876-43c0-9517-5819ea3468bc", "150449b6-f8e9-4708-902c-c9bebf7f13a3", "16975119-acff-47ea-89a7-7dee30b42da6", "17d8cb07-d231-4e29-a6a5-2dadf6521f83", "1ba94a3f-ba8a-4aff-8151-3a855803711c", "30bd8026-db22-49d3-893e-865a82bb451c", "32948877-48a6-46a0-bdef-a1895952d4c7", "3470ea47-1bc8-4c06-91c6-0d726b66a1b2", "389ddd80-8f2c-490d-944a-800043ace705", "3ed17ffd-b416-470a-973a-77d7085a3503", "4db6c10f-b1bb-49c2-b00c-bca8425aa979", "5211a65c-b4a7-45e8-a883-87931ec0cb07", "599d75ff-ac1b-409e-b7f4-d804bca6f387", "5d1871cf-c728-46a5-8b08-f2aac4963a22", "5f146a05-3f37-4bc7-9112-e858b5fe4794", "6300a64b-4e61-472d-8e92-4daaf85c2163", "67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3", "6fc9ec8b-919b-460b-99c6-c914db98fbf9", "7707a3d2-2833-4787-ab42-f47f7944f836", "78bc8abc-dd21-47f3-88bd-6103f7307523", "8a7f598f-a308-4e6a-9c3c-c57e44198d79", "8b519a65-db09-4764-b8e3-70e8b6d64449", "8f46926d-3e16-4f99-8345-b87c14919d04", "8f4b93ce-9d3c-43df-be5a-908c7718e14c", "910a223b-1f53-4100-a600-6cce47c85f1d", "93f9ba88-4953-4158-a234-ede0b9e329f2", "9676f647-b561-45db-9747-d2a5b4b8d63b", "96df0fac-7ae8-46d6-a5ea-9fe17fdbae67", "a3edac38-9392-4279-9a67-156f5a976a48", "a7176457-ef4b-430d-b0f0-fdaa8da603ad", "afd5f6f0-8fe7-4f6c-bbfc-b4f130afbce0", "b2c6ca2b-742b-4798-a827-65c7d68d85f0", "b7e9f9d5-aca7-467d-bf04-95941999c308", "b85ccd53-b7e0-4023-aa56-36fa9c32cd23", "b944f77f-113b-4a02-ae5e-d4a124b8fd5b", "bc9d9aee-be96-44a1-b36e-4c4421f06d9d", "bd55f75d-0d78-4d54-b5b1-2ea7b9134e87", "c484503d-2cc2-489a-9bcd-10d182e6d999", "c9fee18e-7be9-466d-a79f-f322a8f25e1c", "cc85b5a4-5191-44a5-b936-a2fe802f107b", "d34f6bdd-3a38-4223-8510-43367b3d667d", "d575b939-0808-4629-95ff-c5775c97c0eb", "dcdd3b1b-bf52-4ae3-a68d-efec6aba5cef", "de765462-b531-44de-8b28-9937d0fa5e0f", "e2def938-8225-4439-a774-de9acfbaae87", "e9388cc0-e092-480e-82d4-5c42b53bc355", "f225f439-4389-4312-a503-f8c1b0aa02de", "f9809cc2-9acb-4d06-88fa-64e5a079bb6b"], "title": "A Geometric Particle Filter for Template-Based Visual Tracking", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2014, "id": "8f23b7fd-98d9-4358-a82a-88cf09a1fed8"}
{"abstract": "We show that the typed region calculus of Tofte and Talpin can be encoded in a typed \u03c0-calculus equipped with name groups and a novel effect analysis. In the region calculus, each boxed value has a statically determined region in which it is stored. Regions are allocated and de-allocated according to a stack discipline, thus improving memory management. The idea of name groups arose in the typed ambient calculus of Cardelli, Ghelli, and Gordon. There, and in our \u03c0-calculus, each name has a statically determined group to which it belongs. Groups allow for type-checking of certain mobility properties, as well as effect analyses. Our encoding makes precise the intuitive correspondence between regions and groups. We propose a new formulation of the type preservation property of the region calculus, which avoids Tofte and Talpin's rather elaborate co-inductive formulation. We prove the encoding preserves the static and dynamic semantics of the region calculus. Our proof of the correctness of region de-allocation shows it to be a specific instance of a general garbage collection principle for the \u03c0-calculus with effects.", "authors": ["Silvano Dal-Zilio", "Andrew D. Gordon"], "n_citation": 50, "references": ["06ba4781-7271-42e5-a2d2-c7a34492c427", "1bde5716-a2ee-4ab6-8d9c-0906f70b2762", "23c82e3b-76e3-401a-835b-7b7cc9e708c0", "30ccc8ec-434d-496e-ab40-d669add4041c", "318c2ed9-9d51-403d-9dee-76410683b58d", "3c70b92f-ef52-443d-95a8-39870acad02c", "684f80ac-4d7d-46eb-9d1b-2599bae23de6", "703f2125-316e-4930-bbde-57e81ebd88e6", "85033f09-94ac-4dc1-929c-04f4152c4712", "8c07e38c-ee82-473e-879a-ebe9d02dd941", "9469dba9-4205-4782-a3d3-b83b86658620", "a59257db-95e5-4bd8-9010-61dd1864c875", "a97daab8-b47b-401f-93ea-f7dab1cfcda7", "aefe70e0-4854-4244-8434-28acb3324aac", "afef5e47-6b27-47db-96a6-543f1cfba92a", "b2ee0ee6-0988-486e-b4fd-96ff0fa5f0ca", "d778f216-81b6-4ced-a2b6-3b1c4fac146b", "f10cfb56-1737-4597-87cf-75f35143a3e5"], "title": "Region Analysis and a pi-Calculus wiht Groups", "venue": "mathematical foundations of computer science", "year": 2000, "id": "26a7c2ad-acc3-4903-9237-7b2ae54f9420"}
{"abstract": "This paper presents a new nonlinear filtering algorithm that is shown to outperform state-of-the-art particle filters with resampling. Starting from the Ito\u0302 stochastic differential equation, the proposed algorithm harnesses Karhunen-Loeve expansion to derive an approximate non-autonomous dynamical system, for which transfer operator based density computation can be performed in exact arithmetic. It is proved that the algorithm is asymptotically consistent in mean-square sense. Numerical results demonstrate that explicitly accounting prior dynamics entail significant performance improvement for nonlinear non-Gaussian estimation problems with infrequent measurement updates, as compared to the performance of particle filters.", "authors": ["Parikshit Dutta", "Abhishek Halder", "Raktim Bhattacharya"], "n_citation": 4, "references": ["4aea3e01-f966-4aea-8184-10c14e38fa84", "67efeb3a-56bb-4bd8-bc0b-dca8f84fa3d3", "8e7a8892-2582-44b0-8704-d732c4001c77", "bd5c58b2-15e6-4419-b28b-968d17654bf5", "d8116977-0962-4d4d-832d-f9b0a095c75c"], "title": "Nonlinear filtering with transfer operator", "venue": "american control conference", "year": 2013, "id": "636ddfd8-57aa-4c96-a1b7-5e6e8222fb10"}
{"abstract": "Using classical automata theory the authors show how noninterference can be viewed as a relatively simple phenomenon. They also give direction for future work concerning probabilistic security problems using classical automata theory. >", "authors": ["Ira S. Moskowitz", "Oliver Costich"], "n_citation": 50, "references": ["0b1d2e5e-d952-464b-abd7-e11b6d11c290", "0ec905cf-2eca-4a6e-b96a-aaed5a1e3789", "1baeeaaf-052d-4fa9-873f-4f6528389e30", "2c1c6b3c-0fb2-4131-a1f4-7cf54a76a072", "33968969-49d4-424f-a1db-59a82bf959c4", "4598aa14-0c4c-4dc0-850a-b2e6a331749b", "8ab2562e-5198-4aa3-8e8e-37ee9a0417a2", "b0f6455a-6f99-42c5-8502-4fa535768ceb", "ce2442f4-2cd7-40f0-a6ee-e6019f962810", "d1db3d38-6d1d-49d4-b418-ffc799c8621c", "d3e02530-7dca-4e01-8789-3490b8f1ca4f", "e38f5822-ccd2-4fce-aca1-4bd838724dea", "fe9d2177-5770-40ec-acd2-2fc1ce394947"], "title": "A classical automata approach to noninterference type problems", "venue": "", "year": 1992, "id": "d3499fb0-052d-4b3a-b535-da07e71ccf6a"}
{"abstract": "The paper is an attempt to show that the formalism of subjective probability has a logical interpretation of the sort proposed by Frank Ramsey: as a complete set of constraints for consistent distributions of partial belief. Though Ramsey proposed this view, he did not actually establish it in a way that showed an authentically logical character for the probability axioms (he started the current fashion for generating probabilities from suitably constrained preferences over uncertain options). Other people have also sought to provide the probability calculus with a logical character, though also unsuccessfully. The present paper gives a completeness and soundness theorem supporting a logical interpretation: the syntax is the probability axioms, and the semantics is that of fairness (for bets).", "authors": ["Colin Howson"], "n_citation": 50, "references": ["20cf7b82-4d58-4f4c-a07c-54342c1169b1"], "title": "Probability and logic", "venue": "Journal of Applied Logic", "year": 2003, "id": "31d88036-1441-42c4-9117-af4ecfa78de7"}
{"abstract": "TRIDENT is a set of interactive tools that automatically generates a user interface for highly-interactive business-oriented applications. It includes an intelligent interaction objects selection based on three different concepts. First, on object oriented typology classifies abstract interaction objects to allow a presentation independent selection. Second, guidelines are translated into automatic rules to select abstract interaction objects from both an application data model and a dialog model. Third, these guidelines are encapsulated in a decision tree technique to make the reasoning obvious to the user. This approach guarantees a target environment independent user interface. Once this specified, abstract interaction objects are mapped into concrete interaction objects to produce the observable interface.", "authors": ["Jean Vanderdonckt", "Fran\u00e7ois Bodart"], "n_citation": 333, "references": ["25884285-da07-4a10-9260-821d1d1a2585", "2f8df832-cd28-4a08-b12a-1002c3f0192e", "5bca49d5-06a9-4976-afb4-652401553470", "67bbf4d8-05e3-4114-9a3c-664fffc8aef9", "7cfd979a-05ce-48f4-b052-431af87cd01c", "db5c499a-c1ee-461a-94b3-f1292dbcf50e"], "title": "Encapsulating knowledge for intelligent automatic interaction objects selection", "venue": "human factors in computing systems", "year": 1993, "id": "8dde73de-25a1-484b-bd91-08b8cc776514"}
{"abstract": "Component programming is a multiparadigm approach to software construction based on highly generic components. Because component programming is concerned with source-code components, it is assumed by many to be a low-level approach to software development that affects only the development of source code libraries. On the contrary, this paper shows that the concepts of component programming go beyond library and source code issues and define a new conceptual attempt to software development with generic components. We show that component programming is an architectural style that supports the building of classes of software architectures in a specific domain. Component programming can be applied in the early stages of software development when architectural issues are to be determined. All the benefits of using an architectural style, therefore, can also be gained by using component programming: it guides the engineer in the problem decomposition towards the design and implementation of a system. The paper presents the architectural style of component programming and the insights we gained about component programming as we tried to define it as an architectural style.", "authors": ["Harald C. Gall", "Reza Jazayeri", "Ren\u00e9 Kl\u00f6sch", "Georg Trausmuth"], "n_citation": 9, "references": ["255c2203-b8b0-4bf1-ae59-1f95e7a35e73", "32a9c3fa-fbde-4731-ae01-f45853be60a1", "346d79ba-2175-4f98-ae4e-d505dd607bc6", "440ba1f2-d16f-4b2c-9b6a-0b9ebc244388", "7a551c2f-a20e-4bbc-9cfc-06c5a111b414", "a13a126e-37f7-4fad-8cfe-a3184320d64a", "a8840afa-a1ab-49f3-990e-e86a398da051", "b54d2959-55a5-4d4c-bf67-9ebf2a1e61f3", "cea0ce3c-791c-4591-ab87-0cb3510c9fcb", "f794bd44-aadf-4e34-83db-9c7e8b8cac7c"], "title": "The architectural style of component programming", "venue": "computer software and applications conference", "year": 1997, "id": "4195019a-8182-4ee9-9f6e-6a1c818bef07"}
{"abstract": "Part 1 Logic programs: basic constructs database programming recursive programming the computation model of logic programs theory of logic programs. Part 2 The Prolog language: pure Prolog programming in pure Prolog arithmetic structure inspection meta-logical predicates cuts and negation extra-logical predicates program development. Part 3 Advanced Prolog programming techniques: nondeterministic programming incomplete data structures second-order programming interpreters program transformation logic grammars search techniques. Part 4 Applications: game-playing programs a credit evaluation expert system an equation solver a compiler. Appendix: operators.", "authors": ["Leon Sterling", "Ehud Y. Shapiro"], "n_citation": 2843, "title": "The art of Prolog: advanced programming techniques", "venue": "", "year": 1986, "id": "119f9bcf-3fa5-4dca-a480-24c524da8e7d"}
{"abstract": "This article describes a modular solftware package for solving systems of nonlinear equations and nonlinear problems, using a new class of methods called tensor methods. It is intended for small- to medium-sized problems, say with up to 100 equations and unknowns, in cases where it is reasonable to calculate the Jacobian matrix or to approximate it by finite differences at each iteration. The software allows the user to choose between a tensor method and a standard method based on a linear model. The tensor method approximates  F ( x ) by a quadratic model, where the second-order term is chosen so that the model is hardly more expensive to form, store, or solve than the standard linear model. Moreover, the software provides two different global  strategies: a line search approach and a two-dimensional trust region approach. Test results indicate that, in general, tensor methods are significantly more efficient and robust than standard methods on small- and medium-sized  problems in iterations and function evaluations.", "authors": ["Ali Bouaricha", "Robert B. Schnabel"], "n_citation": 57, "references": ["3926b970-ea1f-44f1-acf7-4ed258e9b960", "50eed905-e3e0-457f-bcf9-498da4035e48", "a1af3cf2-67c9-4e4b-8881-7c19ad16f6c4", "b4765cc2-d138-430a-b136-e186a8119eb0", "b59d5649-b81d-422a-89fc-3c1287e3de3d"], "title": "Algorithm 768: TENSOLVE: a software package for solving systems of nonlinear equations and nonlinear least-squares problems using tensor methods", "venue": "ACM Transactions on Mathematical Software", "year": 1997, "id": "cc7013e1-45ce-4b0e-b5af-3efe29bdf2b7"}
{"authors": ["Yuta Fujishige", "Michitaro Nakamura", "Shunsuke Inenaga", "Hideo Bannai", "Masayuki Takeda"], "n_citation": 3, "title": "Finding Gapped Palindromes Online", "venue": "", "year": 2016, "id": "49d1a3a9-ad7a-4a30-a16a-5c094281e466"}
{"abstract": "A key to an optimal assortment of goods and pricing of individual items in a store is the knowledge about potential customer's behaviour. In this paper we present the simulation of individual customers based on a multiagent system which models the important elements and external influences as single agents. An agent can be member of several agent groups which are represented as holons. We model each individual customer as an agent which behaves according the customer's individual preferences. These preferences are extracted from real world data, such as customer cards, sales data and interviews. The customer's shopping behaviour is represented in behaviour networks (Bayesian nets) which are stored in the customer agents' knowledge bases. The behaviour of a representative group of customers induces the overall sales figures, which support decisions what to sell at which price. The presented concepts are based on ideas of Joachim Hertel from DACOS and Jorg Siekmann from the DFKI. They are implemented as a prototype, which provides, after further evaluation, the basis for a new and final system to be used by retailers.", "authors": ["Arndt Schwaiger", "Bj\u00f6rn P. Stahmer"], "n_citation": 21, "references": ["8632d60c-029f-469d-bdf0-407ebba11bad", "ae80d889-23b3-488e-b4a7-cbc46310eec2"], "title": "SimMarket: Multiagent-Based Customer Simulation and Decision Support for Category Management", "venue": "multiagent system technologies", "year": 2003, "id": "64f49e42-ddd4-4636-8be5-6752c94209fe"}
{"abstract": "Hand-made illustrations in scientific and technical textbooks commonly use internal and external labels or legends to establish co-referential relation between pictorial elements and textual expressions. By analyzing the most complex examples, we extracted several label layout styles and classified them. We propose a variety of real-time label layout algorithms that aim to produce nice and clean layouts. In order to achieve a frame-coherent label layout during user interactions, the algorithms consider layout decisions from previous frame. Moreover, several evaluation criteria to measure the quality of static as well as dynamic label layouts are presented.", "authors": ["Kamran Ali", "Knut Hartmann", "Thomas Strothotte"], "n_citation": 95, "references": ["179ce328-3b8a-4ed5-b0bb-f674e7d74da5", "3cb64c94-b9bb-4e3c-8984-7424ba44d26a", "6b7ed399-5f48-4f7e-a3c9-a304472adf12", "6dd1497f-ad3e-4e1c-91b9-11bf002bbfd6", "727b7f9a-65af-43eb-abb5-b2f53cb0ade8", "76660e51-3f4b-4cb2-9bd4-c573ec944777", "8fff39f7-9f7f-41ef-9c04-14f3a5169a43", "efea2966-0b4d-4041-8dd7-467f45e949b9", "f77f6f81-7929-4971-9529-fb6f3ba36e06"], "title": "Label Layout for Interactive 3D Illustrations", "venue": "international conference in central europe on computer graphics and visualization", "year": 2005, "id": "8c62bb31-d976-4e34-991d-651ed72ee542"}
{"abstract": "A novel query language for database mining, called RDM, is presented. RDM provides primitives for discovering frequent patterns and association rules, for manipulating example sets, for performing predictive and descriptive induction and for reasoning about the generality of hypotheses. RDM is designed for querying deductive databases and employs principles from inductive logic programming. Therefore RDM allows to query patterns that involve multiple relations as well as background knowledge. The embedding of RDM within a programming language such as PROLOG puts database mining on similar grounds as constraint programming. An operational semantics for RDM is outlined and an efficient algorithm for solving RDM queries is presented. This solver integrates Mitchell's versionspace approach with the well-known APRIORI algorithm by Agrawal et al.", "authors": ["Luc De Raedt"], "n_citation": 50, "references": ["102a0577-3322-4cd1-86cd-1726bf675ad1", "1f226ef7-3557-45b0-8aca-4b2a0f7f1827", "2f53b167-06ed-4217-b520-7ac21ed02964", "3aea4255-a789-43e2-9a70-3a2f0641eab5", "4516543e-c8bb-4b21-818e-dad61ff606d0", "51b3ac0e-0afc-427f-9806-42a204295d12", "5899eb6c-2e22-4d79-a2be-15fe67911177", "7ad703e7-984f-4d99-bf91-0f08076f3371", "8afef1a5-6b09-410b-9520-6fd9d082f70c", "a95a5dc2-0588-4cbf-b22b-f82dce404acb", "acc12e1e-3e1d-4f9e-b24b-20cd3dae38ce", "b98f39cf-e815-48be-acb1-f09b92eac912", "d13f5663-ccf9-4f2e-b78c-e8e1264ffd36", "ecd6a845-8439-49b0-abe8-f71fff81da23"], "title": "A Logical Database Mining Query Language", "venue": "inductive logic programming", "year": 2000, "id": "047e66f8-10a7-4c4c-9786-3f1dd73dfc53"}
{"abstract": "The paper deals with the decision process for IT outsourcing as a governance strategy for IT harmonization. IT harmonization is the standardization of IT solutions and IT functionality within former autonomously acting organizational units with independently grown IT departments. A case study shows the migration and implementation of a lead e-government application in the Austrian federal administration, where records management and workflows were previously operating independently in government agencies. Harmonization has been accomplished via a directed outsourcing decision which also supported the process of harmonizing IT governance. Sourcing design has proven to be crucial in that case, as several stakeholders presented different principle objectives. The approach of the outsourcing decision within the case study is analyzed by examining the decision process and interviewing major participants of the project.", "authors": ["Christian Sterba", "Thomas Grechenig", "Martin Pazderka"], "n_citation": 50, "references": ["2e5f21d9-098f-4345-8d26-2464f7a32c6c", "3ddf8245-810b-4404-881d-921589dd4e42", "3eff734e-eb2b-43c3-9042-4beb64d42271", "4de005de-7410-4425-9cdb-b4e65d8a4344", "6e92c10d-ffc8-4ecd-bbe7-1ba2a2ec3606", "877e0f5b-4c1e-4531-b053-3ee423384d8f", "ba6e7aa2-8961-41a9-afb2-56e233a4c420", "fa564687-1b02-400f-881c-1a06279c6abc", "fbe91d41-aba4-4309-965e-5e5e434ccddb"], "title": "Outsourcing as a strategy for IT harmonization: a public sector case study proposing an approach in independent stakeholder scenarios", "venue": "", "year": 2008, "id": "6856989d-a1bb-43bb-a036-f13aa1226369"}
{"abstract": "Component-based technology is increasingly adopted to speed up the development of complex software through component reuse. Unfortunately, the lack of complete information about reused components, and the complex interaction patterns among components can lead to subtle problems that throw new verification challenges. Good components are often re-used many times, sometimes within product lines, in other cases across different products. The reuse of components provides a lot of information that could be useful for verification. In this paper, we show how to automatically analyze component interactions by collecting information about components' behavior during testing and field execution, and then using the collected information for checking the compatibility of components when updated or reused in new products. The paper illustrates the main problems in developing the idea, proposes original solutions, and presents a preliminary experience that illustrates the effectiveness of the approach.", "authors": ["Leonardo Mariani", "Mauro Pezz\u00e8"], "n_citation": 61, "references": ["19cc1dca-7b33-4c22-8f90-306ce3781da2", "3e110cce-758e-4c2a-b257-32540f355f34", "457a887b-0ff6-48f4-9413-c7785080fe86", "50303516-dc41-41d9-992b-ab288fecf300", "560da421-9815-40a8-8ee8-101f5544b53e", "a37bac2e-5ffb-4607-b163-c26d23d30af6", "ab4562e5-00cf-4372-8992-5e276613fcbb", "b954bac0-384c-4a76-a0bb-997cc05d58c0", "c4f7de79-9cb5-41cf-86e2-c74117ae46f5", "c990280f-1cf1-4909-8b89-53f15f796fdb", "dab547d1-305b-4774-9951-7c5e62181c3b", "dc2bdc72-b814-4d59-a138-1d6a7db2d1c9", "ddf1d9e8-4e23-4b20-9f75-39aa6de72ea2", "eba14c6b-62f1-4fb0-938e-9b5ba101829d"], "title": "Behavior capture and test: automated analysis of component integration", "venue": "international conference on engineering of complex computer systems", "year": 2005, "id": "e4b261cc-b74f-4658-8da6-2673e692e2ea"}
{"authors": ["Michael Schmitt", "Anders Ek", "Beat Koch", "Jens Grabowski", "Dieter Hogrefe"], "n_citation": 55, "references": ["296d1831-3471-4251-a3f8-68df9158a64d", "37d27133-afc2-41cf-bbc2-360297c162bc", "57642da6-576c-4d73-aa9a-8ec7c77e50cc"], "title": "Autolink - Putting SDL-Based Test Generation Into Practice", "venue": "", "year": 1998, "id": "6f5a272a-13ec-4ee5-8537-37901ddd9118"}
{"abstract": "Healthcare has been slow in using human factors principles to reduce medical errors. The Center for Devices and Radiological Health (CDRH) recognizes that a lack of attention to human factors during product development may lead to errors that have the potential for patient injury, or even death. In response to the need for reducing medication errors, the National Coordinating Council for Medication Errors Reporting and Prevention (NCC MERP) released the NCC MERP taxonomy that provides a standard language for reporting medication errors. This project maps the NCC MERP taxonomy of medication error to MedWatch medical errors involving infusion pumps. Of particular interest are human factors associated with medical device errors. The NCC MERP taxonomy of medication errors is limited in mapping information from MEDWATCH because of the focus on the medical device and the format of reporting.", "authors": ["Juliana J. Brixey", "Todd R. Johnson", "Jiajie Zhang"], "n_citation": 39, "references": [], "title": "Evaluating a medical error taxonomy.", "venue": "", "year": 2002, "id": "e9b8a6ed-91f4-4ba0-9b7b-bb06cd778144"}
{"abstract": "Experimentation in software engineering is necessary but difficult. One reason is that there are a large number of context variables and, so, creating a cohesive understanding of experimental results requires a mechanism for motivating studies and integrating results. It requires a community of researchers that can replicate studies, vary context variables, and build models that represent the common observations about the discipline. The paper discusses the experience of the authors, based upon a collection of experiments, in terms of a framework for organizing sets of related studies. With such a framework, experiments can be viewed as part of common families of studies, rather than being isolated events. Common families of studies can contribute to important and relevant hypotheses that may not be suggested by individual experiments. A framework also facilitates building knowledge in an incremental manner through the replication of experiments within families of studies. To support the framework, the paper discusses the experiences of the authors in carrying out empirical studies, with specific emphasis on persistent problems encountered in experimental design, threats to validity, criteria for evaluation, and execution of experiments in the domain of software engineering.", "authors": ["Victor R. Basili", "Forrest Shull", "Filippo Lanubile"], "n_citation": 854, "references": ["03f892cb-5927-4719-b33b-92408afac3dd", "0dbbeb25-df1d-4f2a-a9fd-61757ce20d3c", "10ce0666-7e31-4f6f-b28b-7fa26a1d2d80", "1b239f58-9a9b-4b29-b124-81796e8a0818", "2e31c533-00d4-4bfe-935e-a52d4c28a096", "31817259-efa0-4c11-beb9-e8af125fece7", "35075d32-bea2-41ef-b949-93b6bb38c265", "3a80feca-efd7-4c2f-9785-a3ec05a82c49", "4c1c86de-d732-42fa-a7e1-e801ff97daba", "56320885-f8c7-478d-aa3e-e890862d2e29", "5b165419-6843-4c59-a43f-6fb52f50de8b", "5e6ba10f-32c8-45c5-8e2d-52f5fc53c5f5", "69e6b83a-2d17-4d0a-b42d-2929edf79264", "6ceb29f2-fdc1-4532-a5c1-45222e39da81", "775fcaec-2834-46ac-92b2-626c676c60b0", "83d54f51-723b-4ab2-9ef7-b844797dacc1", "91dc1d1f-6803-44ec-8d93-073db4ba289f", "a7ecc724-2a24-496f-98b5-f597ff0f00f9", "b2df37cd-3df1-46dc-af4d-cf109781c8a7", "bab96a0a-dbe8-490a-8fe5-96602e2f67f2", "d6707e83-68c8-459e-8e79-f724ec91ed3d", "e2b22c3a-28b4-4502-bfc1-77fe1f092bb1", "eb02e8fe-95d5-448e-afd3-5468c2b3dd50", "ed9be032-4ecf-4317-b587-53eb90996859", "fd6f8b28-b44d-4b03-80f8-9a5f38811528"], "title": "Building knowledge through families of experiments", "venue": "IEEE Transactions on Software Engineering", "year": 1999, "id": "f165d960-af33-4588-8319-b90fce361d80"}
{"abstract": "Despite the growing usage of web applications, extreme resource constraints during their development frequently leave them inadequately tested. Because testing may be perceived as having a low return on investment for web applications, we believe that providing a consumer-perceived fault severity model could allow developers to prioritize faults according to their likelihood of impacting consumer retention, encouraging web application developers to test more effectively. In a study involving 386 humans and 800 web application faults, we observe that an arbitrary human judgment of fault severity is unreliable. We thus present two models of fault severity that outperform individual humans in terms of correctly predicting the average consumer-perceived severity of web application faults. Our first model uses human annotations of fault surface features, and is 87% accurate at identifying low-priority, non-severe faults. We also present a fully automated conservative model that correctly identifies 55% of non-severe faults without missing any severe faults. Both models outperform humans at flagging severe faults, and can substitute or reinforce humans by prioritizing faults encountered in web application development and testing.", "authors": ["Kinga Dobolyi", "Westley Weimer"], "n_citation": 10, "references": ["14aa430f-3d7b-45d9-800a-b64cd85f2489", "1f8f0d30-e708-4ca1-a36c-d1b460553e00", "20507964-36cc-46db-be9f-4ed1798e525f", "22282c3a-bc5d-4b28-95f5-03eb346da583", "53ec1f2b-8a6e-4e92-a90a-0cc29d55fb7b", "58a77f39-fd3c-4379-9f04-5fdac60a736f", "60e7b89b-8cc4-4980-bdb9-fea41f3165a7", "63a632c2-cbf0-4ba4-b9f2-51ffc0332afc", "7536f534-6101-4fa3-bd28-3fa2f1f8d340", "7df14d34-4f76-4c28-9a31-8e59e75f1964", "7ea49f61-631d-4dee-bce3-8009523f45ef", "7ed29474-2c76-4439-a9e9-e60ccfbae7da", "83eea89d-7ee1-454e-98bd-1ce1e7ea8b08", "8b305bb5-d0c5-45d6-8282-5ab5b89cf551", "9ffeb896-b07c-4006-baa7-10627993b4e6", "a951b823-ef07-46a8-821b-54d6b573a636", "cfe58ed4-6ab7-4d2e-8c0e-e154484a7ff8", "fb0e96b6-666a-43ff-9dc4-93a79cbb159b", "fed3e232-a3ad-418a-bcce-f7db283ee614"], "title": "Modeling consumer-perceived web application fault severities for testing", "venue": "international symposium on software testing and analysis", "year": 2010, "id": "c155938d-f03b-4331-b950-9497ecf9a97c"}
{"abstract": "With the widespread popularity of the Internet, specifically the World Wide Web, Internet Electronic Commerce provides a revolutionary way of doing business, offers tremendous opportunities for business, and, most importantly, represents a market worth potentially hundreds of billions of dollars. Internet electronic commerce has become an active area recently, with many standards and solutions defined, proposed, and emerged. This paper will cover basic concepts of electronic commerce and framework of application lifecycle and three levels of approach from electronic commerce to electronic business. We will discuss recently proposed internet standards such as OTP, OBI, ICE, EDI, XML, and ebXML We will conclude with the e-marketplaces trends and directions.", "authors": ["Deren Chen", "Jen-Yao Chung"], "n_citation": 4, "references": ["0571088c-ed99-4227-af65-6e7f39dc9bad", "47a87250-62a8-42cd-8b8d-fda5852927b5", "ae6c0277-f760-452e-86f2-db9ec45b2edd", "d59ec8b8-145a-4570-a91c-38587a3613a5", "f198b1a4-9d0b-4732-96b7-ac4b93a9a6eb"], "title": "Internet Based Electronic Business Framework Applications and Business to Business Standards", "venue": "india software engineering conference", "year": 2001, "id": "68d9e1c4-baaf-4ca9-852a-91db7cc9c7b3"}
{"abstract": "This article proposes a taxonomy of model transformation, based on the discussions of a working group on model transformation of the Dagstuhl seminar on Language Engineering for Model-Driven Software Development. This taxonomy can be used, among others, to help developers in deciding which model transformation language or tool is best suited to carry out a particular model transformation activity.", "authors": ["Tom Mens", "Pieter Van Gorp"], "n_citation": 1123, "references": ["1d106e2e-1f1a-46ab-b836-2f61e08e6a46", "22c9ac00-f036-4c8d-9e20-1e357ac85309", "548d6335-f752-49dc-93a5-fc79d76e511d", "5db62f3e-d72c-497d-bf90-19d4b4fdf55f", "5df3a54c-8184-48a7-a615-4461e4e9ccc1", "5ee40d6c-109f-4a20-8644-329ee56934b7", "7570a12d-3189-46a9-b523-bb07b3bd2725", "78b75f73-29df-4d35-8f2c-dad498aaca14", "7dca2375-f135-45e0-a405-4e5f8145ae1d", "8313ef36-30a4-45fb-8770-8d68cbd70023", "a488c48f-a280-43ff-8c54-ebbb423d91ac", "adb6a9ff-a613-43e5-8cd5-ab6b4e75eeaa", "b1a4e18b-5634-4a43-b73c-77c1a687b22a", "c28cf51b-79cf-4b24-9234-8b304f11e6ca", "e64a248a-d777-4241-a8e0-d3b65d40c099", "f69dcbcf-d9fb-4c8c-acb4-359758285b7f"], "title": "A Taxonomy of Model Transformation", "venue": "Electronic Notes in Theoretical Computer Science", "year": 2006, "id": "7a461dfc-d075-43be-93be-6e0919ba8956"}
{"abstract": "The determination of upper bounds on execution times, commonly called worst-case execution times (WCETs), is a necessary step in the development and validation process for hard real-time systems. This problem is hard if the underlying processor architecture has components, such as caches, pipelines, branch prediction, and other speculative components. This article describes different approaches to this problem and surveys several commercially available tools 1  and research prototypes.", "authors": ["Reinhard Wilhelm", "Jakob Engblom", "Andreas Ermedahl", "Niklas Holsti", "Stephan Thesing", "David B. Whalley", "Guillem Bernat", "Christian Ferdinand", "Reinhold Heckmann", "Tulika Mitra", "Frank Mueller", "Isabelle Puaut", "Peter P. Puschner", "Jan Staschulat", "Per Stenstr\u00f6m"], "n_citation": 1703, "references": ["032623e7-68bf-4642-b97d-7998bd6770c5", "058e9e26-3529-4244-aff4-13a7bed7fab8", "0709f58a-4586-4a77-8e32-3274d57c7138", "07c47b2c-89dd-4757-9bb5-e923b18ea4e9", "0824ea87-5054-4009-bb1b-5a7163960acf", "0a14a4e0-62ce-49f7-8864-738e957728d7", "0cf6272f-418d-4abc-8fc2-68495cc61636", "194c7b31-f80f-40f5-8be7-5ac89f681043", "1cd271e4-f5f1-49a6-9a3b-ddd1c18cef86", "1e288c30-78f7-4366-a02a-d1997bc8e320", "20a80c49-ec4e-4cf3-abe9-b010679d678e", "26b6178f-b143-4e9d-813f-16a9fb9e4e58", "295398cf-9987-478f-84eb-488e371e0108", "2b9bc3a0-2cc0-4869-9f1b-edb08df10ee5", "2c526205-5805-405f-b450-d1e16efd89fb", "34ae12e8-141a-4210-b3f9-aedd24bc831c", "371d9f68-5d33-488d-8471-ec4624cdf33b", "373c470a-32a1-43df-b2cd-94e35c428df5", "3be27f65-400c-41d6-bad3-b5413be65fa8", "3e0843a3-1d82-4ff0-8325-f35927ec572a", "43f3b6ea-9b28-4c86-be65-e43c0581670b", "4678776b-ed0c-4778-9e5a-f2f641273495", "4a778f3b-5763-4bfd-a94f-e23d17b67990", "533251b5-d3a7-41ef-a6f0-c7c436e30d50", "558cd936-390d-45f3-a6f0-062efe79d752", "56281453-2699-4631-8321-19166c50cd13", "58480531-46fe-4285-ac39-bca2ab78ae27", "64f335a5-0b45-4a01-9ef5-36e53aaa770c", "77afbaa3-2010-438f-af03-2afc73533bb0", "7a298a68-8f72-407e-aba0-925e65ee77a4", "7ebd5ff2-b0a5-4318-acee-a0d66c5e2516", "80fb62db-2283-42d3-8ea9-561fbb29bfa7", "86c4ed2a-03f0-459d-a1f3-e54d1bbce176", "8f211981-73d1-49d4-a60d-d83e83330b5b", "90b8f797-93f1-4203-949d-76ba11f0ef28", "930d7acd-ff90-4c16-99a9-2f63629823c8", "94d4b21c-c42e-4c01-978a-8053b4d4249e", "956a527d-172e-4d56-96b0-91fcac86665b", "97ac5976-4169-4aab-9538-d70fb052cae4", "9a4984f9-27d4-47eb-8bc8-0469bf540f94", "9b7fafe3-81fb-4aeb-87b9-6c73582c66d9", "a10dcf43-6745-4c63-9ca6-b91f7d356754", "a8f7d0ca-58b4-442f-b7ad-7776c0c3c765", "ac4a1c80-60bf-4b4c-9e09-e9971e72fb3e", "b041e2e6-d197-484c-93d6-5c7d83e09233", "b10d7317-f68a-4b03-b302-53fdaf4ed970", "bf0a70fd-5073-4920-a36c-d2ad886631f8", "bf44be36-073c-480b-b525-10641b08724b", "c00bbb49-6e29-4103-8883-55acd23c248b", "c3745e99-e221-4f45-a110-d08147f2537e", "c9e97013-9140-4c2f-b6d4-7058b18b5c7b", "c9f488ba-4966-41e0-a77a-97252b2eb283", "cba6cce8-c292-4a20-95f3-ae0ed2065a1c", "cc609655-73d2-4a52-bfe5-2528f5d528fd", "cf738431-54f9-4b97-ab9e-4e90c1142ae3", "d62ee68e-2239-4fc3-82cb-d3cc3f087e99", "d7b5a5b1-0578-4992-aa34-5e55872b6f08", "dc527387-d5b0-450d-875c-3a8d45eaa48d", "e61c51d1-9090-406c-8c0d-c760afcef9ec", "e6574d1b-d1b5-4c46-9710-151c7a1cacc1", "e90302db-7a70-4a8c-bf99-84af8e241781", "ed190691-655d-4e5f-894f-e5be841de7b7", "ed6524ba-04aa-4aa3-8d9e-8f2d717be071", "ed75b131-d2b9-447f-817b-0d61b038bcd2", "f092cad5-bc21-4aa5-b2b5-691473ac3a76", "f544b8b4-7d05-433c-9e2e-4335d261102f", "fd642d54-0234-421c-b6ac-4f6fc7b9ff69"], "title": "The worst-case execution-time problem\u2014overview of methods and survey of tools", "venue": "ACM Transactions in Embedded Computing Systems", "year": 2008, "id": "da980a7a-fdbf-479b-beda-bf7b2040e22a"}
{"abstract": "Changes to software requirements not only pose a risk to the successful delivery of software applications but also provide opportunity for improved usability and value. Increased understanding of the causes and consequences of change can support requirements management and also make progress towards the goal of change anticipation. This paper presents the results of two case studies that address objectives arising from that ultimate goal. The first case study evaluated the potential of a change source taxonomy containing the elements \u2018market\u2019, \u2018organisation\u2019, \u2018vision\u2019, \u2018specification\u2019, and \u2018solution\u2019 to provide a meaningful basis for change classification and measurement. The second case study investigated whether the requirements attributes of novelty, complexity, and dependency correlated with requirements volatility. While insufficiency of data in the first case study precluded an investigation of changes arising due to the change source of \u2018market\u2019, for the remainder of the change sources, results indicate a significant difference in cost, value to the customer and management considerations. Findings show that higher cost and value changes arose more often from \u2018organisation\u2019 and \u2018vision\u2019 sources; these changes also generally involved the co-operation of more stakeholder groups and were considered to be less controllable than changes arising from the \u2018specification\u2019 or \u2018solution\u2019 sources. Results from the second case study indicate that only \u2018requirements dependency\u2019 is consistently correlated with volatility and that changes coming from each change source affect different groups of requirements. We conclude that the taxonomy can provide a meaningful means of change classification, but that a single requirement attribute is insufficient for change prediction. A theoretical causal account of requirements change is drawn from the implications of the combined results of the two case studies.", "authors": ["Sharon McGee", "Des Greer"], "n_citation": 50, "references": ["10103d8b-18af-4d2b-8968-12f618e871d6", "147d66ed-71a1-4744-b566-c224b484771b", "26a30946-4795-4737-87e9-a5530e42448b", "29ea1350-128e-4ca4-8b5b-0393da979614", "3e564625-850c-4b51-b2d5-17b22dbe1245", "3eba8928-cfa1-451b-8c13-ad87807ec11a", "466d60f6-c1f0-43cd-995e-06336963e237", "57b231bd-63f1-49f8-82ca-c2e02fb6704a", "5cad0949-23a7-4a7d-a624-708ff7cce16c", "65df2063-f5ea-4136-9ac9-14308ccc4e17", "671271d6-582d-4640-b67b-3c3e067815ad", "69cac2da-7ed8-42b6-b2db-2bdc0f6d130b", "6fd87f6e-b564-48c4-b16e-1922a8763c08", "84de3bad-f75f-4860-a85e-6999600ee211", "9f84e6eb-4ec9-44e4-9729-1b6ffa172dc5", "b38d0472-3ef2-4aa9-a5d5-b7c89299ab62", "b5ea5761-5fdf-4567-bd50-ec4d5a786195", "c4cbaf1d-56de-4232-91dc-fcc9898d0746", "c8a9dcea-ff60-45a5-bee1-8da7a85b8f85", "d20d8505-e5e3-4164-9e68-a39d33b4cf9c", "e015409c-0810-486d-b5f7-b186d1b705bd", "e4249366-fb19-458f-b91b-d2504a61f530", "e7c5501b-6ba7-48f7-be99-c1b61ec11dcc", "ea38d12d-b238-46da-841e-7cc9e954d10f", "ec32ab80-dbc3-4bf7-af49-ab46456f55a2", "ec5c5dfa-4f23-4fa1-9e82-b9d19e16625e", "f04e17ea-355f-44c7-8bf0-1147a8b41a4a"], "title": "Towards an understanding of the causes and effects of software requirements change: two case studies", "venue": "Requirements Engineering", "year": 2012, "id": "0430299d-5051-43a3-b88c-aa740af950cd"}
{"abstract": "The current IEEE 802.16a and 802.16d standards of wireless metropolitan area networks specify a ranging channel in the OFDMA physical layer that employs a set of CDMA codes for ranging and bandwidth requests. The ranging channel is contention-based and inherently unstable. In this paper, we propose two stabilization algorithms to enable efficient utilization of the ranging channel at close to the theoretical throughput limit, and analyze their performance using a continuous time Markov chain M/M/1 model. We show how to estimate system parameters such as the number of backlogged users, arrival rate and the first exit time for the critical. Based on these parameters, we present two methods for channel stabilization, for the cases that the number of ranging codes per frame is fixed and adjusted dynamically, respectively. We then present simulation results to show that, by restricting the actual arrival rate or dynamically adjusting the number of ranging codes, the ranging channel can be stabilized under all traffic conditions.", "authors": ["Jeong-Jae Won", "Choong-Ho Cho", "Hyong-Woo Lee", "Victor C. M. Leung"], "n_citation": 8, "references": ["32d4be8a-b24f-455d-a688-a2dc0e38d809", "52aa459e-e562-4520-8978-80a910f55ef4", "7cb4db8b-1746-41d1-ae4c-9a33ea612782", "9169a37e-6720-4a7e-96e8-2faa131bfc62"], "title": "Stabilization of contention-based CDMA ranging channel in wireless metropolitan area networks", "venue": "international conference on networking", "year": 2005, "id": "1851371b-09a4-468f-8ded-00cf5a59e285"}
{"abstract": "We present a novel approach for improving particle filters for multi-target tracking. The suggested approach is based on drift homotopy for stochastic differential equations. Drift homotopy is used to design a Markov Chain Monte Carlo step which is appended to the particle filter and aims to bring the particle filter samples closer to the observations while at the same time respecting the target dynamics. We have used the proposed approach on the problem of multi-target tracking with a nonlinear observation model. The numerical results show that the suggested approach can improve significantly the performance of a particle filter.", "authors": ["Vasileios Maroulas", "Panos Stinis"], "n_citation": 41, "references": ["8152010b-312f-45e7-8f16-afb64c3250ce", "fe5db668-9409-42fa-a09c-f88c58cdcedc"], "title": "Improved particle filters for multi-target tracking", "venue": "Journal of Computational Physics", "year": 2012, "id": "ec24af46-3a28-4574-9bf7-468c786b7129"}
{"abstract": "This paper presents an interactive video visualization system. In this visualization video data is considered to be a block of three dimensional data where frames of video data comprise the third dimension. The user can manipulate and see a cut plane through the video data. The visualization leads to images that are aesthetically interesting as well as being useful for image analysis", "authors": ["Sidney Fels", "Kenji Mase"], "n_citation": 50, "references": ["5ba1a5e7-ba43-4057-a005-492fa465b1e6", "6b12bb36-aa00-42d0-8603-5114fd969140", "c3ec3b14-75be-4b18-af66-195537226585"], "title": "Interactive video cubism", "venue": "conference on information and knowledge management", "year": 1999, "id": "3c018064-a6cd-49f6-9215-1bafd2fae17b"}
{"abstract": "Even though the programming languages C and C++ have been standardized by the American National Standards Institute (ANSI) and the International Standards Organization (ISO) and - in addition to that - the availability of the C library and the standard template library (STL) enormously simplified development of platform independent applications for the most common operating systems, such a project often already fails at the beginning of the toolchain - the build system or the source code project management.In our opinion this gap is filled by the open source project CMake in an excellent way. It allows developers to use their favourite development environment on each operating system, yet spares the time intensive synchronization of platform specific project files, by providing a simple, single source, textual description. With KDE4, CMake was introduced to a very popular project. In this article we propose a workflow to ease the development of cross platform projects and we show, how we used CMake to create an OpenGL application as a demonstrator for a windowed application running on Windows, Linux and Mac OS X as well as a platform independent camera interface as an example for hardware dependent cross platform applications.", "authors": ["Martin Wojtczyk", "Alois Knoll"], "n_citation": 6, "references": [], "title": "A Cross Platform Development Workflow for C/C++ Applications", "venue": "international conference on software engineering advances", "year": 2008, "id": "14765216-dbda-421a-a2b8-528ed88a2aed"}
{"abstract": "N-shift cross-orthogonal sequences and a complete complementary code derived from them are defined and discussed. A general method for generating this code is also discussed. A synchronous multiple-user spread-spectrum multiple system is proposed that uses N-shift cross-orthogonal sequences. >", "authors": ["Naoki Suehiro", "Mitsutoshi Hatori"], "n_citation": 390, "references": [], "title": "N-shift cross-orthogonal sequences", "venue": "IEEE Transactions on Information Theory", "year": 1988, "id": "070021bb-eb69-44d1-abc8-c911a9f8a2a0"}
{"abstract": "We developed a platform independent, three-tier system, called WebFlow. The visual authoring tools implemented in the front end integrated with the middle tier network of servers based on CORBA and following distributed object paradigm, facilitate seamless integration of commodity software components. We add high performance to commodity systems using GLOBUS metacomputing toolkit as the backend.", "authors": ["Tomasz Haupt", "Erol Akarsu", "Geoffrey C. Fox"], "n_citation": 50, "references": ["1d7070ff-1776-4045-ad59-a73a56bf93bf", "36c05ec1-7f89-44d4-a180-49820c36e4a0", "f8e3d7e6-d55a-4c84-b105-6da762cde15f"], "title": "WebFlow: a framework for Web based metacomputing", "venue": "ieee international conference on high performance computing data and analytics", "year": 2000, "id": "bcde413d-9747-41b2-95b2-6e3d7a1ddcea"}
{"abstract": "A consensus control framework for configuration of multiple underactuated planar rigid bodies is developed. Following the results by Bullo et al. (2000), we propose a control law that achieves asymptotic consensus between the planar rigid bodies. Finally, we present a numerical example to show efficacy of the proposed approach.", "authors": ["Maclaurin Hutagalung", "Tomohisa Hayakawa", "Takateru Urakubo"], "n_citation": 50, "references": ["1a105209-58c2-42d6-bd52-da9cab2a8b25", "482be309-740a-477b-a771-8f9dfef13c40", "4bf14681-5ef6-4a06-be84-01d5e4c125a1", "544d2bfa-c485-4dea-8cdc-dd1ad0631ce6", "59d8f17b-4019-4a3c-9cbd-7f0f25c44952", "65605a2b-9222-4862-b46c-6a6aeae75d10", "6e235d3d-0ede-4100-b421-3b363f472666", "bf97f463-643e-4a60-bf68-cd6c8f847b51"], "title": "Configuration consensus of two underactuated planar rigid bodies", "venue": "conference on decision and control", "year": 2008, "id": "fa1fb93c-078c-47bb-b5b9-4998224831b5"}
{"abstract": "In this paper, the expressive power of disjunctive rules involving default negation is analyzed within a framework based on polynomial, faithful and modular (PFM) translations. The analysis is restricted to the stable semantics of disjunctive logic programs. A particular interest is understanding what is the effect if default negation is allowed in the heads of disjunctive rules. It is established in the paper that occurrences of default negation can be removed from the heads of rules using a PFM translation when default negation is allowed in the bodies of rules. In this case, we may conclude that default negation appearing in the heads of rules does not affect expressive power of rules. However, in the case that default negation may not be used in the bodies of rules, such a PFM translation is no longer possible. Moreover, there is no PFM translation for removing default negation from the bodies of rules. Consequently, disjunctive logic programs with default negation in the bodies of rules are strictly more expressive than those without.", "authors": ["Tomi Janhunen"], "n_citation": 50, "references": ["0aafaa2b-ebb2-4260-ba7d-66d403c3546a", "184e1940-ca2c-4ff9-820a-3768468b22e3", "2f540642-7318-478e-8ff7-be5f04e8eb4b", "33bafefd-2634-4585-9cc7-b7ff2ea42c4e", "3eb8201d-cd66-4705-9675-4ce354cc01da", "3f76eb00-3cb3-4e78-9c01-f7c56ebe309f", "6717f07c-0876-4353-b0b6-1f9db9fce53c", "6d7f2581-37f1-4f5b-b637-f4b0e655f783", "7252dd8d-7908-4aab-a221-a8b39041ccaa", "77171129-9d11-4dd7-9e3b-b59c45384b57", "7d7e056e-aaee-488e-be00-54af391faaaa", "8c4da6a0-9e40-4bdb-aa12-4fd1d37cd840", "90711760-c69f-440c-9180-8353c7979fbc", "b0b7899b-a3e0-4c28-9670-9d766ee6db26", "b3c6af6a-122c-4087-b503-9213660a2fc2", "bcb2a694-1be7-498f-96b4-1b02878c9e8e", "db658327-1f48-4f80-8f7d-09d88096f297", "e22908da-10e5-49ec-93ed-2d7b1e1e8da3", "e8bb96d8-6613-45bc-b7bb-67fcd761f2c3", "eba510ad-c220-44a3-8c66-306d6cb45d2e", "eee72c4a-943a-48e8-9ddc-885ca0c8e459", "f0315c60-9807-477b-bec5-9058f58f58aa", "f5736b74-fbb0-4a33-a65d-2cba7eff1b52"], "title": "On the Effect of Default Negation on the Expressiveness of Disjunctive Rules", "venue": "international conference on logic programming", "year": 2001, "id": "f28059e7-5c1a-416c-a15c-7daada69f596"}
{"abstract": "This paper describes the use of a process simulator to support software project planning and management. The modeling approach here focuses on software reliability, but is just as applicable to other software quality factors, as well as to cost and schedule factors. The process simulator was developed as a part of a decision support system for assisting project managers in planning or tailoring the software development process, in a quality driven manner. The original simulator was developed using the system dynamics approach. As the model evolved by applying it to a real software development project, a need arose to incorporate the concepts of discrete event modeling. The system dynamics model and discrete event models each have unique characteristics that make them more applicable in specific situations. The continuous model can be used for project planning and for predicting the eAect of management and reliability engineering decisions. It can also be used as a training tool for project managers. The discrete event implementation is more detailed and therefore more applicable to project tracking and control. In this paper the structure of the system dynamics model is presented. The use of the discrete event model to construct a software reliability prediction model for", "authors": ["Ioana Rus", "James S. Collofello", "Peter B. Lakey"], "n_citation": 60, "references": ["abb008ab-69ad-470b-be48-7bf910b7c301"], "title": "Software process simulation for reliability management", "venue": "Journal of Systems and Software", "year": 1999, "id": "5646b385-78a9-437b-a0f6-8295c2cfe32b"}
{"abstract": "Purpose \u2013 The purpose of this research paper is to present a maturity model for IT outsourcing relationships.Design/methodology/approach \u2013 Based on organizational theories and outsourcing practices, this research identified cost stage, resource stage and partnership stage as maturity stages in outsourcing relationships.Findings \u2013 First, relationships focus on economic benefits, then there are concerns about access to competence, and finally the development of norms and alliance management are the main focus. Benchmark variables for each stage are suggested. Future research might apply this framework to empirically test the evolution of IT outsourcing relationships.Practical implications \u2013 Managing successful IT outsourcing relationships requires a consistent understanding of maturity stage between vendor and client in the relationship.Originality/value \u2013 This paper suggests that a long\u2010term IT outsourcing relationship will shift focus as it matures. The original value of the paper is the theory\u2010based stag...", "authors": ["Petter Gottschalk", "Hans Solli-S\u00e6ther"], "n_citation": 194, "references": ["0784aa23-9108-443e-8d4b-62d896373cba", "25e959cd-a329-4af8-8b17-426ca610b677", "27c7148f-3f7e-4edb-8627-1d2360a8b5f7", "4987a929-1a9d-462b-aba0-6b2a64337ce2", "54490a43-58b5-47db-9d0b-eb22141d33c0", "6769ca3a-6dd4-407f-bb7b-f7ec4f184a71", "88d7589c-282a-45a2-9f9c-23a86eba47db", "9020c78d-8155-4813-8d3b-f57c06a35a81", "9131f18a-ac86-4b6d-bc87-f25bacf02628", "94b927f3-b3c9-4799-aa8a-4aa0d6e8b7c8", "96593ed5-eb55-45fb-aafa-48c979f1b15b", "bc59b19d-cbb6-44f4-8d4a-b3a57fd59101", "da8d8cd3-4b7d-4f62-ab78-c583bec0eacb"], "title": "Maturity model for IT outsourcing relationships", "venue": "Industrial Management and Data Systems", "year": 2006, "id": "9bdfe9e8-504c-45f2-9aa7-eab80a7c7975"}
{"authors": ["Claude Montaci\u00e9", "Jean-Luc Le Floch"], "n_citation": 7, "title": "Discriminant AR-vector models for free-text speaker verification.", "venue": "", "year": 1993, "id": "fcbbad4c-bf5f-4aa5-8f6b-648921462246"}
{"abstract": "This paper deals with the problem of model (in)validation of discrete time, causal, linear time-invariant (LTI) stable models subject to slowly linear time-varying structured uncertainty, using frequency domain data corrupted by additive noise. It is well known that in the case of structured LTI uncertainty the problem is NP hard in the number of uncertainty blocks. The main contribution of this paper shows that, on the other hand, if one considers arbitrarily slowly time varying uncertainty and noise in L/sub 2/, then tractable, convex necessary and sufficient conditions for (in)validation can be obtained. Additional results include a discussion of the case where the noise is characterized in terms of the L/sub /spl infin// norm.", "authors": ["Maria Cecilia Mazzaro", "Mario Sznaier"], "n_citation": 9, "references": ["651b4a46-30f9-49b8-8afe-0531bef69ee8", "7598a9fb-b756-44ee-9964-eb6cfaa2f60e", "dc1033fc-ede5-462e-95dc-8b0cdba2e6df"], "title": "Convex necessary and sufficient conditions for frequency domain model (in)validation under SLTV structured uncertainty", "venue": "IEEE Transactions on Automatic Control", "year": 2004, "id": "4b0e4054-7109-46f8-8743-17ed53462cdd"}
{"abstract": "The interpretation of natural scenes, generally so obvious and effortless for humans, still remains a challenge in computer vision. To allow the search of image-based documents in digital libraries, we propose to design classifiers able to annotate images with keywords. First, we propose an image representation appropriate for scene description. Images are segmented into regions, and then indexed according to the presence of given region types. Second, we propound a classification scheme designed to separate images in the descriptor space. This is achieved by combining feature selection and kernel-method-based classification", "authors": ["Bertrand Le Saux", "Giuseppe Amato"], "n_citation": 29, "references": ["096db0e2-546a-4429-95b1-0305f35b5a15", "2190c590-c037-4170-9a93-a9d0c4468077", "4fb87930-7f6c-4f03-ae22-32445138ec83", "5f8d0be4-6a71-4af5-823a-ece72abda47f", "6692d3e1-f6a0-48c0-8733-7b1f72587fd0", "7374c352-8269-4746-bdd7-db09226f17e6", "9d3ae229-67eb-4b0b-abce-8b9bb1d909f7", "a5b5afa4-f9b3-44ab-a93a-6693d0ee09df", "b7e4ddc6-b5ce-4457-a531-0eb6ea818ce8", "cb5e3b2d-a97e-461f-b99e-d4593d0ef2d7", "d38e7662-4ba5-4b3d-92ea-c5dc098f5077", "ee8ff75d-caec-42e9-aa07-cbe4fdd7541b", "f4203f5f-3182-4894-b3b9-cc12cc158960"], "title": "Image recognition for digital libraries", "venue": "multimedia information retrieval", "year": 2004, "id": "fff8b600-1d5f-4cc9-8fe7-1ff712be74ed"}
{"abstract": "We present a robust and inherently parallel strategy for tracking \"corner\" features on independently moving (and possibly non-rigid) objects. The system operates over long, monocular image sequences and comprises two main parts. A matcher performs two-frame correspondence based on spatial proximity and similarity in local image structure, while a (racier maintains an image trajectory (and predictor) for every feature. The use of low-level features ensures an opportunistic and widely applicable algorithm. Moreover, the system copes with noisy data, predictor failure, and occlusion and disocclusion of scene structure. Motion and scene analysis modules can then be built onto this framework. The algorithm is aimed at applications with small inter-frame motion, such as videoconferen cing.", "authors": ["Larry S. Shapiro", "Han Wang", "J. Michael Brady"], "n_citation": 92, "references": ["630a1be4-eafc-4280-aacc-e241691c29d2", "644bec95-ebd2-4f36-91a3-83ff08b24c9f", "d98d389d-ca5f-43f4-b9bc-7dbea42e718e"], "title": "A Matching and Tracking Strategy for Independently Moving Objects", "venue": "british machine vision conference", "year": 1992, "id": "9d7703bf-1b97-4699-ac0a-5faa74279643"}
{"abstract": "The combination of visual and inertial sensors has proved to be very popular in robot navigation and, in particular, Micro Aerial Vehicle (MAV) navigation due the flexibility in weight, power consumption and low cost it offers. At the same time, coping with the big latency between inertial and visual measurements and processing images in real-time impose great research challenges. Most modern MAV navigation systems avoid to explicitly tackle this by employing a ground station for off-board processing. In this paper, we propose a navigation algorithm for MAVs equipped with a single camera and an Inertial Measurement Unit (IMU) which is able to run onboard and in real-time. The main focus here is on the proposed speed-estimation module which converts the camera into a metric body-speed sensor using IMU data within an EKF framework. We show how this module can be used for full self-calibration of the sensor suite in real-time. The module is then used both during initialization and as a fall-back solution at tracking failures of a keyframe-based VSLAM module. The latter is based on an existing high-performance algorithm, extended such that it achieves scalable 6DoF pose estimation at constant complexity. Fast onboard speed control is ensured by sole reliance on the optical flow of at least two features in two consecutive camera frames and the corresponding IMU readings. Our nonlinear observability analysis and our real experiments demonstrate that this approach can be used to control a MAV in speed, while we also show results of operation at 40Hz on an onboard Atom computer 1.6 GHz.", "authors": ["Stephan Weiss", "Markus W. Achtelik", "Simon Lynen", "Margarita Chli", "Roland Siegwart"], "n_citation": 241, "references": ["0aeb56c5-8aea-46dc-af26-ceb4b9f2eb8d", "292f7c64-4a80-48a1-8dcb-c3bafc590a50", "387760b4-414f-4ce1-9631-470f45e284a2", "646df0a8-47c1-4cef-a80a-b38c27f39cc3", "8cb49c2a-4cfa-4b62-ad98-a3605791819e", "974d76ec-d187-4ae3-ac75-a99d423369b2", "9a5c29bd-5553-46e0-823d-413a84b6211e", "ad5ca2dc-3498-4d59-8d3c-2b7aa853f523", "b2c414be-7585-4e71-92b0-4ed0ecc541f0", "b9e45d9b-b453-41fc-9446-2a251f1090c4", "be7ebcb3-afa3-4631-a261-da8ba15b6706", "d63a9228-df9f-42f9-9158-6a3dfb21a756"], "title": "Real-time onboard visual-inertial state estimation and self-calibration of MAVs in unknown environments", "venue": "international conference on robotics and automation", "year": 2012, "id": "a72d0bd7-2024-4406-82ae-9e22c69b8ada"}
{"abstract": "Software security has been recognized to be an important trait for future software development, yet the adoption of a secure software development lifecycle has yet to be fully integrated into current software development models. This is due to immaturities in secure software development lifecycle models and the lengthy development time imposed by security. To further exacerbate the current rampant growth of software vulnerabilities, the future direction for software is moving rapidly into the web space. With the expansive use of Web Services a new attack space is opened. As mobile code increases so will the number of software bugs and vulnerabilities; hence the need for adopting a secure software development model. The need to build a knowledge base of common coding errors is important in exposing current vulnerabilities and preventing future vulnerabilities. In this paper, a study of the current growth of software vulnerabilities, the importance of a categorization tool, the SQUARE model, the evolution of the SQUARE model combined with the Risk Management Framework to produce the SQUARE+R model, and the adaptability of the SQUARE+R model to an agile development lifecycle are presented.", "authors": ["Weider D. Yu", "Kyle Le"], "n_citation": 50, "references": ["63d50719-d1aa-4baf-8ad7-b123bb39f398"], "title": "Towards a Secure Software Development Lifecycle with SQUARE+R", "venue": "computer software and applications conference", "year": 2012, "id": "61187ba8-ef4c-44da-97b6-a40852d1c7c3"}
{"abstract": "The Bayesian framework is ideally suited for induction problems. The probability of observing $x_t$ at time $t$, given past observations $x_1...x_{t-1}$ can be computed with Bayes'' rule if the true distribution $\\mu$ of the sequences $x_1x_2x_3...$ is known. The problem, however, is that in many cases one does not even have a reasonable estimate of the true distribution. In order to overcome this problem a universal distribution $\\xi$ is defined as a weighted sum of distributions $\\mu_i\\!\\in\\!M$, where $M$ is any countable set of distributions including $\\mu$. This is a generalization of Solomonoff induction, in which $M$ is the set of all enumerable semi-measures. Systems which predict $y_t$, given $x_1...x_{t-1}$ and which receive loss $l_{x_t y_t}$ if $x_t$ is the true next symbol of the sequence are considered. It is proven that using the universal $\\xi$ as a prior is nearly as good as using the unknown true distribution $\\mu$. Furthermore, games of chance, defined as a sequence of bets, observations, and rewards are studied. The time needed to reach the winning zone is bounded in terms of the relative entropy of $\\mu$ and $\\xi$. Extensions to arbitrary alphabets, partial and delayed prediction, and more active systems are discussed.", "authors": ["Marcus Hutter"], "n_citation": 20, "references": ["1f61a4c8-87fa-45d9-bd6b-14c5b815f1bc", "1feb9e81-b396-4132-8658-3b03bb361aee", "1ffbdbf7-d766-4ebf-a0da-8da75626b4bc", "3ce043ef-4606-444a-83c0-99e9e6b8854f", "5899bc5a-c760-4412-bef5-dee5b1ee4dde", "69f00f82-45eb-4e2b-b239-5526d80f11ea", "adaeb4f1-7d0e-4bc8-93b8-8fecaa91c618", "b0cc5040-4d3d-4981-9248-6aceee4a827c", "b3ffe2d9-f311-4590-86f2-e981893a9acd", "bd20c3c8-f7cc-403d-bf4c-bc5181604608"], "title": "General Loss Bounds for Universal Sequence Prediction", "venue": "international conference on machine learning", "year": 2001, "id": "6dfdb227-7889-4c9f-9720-298fe2a980e6"}
{"authors": ["Oded Goldreich", "Hugo Krawczyk"], "n_citation": 128, "references": ["02ac14f0-f4a7-44d8-ac6c-c5317d32e4e7", "0dd040aa-d2e6-447d-ad59-c2a19b828c99", "11676a2d-74b0-4d81-975e-2c0d6044ba46", "1e4da96e-9a39-4cf4-9bb8-c2e85b1ee527", "29a88cc8-b0ac-41a3-9a72-699050c9aad6", "2ae955b7-1d0a-4cc3-afa3-fe293e1d2e85", "2d0e186b-030c-4613-b4df-f7f7d511acd5", "6ba6acec-3ccc-4287-8c9f-390cc6433e6d", "7225aced-64d3-4dc6-b491-7eb2739b8828", "8506cb9b-c48e-4f22-ac40-dc0cd45ac8ad", "8d25e57a-8d0a-4ed4-b2f5-5af84e732ae5", "ba5ec268-89bc-4e36-b4e1-d6694c24045e"], "title": "On the Composition of Zero-Knowledge Proof Systems", "venue": "international colloquium on automata languages and programming", "year": 1990, "id": "5c1749b1-ef61-4596-a468-ea62d6541ddb"}
{"abstract": "In industrial practice, test cases often start out as steps described in natural language and are intended to be executed by a human. Since tests are executed repeatedly, they go through an automation process, in which they are converted to automated test scripts (or programs) that perform the test steps mechanically. Conventional test-automation techniques can be time-consuming, require specialized skills, and can produce fragile scripts. To address these limitations, we present a tool, called ata, for automating the test-automation task. Using a novel combination of natural-language processing, backtracking exploration, and learning, ata can significantly improve tester productivity in automating manual tests. ata also produces  change-resilient  scripts, which automatically adapt themselves in the presence of certain common types of user-interface changes.", "authors": ["Suresh Thummalapenta", "Nimit Singhania", "Pranavadatta Devaki", "Saurabh Sinha", "Satish Chandra", "Achin K. Das", "Srinivas Mangipudi"], "n_citation": 50, "references": ["66961884-7559-4a42-97dc-fd5f88a7186f", "938ec820-1a7b-42a4-adf7-e30d3829b843"], "title": "Efficiently scripting change-resilient tests", "venue": "foundations of software engineering", "year": 2012, "id": "e1226efd-6889-48fd-89ab-0b8ae8a4e55d"}
{"abstract": "This paper presents the stability and criticality analysis of integer linear programs with respect to perturbations in stochastic data given as Markov chains. These perturbations affect the initial distribution, the transition matrix, or the stationary distribution of Markov chains. Stability analysis is concerned with obtaining the set of all perturbations for which a solution remains optimal. This paper gives expressions for stability regions for perturbations in the initial distribution, the transition matrix, the stationary distribution, and the product of elements of the transition matrix and the stationary distribution. Furthermore, criticality measures that describe the sensitivity of the objective function with respect to an element of the problem data are derived. Stability regions that preserve the stochasticity of the problem data are given. Finally, stability regions for perturbations of elements of the transition matrix, given that the problem is not linear in the initial distribution or the transition matrix, are obtained using a small perturbation analysis. The results are applied to sensor placement problems and numerical examples are given.", "authors": ["Jonathan C. Las Fargeas", "Moritz Niendorf", "Pierre T. Kabamba", "Anouck R. Girard"], "n_citation": 3, "references": ["2da3dae7-c541-4a4f-a7ff-0e47f106b3e5", "561090e0-ae5f-4e09-925f-a2d6ea3aa874", "61db8a97-0982-4592-bb61-7c08ca7b9dd1", "b9e1613a-9cee-4711-bde5-69a0d6e17ed0", "d0b77ce8-bbd4-4598-9ca9-c277f6db3352"], "title": "Stability and Criticality Analysis for Integer Linear Programs With Markovian Problem Data", "venue": "IEEE Transactions on Automatic Control", "year": 2016, "id": "64102901-5a42-4228-9127-5a8b3021299b"}
{"abstract": "The Virtual Interface Architecture (VIA) is an industry standard user-level communication architecture for system area networks. The VIA provides a protected, directly-accessible interface to a network hardware, removing the operating system from the critical communication path. In this paper, we design and implement a user-level Sockets layer over VIA, named SOVIA (Sockets Over VIA). Our objective is to use the SOVIA layer to accelerate the existing Sockets-based applications with a reasonable effort and to provide a portable and high performance communication library based on VIA to the application developers.SOVIA realizes comparable performance to native VIA, showing the minimum latency of 10.5usec and the peak bandwidth of 814Mbps on Giganet's cLAN. We have verified the functional compatibility with the existing Sockets API by porting FTP (File Transfer Protocol) and RPC (Remote Procedure Call) applications over the SOVIA layer. Compared to the Giganet's LANE driver which emulates TCP/IP inside the kernel, SOVIA easily doubles the file transfer bandwidth in FTP and reduces the latency of calling an empty remote procedure by 77% in RPC applications.", "authors": ["Jin-Soo Kim", "Kang-Ho Kim", "Sung-In Jung"], "n_citation": 52, "references": ["08606bae-eb29-4180-875f-03406bc0d7f2", "288de127-a193-4a41-9764-71c115ddfea0", "3fde9cbc-651b-4d22-9262-782c3f2bc4a6", "51d3a55b-133f-4d99-a493-59efa892598f", "a61efbb8-9d89-4d05-a407-36dd203206b0", "c39eace1-d09f-4415-8e51-e2bdf9824d67"], "title": "SOVIA: a user-level sockets layer over virtual interface architecture", "venue": "foundations of computer science", "year": 2001, "id": "434b3cd5-f668-48c5-9994-961eac0c2ec4"}
{"abstract": "We propose a new method to construct discrete Voronoi diagrams, which we call the direct diffusion method. Once we implement it as software, we can easily modify it for various types of digital Voronoi diagrams by changing only the the distance function from a point to a generator represented by a general shape. Our method can construct discrete Voronoi diagrams even if the generator points are not at the centers of pixels. Furthermore, our method can construct the Voronoi diagrams without approximating general shapes by sets of pixels.", "authors": ["Tetsushi Nishida", "Shingo Ono", "Kokichi Sugihara"], "n_citation": 4, "references": ["03a2186f-8f49-46b0-80db-9a3560a14edd", "3a52b1ff-ea96-4c5f-b4f4-a7ae9651096b", "48e2f7da-0687-4722-a420-438c828db5eb", "4c968194-70a3-45a9-8188-b8637a258582", "589f3b8a-d768-4817-885a-2f1043f61966", "5906e72e-6c7d-4c7f-a620-ced073624d29", "5fbc736c-5b79-4773-92b5-9b9b1dc3d402", "90df3f6e-f2c6-41f9-be2f-f4f3721b8651", "93fc8723-799e-4884-be5a-083d93040314", "a67ad67e-9c96-4bfa-93d0-d044e6b0940b", "b150402e-fce0-4206-86bd-789590a7bc05", "be5605bd-73ae-4293-8ef6-9fd6d06be3ec", "c8609949-028b-4824-a9ca-95ff108eb18f", "cebc84ef-686b-43dd-ae70-90208e78cb83"], "title": "Direct Diffusion Method for the Construction of Generalized Voronoi Diagrams", "venue": "", "year": 2007, "id": "070de078-474e-47e0-868a-e2f605bb6341"}
{"abstract": "Mathematical models of the human respiratory control system have been developed since 1940 to study a wide range of features of this complex system. The phenomena collectively referred to as periodic breathing (including Cheyne-Stokes respiration and apneustic breathing) have important medical implications. The hypothesis that periodic breathing is the result of delay in the feedback signals to the respiratory control system has been studied since the work of F.S. Grodins, J. Gray, A.I. Norins, R.W. Jones [J. Appl. Physiol. 1 (1954) 283-308] in the early 1950s. The purpose of this paper is to extend the model presented by M.C.K. Khoo, R.E. Kronauer, K.P. Strohl, A.S. Slutsky [J. Appl. Physiol. 53 (3) (1982) 644-659] in 1991 to include variable delay in the feedback control loop and to study the phenomena of periodic breathing and apnea as they occur during quiet sleep in infant sleep respiration at around 4 months of age. The nonlinear mathematical model consists of a feedback control system of five delay differential equations. Numerical simulations are performed to study instabilities in the control system and the occurrence of periodic breathing and apnea in the above case which is a time frame of high incidence of sudden infant death syndrome (SIDS).", "authors": ["Jerry J. Batzel", "Hien T. Tran"], "n_citation": 50, "references": [], "title": "Modeling instability in the control system for human respiration: applications to infant non-REM sleep", "venue": "Applied Mathematics and Computation", "year": 2000, "id": "148a97cb-416b-4a2a-a493-6a9214fde73a"}
{"abstract": "Applying the noisy channel model to search query spelling correction requires an error model and a language model. Typically, the error model relies on a weighted string edit distance measure. The weights can be learned from pairs of misspelled words and their corrections. This paper investigates using the Expectation Maximization algorithm to learn edit distance weights directly from search query logs, without relying on a corpus of paired words.", "authors": ["Farooq Ahmad", "Grzegorz Kondrak"], "n_citation": 110, "references": ["0cb06ffe-08d6-4163-b5c7-ca2953b8b3b6", "10b46196-2b40-45f6-8c27-89ac24eec0ac", "16e0a963-757b-4450-a056-a46170bdb7d0", "9f9034e7-bb14-4c9e-ba49-ec6205d4b998", "a2530144-b6fd-4659-84f5-73a470275dd4", "b6f96238-c356-49c9-9638-53e39931954c", "c8323642-f362-4ef3-bcc6-7ed07536c658", "fc6e584e-351a-4148-84f8-5845077c1e41"], "title": "Learning a Spelling Error Model from Search Query Logs", "venue": "empirical methods in natural language processing", "year": 2005, "id": "d713277b-9518-4cf9-8ca0-0acbb55e13f0"}
{"authors": ["Vijay A. Saraswat", "Kenneth M. Kahn", "Jacob Levy"], "n_citation": 163, "title": "Janus: a step towards distributed constraint programming", "venue": "", "year": 1990, "id": "ccf4b2a6-8f20-4dcc-a278-339f1ab8728f"}
{"abstract": "Sophisticated modeling and analysis methods are being developed in academic and industrial research labs for reliability engineering and other domains. The evaluation and evolution of such methods based on use in practice is critical to research progress, but few such methods see widespread use. A critical impediment to disseminating new methods is the inability to produce, at a reasonable cost, supporting software tools that have the: usability and dependability characteristics that industrial users require; and evolvability to accommodate software change as the underlying analysis methods are refined and enhanced. The difficulty of software development thus emerges as a key impediment to advances in engineering modeling and analysis. This paper presents an approach to tool development that attacks these problems. Progress requires synergistic, interdisciplinary collaborations between application-domain and software-engineering researchers. The authors have pursued such an approach in developing Galileo: a fault tree modeling and analysis tool. These innovations are described in two dimensions: (1) the Galileo core reliability modeling and analysis function; and (2) the authors' work on software engineering for high-quality, low-cost modeling and analysis tools.", "authors": ["Joanne Bechta Dugan", "Kevin J. Sullivan", "David Coppit"], "n_citation": 211, "references": ["0250c362-b7e1-4638-832b-4c630c1013e6", "03c8985a-a428-4921-bdb0-66b2bdd342cf", "13678b40-189f-425f-9abb-78907158d090", "235c979a-8bf1-4868-903c-9fc7e1b1b9f2", "288a13d8-e16d-48e4-84f4-f9dad779ee58", "502076a0-ff08-41a8-b118-a8dadd357d4a", "61766eda-d318-44ea-80e3-6185a50b5e6d", "802fa0be-9de7-47af-a724-5d19983ccc6a", "931d1b54-396e-4072-b4d6-1b9394c120a9", "b3114180-6a9a-4d6b-ab44-40becb831453", "b86bdadc-b4b0-4eae-96b8-b9f9b392026a"], "title": "Developing a low-cost high-quality software tool for dynamic fault-tree analysis", "venue": "IEEE Transactions on Reliability", "year": 2000, "id": "c4b966ab-471f-4e50-8785-a340e6769b18"}
{"abstract": "A t the system level, reusable Intellectual Property (or IP) blo cks can be represented abstractly as blocks that exchange messages. The concrete implementations of these IP blocks m ust exc hange the messages through complex signaling protocols. Interfacing bet ween IP that use different signaling protocols is a tedious and error prone design task. We propose using regular expression based protocol descriptions to sho w ho w to map the message on to a signaling protocol. Given t w o protocols,an algorithm is proposed to build an interface machine. We ha ve implemented our algorithm in a program named PIG that synthesizes a Verilog implementation based on a regular expression protocol description.", "authors": ["Roberto Passerone", "James A. Rowson", "Alberto L. Sangiovanni-Vincentelli"], "n_citation": 205, "references": ["2ff3ca18-2bdb-4b82-9a01-2f617c70deb5", "a30ba077-4035-4dea-a367-9f955aefcccf", "c25b8588-278b-4040-a0b5-31bf74e10ba6", "cb083b29-7db2-4c9c-8a25-a68ac524377e", "d94cb179-5f38-49cc-bfbd-86fd0fa1ccdf", "e691cf03-475e-4560-9a7d-0b8c9b43a003"], "title": "Automatic synthesis of interfaces between incompatible protocols", "venue": "design automation conference", "year": 1998, "id": "f822a002-cd8c-4a2f-8aa2-8050588313af"}
{"abstract": "Many modern software-intensive systems consist of multiple components interacting together to deliver the intended functionality. Often, these systems come in many variants (products) and are managed together as a software product line. This variability is the source of additional complexity which can cause inconsistencies and offset the economies of scale promised by product line engineering. Engineers thus need intuitive, yet precise means for specifying requirements and require tools for automatically detecting inconsistencies within these requirements. In recent work, we proposed a technique for the scenario-based specification of interactions in product lines by a combination of Modal Sequence Diagrams and Feature Diagrams. Furthermore, we elaborated an efficient consistency-checking technique based on a dedicated model-checking approach especially tailored for product lines. In this paper, we report on further evaluations that underline significant performance benefits of our approach. We describe further optimizations and detail on how we encode the consistency-checking problem for a model-checker.", "authors": ["Joel Greenyer", "Amir Molzam Sharifloo", "Maxime Cordy", "Patrick Heymans"], "n_citation": 50, "references": ["1303bc5a-3601-454e-b820-a159ed671fc4", "15a2d332-783d-4a0e-900c-faadda3c080c", "2bb33756-67db-4329-8c0d-f3c5fdab2367", "4d039b9e-f25f-4ec5-a59e-9f03b8bb5ca3", "5d3752d1-085a-48c7-bdef-9d28e344ce44", "5d58db83-a1f9-4a94-a617-e14d0bb142db", "62fb3e25-0569-4641-a40d-59d2ff00f278", "64fec467-4e81-4bf1-801d-1cd9a7b07744", "70aa76a0-2ba6-4abb-b6b4-923da9c4de9b", "737de1cf-5cf6-4496-87da-3523f4228eba", "74ccccb3-7baf-4bd6-9f8b-b8f17fdd9737", "759281b8-c868-4dc2-85db-648df7bcb015", "76204637-8e4d-49ed-941e-e1c22f9839f6", "77f131fe-0ff0-4ce3-8706-f81f4400362b", "83cb0010-b854-4ca5-85c6-5e8619a1d4c9", "86ea10a5-32e1-4e03-aff9-7be0e802044c", "8874d522-fedc-40f8-8acd-e418cbeaccbe", "8915cffe-4ff0-45b2-9d7e-476b39fd57b3", "8cf8e6c9-124c-4864-bbbf-b879134220b3", "9dd11221-5bc9-400b-9227-b295d036e2de", "cc2dece9-5e35-495c-b5c4-7581d006ba02", "cf2cbc7e-e426-405a-b32c-a6fc19d8c506", "d9564fac-7d77-4627-9e10-f46c69711cf0", "db04d3a5-522c-4071-a1fc-003e766bd349", "e3328d62-6741-463d-bb06-892b1ef5f5a2", "f08cbffa-9467-4c74-a284-7db15837ac53"], "title": "Features meet scenarios: modeling and consistency-checking scenario-based product line specifications", "venue": "Requirements Engineering", "year": 2013, "id": "464431a5-4a5b-449e-bfc3-d10de944c305"}
{"abstract": "Multimedia technologies are being adopted both in the professional and commercial world with great enthusiasm. This has led to a significant interest in the research and development of multimedia databases. However, none of these efforts have really addressed the issues related to the benchmarking of multimedia databases. We analyze the problem of benchmarking multimedia databases in this paper and suggest a methodology.", "authors": ["A. Desai Narasimhalu", "Mohan S. Kankanhalli", "Jiankang Wu"], "n_citation": 75, "references": ["077e70f1-ccc3-4c13-9752-3b0a182e0890", "0f1eaa0c-eee7-4acc-af94-73d15916c178", "275fcea5-696d-484d-9e1e-208cfb31587b", "59131c16-c0b5-46c9-b92d-704cf4bf3916", "a653a618-bbb4-434a-9e42-7f8842a19608", "abb162c8-4fae-43e7-afd7-316bbf4f1a1b", "d6de153c-61a5-4c50-8730-0311ac9a21b6", "e75d8e62-a86d-4241-953f-1b315005d920"], "title": "Benchmarking Multimedia Databases", "venue": "Multimedia Tools and Applications", "year": 1997, "id": "e5adc7b5-fab7-412b-a348-eee57a6a8b2f"}
{"abstract": "Dynamic software visualization is supposed to provide programmers with insights as to what the program is doing. Most current dynamic visualizations either use program traces to show information about prior runs, slow the program down substantially, show only minimal information, or force the programmer to indicate when to turn visualizations on or off. We have developed a dynamic Java visualizer that provides a view of a program in action with low enough overhead so that it can be used almost all the time by programmers to understand what their program is doing while it is doing it.", "authors": ["Steven P. Reiss"], "n_citation": 118, "references": ["17609242-36b5-4947-b566-d7cd53a289ca", "263d107c-00f1-453e-9ca1-22f323275619", "497f18fb-a7f0-407d-a993-216e5197ef2f", "75d3b3be-be6b-4ae6-bfd0-d4ecfedca688", "9bef24c7-d97a-49f3-83ac-a99d3d85a6d6", "c990280f-1cf1-4909-8b89-53f15f796fdb"], "title": "Visualizing Java in action", "venue": "software visualization", "year": 2003, "id": "6cf2ad1d-fe7e-4a54-9d9a-6299e6c6f8ed"}
{"abstract": "With the emergence of high data rate sensor network applications, there is an increasing demand for high-performance query services. To meet this challenge, we propose Dynamic Conflict-free Query Scheduling (DCQS), a novel scheduling technique for queries in wireless sensor networks. In contrast to earlier TDMA protocols designed for general-purpose workloads, DCQS is specifically designed for query services in wireless sensor networks. DCQS has several unique features. First, it optimizes the query performance through conflict-free transmission scheduling based on the temporal properties of queries in wireless sensor networks. Second, it can adapt to workload changes without explicitly reconstructing the transmission schedule. Furthermore, DCQS also provides predictable performance in terms of the maximum achievable query rate. We provide an analytical capacity bound for DCQS that enables DCQS to handle overload through rate control. NS2 simulations demonstrate that DCQS significantly outperforms a representative TDMA protocol (DRAND) and 802.11b in terms of query latency and throughput.", "authors": ["Octav Chipara", "Chenyang Lu", "John A. Stankovic", "Gruia-Catalin Roman"], "n_citation": 50, "references": ["0146c1ae-b646-4636-987b-fb0f8e551922", "0e2d22ec-23fc-4421-ab11-1d047b479172", "1baf90c8-5c75-4e5d-99f1-378571ef5a71", "277cd65c-dcb3-4347-835b-e058f2e057f1", "2d6b3f9d-5cfe-42ee-8e8a-52020a02e994", "47aafb1f-c687-42ff-a394-cd74d2d1eb16", "4b016372-5d59-4505-b8f6-353242ffcf53", "50bb8fed-57b5-4acf-85ba-3249e91ac0f6", "6156fa5c-f0d9-4b9b-a12f-34190c6c7f2d", "67e7428d-6d8f-4d70-9a5a-b5bdd0bfb637", "6bfdf9a3-6cd9-43d8-9785-0073dbe96f1b", "6cc24ddc-0411-4877-af07-80d4aa8ed33e", "817fc5f3-966b-4bef-964e-acceb486921b", "8725366c-0176-43d7-acb3-fe8d913eff1d", "8acc4d51-0e0c-4cff-8bdd-5a73df2d49b5", "8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae", "9191c67f-94a4-4977-99ad-954cda004a70", "924d1587-8549-4333-ba69-bd4cf48fca7e", "9535aeab-0d75-4fd5-9522-82012e335999", "b5b1c8b3-5ae9-43cd-a2d7-38bd99c6fd80", "c5560c22-c1e4-4ab7-9263-0d12c0a5e58a", "ce5e8cbe-48f8-4e62-b4ce-30a4b9f1e26c", "d670a693-527b-4452-9d27-e409a536cf4a", "ec066c28-2065-4196-8fdf-d8fd31c0b7bf", "efa04de8-fec3-4c73-8031-5b7990b88e57", "fe27b361-b1ce-4ae4-bb38-8a260ebb6d8d"], "title": "Dynamic Conflict-Free Transmission Scheduling for Sensor Network Queries", "venue": "IEEE Transactions on Mobile Computing", "year": 2011, "id": "7a1bdc34-7987-4a8c-a45d-d13c164081aa"}
{"abstract": "There have been various algorithms designed for simulating natural evolution. This paper proposes a new simulated evolutionary computation model called the abstract evolutionary algorithm (AEA), which unifies most of the currently known evolutionary algorithms and describes the evolution as an abstract stochastic process composed of two fundamental operators: selection and evolution operators. By axiomatically characterizing the properties of the fundamental selection and evolution operators, several general convergence theorems and convergence rate estimations for the AEA are established. The established theorems are applied to a series of known evolutionary algorithms, directly fielding new convergence conditions and convergence rate estimations of various specific genetic algorithms and evolutionary strategies. The present work provides a significant step toward the establishment of a unified theory of simulated evolutionary computation.", "authors": ["Kwong-Sak Leung", "Qihong Duan", "Zongben Xu", "C.K. Wong"], "n_citation": 49, "references": ["0778fc6a-d737-4cd3-b60c-5185b4d0166f", "1109cd7f-0443-4342-82a9-409fa349e012", "1af22edc-af0b-4539-9720-33b76466a068", "2021fce8-ed7e-4124-bb9f-43d2f9c74738", "20e996ee-3877-42ce-adcc-0479d955b8cd", "38126abb-8a4f-4a03-bc36-f7a9311f3660", "421b4cf0-0e39-4cd0-9eaf-4d6687d574aa", "7a3de77f-de00-4fdc-bdbb-48ccfe4789d2", "7d376e3a-d8fe-4739-b94f-548cb59b7d6d", "84a080ee-9904-48d0-a6b9-79d4d492fb77", "9ab28841-6751-445c-93df-7180332c6906", "9ad73da8-1ce4-4ab5-b68b-bb827c65e737", "9b80e173-2d0d-4e2d-8cd0-0fcfe230fd81", "eb5b4cac-5591-4ef4-a444-1fcf44b9dc10", "ef6454e7-6c5e-4577-980d-aff61f6cf1b5", "f7e81571-c7f0-4cda-be5f-db4b904c7a6c"], "title": "A new model of simulated evolutionary computation-convergence analysis and specifications", "venue": "IEEE Transactions on Evolutionary Computation", "year": 2001, "id": "ea8316e7-5b20-40d7-b25b-2c9b23cefec0"}
{"abstract": "Information Systems Engineering (ISE) is an interdisciplinary approach to enable the realisation of successful information systems in a broad sense. ISE comprises a number of areas of expertise that must be integrated and managed in order to build information systems. Since ISE is becoming progressively more complex there is an increasing need to codify and manage knowledge within and about the ISE process. From a knowledge perspective the different model types created in an ISE project are examples of codified knowledge about the future system. The descriptions of how work should proceed are examples of codified knowledge of the process of creating the system. In summary, one of the main concerns in the ISE process is to manage the substantial amount of knowledge associated with the process as such as well as with the target domain of the actual development project and the developed software. In the thesis I recognise three areas of knowledge in ISE: development process knowledge, target domain knowledge, and software knowledge. Furthermore, I use a set of knowledge perspectives in order to describe and analyse ISE from a knowledge perspective. Finally, I introduce three aspects: organisation, artefact, and individual in order to be able to discuss and analyse how methods are actually used in organisations and how they affect the work situation. The results are presented in the form of a framework for knowledge transfer in ISE that comprises the knowledge perspective, the knowledge area, and the aspect of knowledge transfer. The framework is thus used to analyse the results from the six papers enclosed in the thesis. The results also comprise an empirical characterisation of a method in use which is based on data collected during an ethnographical study. Finally the results are made concrete in the form of a pattern collection for method introduction and method use.", "authors": ["Per Backlund", "Christina Hallenborg", "Guomundur Hallgrimsson"], "n_citation": 6, "references": ["211e3d6d-8a0a-45d3-a112-c3e3b3dd00fc", "5fa40100-8053-4fe9-95b4-25b4e2fcad65"], "title": "Transfer of Development Process Knowledge through Method Adaptation and Implementation", "venue": "european conference on information systems", "year": 2003, "id": "eed715f8-2334-44f0-98f2-a1eaad03c9a7"}
{"authors": ["Anindya Datta", "Kaushik Dutta", "Krithi Ramamritham", "Helen M. Thomas", "Debra E. VanderMeer"], "n_citation": 21, "title": "Dynamic content acceleration: a caching solution to enable scalable dynamic Web page generation", "venue": "international conference on management of data", "year": 2001, "id": "888a2156-44aa-43b6-bdb6-d8cbaa48954c"}
{"abstract": "The implementation of usable security is particularly challenging in the growing field of Grid computing, where control is decentralised, systems are heterogeneous, and authorization applies across administrative domains. PERMIS, based on the Role-Based Access Control (RBAC) model, provides a unified infrastructure to address these challenges. Previous research has found that resource owners who do not understand the PERMIS RBAC model have difficulty expressing access control policies. We have addressed this issue by investigating the use of a controlled natural language parser for expressing these policies. In this paper, we describe our experiences in the design, implementation, and evaluation of this parser for the PERMIS Editor. We began by understanding Grid access control needs as expressed by resource owners, through interviews and focus groups with 45 Grid practitioners. We found that the many areas of Grid computing use present varied security requirements; this suggests a minimal, open design. We designed and implemented a controlled natural language system to support these needs, which we evaluated with a cross-section of 17 target users. We found that participants were not daunted by the text editor, and understood the syntax easily. However, some strict requirements of the controlled language were problematic. Using controlled natural language helps overcome some conceptual mis-matches between PERMIS RBAC and older paradigms; however, there are still subtleties which are not always understood. In conclusion, the parser is not sufficient on its own, and should be seen in the interplay with other parts of the PERMIS Editor, so that, iteratively, users are helped to understand the underlying PERMIS model and to express their security policies more accurately and more completely.", "authors": ["Philip Inglesant", "M. Angela Sasse", "David W. Chadwick", "Lei Lei Shi"], "n_citation": 50, "references": ["00f9e7df-444c-4c97-a13a-49ac6c337511", "063b6735-1851-4861-a4d5-3a1c8f67f1db", "2567df1e-8d51-4ce5-8ba3-4760660d6301", "299b8837-a54b-4a35-9d39-4c289516f86f", "4c9e0d23-a432-420e-9309-28f76d3e1887", "567d665e-5ed1-42a2-a9bd-09c507bfb7d9", "712006f0-d462-46a4-b349-0ed324afdec7", "8eda006e-ff70-4fbe-a404-86bb3613906e", "b9cfb00a-19bc-48ee-92ac-11e88a239150", "b9d6e782-9986-4c73-ae66-a8d339ed732c", "d83e016f-76d2-437e-8572-581248ef9b13", "d95ad1c7-4541-4b1c-84e0-85f535a596d2", "dc3f2f6c-7a41-4cd3-8996-a9e918f49d96", "e9a67236-e09b-4f1a-8aa6-dec86704a4fe", "ecc7bfa2-c316-4b0b-b6a6-ca7aae40e490", "ecfb2022-e18c-4e5e-8733-d8bc6f4c8fc9", "f923d0af-7301-4c17-ae5f-7f6a64e9aee6"], "title": "Expressions of expertness: the virtuous circle of natural language for access control policy specification", "venue": "symposium on usable privacy and security", "year": 2008, "id": "0ae58521-f952-43fd-9f0b-d885685b6b63"}
{"abstract": "We investigate the existence and efficient algorithmic construction of close to optimal independent sets in random models of intersection graphs. In particular, (a) we propose a new model for random intersection graphs (G\"n\",\"m\",\"p\"->) which includes the model of [M. Karonski, E.R. Scheinerman, K.B. Singer-Cohen, On random intersection graphs: The subgraph problem, Combinatorics, Probability and Computing journal 8 (1999), 131-159] (the ''uniform'' random intersection graph models) as an important special case. We also define an interesting variation of the model of random intersection graphs, similar in spirit to random regular graphs. (b) For this model we derive exact formulae for the mean and variance of the number of independent sets of size k (for any k) in the graph. (c) We then propose and analyse three algorithms for the efficient construction of large independent sets in this model. The first two are variations of the greedy technique while the third is a totally new algorithm. Our algorithms are analysed for the special case of uniform random intersection graphs. Our analyses show that these algorithms succeed in finding close to optimal independent sets for an interesting range of graph parameters.", "authors": ["Sotiris E. Nikoletseas", "Christoforos Raptopoulos", "Paul G. Spirakis"], "n_citation": 27, "references": ["6cceddf5-a9da-4383-879b-6d260f4faae7", "801e8a45-e3f1-4a83-aebc-881138683e78", "ad2f3923-b172-421b-897a-3ff4c83a3834", "c7dc4aee-e842-4026-91a5-24c24e7665b8", "ce25326b-374a-4ca2-98ec-9fba00906462", "dfc3b66e-790a-4a61-8ac3-80bd32e2cf2c", "dfe038d6-76ee-4389-ac5d-f08f40dcc239"], "title": "Large independent sets in general random intersection graphs", "venue": "Theoretical Computer Science", "year": 2008, "id": "80b6aafb-5f21-43fc-a5bd-90cf075681bc"}
{"abstract": "Student involvement in Humanitarian Free and Open Source Software (HFOSS) projects holds the potential to provide a rich education experience to undergraduates. This paper discusses educational use of HFOSS including identification of the potential for HFOSS to impact curricula, an overview of an implementation of HFOSS in education and a description of an evaluation framework that includes measures of success of such a program. The paper also presents results from initial surveys of students involved in HFOSS development in several U.S. academic institutions. The paper concludes with a discussion of work in progress.", "authors": ["Gregory W. Hislop", "Heidi J. C. Ellis", "Ralph Morelli"], "n_citation": 12, "references": ["0f510b65-c6fd-4cd4-8327-5bba06f15fb7", "3dfa1b06-2aa1-47f1-8ac2-7b5ff38d5965", "56d2144e-24c9-4bf7-a73c-7f93226baa51", "5e2bb114-a90b-472a-8929-eacbfca9ccfa", "65cd2b6a-7d29-44a8-bb1f-d09f02da5a41", "74afdfde-b521-4080-9388-6d165fcbf626", "76458fde-17e0-4cdc-8f46-bf0e93f56948", "e0f4e0cf-54c2-4b8b-a008-e56715849b63"], "title": "Evaluating student experiences in developing software for humanity", "venue": "technical symposium on computer science education", "year": 2009, "id": "4f7047e5-e823-4e8f-a3be-8c1fc1b71913"}
{"abstract": "An emerging class of data-intensive applications involve the geographically dispersed extraction of complex scientific information from very large collections of measured or computed data. Such applications arise, for example, in experimental physics, where the data in question is generated by accelerators, and in simulation science, where the data is generated by supercomputers. So-called Data Grids provide essential infrastructure for such applications, much as the Internet provides essential services for applications such as e-mail and the Web. We describe here two services that we believe are fundamental to any Data Grid: reliable, high-speed transport and replica management. Our high-speed transport service, GridFTP, extends the popular FTP protocol with new features required for Data Grid applications, such as striping and partial file access. Our replica management service integrates a replica catalog with GridFTP transfers to provide for the creation, registration, location, and management of dataset replicas. We present the design of both services and also preliminary performance results. Our implementations exploit security and other services provided by the Globus Toolkit.", "authors": ["Bill Allcock", "Joseph Bester", "John Bresnahan", "Ann L. Chervenak", "Carl Kesselman", "Sam Meder", "Veronika Nefedova", "Darcy Quesnel", "Steven Tuecke", "Ian T. Foster"], "n_citation": 401, "references": ["30fe84b9-cc5e-4951-a21b-662ab3291aec", "3292dc0a-74c7-4d4b-82f5-682cdf4f01f7", "36c05ec1-7f89-44d4-a180-49820c36e4a0", "ad25fbbd-feb2-4137-b6e9-b7c3dd1396d7", "b933f197-4416-4563-9bad-686215e287a7", "c1a0f931-e38f-4047-9f63-942f1887dfe7"], "title": "Secure, Efficient Data Transport and Replica Management for High-Performance Data-Intensive Computing", "venue": "arXiv: Distributed, Parallel, and Cluster Computing", "year": 2001, "id": "0e99f68d-e44d-4108-8ddb-1df090a2aaae"}
{"abstract": "It is shown that the universe problem L(A \u03b3) = A a is undecidable for 4-state finite automata A with integer weight function \u03b3 on its transitions. This holds even in the case, where A is acyclic and the weighting \u03b3 satisfies the unimodality condition. The language L(A \u03b3) is defined as the set of words \u03c9 for which there exists a path \u03c0 of A having zero weight, that is, \u03b3(\u03c0) = 0.", "authors": ["Vesa Halava", "Tero Harju"], "n_citation": 28, "references": ["0469d336-c4d6-4c4d-9677-bf5eac1e5c33", "91712f99-91af-466d-983c-cc4e8530fedd", "dbb49b62-2c8a-430b-9674-8d78d9dc9662"], "title": "Undecidability in Integer Weighted Finite Automata", "venue": "Fundamenta Informaticae", "year": 1999, "id": "2d7a4917-046e-4452-bf5d-d52decaf6eef"}
{"abstract": "We introduce a cache protocol verification technique based on a symbolic state expansion procedure. A global Finite State Machine (FSM) model characterizing the protocol behavior is built and protocol verification becomes equivalent to finding whether or not the global FSM may enter erroneous states. In order to reduce the complexity of the state expansion process, all the caches in the same state are grouped into an equivalence class and the number of caches in the class is symbolically represented by a repetition constructor. This symbolic representation is partly justified by the symmetry and homogeneity of cache-based systems. However, the key idea behind the representation is to exploit a unique property of cache coherence protocols: the fact that protocol correctness is not dependent on the exact number of cached copies. Rather, symbolic states only need to keep track of whether the caches have 0, 1, or multiple copies. The resulting symbolic state expansion process only takes a few steps and verifies the protocol for any system size. Therefore, it is more efficient and reliable than current approaches. The verification procedure is first applied to the verification of five existing protocols under the assumption of atomic protocol transitions. A simple snooping protocol on a split-transaction shared bus is also verified to illustrate the extension of our approach to protocols with nonatomic transitions. >", "authors": ["Fong Pong", "Michel Dubois"], "n_citation": 42, "references": ["24d4f0a4-7316-4169-b512-8ba118534bfa", "28b963bc-fb0e-45f4-963a-8004b0e38bf7", "37465eb4-66ed-4b92-ade9-1fe2224925de", "4769ce8b-05ed-49ba-874f-7a6d0882b9a4", "4814eca2-167a-48bd-a7e6-60150e7a54e3", "5375c5a4-a476-44d6-b1ce-a6ec5506a2f8", "726a9e26-3cf5-43cc-b96e-89f21f7eb091", "80df9244-0535-42ff-9eba-ac4d850a1972", "9537a8fc-acdb-4ec6-9548-0021f4790082", "c325c735-8829-4c63-ba3b-baf6efe7d02d", "c85dca47-04cc-4d3b-beca-98d12b7af08e", "d31c856d-94c9-4768-9cbe-872c482dd02f", "fa01bab1-ed50-49aa-9a6d-f44bc4c89120"], "title": "A new approach for the verification of cache coherence protocols", "venue": "IEEE Transactions on Parallel and Distributed Systems", "year": 1995, "id": "f907e2a5-810c-42bf-9311-cf58ac53338c"}
{"abstract": "An automatic method that can transform a sequence of tomographic image slices into an isotropic volume data set is described. In this method, correspondence is established between points in consecutive slices, and then this correspondence is used to estimate data between the slices by linear interpolation. The method takes advantage of the fact that consecutive slices have small geometric differences, and carries out the search in predicted small neighborhoods. Only points with high gradient magnitudes are used in the search process to increase the reliability of the correspondences. Mismatches that occur are detected and corrected using the continuity constraint in the correspondences. Experimental results showing the matching and interpolation of magnetic resonance slices and computed tomography slices are presented. >", "authors": ["A. Ardeshir Goshtasby", "David A. Turner", "L V Ackerman"], "n_citation": 198, "references": ["15727c7d-3b63-4db0-8609-cbf2bfe03b61", "2558c1e5-b937-4d00-a701-493a943e9e87", "5107e016-971b-48c1-a464-74d179777a93", "ef330947-bc34-4f55-834b-40469ee33769", "f39486db-a4d9-49b4-a659-44c63900a7d5"], "title": "Matching of tomographic slices for interpolation", "venue": "IEEE Transactions on Medical Imaging", "year": 1992, "id": "a3445184-47ad-488e-a1e1-363c3b4d39f6"}
{"abstract": "The Darwin Information Typing Architecture is an XML architecture for producing and reusing technical information. DITA promises the following:  Scalable reuse, so you can reuse content in any number of delivery contexts simultaneously without complicating the source  Descriptive markup, so you can use markup that describes your information in terms your customers need  Interchangeability, so you can treat specialized markup as if it were general, getting reuse of tools and processes defined at more general levels of descriptiveness  Process inheritance, so you can reuse existing process logic in your specialized processes.  It accomplishes these goals by applying the principle of reuse by reference to the dimensions of content, design, and process within a technical communications workflow.", "authors": ["Michael Priestley"], "n_citation": 41, "references": [], "title": "DITA XML: a reuse by reference architecture for technical documentation", "venue": "international conference on design of communication", "year": 2001, "id": "6277c617-a0e0-419f-a378-eff8e8513259"}
{"abstract": "We present a protocol that allows a sender to gradually and verifiably release a secret to a receiver. We argue that the protocol can be efficiently applied to exchange secrets in many cases, for example when the secret is a digital signature. This includes Rabin, low-public-exponent RSA, and El Gamal signatures. In these cases, the protocol requires an interactive 3-pass initial phase, after which each bit (or block of bits) of the signature can be released non-interactively (i.e. by sending 1 message). The necessary computations can be done in a few seconds on an up-to-date PC. The protocol is statistical zero-knowledge, and therefore releases a negligible amount of side information in the Shannon sense to the receiver. The sender is unable to cheat, if he cannot factor a large composite number before the protocol is completed.We also point out a simple method by which any type of signatures can be applied to fair contract signing using only one signature.", "authors": ["Ivan Damg\u00e5rd"], "n_citation": 50, "references": ["0dd040aa-d2e6-447d-ad59-c2a19b828c99", "19799e24-d2f1-42ab-8b01-9cfe41708d32", "1c54ac14-4d40-4701-a384-c7824004b11f", "1e4da96e-9a39-4cf4-9bb8-c2e85b1ee527", "1e7dfa37-69e0-4742-b47b-661241b31080", "1e7e39e3-3221-46e0-a63d-46c5a68a2508", "29c593e2-6811-440d-b195-872b25fe4085", "3edc6d75-cbe2-42a9-8f21-bb4061526d8d", "7c4d95af-2bbb-4c4d-8e49-db32fafeda24", "8d25e57a-8d0a-4ed4-b2f5-5af84e732ae5", "a393a4d5-f559-4bdb-8e56-0c1ea2eb9911", "ba5ec268-89bc-4e36-b4e1-d6694c24045e", "d7524636-2862-465a-badf-5cab67501fa4", "dc486f10-1d74-42af-be2a-208070727455", "dc847a05-6b31-4aa4-838f-51f209e645b6"], "title": "Practical and provably secure release of a secret and exchange of signatures", "venue": "theory and application of cryptographic techniques", "year": 1994, "id": "9fb5e59d-1900-4f80-8f5e-6b613b7c57d3"}
{"abstract": "Abstract   This paper provides a systematic and comprehensive study of the underlying semantics of temporal databases, summarizing the results of an intensive collaboration between the two authors over the last five years. We first examine how facts may be associated with time, most prominently with one or more dimensions of  valid  time and  transaction  time. One common case is that of a  bitemporal relation , in which facts are associated with timestamps from exactly one valid-time and one transaction-time dimension. These two times may be related in various ways, yielding  temporal specialization . Multiple transaction times arise when a fact is stored in one database, then later replicated or transferred to another database. By retaining the transaction times, termed  temporal generalization , the original relation can be effectively queried by referencing only the final relation. We attempt to capture the essence of time-varying information via a very simple data model, the  bitemporal conceptual data model . Emphasis is placed on the notion of snapshot equivalence of the information content of relations of different data models. The logical design of temporal databases is a natural next topic. Normal forms play a central role during the design of conventional relational databases. We show how to extend the existing relational dependency theory, including the dependencies themselves, keys, normal forms, and schema decomposition algorithms, to apply to temporal relations. However, this theory does not fully take into account the temporal semantics of the attributes of temporal relations. To address this deficiency, we study the semantics of individual attributes. One aspect is the  observation  and  update patterns  of attributes\u2014when an attribute changes value and when the changes are recorded in the database, respectively. A related aspect is when an attribute has some value, termed its  lifespan . Yet another aspect is the values themselves of attributes\u2014how to derive a value for an attribute at any point in time from stored values, termed  temporal derivation . This study of attribute semantics leads to the formulation of temporal guidelines for logical database design.", "authors": ["Christian S. Jensen", "Richard T. Snodgrass"], "n_citation": 167, "references": ["1b81c485-cc28-46cc-a1f8-4da8466b2906", "1e41e35b-5580-4951-b5c2-32937f9d6384", "1f9d31e9-c9bd-4c05-9bec-92bcd47bc1a6", "2599f0af-8fa7-4511-a5f7-af450427460c", "2cdc4530-3547-4d2a-9700-21df9472096a", "2d414d43-bfaa-49a2-9560-6595b0841489", "32b93504-b4a9-4147-9d7d-37bce16a8a85", "32cc4c53-ea97-4e00-bc1b-482b66c62735", "3565d493-ec80-4663-8a6d-f0c82049500c", "3593557c-382c-4175-adc1-271c254b3e30", "38b7c9c9-f68f-407f-8d5a-217bef9d6fb1", "39585c30-ac53-427f-a784-86840f6bbb28", "3a4b6f6e-bd4b-4da2-8c97-d9da785e86d5", "411fbc6d-a7ed-42d6-83f2-d7c73b1c7118", "43df6cf4-84fa-4441-859d-a77950b4161b", "448e1e91-27fb-471a-9ecb-08f2682e590c", "47f3b62f-43dc-4a17-bd5e-91e5a22298c0", "4b8a2923-d707-44cd-94d2-a03d822d4ec8", "59364f91-79a3-4ab5-9c6d-5c6042f6ad31", "5d44f76c-437f-41c9-92d1-470daef2e464", "607c05cf-df79-4b56-b6b4-8c6c008a7c24", "63998e1e-8d92-43b8-825e-348eb6433938", "640ddf66-4fc2-4c62-bd93-45e3d141d2ad", "774026f3-7e4f-4217-97dd-6ca52689b85a", "7814b203-5af9-4ab1-8b15-ff3412e67bcc", "7fcc0488-0554-4a27-b609-80aabd2e4357", "91ad1b3b-a266-4792-8533-9736af655071", "91e0249a-e9b1-4ccf-8779-38aba4c2e466", "93812939-66d9-4b0b-9137-d08f62dea283", "9505b840-176e-488a-bbfc-e488442e45e8", "96f6f15b-187b-495e-945c-51243fda7246", "a52c089c-9222-4085-91c7-93b217adc8a8", "a855ec29-f56d-4f8c-bd08-f7a2dc92d6b4", "b406c0e2-f2a0-4c7e-aaca-dd8f0f63c1a2", "b6caccd3-d282-427c-a278-3399e434c522", "b97e43de-3de2-4dd9-9c11-048b0d8b940e", "bebf0345-3265-4766-be6a-4ca99d9288b1", "c590955a-f100-4b48-aa20-7b9940e71689", "c987bba4-4202-4524-acf9-8f1920ef5387", "d3baf8bd-d172-4062-bf03-ba6c85ee2579", "dc86489e-60ca-47f1-92b8-16f235ecf178", "ddd53c8c-5376-43e9-8ab4-a940afcb1d59", "e2cd7287-8efc-4401-b121-afeeca4daa53", "e3ec3b5a-db81-4325-b30c-b670bd7c0e54", "e7d875ac-e3bf-4100-92a9-21642569614d", "e99e11c6-256a-48f7-b3c5-32545b5541d8", "ea23fe48-7f24-4c3c-8dba-e7b2ed20586c", "f1174317-1786-4954-b7bf-d074716db1d3", "f3d6a1dc-9d32-476b-bb22-f1303a335507", "f52ef1bf-643c-40ba-bb78-ac32411ae6d1", "f7bc90f3-a534-4066-be4e-dc1ba5a43b9f", "f974ee8d-b6ba-413d-b5b2-f45507631041", "fe220775-3716-4828-8c7f-55ea6469b66a", "ff0b3421-f23c-4780-84bb-223fd1219439"], "title": "Semantics of time-varying information", "venue": "Information Systems", "year": 1996, "id": "38ade521-cedd-40bb-a9c8-0b8c7bbdbfe3"}
{"abstract": "Energy conservation is a critical issue in wireless ad hoc networks since batteries are the only energy source to power the nodes. One major metric for energy conservation is to route a communication session along the routes which require the lowest total.", "authors": ["Song Guo", "Oliver W. W. Yang"], "n_citation": 50, "references": ["03a67937-3823-48ca-8b6c-98bf2774800b", "05fb3436-276f-43ca-979b-0a3323240c19", "18205fbb-d605-4d42-8a04-84035db9761a", "1bec0dfe-7bf6-467e-be96-46bc98d24633", "30709b2e-049a-4846-a358-831f0b04c9b2", "32591c3e-f867-4910-91ec-ce8d8113767a", "38f54b84-5272-43df-8cde-a3e755b17dee", "5273f0b5-1a2f-4c52-a2fd-4f59fd18bbc6", "7364dac5-960b-4593-9b6c-163c2d4a9c43", "7f3b1fea-7e7e-4102-a709-3bd3b9846d68", "90b80d6a-d4e1-445a-a42e-cf37ccc650b7", "9e36872e-fd97-41b8-8ac7-f50dc2da7cbc", "a202d101-de4d-4072-9859-d7739d4c791b", "ccabb476-c38d-4867-bf93-60f1abe6e95b", "f9532880-407d-40b7-8a3c-fb70fa2d50d8", "fb2003f6-ed7b-424e-94b2-6b150f8e7302"], "title": "Antenna orientation optimization for minimum-energy multicast tree construction in wireless ad hoc networks with directional antennas", "venue": "mobile ad hoc networking and computing", "year": 2004, "id": "55b1f587-9622-49ea-81a0-71f8fe994e47"}
{"abstract": "Recent work in wireless embedded networked systems has followed  heterogeneous  designs, incorporating a mixture of elements from extremely constrained 8- or 16-bit \u201cMotes\u201d to less resource-constrained 32-bit embedded \u201cMicroservers.\u201d   Emstar is a software environment for developing and deploying complex applications on such heterogeneous networks. Emstar is designed to leverage the additional resources of Microservers by trading off some performance for system robustness in sensor network applications. It enables fault isolation, fault tolerance, system visiblity, in-field debugging, and resource sharing across multiple applications.   In order to accomplish these objectives, Emstar is designed to run as a multiprocess system and consists of  libraries  that implement message-passing IPC primitives,  services  that support networking, sensing, and time synchronization, and  tools  that support simulation, emulation, and visualization of live systems, both real and simulated. We evaluate this work by discussing the Acoustic ENSBox, a platform for distributed acoustic sensing that we built using Emstar. We show that by leveraging existing Emstar services, we are able to significantly reduce development time while achieving a high degree of robustness. We also show that a sample application was developed much more quickly on this platform than it would have been otherwise.", "authors": ["Lewis Girod", "Nithya Ramanathan", "Jeremy Elson", "Thanos Stathopoulos", "Martin Lukac", "Deborah Estrin"], "n_citation": 328, "references": ["079090cb-9ba8-419b-845c-7cccb6039da3", "07e7041b-1b6f-4948-b281-61a77aac8604", "091417ee-537f-40a2-a7c0-697b8a0ae663", "1dd8c68d-3b20-4171-9245-3a12c64c2838", "3018f14f-3447-42c2-b3a8-1f61fbb2d3ca", "3ac61fef-7bd4-4d7f-9e1f-75075bbab07c", "416689be-ec06-46cc-96c4-43670338a935", "5dff73b0-a0d7-4104-b7a4-1a58644cd651", "5fa6d73a-a995-4f12-95b1-dd1daa872b15", "73195585-0e6d-4174-857d-8a9f1b862d14", "7825483e-9910-4c7f-afd3-0f86252f2fce", "85352dec-58be-43db-a428-f3f574ff96ec", "89945fa0-84f5-4680-b695-24fbbc1384da", "8a93205f-cd08-48be-90a1-0bcfd3658411", "95fc90bc-37a0-42b4-ae30-19e9c6a6540e", "9b71158d-d510-4cc5-b422-a120aa3ba98a", "9efda63c-320d-46b0-8a7b-175012a2936f", "ab527421-8d2d-4112-a54c-7211b4b8e1e6", "c0d82143-01df-49db-a228-00b4b9e6c048", "d670a693-527b-4452-9d27-e409a536cf4a", "dd8bc187-a8f3-4a3e-b20f-9e54e03a3031", "fd15feef-f60a-40af-a780-a67e4f70bace"], "title": "Emstar: A software environment for developing and deploying heterogeneous sensor-actuator networks", "venue": "ACM Transactions on Sensor Networks", "year": 2007, "id": "569ec03e-4062-42c0-bd2d-b8b4f7f1b1af"}
{"abstract": "Using agile methods to develop large systems presents a thorny set of issues. If large teams are to produce lots of software functionality quickly, the agile methods involved must scale to meet the task. After all, a small team could create the software if the functionality to be delivered was small and, conversely, could be delivered given we had the time. Scaling agile teams thus becomes an issue if the only option for meeting a system delivery deadline is to have many developers working concurrently.", "authors": ["Donald J. Reifer", "Frank Maurer", "M. Hakan Erdogmus"], "n_citation": 75, "title": "Scaling agile methods", "venue": "IEEE Software", "year": 2003, "id": "485e160a-a04a-45cb-b935-674336805a77"}
{"abstract": "A recent paper [Hanks 1985] examines temporal reasoning as an example of default reasoning. They conclude that all current systems of default reasoning, including non-monotonic logic, default logic, and circumscription, are inadequate for reasoning about persistence. I present a way of representing persistence in a framework based on a generalization of circumscription, which captures Hanks and McDermott's procedural representation.", "authors": ["Henry A. Kautz"], "n_citation": 178, "references": ["43959b1e-98f1-45c5-a7eb-cfeb9ce364d9", "47e9ec84-2460-48dd-b255-5a6686a4fdfc"], "title": "The logic of persistence", "venue": "national conference on artificial intelligence", "year": 1986, "id": "7caf30b9-c311-43de-8dfd-c70e150ce9ca"}
{"abstract": "In this paper, an implicit inversion of the hysteresis described by Preisach model is introduced to avoid difficulties of the directly inverse construction for this kind of complex hysteresis models. Based on this inversion, the adaptive control for unknown linear dynamical systems preceded with hysteresis described by Presaich model is formulated. The stability of the controlled systems is analyzed and zero output tracking error can be eventually achieved. Finally, the proposed algorithm is applied to the position control of the nano-stage driven by magnetostrictive actuator.", "authors": ["Xinkai Chen"], "n_citation": 1, "references": ["08233c59-d9f7-41c8-950e-2ced539b8cba", "535588c1-5358-4d4e-aaaa-c1644069da08", "61a648d2-f5eb-44d2-8ce1-b9bf1b65412d", "a5561a94-8986-44b8-a2ad-4cd29fbc8ad0", "f05aad56-7628-49b3-8a78-80128c610d0c"], "title": "Control for unknown linear systems preceded by hysteresis represented by preisach model", "venue": "conference on decision and control", "year": 2013, "id": "7d1b0550-ea62-494c-b185-dc84595e1c26"}
{"abstract": "Research in natural language generation promises significant advances in the ways in which we can make available the contents of underlying information sources. Most work in the field relies on the existence of carefully constructed artificial intelligence knowledge bases; however the reality is that most information currently stored on computers is not represented in this format. We describe some work in progress where we attempt to generate large numbers of texts automatically from existing underlying databases. We focus in particular on the automatic generation of descriptions of objects stored in a museum database, highlighting the difficulties that arise in using a real data source, and pointing to some possible solutions.", "authors": ["Robert Dale", "Stephen J. Green", "Maria Milosavljevic", "C\u00e9cile Paris", "Cornelia Maria Verspoor", "Sandra Williams"], "n_citation": 29, "references": ["3e391bd7-96c8-46c1-9345-d3db932ce201", "60f1d58d-6bed-471b-a689-351e66a59e4c", "9b898498-6ac0-48b1-a27f-7496a424764d", "c0934943-c63e-4a02-a0f4-b7b5ad4aced9", "ce72b144-8aad-4d9b-a3ea-a4893843aee9", "ebfe9403-6317-4881-85c9-cf35ed28e720", "f9ee9c7a-ff98-4449-989d-859f52251e8a"], "title": "Dynamic document delivery: generating natural language texts on demand", "venue": "database and expert systems applications", "year": 1998, "id": "9b98d632-ab0d-4111-97c5-036dc58296ed"}
{"abstract": "Live programming can be considered an interaction with incomplete code. Dynamic languages embrace the similar style of programming, such as pair programming and prototyping in a review session. Static languages require a certain degree of completeness of code, such as type safety and namespace resolution. SOMETHINGit is a Smalltalk library that combines dynamic Smalltalk and static Haskell and VDM-SL. SOMETHINGit enables programmers to write incomplete but yet partially mathematically sound programs by five levels of bridging mechanisms.", "authors": ["Tomohiro Oda", "Kumiyo Nakakoji", "Y. Yamamoto"], "n_citation": 3, "references": ["096a648b-c628-4dd4-9b18-9343fb558e60", "3958dd37-9d6d-4746-adef-567c7e3a360d", "4df19b88-039d-4ed1-a88f-8e77c42dcd72", "50689679-8346-48f2-8d70-4dfd29f8b470", "dc838991-a9b3-4053-8cdb-ed864a135cbc", "e427b1d7-4b8d-462a-9916-122d8fd39f8c", "eb5f5a50-9b60-4b6b-a16b-c922d1de1073"], "title": "SOMETHINGit: a prototyping library for live and sound improvisation", "venue": "", "year": 2013, "id": "79150f20-4507-46c4-a82d-16c3e90723d2"}
{"abstract": "The KnowItAll system aims to automate the tedious process of extracting large collections of facts (e.g., names of scientists or politicians) from the Web in an unsupervised, domain-independent, and scalable manner. The paper presents an overview of KnowItAll's novel architecture and design principles, emphasizing its distinctive ability to extract information without any hand-labeled training examples. In its first major run, KnowItAll extracted over 50,000 class instances, but suggested a challenge: How can we improve KnowItAll's recall and extraction rate without sacrificing precision? This paper presents three distinct ways to address this challenge and evaluates their performance. Pattern Learning learns domain-specific extraction rules, which enable additional extractions. Subclass Extraction automatically identifies sub-classes in order to boost recall (e.g., ''chemist'' and ''biologist'' are identified as sub-classes of ''scientist''). List Extraction locates lists of class instances, learns a ''wrapper'' for each list, and extracts elements of each list. Since each method bootstraps from KnowItAll's domain-independent methods, the methods also obviate hand-labeled training examples. The paper reports on experiments, focused on building lists of named entities, that measure the relative efficacy of each method and demonstrate their synergy. In concert, our methods gave KnowItAll a 4-fold to 8-fold increase in recall at precision of 0.90, and discovered over 10,000 cities missing from the Tipster Gazetteer.", "authors": ["Oren Etzioni", "Michael J. Cafarella", "Doug Downey", "Ana-Maria Popescu", "Tal Shaked", "Stephen Soderland", "Daniel S. Weld", "Alexander Yates"], "n_citation": 1165, "references": ["00f2ca1e-0b3b-45c4-b7b8-d3f182b65012", "04581d18-c119-4988-bff7-ebfc63715ab0", "0500ddbe-e274-477b-bb6b-54a7269e4577", "145e57eb-d121-435e-888e-066601384cd5", "1b006379-4b8d-4b00-a7e7-7fa2c7d28650", "1bd76ab6-c182-416f-b54e-3793fa3e58cb", "1c1a63cd-9b5d-4b60-869b-4b0ca36f2c48", "21edaf4d-d927-4422-9c21-cba71d2aeffd", "2770cf4f-c40d-4a7a-b879-f46893ba4c84", "2bc7fa05-4c37-44f3-9ed4-9f1e68c501ea", "352d0531-d578-41e6-ba8d-cc98bcfa85fb", "3b467d03-83e2-4454-813f-ac19b54dbfb6", "3e49e524-93f9-4181-a940-723a3c24f8e3", "42511ba1-be88-47f3-8345-45cf67a0aa4e", "5f64e855-250b-4300-a06b-d46c5ca820d2", "794b1c44-c02f-483e-befd-ea10cbd03af4", "7fb71be8-65ef-41b5-9b58-65e03d37dcea", "84f69ceb-6599-4f6a-980f-c4331ddbefc4", "8813d266-c047-42f1-92d3-a6f7c276ceab", "9142bfbf-8ab9-411c-887a-22dfe941bef6", "91877231-41b1-4ef3-bcb4-bd36067aaa85", "92d0da63-d882-4d22-b5d2-5c41306bda51", "96d6d9b9-6d69-4c9a-b3f5-c8083966d55c", "9b2e695b-8f77-443a-9332-d2ed96777496", "adaaafab-aa7a-4b1e-842d-e29c8c2f049b", "c75c7b08-7264-4daa-a133-59bea66db0c7", "cbf7acc5-98bb-485a-bf20-5e58af3e29fc", "db6d952c-620f-4f4a-9e5b-59f4daca3224", "dbea02e6-60cd-40c4-9ba3-d8f2b0e1d607", "dec0e015-8bb9-49bc-8288-6cd771075b86", "df930b5d-a543-44ae-9982-b04067c157ef", "efc26e0a-0131-4fca-a1d9-ba8655d08813", "f3ba51d4-53b1-4c0e-8fa3-b09aba85a2d0", "f687a370-50cf-482e-9748-35cf5c975c0b", "f998a503-422a-46ef-adf3-8c23579d7be5", "fc11d583-a297-420a-a99a-d8386f0b0969"], "title": "Unsupervised named-entity extraction from the web: an experimental study", "venue": "Artificial Intelligence", "year": 2005, "id": "b0b711fa-738c-42df-b1a6-c13d85830dd4"}
{"authors": ["Antonio C. Siochi", "Deborah Hix"], "n_citation": 73, "references": ["3733e082-3742-48f6-89b8-4d67f003b72b", "a5b44790-d05b-4ffe-8597-341a4d2cdfd6", "b49ed7a5-e9b1-4de7-a831-c0d8bcc32002", "d9926d4c-affc-4f94-bf4f-32c41671731e"], "title": "A study of computer-supported user interface evaluation using maximal repeating pattern analysis", "venue": "human factors in computing systems", "year": 1991, "id": "62ff5275-8b4f-45d9-875b-38c0a336c8e2"}
{"abstract": "Much of the research on extracting rules from a large amount of data has focused on the extraction of a general rule that satisfies as many data as possible. In the field of health care where people's lives are at stake, the exceptional rules for rare cases are also important. In this paper, we describe the knowledge acquisition from data containing such multiple rules. We consider that a multi-agent approach is effective for extracting multiple rules. In order to realize this approach, we propose a new method using an improved Genetic Programming method, Auto- matically Defined Groups (ADG). By using this method, the clustering of data is performed by sharing roles among agents, and each agent takes charge of rule extraction in the assigned data. As a result, all rules are ex- tracted by multi-agent cooperation. We applied this method to coronary heart disease databases, and showed the effectiveness of this method.", "authors": ["Akira Hara", "Takumi Ichimura", "Tetsuyuki Takahama", "Yoshinori Isomichi"], "n_citation": 6, "references": ["309ec3b9-8035-46f1-8e44-6e3d8f615ef2", "b95de900-b8bd-4e25-b1e5-ff1cba7d17ba", "e1cc87c9-e932-4710-b25f-fb22a77b194b"], "title": "Extraction of Rules from Coronary Heart Disease Database Using Automatically Defined Groups", "venue": "", "year": 2004, "id": "9c763e30-0876-4d88-936a-6cfb95bb9917"}
{"abstract": "Agent-based modeling (ABM), also termed \u2018Individual-based modeling (IBM)\u2019, is a computational approach that simulates the interactions of autonomous entities (agents, or individual cells) with each other and their local environment to predict higher level emergent patterns. A literature-derived rule set governs the actions of each individual agent. While this technique has been widely used in the ecological and social sciences, it has only recently been applied in biomedical research. The purpose of this review is to provide an introduction to ABM as it has been used to study complex multi-cell biological phenomena, underscore the importance of coupling models with experimental work, and outline future challenges for the ABM field and its application to biomedical research. We highlight a number of published examples of ABM, focusing on work that has combined experimental with ABM analyses and how this pairing produces new understanding. We conclude with suggestions for moving forward with this parallel approach.", "authors": ["Bryan C. Thorne", "Alexander M. Bailey", "Shayn M. Peirce"], "n_citation": 116, "references": ["2ba8bae0-4d1d-4dfa-acda-47b046faab65", "304a7215-f58a-40ec-bca7-622cc1e01125", "771c1bba-1e06-48fb-8467-1d4779a37734", "a4a84fcd-c1c2-42c0-afd8-697520623301", "eec85fcd-ec25-44d7-a135-0380e5bad2d6"], "title": "Combining experiments with multi-cell agent-based modeling to study biological tissue patterning", "venue": "Briefings in Bioinformatics", "year": 2007, "id": "d04526f2-010b-46a6-b07c-8fcc2390b11b"}
{"abstract": "Nowadays, more and more information systems are connected to the Internet and offer Web interfaces to the general public or to a restricted set of users. Such openness makes them likely targets for intruders, and conventional protection techniques have been shown insufficient to prevent all intrusions in such open systems. This paper proposes a generic architecture to implement intrusion-tolerant Web servers. This architecture is based on redundancy and diversification principles in order to increase the system resilience to attacks: usually, an attack targets a particular software, running on a particular platform, and fails on others. The architecture is composed of redundant proxies that mediate client requests to a redundant bank of diversified application servers. The redundancy is deployed here to increase system availability and integrity. To improve performance, adaptive redundancy is applied: the redundancy level is selected according to the current alert level. The architecture can be used for static servers, that is, for Web distribution of stable information (updated offline) and for fully dynamic systems where information updates are executed immediately on an online database. The feasibility of this architecture has been demonstrated by implementing an example of a travel agency Web server, and the first performance tests are satisfactory, both for request execution times and recovery after incidents.", "authors": ["Ayda Saidane", "Vincent Nicomette", "Yves Deswarte"], "n_citation": 66, "references": ["19284f49-3a12-49d6-a7db-1cb0bdf4654b", "2f5c4e3f-9346-4422-9dfd-773b2a0c5690", "344be32f-7fe7-4324-aa68-c2ec8eb679d6", "a524be55-f906-4c4f-afdc-e008dbd15ffc", "af5536e7-6535-44c8-9c0e-333d36ac65e8", "af57d44f-d221-43ca-8570-df52f004e47f", "b1419749-eaf0-40ea-9ccc-4f2ec63e28eb", "bd3ea06b-7db6-4fa6-8508-0c08974ecbcc", "cb9366cf-ed14-4458-9bcd-756bf6359983"], "title": "The Design of a Generic Intrusion-Tolerant Architecture for Web Servers", "venue": "IEEE Transactions on Dependable and Secure Computing", "year": 2009, "id": "18eab23f-bdd3-4966-ab05-8f08456ebdb3"}
{"abstract": "Diabetic-related eye diseases are the most common cause of blindness in the world. So far the most effective treatment for these eye diseases is early detection through regular screening. To lower the cost of such screenings, we employ state-of-the-art image processing techniques to automatically detect the presence of abnormalities in the retinal images obtained during the screenings. The authors focus on one of the abnormal signs: the presence of exudates/lesions in the retinal images. We propose a novel approach that combines brightness adjustment procedure with statistical classification method and local-window-based verification strategy. Experimental results indicate that we are able to achieve 100% accuracy in terms of identifying all the retinal images with exudates while maintaining a 70% accuracy in correctly classifying the truly normal retinal images as normal. This translates to a huge amount of savings in terms of the number of retinal images that need to be manually reviewed by the medical professionals each year.", "authors": ["Huan Wang", "Wynne Hsu", "Kheng Guan Goh", "Mong Li Lee"], "n_citation": 194, "references": ["3ac1ae7b-df5a-437f-a653-83504385b9be", "70caa088-db95-482e-8d60-b1b95ae48081"], "title": "An effective approach to detect lesions in color retinal images", "venue": "computer vision and pattern recognition", "year": 2000, "id": "277835ee-9c13-41fd-bf19-617f85b8e6be"}
{"authors": ["Michael Gleicher", "Andrew P. Witkin"], "n_citation": 358, "references": ["05001a6c-b8b0-43da-aeb6-8f1baefa1a0f", "19a9fb05-b563-4cb9-936f-4680b572a10a", "3a55b343-9430-48b9-b2dc-3c28055f5624", "4a7b9a21-1050-4958-87a8-f8b036114835", "5b3acbaa-b46e-4d2b-8cf8-ef4f5a1c490b", "78b814cd-89a1-445e-b7b5-35e5668fe2cc", "82f84675-3b8f-4c57-9399-10aaaa572f1c", "961aa2a5-c0a2-409d-a4f7-f6ed6e1eb116", "9a8f2933-58da-45b6-bc06-883207784356", "ae27737c-91dc-4bec-a858-3a7bb3aeae20", "bfdc529c-b971-4d4e-9882-2f21ff888198", "c969361e-86ff-4052-aaad-9bfba4b404c2", "cba3dbb0-8444-4d04-b867-1909bfda6ae7", "e2f50d9c-394d-49a6-931e-82b389fd1464", "e47604d5-6a55-40ef-b218-fb1fd93e4ab8"], "title": "Through-the-lens camera control", "venue": "international conference on computer graphics and interactive techniques", "year": 1992, "id": "1c940510-5473-4e01-9c7c-bce8e006134a"}
{"abstract": "Most reports of Internet collaboration refer to small scale operations among a few authors or designers. However, several projects have shown that the Internet can also be the locus for large scale collaboration. In these projects, contributors from around the world combine their individual forces and develop a product that rivals those of multibillion dollar corporations. The Apache HTTP Server Project is a case in point. This collaborative software development effort has created a robust, feature-rich HTTP server software package that currently dominates the public Internet market (46 percent compared with 16 percent for Microsoft and 12 percent for Netscape, according to a June 1997 survey published by Netcraft). The software and its source code are free, but Apache's popularity is more often attributed to performance than price. The project is managed by the Apache Group, a geographically distributed group of volunteers who use the Internet and Web to communicate, develop, and distribute the server and its related documentation. In addition, hundreds of users have contributed ideas, code, and documentation to the project.", "authors": ["Roy Fielding", "Gail E. Kaiser"], "n_citation": 221, "title": "The Apache HTTP Server Project", "venue": "IEEE Internet Computing", "year": 1997, "id": "2bc7f44f-1fe1-4747-891f-52e82a4dacc0"}
{"authors": ["Ran Canetti"], "n_citation": 62, "title": "A unified framework for analyzing security of protocols", "venue": "Electronic Colloquium on Computational Complexity", "year": 2001, "id": "a1996cb2-2f54-40c2-9e36-9e87402b12ca"}
{"abstract": "The characteristics of mobile environments, with the possibility of frequent disconnections and fluctuating bandwidth, have forced a rethink of traditional middleware. In particular, the synchronous communication paradigms often employed in standard middleware do not appear to be particularly suited to ad hoc environments, in which not even the intermittent availability of a backbone network can be assumed. Instead, asynchronous communication seems to be a generally more suitable paradigm for such environments. Message oriented middleware for traditional systems has been developed and used to provide an asynchronous paradigm of communication for distributed systems, and, recently, also for some specific mobile computing systems.   In this paper, we present our experience in designing, implementing and evaluating EMMA (Epidemic Messaging Middleware for Ad hoc networks), an adaptation of Java Message Service (JMS) for mobile ad hoc environments. We discuss in detail the design challenges and some possible solutions, showing a concrete example of the feasibility and suitability of the application of the asynchronous paradigm in this setting and outlining a research roadmap for the coming years.", "authors": ["Mirco Musolesi", "Cecilia Mascolo", "Stephen Hailes"], "n_citation": 48, "references": ["717a4dfd-7479-4ac8-9f66-8c6e59b8746e", "8bc8b1a1-9d53-4c04-a5b0-66074548cc0c", "917d43c2-4bdd-49ed-afc6-66df3a756f6f", "b1ac6690-5db9-42ca-9f50-12d1e4096546", "b8f1cb09-2200-4ee9-ae11-5f22e68d8855"], "title": "Adapting asynchronous messaging middleware to ad hoc networking", "venue": "", "year": 2004, "id": "2b6258d0-7a00-4cdb-8715-0c28588ed66e"}
{"abstract": "Context: In order for model-driven engineering to succeed, automated code generation from models through model transformations has to guarantee that extra-functional properties specified at design level are preserved at code level. Objective: The goal of this research work is to provide a full round-trip engineering approach in order to evaluate quality attributes of the embedded system by code execution monitoring as well as code static analysis and then provide back-propagation of the resulting values to modelling level. In this way, properties that can only be roughly estimated statically are evaluated against observed values and this consequently allows to refine the design models for ensuring preservation of analysed extra-functional properties at code level. Method: Following the model-driven engineering vision, (meta-) models and transformations are used as main artefacts for the realisation of the round-trip support which is finally validated against an industrial case study. Result: This article presents an approach to support the whole round-trip process starting from the generation of source code for a target platform, passing through the monitoring of selected system quality attributes at code level, and finishing with the back-propagation of observed values to modelling level. The technique is validated against an industrial case study in the telecommunications applicative domain. Conclusion: Preservation of extra-functional properties through appropriate description, computation and evaluation makes it possible to reduce final product verification and validation effort and costs by generating correct-by-construction code. The proposed round-trip support aids a model-driven component-based development process in ensuring a desired level of extra-functional properties preservation from the source modelling artefacts to the generated code.", "authors": ["Federico Ciccozzi", "Antonio Cicchetti", "Mikael Sj\u00f6din"], "n_citation": 31, "references": ["079219d5-3f6b-4453-ad05-170a88cb96c0", "1106cadf-7f33-4769-9f2c-3fe719db3327", "3dee12aa-42a8-4ed1-9e6a-a1445b8130ee", "692db4f3-7188-47dc-87e2-851bc96bb601", "6e85c05f-f542-4b00-ac79-41498087d717", "79f77609-c572-4f9c-b229-276fac028e8b", "86df1f67-b55b-43c2-80bc-b3a005cb052e", "87226b9d-935e-4394-af74-4e3229002671", "9a5c4f5c-afc5-41af-b056-ddaac6fc5b34", "a3bdcfc3-87f0-46de-ae33-e9d670528314", "a63d0fe7-4bd5-40a3-ad0f-fd489cf30998", "ab76454c-9601-48ed-a273-c4d9d0ae52f0", "c6b144a8-2239-406c-878a-3f8a6c73f830", "d0f5e477-d097-4d10-bd95-0884a7b9c37b", "ebb6cc54-54e2-4da8-bb1c-166df5199451", "fe8cd95a-7197-47bd-ba0d-9b8c91df0b0f"], "title": "Round-trip support for extra-functional property management in model-driven engineering of embedded systems", "venue": "Information & Software Technology", "year": 2013, "id": "6401fa66-95d1-476f-82ec-106965bc6360"}
{"abstract": "Focuses on the temperature control of a semibatch chemical reactor used for fine chemicals production. Such a reactor is equipped with a heating/cooling system composed of different thermal fluids. Without extensive modeling investigations, a feedback-feedforward control strategy is proposed for ensuring the tracking performance of the desired temperature profile. Such a strategy is derived from a family of the iterative learning control (ILC) algorithms named batch model predictive control (BMPC). Learning is achieved without requiring a detailed knowledge of the system, which may be affected by unknown but repetitive disturbances. The learning control solution is based on the minimization of a linear quadratic cost function. The synthesis of the proposed strategy is studied, and improvements of the algorithm features are proposed. First, guaranteed convergence of the algorithm is illustrated in a few experimental runs. Second, some practical considerations for the removal of high-frequency disturbance effects are outlined to improve the achieved performance. Third, a robust supervisory control procedure is employed to choose the right fluid and to reduce the superfluous fluid changeovers, mainly when different fluids are available. Finally, experimental results are presented to illustrate the practical appeal and effectiveness of the proposed scheme.", "authors": ["M. Mezghani", "G. Roux", "Michel Cabassud", "M.V. Le Lann", "B. Dahhou", "Georges Casamatta"], "n_citation": 12, "references": ["05b3f309-98f7-4cbc-bc3e-b2f66514db94", "6be22e5e-3c43-4cc4-b445-429e8048a604", "a98ffa55-a964-46ec-8891-784db26c4340", "d5c10f26-5179-44d6-b627-79b7086c592b"], "title": "Application of iterative learning control to an exothermic semibatch chemical reactor", "venue": "IEEE Transactions on Control Systems and Technology", "year": 2002, "id": "51fce764-63e1-47c7-8aa9-c6c6108a3539"}
{"abstract": "We present Galileo, a dynamic fault tree modeling and analysis tool that combines the innovative DIF-Tree analysis methodology with a rich user interface built using package-oriented programming. DIFTree integrates binary decision diagram and Markov methods under the common notation of dynamic fault trees, allowing the user to exploit the benefits of both techniques while avoiding the need to learn additional notations and methodologies. Package-oriented programming (POP) is a software architectural style in which large-scale software packages are used as components, exploiting their rich functionality and familiarity to users. Galileo can be obtained for free under license for evaluation, and can be downloaded from the World-Wide Web.", "authors": ["Kevin J. Sullivan", "Joanne Bechta Dugan", "David Coppit"], "n_citation": 183, "references": ["235c979a-8bf1-4868-903c-9fc7e1b1b9f2", "931d1b54-396e-4072-b4d6-1b9394c120a9", "b86bdadc-b4b0-4eae-96b8-b9f9b392026a"], "title": "The Galileo fault tree analysis tool", "venue": "", "year": 1999, "id": "0250c362-b7e1-4638-832b-4c630c1013e6"}
{"abstract": "In this paper we present a hardware architecture for a Support Vector Machine intended for vision applications to be implemented in a FPGA device. The architecture computes the contribution of each support vector in parallel without performing multiplications by using a CORDIC algorithm and a hardware-friendly kernel function. Additionally input images are not preprocessed for feature extraction as each image is treated as a point in a high dimensional space.", "authors": ["Marta Ruiz-Llata", "Mar Y\u00e9benes-Calvino"], "n_citation": 8, "references": ["1cd34a53-2a93-4ecd-b6d7-f0be7efbf601", "2750b9ea-36d7-4b74-9056-7fa9c23eef5f", "532dec4c-28bf-4ca8-aa3b-fc5b5b20bb2d", "bdb0a7c9-2764-4724-9f15-b177d39d066e", "e1380777-7a37-4fa2-81bd-fc1257f18ca2"], "title": "FPGA Implementation of Support Vector Machines for 3D Object Identification", "venue": "international conference on artificial neural networks", "year": 2009, "id": "5ea6e462-8180-472e-b4bc-bdc0e3ca71f5"}
{"abstract": "Repetitive control is useful if periodic disturbances act on a control system. Perfect (asymptotic) disturbance rejection is achieved if the period-time is exactly known. For those cases where the period-time changes and cannot be measured directly by an auxiliary signal, a robust repetitive controller structure is proposed. It uses multiple memory-loops in a certain feedback configuration, such that small changes in period-time do not diminish the disturbance rejection properties. The robust repetitive controller shows good implementation results for a tracking control problem of a Compact Disc player.", "authors": ["M Maarten Steinbuch"], "n_citation": 47, "references": ["547a0285-7a60-4674-badb-0cdf82926087", "8bf3c359-4dc1-4f8c-aaef-2b21d323c8a0", "99ac102f-6fdb-43fb-a0a7-656ef7d73c1d", "a80a1efe-c866-4a9d-a547-ea6a3b0634cd", "d0bea583-e985-4549-bd39-7ebe338dde20"], "title": "Brief Repetitive control for systems with uncertain period-time", "venue": "Automatica", "year": 2002, "id": "d0519ebd-61d1-46c5-87f0-bbb0953b9365"}
{"abstract": "A software system often consists of thousands of source files, which must be translated into thousands of intermediate files, which eventually must be translated into some small number of library and executable files. Collectively, these steps compose its build process. A large software system can be difficult to build. The steps can be numerous and complex. Of course, there are a variety of tools to assist us (e.g. MAKE), but their languages emphasize the specification of low-level details (e.g. compiler names and options), rather than high-level attributes (e.g. host/target platforms and required subsystems). This paper describes a new domain-specific language for specifying the composition and construction of a software system, where the emphasis is on high-level attributes. A specification is processed by a pipeline of fairly simple tools to produce a set of makefiles, which are then processed by MAKE in the usual way.", "authors": ["J. Buffenberger", "Kirk Gruell"], "n_citation": 50, "references": ["1412ff23-1344-4034-87ac-344cc850f0b3", "15b522d6-ba85-40b9-84e7-753d10ff9b07", "23b06abc-28c8-4a60-8cde-8f905927ca34", "4093c606-435d-46ff-a543-9cba331902df", "4f88d229-c13a-4cf0-ab22-2d55c8dfcff6", "6321c4eb-6305-4883-b93f-dd45be3002ac", "81af47a7-ab44-4c45-a9a0-f2aad99d28d6", "afb53ab6-f19a-4185-849f-150666fae6b9", "ba0ffed5-3044-4547-a891-3891007c44de", "e637e620-edf3-4752-8e6b-d82afd9678fb", "e87f25fc-5d8c-4b87-895b-4c82cba7dc48", "ed323699-4f23-44fd-b187-7a1f6f5d1260"], "title": "A language for software subsystem composition", "venue": "hawaii international conference on system sciences", "year": 2001, "id": "afad0467-8ebc-45ee-8f36-ceeb5080493f"}
{"abstract": "DML (Denotational Meta Language) is a specification language and a compiler generation tool for producing practical and efficient compilers from denotational semantics specifications. This means that code emitted from generated compilers should be product quality, and that generated compilers should have reasonable compilation speed and interface well with standard front-ends and back-ends. To achieve this goal, the DML system contains: a general algorithm for producing efficient quadruple code from continuation semantics of Algol-like languages, and enhancements in the DML specification language with BNF rules for abstract syntax declarations and semantic brackets with inline concrete syntax and pattern matching for readable and concise semantic equations. Generated quadrupole code is fed into a standard optimizing back-end to obtain high-quality target code. The DML system generates efficient compilers in C and contains a foreign language interface for communication, e.g. with parsers or optimizing back-ends. DML is a superset of Standard ML and uses applicative order semantics, i.e. call by value, for reasons of efficiency. >", "authors": ["M. Pattersson", "Peter Fritzson"], "n_citation": 50, "references": ["1beecffd-9d3d-4b5f-b118-154ed1843975", "21a992d5-d74a-4983-bc8d-8ae02dcadf6f", "2c04adbe-7a6a-4562-817b-facb05b2fcb4", "70d50efe-dd02-49ef-9f25-d3642bca0bca", "7a37f8d5-c095-4e19-9bff-5b2443d59693", "801d79fc-df14-436f-9350-568e22ff92c3", "9db400ca-91d0-4eb2-8487-9861145ea285", "a57ffe56-785d-4a5d-b54c-a49b36385c2f", "aa8e88bc-a731-487c-86c3-502c9f4e8cf4", "b5cb4de8-c7da-4fa5-9663-2fa24a1044fa", "bcb7c669-9e4c-4d8b-aa7d-ac4d636cf769", "cdce4755-196a-4db7-adc2-44fbbe567387", "d1fa81fb-2b52-4392-845e-4c2114b4dba0", "e84d16c7-ec1b-40bd-9038-d21a136b20d9", "ea7b40f1-538f-4ea4-807b-b8ef8be4a794"], "title": "DML-a meta-language and system for the generation of practical and efficient compilers from denotational specifications", "venue": "international conference on computational logistics", "year": 1992, "id": "82a5fccd-a97f-4a52-a48f-d41e6b3c6d8d"}
{"abstract": "In search for new organizational forms that incorporate the appropriate level of flexibility to offer a high variety of products and services, while keeping costs and lead times low, the virtual organization has emerged. The capabilities of information and communication technology (ICT) enable the virtual organization to link and coordinate a wide variety of globally dispersed business partners. The virtual organization in action is difficult to manage. We introduce a management support tool, called Modular Network Design (MND). MND supports managers of a virtual organization in four steps: determination and analysis of customer requirements; tracking of possibilities to satisfy customer requirements; allocation of production tasks among network partners; and ongoing assessment and adjustment of activities and allocation procedures. The applicability of MND, and the evaluation of ICT use, is illustrated with a case study at KLM Distribution, the center of a globally operating virtual organization. This business unit of KLM Royal Dutch Airlines distributes worldwide aircraft spare-parts for KLM and its partners and customers. The case study describes how MND supports the management of the virtual organization and contributes to better planning of individual, customized transport orders.", "authors": ["Matthijs J. J. Wolters", "Martijn R. Hoogeweegen"], "n_citation": 50, "references": ["4518623e-0fee-40a6-a839-0e93fe39ff67", "9627348b-70e9-4a9d-a0af-4fcdb9584378", "b26ea36f-d22e-46d9-92a1-e63f9c140494", "d00989a7-f2f1-4b29-8ac8-0562e5975f39"], "title": "Management support for globally operating virtual organizations: the case of KLM Distribution", "venue": "international conference on systems", "year": 1999, "id": "7f4aea8b-6017-4d01-947d-99c32c7ec48d"}
{"abstract": "Developers contributing to open source projects spontaneously group into \"emerging'' teams, reflected by messages exchanged over mailing lists, issue trackers and other communication means. Previous studies suggested that such teams somewhat mirror the software modularity. This paper empirically investigates how, when a project evolves, emerging teams re-organize themselves-e.g., by splitting or merging. We relate the evolution of teams to the files they change, to investigate whether teams split to work on cohesive groups of files. Results of this study-conducted on the evolution history of four open source projects, namely Apache httpd, Eclipse JDT, Netbeans, and Samba-provide indications of what happens in the project when teams reorganize. Specifically, we found that emerging team splits imply working on more cohesive groups of files and emerging team merges imply working on groups of files that are cohesive from structural perspective. Such indications serve to better understand the evolution of software projects. More important, the observation of how emerging teams change can serve to suggest software remodularization actions.", "authors": ["Sebastiano Panichella", "Gerardo Canfora", "Massimiliano Di Penta", "Rocco Oliveto"], "n_citation": 50, "references": ["013844ba-a0e7-43ef-ab2b-17f78f0ee8cd", "03292aaa-ba6a-4266-a01d-0e7a46dc6586", "0f5fc2db-6621-46e1-8d8c-f82855eefb5d", "269223b9-32c2-47c6-a883-92bd453d7f0d", "3022f75e-4d9d-45bc-b393-dc13b8cf4d51", "3d8ee568-83f5-4b81-afe4-1690632e3e69", "42a88bb2-e1e7-46f1-bc2b-2e170f6549af", "4f1fe3fb-dd0a-4b64-b60a-a7df8348031a", "513c54f3-9252-49e7-8da1-c03670719854", "53649a4b-3941-4221-ae31-c0334a1cfac4", "5ea012d7-e381-44f5-8b83-f833cef3a29a", "7cf5958d-cb7b-4884-aece-fec4570c6b3c", "7f4a790a-a76a-4a4b-9195-65d2dfd05f70", "8171be68-150e-437d-87cc-389036886c53", "aba2e4e2-ef14-4fc7-a8dd-c0d4c907c555", "b306a192-7333-4f62-a21a-42ffebeb9009", "b4eb572a-6f12-42da-a521-4e7f61bbca3b", "cb471966-7f91-4cd7-80f1-1d78c51fb4cf", "cd2d8bd4-62e4-43ca-8eae-f4cfa93a10b0", "d84f5c30-6717-4231-80ab-51f80c8273b8", "da952ef1-2605-4ad8-9612-0554dd4e7046", "f2f65d68-f4db-4267-982c-bcf85e412b35"], "title": "How the evolution of emerging collaborations relates to code changes: an empirical study", "venue": "international conference on program comprehension", "year": 2014, "id": "4cbb46c7-cbaa-4d3b-851c-0720b2324d45"}
{"abstract": "Web sites are complex and heterogeneous systems, characterized by a large number of employed technologies. Evolving these systems requires the skills of a \"renaissance reverse engineer\". In order to assist reverse engineers in their efforts, new program analyses need to be developed that are specifically tailored to the unique task of Web site reverse engineering. To illustrate the design space for program analyses, we introduce a classification based on dichotomies and discuss each of them in the light of Web site reverse engineering. The main contribution of the paper is a better understanding of the program analyses features for Web site reverse engineering.", "authors": ["Holger M. Kienle", "Hausi A. M\u00fcller"], "n_citation": 19, "references": ["00a5de5d-f97a-4c84-ba45-8df47a906411", "181fe0ea-0789-4699-85ac-1b8006db8afe", "200e9c50-c52a-4252-8beb-cb3fee9d0594", "2e2e9d2e-b4f5-4773-8978-94b2d8025d8a", "3862ed0e-6560-4934-adb5-c274c299a61e", "3d847f40-5329-47f0-b336-bc7514a77ebc", "40dc7e80-f055-4c29-8adf-660fb025350e", "4d6e2b43-effe-4f19-b12d-13410e7c1fe1", "4e4e9cf0-59a2-4e1f-b092-7f3a241a9382", "5dde1383-6605-408d-83b8-9b9b5a768aa9", "62b1182c-210f-4837-9009-8c1609ff011e", "6f750ee9-5de1-4942-8b82-daf428659e72", "6fb50604-7867-4939-8d64-5e40a358a4ce", "760f4324-0aee-4f58-ada7-d9ea95157e31", "807e269a-b03e-447b-951c-833dd5a34ec5", "9855fb14-d848-4488-b991-dcec89e4fb48", "9e7f3551-f4b2-496e-8a92-2daa22a155bc", "a143d714-a422-4659-8447-8fc0ac1c6ee5", "a63d0fe7-4bd5-40a3-ad0f-fd489cf30998", "aae28991-2af5-4b6a-8130-69e0db035916", "ad8f2070-0ce2-4cca-9dbf-2b7bc05f036f", "e97088ac-770d-4637-96cf-022e05f816a4"], "title": "Leveraging program analysis for Web site reverse engineering", "venue": "symposium on web systems evolution", "year": 2001, "id": "82197437-0118-46d7-b842-1fee5e4d04e5"}
{"authors": ["Andrew Swan", "Steven McCanne", "Lawrence A. Rowe"], "n_citation": 32, "references": ["14dbcb0a-b6a3-4407-9a3c-0ce575e268c9", "2b30a6ed-15e1-4271-9c91-d7032fd66543", "779cf409-6fe4-4e63-a9fb-d5e067ac01f9", "815396f0-0de6-4784-9014-30467e295cdb", "afe332fa-d8bd-425f-b861-f32a53e2a1f1", "b46af373-5147-4193-9c1d-70adb1f5a527", "b5bf7637-40a1-4390-ba25-6329d57c4084", "d563bff2-b63b-470e-a53f-567f8927dbf4", "f6fc4443-7a98-4f9f-92e8-e4e5d94521a7"], "title": "Layered transmission and caching for the multicast session directory service", "venue": "acm multimedia", "year": 1998, "id": "7b25fdaa-fc50-46bc-b174-f5802fc580fb"}
{"abstract": "We investigate the application of an extension of Kohonen's self-organizing mapping algorithm to the learning of visuo-motor-coordination of a simulated robot arm. We show that both arm kinematics and arm dynamics can be learned, if a suitable representation for the map output is used. Due to the topology-conserving property of the map spatially neighboring neurons can learn cooperatively, which greatly improves the robustness and the convergence properties of the algorithm.", "authors": ["Helge Ritter", "Thomas Martinetz", "Klaus Schulten"], "n_citation": 485, "references": ["0b80498e-e050-4140-a46e-cac5dbad9506"], "title": "Topology-conserving maps for learning visuo-motor-coordination", "venue": "Neural Networks", "year": 1989, "id": "d4f3fc71-3e7b-4044-81c9-42096677fa79"}
{"abstract": "In this brief, modifications of the Schneider operator and the Al-Alaoui-Schneider-Kaneshige-Groutage rule have been explored for the improved performance of the fractional-order differentiator (FOD) in the low-frequency range. The FOD models are obtained using continued-fraction expansion (CFE), and it is observed that the magnitude responses obtained using the CFE outperform the results of the discretizations of FODs based on existing first-order and higher order  s -to- z  transformations in the low-frequency range. The phase responses of the FOD models show a linear response over a part of the low-frequency ranges that can be used for various applications. MATLAB simulation results have been presented to validate the effectiveness of the proposed work. These models can be used for hardware realizations of fractional-order systems.", "authors": ["G. S. Visweswaran", "Pragya Varshney", "Maneesha Gupta"], "n_citation": 5, "references": ["053ddff2-0144-49c7-a9d9-c33ad7128002", "5cd6dd8f-7c4b-45eb-9f80-678eee1cf22c", "63225e29-7e8b-474f-ab07-76a21ea246b7", "b2601d66-6517-4955-beed-73b87d314425", "e28e5d62-33ce-41f4-92a8-5a120fdc44b3", "f6c69456-fce5-472b-bada-070a61168885"], "title": "New Approach to Realize Fractional Power in $z$ -Domain at Low Frequency", "venue": "IEEE Transactions on Circuits and Systems Ii-express Briefs", "year": 2011, "id": "df719f5e-92db-42c0-8090-b8a82ce1f9f0"}
{"abstract": "We present a biologically inspired approach to the dynamic assignment and reassignment of a homogeneous swarm of robots to multiple locations, which is relevant to applications like search and rescue, environmental monitoring, and task allocation. Our work is inspired by experimental studies of ant house hunting and empirical models that predict the behavior of the colony that is faced with a choice between multiple candidate nests. We design quorum based stochastic control policies that enable the team of agents to distribute themselves among multiple candidate sites in a specified ratio, and compare our results to the linear stochastic policies described in (Halasz et al., in Proceedings of the International Conference on Intelligent Robots and Systems (IROS\u201907), pp. 2320\u20132325, 2007). We show how our quorum model consistently performs better than the linear models while minimizing computational requirements and now it can be implemented without the use of inter-agent wireless communication.", "authors": ["M. Ani Hsieh", "\u00c1d\u00e1m M. Hal\u00e1sz", "Spring Berman", "Vijay Kumar"], "n_citation": 72, "references": ["13fc52dc-b393-4671-b70d-ea9a6fed129e", "3107de94-0e53-4049-871e-efba54598fec", "3af59359-8f8a-47da-b79f-613b5a9b9b6b", "76117538-def1-465f-9d04-5872728d6d51", "859fc4be-3548-4d69-be1d-b36f816feda2", "8ea3b88c-00af-4478-95b9-1bf5fac3ac7f", "9355c0ed-88b7-4026-8ea0-a58886878d23", "98c751a8-f31c-4c5b-ac97-db1e986d912b", "a4541d58-b65d-4342-b1aa-1e422093421a", "a4b7f03d-7a42-4697-b2cc-ff1a349351c6", "aba8d723-de51-4547-ad5b-95ab574a1754", "b062eb97-029b-43fe-874a-3d9e66645674", "d3e3b0c3-99ad-4e6d-a588-6fa32652a529", "ee92e9c6-6fcc-40fe-8508-087018d56b9c", "f2143013-8d1c-4f93-9bf5-b9e2908c6ea8", "f361d9ee-9738-45df-b8f4-17de2ea428f7"], "title": "Biologically inspired redistribution of a swarm of robots among multiple sites", "venue": "Swarm Intelligence", "year": 2008, "id": "2bf94b33-0574-438f-ac33-1714b78ed05e"}
{"authors": ["Setsuo Ohsuga"], "n_citation": 50, "references": ["21b0a9d5-ecda-425c-a3c2-927db1d03eba", "77e6cb31-c25a-4535-b23c-21a333784c42"], "title": "Symbol Processing by Non-Symbol Processor", "venue": "pacific rim international conference on artificial intelligence", "year": 1996, "id": "5f6842a4-ba45-4eab-a096-7896b7e197c4"}
{"abstract": "The ordered binary decision diagram is a canonical representation for Boolean functions, presented by R.E. Bryant (1985) as a compact representation for a broad class of interesting functions derived from circuits. However, the size of the diagram is very sensitive to the choice of ordering on the variables; hence, for some applications, such as differential cascode voltage switch (DCVS) trees, it becomes extremely important to find the ordering leading to the most compact representation. An algorithm for this problem with time complexity O(n/sup 2/3/sup n/) is presented. This represents an improvement over the previous best algorithm. >", "authors": ["Steven J. Friedman", "Kenneth J. Supowit"], "n_citation": 336, "references": ["24e88c34-4234-48ae-b2c4-070566e4300f", "7e4a176e-5c7c-475a-b9fa-c1a5c5635a27", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "e0828cdc-729a-4b9f-9b0c-a11aa5789172"], "title": "Finding the optimal variable ordering for binary decision diagrams", "venue": "IEEE Transactions on Computers", "year": 1990, "id": "cdecc1db-2241-4214-8fda-a0170b7338e6"}
{"abstract": "Today, three different physical (PHY) layers for the IEEE 802.11 WLAN are available (802.11a/b/g); they all provide multi-rate capabilities. To achieve a high performance under varying conditions, these devices need to adapt their transmission rate dynamically. While this rate adaptation algorithm is a critical component of their performance, only very few algorithms such as Auto Rate Fallback (ARF) or Receiver Based Auto Rate (RBAR) have been published and the implementation challenges associated with these mechanisms have never been publicly discussed. In this paper, we first present the important characteristics of the 802.11 systems that must be taken into account when such algorithms are designed. Specifically, we emphasize the contrast between  low latency  and  high latency  systems, and we give examples of actual chipsets that fall in either of the different categories. We propose an Adaptive ARF (AARF) algorithm for low latency systems that improves upon ARF to provide both short-term and long-term adaptation. The new algorithm has very low complexity while obtaining a performance similar to RBAR, which requires incompatible changes to the 802.11 MAC and PHY protocol. Finally, we present a new rate adaptation algorithm designed for high latency systems that has been implemented and evaluated on an AR5212-based device. Experimentation results show a clear performance improvement over the algorithm previously implemented in the AR5212 driver we used.", "authors": ["Mathieu Lacage", "Mohammad Hossein Manshaei", "Thierry Turletti"], "n_citation": 768, "references": ["4d994ac6-8a2d-4070-b7de-473dbb2233bb", "98783db9-d399-4537-9eaa-8964f92d99c7", "d2a7d5ad-8d42-402b-9f8f-894eff1b17e2", "e3d09cfb-8e82-4f07-9b2c-0aae3367663d"], "title": "IEEE 802.11 rate adaptation: a practical approach", "venue": "modeling analysis and simulation of wireless and mobile systems", "year": 2004, "id": "3e4101e4-d5e2-4d43-823b-1e577080d308"}
{"abstract": "Abstract   Nearest neighbour rules classify a new data point on the basis of the class of the closest design set point. A prerequisite for this is a choice of metric by which distance may be calculated. Metrics which have been suggested for the two-class case fall into two classes:  global  and  local . In this paper local metrics are described and are generalized to the multi-class case. Properties of various possible generalizations are compared, and the results of a simulation study are described.", "authors": ["James Myles", "David J. Hand"], "n_citation": 85, "references": ["0aacd7ce-475f-4f9c-b53c-45d796f3f906"], "title": "The multi-class metric problem in nearest neighbour discrimination rules", "venue": "Pattern Recognition", "year": 1990, "id": "8febb023-ab10-410e-978c-fd94b96189b5"}
{"abstract": "Software architecture descriptions are high-level models of software systems. Most existing special-purpose architectural notations have a great deal of expressive power but are not well integrated with common development methods. Conversely, mainstream development methods are accessible to developers, but lack the semantics needed for extensive analysis. In our previous work, we described an approach to combining the advantages of these two ways of modeling architectures. While this approach suggested a practical strategy for bringing architectural modeling into wider use, it introduced specialized extensions to a standard modeling notation, which could also hamper wide adoption of the approach. This paper attempts to assess the suitability of a standard design method \"as is\" for modeling software architectures.", "authors": ["Nenad Medvidovic", "David S. Rosenblum"], "n_citation": 88, "references": ["13559fb0-547b-4ec4-816d-1e088fe238f1", "14f8e42e-e2eb-4dfb-9b21-d04453fe8e62", "17efcff5-665b-440c-8664-2faf03a89172", "207cfa96-d888-4f50-9c68-8332f68701b1", "273a8d4c-477e-450f-99aa-47710e9ce1af", "32a9c3fa-fbde-4731-ae01-f45853be60a1", "42ca4968-70cb-4f5b-ab34-df392a502b70", "5ae29b96-5968-4f0a-9f68-8e7b2c334289", "61394dbb-e4c4-4b87-82e0-f0bf109afa4c", "67113b9d-5a7a-4f04-9b81-fe5d2ab00b58", "7f98ff3f-83eb-4aaa-87d2-92df44d5aa68", "85c1de96-97f5-478f-aa27-3c8581595c15", "a13a126e-37f7-4fad-8cfe-a3184320d64a", "a8840afa-a1ab-49f3-990e-e86a398da051", "ba1b9b3f-d911-4ad6-bd03-afa54de2ccee", "c2b3f6cf-ea37-46c1-8143-8c454474f7fa"], "title": "Assessing the Suitability of a Standard Design Method for Modeling Software Architectures", "venue": "working ieee ifip conference on software architecture", "year": 1999, "id": "d1c3f9f5-aed3-4eed-8783-2ecd71aa7bed"}
{"abstract": "We propose a technique for analyzing cache-related preemption delays of tasks that cause unpredictable variation in task execution time in the context of fixed-priority preemptive scheduling. The proposed technique consists of two steps. The first step performs a per-task analysis to estimate cache-related preemption cost for each execution point in a given task. The second step computes the worst case response time of each task that includes the cache-related preemption delay using a response time equation and a linear programming technique. This step takes as its input the preemption cost information of tasks obtained in the first step. This paper also compares the proposed approach with previous approaches. The results show that the proposed approach gives a prediction of the worst case cache-related preemption delay that is up to 60 percent tighter than those obtained from the previous approaches.", "authors": ["Chang-Gun Lee", "Hoosun Hahn", "Y. Seo", "Sang Lyul Min", "Rhan Ha", "Seongsoo Hong", "Chang Yun Park", "Minsuk Lee", "Chong Sang Kim"], "n_citation": 334, "references": ["345d3dcf-970c-40a0-bbec-f83edd8c1ca8", "34a9248a-96ea-427d-835d-85f4c7c9b486", "4978382e-dcaf-453b-887e-cd77a6d33c8b", "533ace90-fd57-4a85-bd79-1ac608fb639a", "57821f58-5cd8-41a7-9371-8bf18a6809ec", "60fc7e5d-637f-4e0c-96c3-24527add14c8", "64cf5873-2a31-4a0e-b091-492f20dd62f9", "6536b436-fd22-4b16-a18a-b75776f74662", "6a66b364-8f41-4bfb-a66b-18ded6864c52", "76d0c79b-c985-4337-a5f6-8ff5c366d749", "80ef8d5d-a257-415f-9bc0-ddc6c983c9a0", "96ff09f7-e819-4de9-aaf8-9eac2f5fa751", "a8900321-d3de-444c-b3dc-cf4ec072733a", "a8f7d0ca-58b4-442f-b7ad-7776c0c3c765", "ae97a9ac-4442-4d04-93e0-9fa367f71386", "c3745e99-e221-4f45-a110-d08147f2537e", "e22a58d1-c683-4c93-bbca-6b75baa90dc2", "e3539cca-e3bb-4c8c-a339-58ac651803b1", "e7513c6d-deb4-4d76-973b-164c4102eb1f", "ec70c332-ec64-4d07-bc89-488594f8166b", "ed89b74e-4e18-4024-bfc4-c4444e3fd18f"], "title": "Analysis of cache-related preemption delay in fixed-priority preemptive scheduling", "venue": "IEEE Transactions on Computers", "year": 1998, "id": "943ec534-91ab-47e4-855e-1aefc0303fd4"}
{"abstract": "We pose the problem of 3D human tracking as one of inference in a graphical model. Unlike traditional kinematic tree representations, our model of the body is a collection of loosely-connected limbs. Conditional probabilities relating the 3D pose of connected limbs are learned from motion-captured training data. Similarly, we learn probabilistic models for the temporal evolution of each limb (forward and backward in time). Human pose and motion estimation is then solved with non-parametric belief propagation using a variation of particle filtering that can be applied over a general loopy graph. The loose-limbed model and decentralized graph structure facilitate the use of low-level visual cues. We adopt simple limb and head detectors to provide \"bottom-up\" information that is incorporated into the inference process at every time-step; these detectors permit automatic initialization and aid recovery from transient tracking failures. We illustrate the method by automatically tracking a walking person in video imagery using four calibrated cameras. Our experimental apparatus includes a marker-based motion capture system aligned with the coordinate frame of the calibrated cameras with which we quantitatively evaluate the accuracy of our 3D person tracker.", "authors": ["Leonid Sigal", "Sidharth Bhatia", "Stefan Roth", "Michael J. Black", "Michael Isard"], "n_citation": 487, "references": ["04d8a9cb-a14d-4ccf-8b19-da1327e86b91", "177b7083-bfca-472b-833a-515f1ad77735", "2a0e501f-fa2d-4ee6-aa42-4fec513372d4", "2cd8042c-88b4-40b6-acfe-b608da036a27", "3eea7845-e0ae-46a7-9e9c-b79e7bff8fce", "4a5d1ed7-1161-4d67-a229-15f98b62a2fd", "4adf54c9-f808-4988-ad8a-bf9cc87c6668", "4f5078b2-5221-47c9-a3eb-84803691e343", "5bb6c752-7222-407e-88a0-b75f707ab87e", "6759555b-95e6-451d-a447-6b395a0db4d5", "6ad1e0f6-2654-4db5-984b-4ec7ef5b6abe", "6e8cc926-79a1-4676-a2bd-f9d49f3144cf", "6f6fe122-6003-498c-a584-b27b3f7a6be3", "772b2b45-8f96-40d3-b428-359db7aaebaa", "779db54d-a398-4ba9-aacf-7fd6cf976dcb", "79622519-07fe-4809-ab3b-90c01d6fce5b", "7f3d9495-7b9e-44ad-a36b-61b8bd7e0e43", "80067f18-2af9-410f-afa1-5237f62b75b0", "9f84e529-87a3-42f1-9d63-9af710f40925", "a1fb7d7f-fb69-468e-8a17-d3c27a36616c", "b5e72744-0105-48bf-95ea-753f52280f48", "b8a86432-fff7-474e-9d72-046c5189e6dc", "c068ed44-dae8-464a-845b-113d70cb33ff", "e649a9fd-f6d9-4aac-b428-29b82c20a484", "ef35a024-f5f3-4a7b-b6f6-61d9167385e6", "f177868f-558f-49bf-b881-ce4f987fe916", "f2230ecb-9b00-43fb-a566-29cf98431d00"], "title": "Tracking loose-limbed people", "venue": "computer vision and pattern recognition", "year": 2004, "id": "98491104-9858-49ed-9620-9ffa7f5a9bb9"}
{"abstract": "A method of localising objects in images is proposed. Possible configurations are evaluated using the contour discriminant, a likelihood ratio which is derived from a probabilistic model of the feature detection process. We treat each step in this process probabilistically, including the occurrence of clutter features, and derive the observation densities for both correct \"target\" configurations and incorrect \"clutter\" configurations. The contour discriminant distinguishes target objects from the background even in heavy clutter, making only the most general assumptions about the form that clutter might take. The method generates samples stochastically to avoid the cost of processing an entire image, and promises to be particularly suited to the task of initialising contour trackers based on sampling methods.", "authors": ["John MacCormick", "Andrew Blake"], "n_citation": 69, "references": ["5bf79dad-2d36-4137-b074-62851e9952e0", "d135cd2a-505f-4571-be8a-2ce936eb4a0a"], "title": "A probabilistic contour discriminant for object localisation", "venue": "international conference on computer vision", "year": 1998, "id": "b9b9ec97-ca63-4349-b23b-9746654f4f87"}
{"abstract": "This paper extends the dual calculus with inductive types and coinductive types. The paper first introduces a non-deterministic dual calculus with inductive and coinductive types. Besides the same duality of the original dual calculus, it has the duality of inductive and coinductive types, that is, the duality of terms and coterms for inductive and coinductive types, and the duality of their reduction rules. Its strong normalization is also proved, which is shown by translating it into a second-order dual calculus. The strong normalization of the second-order dual calculus is proved by translating it into the second-order symmetric lambda calculus. This paper then introduces a call-by-value system and a call-by-name system of the dual calculus with inductive and coinductive types, and shows the duality of call-by-value and call-by-name, their Church-Rosser properties, and their strong normalization. Their strong normalization is proved by translating them into the non-deterministic dual calculus with inductive and coinductive types.", "authors": ["Daisuke Kimura", "Makoto Tatsuta"], "n_citation": 2, "references": ["4fa47055-e721-438a-9302-03687c784a9b", "63ec60e9-80ea-4a13-96f9-a4529d3dc191", "66646c51-ed95-43c3-a145-54653dafc301", "66df01b7-5c88-45d4-b4c3-8e659c7f868d", "78de7817-59e3-4c9b-9a8e-e79388a86740", "97aff6cc-7ce1-438e-86bf-1352b526f361", "a550d06d-8443-49f5-8670-8b62914e941c", "adda8d3e-6b8c-4a22-b544-badef884d80a", "b6c642d8-35b9-4dd4-9c54-1d66dca202ce", "b7e4a9a5-1374-4559-af45-de250196557f", "bc4db2b4-cb93-48ff-8607-9cefe7bcdf9f", "f3a78e9a-30d2-4b1c-8200-ba9a9190eab4"], "title": "Call-by-Value and Call-by-Name Dual Calculi with Inductive and Coinductive Types", "venue": "Logical Methods in Computer Science", "year": 2013, "id": "5bb91ab2-585c-4320-a7a5-cdfa8546979c"}
{"abstract": "Neural networks often surpass decision trees in predicting pattern classifications, but their predictions cannot be explained. This algorithm's symbolic representations make each prediction explicit and understandable. Our approach to understanding a neural network uses symbolic rules to represent the network decision process. The algorithm, NeuroRule, extracts these rules from a neural network. The network can be interpreted by the rules which, in general, preserve network accuracy and explain the prediction process. We based NeuroRule on a standard three layer feed forward network. NeuroRule consists of four phases. First, it builds a weight decay backpropagation network so that weights reflect the importance of the network's connections. Second, it prunes the network to remove irrelevant connections and units while maintaining the network's predictive accuracy. Third, it discretizes the hidden unit activation values by clustering. Finally, it extracts rules from the network with discretized hidden unit activation values.", "authors": ["Rudy Setiono", "Huan Liu"], "n_citation": 233, "references": ["3291e54c-773c-412a-93b0-666345f8499e", "42bd4971-02a1-4755-b685-6d350b378e98", "70d22077-68e8-4eb1-a955-5b1c5b59cb4a", "90cc5b69-db76-4753-997e-1961d8d97ec7", "bb4cbdf3-429f-48a4-a3b2-7f6dc12ec41a"], "title": "Symbolic representation of neural networks", "venue": "computational science and engineering", "year": 1996, "id": "8dd58747-a54a-4239-82e7-acea906a83a4"}
{"abstract": "Speculative partial redundancy elimination (SPRE) uses execution profiles to improve the expected performance of programs. We show how the problem of placing expressions to achieve the optimal expected performance can be mapped to a particular kind of network flow problem and hence solved by well known techniques. Our solution is sufficiently efficient to be used in practice. Furthermore, the objective function may be chosen so that reduction in space requirements is the primary goal and execution time is secondary. One surprising result that an explosion in size may occur if speed is the sole goal, and consideration of space usage is therefore important.", "authors": ["Bernhard Scholz", "R. Nigel Horspool", "Jens Knoop"], "n_citation": 25, "references": ["094f8a81-158b-4a44-90a8-e90e29277cd1", "09cad2fe-116c-4645-9e42-f2cba3d6dc4c", "3797a217-9755-487d-a46f-37a45a31e5ec", "4ba9bdd7-00e2-4b6a-8667-d90a49e08601", "78f0682e-5ec4-47e5-b77a-6842fb2f3c10", "807f3474-8c10-401e-8f4c-a5c6c391019f", "8ff9ee21-dda6-4cef-9083-817b53687a5c", "b7dd249d-3106-4fa8-a077-6a9a19432c10", "d777c73d-0b5b-4de8-816f-c108655404a5", "ef8583c7-6889-45f6-8b77-52098f4d73c0", "f5de6b41-0df8-4270-8211-a67a081dad45", "f6820b0c-0c79-41b9-b465-a032f14368ab", "f8ec7b2a-d699-42be-a404-b257a91c8985"], "title": "Optimizing for space and time usage with speculative partial redundancy elimination", "venue": "languages, compilers, and tools for embedded systems", "year": 2004, "id": "d7980a4c-8920-48ce-95bb-14b9ab4cda1e"}
{"abstract": "We propose a randomized method for the detection of symmetry in polyhedra without assuming the predetermination of the centroids of the objects. Using a voting process, which is the main concept of the Hough transform in image processing, we transform the geometric computation for symmetry detection based on graph theory, to the peak detection problem in a voting space in the context of the Hough transform.", "authors": ["Atsushi Imiya", "Tomoki Ueno", "Iris Fermin"], "n_citation": 50, "references": ["0aed440e-6b5c-4bda-a921-6d68fbe2ab90", "1c2f0008-7535-49de-8e9f-400a8b3b7fc6", "281268c5-8c0f-4e2d-abdf-6e1fa17fed48", "5e58010e-caeb-4c75-a4e1-3c63498e5ed8", "64ee9434-ab91-4e06-88d9-9ee17824134b", "fec56a7f-3b22-41bb-9f35-f82b0d68d27c"], "title": "Symmetry detection by random sampling and voting process", "venue": "international conference on image analysis and processing", "year": 1999, "id": "062da24d-a008-49b2-b2af-56ec1a61fe40"}
{"abstract": "With the advent and subsequent popularity of portable computers, power management of system components has become an important issue. Current portable computers implement a number of power reduction techniques to achieve a longer battery life. Included among these is spinning down a disk during long periods of inactivity. In this paper, we perform a quantitative analysis of the potential costs and benefits of spinning down the disk drive as a power reduction technique. Our conclusion is that almost all the energy consumed by a disk drive can be eliminated with little loss in performance. Although on current hardware, reliability can be impacted by our policies, the next generation of disk drives will use technology (such as dynamic head loading) which is virtually unaffected by repeated spinups. We found that the optimal spindown delay time, the amount of time the disk idles before it is spun down, is 2 seconds. This differs significantly from the 3-5 minutes in current practice by industry. We will show in this paper the effect of varying the spindown delay on power consumption; one conclusion is that a 3-5 minute delay results in only half of the potential benefit of spinning down a disk.", "authors": ["Kester Li", "Roger Kumpf", "Paul Horton", "Thomas E. Anderson"], "n_citation": 339, "references": ["30ccc346-4179-4134-b24a-f09ac9f61532", "5520e73e-d943-43fd-a6f2-88032a1ee589", "5f8523ec-679b-4e6a-87c6-80bde42e6ae5"], "title": "A Quantitative analysis of disk drive power management in portable computers", "venue": "", "year": 1994, "id": "9ada4e4d-dfeb-4ed6-b7b7-1e9464a771b3"}
{"abstract": "We study  fairness in classification , where individuals are classified, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classifier (the university). The main conceptual contribution of this paper is a framework for fair classification comprising (1) a (hypothetical) task-specific metric for determining the degree to which individuals are similar with respect to the classification task at hand; (2) an algorithm for maximizing utility subject to the  fairness constraint , that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of \"fair affirmative action,\" which guarantees  statistical parity  (i.e., the demographics of the set of individuals receiving any classification are the same as the demographics of the underlying population), while treating similar individuals as similarly as possible. Finally, we discuss the relationship of fairness to privacy: when fairness implies privacy, and how tools developed in the context of differential privacy may be applied to fairness.", "authors": ["Cynthia Dwork", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Richard S. Zemel"], "n_citation": 117, "references": ["01797f9d-59b3-4b28-b671-5b47592c097e", "1d4a25e1-b016-4600-baef-04fea1b2da49", "2ff1b7e9-ea63-47d2-bab5-64115f5a015a", "38933779-8489-43cf-bacd-5006410255f8", "396c6192-d592-41a9-a37e-9bc3efa5dfd7", "400d44a7-39be-4782-a000-36a3e8202ea5", "6a848f3a-6cfa-413e-8f21-a324fcdfa0bb", "70f4dcf0-2784-4627-899c-1463988a3f52", "9a9042ef-19fd-4cc4-90db-059122355179", "b295b49c-25f5-4b77-b72e-4b63f4d09678", "bd3a3a31-46b2-420d-ba03-057ac8ead4b2"], "title": "Fairness through awareness", "venue": "arXiv: Computational Complexity", "year": 2012, "id": "11ecafb3-ea19-480f-8831-c3526832cea4"}
{"abstract": "In this paper, we present an efficient method for automatically generalizing programs written in spreadsheet languages. The strategy is to do generalization through incremental analysis of logical relationships among concrete program entities from the perspective of a particular computational goal. The method uses deductive dataflow analysis with algebraic back-substitution rather than inference with heuristics, and there is no need for generalization-related dialog with the user. We present the algorithms and their time complexities and show that, because the algorithms perform their analyses incrementally, on only the on-screen program elements rather than on the entire program, the method is scalable. Performance data is presented to help demonstrate the scalability.", "authors": ["Margaret M. Burnett", "Sherry Yang", "Jay W. Summet"], "n_citation": 50, "references": ["072af24c-e352-4d96-8357-c96d1ccdc6c1", "0ac4c721-5584-457a-8043-e904f5a1883c", "1457844a-add0-4c01-b2d1-988453cb177c", "170b47c0-4b39-4225-b174-2291e1184986", "1cc2bd28-62c5-4ff1-aa06-6f10eaca5ed0", "2c749618-cc1b-4b2d-8ccd-3f073a6b2cfb", "41b5cb43-3a4b-499e-acc4-5ac185e74334", "457b883d-6598-42c9-beaa-a5c1ffcd2d20", "4dcb4779-72c3-41b1-b577-f9361906218b", "5c9eb24d-c594-44ae-a61b-1983f1b31834", "5f1cba39-ad4c-475d-812a-148a2bad122e", "6768c76b-4853-4821-a7fb-873f795557db", "82e7cbea-1041-48c7-93a0-1ca5b5dc28e6", "8a69c1e6-f07e-4941-965a-54e19201d2c3", "91a6e4b8-c2b3-4b9b-9539-4a35f0ca723a", "9323182f-7284-4d71-a4ea-0350aff459da", "9662e467-5667-4871-92b5-078fd2e19045", "a7d9e8aa-520e-483b-9506-5c1e95aa7521", "ad172799-b14e-4d79-b85b-b889f8afe02b", "ce91caf9-d9f8-47a4-85eb-d9e2aeb6f65f", "d1852dab-8b84-4b25-8498-00983fcb357c", "dcd4f7c2-2b3b-400b-a536-ce6db5f8de5a", "fa5fcb12-5a8d-4569-8b00-043054fee9cc", "fc081e1c-a901-4ee5-b6ae-92e49d033d94"], "title": "A scalable method for deductive generalization in the spreadsheet paradigm", "venue": "ACM Transactions on Computer-Human Interaction", "year": 2002, "id": "6514cedc-a2b2-4cb5-97be-845e28145c7c"}
{"abstract": "Artificial Evolution Based Autonomous Robot Navigation Evolvable Hardware in Evolutionary Robotics FPGA-Based Autonomous Robot Navigation via Intrinsic Evolution Intelligent Sensor Fusion and Learning for Autonomous Robot Navigation Task-Oriented Developmental Learning for Humanoid Robots Bipedal Walking Through Reinforcement Learning Swing Time Generation for Bipedal Walking Control Using GA Tuned Fuzzy Logic Controller Bipedal Walking: Stance Ankle Behavior Optimization Using Genetic Algorithm.", "authors": ["Lingfeng Wang", "Kay Chen Tan", "Chee Meng Chew"], "n_citation": 37, "title": "Evolutionary Robotics: From Algorithms to Implementations", "venue": "", "year": 2006, "id": "8adc1e67-cf28-4127-a61b-b929320a2521"}
{"authors": ["Jeen Broekstra", "Arjohn Kampman", "Frank van Harmelen"], "n_citation": 84, "references": [], "title": "Sesame: An Architecture for Storin gand Querying RDF Data and Schema Information.", "venue": "", "year": 2003, "id": "aa2a0349-f874-4fde-b79f-ca82890d04c7"}
{"abstract": "This paper describes the Intentional Planning System(ItPlanS) an incremental, hierarchical planner that uses a series of experts to develop plans. This system takes seriously the concept of the context sensitivity of actions while working in a resource bounded framework.", "authors": ["Christopher W. Geib"], "n_citation": 50, "references": ["015b8db1-b997-47bb-9b26-4bfd9c4a0e75", "17d1ecd0-224c-484d-b35c-0d6d13e89558", "2329ae1f-1062-4504-9ef1-45d9e5c0dd2e", "46bb8dc7-0793-4dd4-b9cf-a20bc25930a2", "4f93c731-1c76-4a32-bbd8-c97001c57118", "67e983a6-1b1f-41b6-b418-5509db1d0508", "9636f9cd-0a36-44a3-a04a-b33ec8fc6ea0", "bdd72f1c-6df6-4069-bb3a-40a82dfc9065", "de785736-6f18-4b87-8748-cc4a14073b2e", "ee4bbc14-80ef-4bb0-9ec8-ce8f7be6d11c", "fe537d93-5826-48ec-a1c5-8728d60b2167"], "title": "The Intentional planning system: ItPlanS", "venue": "", "year": 1994, "id": "986ca74d-84c5-4c65-8539-3556bc121696"}
{"abstract": "Abstract#R##N##R##N#We consider the problem of generating permutations almost uniformly at random in distributed and parallel systems. We propose a simple distributed scheme for permuting at random, which we call distributed mixing, and provide its precise stochastic analysis. Our main result is that distributed mixing needs \u0398(log\u2009n) simple point-to-point communication rounds to generate a permutation almost uniformly at random. We further apply distributed mixing to design very fast parallel algorithms for OCPC and QRQW parallel computers (with runtimes (log\u2009log\u2009n) and , respectively). Our analysis of distributed mixing is based on the analysis of the mixing time of the Markov chain governing the process. The main technical tool developed in the paper is a novel method of analyzing convergence of Markov chains. Our method, called delayed path coupling, is a refinement of the classical coupling technique and the path coupling technique of Bubley and Dyer, and its main, novel feature is the use of possible non-Markovian coupling.\u00a0\u00a9 2000 John Wiley & Sons, Inc.\u00a0Random Struct. Alg., 17: 238\u2013259, 2000", "authors": ["Artur Czumaj", "Miros\u0142aw Kuty\u0142owski"], "n_citation": 22, "references": ["035d2bb9-16d0-4fc6-9492-157b5f39705c", "07cf1b56-6519-449f-a31d-a5c3b6a60e65", "1921219f-be39-4369-851a-3df0f495e7b1", "1f9e3e38-eddf-4f8a-b06c-a09a6f67d76c", "562a834a-d414-4992-b74b-452e6641d71e", "5a13621e-7eae-404d-acc6-0830b8c7f1ac", "8e871176-7529-4575-a402-f3a1a6b87fb5", "95a087a2-df62-4142-876b-7c35d984f62c", "9ba84ef8-4c14-4702-ad12-56623d13ecf2", "afe64efb-2c57-4d75-bc78-c6b597dcfac3", "b39ebd07-a487-4651-81f7-d044fe17ac65", "b51db4fa-6b00-44f7-b60a-4d2a7a12cc1a", "c1167e88-960a-40af-a304-1cf26268a3f5", "c3cac5ab-fa29-4961-baab-301a1eba9a5b", "ceed1b9c-f2c9-4b01-957f-3a4f697e779e", "d1149def-2f19-4336-8948-eefeab010efd", "e621c2e4-5f84-46d8-b714-25e5897ad659"], "title": "Delayed path coupling and generating random permutations", "venue": "Random Structures and Algorithms", "year": 2000, "id": "2be72cac-2b11-4330-92a7-aabb520e388d"}
{"abstract": "The liberalisation of the telecommunications industry has resulted in a proliferation of new services and services providers. This is particularly the case in the rapidly expanding IP-based services market. Providers include ISPs, virtual private network (VPN) and application service providers, and backbone operators. The final service set delivered to the customer will result from the combination of these service offerings. From a service usage accounting perspective, this new environment creates a number of important challenges, which did not apply in the traditional monopolistic telecommunications environment. The first issue is that of multiple administrative domains from the customer and service provider side and the second issue concerns applying customer service level agreements (SLA) and quality of service (QoS). This paper addresses the issue of settlement of usage charges across several service providers when they collectively provide services to customers. The main issue is to develop standardised mechanisms that allow various business and operation support systems operating in various domains to exchange accounting information. The work presented in this paper focuses on the development of a business-to-business (B2B) service provisioning and management architecture to provide guidance to international organisations on the development of a federated accounting management solution. This architecture aims to be both open and adaptable and is based on standardisation work going on in TMForum (TeleManagement Forum), IPDR (IP detail record), IETF and ETSI (European Telecommunication Standardisation Institute).", "authors": ["Bharat Bhushan", "Michael Tschichholz", "Eric Leray", "Willie Donnelly"], "n_citation": 25, "references": [], "title": "Federated accounting: service charging and billing in a business-to-business environment", "venue": "integrated network management", "year": 2001, "id": "bf022e85-d594-44aa-98fe-eaedee8326a7"}
{"abstract": "Noise reduction and signal decomposition are among important and practical issues in time-domain signal analysis. This paper presents an adaptive notch filter (ANF) to achieve both these objectives. For noise reduction purpose, the proposed adaptive filter successfully extracts a single sinusoid of a possibly time-varying nature from a noise-corrupted signal. The paper proceeds with introducing a chain of filters which is capable of estimating the fundamental frequency of a signal composed of harmonically related sinusoids, and of decomposing it into its constituent components. The order of differential equations governing this algorithm is 2n+1, where n is the number of constituent sinusoids that should be extracted. Stability analysis of the proposed algorithm is carried out based on the application of the local averaging theory under the assumption of slow adaptation. When compared with the conventional Fourier analysis, the proposed method provides instantaneous values of the constituting components. Moreover, it is adaptive with respect to the fundamental frequency of the signal. Simulation results verify the validity of the presented algorithm and confirm its desirable transient and steady-state performances as well as its desirable noise characteristics", "authors": ["Mohsen Mojiri", "Masoud Karimi-Ghartemani", "Alireza Bakhshai"], "n_citation": 146, "references": ["00bfb903-749f-4cdf-8720-bdf683d0d364", "11d1a808-d8c9-4c0a-87dc-184cfbb4768e", "35006095-f692-4d06-86ce-a06b3cf5a470", "53eb436b-27a6-4497-86a9-364a7cbabbc4", "6a3e8290-a664-4120-b6f1-17ee4e70d76a", "84f4eb58-973c-4056-8c34-713cb8cf8a2b", "87acf786-a01d-47e5-9e8f-57d3705b7feb", "8ce40fec-1fc2-4a5d-96da-fbf814a7ab4c", "d5b77f79-a18d-4607-ad3e-763f029786bb"], "title": "Time-Domain Signal Analysis Using Adaptive Notch Filter", "venue": "IEEE Transactions on Signal Processing", "year": 2007, "id": "703fdf92-a853-47ab-b280-40728e8fc2fd"}
{"abstract": "In this paper we study the impact of sharing memory resources on five Google datacenter applications:  a web search engine, bigtable, content analyzer, image stitching , and  protocol buffer . While prior work has found neither positive nor negative effects from cache sharing across the PARSEC benchmark suite, we find that across these datacenter applications, there is both a sizable benefit and a potential degradation from improperly sharing resources. There are four main contributions of this paper. First, we present a study of the importance of thread-to-core mapping for applications in the datacenter as threads can be mapped to share or to not share caches and bus bandwidth. Second, we investigate the impact of co-locating threads from multiple applications with diverse memory behavior and discover that the best mapping for a given application changes de- pending on its co-runner. Third, we investigate the application characteristics that impact performance in the various thread-to-core mapping scenarios. Finally, we present both a heuristics-based and an adaptive approach to arrive at good thread-to-core decisions in the datacenter. We observe performance swings of up to 25% for web search, and 40% for other key applications, simply based on how application threads are mapped to cores. By employing our adaptive thread to core mapper the performance of the datacenter applications presented in this work improved by up to 22% over status quo thread-to-core mapping and performs within 3% of optimal.", "authors": ["Lingjia Tang", "Jason Mars", "Neil Vachharajani", "Robert Hundt", "Mary Lou Soffa"], "n_citation": 194, "references": ["08f93e66-54ba-4cd1-9224-730024fe01b0", "0ee52d92-42d1-484e-8087-1b2f68bb0e6d", "18effa91-f8d5-47ee-85ef-0e1d475d6f3c", "20d28824-b9e3-4ab2-a7e4-9b3c4ac9a5f4", "26d36318-b26e-4bfd-adfb-a64c05a456b0", "2abfd6e5-3aaa-4035-9a2f-fd98bf90a2f3", "361c3a64-526a-406b-8d96-aff900ac6b77", "39b27ab1-a6b6-4150-982f-4e48923b860f", "437b6b56-a171-42dd-adce-5be215a3d2e1", "43cfca2e-5b03-42a5-9b52-d3a501197909", "48dc88de-40b9-44e8-a053-bdc77c6fc2a9", "4b09b11f-23d7-485d-ade9-03c90437a56e", "513731aa-8974-4ead-9f5e-8b1e42a73ec9", "5c3aa45d-fc98-43fc-a12c-9746bddaf575", "6374a07c-68d4-4cb7-bd48-f0700e80ef74", "6800b161-56e7-435b-b8cb-5c9f0d1ca3aa", "6be1ce76-89bd-4864-9f61-3072c1a735fa", "7169d097-a1a1-46d5-b40d-76dce80aca65", "77691a42-06b4-46df-af97-eeb6dea5eb81", "883f8c8f-64de-4b3f-aaac-1ffd85047b7f", "8e7ffd7a-b92a-4847-9d91-d8593480be74", "a0cfbea4-310b-4762-a451-6b8b58391e4e", "a46df235-07d9-4733-b5e9-8ccb8918c160", "a54aa36a-7e37-4b79-867e-fb4490a4d019", "b09518f6-cd8a-4af0-b01f-60a65b696293", "b3c24160-07e9-4a45-923e-20927c8fa31a", "b5c489ec-d2dd-4f80-900d-25e7fbcecb76", "b9a9d962-dbcc-4776-af6d-25f7d2b313d6", "b9b3f626-0528-46ce-b60e-71ed6c6f6491", "bb19a1a3-f510-46d4-893f-367220f6b2bd", "be051095-a939-49a5-b890-0780b13cea77", "c7967aba-9e39-4f16-bc70-90f11c61a3ea", "d619d941-098d-4fda-80bc-729745ad3090", "eacccf86-09e1-49db-92db-ba42cd1b10ff", "edfb71c4-2133-4c9b-a61a-c082852e3dfa", "f1fbf0f2-ff32-48e0-8486-1cf9f6616c76", "f93c3355-978f-411b-bd5a-8d262fa7bddf", "fa23f481-d712-4e36-8495-47e7076f240c", "faf6f023-8f76-4c49-9d14-5230d81d8b60", "fe44131d-b5b3-423b-8fb3-fdd0797800ac"], "title": "The impact of memory subsystem resource sharing on datacenter applications", "venue": "international symposium on computer architecture", "year": 2011, "id": "a9afc4a6-3209-4bb7-af95-8240471af883"}
{"authors": ["Michel Sintzoff"], "n_citation": 50, "references": ["092b6453-1fec-467b-8b7d-1622130e908e", "093e42e3-bbac-49ea-90e7-71d784b572ba", "12afab5a-8673-482d-8dbc-964fd67b0809", "58545ad6-a13e-4cb7-a1c8-05b906df4a5d", "84fa03c4-9f04-407a-b6f5-e51571cf6fa8", "aa8cc63e-60f1-4686-be4a-85253428a2df", "c0c9b5bd-3a28-435b-ac30-d1aede2e3b28", "c942b45f-fb61-43da-8e2f-051d7a8a91ee", "fe8b6639-5345-444d-93ad-e3fbcf3e6239"], "title": "Suggestions for Composing and Specifying Program Design Decisions", "venue": "", "year": 1980, "id": "8784865e-408e-46d5-9f20-b68dd6aab36e"}
{"abstract": "In this paper, a new method of fuzzy decision trees called soft decision trees (SDT) is presented. This method combines tree growing and pruning, to determine the structure of the soft decision tree, with refitting and backfitting, to improve its generalization capabilities. The method is explained and motivated and its behavior is first analyzed empirically on 3 large databases in terms of classification error rate, model complexity and CPU time. A comparative study on 11 standard UCI Repository databases then shows that the soft decision trees produced by this method are significantly more accurate than standard decision trees. Moreover, a global model variance study shows a much lower variance for soft decision trees than for standard trees as a direct cause of the improved accuracy.", "authors": ["Olaru C", "Louis Wehenkel"], "n_citation": 395, "references": ["2aea0eff-604e-4f3b-9f74-b5c21b7fcc32", "4fb54659-e114-4670-93da-40caea09e193", "5a2dadbd-e3c3-4261-ae7d-e2a40da120e9", "5c223661-ab2b-4201-83c6-965bef8690bd", "62549bc2-e0b3-46e8-8d32-390dded105d5", "6c871065-76b8-44f3-97d5-ac3bce951421", "839729e8-fc43-44bd-bc73-c30738d01648", "8caa574b-42cd-4703-8452-64aef1ad87a1", "9f5b83b1-9544-4e49-9e95-007bdabd4f2b", "a811c8d7-f015-458d-ae38-fb25ec584b8a", "b0efb9f1-ef31-4aa2-a6e4-0f81a78315ce", "b49c1e2b-0cd0-4950-a724-00c698e5b49d", "b9d06971-6031-401d-a27d-a9cd8d1c5462", "c1523896-7db7-4088-a54f-cf046da6ba25", "d129481b-d4f7-423c-9ccc-799b984f35c4", "dcd9d334-ec87-46cf-98ae-22d940b98a27", "f1185517-5d86-41e4-8155-9af643e459d5", "f2f2f45f-53c0-4b76-9031-42bc472befd6"], "title": "A complete fuzzy decision tree technique", "venue": "Fuzzy Sets and Systems", "year": 2003, "id": "63d57efd-eebd-4d25-9ca7-3191903a7387"}
{"abstract": "We study clustering algorithms for data with Boolean and categorical attributes. We show that traditional clustering algorithms that use distances between points for clustering are not appropriate for Boolean and categorical attributes. Instead, we propose a novel concept of links to measure the similarity/proximity between a pair of data points. We develop a robust hierarchical clustering algorithm, ROCK, that employs links and not distances when merging clusters. Our methods naturally extend to non-metric similarity measures that are relevant in situations where a domain expert/similarity table is the only source of knowledge. In addition to presenting detailed complexity results for ROCK, we also conduct an experimental study with real-life as well as synthetic data sets. Our study shows that ROCK not only generates better quality clusters than traditional algorithms, but also exhibits good scalability properties.", "authors": ["Sudipto Guha", "Rajeev Rastogi", "Kyuseok Shim"], "n_citation": 2159, "references": ["010793c8-fedb-49ee-88bc-1e20f8bae870", "7ff41e6e-42c9-489f-acf7-46f42f04a5d2", "bdb8d83d-1771-4399-b593-d43be5a9f892", "e1e95cfd-76f7-479c-8a39-ab711d18fd7c"], "title": "ROCK: a robust clustering algorithm for categorical attributes", "venue": "international conference on data engineering", "year": 1999, "id": "0d5275a0-bdd7-41c6-99fa-25809e761cb1"}
{"abstract": "Continuous evolution towards very large, heterogeneous, highly dynamic computing systems entails the need for sound and flexible approaches to deal with system modification and re-engineering. The approach proposed in this paper combines an analysis stage, to identify concrete patterns of interaction in legacy code, with an iterative re-engineering process at a higher level of abstraction. Both stages are supported by the tools CoordPat and Archery, respectively. Bi-directional model transformations connecting code level and design level architectural models are defined. The approach is demonstrated in a (fragment of a) case study.", "authors": ["Alejandro Sanchez", "Nuno Oliveira 0001", "Lu\u00eds Soares Barbosa", "Pedro Rangel Henriques"], "n_citation": 4, "references": ["0a16ca86-6d27-4cb7-9fc7-34aa6a3dc4c7", "10e652b2-c8f0-48c7-9119-07516b0ba630", "1412ff23-1344-4034-87ac-344cc850f0b3", "186e639f-59fd-4edb-be67-e84ce75a5a32", "1ef74256-a040-47b4-81a2-8ab106c83bb7", "23e01944-f663-4695-b1a7-2d01aeec7354", "2e3e7506-a83b-4f24-a812-75eb904e511b", "3a810c25-dc8d-4ad9-9e31-51aeb72c6578", "3f7ad23c-139d-425e-ad5e-ebd19ef2d841", "42ea6086-62ba-4bfa-b59c-4e454c848818", "4a21ecbb-183c-40b5-a95d-b833503c0694", "4bfa477e-e620-4c05-acdc-03055b00747d", "61394dbb-e4c4-4b87-82e0-f0bf109afa4c", "6ed85bc5-b398-416e-94ee-901a354f8d22", "7437ddcc-4bfc-4677-b5bc-8c3bb7ecd64d", "79798bf1-3d66-47a8-819b-d1d8b7a9b3ce", "80d75963-4e58-4367-b841-e131327a6376", "85c1de96-97f5-478f-aa27-3c8581595c15", "8a3272b7-50ab-4b40-9807-1eb6a12f28ff", "93b22478-94f8-4c15-ae03-ed98a856f60c", "97103f73-da4a-42a3-a360-c03c5a7cfd5b", "9806b964-9cf3-4cba-b8e6-07904adf7be8", "9e7e66fa-bbb3-431f-8b73-03e5f26fb837", "9eb223dc-2634-4917-b9b2-4d937fa36513", "a0092b61-7207-4950-8e22-83fed67da31a", "abde5ea1-99dc-4812-aa90-50f17478138f", "bbe45468-c69c-4794-a54f-856d31e96ca1", "c898979b-eed2-49f4-abed-cf1ccc348b96", "db9aec0d-fcd8-4b07-833b-3a4ce5a2a1c4", "dc98562f-e69f-4522-9123-8dbab20ffb33", "ded73f0a-0715-469f-b384-a98cc070a908", "e1f953ea-fac4-407a-8a80-eac6bca2822a", "f9e2163f-1816-4267-aaee-c152e723390c", "f9fbe00e-2980-4c0e-a9b1-4e62fd5fa383"], "title": "A perspective on architectural re-engineering", "venue": "Science of Computer Programming", "year": 2015, "id": "1eff0c41-25fd-4dc1-81bb-68f0ef82eb39"}
{"authors": ["Nir Shavit", "Dan Touitou"], "n_citation": 35, "title": "Elimination Trees and the Construction of Pools and Stacks", "venue": "acm symposium on parallel algorithms and architectures", "year": 1995, "id": "0977e7a2-8ae5-40b6-bf45-d1f0e66eadc3"}
{"abstract": "Firewall is the de facto core technology of today's network security and defense. However, the management of firewall rules has been proven to be complex, error-prone, costly and inefficient for many large-networked organizations. These firewall rules are mostly custom-designed and hand-written thus in constant need for tuning and validation, due to the dynamic nature of the traffic characteristics, ever-changing network environment and its market demands. One of the main problems that we address in this paper is that how much the firewall rules are useful, up-to-dated, well-organized or efficient to reflect the current characteristics of network traffics. In this paper, we present a set of techniques and algorithms to analysis and manage firewall policy rules: (1) Data Mining technique to deduce efficient firewall policy rules by mining its network traffic log based on its frequency, (2) Filtering-Rule Generalization (FRG) to reduce the number of policy rules by generalization, and (3) a technique to identify any decaying rule and a set of few dominant rules, to generate a new set of efficient firewall policy rules. The anomaly detection based on the mining exposes many hidden but not detectable by analyzing only the firewall policy rules, resulting in two new types of the anomalies. As a result of these mechanisms, network security administrators can automatically review and update the rules. We have developed a prototype system and demonstrated usefulness of our approaches.", "authors": ["Korosh Golnabi", "Richard Min", "Latifur Khan", "Ehab Al-Shaer"], "n_citation": 106, "references": ["09abd09b-1156-41fd-a9ee-1ff63ce415e4", "194dc0f0-56c1-41db-ba3b-39d48dd2aed1", "686ff2e7-daa0-4438-a853-abb392b687fb", "709b0146-7a6a-4f7e-84fd-8910c2569fa6", "715327e6-a94c-429c-8ad4-6b0a92ad83c2", "7198c55c-806a-4309-811e-529ecd537cbe", "74124cdf-4269-4256-a3a6-04e14437e201", "847f2e32-21c0-49ae-9795-f7005a17e85f", "8c6ad07d-527d-4d26-b38b-3e764c868228", "8f9fd5f8-8c16-47ef-9b13-e03e201b132e", "913d9a74-f021-42ba-8e8f-8a354a40a4ce", "9264577f-a51a-4b18-8c27-c4fecff9794a", "929abc46-4b62-459b-a972-caa1d09e0fcc", "9476cdfd-bd71-44a9-b759-5b6c994e546d", "ac88da07-ade7-40cb-9e6c-b6667525c09a", "c129e2b2-6aaa-42cf-a26a-b89740531e0b", "d3873a9a-46df-4d21-85f1-079f404d320f", "ec129a04-1877-4223-9669-ec6921cf75af", "ecd6a845-8439-49b0-abe8-f71fff81da23", "ee3a15e2-3731-437c-9bf7-3fa3a37cdc89", "f3bb8e7a-35ed-486c-97b0-a45c2c2234d0"], "title": "Analysis of Firewall Policy Rules Using Data Mining Techniques", "venue": "network operations and management symposium", "year": 2006, "id": "24617c8d-ae47-4cca-8105-e9075dd71984"}
{"abstract": "We propose a novel approach for organizing and describing e-government services on the envisioned Semantic Web. We combine the emerging concepts of Web services and ontologies to cater for Semantic Web enabled e-government services. This would lay the ground for the automatic selection, interoperation, and composition of e-government services.", "authors": ["Brahim Medjahed", "Athman Bouguettaya", "Mourad Ouzzani"], "n_citation": 17, "references": ["72be3263-98de-48d8-9f6e-647e33366ef4"], "title": "Semantic web enabled e-government services", "venue": "", "year": 2003, "id": "b1253506-1415-4546-aa32-387e5c4a46e9"}
{"abstract": "This paper describes an application of nonlinear decentralized robust control (Guo, Jiang & Hill, 1998) to large-scale power systems. Decentralized power controllers are designed explicitly to maintain transient stable closed-loop systems. For the first time, nonlinear bounds of generator interconnections are used which achieves less-conservative control gains. The proposed controllers are robust with regard to uncertain network parameters and attenuate the persistent disturbances in the sense that the L\"2-gain from the disturbance to the power frequency is reduced to a certain level. Simulations on a two-generator infinite bus power system exhibit enhancement of system transient stability at different conditions of operation points, fault locations and network parameters.", "authors": ["Yi Guo", "David J. Hill", "Youyi Wang"], "n_citation": 282, "references": ["03e98e25-8ef5-44bb-afd5-0c63b2b8c46f", "15964df9-175f-4392-8a7a-b3c4aeda0e1e", "8e1f94ec-71a9-47b4-a95d-1c9695f904db"], "title": "Nonlinear decentralized control of large-scale power systems", "venue": "Automatica", "year": 2000, "id": "af1ae334-c667-4139-8bb7-0bcdbd396fc9"}
{"abstract": "According to the demand of communication between equipments in vehicle and external network in VANET, this paper designs and implements a multimode wireless gateway based on Embedded system. The hardware uses ARM11 microprocessor, S3C6410, as controller and integrates 3G module, IEEE802.11g module and Bluetooth module. The software is based on Embedded Linux, develops drivers of integrated modules and user applications, and realizes the function of protocol conversion and routing. With the gateway design in this paper, equipments with different wireless techniques in vehicle can interconnect and have access to external networks including 3G network and WLAN.", "authors": ["Yunchuan Mao", "Weiwei Xia", "Yi Wu", "Lianfeng Shen"], "n_citation": 1, "references": ["1f521781-7a31-4843-a158-2d0dfb61ec8d", "b16b3411-d9ce-4a9f-9d65-1a12bcfe7185"], "title": "Designing and implementing of multimode wireless gateway in VANET", "venue": "", "year": 2012, "id": "d1af9d35-28a7-462c-9243-000e35dff013"}
{"abstract": "A key functionality in today's widely used interior gateway routing protocols such as OSPF and IS-IS involves the computation of a shortest path tree (SPT). In many existing commercial routers, the computation of an SPT is done from scratch following changes in the link states of the network. As there may coexist multiple SPTs in a network with a set of given link states, such recomputation of an entire SPT not only is inefficient but also causes frequent unnecessary changes in the topology of an existing SPT and creates routing instability. This paper presents a new dynamic SPT algorithm that makes use of the structure of the previously computed SPT. This algorithm is derived by recasting the SPT problem into an optimization problem in a dual linear programming framework, which can also be interpreted using a ball-and-string model. In this model, the increase (or decrease) of an edge weight in the tree corresponds to the lengthening (or shortening) of a string. By stretching the strings until each node is attached to a tight string, the resulting topology of the model defines an (or multiple) SPT(s). By emulating the dynamics of the ball-and-string model, we can derive an efficient algorithm that propagates changes in distances to all affected nodes in a natural order and in a most economical way. Compared with existing results, our algorithm has the best-known performance in terms of computational complexity as well as minimum changes made to the topology of an SPT. Rigorous proofs for correctness of our algorithm and simulation results illustrating its complexity are also presented.", "authors": ["Paolo Narvaez", "Kai-Yeung Siu", "Hong-Yi Tzeng"], "n_citation": 50, "references": ["07942428-e617-4871-9275-7f581abcc2e4", "1cb42fca-4ec4-48ff-a0ab-ae302eef0fd6", "31ac4a7b-62b0-409f-a508-04fe8c4df0f2", "4b5c9003-da3b-4a1c-9ddd-0262278668e5", "62c5e5c0-e1ad-49dc-8bb6-3d79f150ccc1", "80532a94-f2fc-4dcf-af88-af38ed8279f7", "8638f928-050c-4035-80de-c0c7306d9671", "992ee36f-a6ca-48ad-9fd7-80d41bdbc16f", "dbc76f9e-32d6-4192-8872-a9043f0d06f6", "e1c7443f-fbc7-4edc-919b-8f3bd2c1a34c", "e80c59fb-2f00-48b1-845a-a46e18afca99"], "title": "New dynamic SPT algorithm based on a ball-and-string model", "venue": "international conference on computer communications", "year": 1999, "id": "e8492482-3e43-488d-8bd5-590266457b9f"}
{"abstract": "Rough set and vague set theories are used to study the different kinds of uncertainty in the information systems. They are generalizations of classical set theory for describing vagueness and uncertainty. The focus of this paper is to characterize probabilistic rough sets by vague sets. Firstly, the membership functions of vague sets are shown by conditional probabilities. Secondly, the concepts of variable precision lower and upper approximations of a probabilistic rough set are given by the lower and upper bounds of truth-membership and false-membership functions of a vague set. At last, the fuzziness in a probabilistic rough set can be induced by fuzzy entropies of a vague set.", "authors": ["Li Ma", "Li-Li Wei"], "n_citation": 50, "references": ["0aad2bb7-eb48-426c-81ed-7308404083b2", "a4589cfe-15e7-4c34-9349-d002d1d2c9df"], "title": "Probabilistic rough sets characterized by vague sets", "venue": "fuzzy systems and knowledge discovery", "year": 2011, "id": "9e26d54a-eb92-422a-a2d3-e7870e51463b"}
{"abstract": "Choreographies are an emergent Service Engineering (SE) approach to compose together and coordinate services in a distributed way. A choreography formalizes the way business participants coordinate their interactions. The focus is not on orchestrations of the work performed within them, but rather on the exchange of messages between these participants. The problems usually addressed when considering a choreography-based specification of the system to be realized are realizability check, and conformance check. In this paper we describe the CHOReOSynt tool, which has been conceived to deal with an additional problem, namely, automated choreography enforcement. That is, when the goal is to actually realize a service choreography by reusing third-party services, their uncontrolled (or wrongly coordinated) composite behavior may show undesired interactions that preclude the choreography realization. CHOReOSynt solves this problem by automatically synthesizing additional software entities that, when interposed among the services, allow for preventing undesired interactions. Screencast: http://choreos.disim.univaq.it/downloads/", "authors": ["Marco Autili", "Davide Di Ruscio", "Amleto Di Salle", "Alexander Perucci"], "n_citation": 6, "references": ["1e9d5d46-4f9e-4e1a-b518-12fadf7f9e02", "22f8eca2-bcea-4848-83a4-9f0e47512ca2", "28b6d68d-c477-412b-9bbf-eeb3a6bb21e8", "35392458-f8cd-4904-861b-6f65317e6fdb", "7cd31a0e-39ba-4f49-8e4c-1efe68582122", "91909db5-058e-4571-a03d-340f018d743b", "96528c61-de06-4cdf-98fc-c2fc0c6fa4ca", "bee65526-f9cf-4492-86bf-c77f03e956df", "dc54a679-dceb-4674-bccf-94b4dc9a42ab", "e74463df-fd8a-4c86-987d-23aefca7e41f"], "title": "CHOReOSynt: enforcing choreography realizability in the future internet", "venue": "foundations of software engineering", "year": 2014, "id": "dfc605f1-a372-4e35-9c34-fb10a91fca7d"}
{"abstract": "This paper is devoted to the design of fast parallel accelerators for the cryptographic \u03b7 T  pairing on supersingular elliptic curves over finite fields of characteristics two and three. We propose here a novel hardware implementation of Miller's algorithm based on a parallel pipelined Karatsuba multiplier. After a short description of the strategies that we considered to design our multiplier, we point out the intrinsic parallelism of Miller's loop and outline the architecture of coprocessors for the \u03b7 T  pairing over F(2 m ) and F(2 m ). Thanks to a careful choice of algorithms for the tower field arithmetic associated with the \u03b7 T  pairing, we manage to keep the pipelined multiplier at the heart of each coprocessor busy. A final exponentiation is still required to obtain a unique value, which is desirable in most cryptographic protocols. We supplement our pairing accelerators with a coprocessor responsible for this task. An improved exponentiation algorithm allows us to save hardware resources. According to our place-and-route results on Xilinx FPGAs, our designs improve both the computation time and the area-time trade-off compared to previously published coprocessors.", "authors": ["Jean-Luc Beuchat", "J\u00e9r\u00e9mie Detrey", "Nicolas Estibals", "Eiji Okamoto", "Francisco Rodr\u00edguez-Henr\u00edquez"], "n_citation": 50, "references": ["1c0ecf9a-8cd5-4336-9e5b-552a0d1d9533", "33d17770-9024-4306-90e8-13f02391187a", "41f9e4f5-8757-4b56-a74b-e0da07e7e17b", "4da2fc3d-e476-4bc6-9cd4-1dba96e81dbf", "50cdb2ad-fe6f-4f64-a4e2-4371ac375104", "52c9a178-8608-4bc2-856a-62200b59b1ef", "5605beff-05ac-4e8c-9ecf-60d93b1d77af", "5609c335-2c71-4879-ad9f-a3927dde08eb", "63575056-9db2-470b-9d97-60549430cd45", "666e1ca7-8c79-43b1-8b57-6c5714301481", "6d71aa95-358b-46a6-8bdd-f1c1e27d5bb9", "88fa033c-cdd6-47f3-9aac-5c1ed94bd39c", "c5fe538f-f60b-47e2-9239-26f67f5a3809", "ca5e3acc-4ca6-4717-a93a-63fd9ae4cd0b", "ce721d10-4e08-4823-b62d-0afb88342d74", "d6957412-c897-4c35-944b-72033071ff44", "dcab76d9-485d-4ed8-b9f5-97d55a1ab328", "ece21cde-a43c-400d-aecd-06e7a5daed9e", "ee545397-91e2-4804-8c70-9f2e5248424a", "ff8c1a16-00bc-4fb2-96b8-4a60a40b2a19"], "title": "Fast Architectures for the \\eta_T Pairing over Small-Characteristic Supersingular Elliptic Curves", "venue": "IEEE Transactions on Computers", "year": 2011, "id": "05e1be8d-2712-4738-b0c7-3c7eb9195962"}
{"abstract": "The main drive for Model-Driven Architecture is that many software applications have to be deployed on a variety of platforms. The way MDA achieves this is by transforming a platform-independent model of the software to a platform-specific model, given a platform model. In current MDA approaches, the model transformations implicitly represent this platform model. Therefore, the number of different target platforms is limited to the number of supported model transformations. We propose a separate platform model, based on description logics, that can can be used to automatically select and configure a number of reusable model transformations for a concrete platform. This platform model can be extended to describe the relevant platform information, including concrete platform instances as well as platform constraints for each model transformation. This separates the model transformation concern from the platform concern and, since the model transformations are no longer limited to targeting one platform, more platforms can be supported with the same set of transformations.", "authors": ["Dennis Wagelaar", "Viviane Jonckers"], "n_citation": 27, "references": ["0a3a12fe-28dc-41fc-aa7c-3e75ad04b82a", "147f09f6-a01d-416c-b9ac-5b6611a44b1b", "28c49b78-9398-4832-baa9-0207cba36e12", "56f0d32b-889c-40a5-8ece-368d289342b6", "6b1d09b5-b5df-4b84-8d7e-ad8ecc53f8aa", "7dad8dc8-ddeb-4b80-a81c-e40a2c9a6775", "cfe2910e-e76f-4b04-87c9-faf88f03f1aa", "f6e67623-9df8-4bde-9ba3-d0c93fc050a3", "ff6e8d24-9cfc-4af6-8d87-a0e195df0bba"], "title": "Explicit platform models for MDA", "venue": "model driven engineering languages and systems", "year": 2005, "id": "68b6ec63-63ef-4206-979a-d3d7f032d431"}
{"abstract": "We conducted two experiments designed to examine whether animations of algorithms would help students learn the algorithms more eAectively. Across the two studies we used two diAerent algorithms \u2014 depth-first search and binomial heaps \u2014 and used two diAerent subject populations \u2014 students with little or no computer science background and students who were computer science majors \u2014 and examined whether animations helped students acquire procedural and conceptual knowledge about the algorithms. The results suggest that one way animations may aid learning of procedural knowledge is by encouraging learners to predict the algorithm\u2019s behavior. However, such a learning improvement was also found when learners made predictions of an algorithm\u2019s behavior from static diagrams. This suggests that prediction, rather than animation per se, may have been the key factor in aiding learning in the present studies. These initial experiments served to highlight a number of methodological issues that need to be systematically addressed in future experiments in order to fully test the relationship between animation and prediction as well as to examine other possible benefits of animations on learning. # 2000 Published by Elsevier Science Ltd. All rights reserved.", "authors": ["Michael D. Byrne", "Richard Catrambone", "John T. Stasko"], "n_citation": 74, "references": ["025143ca-b6dc-4fd6-bae7-7340f6f5fac3", "0c7bb8fe-f930-44ba-bf95-eb327ed3fe04", "25fd9577-7cfc-431a-b12d-b729d31e6328", "26bf94f5-db54-4000-b92f-f7400279c99a", "33913ad7-fe5f-4f42-b656-b9332facb8a1", "34bd16bb-6bdb-42f5-a31f-833637ede260", "3dc61b13-ad12-4a8b-b777-f5fc8e042f6f", "43210ba2-b752-4a78-99f9-ebf963a45971", "484f708a-caf5-4584-9b97-d2b1e2ca5a95", "566cbae9-6567-47ec-96b1-f5d91006d133", "5cb097c8-8760-4db4-80cb-60bbf7ebc214", "6ea19c8b-c178-4940-9fbc-aed4dacd4c60", "813b9916-3353-4346-bc72-62aae297a3d7", "bbeb878e-0fd6-409c-bfae-b67ca7b42031", "c36de38a-7f33-4150-855a-f101d24ac34b", "cfcf14c1-ef01-4ecf-9b43-82b7a8e04a2b", "d034b27e-49f4-4a64-aa17-621b9091cac2", "d112e7dc-031f-4623-9eb9-cb93e70da7ac", "df2ee62e-9213-4fa7-8493-6b9181a843bb", "f0f447bc-4ed3-45ef-924f-1bcdeb0ba5d5"], "title": "Evaluating animations as student aids in learning computer algorithms", "venue": "Computers in Education", "year": 1999, "id": "95226b63-c020-447b-a454-2976c5b0c6b0"}
{"abstract": "Application level multicast schemes have traditionally been evaluated with respect to the  efficiency penalties  incurred in migrating the multicast functionality from the network layer to the application layer. We argue that the current performance measures, and therefore design strategies, are  incomplete  as they do not consider transience of peers. The routers in application level multicast systems are participant clients, and not infrastructure units. As such, the assumptions on the behavior of these application routers are significantly different from the infrastructure routing units that traditional research has dealt with, especially in a peer-to-peer setting where peers are multi-use and the management is decentralized. we argue that the transience in peer behavior has  implications on end-performance enabled . We outline a design philosophy that seeks to  separate  policy decisions in handling peer behavior from the end-application at a basic infrastructural  peering layer.  As a proof of concept, we have implemented a peering layer prototype, which is available for download.", "authors": ["Mayank Bawa", "Hrishikesh Deshpande", "Hector Garcia-Molina"], "n_citation": 122, "references": ["436b5fcd-6488-4a4c-b41a-85130718b39a", "559c2078-b2d3-4fd7-b80c-04620a34f942", "69c181d4-c63d-4951-bce6-e44733a2f3c5", "afe13b82-4826-4529-b26c-5ccd6a564f50", "b61d40f0-06b8-4779-8600-4884087348ca", "cb01bb2a-8126-4385-bd2a-4f862016ae6c", "ec7d1720-3285-4729-b819-b4c58a826ec8"], "title": "Transience of peers & streaming media", "venue": "acm special interest group on data communication", "year": 2003, "id": "a011afb0-9890-4b1d-b87f-fc7eba6bc2c5"}
{"abstract": "Abstract : Specification matching is a way to compare two software components. In the context of software reuse and library retrieval it can help determine whether one component can be substituted for another or bow one can be modified to fit the requirements of the other. In the context of object-oriented programming, it can help determine when one type is a behavioral subtype of another. In the context of system interoperability, it can help determine whether the interfaces of two components mismatch. We use formal specifications to describe the behavior of software components, and hence, to determine whether two components match. We give precise definitions of not just exact match, but more relevantly, various flavors of relaxed match. These definitions capture the notions of generalization, specialization, substitutability, subtyping, and interoperability of software components. We write our formal specifications of components in terms of pre-and post-condition predicates. Thus, we rely on theorem proving to determine match and mismatch. We give examples from our implementation of specification matching using the Larch Prover.", "authors": ["Amy Moormann Zaremski", "Jeannette M. Wing"], "n_citation": 632, "references": ["1cade51a-6086-44e5-bb85-38dcc328bbd6", "3d15988d-d90d-4c7e-ae81-2ca459554aed", "401eb13d-ccd2-4866-b881-a85c9136c40d", "482e7262-0d6e-4afd-b876-893e5a578f69", "4ae54bdc-401b-430b-8434-f5a8f80d6c2c", "65e9d883-cc87-4505-ab64-99a181371d6f", "6dc549af-c1bd-4695-9983-6bd5211fc5d9", "a2333d5c-502d-41af-8e4a-fffc5ed4d374", "ccc8ecf8-5aa5-4a49-9df8-884c207b3bda", "ccd000e4-cd34-4170-a51a-36be6f6b3814", "d0b1473f-8fdd-4128-b977-e02ada2f87da", "d72b45e5-5274-4a75-8007-79131cdf83df", "de198f0e-90cb-4591-accd-0f45b503ea77", "e75d8e62-a86d-4241-953f-1b315005d920", "ea89ced8-e205-4c33-9855-6fe150bdc158", "f6d4d483-1efe-4899-a384-814cf3148320", "f7206031-fdc6-44ee-897d-155a1710278b"], "title": "Specification matching of software components", "venue": "foundations of software engineering", "year": 1995, "id": "81a34810-632e-45dd-be5f-52f0519c9cb2"}
{"authors": ["Kriengkrai Porkaew", "Kaushik Chakrabarti"], "n_citation": 201, "references": ["13b91eb0-0857-4556-b32a-0f85a1cf43f6", "24d54168-6f8c-48ca-82c1-73706287f3ae", "6e4ecc92-bf51-4a12-a2df-15f0da3d8e14", "fdd18096-827d-414b-b512-fd1d4ef3bfc4"], "title": "Query refinement for multimedia similarity retrieval in MARS", "venue": "acm multimedia", "year": 1999, "id": "aea0239c-942b-45a5-88b6-2f9663860123"}
{"authors": ["Raimund Moser", "Pekka Abrahamsson", "Witold Pedrycz", "Alberto Sillitti", "Giancarlo Succi"], "n_citation": 75, "references": ["086babf5-2a0f-4c67-a3e4-030fcf50d7c8", "0c250218-3343-45ed-9668-b1a9a0cecace", "14e0a592-c5df-484c-a7bb-f36762a549ca", "1e463aed-c065-44d5-9d80-65d2923d3043", "225fc4c1-bb13-4f5a-8aab-e2d10bca9637", "22c9ac00-f036-4c8d-9e20-1e357ac85309", "3c4a7476-a0f1-4f65-b972-ac7b1ae996c0", "462669ee-4096-4034-b693-97e324dc4b01", "48c2799c-c7d4-4b37-8878-2cafffa2d850", "57af1f08-da6a-466f-97a2-99e98a992768", "6b9b14e3-0f4f-474f-99c4-d8e8d358f9a7", "8a724e91-4410-4a5a-9a07-11bfb7013661", "a583ce86-a149-48a9-b524-f29bcefaaeac", "a8b0574c-0172-4828-bd90-19fc75d6a085", "b0090d06-65c1-41ae-a249-ac4506a9ab76", "c28cf51b-79cf-4b24-9234-8b304f11e6ca", "d32786fc-ea8d-41f0-a803-5d00e550329c", "d5e15735-d11a-48d5-9c9d-fb1edc4669e0", "fcb4559e-3a76-472a-b090-cb033344ea32", "fcf11b61-a2f4-4b64-9f77-f2e3d8177b15"], "title": "A Case Study on the Impact of Refactoring on Quality and Productivity in an Agile Team.", "venue": "", "year": 2007, "id": "851fb1f6-fb31-424d-b2ed-dc78ad7a7133"}
{"abstract": "The publish/subscribe (or pub/sub) paradigm is an increasingly popular model for interconnecting applications in a distributed environment. Many existing pub/sub systems are based on pre-defined subjects, and hence are able to exploit multicast technologies to provide scalability and availability. An emerging alternative to subject-based systems, known as content-based systems, allow information consumers to request events based on the content of published events. This model is considerably more flexible than subject-based pub/sub. However, it was previously not known how to efficiently multicast published events to interested content-based subscribers within a large and geographically distributed network of broker (or router) machines. We develop and evaluate a novel and efficient distributed algorithm for this purpose, called -link matching\". Link matching performs just enough computation at each node to determine the subset of links to which an event should be forwarded. We show via simulations that: link matching yields higher throughput than flooding when subscriptions are selective; and the overall CPU utilization of link matching is comparable to that of centralized matching.", "authors": ["Guruduth Banavar", "Tushar Deepak Chandra", "Bodhi Mukherjee", "Jay Nagarajarao", "Robert E. Strom", "Daniel C. Sturman"], "n_citation": 705, "references": ["3b52f92e-8185-46f8-a4e6-ce056a957ef3", "51be15ac-cd74-4fec-96b2-3ec79f7fa9c5", "9eac8f56-e6ce-4d57-89ba-6f1119209b9a", "c2ae33d8-85e5-4d1d-8f17-b71a210b4546", "c9b8f3bf-babd-427a-8723-68b7e4526dd4", "ee8565d9-0876-4744-b87c-1e56592fc99f"], "title": "An efficient multicast protocol for content-based publish-subscribe systems", "venue": "international conference on distributed computing systems", "year": 1999, "id": "8d33ee89-ed11-465b-b744-05ca0fadc72f"}
{"abstract": "Dynamic spectrum-sharing protocols are gaining attention due to the need for improved spectrum utilization. We propose a spectrum-sharing protocol with two-way relaying systems, where two licensed primary users A and B communicate with each other with the assistance of an unlicensed secondary transceiver C, which acts as a relay. The secondary transceiver C gains spectrum sharing by using a decode-and-forward (DF) relay protocol and superposing the secondary transmission on network-coded primary signals. We analytically derive the outage probabilities for both the primary and secondary systems under the proposed cognitive two-way relaying (CTR) protocol. Our results show that a spectrum-sharing region exists such that, as long as C is located within this region, there will be a power-allocation threshold above which the proposed CTR protocol is able to provide a better (or an equal) outage performance for the primary system and, at the same time, achieve secondary spectrum sharing.", "authors": ["Qiang Li", "See Ho Ting", "Ashish Pandharipande", "Yang Han"], "n_citation": 104, "references": ["1774d6ce-20bb-4010-ad23-361fa8e367be", "1b125476-9f94-4304-a022-199806a0116e", "222e8196-b98b-47bc-a679-641bbf57b770", "2a5d8747-0d25-4166-aa6c-129466a70057", "6acdadd8-d600-432b-a16f-b73178eea9ab", "9e3e64ce-6a16-47bd-ad8e-fdc9fcd49cd5", "d0220001-fa14-4951-8aee-0e89f69e7319", "d1ba534e-3f80-4366-bb83-be16006f9e18", "e73f6287-e6c7-4178-a841-02a3bb8de774", "f3a452af-b73b-4c20-8b60-06c7a6f4609f", "fe91049c-c256-4738-b59a-77de0fe449f1"], "title": "Cognitive Spectrum Sharing With Two-Way Relaying Systems", "venue": "IEEE Transactions on Vehicular Technology", "year": 2011, "id": "37685253-f7e5-4cba-be13-f91d815aec7f"}
{"abstract": "The paper describes the MIKE (Model-based and Incremental Knowledge Engineering) approach for developing knowledge-based systems. MIKE integrates semiformal and formal specification techniques together with prototyping into a coherent framework. All activities in the building process of a knowledge-based system are embedded in a cyclic process model. For the semiformal representation we use a hypermedia-based formalism which serves as a communication basis between expert and knowledge engineer during knowledge acquisition. The semiformal knowledge representation is also the basis for formalization, resulting in a formal and executable model specified in the Knowledge Acquisition and Representation Language (KARL). Since KARL is executable, the model of expertise can be developed and validated by prototyping. A smooth transition from a semiformal to a formal specification and further on to design is achieved because all the description techniques rely on the same conceptual model to describe the functional and nonfunctional aspects of the system. Thus, the system is thoroughly documented at different description levels, each of which focuses on a distinct aspect of the entire development effort. Traceability of requirements is supported by linking the different models to each other.", "authors": ["J\u00fcrgen Angele", "Dieter Fensel", "Dieter Landes", "Rudi Studer"], "n_citation": 202, "references": ["0c5c8cf3-8767-47e6-bbdb-5dd85b0c0ef0", "0dc5f0af-ec26-4de6-b2e6-2440b4e6b854", "1c7e166d-94cb-4cdd-b23b-1fd26029ff3d", "2681de88-e95e-410e-8fdf-ded54604717c", "2a458d59-b60b-45eb-a49f-b135f9ad2b4d", "317d5c58-0c1b-4c74-8016-83c796f88083", "33442a76-b67b-47a1-a638-83e8c37908d2", "3389f4fc-8dc1-49cf-bfe9-80e45f42a072", "3cf64567-3060-443c-8ad4-76b3404099d4", "3f1dc5c4-0183-4c78-aeab-b552a51a9f03", "4ccb7308-48e7-47a2-a013-38c319831130", "69220232-821f-4e21-8d99-3decfb2f9da6", "747c8a1e-4b4a-41d5-bbff-87271053360c", "8f00d033-f73d-4319-ac53-f6230f37a704", "9c58b915-c7a3-4b62-b4d2-c0725d6b1394", "a8743d27-1912-424a-a24b-3b670d3c15c3", "abc285c8-40d8-4d5c-b1f6-dfdf82f9553a", "ac8b9af7-1b1e-4e6c-9050-46044f319449", "d12c67ad-a58c-4753-bbf7-83c33e586336", "d63dd4ae-4b30-484b-8ffc-88d21839ddad", "d79b4ee5-a648-47de-bd88-934aba95b670", "de36ba59-4627-4a20-a2eb-b1d9bab2e69f", "df63214a-03af-4d3e-8275-3992284e6fd0", "e558a451-68ec-4df7-b9a0-4387d6f6bf85", "e9cb4f12-f852-4a0d-bc43-822771528cbd", "f0d47180-9b15-4b5d-835f-6c26ba09824f", "fd51ccc8-de62-4814-a3d1-911ce3b5f39c"], "title": "Developing Knowledge-Based Systems with MIKE", "venue": "automated software engineering", "year": 1998, "id": "b3739cb1-1809-43b4-afcb-44d958c3634d"}
{"abstract": "IEEE 802.11 MAC mainly relies on two techniques to combat interference: physical carrier sensing and RTS/CTS handshake (also known as \"virtual carrier sensing\"). Ideally, the RTS/CTS handshake can eliminate most interference. However, the effectiveness of RTS/CTS handshake is based on the assumption that hidden nodes are within transmission range of receivers. In this paper, we prove using analytic models that in ad hoc networks, such an assumption cannot hold due to the fact that power needed for interrupting a packet reception is much lower than that of delivering a packet successfully. Thus, the \"virtual carrier sensing\" implemented by RTS/CTS handshake cannot prevent all interference. Physical carrier sensing can complement this in some degree. However, since interference happens at receivers, while physical carrier sensing is detecting transmitters (the same problem causing the hidden terminal situation), physical carrier sensing cannot help much, unless a very large carrier sensing range is adopted, which is limited by the antenna sensitivity. We investigate how effective is the RTS/CTS handshake in terms of reducing interference. We show that in some situations, the interference range is much larger than transmission range, where RTS/CTS cannot function well. Then, a simple MAC layer scheme is proposed to solve this problem. Simulation results verify that our scheme can help IEEE 802.11 resolve most interference caused by large interference range.", "authors": ["Kaixin Xu", "Mario Gerla", "Sang Bae"], "n_citation": 277, "references": ["1aaee431-d884-4764-b1ab-fa15594bf745", "60fb0dc2-bde3-4714-948e-de0ed12ab460", "83c62a2a-e0de-4bd8-bc02-a7e03a28c600", "f4f581ba-fa62-483c-a5aa-9a37370ccd3e", "f65a4365-2696-47f3-849b-501792da7e23"], "title": "How effective is the IEEE 802.11 RTS/CTS handshake in ad hoc networks", "venue": "global communications conference", "year": 2002, "id": "da62b2a8-99c2-4d97-901f-05c924e13d69"}
{"abstract": "The potential of mobile technologies is not fully exploited by current software services. One of the most influencing reasons for this problem is the lack of novel software engineering methods and tools that can master the complexity of mobile environments. Looking at a person in a smart environment, where mobile technologies and sensors are installed to support daily activities, it is observed that informed decision-making with the help of mobile technologies is beyond what users can expect from current software services. In this paper we present a motivating scenario to highlight the limitations of current decision support approaches. Based on this discussion we identify significant software engineering challenges, which currently hinder the realization of advanced decision support. In our research we have developed an initial version of a comprehensive framework that allows overcoming the challenges identified. It furthermore highlights which software engineering research lines may help to realize this vision.", "authors": ["Xavier Franch", "Anna Perini", "Norbert Seyff"], "n_citation": 1, "references": ["0cdd99ec-6f71-48c2-a830-581a84741064", "15c67eca-f869-457a-b844-cd174e4ac3af", "19175c17-bd82-43c0-8c33-b1ad24531275", "1ee20ff0-378f-44f9-aad4-8494dae10329", "3e991b02-bb09-49f1-af7d-3871e4431f12", "47dea4fa-d1fb-4332-a3e2-c06cc54525a2", "4aeae075-bed4-468a-9f10-79708d9cd488", "4ea66b40-534e-4b2c-ac37-07119e6e1d6a", "620150d0-8acf-467e-b69d-dd831c5b59c9", "66c5269e-d948-4de6-9715-1e467460592c", "6d868893-713d-4e04-901e-0323e7426c88", "85207a21-969b-48d9-addf-977743b94c62", "b20e3518-0499-4f34-b21f-e78efd0f6396", "b6d4b2ad-627f-45d7-9e9e-4b88167c3c44", "d84f537d-1415-4990-9a48-fd5cb69d180a", "d8deba7f-dc73-46ff-bf19-4a91da724983", "dabdbc44-0beb-4468-ba8e-f9269d04fe50", "e1551f44-2eaa-43d9-9c83-b13fceb45c47", "ed2bf2ea-9e72-44f3-a1b8-d00f6d50ca67", "f26f1cdc-be80-426a-a05d-d4fdb7ff8ff2", "fed36597-a49a-4fb1-adfc-a293a24b0540", "feddae21-3c05-4743-80fa-b8e101f1b93f"], "title": "Enabling Informed Decision Making Through Mobile Technologies: A Challenge for Software Engineering", "venue": "", "year": 2013, "id": "c62a2ad5-5958-4837-8aa1-43236363ca5e"}
{"abstract": "Enabling nonexperts to understand a software system and the scenarios of usage of that system can be challenging. Visually modeling a collection of scenarios as social interactions can provide quicker and more intuitive understanding of the system described by those scenarios. This project combines a scenario language with formal structure and automated tool support (ScenarioML) and an interactive graphical game engine featuring social automomous characters and text-to-speech capabilities. We map scenarios to social interactions by assigning a character to each actor and entity in the scenarios, and animate the interactions among these as social interactions among the corresponding characters. The social interactions can help bring out these important aspects: interactions of multiple agents, pattern and timing of interactions, non-local inconsistencies within and among scenarios, and gaps and missing information in the scenario collection. An exploratory study of this modeling's effectiveness is presented.", "authors": ["Thomas A. Alspaugh", "Bill Tomlinson", "Eric Baumer"], "n_citation": 14, "references": ["3455249a-3093-49c7-b031-c4de8bbb1cb4", "3e6077bf-740e-4578-9822-b6176d7912f3", "41091ff4-b4bf-49e4-a0a7-e49be033177d", "71ff9a0c-1ff4-40a9-b345-11b280a664a3", "76cecf4c-fa3d-4d07-8cbd-607208f4816c", "9eda6a74-4b7b-4109-bac6-daf3e7a45218", "bf3bb8d7-062c-44d8-9d9d-c8af6de3fd4b", "c9d799fa-eab9-42fb-86cd-6fd2e05be201", "cac33aed-460e-4aeb-9fdf-52162fa1aac7", "d6e21f09-0963-40b1-a23d-e757cee163f7", "d98cb2a7-0f1e-40ab-b271-8dcff8d2cbc2", "e79c68ad-bbd7-4e92-962c-d467788a745f"], "title": "Using social agents to visualize software scenarios", "venue": "software visualization", "year": 2006, "id": "04f35994-5196-46ae-81e3-9c7dbeccba80"}
{"abstract": "Concept location identifies parts of a software system that implement a specific concept that originates from the problem or the solution domain. Concept location is a very common software engineering activity that directly supports software maintenance and evolution tasks such as incremental change and reverse engineering. This work addresses the problem of concept location using an advanced information retrieval method, Latent Semantic Indexing (LSI). LSI is used to map concepts expressed in natural language by the programmer to the relevant parts of the source code. Results of a case study on NCSA Mosaic are presented and compared with previously published results of other static methods for concept location.", "authors": ["Andrian Marcus", "Andrey Sergeyev", "Vaclav Rajlich", "Jonathan I. Maletic"], "n_citation": 458, "references": ["0096859a-c41a-426c-ac38-7a086a6b86d0", "067d7741-cc32-4c7e-b536-719b9a216812", "18e8aabb-695b-428f-9a52-c2ec0707f03c", "1a50cb82-42ee-4d26-b74c-cccf045855f0", "2803eb06-4cde-4d79-8596-72013bc08d1e", "33d6dabd-c086-4a6e-939a-c322b6ada724", "3592ded5-371b-43e6-940c-c761a036880f", "3a1a1813-de2b-465f-a2af-ad6a69e93334", "4c58c136-7019-498f-9f81-7eb99f9b4699", "4df004e1-b013-4da9-8157-0999add3a12b", "54936cc8-17a4-4db3-8e87-b8c20842acb2", "55948cd3-b9de-4a5f-8369-3f9825793ee7", "5ad13e64-7294-4851-b753-dc9bef4648c7", "5c1825a2-fde0-4f16-8072-0e4e45aa5f75", "646c2c09-fdf0-4f39-9109-57d5eae61435", "65e9d883-cc87-4505-ab64-99a181371d6f", "6e198e5e-9655-418f-9abe-f2507c87ad91", "9b86aec6-f6e4-45da-9e0e-a0ed07c49394", "ac14afe6-de4d-4056-b2ac-0f6e36f369a2", "af248d74-e634-4738-8f14-c900b36df7ce", "b5e53e77-9346-4dee-8a50-ab104f735a1a", "b7bf2413-b8b8-4b52-b6a4-6d7595533bb0", "c9cf1548-cbd1-48ca-86c9-9dd2bf3055d2", "e427f800-7a52-4845-a774-fd5c823634d2", "e5115d61-6459-4beb-88d1-603c9040c726", "e75d8e62-a86d-4241-953f-1b315005d920", "fe1c3535-c0e9-43b8-a1d9-78c8108eea64"], "title": "An information retrieval approach to concept location in source code", "venue": "working conference on reverse engineering", "year": 2004, "id": "30d4f0ad-89c2-4c3e-8330-295a5cc80502"}
{"abstract": "This paper describes a novel driving pattern recognition and status monitoring system based on the orientation information. Two fixed cameras are used to capture the driver's image and the front-road image. The driver's sight line and the driving lane path are found from these 2 captured images and are mapped into a global coordinate. Two correlation coefficients among the driver's sight line, the driving lane path and the car heading direction are calculated in the global coordinate to monitor the driving status such as a safe driving status, a risky driving status and a dangerous driving status. The correlation coefficients between the lane path and car heading direction in a fixed period are analyzed and recognized as one of 4 driving patterns by HMM. Four driving patterns including the driving in a straight lane, the driving in a curve lane, the driving of changing lanes, and the driving of making a turn are able to be recognized so far.", "authors": ["Jiann-Der Lee", "Jiann-Der Li", "Li-Chang Liu", "Chi-Ming Chen"], "n_citation": 50, "references": ["357dd74b-362c-49e8-b631-94ee0e8bde67", "643db181-b935-4ddf-bd64-8112287ccf27", "7e9f9842-a966-478f-8bcd-2885d0cefefd", "93ed847e-2ad4-46f2-aaee-cfce0a3ddb2d", "b592576f-ff29-4a68-9b2f-8a8ad02e9c70", "e649a9fd-f6d9-4aac-b428-29b82c20a484"], "title": "A novel driving pattern recognition and status monitoring system", "venue": "pacific-rim symposium on image and video technology", "year": 2006, "id": "2fd8341e-e979-403f-a594-b07eb5260e77"}
{"abstract": "This paper presents a systematic study of the properties of a large number of Web sites hosted by a major ISP. To our knowledge, ours is the first comprehensive study of a large server farm that contains thousands of commercial Web sites. We also perform a simulation analysis to estimate potential performance benefits of content delivery networks (CDNs) for these Web sites. We make several interesting observations about the current usage of Web technologies and Web site performance characteristics. First, compared with previous client workload studies, the Web server farm workload contains a much higher degree of uncacheable responses and responses that require mandatory cache validations. A significant reason for this is that cookie use is prevalent among our population, especially among more popular sites. However, we found an indication of wide-spread indiscriminate usage of cookies, which unnecessarily impedes the use of many content delivery optimizations. We also found that most Web sites do not utilize the cache-control features ofthe HTTP 1.1 protocol, resulting in suboptimal performance. Moreover, the implicit expiration time in client caches for responses is constrained by the maximum values allowed in the Squid proxy. Finally, our simulation results indicate that most Web sites benefit from the use of a CDN. The amount of the benefit depends on site popularity, and, somewhat surprisingly, a CDN may increase the peak to average request ratio at the origin server because the CDN can decrease the average request rate more than the peak request rate.", "authors": ["Leeann Bent", "Michael Rabinovich", "Geoffrey M. Voelker", "Zhen Xiao"], "n_citation": 92, "references": ["2a71f2d9-ff69-4b06-b1d2-e6ea21e1ad58", "2b998d03-c1e7-4a84-8dcd-9278a479e00c", "34596e78-20bf-473e-8ad7-01d41d918a00", "37b8e0cd-5ca8-4b15-86ab-fbb01930ad06", "3a16db1e-368b-49dd-937b-f14575a164c4", "537d266a-952c-4d06-840b-8abd29ee0de5", "5932b561-7e51-4971-beb8-3231e1dec7f4", "5a593b43-297d-4644-8b4c-288dd8e4ed4e", "5f1a52f2-faca-45ab-bb82-8d459d1c77ce", "65d6a082-c966-41b5-96ca-3410a8dda886", "694993a7-da6d-4b37-8742-1341a25f8974", "6b64058c-5de2-4050-86a9-32518b3e8259", "716a3f63-879a-428c-811a-3e2956a2bf79", "8504c16f-faca-4ee7-bde5-7bc961e4a314", "8d073d97-9e5f-4443-9138-0f3dd92336f7", "a2716817-2ad5-4a18-a926-483483a0bb3d", "a792462b-c9bb-438e-a68c-2dd27feeb790", "b678bada-3feb-43ac-b4b2-0115f76c28d3", "ba7b9b81-a05e-4648-9ca2-efcd40344672", "c4ef777e-3893-475a-bcf5-634528d2e6ab", "d26d2739-f50b-4b9b-9620-1f4ffd316114", "d59ec8b8-145a-4570-a91c-38587a3613a5", "e5a62852-2995-41f0-805c-97f992b779c8", "e6c5c8ec-8887-47f8-82b2-f426c2db9cd2"], "title": "Characterization of a large web site population with implications for content delivery", "venue": "international world wide web conferences", "year": 2004, "id": "cd8a4b59-48dc-4194-a484-b92e870b2e4c"}
{"abstract": "To enable efficient authoring, management and access to multimedia content, media data has to be augmented by semantic metadata and functionality. Semantic representation has to be integrated with domain ontologies to fully exploit domain-specific knowledge. This knowledge can be used within the authoring process and for the efficient management of multimedia content. Also, this knowledge can be used for refining ambiguous user queries by closing the conceptual gap between the user and the information to be retrieved. In our previous research, we have introduced Enhanced Multimedia Metaobjects (EMMOs) as a new approach for semantic multimedia meta modelling, as well as the query algebra EMMA, which is adequate and complete with regard to the EMMO model. This paper illustrates how ontological knowledge can be used within the authoring process of EMMOs, integrated into the EMMO knowledge structures and exploited for refining EMMA queries.", "authors": ["Sonja Zillner", "Werner Winiwarter"], "n_citation": 7, "references": ["42325fb2-7ab8-4eb5-ba1e-d9f22af4f988", "6b85c9c7-a72f-4160-87e3-db25a8cba91b", "7a48e15b-c3b6-45e6-bb33-ecd30a49cfed", "eb74c6f4-388b-4175-9942-1a8b6e3828f1", "ed50e183-21f9-4532-9110-57c86c34a49c", "f352d1a5-134b-4841-a166-a22e93654815"], "title": "Integration of ontological knowledge within the authoring and retrieval of multimedia metaobjects", "venue": "International Journal of Web and Grid Services", "year": 2005, "id": "0a80bca2-2678-4225-a93a-31f10a6a9559"}
{"abstract": "High Performance Computing systems have shown an impressive growth so far with a performance increase of 10x every 3.6 years. Performance predictions seem to confirm this trend for the future: Roadrunner achieved 1 petaFLOPS in 2008 and 10 petaFLOPS system are expected to be operational in the next few years. If these predictions are correct, exascale performance will be achieved by 2018.", "authors": ["Roberto Gioiosa"], "n_citation": 12, "references": ["0fea0f4e-77a0-4ee0-811b-249f2f05ce70", "143da6b4-f895-4c1e-a9cf-04948f0aaa1a", "28323bfc-f269-4778-9927-60a5931e0bc1", "2b29bc10-fd1b-4d8b-8efb-ca4f81c6d093", "2d7bbb7b-6373-4926-beb3-5d000d841ca0", "36653de4-ccd6-49d2-8f6d-25c1b7f4f856", "3c9affe5-a987-43bd-89a9-68eb9762659b", "61a79524-1ae6-487b-b1a0-df66c72f28b6", "86169ce5-315a-4e04-b194-f7b141abb940", "95aeaf56-4984-4b3d-9877-e2d50f9a53ca", "b219795c-bc95-4c9e-9407-c0cc79bbae2a", "b5c4c8a7-9fcb-4cb5-a00c-cc4b27c1d74f", "c2dc4b00-fb1f-4c3e-b9f4-addd7ca807b3", "da8dfbfa-714b-4ac2-a4bb-65627bac306b", "dea8e7d6-2c11-4714-ab98-e970e3790979", "e0ac8b20-3add-4d6a-9d03-d6ddf4f1ae96", "e0f88696-6a82-4016-b5fe-28696d0dad3f", "e866b6c6-0a18-45c3-a552-fe8a5d264a60", "f3460828-62c9-4fec-9796-0e94454ce420", "fec83c16-38bf-4cd6-8b74-40f621e2c0c1"], "title": "Towards sustainable exascale computing", "venue": "IEEE Transactions on Very Large Scale Integration Systems", "year": 2010, "id": "4b6812e3-4624-4cb4-9a17-45f336dd3b3f"}
{"authors": ["Xiaoyu Huang", "Hui Zhang", "Guoguang Zhang", "Junmin Wang"], "n_citation": 32, "references": ["27c240e0-e31e-44a2-8529-2d4a7ddddfda", "39de9ba4-9f4f-433e-afdf-c3c83a9f828b", "45836843-3803-4b8e-add3-908824f7d229", "578fd280-e0d4-4f1c-9372-0c24ff1b6ae5", "59c5c3e0-cdcc-41fb-8da7-b220bf0a461d", "69f0b56d-ecfa-4d83-b384-8eae6a2051a6", "9ea0ba0b-5352-4b23-b1dd-58b463b8220f", "a22ea999-c6d6-4665-beaf-fdf7aa0a33b9", "acb6d866-dddf-4646-98f8-16ae00abd972", "b67261ba-4cb9-40ba-8647-0db2a00f4ac8", "c1520d66-5b8a-43d3-9b97-bd25cd274c64", "d06439aa-7f9d-4f74-8503-d9f613896b62", "d6b0f6de-2f5d-4d6e-9e8a-e01f51ec87ba", "eb5bb896-d7cf-4f6f-8629-27e5d0e7c64f", "ebb04705-3850-43f2-821f-055d31d4359c", "f678fbf4-2072-4fc0-aae3-1b1448b5a893"], "title": "Robust Weighted Gain-Scheduling \\(H_{\\infty }\\) Vehicle Lateral Motion Control With Considerations of Steering System Backlash-Type Hysteresis.", "venue": "IEEE Transactions on Control Systems and Technology", "year": 2014, "id": "9b3e697f-d919-4132-8fb7-3024cbbdb1c6"}
{"abstract": "Cardinality constraints are often considered as one of the basic constituents of the entity-relationship approach to database design. In his original proposal of this model, Chen [6] defined cardinality constraints as look-across constraints. Alternatively, however, cardinality constraints may also be defined on the basis of the participation or look-here interpretation.While both definitions correspond to each other for binary relationships, they differ for n-ary relationships (with n \u2265 3). Participation constraints restrict the number of relationships a fixed object may participate in. Chen-style constraints limit the number of objects that co-occur with a given tuple comprising instances of the remaining n - 1 components of the relationship type under discussion.In our paper we present a sound and complete system of inference rules for a class of generalized cardinality constraints containing both, participation constraints and Chen-style constraints. It turns out that both constraint classes are almost independent, which justifies their juxtaposition in conceptual database design. Similar results will be presented in the presence of additional functional dependencies. The paper concludes with an axiomatization for the joint class of generalized cardinality constraints and functional dependencies.", "authors": ["Sven Hartmann"], "n_citation": 50, "references": ["0bce3280-56f7-443f-8e80-6ea048a492ba", "1c44fe65-43d5-4e5a-a227-1d33ff4020de", "1d82e414-4b95-432c-9634-1d12ba5e6a70", "41ecddeb-6a0f-4922-b4ed-b231d4225808", "42ea6086-62ba-4bfa-b59c-4e454c848818", "57f198d1-33ac-4306-bcb3-4689e15ab0fb", "7e628c40-44ce-4006-8855-4de8acb012cd", "9255dfac-0d05-4317-8552-2c146726bd70", "94584b62-bbde-42f3-9472-e7f1ac37fe50", "a2060b9b-b780-4883-b994-c2ebc1caa281", "e037a6a1-ad95-4275-acbb-11f113f807cc", "e8d91ced-f2c1-41f5-9abc-a55a46b2411a", "f9c9d021-10f7-4132-9dc4-61940e3b7728"], "title": "Reasoning about participation constraints and Chen's constraints", "venue": "australasian database conference", "year": 2003, "id": "567b8eb3-424d-44f6-a8c2-a8317ae4c136"}
{"abstract": "Integrating diagnosis and repair is particularly crucial when gaining sufficient information to discriminate between several candidate diagnoses requires carrying out some repair actions. A typical case is supply restoration in a faulty power distribution system. This problem, which is a major concern for electricity distributors, features partial observability, and stochastic repair actions which axe more elaborate than simple replacement of components. This paper analyses the difficulties in applying existing work on integrating model-based diagnosis and repair and on planning in partially observable stochastic domains to this real-world problem, and describes the pragmatic approach we have retained so far.", "authors": ["Sylvie Thi\u00e9baux", "Marie-Odile Cordier", "Olivier Jehl", "Jean-Paul Krivine"], "n_citation": 50, "references": ["0e4c1528-6e83-4e8e-b20d-397a4728e3d2", "24d170fd-181e-4cbe-8186-db727d128531", "6f1a1553-3a94-4b60-9828-65243f11d2c5", "bf717395-74d1-424d-8f33-b0cba4ecc5c8", "e7a4dfe5-dd09-4984-9213-3449c71cb93a"], "title": "Supply restoration in power distribution systems: a case study in integrating model-based diagnosis and repair planning", "venue": "uncertainty in artificial intelligence", "year": 1996, "id": "62b25d09-d12f-4477-9617-fe639a1b6429"}
{"abstract": "We describe a multiagent approach of the organisation of a collective activity within a pedagogical context. We consider pedagogical situations where students have to explicitly define the articulation of their collective work and then achieve the different tasks they have defined. Our objective is to support these students by taking some of these tasks in charge whilst making them work out such organisation features. For this purpose, we propose to consider that the group of students forms a multi agent system and to introduce software agents that can achieve some of the tasks within this group. This conducts students to tackle the problem in terms of human and software agent coordination. We present how this approach can be conceptualized and modelled using Engestrom's triangle and how task delegation can be used as a means to enable students to define the software agent's behaviour.", "authors": ["Neil Taurisson", "Pierre Tchounikine"], "n_citation": 5, "references": ["66cef6b7-e77b-48b9-9367-23db29a03d3b", "9e94aa1c-b52f-4879-82b5-cfdad5073e81"], "title": "Mixing human and software agents: a case study", "venue": "international conference on advanced learning technologies", "year": 2003, "id": "54054b29-ad25-4cab-aebf-ecb9a1ef5979"}
{"abstract": "Selection and join queries are fundamental operations in database management systems (DBMS). Support for nontraditional data, including spatial objects, in an efficient manner is of ongoing interest in database research. Toward this goal, access methods and cost models for spatial queries are necessary tools for spatial query processing and optimization. We present analytical models that estimate the cost (in terms of node and disk accesses) of selection and join queries using R-tree-based structures. The proposed formulae need no knowledge of the underlying R-tree structure(s) and are applicable to uniform-like and nonuniform data distributions. In addition, experimental results are presented which show the accuracy of the analytical estimations when compared to actual runs on both synthetic and real data sets.", "authors": ["Yannis Theodoridis", "Emmanuel Stefanakis", "Timos K. Sellis"], "n_citation": 175, "references": ["24e2beb6-4741-48ad-87fa-27c108ab2ffd", "25be7962-f058-4d33-93d7-84de191a740e", "28af31e8-07f0-4017-acb1-45246f5b4f90", "34c2f9a5-a5be-46d7-b539-5e3cbfd4aab9", "35af9e2f-71b6-4431-b60b-4c12d8954b48", "36121bc5-3ebc-485a-9890-92df89716d59", "3dc33be3-0fbf-4765-a1cd-67fda306675d", "3ee39def-f8aa-43e8-bc61-63f1f587dc1a", "47b2eb4e-c475-445a-9a87-9c836c024d92", "4c08b9ef-dd4d-4f91-8ede-409aabef0dfd", "510eec1d-f82c-4b19-b116-b8fd4c66531a", "5113d676-dde0-4807-86e1-460567719413", "5c5fcd0c-388f-4767-9fe5-60922a05fe27", "5f79215b-40d5-4d63-a0e8-389c297af5dd", "60ed31c3-9888-4d88-9c87-0c34e666bdf2", "612215ed-ac2a-420d-a56f-bc12d3e3c733", "707fdea7-fc59-4279-89af-6ae91e683358", "7431bf6e-a371-4d80-807c-6c9bc08b8b7b", "783e5a24-8505-4817-9566-36b1a478a6be", "7ab0950b-d90b-4058-aa0b-5879ac881c72", "85ec669b-69db-45c8-9ae3-5489ed73f2ff", "8a301c6e-70ee-4182-b5a3-015f3ac14bfa", "998d86e5-7812-4e99-84b4-94f57e9fe312", "9e6cf3e6-7bea-4ea2-8269-16f4cb4f4ad5", "b8ea6de1-8940-48bd-af03-14915a703aa3", "baa500b9-35d5-49f7-85a9-a75803046999", "c16c2977-7c76-4d59-a55e-e23e4728f19b", "c9be6fc9-cae6-425c-b3a5-c693947daae4", "d6ffd0e7-61aa-4dea-9fe0-4345e2382e96", "dbe5ae2e-bbc0-4508-8df5-3ec95c784fa8", "e930195e-baa4-4d42-9d5f-e042fcaf5a9e", "eb95e6ce-9479-4c5b-add6-d7ad6f9181ae", "ed6d1d25-e05a-4d33-9cea-4cec3fb17ab5", "eef59e87-e6b8-4c94-944e-9f180e3bca33", "f36b3145-31a3-4da7-839c-f14af75483d3", "ff177353-c9ba-414a-ab55-407d58302e3a"], "title": "Efficient cost models for spatial queries using R-trees", "venue": "IEEE Transactions on Knowledge and Data Engineering", "year": 2000, "id": "222dd08b-887c-457e-9b97-39726d6c803e"}
{"abstract": "Sassafras is a prototype User Interface Management System (UIMS) specifically designed to support a wide range of user interface styles. In particular, it supports the implementation of user interfaces where the user is free to manipulate multiple input devices and perform several (possibly related) tasks concurrently. These interfaces can be compactly represented and efficiently implemented without violating any of the rules of well-structured programming. Sassafras also supports elaborate run-time communication and synchronization among the modules that make up the user interface. This is needed to implement user interfaces that have context-sensitive defaults, and it simplifies recovery from semantic errors.  Sassafras is based on a new language for specifying the syntax of human-computer dialogues known as Event-Response Language (ERL) and a new run-time structure and communication mechanism for UIMSs known as the Local Event Broadcast Method (LEBM). Both ERL and LEBM are described in detail, and implementation techniques are presented. The effectiveness of Sassafras is demonstrated by describing two interfaces that have been implemented with Sassafras.", "authors": ["Ralph D. Hill"], "n_citation": 201, "references": ["061bee44-5292-49c7-8f31-df969459398c", "0c66ece5-fc9a-4373-b11d-5f04afa4313c", "2e1fce1f-ca8c-4145-b44f-f550aea62b8f", "3594315e-255c-4eae-a6d5-edb4d99ac8fa", "3733e082-3742-48f6-89b8-4d67f003b72b", "577dad51-cc83-456b-8b17-7870c59a6996", "5b1eafa6-0b05-41de-aba1-0d5476cb4b66", "69b23ffc-09f4-40cb-98dc-a7b5194f3e68", "9912ffe5-ace5-4025-b1b0-c99c6e4ece96", "ba7ca186-3592-46bf-9450-401f007c62ab"], "title": "Supporting concurrency, communication, and synchronization in human-computer interaction\u2014the Sassafras UIMS", "venue": "ACM Transactions on Graphics", "year": 1986, "id": "002e5c31-9e4c-48f7-ad44-8e85eb104378"}
{"abstract": "In a multi-radio multi-channel wireless mesh network, a channel assignment that is based on a fixed number of available frequency channels may cause co-channel interference, which degrades the network throughput. We address this problem by ensuring interference-free communication among the mesh nodes. The main purpose of this work is to determine the minimum number of non-overlapping frequency channels required for interference-free channel assignment in order to achieve the maximum network throughput while maintaining fairness among the multiple network flows, given the location of the mesh nodes and the number of their half-duplex radio interfaces. To minimize the number of channels required, we apply our Select x for less than x Topology Control Algorithm to build the connectivity graph instead of using the classical approach based on maximum power (MP). We show that our approach outperforms the MP-based approach in terms of the number of channels required as well as the links to channels ratio for all node-degrees.", "authors": ["Aizaz U. Chaudhry", "John W. Chinneck", "Roshdy H. M. Hafez"], "n_citation": 50, "references": ["06005294-96ac-4336-a9d1-95f380737b3d", "158b84d8-d076-440c-bb4c-bf2b2071aeda", "172f9f68-8417-43bb-8fe5-b377d569f6b6", "1d002c1d-c350-421c-969b-f323f1a4571d", "2e764def-2a54-4442-acb0-16cb1306b7f5", "31caf4dd-bccf-4b57-8d13-fbafe9675a07", "53509df6-4f4f-4652-bf8a-43098126e01b", "6d04d192-67b2-4b76-acb3-97cdeb433e04", "8110182e-b1fc-455d-83ff-4d51a55d02a5", "825e4d12-d9a5-49f9-862a-6dae585b14a3", "85948743-33aa-4c52-8dd6-9e7f7a02c887", "8663e11d-f206-4445-a0bd-e012a5f9e483", "8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae", "9c644838-3f27-4c09-b718-744b6ae55f77", "a42b6187-465e-4dd9-926b-ff09da46b090", "a863dd1e-4847-4191-ac7f-2efb30c47777", "b7302821-2129-46f6-8d12-6397894e2b95", "ba3bc42f-a041-461e-b0ee-bc61d6d65c09", "d740062f-cf85-4194-8c19-ce0cf23ef3ad", "eac0ff4f-6bf8-4319-b7ba-cee0aca49571"], "title": "Channel Requirements for Interference-Free Wireless Mesh Networks to Achieve Maximum Throughput", "venue": "international conference on computer communications and networks", "year": 2013, "id": "6851e83e-369f-4526-9849-94f23aca2dd3"}
{"abstract": "This paper introduces a set of data flow patterns that reveal code locations able to produce equivalent mutants. For each pattern, a formal definition is given and the necessary conditions implying its existence in the source code of the program under test are described. By identifying such problematic situations, the introduced patterns can provide advice on code locations that should not be mutated. Apart from dealing with equivalent mutants, the proposed patterns are able to identify specific paths for which a mutant is functionally equivalent to the original program. This knowledge can be leveraged by test case generation techniques in order not to target these paths when attempting to kill the corresponding mutants. An empirical study, conducted on a set of manually identified equivalent mutants, provides evidence regarding the detection power of the introduced patterns and unveils their existence in real world software.", "authors": ["Marinos Kintis", "Nicos Malevris"], "n_citation": 13, "references": ["062152bd-4998-4e00-af8c-c8624cbc9857", "14c4665f-878d-4991-8b66-5d7aacca4f07", "160e12a9-e648-4173-88f2-438cdb355d4a", "17df70e7-0407-455e-a2e5-eee26012f400", "2448f6ce-230a-495c-8cab-21a8bf2865eb", "2b47a5ec-fd51-4b53-bd29-f6fc5e44da8a", "36a1f474-dca0-4b1c-8b9a-e1a65c413846", "4e684bad-f6c1-4df5-ab38-7e7ca826d5f4", "5513af4e-d344-46d9-96c6-7a45bf4e99d7", "5b03270b-2d1a-45ad-b0bc-dfa4e457d61c", "6153e1a3-0c17-49d6-bde9-240db2a42c40", "81e024c5-4bd4-42e1-b0cf-6a371828b25d", "8526380c-2607-47c1-b6a2-ab211992adca", "86fa0d78-1248-475d-8d6a-cb04571355c4", "a7122806-c66c-49e6-8876-70093d70f605", "a999b6c8-79f0-49b6-b20a-df07e2413d49", "ae57e5ef-203a-4e8f-8c2e-b334d480d5c9", "bd6a3420-d02e-4d21-a212-0087161afe89", "c8573c5a-fdef-4713-8d67-aa327a144aa4", "ce47940f-ad9c-4f55-a174-9c1d56d27261", "cf752ca1-6232-4a5d-8fda-7dd7cb70e405", "dc7a8992-eb7b-4e47-a04b-e3b626bca0c0", "e4a3b24c-eaa7-458b-a16f-ccec3af310ed"], "title": "Using Data Flow Patterns for Equivalent Mutant Detection", "venue": "international conference on software testing verification and validation", "year": 2014, "id": "4ef8a5d8-879d-44ba-b8f5-f8134c41d1a6"}
{"abstract": "This paper describes our work on building Part-of-Speech (POS) tagger for Bengali. We have use Hidden Markov Model (HMM) and Maximum Entropy (ME) based stochastic taggers. Bengali is a morphologically rich language and our taggers make use of morphological and contextual information of the words. Since only a small labeled training set is available (45,000 words), simple stochastic approach does not yield very good results. In this work, we have studied the effect of using a morphological analyzer to improve the performance of the tagger. We find that the use of morphology helps improve the accuracy of the tagger especially when less amount of tagged corpora are available.", "authors": ["Sandipan Dandapat", "Sudeshna Sarkar", "Anupam Basu"], "n_citation": 54, "references": ["4fc3caab-42fb-4f3d-9b34-bf5609ac5d7d", "8654c567-16e7-4ee2-825d-58f625a73168", "a05838da-089f-4be8-a169-b0223ae4f0ac"], "title": "Automatic Part-of-Speech Tagging for Bengali: An Approach for Morphologically Rich Languages in a Poor Resource Scenario", "venue": "meeting of the association for computational linguistics", "year": 2007, "id": "a45ec868-fd75-4a52-b932-a8a4c04013d1"}
{"abstract": "We exhibit randomized Byzantine agreement (BA) algorithms achieving optimal running time and fault tolerance against all types of adversaries ever considered in the literature. Our BA algorithms do not require trusted parties, preprocessing, or non-constructive arguments.  Given private communication lines, we show that  n  processors can reach  BA  in expected constant time    in a  syncronous  network if any  n /3 faults occur    in an  asynchronous  network if any  n /4 faults occur     For both synchronous and asynchronous networks whose lines do not guarantee private communication, we may use cryptography to obtain algorithms optimal both in fault tolerance and running time against computationally bounded adversaries. (Thus, in this setting, we tolerate up to  n /3 faults even in an asynchronous network.)", "authors": ["Paul A. Feldman", "Silvio Micali"], "n_citation": 208, "references": ["011d2be0-3700-44e0-9d49-ca1a8e5e58f9", "026c8849-ec61-4799-859b-d9bb670baa9f", "35a018d5-a334-43d4-8c3e-117e254bd296", "54f72e05-04da-4d26-bd5d-6bb60e5f1d87", "63621934-ccab-4828-93fc-4958bbfb9346", "68912f2a-9e5e-4b85-b59e-b973f44b94ca", "8a2dca1d-8d5a-4d34-a89d-4ae99b2b3a5a", "8b495c61-ea6e-4c7b-9b45-3121ab994aa8", "92a8b32d-4ebf-42fd-b268-99c6c42c8148", "98f543e3-d61c-4099-ae96-237816472592", "eb2b3a62-d0fe-47d4-907e-dc3f69fe9017", "f4e11c1a-bcb0-4a4a-939a-3d4e95ece4ff"], "title": "Optimal algorithms for Byzantine agreement", "venue": "symposium on the theory of computing", "year": 1988, "id": "f5676fa8-c7d4-4d4e-9475-c1462aede03a"}
{"abstract": "In this paper we introduce a continuous-time version of a recently proposed decentralized multi-agent optimization scheme. In this scheme, a number of networked agents cooperate in locating the optimum of the sum of their individual objective functions. Each agent has access only to its own objective function and its neighbors' estimates of the collective optimum. Under mild assumptions, we derive explicit expressions for a lower bound on the algorithm's convergence rate and an upper bound on the agents' ultimate estimation error, in terms of relevant problem parameters. We build on the analytic techniques we previously introduced, in which we treat the evolution of the mean and deviation of agents' estimates as two coupled dynamic subsystems, and provide a Lyapunov argument for the practical asymptotic stability of their interconnection. More generally, this approach turns out to be useful in deriving sharper convergence results under weaker assumptions in the continuous-time case, as well as in providing an elegant way to account for the effects of positive projections that might need to be employed by each agent in some applications. Finally, we propose an application of this scheme to the design of fully decentralized dual resource allocation algorithms.", "authors": ["Karla Kvaternik", "Lacra Pavel"], "n_citation": 50, "references": ["2735c627-4c9f-4b1d-9fab-9c2ce0a17e3b", "4014a440-363a-4a73-b102-de8c45f1b06b", "52ed45d2-f4ae-4725-8b69-011a6e9343b6", "7603cbad-955f-4122-96f9-64b5ba0efd38", "8fd6531b-c809-4e63-895b-fb91be11759d", "9c7174a1-3c73-4a2e-a78b-b23816830420", "af342d20-c229-4e21-8b04-26a5af4c8ede", "d340974e-775f-48f4-a83d-754e7d5b35db", "d9162547-fd7f-4605-855d-0a3173c4b08e"], "title": "A continuous-time decentralized optimization scheme with positivity constraints", "venue": "conference on decision and control", "year": 2012, "id": "187925cc-ea93-4fc2-a52a-dfd2e7ca2fd5"}
{"abstract": "Markov-reward models, as extensions of continuous-time Markov chains, have received increased attention for the specification and evaluation of performance and dependability properties of systems. Until now, however, the specification of reward-based performance and dependability measures has been done manually and informally. In this paper, we change this undesirable situation by the introduction of a continuous-time, reward-based stochastic logic. We argue that this logic is adequate for expressing performability measures of a large variety. We isolate two important sub-logics, the logic CSL [1, 3], and the novel logic CRL that allows one to express reward-based properties. These logics turn out to be complementary, which is formally established in our main duality theorem. This result implies that reward-based properties expressed in CRL for a particular Markov reward model can be interpreted as CSL properties over a derived continuous-time Markov chain, so that model checking procedures for CSL [3, 2] can be employed.", "authors": ["Christel Baier", "Boudewijn R. Haverkort", "Holger Hermanns", "Joost-Pieter Katoen"], "n_citation": 135, "references": ["02302d84-381f-4154-9b10-ee216d7ebd20", "045ee061-f35f-4785-a58c-a9ea4d812256", "24903b34-eb6e-4b71-b354-b67d04d93822", "40eca1ae-2870-4b43-8ab0-f3d54ea0749c", "604cb2a6-0672-42cd-8299-85a91afbc2c1", "64783443-a830-4f7d-9063-026493942009", "c733d901-eeeb-4282-9b31-19a79512a111", "e82ac6ce-36e8-43d3-8539-7055847e420f", "f3a99089-9790-46f2-9448-7be2992a3bd6", "f8fa19a0-166e-4b9e-9b1f-48ada14db1ed"], "title": "On the Logical Characterisation of Performability Properties", "venue": "international colloquium on automata, languages and programming", "year": 2000, "id": "e7d4f300-a318-4d6e-bbd8-0a255c7d19fd"}
{"abstract": "Wireless Sensor Networks play a vital role in military applications. In Military it's very important to extract the actual information from the transmitted message. Sentiment analysis is a valuable knowledge resource which analyses collective sentiments of a text and helps in decision making. This paper proposes an Intelligent Information Retrieval Technique (IIRT) based on SentiWordNet, a lexical resource which is used for aspect analysis of text messages sent among military groups. The Proposed IIRT extracts the intelligent information from the text messages transmitted in military groups in WSNs. Proposed IIRT is based on sentiment analysis, where first the aggregated message is filtered then segregated with the help of lemmatization and then opinion words are gathered by grammatical tagging. At last aspect analysis of these opinion words is done with the help of SentiWordNet. IIRT gathers the intelligent information from the original message by calculating the polarity values of the opinion words. The proposed IIRT is executed on the time stamping data messages sent among military groups in wireless sensor networks and the results prove the correctness and accuracy of our IIRT.", "authors": ["Deepali Virmani", "Savneet Kaur", "Geetika Malhotra"], "n_citation": 2, "references": ["2b93a1a1-31a7-496b-96b0-d313e9d2eae2", "997a380e-1159-40d1-9fdc-2f7fb2d0be18", "9c8f34c9-ba7a-4b5e-bea1-559f02e0f792"], "title": "Intelligent Information Retrieval Technique for Wireless Sensor Networks", "venue": "", "year": 2015, "id": "f9bbd59b-fc83-4c9d-916a-beebe1282ebe"}
{"abstract": "In this paper, an improved algorithm for enhancement of fingerprint image is proposed on the basis of the image normalization and Gabor filter Firstly, the adaptive normalization based on block processing is suggested for improvement of fingerprint images. An input image is partitioned into sub-blocks with the size of K /spl times/ L at first and the region of interest (ROl) of the fingerprint image is acquired The parameters for the image normalization are adaptively determined according to the statistics of each block. By utilizing these parameters, the block image is normalized for the next process. Secondly, a new technique for selection of two important parameters of Gabor filter is devised. These parameters are the ridge direction and the ridge frequency. In this study, the ridge direction of a block image is determined by the probabilistic approach unlike other works. With this ridge direction, the ridge frequency is selected by utilizing the directional projection. The proposed algorithms are tested with NIST fingerprint images and show significant improvement in the experiments.", "authors": ["Byung-Gyu Kim", "Hanju Kim", "Dong-Jo Park"], "n_citation": 50, "references": ["0086e6e9-009c-44fe-9195-626828e53454", "10e0cd21-cda6-4c37-90c6-af1ebdc3f83c", "4ec834fc-fb84-427f-8a0b-ee3aa9c63350", "6b37bf24-cd49-4938-947b-deae005e135b"], "title": "New enhancement algorithm for fingerprint images", "venue": "international conference on pattern recognition", "year": 2002, "id": "34d9a635-7adc-4df1-aace-51fb170babb1"}
{"abstract": "This article enhances existing approaches to present-day asynchronous awareness concepts by providing the means to explicitly represent and mediate contextual information. The resulting concept of contextual awareness takes different notions of the term context into account. Following a human-centered approach, the proposed methods serve as mediators for context between persons rather than automatically detecting context. Based on this variant of awareness, the atmosphere framework is introduced to provide mechanisms to deal with the problem of workload in tandem with contextual information. Atmosphere provides a highly tailorable structure and interface to deal with a wide variance of user and organizational requirements. The article closes with the description of a partial implementation of the framework and its evaluation.", "authors": ["Markus Rittenbruch"], "n_citation": 46, "references": ["0b83bb16-1669-4014-9395-9dad89c51a0e", "15bf6968-0530-45ac-95ed-2edbb1829379", "2107c232-3827-4209-8cd6-e201e3cc21c4", "32e76f3e-bf3f-4b04-97f2-313cdb1ba7c8", "4884ee9a-dd5f-4204-ad73-11a3f2af2285", "59071085-49f3-459f-9544-0bbecd0e0c81", "59954a6b-0e1b-4b35-a587-694c79e0e106", "69a61375-719c-4e1d-8d37-4d1908a46c97", "6ba277e0-ed18-4ac3-9e12-95e491264793", "6e752821-db46-47b4-99c2-2b4f13cec39a", "76876b42-c331-4a7c-9e63-34a3251ea16d", "77f013dc-d8f8-435f-b5f3-e3b84ac71981", "86667d77-a67c-4843-9ee1-5c9070cf07cf", "9bfa45c5-7c26-4007-adcc-bcf1a3c41907", "ab15d84f-1f77-4430-9681-964ce7b2f322", "c5c8f572-4dea-46cc-9546-b1c87faaae37", "c714d911-95e5-4ce3-8019-1db42dd04b3f", "d34bee88-436d-4e54-a4b7-d7446da8c586", "d7825e13-b803-413c-924c-7aea5e2a1159", "de8e60ab-025a-49af-9441-1f796cd0444c", "f0da2af9-4838-4942-8a5c-2a25d5f9807f", "faa8a1f2-d51d-42be-b0e7-50efc867a15a"], "title": "Atmosphere: A Framework for Contextual Awareness", "venue": "International Journal of Human-computer Interaction", "year": 2002, "id": "86c07e12-b14f-4f11-809e-64a8efdb7b8a"}
{"authors": ["Ingrid Fischer", "Manuel Koch", "Gabriele Taentzer"], "n_citation": 50, "references": ["3350ea24-e7d9-4a1d-9e62-2104ef788a11", "92cf7f71-70f0-49ff-836c-79cfec4d1db9"], "title": "Local Views on Distributed Systems and Their Communication", "venue": "", "year": 1998, "id": "c67dac0a-7a8e-49f0-9573-c864219e4f67"}
{"abstract": "Maria performs simulation, exhaustive reachability analysis and on-the-fly LTL model checking of high-level Petri nets with fairness constraints. The algebra contains powerful built-in data types and operations. Models can be exported to low-level Petri nets and labelled transition systems. Translator programs allow Maria to analyse transition systems as well as distributed computer programs written in procedural or object-oriented languages, or high-level specifications such as SDL. Maria has been implemented in portable C and C++, and it is freely available under the conditions of the GNU General Public License.", "authors": ["Marko M\u00e4kel\u00e4"], "n_citation": 31, "references": ["2d01ad02-a9b5-4a5b-8789-f0af5657fa61", "32797d89-028d-42ca-aa08-2187d9739fe8", "3b4d0dc9-e6ba-412b-90d3-000ec962a32c", "4a778f3b-5763-4bfd-a94f-e23d17b67990", "5382ddad-9e94-442b-a9ee-0229d1d685d2", "66a5d791-4d06-4674-8590-726b816f4d0d", "6c5ba743-d86c-44b6-aa8c-ca4eb41a0c78", "7dc3d6e8-85f1-4b9b-8aff-ae0415b1ea67", "846fb8fa-6bf7-4847-b3e2-d3843775546d", "8c322de3-f952-4618-96e1-29f21fefe6f0", "8f7a9f31-f81c-4b8c-89fe-e1e1089dee75", "9762e35a-b0fa-496f-930a-187994abbb72", "b933cabd-7b57-480d-9ef8-8ab1202b4bd5", "ce288664-dfb0-4389-88f4-a48bc0a25a5c", "dfc809b2-26b1-4224-9d0b-f195d4200547", "f89fce02-5ea9-454b-b706-b7a1c4b48fa9", "fdb4cbb6-3fb9-494c-bef8-d3260ea29879"], "title": "Maria: Modular Reachability Analyser for Algebraic System Nets", "venue": "applications and theory of petri nets", "year": 2002, "id": "ebd3c942-a5cc-42b4-9956-1cdaf12fbd65"}
{"abstract": "Heart rate variability (HRV) is a reliable reflection of the many physiological factors modulating the normal rhythm of the heart. In fact, they provide a powerful means of observing the interplay between the sympathetic and parasympathetic nervous systems. It shows that the structure generating the signal is not only simply linear, but also involves nonlinear contributions. Heart rate (HR) is a nonstationary signal; its variation may contain indicators of current disease, or warnings about impending cardiac diseases. The indicators may be present at all times or may occur at random\u2014during certain intervals of the day. It is strenuous and time consuming to study and pinpoint abnormalities in voluminous data collected over several hours. Hence, HR variation analysis (instantaneous HR against time axis) has become a popular noninvasive tool for assessing the activities of the autonomic nervous system. Computer based analytical tools for in-depth study of data over daylong intervals can be very useful in diagnostics. Therefore, the HRV signal parameters, extracted and analyzed using computers, are highly useful in diagnostics. In this paper, we have discussed the various applications of HRV and different linear, frequency domain, wavelet domain, nonlinear techniques used for the analysis of the HRV.", "authors": ["U. Rajendra Acharya", "K. Paul Joseph", "N. Kannathal", "Choo Min Lim", "Jasjit S. Suri"], "n_citation": 1305, "references": ["364b8d5b-9ce6-4ff5-b9bb-d3342a9d00d7", "3d357303-ffa3-4676-a6b4-2237f5e9fb28", "3ff52828-0972-4b92-a8bc-b15b240b237f", "6d8abeb1-6cec-4b5f-8441-5a2a565bfa3c", "72c0c418-3fb0-4ad5-af2d-4d8803f2c763", "9eff9e80-c657-4a32-82e4-1e79fd4a9f40", "af0305d2-0e1f-4b69-9fb6-beb8a48f1fda", "b27e99cb-56f1-48ba-86c4-aa88037ab730", "b6227734-5054-42f5-a3ad-36694d9358be", "b78e0e6e-c472-4919-ae96-1a69d037609b", "f3f60394-d3df-482d-ba7e-0e2cff28eedd"], "title": "Heart rate variability: a review", "venue": "Medical & Biological Engineering & Computing", "year": 2006, "id": "7a7dca9f-e3f1-4930-a2f1-4a618c0a1974"}
{"authors": ["Oded Goldreich", "Amit Sahai", "Salil P. Vadhan"], "n_citation": 123, "references": ["0dd040aa-d2e6-447d-ad59-c2a19b828c99", "1a94a556-e80f-4aea-aa32-0dc71d91fbaf", "1e346a22-0f75-4713-9c68-5c8dd9cacdd2", "29a88cc8-b0ac-41a3-9a72-699050c9aad6", "2f4de822-6264-454c-b787-667757b5e2d2", "44227e17-6832-468d-a41a-0777020af6a3", "5e197249-0312-49a8-ad2a-30491df95412", "6cadc6ba-8a77-4233-833f-d0532074f639", "70af3b1c-81bc-4774-9a5c-1db432c0d6c5", "769ef5ce-43eb-4ea3-8f5a-c94a0bd2e3cb", "7958d2bb-d2af-4726-98fc-11939a71a669", "8506cb9b-c48e-4f22-ac40-dc0cd45ac8ad", "91670cbd-23fe-4704-a3c3-68c895a39490", "be503502-3269-40b6-8e16-a51c4585695e"], "title": "Honest-verifier statistical zero-knowledge equals general statistical zero-knowledge", "venue": "symposium on the theory of computing", "year": 1998, "id": "9107aed7-7d32-45f6-bb46-23331e70ea5f"}
{"authors": ["Rajkumar Roy", "Ian C. Parmee"], "n_citation": 50, "references": ["6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "8103ce41-33c5-43eb-91e3-c0c6566651d0", "8e03f499-48ce-43cd-ac9e-9dcb64cfd56b", "f505afb8-a7c5-408f-a1bd-1c8c3ac332d1"], "title": "Adaptive Restricted Tournament Selection for the Identification of Multiple Sub-Optima in a Multi-Modal Function", "venue": "artificial intelligence and the simulation of behaviour", "year": 1996, "id": "ffc774ac-39d6-4e18-a331-6f786d8f625b"}
{"abstract": "Clustering in spatial data mining is to group similar objects based on their distance, connectivity, or their relative density in space. In the real world there exist many physical obstacles such as rivers, lakes and highways, and their presence may affect the result of clustering substantially. We study the problem of clustering in the presence of obstacles and define it as a COD (Clustering with Obstructed Distance) problem. As a solution to this problem, we propose a scalable clustering algorithm, called COD-CLARANS. We discuss various forms of pre-processed information that could enhance the efficiency of COD-CLARANS. In the strictest sense, the COD problem can be treated as a change in distance function and thus could be handled by current clustering algorithms by changing the distance function. However, we show that by pushing the task of handling obstacles into COD-CLARANS instead of abstracting it at the distance function level, more optimization can be done in the form of a pruning function E'. We conduct various performance studies to show that COD-CLARANS is both efficient and effective.", "authors": ["Anthony K. H. Tung", "Jean Hou", "Jiawei Han"], "n_citation": 246, "references": ["010793c8-fedb-49ee-88bc-1e20f8bae870", "1b2978e6-cdf8-42fb-beb0-690759e4d562", "1c7f6b4c-ea89-45d4-9778-8d64987f8a0f", "3798c675-2d6a-456c-a79e-f3fcbfa50989", "57697343-4573-43c6-be91-5456f3e16b0c", "9982ca07-6ac3-4ad6-a826-fe469a22ac0d", "a8ac113b-d9d1-4083-accd-85a17751a944", "ab303706-3c44-43a4-bf7d-bbc746b64d37", "b0bdd4b7-7a7f-4a25-ba45-0e09c2a39711", "b50afe09-263f-44ea-8628-4fe0f7da2183", "bdb8d83d-1771-4399-b593-d43be5a9f892", "d9150c43-b726-4cd5-87ed-debc6c66d895", "f0a2aab5-5ab0-4518-9097-1a78f0636156"], "title": "Spatial clustering in the presence of obstacles", "venue": "international conference on data engineering", "year": 2001, "id": "4faabf56-a333-4a47-8c41-8f56a7d5f92b"}
{"abstract": "This paper shows how to quickly move the state of a running computer across a network, including the state in its disks, memory, CPU registers, and I/O devices. We call this state a  capsule . Capsule state is hardware state, so it includes the entire operating system as well as applications and running processes.We have chosen to move  x 86 computer states because  x 86 computers are common, cheap, run the software we use, and have tools for migration. Unfortunately,  x 86 capsules can be large, containing hundreds of megabytes of memory and gigabytes of disk data. We have developed techniques to reduce the amount of data sent over the network: copy-on-write disks track just the updates to capsule disks, \"ballooning\" zeros unused memory, demand paging fetches only needed blocks, and hashing avoids sending blocks that already exist at the remote end. We demonstrate these optimizations in a prototype system that uses VMware GSX Server virtual, machine monitor to create and run  x 86 capsules. The system targets networks as slow as 384 kbps.Our experimental results suggest that efficient capsule migration can improve user mobility and system management. Software updates or installations on a set of machines can be accomplished simply by distributing a capsule with the new changes. Assuming the presence of a prior capsule, the amount of traffic incurred is commensurate with the size of the update or installation package itself. Capsule migration makes it possible for machines to start running an application within 20 minutes on a 384 kbps link, without having to first install the application or even the underlying operating system. Furthermore, users' capsules can be migrated during a commute between home and work in even less time.", "authors": ["Constantine P. Sapuntzakis", "Ramesh Chandra", "Ben Pfaff", "Jim Chow", "Monica S. Lam", "Mendel Rosenblum"], "n_citation": 519, "references": ["004a3de1-21f1-4f66-bf6f-663581826ea5", "0209c39e-1602-4ed0-965c-ce1ac295578f", "0e015120-cce1-4cb7-bbe3-f0ea3679c5c3", "1c2688fa-75db-4c48-9a40-10ba11aada5b", "2c9ebc3d-713f-42d8-a867-0ff2d24644d3", "53f82d8c-22d7-43e4-be03-fe0cdd7b8abc", "553e719c-81cd-4191-9c68-f0adf7c15361", "569b777f-eb40-4fa8-9567-c5844c8c3522", "65225cd7-9916-41fe-8ef0-633d688a4ede", "72d25d6f-1fc1-435e-b0be-c15a2a384f2a", "735dedeb-a935-4e6e-b071-4f7e3edfebb8", "8f877f63-55b7-4408-9cf0-cb5fffe27ac6", "9553fde5-7523-4944-abb2-ce12a6d02afc", "a92590bb-3e2a-4670-97ca-67e9ab17f9b5", "b5314950-0f11-43e7-be75-0e132b6a6c7f", "fa891d16-aafe-45a6-91d6-ec49da2ca5d1", "fd2c1d27-30e7-4004-a891-81062e14089f"], "title": "Optimizing the migration of virtual computers", "venue": "operating systems design and implementation", "year": 2002, "id": "fd5b4339-0328-41fc-90b7-12d5f093072c"}
{"abstract": "This paper proposes and analyzes bandwidth allocation and reclaiming schemes on wireless media to enhance the timeliness of the real-time messages and accordingly the correctness of fuzzy control decision. Bandwidth allocation scheme generates efficient round robin polling schedule represented as a capacity vector by directly considering the deferred beacon problem. The resource reclaiming scheme reassigns unused slot time to non-real-time traffic by extending the collision period without violating the hard real-time guarantee. The simulation results show that the proposed scheme can not only enhance the schedulability of wireless network by up to 18% but also give more bandwidth to the non-real-time traffic up to 5.3%, while the resource reclaiming scheme can maximally improve the achievable throughput by 11% for the given stream set.", "authors": ["Junghoon Lee", "Mikyung Kang", "Yongmoon Jin", "Hanil Kim", "Jinhwan Kim"], "n_citation": 10, "references": ["0e37e2f2-5d6d-4468-a3bd-589be2a4ada0", "0ea7381b-e5c8-4ae4-a26c-e45779b88639", "1646dd38-344a-4130-9509-6ee4d8b99fa7", "4084da27-27c0-4c36-b2a0-aa1eb9f45ab5", "70b7d8fc-4d0d-43b6-aa10-30aef1dcad52", "cac32dc2-a3c5-4f98-b5c0-ed9b64c7f6d8", "e35c93fe-9736-4478-b5d8-94cb2f05627f"], "title": "An efficient bandwidth management scheme for a hard real-time fuzzy control system based on the wireless LAN", "venue": "granular computing", "year": 2005, "id": "7cb01c13-b35f-438c-90a5-7e98447621f5"}
{"abstract": "Acoustical signals are often corrupted by other speeches, sources, and background noise. This makes it necessary to use some form of preprocessing so that signal processing systems such as a speech recognizer or machine diagnosis can be effectively employed. In this contribution, we introduce and evaluate a new algorithm that uses independent component analysis (ICA) with a geometrical constraint [constrained ICA (CICA)]. It is based on the fundamental similarity between an adaptive beamformer and blind source separation with ICA, and does not suffer the permutation problem of ICA-algorithms. Unlike conventional ICA algorithms, CICA needs prior knowledge about the rough direction of the target signal. However, it is more robust against an erroneous estimation of the target direction than adaptive beamformers: CICA converges to the right solution as long as its look direction is closer to the target signal than to the jammer signal. A high degree of robustness is very important since the geometrical prior of an adaptive beamformer is always roughly estimated in a reverberant environment, even when the look direction is precise. The effectiveness and robustness of the new algorithms is proven theoretically, and shown experimentally for three sources and three microphones with several sets of real-world data", "authors": ["Mirko Knaak", "Shoko Araki", "Shoji Makino"], "n_citation": 50, "references": ["15251851-c3fd-4c87-9079-7e7cd56e7e6b", "46351753-24cb-4ebd-a2eb-db6a46dcdca0", "519fa34b-b981-4cd7-ac12-0071fdfd9b1f", "576ceab7-3cfa-4964-9875-295a9276a496", "581df112-db29-4299-b7d3-38b08468c200", "6f339396-22e8-41d0-a2f7-ff4f78665b45", "7ccac9f1-f310-45b1-9c15-7ff32f1052c7", "8337dbea-9097-493d-ad79-17d2a5bf2765", "8fd1e3ec-7ad8-47f9-8fe1-351602d6e0b1", "984e6f85-be9b-4965-b8c0-ae5887007504", "9cfb9233-a8b9-459f-a5fd-9e0bdc82ed24", "a6c892a4-5493-4013-b2e6-fa39d824463d", "d1c76d19-d54c-4dc5-8cbc-e04c80832768", "f7b2adfd-c11d-475d-8ada-3fe178f62849"], "title": "Geometrically Constrained Independent Component Analysis", "venue": "IEEE Transactions on Audio, Speech, and Language Processing", "year": 2007, "id": "db2ea4b2-21bb-41d5-a0dd-f93f349b7782"}
{"abstract": "During maintenance, professional developers generate and test many hypotheses about program behavior, but they also spend much of their time navigating among classes and methods. Little is known, however, about how professional developers navigate source code and the extent to which their hypotheses relate to their navigation. A lack of understanding of these issues is a barrier to tools aiming to reduce the large fraction of time developers spend navigating source code. In this paper, we report on a study that makes use of information foraging theory to investigate how professional developers navigate source code during maintenance. Our results showed that information foraging theory was a significant predictor of the developers' maintenance behavior, and suggest how tools used during maintenance can build upon this result, simply by adding word analysis to their reasoning systems.", "authors": ["Joseph Lawrance", "Rachel K. E. Bellamy", "Margaret M. Burnett"], "n_citation": 42, "references": ["10131c9a-7971-4241-bff5-6cc507af60fa", "3977dd47-9402-46a4-8cf1-40d4ab124255", "3c8f495d-993a-464f-9ca1-cc2cbe87264b", "3e0370c4-e0b1-4c6f-a13c-b2b7ff9ceac0", "5477716a-9a72-4ce0-a237-9b74bee747cf", "651d58f3-5b85-41db-8b6c-cb7084ac0315", "65dedb28-b956-459c-bb38-0f7f0520c372", "6c4d90c8-cc2a-47c6-a6fc-361c36d01ddc", "81919e0f-df11-4be6-9236-2c3708b618b7", "83c584f6-27a0-4965-8391-d5816da3e060", "bc3eee18-dec3-47c8-8908-d9dc1e1197ee", "ce9f2344-ae4d-4196-bf02-c0d164937a49", "fbadd9a9-e6c9-490b-8818-febb1738a2dc"], "title": "Scents in Programs:Does Information Foraging Theory Apply to Program Maintenance?", "venue": "", "year": 2007, "id": "da565b5e-5d2a-4264-aebc-a089500ef4ed"}
{"abstract": "IP spoofing is one of the most common network threats today. While current IP Traceback techniques are capable of identifying the source of a message, they are limited by the huge number of messages that routers have to store to provide this facility. One way to reduce the storage overhead is to store the messages as indices in a Bloom filter. Current systems use Bloom filters at a router to know if a given message has gone through that router. However, often there is a need to know if a similar message has traversed through the router. This calls for similarity measures in the context of Bloom filters. In this paper, we develop such similarity measures (coefficients) in the context of two specialized Bloom filters \u2014 Hierarchical Bloom filter (HBF) and Winnowing Block Shingling (WBS). We compare the efficacy of these similarity measures with the Jaccard similarity coefficient. Simulations were carried out to evaluate the measures. The results indicate that HBF-measure is an optimistic metric and WBS-similarity is a pessimistic measure. Jaccard measure falls between the two. We propose a weighted metric that combines all the metrics and is more flexible than the individual measures.", "authors": ["A. Telidevara", "V. Chandrasekaran", "Avinash Srinivasan", "Ravi Mukkamala", "Shreyas Gampa"], "n_citation": 50, "references": ["08aa4226-d8a1-42cf-9eb6-6fe0899c2420", "346a6fbd-115d-40ef-9015-2f06f2d86257", "4e394ecc-3015-4b57-97af-33a34230dba5", "502bcc3c-d14b-4edb-8ca2-a2ec0925c41a", "5e0cd287-23ce-4c6c-aba2-e9364b20e295", "85e26c5b-985e-4032-881e-809c535b6c9f", "8761ee80-a4d0-4fc9-a2bb-7dbc8235480d", "b1f771a9-3739-446d-adc3-600bd9bb7c8b", "c4f0d977-2bd8-4e47-a02d-4fdf6e8e61c2"], "title": "Similarity coefficient generators for network forensics", "venue": "", "year": 2010, "id": "d12e078b-0957-409e-a403-23ea974e4e46"}
{"abstract": "Multimedia data are generally stored in compressed form in order to efficiently utilize the available storage facilities. Access to multimedia archives is thus dependent on our ability to browse compressed information. In this paper, a novel approach to multiple object tracking from compressed multimedia databases is presented. This approach is intended to operate in a distributed environment, where users initiate video searches and retrieve relevant video information simultaneously from multiple compressed video archives. The system operates on the compressed video to find and track objects of interest and determine their positions in the image. This enables more complex query formulations in terms of the relative positions of the target objects in the image. The filtering and analysis of motion information (motion vectors) is used to track objects in the video bit stream. Once the search has terminated, the system may decompress and display the query-relevant video sequences upon request. C \u221e 2000 Academic Press", "authors": ["Dan Schonfeld", "Dan Lelescu"], "n_citation": 50, "references": ["0c2a5217-9477-436d-bf0f-82d64deb44b2", "0c2e76eb-c2a1-45d4-8d49-6e1415b4c37c", "0ef65833-1afb-4c5d-a1a5-ab77db9b4604", "24c22c07-3789-4a3f-b2b8-6904de05ecf1", "3dbbfb7b-8879-4240-8ffe-00cb2fa43fdb", "4a53e251-9066-4388-84e1-ac2a7e719cae", "51ab753d-aa72-4c0a-b36e-8a31bd93f3c9", "78c0c738-ffeb-492c-aa84-3f867500a0fc", "7cd2061f-636a-4f06-9a1a-9a686c10b732", "7e7aeb72-43aa-4b8d-94c3-d20c63efc175", "90d93129-9501-4521-a610-2b7fbff31c1a", "96e77314-2766-4153-b34d-6373093d659b", "aef49ce6-051c-4146-8237-485d14a9b6ff", "b1fe1e9f-265e-479f-988b-dffa63c3f39b", "bb4fd142-3cbc-4649-b41b-01a029a671cb", "c9637654-5f37-4090-80b2-37ffddf2500a", "d6633ead-f1a2-406d-8336-9d6474b5441b", "e4fca52c-1217-4d18-9410-02b4ee1f89dc", "ee93ef28-8456-4d4b-b06f-06f2dfa92be2", "f183371a-4b0e-4e22-86f2-d944e8198b50", "f815f346-6707-4036-b766-0a0ca290809f"], "title": "VORTEX: Video Retrieval and Tracking from Compressed Multimedia Databases\u2014Multiple Object Tracking from MPEG-2 Bit Stream", "venue": "Journal of Visual Communication and Image Representation", "year": 2000, "id": "680dedc2-a949-4955-92e7-b768f0b6a759"}
{"abstract": "The hearing sense on a mobile robot is important because it is omnidirectional and it does not require direct line-of-sight with the sound source. Such capabilities can nicely complement vision to help localize a person or an interesting event in the environment. To do so the robot auditory system must be able to work in noisy, unknown and diverse environmental conditions. In this paper, we present a robust sound source localization method in three-dimensional space using an array of 8 microphones. The method is based on time delay of arrival estimation. Results show that a mobile robot can localize in real time different types of sound sources over a range of 3 meters and with a precision of 3/spl deg/.", "authors": ["Jean-Marc Valin", "Fran\u00e7ois Michaud", "Jean Rouat", "Dominic L\u00e9tourneau"], "n_citation": 340, "references": ["1563bf2c-2d47-4bfb-a2f0-88858a15eaf4", "3b7ce44e-e696-457e-bfde-b6af4c7670d7", "551e37be-b851-4a32-9211-f444bea7a453", "d0d4d088-947d-488f-9020-8b069ead75fa"], "title": "Robust sound source localization using a microphone array on a mobile robot", "venue": "intelligent robots and systems", "year": 2003, "id": "1d7a9d54-bd31-4cd0-b7a5-78a8b60b7ec9"}
{"abstract": "To improve the scalability of the Web, it is common practice to apply caching and replication techniques. Numerous strategies for placing and maintaining multiple copies of Web documents at several sites have been proposed. These approaches essentially apply a global strategy by which a single family of protocols is used to choose replication sites and keep copies mutually consistent. We propose a more flexible approach by allowing each distributed document to have its own associated strategy. We propose a method for assigning an optimal strategy to each document separately and prove that it generates a family of optimal results. Using trace-based simulations, we show that optimal assignments clearly outperform any global strategy. We have designed an architecture for supporting documents that can dynamically select their optimal strategy and evaluate its feasibility.", "authors": ["G.E.O. Pierre", "van M.R. Steen", "Andrew S. Tanenbaum"], "n_citation": 125, "references": ["27b24e7f-9310-41a6-bc12-1fcf37cf928a", "43781308-7ab6-4a55-981b-f16ac050f8a6", "4bfa65c5-4fce-4399-98b6-0470a5aa281a", "50de5f13-c4ef-4c70-882e-7b6586f0c09a", "5320bc98-beb8-4b2c-b906-3a05df4e018c", "5a2cfd16-73c3-4a9a-9e92-96a5d0f34fe6", "5ad83b9b-6ae3-42ea-9b5f-e2fabe669c74", "5f1a52f2-faca-45ab-bb82-8d459d1c77ce", "5fa0709f-7330-417f-8da7-3ab31d91da5b", "60469fa8-4b4c-4146-857f-abd99a747051", "622b4845-f870-431c-8445-7921dd8d6c7c", "6370cfda-5e81-4832-839e-fcdd3787f87c", "64a1581a-5577-4a7f-b64d-6e0985216847", "6e17f4c2-6698-4048-813f-375e171d2e5d", "6fe24d1c-4d76-4b8e-a619-85791d5c76ed", "917d43c2-4bdd-49ed-afc6-66df3a756f6f", "98f5e5de-e7d2-4d72-b64f-0860f79d0dba", "9d11aa6c-586e-40dc-a475-094bf043431f", "9f5c38cd-b9ca-4bce-9cfe-cdae3bfa4189", "a0510266-227a-41c1-9bc3-20fb44f80b5d", "a6a83822-a71e-439f-966a-eaa4f75a7d91", "ae8ecc68-0486-4aeb-9a2a-5639214e1150", "b75a0c34-2080-473a-9f83-ae0a1c45e121", "b9aef3f2-cc09-41c2-a7ec-84ec158b487f", "c9b19000-e110-44c3-9659-48dfa186179b", "cae1e692-9d2c-48ca-80da-956c63397390", "e2cfbbb0-e1ff-48bd-9ccf-c5e50b4dcff6", "f139baab-b0a0-4eaf-9a15-f9b2928ce27c", "ff086b09-5553-429f-b80c-c78a13ee6bbc"], "title": "Dynamically selecting optimal distribution strategies for Web documents", "venue": "IEEE Transactions on Computers", "year": 2002, "id": "c206ead3-d823-4645-8308-842234828fc7"}
{"authors": ["Robert E. Bixby", "Mary Fenelon", "Zonghao Gu", "Edward Rothberg", "Roland Wunderling"], "n_citation": 303, "references": ["0e4badbb-7a24-494e-b4a2-48499edcf173", "35ce4a1d-ae1e-4f2d-bb9d-a7881ed0de81", "833fd04a-3c90-4fa6-aff5-ca1ad3ca441e", "ac084a2c-706c-48c1-931f-e0bdbf8c2aeb", "ac28409e-3f2d-49a1-8463-4095dd82c753", "c1ee304c-498d-42de-8459-ed3618b32598", "e0ff6569-833f-44b7-a2a3-e9ab07420722", "e3ad7b75-7c6f-412b-8c35-ad6417ccb2bc", "f01abda8-877f-4df5-bc80-50f2a4487e8f", "f94c480c-a7e2-4088-9dd5-b51b5a21dda7"], "title": "MIP: Theory and Practice - Closing the Gap", "venue": "", "year": 1999, "id": "e2eee064-5a24-4572-94bb-ff42b597080e"}
{"abstract": "Texture segmentation is one of the early steps towards identifying surfaces and objects in an image. In the paper a moment based texture segmentation algorithm is presented. The moments in small windows of the image are used as texture features which are then used to segment the textures. The algorithm has successfully segmented binary images containing textures with identical second-order statistics as well as a number of natural gray level texture images. >", "authors": ["Mihran Tuceryan"], "n_citation": 215, "references": ["187d4fe7-8c93-42ae-88ac-309c1f4d3539", "1ea5e7e1-b1ac-4b50-ad75-d882e4627317", "400c7d3d-a4e9-49a1-821c-3646904d44ed", "a7118e96-8f8c-4294-9abb-e12647db7127", "a97d6326-5dcc-4478-8554-46ef738e1f0a", "c54f5e9b-8ee1-4c6d-934f-84c1f2413015", "d12c8fca-a82c-45db-b29c-8fc7a47fce2e"], "title": "Moment based texture segmentation", "venue": "international conference on pattern recognition", "year": 1992, "id": "8c00716e-6803-4f11-b7a9-bd9955ad5c03"}
{"abstract": "A new hand-held laser range scanner is introduced that can capture multi-view range images of an object and integrate the images without registering them. The scanner uses a reference double-frame that acts as the coordinate system of the object. Range images captured from different views of the object are in the coordinate system of the double-frame and, thus, automatically come together. A single-view image is obtained by sweeping a laser line over the object while keeping the camera fixed and analyzing the acquired laser stripes. The laser line generator and the camera can move independently, making it possible to conveniently scan an object just like painting over it with a paintbrush while viewing it from different views. The hardware and software organization of the scanner are described, the characteristics of the scanner are investigated, and example images captured by the scanner are presented.", "authors": ["Lyubomir Zagorchev", "A. Ardeshir Goshtasby"], "n_citation": 37, "references": ["1f520d1a-5870-477d-85d7-0f50be690ea7", "1ff54fc8-23e2-402c-9645-7cf53f7505fa", "243e4af7-3519-47a8-83a3-bb7ea9281444", "338f8c83-4965-455b-ad03-805af7400e88", "36dd023a-14a7-479a-89c6-26d731dc5ae3", "3c82f802-1de8-4eaa-aafe-533a5d3f8056", "4d65d267-6ba1-46fc-87b2-220f24faf134", "590476dc-e34f-4e1b-ba3c-e83a17773cae", "7a2f437f-f3ba-4f94-b29a-ad746eb5cdb8", "8c0bdf2e-74bd-46c6-ae3d-784f37594c7f", "8c7e21f2-3823-4516-97da-eb2c8ac154e3", "96667231-4049-4e4a-bf20-7d4b3db79455", "a1b4e146-5111-4c2c-b07a-5026cac29367", "a3467d3b-fec5-45ad-9545-de065cd616d7", "a7a01782-8e14-4dd6-9336-60718abbfc0b", "b99bba45-2c69-4965-9791-c34dccf2cbe8", "cf4390ad-9d8f-4184-9076-fca0eff4bb11", "dabd43c0-d6dd-487e-a83e-865070297a46", "dfb17b88-02c4-4941-b386-12303355a280", "eaaa633b-0b1d-44e0-9ed9-836344603109", "f5a9670c-15ea-488c-a729-b2a179ece08b", "f9fd6695-adec-4a27-99de-47cdd887ddef", "fbf9aee0-7362-4662-becb-e63b232bcded", "fd82d4f6-8a11-4e1d-b14e-fe6c43322fc6", "fd99798c-d5f3-42fc-a14c-4edae6dfbd5f"], "title": "A paintbrush laser range scanner", "venue": "Computer Vision and Image Understanding", "year": 2006, "id": "42072326-0ade-47f0-a813-fa019f483f8b"}
{"abstract": "Fault injection is an effective method for studying the effects of faults in computer systems and for validating fault-handling mechanisms. The approach presented involves injecting transient faults into integrated circuits by using heavy-ion radiation from a Californium-252 source. The proliferation of safety-critical and fault-tolerant systems using VLSI technology makes such attempts to inject faults at internal locations in VLSI circuits increasingly important. >", "authors": ["Johan Karlsson", "Peter Lid\u00e9n", "Peter Dahlgren", "Rolf Johansson", "Ulf Gunneflo"], "n_citation": 216, "references": ["3bc8564f-242d-4a42-88d4-82e51b5360fe", "5454c4d3-5607-45cc-a167-918e469a10e8", "5f5b25cb-066c-4716-a082-202b68447e2c", "8660856f-eba3-410f-af5c-c3929641ba72", "e05f3c0d-8c8a-42dd-84ad-2fb52aaa6a82", "fee4f97e-4752-4b13-b4ce-0d8268934548"], "title": "Using heavy-ion radiation to validate fault-handling mechanisms", "venue": "international symposium on microarchitecture", "year": 1994, "id": "6bcf6b13-313d-42e4-b828-bed920213550"}
{"abstract": "We discuss the general concept of calculational reasoning within Isabelle/Isar, which provides a framework for high-level natural deduction proofs that may be written in a human-readable fashion. Setting out from a few basic logical concepts of the underlying metalogical framework of Isabelle, such as higher-order unification and resolution, calculational commands are added to the basic Isar proof language in a flexible and non-intrusive manner. Thus calculational proof style may be combined with the remaining natural deduction proof language in a liberal manner, resulting in many useful proof patterns. A case-study on formalizing Computational Tree Logic (CTL) in simply-typed set-theory demonstrates common calculational idioms in practice.", "authors": ["Gertrud Bauer", "Markus Wenzel"], "n_citation": 50, "references": ["09a472b4-8040-4627-8bd5-471c3920d09b", "10e36f78-f471-4a73-adb3-99734b9db924", "14ba3e95-f380-4a7d-ac58-d461ce37d1d8", "1dd1e7a1-cf45-41c7-b4f7-928594f3ea12", "27b1986e-af76-4731-b0cb-728fd0e09777", "335befa9-382f-47a9-9e96-7c71291a15b3", "3e463040-e697-4c3c-a555-5635b90ef134", "44668c03-840c-4130-b48d-80fb380f3e61", "9e64910a-3cd7-4312-a1fa-a71e5ec62bec", "de61533d-1f0a-441b-bc32-b10243cb622a"], "title": "Calculational Reasoning Revisited (An Isabelle/Isar Experience)", "venue": "theorem proving in higher order logics", "year": 2001, "id": "a03dfb77-d702-480a-b0dd-db9926695757"}
{"abstract": "The WGS84 ellipsoid is tessellated using quadrilaterals of roughly the same size. This tiling is of general interest to global geographical information systems, but it has special relevance to global digital elevation models based on block averages. The simple relation between the tiling presented and the latitude/longitude reference system makes the tiling easy to implement, and the quadrilateral property of the cells offers regular subdivision like quadtrees. An error analysis gives a strict bound on the difference between cell averages calculated in plane and ellipsoidal coordinates. The mathematical results from this investigation are general and can be applied in error analysis related to other types of quadrilateral meshes. The grid can be easily subdivided into quadtree blocks. The error estimate makes it possible to combine the quadtree structure with standard two-dimensional wavelet representations.", "authors": ["Jan Terje Bj\u00f8rke", "Stein Nilsen"], "n_citation": 50, "references": ["14fe7efa-eef2-4597-8fc2-489a0bcd636d", "24e2beb6-4741-48ad-87fa-27c108ab2ffd", "df17e46b-901c-4a36-8028-759e7beffc4c"], "title": "Examination of a constant-area quadrilateral grid in representation of global digital elevation models", "venue": "International Journal of Geographical Information Science", "year": 2004, "id": "f8323a90-d462-4c6c-a5e7-b6a7e378fd8e"}
{"abstract": "This paper reviews research on automatic summarising in the last decade. This work has grown, stimulated by technology and by evaluation programmes. The paper uses several frameworks to organise the review, for summarising itself, for the factors affecting summarising, for systems, and for evaluation.#R##N##R##N#The review examines the evaluation strategies applied to summarising, the issues they raise, and the major programmes. It considers the input, purpose and output factors investigated in recent summarising research, and discusses the classes of strategy, extractive and non-extractive, that have been explored, illustrating the range of systems built.#R##N##R##N#The conclusions drawn are that automatic summarisation has made valuable progress, with useful applications, better evaluation, and more task understanding. But summarising systems are still poorly motivated in relation to the factors affecting them, and evaluation needs taking much further to engage with the purposes summaries are intended to serve and the contexts in which they are used.", "authors": ["Karen Sparck Jones"], "n_citation": 344, "references": ["02e0b9b4-b55f-4d31-aeae-88d3182e8362", "048f0427-622a-4114-a056-55e85fbd7a04", "11468255-02a1-446c-90f6-9c8e070bf056", "135c7d8b-578a-462d-98d0-0288eec3a9fc", "13be3b29-85e5-4d99-967e-8101b0860cf6", "2c3cb023-6731-490f-8e58-c3582754645d", "2e5b14fa-c54a-4191-9711-6dda5f0eb75d", "3268d2e1-c734-4618-910c-15302ba3e953", "39e42ab7-16c5-4b95-9b7d-f1b9f9d3ccdf", "40354185-c519-46d9-be0d-9de4b519c969", "4398c4b1-a1f9-4599-a3e9-271d334b1c5d", "4568ebdb-a88e-4870-bfe0-54e99cd37907", "4d6d6771-9f00-4524-be41-84819600a9f1", "4e48f08b-df95-44d2-86a5-525f8f9335ae", "4ebf1acd-5a5c-4c7d-9845-d5b2545f6ca9", "50b0c830-3972-48a9-8bc6-e24b867f6446", "51c3e47b-9d24-4119-8fb3-51e699177618", "572f4345-2b82-4f25-ad73-5f8c318e8c31", "58eab481-71dd-4b9b-9b11-68880ace8aae", "5dea7564-e28d-4906-911e-0c10ad4dc32f", "658ed0b3-f66c-4696-8f09-47d0ea4b4398", "6e677df2-9ace-445e-a7e8-7f5ed5b91582", "754a41c5-88b0-4206-a51d-49e759211538", "75a740ac-fbd7-4d32-b619-65abb60880b9", "7d0884ef-5faf-47b6-8aa6-b197581bbc8b", "7d759bcc-5ce1-45bc-a04f-f763182656c5", "7dac955b-e01d-4069-96a0-e7d306ed205f", "835d40ff-2f69-45e6-842f-69141d0520c8", "8b6b8652-127b-4e49-a833-c4bde5856d41", "9090ecde-0cbc-40d1-9d18-9197aacf783b", "92311dcc-18f1-4158-8a16-b3b920c7d716", "967a658f-caee-4957-ac8f-0b06d98b5c7b", "97ab4610-4de0-4991-bd51-8180f650e7a8", "9f711920-56a2-4f55-903a-268afa123d78", "a1cc81da-48b5-4e4f-a9c2-9bcb8d518fc7", "a3b16b01-90b0-4c0f-82ea-5ebc4c2bc3f2", "a7ee5788-a47e-417c-b5e1-0272a6581811", "b1a48fca-5e47-483d-8171-5a604b136e1b", "b23adb78-65ed-4bbb-bce9-fdd70d14699e", "bac42b33-620d-4414-b4dc-2cf245432321", "bc889676-4be9-4288-a05e-580080038bac", "bcea6f66-316b-492e-9242-e779180d1da0", "c65ac26b-73f4-4133-8304-8e70125c358b", "c8a1eae3-e8ea-41de-a471-a2539c9cfa9c", "ca4d5e0b-a808-4a8b-8feb-e613bb8b8aaf", "ccf66113-dd3b-41a4-b8d4-40180550e6bd", "d13e1fd6-83b6-45c3-a473-ebd53e5b85e8", "e8325d31-dfb0-467c-a56e-48a95eeea2c0", "e96f028e-c688-4f2c-87c2-f85862587f0a", "eab9ce6a-00fa-49e3-9e51-b2ce3807d9c2", "ebb4fcf8-cb64-43f1-8768-0214ea3690ce", "ec217317-bfc6-4548-9204-b1134b5a50ba", "f6527aab-f84c-4bc8-bb0d-08e5febed045"], "title": "Automatic summarising: The state of the art", "venue": "Information Processing and Management", "year": 2007, "id": "ecb125c3-cdc1-435d-83d0-b053c0e6140a"}
{"abstract": "It is observed that most object oriented coupling metrics are macroscopic, which makes them unsuitable for making finer refactoring decisions. The notions of microscopic viewpoints and coupling projections are introduced. Existing metrics are classified in terms of viewpoints and projections. Two microscopic metrics called relative method coupling (RMC) and relative inward coupling (RIC) are introduced, and a method of applying them to refactoring is discussed. A case study is also included.", "authors": ["Padmaja Joshi", "Rushikesh K. Joshi"], "n_citation": 24, "references": ["0899c1e2-6bac-45e9-ae6f-7f0f71a022a6", "24cbcdb6-3d6f-41fa-855a-0166b7060852", "283a47a0-f895-4185-b433-fe7a35408aca", "493f51c9-d389-4555-afb2-30aa84e56649", "79cf0ac7-c5ea-4c13-94c6-a1039347a03f", "9704001a-a026-4109-9021-ce7853cd7e63", "a2841161-6610-416e-aa69-b8b71757d106", "a2bee3ce-2a4d-4861-9494-b0060ab03219", "d1641855-866e-4b35-b5e7-5ba1415b1eb0", "d32786fc-ea8d-41f0-a803-5d00e550329c", "d76616fc-e6c4-48da-9770-298c70b33c5e", "e580b2d9-3e7c-4122-9932-f2cf985040cd"], "title": "Microscopic coupling metrics for refactoring", "venue": "conference on software maintenance and reengineering", "year": 2006, "id": "0f15b7d7-730b-4990-9801-2c3f8b1abc4e"}
{"abstract": "We propose an algebraic semantics for the temporal logic CTL \u2217 and simplify it for its sublogics CTL and LTL. We abstractly represent state and path formulas over transition systems in Boolean left quantales. These are complete lattices with a multiplication that preserves arbitrary joins in its left argument and is isotone in its right argument. Over these quantales, the semantics of CTL \u2217 formulas can be encoded via finite and infinite iteration operators; the CTL and LTL op- erators can be related to domain operators. This yields interesting new connections between representations as known from the modal \u03bc-calculus and Kleene/\u03c9-algebra.", "authors": ["Bernhard M\u00f6ller", "Peter H\u00f6fner", "Georg Struth"], "n_citation": 50, "references": ["0278ccc8-b64a-4d37-b51d-3337288266e0", "0d4cc186-9c63-429b-85e4-83b606481524", "270dd8dc-e574-498b-a752-491d9efcd27c", "32734738-0d21-40c2-ae66-bab3e936eee0", "3444a807-53dd-4c2b-ad27-9c98bbecbd2f", "4397f724-fa30-4db1-8fde-e267ca987890", "565f5085-33af-4157-8375-7799280e7203", "621dbeef-6a77-4256-8119-8ba7bcadcfae", "672e1500-db3f-4b0c-a00e-751cbaadbf2d", "681a3a15-4995-4f42-9600-03036f18a31b", "7369cee6-e07f-479b-a636-6150537a9807", "82ad380c-2ab9-4342-bac8-ebb6babe2591", "9cf4923e-e611-4e08-be09-4ed070e83843", "caa07e86-48de-4c6c-9dd2-25d6ec29e310", "d9c82775-d390-453d-94ab-ffabeb365edc", "e1752f62-251e-4cf9-b4f2-b1c754cdf5c7", "ebbd0de2-3386-4758-8852-fcecfe09b3b3"], "title": "Quantales and temporal logics", "venue": "algebraic methodology and software technology", "year": 2006, "id": "8fb2cb3b-24cf-49a8-8491-e59f1f7a6a9f"}
{"abstract": "Probabilistic models have been widely used for natural language processing. Part-of-speech tagging, which assingns the most likely tag to each word in a given sentence, is one of the problems which can be solved by statistical approach. Many researchers have tried to solve the problem by hidden Markov model (HMM), which is well known as one of the statistical models. But it has many difficulties: integrating heterogeneous information, coping with data sparseness problem, and adapting to new environments. In this paper, we propose a Markov radom field (MRF) model based approach to the tagging problem. The MRF provides the base frame to combine various statistical information with maximum entropy (ME) method. As Gibbs distribution can be used to describe a posteriori probability of tagging, we use it in maximum a posteriori (MAP) estimation of optimizing process. Besides, several tagging models are developed to show the effect of adding information. Experimental results show that the performance of the tagger gets improved as we add more statistical information, and that MRF-based tagging model is better than HMM based tagging in data sparseness problem.", "authors": ["Sung-Young Jung", "Young Park", "Key-Sun Choi", "Youngwhan Kim"], "n_citation": 50, "references": ["0c35895c-9f13-4678-80f3-9310652446e0", "1802f356-431d-4810-84b3-02bcf376ff3b", "20c0235e-ee74-4311-ad2e-ec5f82817910", "39a44489-0d56-4f78-abc6-db74c3a29d4e", "51f1493d-ce3b-4589-8373-55940026fecd", "6e0d7a60-4787-4348-84a5-5b94664a5777", "8e1f4895-8737-4c18-8712-9ba4c349e2d9", "b2609001-4e18-4b54-8f2d-ae1f6cbd0a3d", "cf4069ce-61b9-4202-bf2b-99f8fc53a15b", "ec4966d6-e8f5-4af6-836e-5a6b0e37c382"], "title": "Markov random field based English part-of-speech tagging system", "venue": "international conference on computational linguistics", "year": 1996, "id": "2d54f086-856f-4984-a5c5-104e2326ec9b"}
{"authors": ["David J. Musliner", "Edmund H. Durfee", "Jianhui Wu", "Dmitri A. Dolgov", "Robert P. Goldman", "Mark S. Boddy"], "n_citation": 44, "references": ["21ef532b-de84-4465-bb41-85546f137592", "7cf47aa4-d811-4aef-a7de-4b554206fb17", "83552788-f8c2-4ca7-9fb5-f8f09a816a8c"], "title": "Coordinated Plan Management Using Multiagent MDPs", "venue": "national conference on artificial intelligence", "year": 2006, "id": "6ff38722-9236-4211-a875-2e700a9d6a3c"}
{"abstract": "Service-oriented modeling and architecture (SOMA) has been used to conduct projects of varying scope in multiple industries worldwide for the past five years. We report on the usage and structure of the method used to effectively analyze, design, implement, and deploy service-oriented architecture (SOA) projects as part of a fractal model of software development. We also assert that the construct of a service and service modeling, although introduced by SOA, is a software engineering best practice for which an SOA method aids both SOA usage and adoption. In this paper we present the latest updates to this method and share some of the lessons learned. The SOMA method incorporates the key aspects of overall SOA solution design and delivery and is integrated with existing software development methods through a set of placeholders for key activity areas, forming what we call solution templates. We also present a fractal model of software development that can enable the SOMA method to evolve in an approach that goes beyond the iterative and incremental and instead leverages method components and patterns in a recursive, self-similar manner opportunistically at points of variability in the life cycle.", "authors": ["Ali Arsanjani", "Soumyadip Ghosh", "Abdul Allam", "T. Abdollah", "S. Gariapathy", "Kerrie L. Holley"], "n_citation": 479, "references": ["29cafeb4-d78b-4f08-a8c5-433d9a232f34", "4f3f7073-5756-4e0e-baee-637c332b3906", "a2034ea1-85a9-4c65-8559-41158ffdcfc2", "a440f19d-ce86-449f-9b8f-76fdbcfab6af", "d6285e34-13fa-4327-b4f9-203181baa8c6", "f00c17a9-c5dc-43dc-a995-8169a7e01175", "ff502835-b670-4542-9452-45d7fc9709f6"], "title": "SOMA: a method for developing service-oriented solutions", "venue": "Ibm Systems Journal", "year": 2008, "id": "70f5fa27-727a-4664-a167-6bc60a034420"}
{"authors": ["Carl H. Smith"], "n_citation": 97, "references": ["3affdf45-39d4-4894-b95a-34575b18607c", "3e1b8ccc-96a0-46a8-9f95-415b8b499d3c", "8e34d950-cc2d-484e-b027-e00fa3df269a", "96b2a2ea-2904-439d-ac17-ea1357a08419", "a0535590-7808-4e3d-a8f5-7c3335b0ae4f"], "title": "The Power of Pluralism for Automatic Program Synthesis", "venue": "Journal of the ACM", "year": 1982, "id": "68ef52cc-965b-4fb1-8413-3ae0031a4b67"}
{"abstract": "We consider the decentralized detection problem. In which N indepen- dent, identical sensors transrmt a firute-valued function of their observations to a fusion center which then decides which one of M hypotheses is true. For the case where the number of sensors tends to infinity, we show that it is asymptotically optimal to divide the sensors into M(M - 1)/2 groups, with all sensors in each group using the same decision rule m deciding what to transnut. We also show how the optimal number of sensors in each group may be determined by solving a mathematical programming problem. For the special case of two hypotheses and binary messages the solution simplifies considerably: it is optimal (asymptotically, as N -. co) to have all sensors perform an identical likelihood ratio test, and the optimal threshold is very easy to deterrmne numerically.", "authors": ["John N. Tsitsiklis"], "n_citation": 422, "references": ["51799721-cca7-481a-9f8b-812485017c97", "af3dcf0c-6e6f-4190-a9d6-9a9d2551e378"], "title": "Decentralized detection by a large number of sensors", "venue": "Mathematics of Control, Signals, and Systems", "year": 1988, "id": "188155e2-ae44-4bfb-af85-3b3849a029e9"}
{"abstract": "We are dealing with the problem of space layout planning here. We present an architectural conceptual CAD approach. Starting with design specifications in terms of constraints over spaces, a specific enumeration heuristics leads to a complete set of consistent conceptual design solutions named topological solutions. These topological solutions which do not presume any precise definitive dimension correspond to the sketching step that an architect carries out from the Design specifications on a preliminary design phase in architecture.", "authors": ["Benachir Medjdoub", "Bernard Yannou"], "n_citation": 82, "references": ["2b2ada03-8693-4405-8657-a5f936bf9dca", "36ed50a5-a73e-41be-9060-de6c0ca9dce0", "3d753fc7-52ef-4c90-9bb7-10c9f119ad45", "4d8e50f4-63f0-4a80-b7d1-b7fae2d151dd", "e5f9758c-e864-40ca-a7b8-215c8e8470ca"], "title": "Separating Topology and Geometry in Space Planning", "venue": "Computer-aided Design", "year": 2000, "id": "1ebc59f1-5d3a-4166-8eda-8907a8b54e5c"}
{"abstract": "We have been developing Name-It, a system that associates faces and names in news videos. First, as the only knowledge source, the system is given news videos which include image sequences and transcripts obtained from audio tracks or closed caption texts. The system can then either infer the name of a given face and output the name candidates, or can locate the faces in news videos by a name. To accomplish this task, the system extracts faces from image sequences and names from transcripts, both of which might correspond to key persons in news topics. The proposed system takes full advantage of advanced image and natural language processing. The image processing contributes to the extraction of face sequences which provide rich information for face-name association. The processing also helps to select the best frontal view of a face in a face sequence to enhance the face identification which is required for the processing. On the other hand, the natural language processing effectively extracts names by using lexical/grammatical analysis and knowledge of the news video topics structure. The success of our experiments demonstrates the benefits of the advanced image and natural language processing methods and their incorporation.", "authors": ["Shin'ichi Satoh", "Yuichi Nakamura", "Takeo Kanade"], "n_citation": 42, "references": ["0b4c0d6f-58fd-4704-98af-8c12de196ede", "5e201ff6-e335-498c-8b37-46b117673364", "648675c6-6ea7-4fa5-a91d-9d3156d09692"], "title": "Name-it: naming and detecting faces in video by the integration of image and natural language processing", "venue": "international joint conference on artificial intelligence", "year": 1997, "id": "c168cb01-502c-4d18-a864-6213004bde92"}
{"abstract": "We suggest the Wigner distribution (WD) for the analysis of 2-D images. The WD can be used to rigorously define a local power-spectrum at each point of an image. Furthermore, an invariant representation of a given image can be obtained by applying a complex-logarithmic (CL) conformal mapping to the spatial-frequency domain of the WD. The representation is such that all local spectra are invariant, within a linear shift, with respect to linear transformations of the image. A discrete WD has been implemented and results are shown. We next describe how the same CL-mapped WD of a scalar or vector field could be used for binocular disparity and motion analysis, respectively, where the goal is object recognition.", "authors": ["Lowell Jacobson", "Harry Wechsler"], "n_citation": 50, "references": ["ec37f001-2879-42a2-91f6-5d0d24a044ef"], "title": "A paradigm for invariant object recognition of brightness, optical flow and binocular disparity images", "venue": "Pattern Recognition Letters", "year": 1982, "id": "da542663-6086-47d1-b7a0-21868f88741f"}
{"abstract": "Dynamic change is a large and pervasive unsolved problem which surfaces within office systems as well as within software engineering, manufacturing, and numerous other domains. Procedural changes, performed in an ad hoc manner, can cause inefficiencies, inconsistencies, and catastrophic breakdowns within offices. This paper is concerned with dynamic change to procedures in the context of workflow systems. How can we make workflow systems more flexible and open? We believe that part of the answer lies in the study and solution of the dynamic change problem. In this paper, we use a Petri net formalism to analyze structural change within office procedures. As an example, we define a class of change called \u201csynthetic cut-over change\u201d, and apply our formalism to prove that this class maintains correctness when downsizing occurs.", "authors": ["Clarence A. Ellis", "Karim Keddara", "Grzegorz Rozenberg"], "n_citation": 713, "references": ["3b48db0b-0931-48b1-bebe-5ff6ffef1e3d", "3d091219-6a6d-4954-b9eb-a12df0d9ebfa", "3eb2ecbd-aff2-48ba-9131-6aa8ad4a8cb4", "975d1072-871c-4cef-88de-a8843744bec9", "c006523a-5a44-4790-ab1c-5f7a95b4ef21", "e927699f-c24e-49fa-9cff-db1e77776285"], "title": "Dynamic change within workflow systems", "venue": "", "year": 1995, "id": "c06070b1-79ec-4f64-8d76-3804f6be9ec4"}
{"abstract": "A universal point-set supports a crossing-free drawing of any planar graph. For a planar graph with n vertices, if bends on edges of the drawing are permitted, universal point-sets of size n are known, but only if the bend points are in arbitrary positions. If the locations of the bend points must also be specified as part of the point-set, we prove that any planar graph with n vertices can be drawn on a universal set S of O(n^2/logn) points with at most one bend per edge and with the vertices and the bend points in S. If two bends per edge are allowed, we show that O(nlogn) points are sufficient, and if three bends per edge are allowed, O(n) points are sufficient. When no bends on edges are permitted, no universal point-set of size o(n^2) is known for the class of planar graphs. We show that a set of n points in balanced biconvex position supports the class of maximum-degree-3 series-parallel lattices.", "authors": ["Vida Dujmovi\u0107", "William S. Evans", "Sylvain Lazard", "William Lenhart", "Giuseppe Liotta", "David Rappaport", "Stephen K. Wismath"], "n_citation": 50, "references": ["0d1e5fde-5a76-4547-8e97-785911e91633", "206ea520-3a18-4cfc-a8c7-e11084250f38", "22edaeae-5899-46cd-86b2-736378ba69b8", "4d96426b-081f-41a7-9aea-349470b2d69a", "5132f2dc-b210-4e1f-873d-d0a80bcf5e8c", "a645ede3-7024-417b-ad0c-76f59fb2d401", "b87ab062-4231-4fc6-8b5b-a3a421dea308", "db9178dc-a142-47f5-89a2-52cb5284f689", "e8c2d078-1b1e-4964-943e-020fccfbcdc7"], "title": "On point-sets that support planar graphs", "venue": "Computational Geometry: Theory and Applications", "year": 2013, "id": "f39437c2-aa2f-40fe-8033-c87e68728a63"}
{"abstract": "In this paper we argue thatordinal rather thancardinal optimization, i.e., concentrating on finding good, better, or best designs rather than on estimating accurately the performance value of these designs, offers a new, efficient, and complementary approach to the performance optimization of systems. Some experimental and analytical evidence is offered to substantiate this claim. The main purpose of the paper is to call attention to a novel and promising approach to system optimization.", "authors": ["Yu-Chi Ho", "Ramavarapu S. Sreenivas", "Pirooz Vakili"], "n_citation": 509, "references": ["020a7e27-ed0d-4919-a11c-5054c8799d85", "1c26e228-57d2-4b2c-b0c9-8d5851c17fac", "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "9bcdcbd4-e8bd-4b04-a79c-830b43472a4a"], "title": "Ordinal Optimization of DEDS", "venue": "Discrete Event Dynamic Systems", "year": 1992, "id": "d4bd508d-160b-4018-91c9-b17c8fbc9f7d"}
{"abstract": "For robot arm tracking, the authors propose a nonlinear and adaptive approach based on decentralized system structure. Using the passive feature of robots and cubic feedback to treat the nonlinear couplings and quadratic interconnections, the decentralized adaptation is achieved by applying the linear-in-parameters property of the motion equation. The nonlinear feedback improves the performance of PD control from local to global stability and the adaptation reduces its tracking errors. The practical significance of the approaches lies in the fact that they can be implemented in most robots without hardware alteration.", "authors": ["Ming Liu"], "n_citation": 125, "references": ["1fd97f8f-f14b-4165-89e5-25b0a333cbd9", "3bd67830-0ce7-4d48-80fc-7491284d4f22", "532b27fb-f9c5-4723-86e7-d27c17753431", "5a99c9b9-ea53-4b58-85d8-44c657ab4046", "5fc00814-9934-471b-954b-4314f4df0d07", "6f47b50b-c366-4c9c-84cc-f9bc5fec53a4", "7470b7b1-c0fd-4969-80f1-2e2ca23d8c49", "a14230db-a597-4db0-8436-545915d237d1", "aca4eca9-0505-4649-9b6a-7f9dd463faf8", "b70de2db-21e9-4023-8510-182d46a50c39"], "title": "Decentralized control of robot manipulators: nonlinear and adaptive approaches", "venue": "IEEE Transactions on Automatic Control", "year": 1999, "id": "78ad46a6-453f-4b46-b488-8091a4dab10d"}
{"abstract": "Rate monotonic scheduling theory puts real-time software engineering on a sound analytical footing. The authors review the theory and its implications for Ada. >", "authors": ["Lui Sha", "John B. Goodenough"], "n_citation": 492, "references": ["31065bf3-51bb-42fe-8604-e1119cac7953", "5bde6d12-9cd8-4494-8710-b8677261bf8a", "5c60e6d7-176f-4b5f-8297-d26572e48d39", "d7eb74d3-04a3-476b-8e3d-563f6729ca3b", "ec70c332-ec64-4d07-bc89-488594f8166b"], "title": "Real-time scheduling theory and Ada", "venue": "IEEE Computer", "year": 1990, "id": "f5782089-595d-47e4-aa3b-731ab3884bd4"}
{"abstract": "The study of the correlations that may exist between neurophysiological signals is at the heart of modern techniques for data analysis in neuroscience. Wavelet coherence is a popular method to construct a time-frequency map that can be used to analyze the time-frequency correlations between two time series. Coherence is a normalized measure of dependence, for which it is possible to construct confidence intervals, and that is commonly considered as being more interpretable than the wavelet cross-spectrum (WCS). In this paper, we provide empirical and theoretical arguments to show that a significant level of wavelet coherence does not necessarily correspond to a significant level of dependence between random signals, especially when the number of trials is small. In such cases, we demonstrate that the WCS is a much better measure of statistical dependence, and a new statistical test to detect significant values of the cross-spectrum is proposed. This test clearly outperforms the limitations of coherence analysis while still allowing a consistent estimation of the time-frequency correlations between two non-stationary stochastic processes. Simulated data are used to investigate the advantages of this new approach over coherence analysis. The method is also applied to experimental data sets to analyze the time-frequency correlations that may exist between electroencephalogram (EEG) and surface electromyogram (EMG).", "authors": ["J\u00e9r\u00e9mie Bigot", "Marieke Longcamp", "Fabien Dal Maso", "David Amarantini"], "n_citation": 20, "references": ["b4c6a6da-4a76-4511-a253-48a60f685ba2", "e6126e39-3859-46b9-853f-bafa23b42c19"], "title": "A new statistical test based on the wavelet cross-spectrum to detect time\u2013frequency dependence between non-stationary signals: Application to the analysis of cortico-muscular interactions", "venue": "NeuroImage", "year": 2011, "id": "3680197f-6975-4dcd-9f04-6295aaed98c0"}
{"authors": ["Peter Scheuermann", "Eugene Inseok Chong"], "n_citation": 50, "references": ["032fee65-7374-41d1-922e-6b9215eccaab", "0a335067-172d-4a69-af48-a502b86a6708", "13ad3d56-9041-4196-be19-7d122a9d916a", "51b52a79-0d0a-4d4f-bab9-7ad1b6a5b3cc", "5f90f4a2-8eb4-406c-b985-ee6c394dd612", "626243a7-eb16-4150-918d-bacfdb5c95d9", "73b43513-62ae-467c-a94f-12e8e256f6c0", "822c95f0-5df9-4219-ad70-b44ca6b4c23d", "af42e879-a6a7-43b3-b33e-12695f003bc3", "babc2975-f8cf-461d-95e3-63888130763b", "c3eaa2d5-6ffc-48ce-be6a-a85828335754", "c54dbf86-bfc1-4075-8158-88c9a3852c51", "d9945bfa-f6a3-47ab-8ec1-c862cf784baa", "e7b435d2-63c0-4e6b-a3eb-582ade08d493", "e81691de-9a1d-4259-8fbc-5a1e9bfeefd5", "f3681358-e4a3-4981-9c23-2f54fe47d4f5"], "title": "Role-based query processing in multidatabase systems", "venue": "extending database technology", "year": 1994, "id": "e51f79d2-8c87-4a9f-95d7-da9d03b1cb03"}
{"abstract": "Existing research suggests that a considerable fraction (5-10%) of the source code of large scale computer programs is duplicate code (\"clones\"). Detection and removal of such clones promises decreased software maintenance costs of possibly the same magnitude. Previous work was limited to detection of either near misses differing only in single lexems, or near misses only between complete functions. The paper presents simple and practical methods for detecting exact and near miss clones over arbitrary program fragments in program source code by using abstract syntax trees. Previous work also did not suggest practical means for removing detected clones. Since our methods operate in terms of the program structure, clones could be removed by mechanical methods producing in-lined procedures or standard preprocessor macros. A tool using these techniques is applied to a C production software system of some 400 K source lines, and the results confirm detected levels of duplication found by previous work. The tool produces macro bodies needed for clone removal, and macro invocations to replace the clones. The tool uses a variation of the well known compiler method for detecting common sub expressions. This method determines exact tree matches; a number of adjustments are needed to detect equivalent statement sequences, commutative operands, and nearly exact matches. We additionally suggest that clone detection could also be useful in producing more structured code, and in reverse engineering to discover domain concepts and their implementations.", "authors": ["Ira D. Baxter", "Andrew Yahin", "Leonardo Mendon\u00e7a de Moura", "Marcelo M. SantAnna", "Lorraine Bier"], "n_citation": 1275, "references": ["028d73d0-7ce5-4fc1-9557-35bb4c339a34", "2fe7c094-9c39-471d-9d2a-f1fc6b37e8ff", "428ee669-7e07-4e1a-80cc-999b0d4df5d7", "43da2f81-9df8-4a21-84c9-63e0bec4cb00", "b1de4d76-1f2e-46bd-99c8-3b2715812a4c", "bcf9b455-8c7d-4b05-bdf5-61de12d9f951", "c7c340fc-f52f-4712-9a2f-58708e29cb32"], "title": "Clone detection using abstract syntax trees", "venue": "international conference on software maintenance", "year": 1998, "id": "ceb6c751-dbd3-4952-b242-e084430367f2"}
{"abstract": "In this article we present a case-based approach for the selflocalization of autonomous robots based on local visual information of landmarks. The goal is to determine the position and the orientation of the robot sufficiently enough, despite some strongly incorrect visual information. Our approach to solve this problem makes use of case-based reasoning methods.", "authors": ["Jan Wendler", "Steffen Br\u00fcggert", "Hans-Dieter Burkhard", "Helmut Myritz"], "n_citation": 50, "references": ["17789398-d1e5-491e-bf0d-6f658005c5ba", "41f748a1-3abf-4660-a0cd-955882903329", "440b78ee-ee54-408a-9f04-afa17a8a08c7", "6f13bb22-df64-4b08-9e5a-d7581edeb31b", "a115b797-205c-43d6-a1cf-f1fc76c37641", "b88ae4df-c612-4ece-8911-fe45558a5324", "f26f8d61-3eed-41e6-b7e9-4df9c193cdc0"], "title": "Fault-Tolerant Self Localization by Case-Based Reasoning", "venue": "robot soccer world cup", "year": 2001, "id": "0db38558-33f0-45f9-8439-a4dc56c74e8d"}
{"abstract": "We compare the effectiveness of four modeling methods--negative binomial regression, recursive partitioning, random forests and Bayesian additive regression trees--for predicting the files likely to contain the most faults for 28 to 35 releases of three large industrial software systems. Predictor variables included lines of code, file age, faults in the previous release, changes in the previous two releases, and programming language. To compare the effectiveness of the different models, we use two metrics--the percent of faults contained in the top 20% of files identified by the model, and a new, more general metric, the fault-percentile-average. The negative binomial regression and random forests models performed significantly better than recursive partitioning and Bayesian additive regression trees, as assessed by either of the metrics. For each of the three systems, the negative binomial and random forests models identified 20% of the files in each release that contained an average of 76% to 94% of the faults.", "authors": ["Elaine J. Weyuker", "Thomas J. Ostrand", "Robert M. Bell"], "n_citation": 63, "references": ["21ffae8e-2406-4e5e-b1e1-e6a0f9a82bf1", "2cf7508b-8bc5-40d0-a4bd-d0db045ace83", "2db8a232-7be1-49cd-9ecb-a92fc778a00f", "32496c5a-28fd-4b33-88c3-3501c2a88fe4", "3a057a1b-e80f-4a43-bf0b-a6599bf341a6", "4e48c748-890e-411e-a167-0cf88c210439", "4e617e38-cf4a-4f8e-9339-0ce1d5d7d5fb", "57f36891-c31b-4cc9-a6f4-eec418712db1", "5be480f2-f2d3-4a62-b819-ad13259aa4fe", "6a12c190-f087-4e10-980e-c064ee63a1eb", "6c3b836b-1fc7-4e16-85d7-16ee9aa34845", "8091f152-eb70-43a6-94c9-06afeaf9f697", "834053cd-218c-401f-a459-46bbc7d22ab0", "8991e403-e7e0-422a-9998-ae33055b1a04", "9350d76b-9925-4734-bc76-0203e92abd03", "97badbeb-818b-4d7b-863f-3d0c6c4870c7", "9ad8070f-393c-42c5-b7a9-c3870e4a68b0", "a47809bd-0a74-4968-ab15-067e436d8656", "b98fe001-68be-47fe-b26f-475dda526879", "d5a44f14-60d8-4dd8-98a2-f805830df6cd", "e143c8b2-d125-4999-bfb5-07d324b134f3", "f6bd8b64-684d-429a-aab5-8ff3a2c23cd6"], "title": "Comparing the effectiveness of several modeling methods for fault prediction", "venue": "Empirical Software Engineering", "year": 2010, "id": "70706929-ff6d-499f-a06b-d68e8c55bbc2"}
{"abstract": "When defining a new system, the history and functionality of the system to be replaced should be considered. This avoids repeating errors and neglecting important system functionality. The properties and the rationale behind the existing system are typically elicited by analysing concrete system usage-scenarios. The results of the analysis of the existing system are typically represented using conceptual models. To establish conceptual models of high quality, reviewing the models is common practice. The problem faced with when reviewing conceptual models, is that the reviewer cannot assess and therefore understand the basis (concrete system usage) on which the conceptual models where build. In this paper, we present an approach to overcome this problem. We argue to establish extended traceability, by recording concrete system usage scenarios using rich media (e.g. video, speech, graphic) and interrelating the recorded observations with the conceptual models. We discuss the main improvements for review processes resulting from the extended traceability and illustrate the advantages with excerpts from a case study performed in a mechanical engineering company.", "authors": ["Peter Haumer", "Klaus Pohl", "Klaus Weidenhaupt", "Matthias Jarke"], "n_citation": 22, "references": ["20732663-8b39-4f72-a043-d991d9bc2c17", "29f08f1d-565b-47dc-90d7-b1bef4e72a4f", "3cdcd294-7e7e-45c3-97b6-c28a10c567e3", "453629d0-e7b1-4a59-821c-358949c46c4e", "4d2b5143-d84b-4a7d-a1ce-b433c7a7ad10", "69220232-821f-4e21-8d99-3decfb2f9da6", "7c12c213-41af-4508-b7b3-a9e9156b41d4", "8d7227aa-7621-4e06-ab39-3a69b34583e5", "973de0db-4784-4fef-a6bf-45fae7a449ac", "b0f437cb-6c5b-4e2e-927a-25d127d0faf7", "c79c9916-43b4-4fbb-867b-5af47fa33786", "d5020036-d0b6-4542-960f-d55bc33a30ad", "d98cb2a7-0f1e-40ab-b271-8dcff8d2cbc2", "e64c997b-646d-4bbc-b2e5-b1b070406be3"], "title": "Improving reviews by extended traceability", "venue": "international conference on systems", "year": 1999, "id": "06fbd4ef-fa84-4b8b-9780-e4448f9ddb59"}
{"abstract": "This is a tutorial introduction to assertional reasoning based on temporal logic. The objective is to provide a working familiarity with the technique. We use a simple system model and a simple proof system, and we keep to a minimum the treatment of issues such as soundness, completeness, compositionality, and abstraction. We model a concurrent system by a state transition system and fairness requirements. We reason about such systems using Hoare logic and a subset of linear-time temporal logic, specifically, invariant assertions and leads-to assertions. We apply the method to several examples.", "authors": ["A. Udaya Shankar"], "n_citation": 119, "references": ["026b656f-4393-4aaf-9b17-359bcdc3422d", "1cf004ef-4374-4127-b39d-2074453941db", "20eb6ae9-d790-454f-93aa-abce1793f759", "2dd0239d-50d7-4349-af9b-49f6148ad951", "30df38a5-877e-423c-9340-9d890a1d2913", "357ef03b-3ad5-4793-a593-888b84bc6848", "35c8c06c-2ad0-46b4-9e92-2d684f3abd94", "4757ce83-5af8-4deb-8ba3-ceb36df4c797", "604822ac-cb3d-4f6b-bec0-735addd21851", "6527f747-563e-4e5f-b9a1-44ea23adbf26", "6b70e529-31ff-49f6-b108-405a97dcc07c", "74e3fd8b-f955-4fde-aad8-0a705f05e27e", "79de76a0-072e-41a4-8353-411e4fb1c6a7", "84212551-3fc6-416b-a5a3-dc0c9f382ca1", "8ae173a1-5670-4845-89c0-afa44ed718fe", "8d0a32ac-4e86-41eb-93db-f46b2bffc91c", "9263d164-aa3d-4ef0-b277-6560f605f417", "b0d2276a-ad6a-469d-a494-3329e2e631ef", "b581d1fb-024c-43eb-80d8-ee7f4a0aaf52", "b8cba481-512c-40b2-aa5d-4ab102a0a9b5", "c2f1cfe2-0ba8-4b2e-a31a-f6cd9f688ad8", "cfbfdf3c-6d4a-4b82-99b3-36f072bca0d9", "eb35749e-7487-47cd-a961-68819b084d89", "ed28d1f9-71c3-4f71-8518-27fae869f6a7", "ed8dc42b-c472-4fcc-9d0a-55f3043446dc", "f068e814-f9ac-42f0-b759-d121db5a50c3", "fa115597-6101-4fee-aa8c-f2501397c738"], "title": "An introduction to assertional reasoning for concurrent systems", "venue": "ACM Computing Surveys", "year": 1993, "id": "bbbcdb15-20e9-4abd-a962-75761f847daf"}
{"abstract": "This paper deals with the problem of feedback control for networked systems with discrete and distributed delays subject to quantization and packet dropout. Both a state feedback controller and an observer-based output feedback controller are designed. The infinite distributed delay is introduced in the discrete networked domain for the first time. Also, it is assumed that system state or output signal is quantized before being communicated. Moreover, a compensation scheme is proposed to deal with the effect of random packet dropout through communication network. Sufficient conditions for the existence of an admissible controller are established to ensure the asymptotical stability of the resulting closed-loop system. Finally, a numerical example is given to illustrate the proposed design method in this paper.", "authors": ["Rongni Yang", "Peng Shi", "Guo-Ping Liu", "Huijun Gao"], "n_citation": 293, "references": ["192f3f87-5c20-4ee1-8f00-e177730a38e7", "4d80ce16-4f36-4300-bedb-5ad5535327a6", "e1d16ff1-e435-4bcb-953b-09636762096c"], "title": "Technical communique: Network-based feedback control for systems with mixed delays based on quantization and dropout compensation", "venue": "Automatica", "year": 2011, "id": "86a1d5c9-93ac-4c1c-b79b-137067a0b52f"}
{"abstract": "Several quality of service models have been proposed for the next generation of Internet, with differentiated service being foreseen to support it in core networks. A new routing architecture must be adopted to cope efficiently with these service differentiation mechanisms. The paper proposes an extension to traditional intra-domain routing protocols which takes into account service differentiation. In the new approach, routing paths must be selected according to network traffic conditions and service level agreements. A new path selection mechanism is proposed, which guides higher priority traffic through the shortest path and diverts lower priority traffic through longer paths when service performance degradation is foreseen.", "authors": ["Antonio Isasi Varela", "Teresa Maria Vaz\u00e3o", "Guilherme Arroz"], "n_citation": 50, "references": ["bcfe8589-cc01-43b3-b33c-10db211c9a43", "ea81ff94-434c-4d2e-988c-274e4f9e1106", "ec765842-597b-4fde-9667-ff7962314e8a"], "title": "Multi-service routing - a new QoS routing approach supporting service differentiation", "venue": "advanced industrial conference on telecommunications", "year": 2005, "id": "7d861e28-a75a-43b4-97a0-47afef5316ab"}
{"abstract": "Formalism based on stochastic Petri nets (SPNs) can employ structural analysis to ensure that the underlying stochastic process is fully determined. The focus is on the detection of conflicts and confusions at the net level, but this might require to overspecify a given SPN model. The problem becomes even more critical when reward processes of interest derived from the basic underlying process are considered. Typical examples are state-dependent impulse reward measures. We propose a definition of well-defined SPNs, which takes into account whether the basic underlying stochastic process or the derived reward processes are determined. A state-space-based algorithm to determine whether a given SPN is well-defined is provided.", "authors": ["Gianfranco Ciardo", "Robert Zijal"], "n_citation": 49, "references": ["09bc1c5f-57b5-4d79-9e88-d26c8c9b2e74", "109c983e-31a6-45d2-afbb-a6a4a6cc39c5", "2cb7bf63-3586-4670-9490-4241d0fb9ad3", "76ed3d06-1416-4ba4-88a3-5309842da9b3", "83706c4e-49f8-47f9-b910-a0089e8c8a22", "d33d5c41-6dc3-4835-b86b-7b219b9d712b", "d5c75ea0-6238-4399-8140-f39f6a3aa4b7", "e1161405-6718-4983-8717-1354ecac5401"], "title": "Well-defined stochastic Petri nets", "venue": "modeling analysis and simulation on computer and telecommunication systems", "year": 1996, "id": "7fd6b9ad-16f9-4942-8b7e-6257ba6de234"}
{"abstract": "We present a scalable, low cost multiprocessor system, which is used in the area of measurement, regulation, controlling and soft computing. The system is an example of extremely modular hardware/software design. Modular in this context means that we can easily change or optimize individually the components in the system for a given problem. One of the most important aspects of our multiprocessor system is the fact that the user can dynamically change the communication topology by software 'on-the-fly'. Thus, the hardware can be (re)configured during operation in less than 1 ms. By this, the CPUs in the multiprocessor system can communicate directly without any invention of another processor preventing the typical bottleneck in parallel systems. First applications have been implemented in an embedded controller for a vote counting machine, with emphasis on high data security and high throughput.", "authors": ["Rolf Drechsler", "Nicole Drechsler", "Elke Mackensen", "Tobias Schubert", "Bernd Becker"], "n_citation": 50, "references": ["aea1de08-4b7a-4a1f-bba8-6f4edd44c1c0", "e3a3bea4-261e-4268-a74d-f4176b8ebd9a"], "title": "Design reuse by modularity: a scalable dynamical (re)configurable multiprocessor system", "venue": "", "year": 2000, "id": "c9c96c40-c27f-401a-bd03-132088eeda87"}
{"abstract": "Communication networks shared by selfish users are considered and modeled as noncooperative repeated games. Each user is interested only in optimizing its own performance by controlling the routing of its load. We investigate the existence of a Nash equilibrium point (NEP) that achieves the system-wide optimum cost. The existence of a subgame-perfect NEP that not only achieves the system-wide optimum cost but also yields a cost for each user no greater than its stage game NEP cost is shown for two-node multiple link networks. It is shown that more general networks where all users have the same source-destination pair have a subgame-perfect NEP that achieves the minimum total system cost, under a mild technical condition. It is shown that general networks with users having multiple source-destination pairs do not necessarily have such an NEP.", "authors": ["Richard J. La", "Venkat Anantharam"], "n_citation": 113, "references": ["1ce49869-0b8c-4e0c-b463-2c37d657492f", "207fe754-ce33-4175-a6fc-19088e34d114", "2df39be6-c853-49a0-a5e5-03889167a183", "3543a72d-adf3-4f9c-8c65-a11f36e99da6", "3c68cc29-caca-419b-9396-36c4b6d703e7", "4c63daa2-c365-4df1-bb33-40ecc29eb8e7", "89e66007-8ca1-4992-9390-79e088248881", "ba36ff86-4ae4-4ed9-9165-346749821a5e", "bc208779-e44c-4ed9-a034-ab0035ccfe9d", "cc53988e-fa91-42ae-9e58-c58179fa41bc", "e5adad34-86d4-40af-9ebe-2013b5f88a92"], "title": "Optimal routing control: repeated game approach", "venue": "IEEE Transactions on Automatic Control", "year": 2002, "id": "813d0e9b-669c-4936-959e-45adfbd28782"}
{"abstract": "Proposes a systematic process for the design of user interfaces for hypertext systems, within the context of a general-purpose semantic framework for hypertext functionality. Although a number of guidelines exist to enhance the usability of interactive systems, there has been no systematic and comprehensive approach to the design of self-evident interfaces for hypertext systems. We believe that there is a strong need for such an approach to user interface design for hypertext systems that should also include the semantic types of the underlying objects. This will not only reduce functional opacity but also system opacity. We present examples from a screen prototype to illustrate our design methodology. >", "authors": ["Venkatraman Balasubramanian", "Murray Turoff"], "n_citation": 50, "references": ["023ba949-2464-4242-8829-d9fddca3eb38", "0f30c4dd-122e-489e-805a-d9235403db85", "0fc69700-02ac-49e0-8484-33deae619fe6", "1360293c-1482-4b16-9156-d1b16b4e9eef", "3d4990c4-107d-47f1-bb94-18af892cda06", "6d5ca5eb-8354-467b-a25b-b4870e8b4e2e", "7cd7146e-5d3e-4b96-b234-8b956e40033d", "a0d0b053-2f9e-46ad-b518-292a07a1b379", "a2b6c7f6-4b3c-47e1-a0a0-4cab7ad9252d", "a641e9cb-9a1a-4e63-97f4-6c8317cc37cb", "abba9b93-abf0-41a6-9d1e-33852ba0b7d8", "d6de153c-61a5-4c50-8730-0311ac9a21b6", "e94be101-304f-4b98-90ed-7438a7ee9192", "f5eef670-eaea-4fdb-b49f-79ce722b1e95"], "title": "A systematic approach to user interface design for hypertext systems", "venue": "hawaii international conference on system sciences", "year": 1995, "id": "35913135-7945-4ae4-9824-25b782c55e3c"}
{"abstract": "Orthogonal frequency division multiple access (OFDMA) has recently attracted vast research attention from both academia and industry and has become part of new emerging standards for broadband wireless access. Even though the OFDMA concept is simple in its basic principle, the design of a practical OFDMA system is far from being a trivial task. Synchronization represents one of the most challenging issues and plays a major role in the physical layer design. The goal of this paper is to provide a comprehensive survey of the latest results in the field of synchronization for OFDMA systems, with tutorial objectives foremost. After quantifying the effects of synchronization errors on the system performance, we review some common methods to achieve timing and frequency alignment in a downlink transmission. We then consider the uplink case, where synchronization is made particularly difficult by the fact that each user's signal is characterized by different timing and frequency errors, and the base station has thus to estimate a relatively large number of unknown parameters. A second difficulty is related to how the estimated parameters must be employed to correct the uplink timing and frequency errors. The paper concludes with a comparison of the reviewed synchronization schemes in an OFDMA scenario inspired by the IEEE 802.16 standard for wireless metropolitan area networks.", "authors": ["M. Morelli", "C.-C.J. Kuo", "Man-On Pun"], "n_citation": 696, "references": ["0258d01b-7da0-4c55-82a6-1c6f20573dff", "0f7f903c-1cd7-42a3-b0a6-39165bc0be7f", "1671d977-7312-41e5-98ba-c07c1f6a7aa1", "1b03c1e5-b760-4e37-81bc-230017843794", "1dc8d7b8-cd52-4e4e-98fd-6f07aae169da", "1e1557e2-9648-457f-9eb9-d1a875d3b97a", "1e78946c-77e5-417a-a56e-0959b82484ac", "1f77d33c-7f56-4e57-9c3b-3efae573d42e", "20fbecb4-319f-4c70-b4f2-7f9adac2d9d4", "25a45594-f1a9-4eec-b74e-789db7a3156b", "26916931-25c5-4ede-a21c-d50dee62153f", "2dfd9714-6835-449c-a287-b36e4ec0a486", "2e85075c-985c-4237-9429-b125d2320007", "32adeb60-745a-4660-bbc3-a475cf5e1703", "446d228d-e918-41f0-923f-3356bd370158", "4df11280-0cd8-4d9a-a331-4090e0fd5a77", "50fbef46-1b72-4e0c-b330-cf7b5c2043be", "518fde6b-2274-4d89-b248-fb549d3b7208", "535f798e-edcb-4ff1-9251-2fa513520116", "5fe100d5-0a35-4cbd-9370-c765969f432a", "6600dd62-3848-45b2-afdf-ed5c36b95f31", "666d0a9e-c22f-4102-ab4b-9a9aed970951", "67363078-a977-4960-b409-67240ec81161", "7a00e784-9323-4a2f-aae4-accd2598bfff", "7feb5176-1bf3-4067-8912-fe1a2c032f75", "8d7de393-5fcc-43bd-9172-f0d02ba3cbda", "a0e1304a-de71-4dba-af44-be5483aa8c46", "aa6c34aa-4a2c-47b5-bd7e-39581ee26d84", "bfcbbcd7-dfd0-427a-b13a-4b43f5755c8f", "c43b8475-b30f-4b7e-bdf3-f557282183ea", "c4bcf622-9656-4004-9a6f-08bb60f3f360", "c5009bae-06fc-4c0b-bd55-c1825f0d730f", "c7e24980-4cd8-4a97-b67f-d89031ccd745", "d3c063da-1971-42d9-a8c8-c848b4f1aef9", "d5768255-026d-41fb-a24b-573acf435576", "dc5c4375-c98d-484b-b67a-27df4a42a3c1", "e4cd3ab9-3ff1-47be-9ab7-911205551aeb", "ef91d13f-74a1-4e13-a61a-d635b07e70ad", "f06ba848-2a65-4f03-9ed9-fc4e49042070", "f9813298-42f2-40ea-a5b6-1c60d015b763"], "title": "Synchronization Techniques for Orthogonal Frequency Division Multiple Access (OFDMA): A Tutorial Review", "venue": "Proceedings of the IEEE", "year": 2007, "id": "103fede6-6e5a-4713-99ab-58723e8ef08d"}
{"abstract": "Total energy shaping is a controller design methodology that achieves (asymptotic) stabilization of mechanical systems endowing the closed-loop system with a Lagrangian or Hamiltonian structure with a desired energy function - that qualifies as Lyapunov function for the desired equilibrium. The success of the method relies on the possibility of solving two PDEs which identify the kinetic and potential energy functions that can be assigned to the closed loop. Particularly troublesome is the partial differential equation (PDE) associated to the kinetic energy which is nonlinear and inhomogeneous and the solution, that defines the desired inertia matrix, must be positive-definite. In this note, we prove that we can eliminate or simplify the forcing term in this PDE by modifying the target dynamics and introducing a change of coordinates in the original system. Furthermore, it is shown that, in the particular case of transformation to the Lagrangian coordinates, the possibility of simplifying the PDEs is determined by the interaction between the Coriolis and centrifugal forces and the actuation structure. The examples of pendulum on a cart and Furuta's pendulum are used to illustrate the results.", "authors": ["Giuseppe Viola", "Romeo Ortega", "Ravi N. Banavar", "Jos\u00e9 \u00c1ngel Acosta", "Alessandro Astolfi"], "n_citation": 85, "references": ["16469145-4e6b-45ac-a836-1378d7b68282", "65605a2b-9222-4862-b46c-6a6aeae75d10", "9f4347db-b1a1-4117-bf19-bc10612714c5", "d0370341-0df7-4eb4-83b3-453d72cfe49d", "e522046a-0255-4df5-ac21-ee379effbf6a"], "title": "Total Energy Shaping Control of Mechanical Systems: Simplifying the Matching Equations Via Coordinate Changes", "venue": "IEEE Transactions on Automatic Control", "year": 2007, "id": "85fd30cf-d9a5-477e-a67f-5d8f28637793"}
{"abstract": "In the past decade, genome rearrangements have attracted increasing attention from both biologists and computer scientists as a new type of data for phylogenetic analysis. Methods for reconstructing phylogeny from genome rearrangements include distance-based methods, MCMC methods, and direct optimization methods. The latter, pioneered by Sankoff and extended with the software suites GRAPPA and MGR, is the most accurate approach, but is very limited due to the difficulty of its scoring procedure\u2014it must solve multiple instances of the reversal median problem to compute the score of a given tree. The reversal median problem is known to be NP-hard and all existing solvers are extremely slow when the genomes are distant. In this paper, we present a new reversal median heuristic for unichromosomal genomes. The new method works by applying sets of reversals in a batch where all such reversals both commute and do not break the cycle of any other. Our testing using simulated datasets shows that this method is much faster than the leading solver for difficult datasets with only a slight accuracy penalty, yet retains better accuracy than other heuristics with comparable speed, and provides the additional option of searching for multiple medians. This method dramatically increases the speed of current direct optimization methods and enables us to extend the range of their applicability to organellar and small nuclear genomes with more than 50 reversals along each edge.", "authors": ["William Arndt", "Jijun Tang"], "n_citation": 9, "references": ["02752285-b3ae-44b6-8a76-ee25202e3bb3", "10f0f060-e685-4402-aa38-fb5098160dbf", "38aabf13-55ab-46b6-b718-a17a97d55886", "467000aa-2df3-445d-95d1-867455be1491", "61af5830-082a-4be0-9add-fc11c9f55718", "8c2a27ac-4cf5-459a-b4e2-2a9345068974", "a744278e-f920-4714-b83a-9806d8f7ba56", "a7e74dd0-74d3-41c9-a9e1-1806dd2c79dd", "bcec76dc-5941-4a10-970d-3700b4fb9590"], "title": "Improving reversal median computation using commuting reversals and cycle information.", "venue": "Journal of Computational Biology", "year": 2008, "id": "dc74e545-ad47-482a-9ddc-4d7fe5bade7d"}
{"abstract": "Real-world learning tasks may involve high-dimensional data sets with arbitrary patterns of missing data. In this paper we present a framework based on maximum likelihood density estimation for learning from such data set.s. We use mixture models for the density estimates and make two distinct appeals to the Expectation-Maximization (EM) principle (Dempster et al., 1977) in deriving a learning algorithm--EM is used both for the estimation of mixture components and for coping with missing data. The resulting algorithm is applicable to a wide range of supervised as well as unsupervised learning problems. Results from a classification benchmark--the iris data set--are presented.", "authors": ["Zoubin Ghahramani", "Michael I. Jordan"], "n_citation": 590, "references": ["addb1033-2d6c-42da-8965-8f2ee611a384", "b889d6ec-330d-406f-87b6-ea34804fadfd"], "title": "Supervised learning from incomplete data via an EM approach", "venue": "neural information processing systems", "year": 1994, "id": "6ce645b9-765d-4660-9df1-5d6ac65040b5"}
{"abstract": "Iteration space tiling is a common strategy used by parallelizing compilers and in performance tuning of parallel codes. We address the problem of determining the tile size that minimizes the total execution time. We restrict our attention to orthogonal tiling-uniform dependency programs with (hyper) parallelepiped shaped iteration domains which can be tiled with hyperplanes parallel to the domain boundaries. Our formulation includes many machine and program models used in the literature, notably the BSP programming model. We resolve the optimization problem analytically, yielding a closed form solution.", "authors": ["Rumen Andonov", "Sanjay V. Rajopadhye", "Nicola Yanev"], "n_citation": 50, "references": ["35446c6a-14dc-4711-a265-3eec5b42a8bb", "45ce3ace-09ea-4e33-828d-948ecee09224", "4abad3f6-6dfa-4ea9-a08f-04bcced86c99", "4b1f6789-efb1-4695-93e1-b0ef642859f9", "669cd2d9-23a8-44f5-856b-92a35b3fe763", "676d5db2-06d5-4bfd-86cd-066c0b3c71b6", "9803e79e-b961-4791-aec9-4af4a437df4d", "9e7f3a14-e586-4bad-aab9-0c36173e441d", "af34fa39-2ed0-48f5-8ec0-e11455dd8b1d", "da905f5d-682e-4e91-bd0d-9f7e658aa1b7", "f52cb74b-fe5f-4b84-81e9-77fa0b763040"], "title": "Optimal Orthogonal Tiling", "venue": "european conference on parallel processing", "year": 1998, "id": "2a8efc56-11e0-44a7-9f98-88d469a1c97f"}
{"abstract": "The time-dependent equations for the M/M/1 queue can be reduced to a single equation for the expected queue size, but the equation is dependent on  P  0 ( t ), the probability of no jobs in the system. An exact equation for the behavior of  P  0 ( t ) under special conditions is derived and an approximation relating  P  0 ( t ) to  Q ( t ), the expected queue size at time  t , is derived for the case when the change in queue size is slow compared to the service rate. It is found that the approximation affords a significant improvement over the use of a steady state approximation to the time-dependent queue and is simpler to use than the exact equations.", "authors": ["Kenneth Lloyd Rider"], "n_citation": 54, "title": "A Simple Approximation to the Average Queue Size in the Time-Dependent M/M/1 Queue", "venue": "Journal of the ACM", "year": 1976, "id": "8a80242a-433b-4c90-993f-781675796e23"}
{"abstract": "In this paper we report on a qualitative study, investigating the meaning of digital games in the lives of older adults. Using a combination of semi-structured interviews and observations (n=35) we research the meaning of digital games from a lifespan perspective, and explore the specific role of playing digital games in a social setting. We conclude that the meaning of these games is derived from the extent to which games are perceived to 1) foster connectedness, 2) cultivate oneself and others, and 3) contribute to society. Finally, we use these findings to formulate design guidelines to facilitate digital gaming experiences that are meaningful with regards to the psychosocial context of this specific demographic.", "authors": ["Bob De Schutter", "Vero Vanden Abeele"], "n_citation": 56, "references": ["38568d9c-cd45-442f-b220-559624ea0c48", "5e38dd73-03fb-4c7f-9edf-d53e56fdbb21", "71836135-c7ce-445e-b783-94cf51669461", "78b702a7-98c0-4e35-915f-697fe6058f63", "bd9fba46-46cc-4be8-894b-a66395a571f8", "f8666dcc-bf0c-43f2-a4df-269a0e5b26f0"], "title": "Designing meaningful play within the psycho-social context of older adults", "venue": "", "year": 2010, "id": "c7aa296d-32cd-42a1-863a-37033c9a4b4a"}
{"authors": ["Christopher H. Brooks", "Nancy Montanez"], "n_citation": 47, "references": ["e75d8e62-a86d-4241-953f-1b315005d920"], "title": "An Analysis of the Effectiveness of Tagging in Blogs.", "venue": "national conference on artificial intelligence", "year": 2006, "id": "fe0970b1-de0e-4b45-ab92-f253cf6fcb1c"}
{"authors": ["Isabelle Comyn-Wattiau", "Jacky Akoka"], "n_citation": 50, "references": ["17834bbe-d53c-4a61-8edd-396a66c7525f", "1dbcb786-5c6c-4d85-a1a3-0b9c43f65479", "42f84c77-f1b0-48f3-ab11-07ab7f12b557", "49a989dc-c75b-458d-952d-08f59e106357", "50cc5067-6931-4d1c-b404-a4e6dba900c9", "52e819e5-3725-4e5f-b397-738ffb367a9d", "53b4c61c-2a7a-41f3-80e9-09d114412fbb", "648b7f48-23d3-42a5-97fd-8ffad352fec8", "6c34ec7d-5895-4215-83d6-f147ed4da28b", "75c2f3bd-11e8-49dd-8c99-d3b37ea20932", "8136237c-5cbd-4cfd-a50a-51ccfa8ce067", "94584b62-bbde-42f3-9472-e7f1ac37fe50", "9a800afa-74cc-4cf2-b386-eb9a5939b038", "a252e3d6-44c1-4fa7-bc1e-cb19f454ba23", "d5fe146e-661c-4f75-94f0-5a44a2ecabf5", "e900776f-587a-4ef3-ac3c-51cbb07c7cda"], "title": "Reverse Engineering of Relational Database Physical Schema", "venue": "international conference on conceptual modeling", "year": 1996, "id": "a557dd95-5f9e-4d72-8afe-5c6264415e2d"}
{"abstract": "In this paper we use coding theory to give simple explanations of some recent results on universal hashing. We first apply our approach to give a precise and elegant analysis of the Wegman-Carter construction for authentication codes. Using Reed-Solomon codes and the well known concept of concatenated codes we can then give some new constructions, which require much less key size than previously known constructions. The relation to coding theory allows the use of codes from algebraic curves for the construction of hash functions. Particularly, we show how codes derived from Artin-Schreier curves, Hermitian curves and Suzuki curves yield good classes of universal hash functions.", "authors": ["J\u00fcrgen Bierbrauer", "Thomas Johansson", "Gregory Kabatianskii", "Ben Smeets"], "n_citation": 143, "references": ["2ae955b7-1d0a-4cc3-afa3-fe293e1d2e85", "44496e2b-6191-4cfd-b0fd-f7cb98c1d270", "44ce008c-9b86-4cf1-99ea-0e598e113987", "559ae7f7-3c22-4b8e-9e26-edb21eac8bf2", "abf003a2-6485-41f0-a111-88b80412d539", "b6acb667-743f-4d2e-86d0-3d8efa88f161", "f32b2ac6-b589-4581-9c6d-8a0a9643b541"], "title": "On families of hash functions via geometric codes and concatenation", "venue": "international cryptology conference", "year": 1993, "id": "966ae27d-15db-4f16-ad01-88ba8c2bb375"}
{"abstract": "We advocate an automated refinement approach to developing programs and their proofs. The approach is partially embodied in the Specware system [6] which has found industrial and government applications. Our view is that the future of software engineering lies in the tight integration of synthesis and analysis processes.", "authors": ["Douglas R. Smith"], "n_citation": 11, "references": ["07151061-914e-45c5-a406-62286d906a5b", "30326129-ea83-459b-b486-3fd01f0c4a6b", "5edb99f2-cc75-468e-9ca0-28ce7a1e709d", "710dfeb0-860a-43b7-a599-c8952ff7ab6c", "780eb9f8-7a62-4f9e-866c-7831490c109e", "a0dc0c3c-eefb-411a-b9c3-94e74234eb6f", "b6fd16e1-15d3-4c18-80cb-17f59af51c20", "c0349984-520e-458f-908d-e1aa6199707d", "c1b6c0d9-81bf-4d21-b1ad-806421cbeb55", "c3f76ae7-0d1e-4f9e-9817-114c0420431b", "e1db7984-8bdc-4e4d-b8b9-edcd97512ebe"], "title": "Generating Programs Plus Proofs by Refinement", "venue": "verified software: theories, tools, experiments", "year": 2005, "id": "aaed3cf9-53c5-4f18-bb49-9a61969a3481"}
{"abstract": "This paper describes a new and straightforward method for controlling spatially distributed plants based on low-order models obtained from spatial discretization techniques. A suitable level of discretization is determined by computing the sequence of @n-gaps between weighted models of successively finer spatial resolution, and bounding this by another sequence with an analytic series. It is proved that such a series forms an upper bound on the @n-gap between a weighted model in the initial sequence and the spatially distributed weighted plant. This enables the synthesis, on low-order models, of robust controllers that are guaranteed to stabilize the actual plant, a feature not shared by most model reduction methods where the gap between the high-order model and plant is often not known, and where the gap between high-order and reduced models may be too expensive to compute. Since the calculation of the current bound is based on weighted models of small state-dimension, the new method avoids the numerical problems inherent in large-scale model reduction based approaches. The ideas presented in this paper are demonstrated on a disturbance rejection problem for a 1D heat equation.", "authors": ["Bryn Ll. Jones", "Eric C. Kerrigan"], "n_citation": 11, "references": ["2f480018-1f26-49d3-accd-5c3cc3081bcc", "b9b6ccc5-44ea-4481-9e29-51cc1e3c1aa7", "c36578f4-4fcf-4b9e-a02e-af3616deb592", "d6272372-77b8-4e6e-a25c-d95cbbdd8f15"], "title": "Brief paper: When is the discretization of a spatially distributed system good enough for control?", "venue": "Automatica", "year": 2010, "id": "0eef4533-c3fd-4ded-9952-f96200c10aed"}
{"abstract": "In the context of pre-Bayesian games we analyze resource selection games with unknown number of players. We prove the existence and uniqueness of a symmetric safety-level equilibrium in such games and show that in a game with strictly increasing linear cost functions every player benefits from the common ignorance about the number of players. In order to perform the analysis we define safety-level equilibrium for pre-Bayesian games, and prove that it exists in a compact-continuous-concave setup; in particular it exists in a finite setup.", "authors": ["Itai Ashlagi", "Dov Monderer", "Moshe Tennenholtz"], "n_citation": 69, "references": ["2bdc04b1-d786-4876-8214-a50cc1ea1445", "41f01954-6809-42c3-a47f-f85293cb3b76", "5c3da41e-4ede-45b2-a162-9949028626de", "5ccb32b8-a9ca-4401-bca2-1cba437c35c1", "81fc55eb-7d5f-424b-8879-d2a8e4644bea", "90e1fe1c-222d-410f-9405-dec0f24c01b1", "94375d9e-e933-4389-9514-e41ce279392b", "b339e825-5747-4c14-bc7f-4405848a48b9", "c6e08cf3-33c3-4277-97e3-8dcb207cae3e", "eff9fe62-1480-483c-9521-79b5da03c47f", "f010e2e1-84e4-4531-b4dc-2fc2eea2515c", "f3a85764-c579-4207-bf55-b49684bbdd8f"], "title": "Resource selection games with unknown number of players", "venue": "adaptive agents and multi-agents systems", "year": 2006, "id": "1c8e35d5-b636-49af-a036-fb4210d29a12"}
{"abstract": "In software development, developers often rely on testing to reveal bugs. Typically, a test suite should be prepared before initial testing, and new test cases may be added to the test suite during the whole testing process. This may usually cause the test suite to contain more or less redundancy. In other words, a subset of the test suite (called the representative set) may still satisfy all the test objectives. As the redundancy can increase the cost of executing the test suite, quite a few test suite reduction techniques have been brought out in spite of the NP-completeness of the general problem of finding the optimal representative set of a test suite. In the literature, there have been some experimental studies of test suite reduction techniques, but the limitations of the these experimental studies are quite obvious. Recently proposed techniques are not experimentally compared against each other, and reported experiments are mainly based on small programs or even simulation data. This paper presents a new experimental study of the four typical test suite reduction techniques, including Harrold et al.'s heuristic, and three other recently proposed techniques such as Chen and Lau's GRE heuristic, Mansour and El-Fakin's genetic algorithm-based approach, and Black et al.'s ILP-based approach. Based on the results of this experimental study, we also provide a guideline for choosing the appropriate test suite reduction technique and some insights into why the techniques vary in effectiveness and efficiency.", "authors": ["Hao Zhong", "Lu Zhang", "Hong Mei"], "n_citation": 106, "references": ["21968dec-82d4-40b7-ad92-0bc41c9a9c56", "30521aed-580e-4260-8074-24f470294419", "392c42e1-b894-4c08-a2a2-d9f1481c5d3a", "43a4d168-8449-4599-b2c3-750b5c0d5ca7", "53577a95-d855-41b3-9ac2-6287b4f0262b", "59e5af7b-f85b-451c-b24d-bc93f06eb38f", "65740780-2e85-47a7-aad7-2a73e9bc0baa", "67fdaffd-21ee-439e-b6ac-6142e3386e6d", "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "8ddcac08-ea20-4405-b1f6-95e6582176b2", "9450b632-2288-4e85-8daf-206d1c95ece9", "9c5ad1a5-92c7-478f-beef-ba29ba4d3e94", "9fe654b4-8dc2-4bc2-8fa5-e232cfac26e3", "a3921949-ef96-4f72-9fa1-de54c33a5e9f", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "bf6c6d3f-980d-4b60-a863-05bcb88658bd", "c08668b0-7613-4c1c-bc1c-bbdc5fb6fb55", "c716bf6a-8185-4d7e-9ca3-5e5af10e2d3e", "d7f95d89-071f-4d6b-b804-d8e22d7d5a1a", "dbef9f33-3d5a-4609-b745-cd3da272a05c", "f1a1e8b5-f589-4c38-b4c9-195a2bedaad2", "fae6805c-b379-4d11-972d-76644b22601c", "fb2766ab-6d87-4eb0-9db7-8be7d734aced", "fb5f8578-f2ba-44b5-8278-cc4ede084a5f"], "title": "An experimental study of four typical test suite reduction techniques", "venue": "Information & Software Technology", "year": 2008, "id": "5f323d30-52ec-446e-b800-fb332b73da72"}
{"abstract": "An architectural hypothesis for the origin of motion-in-depth selectivity in the visual cortex is proposed. On the basis of a time extension of the phase-based techniques for disparity estimation, we consider the computation of the total temporal derivative of the time-varying disparity through the combination of the responses of disparity energy units. The emergence of motion-in-depth tuning is pointed out in relation to the unbalanced ocular dominance of a&erent binocular complex cells. The resulting cortical units of the model exhibit properties that can be directly compared with those reported in the literature for real cortical cells. c", "authors": ["Silvio P. Sabatini", "Fabio Solari"], "n_citation": 50, "references": ["84997f76-8c4c-4ee2-b088-6e1e8b882062", "ba0f08e7-490c-493e-8a9b-c0cc91ddef8c"], "title": "Emergence of motion-in-depth selectivity in the visual cortex through linear combination of binocular energy complex cells with different ocular dominance", "venue": "Neurocomputing", "year": 2004, "id": "3ffe5079-9f01-4a7b-b622-7723bbfb808c"}
{"abstract": "The behavior of a complex system is frequently defined in terms of operational modes---mutually exclusive sets of the system behaviors. Within the operational modes, collections of features define the behavior of the system.   Lucent and understandable modeling of operational modes and features using common state-based notations such as Statecharts or Stateflow can be challenging. In this paper we share some of our experiences from modeling modes and features in the medical device domain. We discuss the challenges and present a generic approach to structuring the modes and features of a generic Patient-Controlled Analgesia infusion pump.", "authors": ["Anitha Murugesan", "Sanjai Rayadurgam", "Mats Per Erik Heimdahl"], "n_citation": 12, "references": ["26db4152-3ccf-4b7a-9b23-fc69cb5d220b", "6505c0bf-62d9-42d3-8b53-ef276738c14c"], "title": "Modes, features, and state-based modeling for clarity and flexibility", "venue": "", "year": 2013, "id": "56f37daf-206b-4d94-8a66-aff47b3b1799"}
{"abstract": "Modern computer systems are based on a wide variety of software servers, such as web servers, application servers, database servers, and mail servers. The typical software architecture of such servers includes a set of processes or threads that serve requests submitted to the server. Requests that arrive at the server and find all threads busy, are placed in a queue. Threads that are busy executing requests compete for hardware resources (e.g., processors and I/O devices) at the machine where the software server runs. It is important to be able to model software servers in a way that takes into account both software contention\u2014waiting for threads\u2014and hardware contention\u2014waiting for processors and I/O devices. This paper presents analytical models for a wide range of multithreaded software server architectures: a) single class (i.e., all requests have similar demands) with unlimited thread queue size, b) single class with limited thread queue size, c) multiclass with unlimited thread queue size, and d) multiclass with limited queue size. Numerical results are presented to illustrate the use of the models.", "authors": ["D. Menasce", "Mohamed N. Bennani"], "n_citation": 50, "references": ["1c26e228-57d2-4b2c-b0c9-8d5851c17fac", "937702cd-0326-44b6-a9a5-ad1e48316458"], "title": "ANALYTIC PERFORMANCE MODELS FOR SINGLE CLASS AND MULTIPLE CLASS MULTITHREADED SOFTWARE SERVERS", "venue": "", "year": 2006, "id": "2a5fcd81-e589-4322-bbdd-889238a1234b"}
{"abstract": "In order for a mobile manipulator to move stably (without overturning) and execute end-effector tasks simultaneously, a manipulator with redundancy is effective. Using this redundancy, it is possible to perform tasks at an expected manipulator configuration when the robot is stable and compensate system stability when the robot is unstable. However, the ability to compensate stability by this manipulator motion is limited. Thus, in order to ensure the feasibility of stability compensation, the task plan or vehicle motion must be within this ability. In this paper, first the concept of the stability compensation range by static posture change is proposed. Then, within the stability compensation range, the compensation motion of a redundant manipulator considering an expected manipulator configuration and the system stability is derived, given the end-effector trajectory and the vehicle motion. Finally, the effectiveness of this method is illustrated by simulation examples.", "authors": ["Qiang Huang", "Kazuo Tanie", "Shigeki Sugano"], "n_citation": 103, "references": ["4199b290-44a4-424a-952f-058c9affacbe", "438ff2e2-bc90-48c7-a237-a09c0ee574ba", "6e2cf53c-fcfd-4f09-aae1-ef0c2bb45fd5", "6e31f389-dfcc-4bcb-b701-e6a3e265a275", "89710834-43ab-45a2-810f-bfd87edf0e20", "8d14b250-fb32-4ed1-921c-71e7269a4d66", "91b40704-bf26-436b-a09f-ed513316cccb", "91ff4f1c-ffaf-4c5e-a590-899521f436c8", "a93ed29d-d21f-44d8-b7e9-9890bcaea744"], "title": "Stability compensation of a mobile manipulator by manipulator motion : feasibility and planning", "venue": "Advanced Robotics", "year": 1998, "id": "52e45041-8956-4a72-ae17-82d1769586e0"}
{"abstract": "For an investor to claim his wealth resulted from his multiperiod portfolio policy, he has to sustain a possibility of bankruptcy before reaching the end of an investment horizon. Risk control over bankruptcy is thus an indispensable ingredient of optimal dynamic portfolio selection. We propose in this note a generalized mean-variance model via which an optimal investment policy can be generated to help investors not only achieve an optimal return in the sense of a mean-variance tradeoff, but also have a good risk control over bankruptcy. One key difficulty in solving the proposed generalized mean-variance model is the nonseparability in the associated stochastic control problem in the sense of dynamic programming. A solution scheme using embedding is developed in this note to overcome this difficulty and to obtain an analytical optimal portfolio policy.", "authors": ["Shushang Zhu", "Duan Li", "Shouyang Wang"], "n_citation": 163, "references": [], "title": "Risk control over bankruptcy in dynamic portfolio selection: a generalized mean-variance formulation", "venue": "IEEE Transactions on Automatic Control", "year": 2004, "id": "dd4b71eb-009d-4ec6-aa0f-419e9e921c66"}
{"abstract": "One of the guiding principles of open source software development is to use crowds of developers to keep a watchful eye on source code. Eric Raymond declared Linus'' Law as \"many eyes make all bugs shallow\", with the socio-technical argument that high quality open source software emerges when developers combine together their collective experience and expertise to review code collaboratively. Vulnerabilities are a particularly nasty set of bugs that can be rare, difficult to reproduce, and require specialized skills to recognize. Does Linus' Law apply to vulnerabilities empirically? In this study, we analyzed 159,254 code reviews, 185,948 Git commits, and 667 post-release vulnerabilities in the Chromium browser project. We formulated, collected, and analyzed various metrics related to Linus' Law to explore the connection between collaborative reviews and vulnerabilities that were missed by the review process. Our statistical association results showed that source code files reviewed by more developers are, counter-intuitively, more likely to be vulnerable (even after accounting for file size). However, files are less likely to be vulnerable if they were reviewed by developers who had experience participating on prior vulnerability-fixing reviews. The results indicate that lack of security experience and lack of collaborator familiarity are key risk factors in considering Linus\u2019 Law with vulnerabilities.", "authors": ["Andrew Meneely", "Alberto Rodriguez Tejeda", "Brian Spates", "Shannon Trudeau", "Danielle Neuberger", "Katherine Whitlock", "Christopher Ketant", "Kayla Davis"], "n_citation": 21, "references": ["0bfef742-9e3c-4c21-bc1f-523a4c759b78", "11df7d57-bad8-4b0b-8ce8-e26c6d9eb2b0", "12ca8848-3dc7-41b1-8ae8-3daff6dae54f", "2852fc62-b0b4-4f8e-b118-ab9f2b5210de", "29f65137-2260-42a9-81ba-eb86e67a1f79", "2bfce744-47b9-4419-97bf-deb7565ec6e3", "354e1732-d9fe-4d3b-a925-eca55b9df0dd", "4d2de09b-f271-48dc-87f1-7e3671176a88", "62d4d63d-9c8f-4b25-a17e-f3fc045c13d0", "63d50719-d1aa-4baf-8ad7-b123bb39f398", "7639cd8a-9cfa-48d8-88c4-bc4bd144ef6d", "876ff9a0-dd59-4ce3-bca3-9ccd8778f9c9", "9bb86970-a63c-434c-98e3-e2864c515dab"], "title": "An empirical investigation of socio-technical code review metrics and security vulnerabilities", "venue": "", "year": 2014, "id": "a7268751-d75a-4f2f-9038-f2d9da8651e1"}
{"abstract": "AVANCE 1  is an integrated application development and run-time system. It provides facilities for programming with shared and persistent objects, transactions and processes. The architecture is designed with decentralization in mind by having a large object identifier space and a remote procedure call interface to objects. Emphasis in this paper is on the programming language PAL and its relation with the underlying virtual machine.", "authors": ["Anders Bj\u00f6rnerstedt", "Stefan Britts"], "n_citation": 57, "references": ["071567c1-6198-4cce-a8b8-7abeb129c3c3", "0ee8791c-a465-45ee-b94e-057e7feafea9", "23e87727-a573-4cbc-ad44-179a13fcf1b1", "25b46064-0d14-4675-a8e7-ab20f1199e54", "50689679-8346-48f2-8d70-4dfd29f8b470", "577d6050-7b0d-46e2-9b95-2e49b5dcdb00", "59333583-92f3-49c8-95fc-12c17003f75d", "59942f27-01a7-401f-a73e-186a408c8a09", "5e19f6b4-7405-4868-bfe7-d50ee4d637a3", "78d07c73-7bc3-4ae7-998b-adf367e746d3", "915d8151-22b9-479c-b6f7-da9b0f417628", "9a9e6cad-3fd2-42ab-9465-40f1eca0855e", "9b0ce67d-567b-4ccd-995c-09ab35b0c90c", "ae77c82a-379f-4afc-820b-1a3ef0d7b03d", "c1f612c2-1906-4787-8206-b8447cdac4f7", "d0e81a2c-9e13-4e54-9e0f-c2795a257d2f", "d3822649-b90d-4633-aefb-07759b601e68", "f7fd25be-a741-4da1-a207-7d4f9ea47d2c"], "title": "AVANCE: an object management system", "venue": "conference on object oriented programming systems languages and applications", "year": 1988, "id": "9ae49aa8-ffab-4f72-9ae4-a4c30f844a5b"}
{"authors": ["Fridrich Sloboda", "B. Zat'ko", "Pavel Ferianc"], "n_citation": 50, "title": "The minimum perimeter polygon and its application", "venue": "", "year": 1992, "id": "9353cb91-c276-410e-b262-0e97c92138e2"}
{"authors": ["Geoffrey C. Fox", "Shrideep Pallickara"], "n_citation": 87, "references": ["5335b857-5dca-493c-9b3a-59cfb5e97656", "827988f6-007e-4c17-a7b8-0981c0c7205a", "a3b33607-fd63-4144-b26b-f8631de4065a", "c9a68afa-e1bb-4063-947b-f66e3d28b22c", "c9b8f3bf-babd-427a-8723-68b7e4526dd4", "f14df1ed-e3e9-4348-9040-fc06e3411b95", "f15b19f2-4b37-454c-851e-a71cccf3e53a"], "title": "The Narada Event Brokering System: Overview and Extensions", "venue": "parallel and distributed processing techniques and applications", "year": 2002, "id": "9a91797b-cb9d-448d-b7e1-4150701bee53"}
{"authors": ["Gustavo Alonso", "Claus Hagen", "Hans-J\u00f6rg Schek", "Markus Tresch"], "n_citation": 65, "references": ["17ec67ed-67cd-4075-9d2d-9e9d8c976aa1", "22d7ef30-ba84-4a7b-a8ee-3384f3a185d5", "2c60c261-89b3-44a0-b3a0-ca57f066afec", "4763dd4f-db8c-4c56-beac-a403067fb41a", "7a7b64f5-a3e0-4c31-8c6a-d49a5d2ee78c", "8064e983-63be-43a2-9827-ab04f5aef992", "f011e1d3-537d-4df2-a6ca-6ba6ac956715"], "title": "Distributed Processing over Stand-alone Systems and Applications", "venue": "very large data bases", "year": 1997, "id": "bb25dcb8-325f-403b-a7ec-df0b4ffbf733"}
{"authors": ["John T. O'Donnell"], "n_citation": 50, "title": "Generating Netlists from Executable Circuit Specifications.", "venue": "", "year": 1992, "id": "fc932f06-787b-4eab-991d-c6dececcb4bb"}
{"abstract": "We present a case study of visualizing the global topology of the Internet MBone. The MBone is the Internet's multicast backbone. Multicast is the most efficient way of distributing data from one sender to multiple receivers with minimal packet duplication. Developed and initially deployed by researchers within the Internet community, the MBone has been extremely popular for efficient transmission across the Internet of real-time video and audio streams such as conferences, meetings, congressional sessions, and NASA shuttle launches. The MBone, like the Internet itself grew exponentially with no central authority. The resulting suboptimal topology is of growing concern to network providers and the multicast research community. We create a geographic representation of the tunnel structure as arcs on a globe by resolving the latitude and longitude of MBone routers. The interactive 3D maps permit an immediate understanding of the global structure unavailable from the data in its original form as lines of text with only hostnames and IP addresses. Data visualization techniques such as grouping and thresholding allow further analysis of specific aspects of the MBone topology. We distribute the interactive 3D maps through the World-Wide Web using the VRML file format thus allowing network maintainers throughout the world to analyze the structure move effectively than would be possible with still pictures or pre-made videos.", "authors": ["Tamara Munzner", "Eric J. Hoffman", "kc claffy", "Bill Fenner"], "n_citation": 97, "references": ["4e394acf-e552-459a-a34a-8aaa98e6e08c", "7f4e4bda-59a8-4117-82ff-82721c89b41d", "baec9dfe-e53d-476e-a399-dcf8ae4e1906", "c91743b6-561a-4030-ba29-9ee12531d100"], "title": "Visualizing the global topology of the MBone", "venue": "ieee symposium on information visualization", "year": 1996, "id": "0bfe144d-4d68-4997-a1b6-09410f642f56"}
{"abstract": "We introduce a new low-distortion embedding of l 2  d  into l p  O(log n)  (p=1,2), called the  Fast-Johnson-Linden-strauss-Transform . The FJLT is faster than standard random projections and just as easy to implement. It is based upon the preconditioning of a sparse projection matrix with a randomized Fourier transform. Sparse random projections are unsuitable for low-distortion embeddings. We overcome this handicap by exploiting the \"Heisenberg principle\" of the Fourier transform, ie, its local-global duality. The FJLT can be used to speed up search algorithms based on low-distortion embeddings in l 1  and l 2 . We consider the case of approximate nearest neighbors in l 2  d . We provide a faster algorithm using classical projections, which we then further speed up by plugging in the FJLT. We also give a faster algorithm for searching over the hypercube.", "authors": ["Nir Ailon", "Bernard Chazelle"], "n_citation": 237, "references": ["07c804bf-b60d-4b5d-b004-8f4652e7d81b", "0d41d9b5-6e7d-476e-a484-36758a6b209a", "0f094852-0668-4dfe-92cc-ae5659ffc1d9", "1cd8a7cf-6612-4ad0-991b-f5850aa76755", "27a080f6-1fb1-4543-85d4-ee8d1aa6ce74", "3c672e4c-2411-4128-8360-f6849f665fce", "43dfd110-6a4d-4463-838a-dad26db1b846", "5437c0a0-8f20-49c3-86e5-9d860f3e4f04", "5ce1553b-2b02-4469-ae72-04a31418fc52", "80030a9c-5ae4-43d3-9bb8-7b94aa5252b5", "80aca55b-1c67-4260-a3a0-e203fd8d49ec", "833da8cb-e068-44eb-955c-48b52adabfae", "8fed7067-5f57-4f15-88cc-c948bcdd83f4", "a004b495-c45e-483b-ba58-0267bdc8659c", "a03d2ca2-f919-42b5-9de0-1d6d7d22d396", "adf6fdf9-01a0-4051-9d99-965f4a5baa4d", "b11f895d-0f55-486d-8d4a-dbd18bf9ba1f", "bf132fef-c091-4f7e-a850-22b83ff7a9e2", "bff52083-617d-45be-a5ab-091d61c23d66", "c4812b4e-c181-4c6b-9e47-f92572417181", "d20995f6-529c-41c6-b75e-a169b005fb5c", "d579ce7e-8b6d-4ce0-9c1e-aeb76f76ff66", "f17cee87-b96c-4891-b510-c165727b4d4a", "f43261e9-b984-4746-97b2-613e071f6357", "f6272ea9-0360-47ed-90a5-651ea958143f"], "title": "Approximate nearest neighbors and the fast Johnson-Lindenstrauss transform", "venue": "symposium on the theory of computing", "year": 2006, "id": "bd99cee2-3297-4155-af82-426ab28c1e11"}
{"abstract": "Collision detection and response are important for interactive graphics applications such as vehicle simulators and virtual reality. Unfortunately, previous collision detection algorithms are too slow for interactive use. The paper presents a new algorithm for rigid or articulated objects that meets performance goals through a form of time critical computing. The algorithm supports progressive refinement, detecting collisions between successively tighter approximations to object surfaces as the application allows it more processing time. The algorithm uses simple four dimensional geometry to approximate motion, and hierarchies of spheres to approximate three dimensional surfaces at multiple resolutions. In a sample application, the algorithm allows interactive performance that is not possible with a good previous algorithm. In particular, the new algorithm provides acceptable accuracy while maintaining a steady and high frame rate, which in some cases improves on the previous algorithm's rate by more than two orders of magnitude. >", "authors": ["Philip M. Hubbard"], "n_citation": 413, "references": ["0bde9924-3568-466a-a13c-0bb590b242ab", "149dd311-059a-4acf-b71d-6e486a288e8a", "2eac3598-419c-402f-b54e-8dc075974882", "332160e8-c117-49c1-9310-2a15431bb77d", "36d53ade-b2ce-4f75-9685-f842d1bbf581", "47045634-cb22-4066-a2c0-fa166ade71c9", "491a2543-fc62-4815-b3c9-7beffae2f13b", "510eec1d-f82c-4b19-b116-b8fd4c66531a", "7b0dc1fe-d795-43a5-80b2-91a663685f20", "7e48af09-aba0-42dd-87cd-9afaaeed8539", "946634c0-b329-4efe-a704-6a28676f7e98", "a1b75ac7-cd09-4343-aef7-fc1a7b10231c", "bb4c83af-c1ca-4408-a5d1-9722b3142a6a", "c5464182-70ad-4fa1-8beb-e2238e6fe4b2", "c9287e41-e1cd-4b62-8c5c-57cbc4a91adf", "d5002826-2d3a-40fa-a1c3-4f1602689d85", "d555efe5-86cc-4c6d-b51a-278eaaad358b", "e58f8209-33f6-4291-b1d3-c3aaf3425aaf", "fdf7ef52-b7ec-4406-9c13-bd40813437f9"], "title": "Collision detection for interactive graphics applications", "venue": "IEEE Transactions on Visualization and Computer Graphics", "year": 1995, "id": "f3558c1a-4b78-479e-8226-55e66b2c738e"}
{"authors": ["Mike Brown"], "n_citation": 9, "references": ["1b978417-c775-4777-bad6-ee3ee15f2025", "47e68050-9e1e-4aaf-b71d-d53f94150b0a"], "title": "An Underlying Memory Model to Support Case Retrieval", "venue": "", "year": 1993, "id": "f94fadac-6b0e-4c1e-8e4c-424684897bcb"}
{"abstract": "IEEE 802.11 wireless local area network (WLAN) physical layers (PHYs) support multiple transmission rates. The PHY rate to be used for a particular frame transmission is solely determined by the transmitting station. The transmitting rate should be chosen in an adaptive manner since the wireless channel condition varies over time due to such factors as station mobility, time-varying interference, and location-dependent errors. In this paper, we present a novel link adaptation algorithm, which aims to improve the system throughput by adapting the transmission rate to the current link condition. Our algorithm is simply based on the received signal strength measured from the received frames, and hence it does not require any changes in the current IEEE 802.11 WLAN medium access control (MAC) protocol. Based on the simulation and its comparison with a numerical analysis, it is shown that the proposed algorithm closely approximates the ideal case with the perfect knowledge about the channel and receiver conditions.", "authors": ["Javier del Prado Pavon", "Sunghyun Choi"], "n_citation": 530, "references": ["4d994ac6-8a2d-4070-b7de-473dbb2233bb", "87bb6963-ebe7-4775-9ee0-7184e1ea6c19", "98783db9-d399-4537-9eaa-8964f92d99c7", "e3d09cfb-8e82-4f07-9b2c-0aae3367663d"], "title": "Link adaptation strategy for IEEE 802.11 WLAN via received signal strength measurement", "venue": "international conference on communications", "year": 2003, "id": "06e501bd-ac6a-452c-97cf-fdffb70d05b5"}
{"authors": ["Daniel R. Dolk", "Benn R. Konsynski"], "n_citation": 45, "references": ["8ad2d4b1-d4b4-45af-aef5-0038a885c50e", "e52738ed-9702-4117-b7db-9052e88eceb6"], "title": "Model management in organizations", "venue": "Information & Management", "year": 1985, "id": "b03bfc49-61db-4709-aec2-b4761e0897c0"}
{"abstract": "In this paper, we address the design issues of a collaborative workspace system, called TeamSpace, that supports geographically distributed teams by managing shared work processes and maintaining shared artifacts in a project. TeamSpace attempts to integrate both synchronous and asynchronous types of team interaction into a task-oriented environment. Since meetings are an integral part of teamwork, our current work focuses on supporting virtual meetings as part of a larger collaborative work process. We present an initial TeamSpace prototype that supports asynchronous meeting management seamlessly integrated with capture and access of synchronous distributed meetings. The captured synchronous data is integrated with other related information in TeamSpace, enabling users to efficiently gain knowledge of both current and past team activities.", "authors": ["Werner Geyer", "Heather Richter", "Ludwin Fuchs", "Tom Frauenhofer", "Shahrokh Daijavad", "Steven E. Poltrock"], "n_citation": 109, "references": ["14192c22-7955-4d12-8c14-c6517f28fdb3", "1dba9c55-ce41-4d90-b18e-056c653e842f", "24b314c9-eb0b-481e-9394-647f0f2ef045", "2cb05992-1225-4f55-b896-44a27a5ea4af", "6d95d1bc-e442-4d16-a08b-bb291d00394c", "810fe595-c33a-42a4-92bc-4ef6aeb0ceb2", "92997de0-0be4-475a-aa1e-36fb240a909b", "a4f45f9b-3071-4c59-aec3-46959a22e3f3", "a8a4bbc2-9c7a-4217-ac1b-4e1d5de019a9", "ba52eb86-0030-42e2-88f4-877459e32372", "bccac6f9-ecc0-497a-a5a0-1ab0e74ff93f", "d116e88c-f914-411e-afa3-d489f1367308", "ff444183-e458-4ee2-a086-a08bcb0e5208"], "title": "A team collaboration space supporting capture and access of virtual meetings", "venue": "international conference on supporting group work", "year": 2001, "id": "5093823a-9527-49d6-8918-7d42de5c182c"}
{"abstract": "In evaluations of text entry methods, participants enter phrases of text using a technique of interest while performance data are collected. This paper describes and publishes (via the internet) a collection of 500 phrases for such evaluations. Utility programs are also provided to compute statistical properties of the phrase set, or any other phrase set. The merits of using a pre-defined phrase set are described as are methodological considerations, such as attaining results that are generalizable and the possible addition of punctuation and other characters.", "authors": ["I. Scott MacKenzie", "R. William Soukoreff"], "n_citation": 516, "references": ["00b44e0f-1667-4f55-9497-376ba71149d1", "1b3dfac2-4af0-4fa2-8976-8848a608da9f", "652a647a-ef06-4bad-adee-3f5aebfcd1c8", "b8067d22-ada9-4005-8d5b-a4f47f99ad79"], "title": "Phrase sets for evaluating text entry techniques", "venue": "human factors in computing systems", "year": 2003, "id": "0c576ed8-f112-4be3-b90a-77f26183539a"}
{"abstract": "A meta-analysis of themes resulting from some human resource studies of information professionals is contrasted with trends in IT worker human resource management in order to highlight an apparent paradox in the path toward organizational knowledge management. Findings from three studies of information sector workers in Europe and America are contrasted with data from a recent information technology workforce convocation conducted in the United States in order to focus attention on the paradox in the movement toward knowledge management and organizational productivity. On the one hand, the human resource studies document the shift in focus from", "authors": ["Eileen M. Trauth"], "n_citation": 20, "references": ["1d7d1d99-eb7b-4d37-a7f9-883246261fbd", "4e6bcf3b-aa6d-42c4-bf44-a5a2f99065f2", "a8399cb7-cb72-4d8a-85b2-f0baae6648f5"], "title": "Who owns my soul? The paradox of pursing organizational knowledge in a work culture of individualism", "venue": "", "year": 1999, "id": "51b58ca5-0037-4ff7-a496-6feb82d2e61a"}
{"abstract": "Currently, most approaches to retrieving textual materials from scientific databases depend on a lexical match between words in users\u0092 requests and those in or assigned to documents in a database. Because of the tremendous diversity in the words people use to describe the same document, lexical methods are necessarily incomplete and imprecise. Using the singular value decomposition (SVD), one can take advantage of the implicit higher-order structure in the association of terms with documents by determining the SVD of large sparse term by document matrices. Terms and documents represented by 200-300 of the largest singular vectors are then matched against user queries. We call this retrieval method Latent Semantic Indexing (LSI) because the subspace represents important associative relationships between terms and documents that are not evident in individual documents. LSI is a completely automatic yet intelligent indexing method, widely applicable, and a promising way to improve users\u0092 access to many kinds of textual materials, or to documents and services for which textual descriptions are available. A survey of the computational requirements for managing LSI-encoded databases as well as current and future applications of LSI is presented.", "authors": ["Michael W. Berry", "Susan T. Dumais", "Todd A. Letsche"], "n_citation": 170, "references": ["0a46b53a-6a12-46b2-a29f-4b477c2b791f", "0dbf9d1d-73cf-4e9c-8719-d0c1ec46495a", "23f66d97-4abf-479f-8af5-ec833d850a24", "33cee52d-fbbf-4a0b-8f03-957ee5fc87d9", "a677a749-cb49-4d5e-a2d8-2078230e4f88", "ac14afe6-de4d-4056-b2ac-0f6e36f369a2", "b3593e4a-622e-49eb-b375-6ce650003a05", "b75a9d6c-4818-4d80-b0c0-aa5dd04a7b7f", "f6a34127-1731-444a-8653-5e365f4f9549", "f8310857-4b0d-491c-8ada-1997c65689d5", "fbd3321c-0fb8-4acc-8294-3f665c4ade7b"], "title": "Computational Methods for Intelligent Information Access", "venue": "supercomputing conference", "year": 1995, "id": "6eb1a3da-9fcf-4b4f-81d1-0196067a9447"}
{"abstract": "Blind sources separation, independent component analysis (ICA) and related methods are promising approaches for analysis of biomedical signals, especially for EEG/MEG and fMRI data. However, most of the methods extract all sources simultaneously, so it is time consuming and not reliable especially, when the number of sensors is large (more than 100 sensors) and signals are contaminated by huge noise. The main objective of this paper is to present a new method for extraction of specific source signals using bandpass filters approach. Such a method allows us to extract source signals with specific stochastic properties, e.g., extraction of narrow band sources with specific frequency bandwidth.", "authors": ["Andrzej Cichocki", "Tomasz M. Rutkowski", "K. Siwek"], "n_citation": 26, "references": ["a3c64624-c1a2-4d0e-9dda-85dbfe5ac6dc", "ada27ede-4400-4e7d-aee5-1b5e62fe1800", "cb6fffe7-d319-46ae-8aed-13ebb259aa90", "fb994544-0cfd-44e0-8482-d1f02193ce76"], "title": "Blind signal extraction of signals with specified frequency band", "venue": "", "year": 2002, "id": "90d34135-1f8e-4a1d-afc3-e3d901862270"}
{"abstract": "Combinatorial interaction testing (CIT) is a method to sample configurations of a software system systematically for testing. Many algorithms have been developed that create CIT samples, however few have considered the practical concerns that arise when adding constraints between combinations of options. In this paper, we survey constraint handling techniques in existing algorithms and discuss the challenges that they present. We examine two highly-configurable software systems to quantify the nature of constraints in real systems. We then present a general constraint representation and solving technique that can be integrated with existing CIT algorithms and compare two constraint-enhanced algorithm implementations with existing CIT tools to demonstrate feasibility.", "authors": ["Myra B. Cohen", "Matthew B. Dwyer", "J. Shi"], "n_citation": 198, "references": ["0004a295-8dcc-480a-a441-495a8bd636f7", "2cab8621-0632-46dd-abcf-dce23c465e43", "3528044b-5453-4440-9372-5258666d57bd", "3e29294c-d9d5-4648-820b-f945366f5c06", "41cf9713-ed76-43a6-8e9f-538abc2f787c", "46ed8cfc-9750-46a8-8492-e4702c5dfb1b", "58b899a5-38a8-4704-9285-f92cad2db957", "6cd7a1a2-cc4f-45ab-986d-5c8f9ce4309f", "7880e45e-5a86-4693-93fa-7f36966c272e", "980dae48-98ee-4b3c-ab6c-db37faa7f050", "caf90b36-ef18-461d-bea2-357d53494c23", "da98bf67-2f1a-4bbf-94a3-9ddb70ddc35d", "ddc824bd-0114-4658-970b-c55c17eba1dc", "e6e7be15-ec67-4845-890d-63e6a15ad0a4", "e7f33b2b-ad3a-4cfe-835e-f00ef8a15ea0", "eeb48257-2159-4e37-bebf-60234df9b2fd", "fb814bfc-7989-4178-983d-a606acd5e6ca", "fd101fa3-ed7b-4221-8a13-001a950f2181"], "title": "Interaction testing of highly-configurable systems in the presence of constraints", "venue": "international symposium on software testing and analysis", "year": 2007, "id": "9f6f0a1b-bd91-497b-8237-43bd83576a24"}
{"abstract": "Abstract   The basic logic programming semantic concepts, query, solutions, solution forms, and the fundamental results such as Herbrand theorems, are developed over any logical system, formalised as institution, by employing \u2018institution-independent\u2019 concepts of variable, substitution, quantifier, and atomic formulae. This sets semantical foundations for a uniform development of logic programming over a large variety of computing science logics, allowing for a clean combination of logic programming with other computing paradigms.", "authors": ["R\u0103zvan Diaconescu"], "n_citation": 50, "references": ["1ca32906-1a97-406e-8d90-8e38c27e274b", "3162f4f2-436a-4d97-b70b-6fbb67f17e10", "31b99f97-c307-45b2-918e-1f440ad13974", "37bfda87-4541-43a8-8eb4-58d5a97d4981", "3f1493bf-4b89-4ee2-9af7-ddbc333ae782", "415322ae-2bf2-4b5e-8027-c0f75b5fcab1", "473e04b2-4c06-48a8-b25d-eb7a4fa24056", "5bd8f5c7-7458-4f72-a57e-bf9afc71581a", "5efdf9b2-a2e2-4929-9728-00fbca01e604", "6664e936-2f40-4052-8451-172f62a7162f", "67c74486-0013-4948-aac8-8905fe95a573", "7ac058e8-3e74-4f85-984a-b35dbf53a95e", "98a2fbfe-2701-491a-8919-150006c95f6a", "a327ec4b-e570-4531-a584-2bd50214d425", "abfe568f-99b6-4969-9d82-bc4aced50cad", "ce6e7dc3-385d-41b9-8601-cb61351ceb8c", "eb2c34c9-d77b-42ca-83e3-3df31a5927d9", "f7937748-4a03-4d66-a770-39c88cc8320f"], "title": "Herbrand theorems in arbitrary institutions", "venue": "Information Processing Letters", "year": 2004, "id": "6eb7b0af-7ad9-418b-9a23-0e0760ac01dc"}
{"abstract": "Mutation analysis evaluates a testing technique by measur- ing how well it detects seeded faults (mutants). Mutation analysis is hampered by inherent scalability problems \u2014 a test suite is executed for each of a large number of mutants. Despite numerous optimizations presented in the literature, this scalability issue remains, and this is one of the reasons why mutation analysis is hardly used in practice. Whereas most previous optimizations attempted to stati- cally reduce the number of executions or their computational overhead, this paper exploits information available only at run time to further reduce the number of executions. First, state infection conditions can reveal \u2014 with a single test execution of the unmutated program \u2014 which mutants would lead to a different state, thus avoiding unnecessary test executions. Second, determining whether an infected execution state propagates can further reduce the number of executions. Mutants that are embedded in compound expressions may infect the state locally without affecting the outcome of the compound expression. Third, those mutants that do infect the state can be partitioned based on the resulting infected state \u2014 if two mutants lead to the same infected state, only one needs to be executed as the result of the other can be inferred. We have implemented these optimizations in the Major mu- tation framework and empirically evaluated them on 14 open source programs. The optimizations reduced the mutation analysis time by 40% on average.", "authors": ["Ren\u00e9 Just", "Michael D. Ernst", "Gordon Fraser"], "n_citation": 37, "references": ["052b7516-f5d4-4649-9037-ef40117ebb1a", "062152bd-4998-4e00-af8c-c8624cbc9857", "0fd5aa4c-c75c-4ea0-8d7d-b3e161691e4d", "1c18f7e1-9622-4479-9ad2-a0058b3024bb", "226623fc-2ec0-44d7-9d48-f0469e821405", "36d8ae9a-9dd8-4c50-922b-83c5d12e36e2", "3743486d-7b1f-4170-ba90-a8adca05889c", "388ed727-133d-4b19-8d16-a7622adb4e37", "40291a5a-5cb0-4189-966e-8197facbd9bd", "4acda6d4-094b-463b-88e0-a4fe30439af1", "4b6174b7-1643-4805-bcb3-f720241b1bc0", "4e684bad-f6c1-4df5-ab38-7e7ca826d5f4", "61e82d89-86ce-4b98-be72-0fa702ff4f90", "64934134-9194-4998-9b54-f4721636b7cb", "7eefbefb-2b7a-452e-ac38-6092532585d1", "936eafe8-550c-4745-ba39-2c3351a1a297", "b0ddde28-9091-471a-b140-bc6d648b1164", "b3493f1a-e697-44d2-8f75-61c92e448d52", "cf752ca1-6232-4a5d-8fda-7dd7cb70e405", "d7d7ca2b-abb6-48ca-9b20-3391bc60ccc7", "e4a3b24c-eaa7-458b-a16f-ccec3af310ed", "ebd9eb70-0e46-4e8e-b0aa-cd66d5b8e702", "f83019e9-025f-4d69-acf7-1f8ef80ce466"], "title": "Efficient mutation analysis by propagating and partitioning infected execution states", "venue": "international symposium on software testing and analysis", "year": 2014, "id": "5265068c-446e-4710-8323-95c973fcab7e"}
{"abstract": "We have designed and implemented Maya, a version of Java that allows programmers to extend and reinterpret its syntax. Maya generalizes macro systems by treating grammar productions as generic functions, and semantic actions on productions as multimethods on the corresponding generic functions. Programmers can write new generic functions (i.e., grammar productions) and new multimethods (i.e., semantic actions), through which they can extend the grammar of the language and change the semantics of its syntactic constructs, respectively. Maya's multimethods are compile-time metaprograms that transform abstract syntax: they execute at program compile-time, because they are semantic actions executed by the parser. Maya's multimethods can be dispatched on the syntactic structure of the input, as well as the static, source-level types of expressions in the input. In this paper we describe what Maya can do and how it works. We describe how its novel parsing techniques work and how Maya can statically detect certain kinds of errors, such as code that generates references to free variables. Finally, to demonstrate Maya's expressiveness, we describe how Maya can be used to implement the MultiJava language, which was described by Clifton et al. at OOPSLA 2000.", "authors": ["Jason Baker", "Wilson C. Hsieh"], "n_citation": 91, "references": ["001d5f8b-33ad-4b9e-bfa8-f288dc55940e", "0b70a87d-5797-462e-8462-0b2ea6102306", "0c8b68b9-7445-4114-bd32-412f7cb76836", "1c915292-2f7b-4af7-9bc1-187001c58e95", "724f83cb-a9ac-4786-99d6-0ff6a0cd0858", "8cc7c20a-4307-407c-be63-ac739e6991c4", "964c1fd4-735f-4e9d-aed3-e9f59636e2af", "a49b27f6-f35b-4977-a130-bfa15872d63e", "aa8858bb-af1e-488e-a33c-cd0ae8467ffa", "b33bb423-71f4-4960-8c9c-d4797bf32671", "c89bb272-f781-491b-88ee-1be0ec4e7ac4", "d45a610c-488f-40cc-bee0-a36b8e8fb4f5", "d560ef09-5419-4ceb-a122-46d00964dc05", "fb647c73-e367-475d-bc72-dc08f4d2d11e"], "title": "Maya: multiple-dispatch syntax extension in Java", "venue": "programming language design and implementation", "year": 2002, "id": "be493d0e-64fc-451f-ad80-ccbc1de3e1ec"}
{"authors": ["Roberto Tron", "Ren\u00e9 Vidal"], "n_citation": 40, "references": ["0168d149-3c91-446e-9bc0-4ad62727b3c7", "1b2f4f99-5cc7-46ef-a765-662e64e7c7b2", "20c98ec1-cbae-40a0-b88d-e8c747fca591", "24cf12ca-f66d-41d3-8754-58d858f7fd98", "269a4dfe-5e0f-460b-8e20-5faeac889f3f", "29357562-ef72-4650-9887-1e608cc09dac", "32f84086-f7ca-40c9-aeb9-f87be84fced9", "351abdcb-f7c4-4863-ac0c-91a0b46fa59b", "39927b42-7fd5-40cb-80ee-f902e9daabde", "39a39ff1-9ffd-4cd6-a5cc-4d635a2093e4", "3bb2e285-8e5c-412d-821f-1ba491d8a0ba", "4feb0a2d-1fc5-4e44-ad76-bef6a0560b0a", "54ed6da4-eefe-41ec-8700-d32b9085b165", "57309909-951c-4c0c-9663-664ec76b9c8e", "60dc6950-f083-4a91-8268-73b9f27f6558", "8077b611-e7e7-430c-b8d6-047c0ae6f965", "9d770a80-2fef-4580-98cd-aa4ff68df5bc", "a20a4ace-5be7-4f06-9223-9907fdc31654", "a7011f5e-9bd7-485c-ac98-708545f2d546", "afc9794f-62e6-44d8-bcde-7fab822b0323", "b72ef385-f390-497c-812d-85d77963045c", "b866b58e-91e8-4039-9056-777767637976", "bb3b9fec-b9be-4ca5-b050-4dc88e17b504", "bba168a3-a73d-496a-bcd7-a09b90ec5ce0", "bde4f48c-9064-49d9-a11a-bac0ebe13621", "bfc63f16-a5b2-46d8-a92c-73d7cfdd4f34", "c694af6f-b809-4f7f-b74d-75267c6e62bd", "c80ecd71-709a-4cb2-923e-bfceccdfa5a4", "ca59562e-1d96-47af-8d60-2df441727e3f", "d18d638d-5817-4991-afd3-2ae4f65bbe87", "d9162547-fd7f-4605-855d-0a3173c4b08e", "ec064890-4c6f-4c10-9920-fe0fd61f7d44", "fa02eec0-9d54-44fd-b2e6-b0786d8d5441", "fc79b3a7-753e-43ab-a149-1fc00f1f357b"], "title": "Distributed 3-D Localization of Camera Sensor Networks From 2-D Image Measurements", "venue": "IEEE Transactions on Automatic Control", "year": 2014, "id": "9a0670e0-e819-4178-9262-40ec3df50b48"}
{"abstract": "In this paper, we propose a multiple-level genetic-fuzzy mining algorithm for mining membership functions and fuzzy association rule on multiple-concept levels. It first encodes the membership functions of each item class (category) into a chromosome according to the given taxonomy. The fitness value of each individual is then evaluated by the summation of large 1-itemsets of each item in different concept levels and the suitability of membership functions in the chromosome. After the GA process terminates, a better set of multiple-level fuzzy association rules can then be expected with a more suitable set of membership functions. Experimental results on a simulation dataset also show the effectiveness of the algorithm.", "authors": ["Chun-Hao Chen", "Tzung-Pei Hong", "Yeong-Chyi Lee"], "n_citation": 2, "references": ["054ff459-b189-4e73-bf05-3c34f5f77c7d", "08f0eb0c-891c-41dd-89c0-abd9c541c768", "1d99afb6-24b2-473e-af88-07cd904b7290", "326fc9e5-9d69-4b89-ae23-987c90bd0f89", "4df8f768-2817-4d0c-857d-f12ff6805135", "51a2a139-ff14-4e03-9ee7-4a3806385a31", "572f6570-87e0-4d51-9ff9-0a3f48c9d6ee", "59ff3da2-3d67-469c-960b-ea69c91ff873", "82c534c6-c89d-4856-b6fc-e1cad5be4482", "83759260-9385-4a77-b108-45aaf008ce1e", "903c8feb-34eb-45f8-8751-d96bd126997d", "9054b15d-a1d5-4326-93a1-01d759993e56", "94948518-6573-41ee-80b6-e65001c1586b", "a25ff071-8c07-46d3-8d55-f36aa2752766", "a32cc01a-e81b-415d-a813-a8a870d29a38", "afd2443d-6050-4871-a3a6-abc9ac709c7c", "b282a562-7f62-4fe5-a52c-918e1794a528", "c1b4dd1c-e9bc-4a8a-a081-50410ab16e28", "c49e6979-a8e3-4d37-b515-b2a5400e9522", "c85ea59f-821a-43d3-9de8-ddf2293a4c44", "d071e399-8d2a-49b2-bfeb-ad62b831a0e1", "e8ab235f-d709-4d84-87d4-c2dba5b73d32", "efa05c16-5ab6-49b2-8028-a362db0d89bb", "f3dc3d81-27dc-47cf-8de1-d544600762b4"], "title": "A multiple-level genetic-fuzzy mining algorithm", "venue": "ieee international conference on fuzzy systems", "year": 2011, "id": "1f88a111-ec97-46ce-9ab2-0d7c96245fea"}
{"abstract": "Cell segmentation is a challenging problem due to both the complex nature of the cells and the uncertainty present in video microscopy. Manual methods for this purpose are onerous, imprecise and highly subjective, thus requiring automated methods that perform this task in an objective and efficient way. In this paper, we propose a novel method to segment nucleus and cytoplasm of white blood cells (WBC). WBC composition of the blood provides important information to doctors and plays an important role in the diagnosis of different diseases. We use simple morphological operators and explore the scale-space properties of a toggle operator to improve the segmentation accuracy. The proposed scheme has been successfully applied to a large number of images, showing promising results for varying cell appearance and image quality, encouraging future works.", "authors": ["Leyza Baldo Dorini", "Rodrigo Minetto", "Neucimar J. Leite"], "n_citation": 104, "references": ["12383caa-bd26-4ab1-a13b-5aa4cdc0850a", "2d091c5a-f0ec-4e13-aa88-1d8ced87d060", "2dbd1339-2b25-492f-b7ea-091b8a1d9bbb", "3ae5a6c6-d1a6-48bd-b846-2ab3b4f02564", "3c1dff88-f8dd-45c6-80e7-9d4a237e87b4", "41ba0a8b-cec5-4618-a99b-fca06baf1253", "4629f9c5-de63-43b2-bd8c-5ea7cf3bdd9c", "5fadd790-4d5c-4a63-9d0c-39661713cf69", "6b9186f4-8305-45a7-a990-24f1f4267b64", "7eb6c101-7409-4b2d-91df-f18fea43f76d", "82043901-35f6-44d9-917a-7222707b101c", "877234cf-bf45-40b2-a615-55197d475e05", "bbdff07c-cd25-452b-b966-3f540cb959e5", "dd2342d6-5551-44c8-bc66-489c47143296", "f3f18d51-a672-412a-943b-f59213a0240e", "f55bfb20-6045-4a81-9438-fce415dc968d", "f6b23b21-e842-4621-a968-6ba578ac4dbc"], "title": "White blood cell segmentation using morphological operators and scale-space analysis", "venue": "", "year": 2007, "id": "ee551d18-dc2e-45d4-9f63-e23a37039d65"}
{"abstract": "Optimal control problems are often solved exploiting the solution of the so-called Hamilton-Jacobi-Bellman (HJB) partial differential equation, which may be, however, hard or impossible to solve in specific examples. Herein we circumvent this issue determining a dynamic solution of the HJB equation, without solving any partial differential equation. The methodology yields a dynamic control law that minimizes a cost functional defined as the sum of the original cost and an additional cost.", "authors": ["Mario Sassano", "Alessandro Astolfi"], "n_citation": 50, "references": ["5724d736-5f7f-4e62-b124-a41c815b80b7", "8b9cd040-b50c-40bd-a31b-dcfae3cd5e4a", "94437a54-e596-45c8-9fe4-0b2155789736", "a2064dc3-677f-48a7-994d-d055c30ec8f7"], "title": "Dynamic solution of the HJB equation and the optimal control of nonlinear systems", "venue": "conference on decision and control", "year": 2010, "id": "c8a8757b-bb73-4f75-b88f-f1940747909f"}
{"abstract": "Video retargeting is the process of transforming an existing video to fit the dimensions of an arbitrary display. A compelling retargeting aims at preserving the viewers' experience by maintaining the information content of important regions in the frame, whilst keeping their aspect ratio. An efficient algorithm for video retargeting is introduced. It consists of two stages. First, the frame is analyzed to detect the importance of each region in the frame. Then, a transformation that respects the analysis shrinks less important regions more than important ones. Our analysis is fully automatic and based on local saliency, motion detection and object detectors. The performance of the proposed algorithm is demonstrated on a variety of video sequences, and compared to the state of the art in image retargeting.", "authors": ["Lior Wolf", "Moshe Guttmann", "Daniel Cohen-Or"], "n_citation": 496, "references": ["21a93e31-884f-47c5-837c-c943021a622c", "6a5e9cd0-60f9-4623-ac93-6bc92d505b6a", "7248a040-50f3-44b0-abdd-229c6a0881d5", "8b86726e-8cb1-4815-9b9f-17cedd01886e", "8b8a2247-bd77-4736-b493-449734f56b9a", "a3b3ecce-5921-47ec-a21b-80a8cb1939b8", "bc0310e3-c11d-4f2d-9bc4-e8a3b10ca18c"], "title": "Non-homogeneous Content-driven Video-retargeting", "venue": "international conference on computer vision", "year": 2007, "id": "ecd283e0-1a8c-49b0-8562-073e5b889af9"}
{"abstract": "In this study, one considers the tracking control problem of a class of nonsmooth fully actuated Lagrangian systems subject to frictionless unilateral constraints. The task under consideration contains both free-motion and constraint-motion phases. A switching controller that guarantees an approximate tracking is designed. Particular attention is paid to transition (impacting and detachment) between different phases of motion. The exogenous signals that assure the stabilization on (take-off from) some constraints are explicitly defined. This paper extends previous works on the topic as it considers more than one constraint for  n -degree-of-freedom systems. Numerical examples illustrate the main results.", "authors": ["Irinel Constantin Mora\u030crescu", "Bernard Brogliato"], "n_citation": 64, "references": ["1bd5bf66-0565-43e4-a31d-5fcf333349e8", "2a448376-a4d2-4efb-95ca-5480339ddffa", "39009176-b326-488c-b6d0-9d5a49c87d6c", "3af3763f-9dea-4af3-a88e-62dccaa2d514", "423d3e48-67d5-4c7f-b64b-f76751733c6f", "7bd18150-02c4-4a9c-80bc-8da0bcf5598f", "8b0d829a-62b4-4bd0-bcc3-0e5ed560f03e", "8b431ea1-2416-43ae-a2f7-ab96858b9827", "a1db2efa-9e44-4160-bc10-4d2daa4c0b7e", "bb5b156d-e0ac-4d4c-9da2-399b74476a64", "c66909a0-005e-411b-9893-dc455f5d073c", "d24d9752-c3d1-4883-81ad-11fa94a36d17"], "title": "Trajectory Tracking Control of Multiconstraint Complementarity Lagrangian Systems", "venue": "IEEE Transactions on Automatic Control", "year": 2010, "id": "877df1e6-a0a1-4502-9461-04ec248ad10e"}
{"abstract": "The mining of changes or differences or other comparative patterns from a pair of datasets is an interesting problem. This paper is focused on the mining of one type of comparative pattern called emerging patterns. Emerging patterns are denoted by EPs and are defined as patterns for which support increases from one dataset to the other with a big ratio. The number of EPs is sometimes huge. To provide a good structure for and to reduce the size of mining results, we use borders to concisely describe large collections of EPs in a lossless way. Such a border consists of only the minimal (under set inclusion) and the maximal EPs in the collection. We also present an algorithm for efficiently computing the borders of some desired EPs by manipulating the input borders only. Our experience with many datasets in the UCI Repository and recent cancer diagnosis datasets demonstrated that: Both the EP pattern type and our algorithm are useful for building accurate classifiers and useful for mining multifactor interactions, for example, minimal gene groups potentially responsible for the development of cancer.", "authors": ["Guozhu Dong", "Jinyan Li"], "n_citation": 141, "references": ["01c6653d-9907-4738-a54f-9b44bbf35043", "080f1756-16ea-49c5-8c66-1b5e0044a507", "08bcceae-cae4-4875-b33f-cbdb11b94387", "0a3db0e1-415d-4481-b8fc-92dab5778294", "20468cc0-395f-4596-830e-7c110922358e", "31ba4f5d-bf85-4095-9a6d-2b95ded0bfcb", "369e1217-6e8b-433a-b919-86a74614a5b7", "46f6963a-2459-4e2c-8667-a8d0fcde43e9", "48463850-faed-4a52-aa93-5d93589aefbb", "4a3e4b9e-0b5b-4666-a6a2-4b5e189d2061", "4f452c65-ca79-43d0-9a00-8616e4924106", "514d2e13-1ec4-4df2-a570-43a89d4be0e8", "62549bc2-e0b3-46e8-8d32-390dded105d5", "65f8bc18-dfba-4ca7-a7b4-568b3cade0f0", "692658b3-b1bc-46b2-a730-7dc8c14d7bd9", "8a6a4907-2e3a-4590-8809-a488df178a3e", "91f98247-ab9a-459c-ac7c-309ee51f62bd", "97f0f520-6175-409f-8a18-6878fa620ed4", "9b94828e-96f0-4870-84a8-5702028d67d0", "ab800736-5ac6-405d-a5c9-e6f64475b98a", "c08adba2-1870-49c3-af30-1696f1752c5e", "c4bbb570-d07f-4186-8339-27306e3b0230", "ccd18d48-1042-4a71-9991-97ed0abb0711", "cf7e0607-5f51-4b91-bf91-60c26afd2703", "d20df5c3-667b-42d4-a128-d5f0b649cc32", "d8f66da3-1fb0-4b7c-8ab5-390c837ff9f2", "e649f2a3-358a-4aa6-a1b7-e46331de17aa", "ecd6a845-8439-49b0-abe8-f71fff81da23"], "title": "Mining border descriptions of emerging patterns from dataset pairs", "venue": "Knowledge and Information Systems", "year": 2005, "id": "60f72d5e-cd9f-44fb-86d1-5e25a6b7486c"}
{"abstract": "Although the INSPIRE Directive provides a roadmap and technical specifications for providing interoperability of spatial information created and held by public bodies across Europe, its relevance to archaeological and built heritage information is unclear. Whilst there is a clear need for access to information about the historic environment by a range of audiences actively engaged in the management of Europe\u2019s rich heritage, delivery of relevant services is restricted to a narrow interpretation of the Annex I Protected Sites theme that focuses on statutory designations. This paper explores business reasons for adopting a more expansive interpretation of what information should be considered as and distributed as part of the Protected Sites theme in order to support policies and activities that impact upon the wider historic environment. The paper also considers the range and potential of information created through investigation and recording of the historic environment, often at public expense or interest. The potential for data reuse generating savings, inspiring smarter working practices, and developing sustainable datasets is explored through case studies from Scotland and Ireland and proposals to establish a thematic geo-portal, web services and applications through the EU Culture funded project ArchaeoLandscapes Europe (ArcLand), are discussed.", "authors": ["Peter McKeague", "Anthony Corns", "Robert Shaw"], "n_citation": 5, "references": [], "title": "Developing a Spatial Data Infrastructure for Archaeological and Built Heritage", "venue": "", "year": 2011, "id": "81e6e6fc-54be-4d2e-8f41-448ddf80184d"}
{"abstract": "Hierarchical decompositions of graphs are interesting for algorithmic purposes. Many NP complete problems have linear complexity on graphs with tree-decompositions of bounded width. We investigate alternate hierarchical decompositions that apply to wider classes of graphs and still enjoy good algorithmic properties. These decompositions are motivated and inspired by the study of vertex-replacement context-free graph grammars. The complexity measure of graphs associated with these decompositions is called clique width. In this paper we bound the clique width of a graph in terms of its tree width on the one hand, and of the clique width of its edge complement on the other. ? 2000 Elsevier Science B.V. All rights reserved.", "authors": ["Bruno Courcelle", "Stephan Olariu"], "n_citation": 508, "references": ["212cae03-ae9b-4e4b-9e18-68cc0d9c70dc", "22fe1167-51e1-4a8d-9017-44243517020b", "3cd9886d-99c3-4e16-b10f-bad99b8eb8c7", "61d25f25-8c2b-431d-95bc-4462422482fc", "65947faa-cadd-405e-94b3-e872ff771a89", "7db57b80-94c2-4aed-b7da-87338b0b7966", "8b408f24-dc00-404f-a7da-8594365826f4", "982e44e9-165b-4c0e-b56b-a0f1462ae77f", "9b7987bf-0723-4e11-866b-965c42559785", "a6ca3a71-d011-42fc-8af0-9af8aabffa62", "b4a4cbc9-a0c8-4da4-80e8-186e96e29250", "b6d4a522-0559-4f20-807f-b21ff3273edf", "b9a80c52-0a57-4760-9d39-28a6cf0ac636", "c454bdc9-60ad-4127-84fe-abbb45ba3a76", "f5083763-d120-436b-8062-7f7441128b15", "f8bf0168-d990-4172-bc96-a4993d44a8a2"], "title": "Upper bounds to the clique width of graphs", "venue": "Discrete Applied Mathematics", "year": 2000, "id": "39d548a6-8b20-42ef-8d37-c1894ff2cb97"}
{"abstract": "Algorithmic information theory studies description complexity and randomness and is now a well known field of theoretical computer science and mathematical logic. There are several textbooks and monographs devoted to this theory where one can find the detailed exposition of many difficult results as well as historical references. However, it seems that a short survey of its basic notions and main results relating these notions to each other, is missing. #R##N#This report attempts to fill this gap and covers the basic notions of algorithmic information theory: Kolmogorov complexity (plain, conditional, prefix), Solomonoff universal a priori probability, notions of randomness (Martin-L\\\"of randomness, Mises--Church randomness), effective Hausdorff dimension. We prove their basic properties (symmetry of information, connection between a priori probability and prefix complexity, criterion of randomness in terms of complexity, complexity characterization for effective dimension) and show some applications (incompressibility method in computational complexity theory, incompleteness theorems). It is based on the lecture notes of a course at Uppsala University given by the author.", "authors": ["Alexander Shen"], "n_citation": 10, "references": [], "title": "Around Kolmogorov Complexity: Basic Notions and Results", "venue": "arXiv: Information Theory", "year": 2015, "id": "6b7d6702-b398-4f18-9350-09f574018164"}
{"abstract": "The general principles for formulating software requirements and designs that meet response-time goals are reviewed. The principles are related to the system performance parameters that they improve, and thus their application may not be obvious to those whose speciality is system architecture and design. The author addresses the designer's perspective and illustrates how these principles apply to typical design problems. The examples illustrate requirements and design of: communication, user interfaces, information storage, retrieval and update, information hiding, and data availability. Strategies for effective use of the principles are described. >", "authors": ["Connie U. Smith"], "n_citation": 50, "references": ["0dac7ec5-d3c1-48b1-bb9d-95c861ed4342", "1b64964e-7aa5-45b1-998c-c75d7917bfaf", "3f556de2-f915-4668-9cf6-3075d8bca8c4", "46c1dc1f-528b-497a-ac3c-bc0461cb37fb", "473ba658-ac30-495c-91a2-5e87934536df", "565d0df4-57e9-4ac2-99b5-8c30abf76bcb", "6fd6c659-55be-47e4-8ccd-667336a30e6b", "961b5d93-afd5-4477-bc5e-8d50082d5327", "9b94e12d-001d-4365-b8fa-500c90327faf", "ad11daec-2293-46ec-b718-85d40b57e9cc", "af481f6f-28ed-450b-97ab-90053e681184", "c760cf6a-8102-4d7f-95b1-65fb457f5596", "cd994992-5676-4840-873d-7f1de7b46195", "d2db0fc6-eee1-431c-a931-8aefa614a9ec", "da01551e-4b14-4b1d-9a54-439acd5ef1f7", "e832bc8d-eaf6-4812-852d-afc280ee7e9a", "fa004d57-1cb7-43da-9939-910d8a053c6c", "fe90a304-9ffb-4152-a6df-b4b3c2671337"], "title": "Applying synthesis principles to create responsive software systems", "venue": "IEEE Transactions on Software Engineering", "year": 1988, "id": "71394d85-f392-42e2-b223-a0f20e8b0406"}
{"abstract": "DNA fragment assembly is an area which makes intensive use of computers. However, computer users in this field are typically not experts in computer science, but build their working environment on an ad-hoc basis. In this situation, it seems appropriate to offer a kind of support which can contribute to a better organization of working environments, and a better exploitation of computer hardware and software. The authors describe an approach in this direction based on the emerging paradigms of workflow modeling and management. In particular they offer three contributions: first, they discuss why workflow management can be fruitfully adopted in DNA fragment assembly, and describe one way to perceive and model sequencing processes as workflows. Second, they outline an architecture of a system intended to support sequencing applications, whose core component is a workflow management system. Finally, they sketch their experience of building a prototype using commercial workflow management technology.", "authors": ["Jo\u00e3o Meidanis", "Gottfried Vossen", "Mathias Weske"], "n_citation": 50, "references": ["09216221-324c-4158-a523-a55d49a17de6", "2a5416f3-cb99-4bc9-a45c-9325bff1481a", "2b6f4958-752b-45bb-ae52-3ab1b56c0dea", "58ccf255-97b9-408f-bd20-51c356142803", "64472c04-d171-4b64-aef2-b21e9078d287", "93c58081-09b5-4549-9c44-d95a75495523", "9b621f86-8ac8-4932-a303-f467e0fb128b", "a11ce7f1-f247-42a0-bcec-803ff42407a4", "b295e29e-09fa-4e81-b415-8341f74e68f1"], "title": "Using workflow management in DNA sequencing", "venue": "cooperative information systems", "year": 1996, "id": "0cdef885-83f8-423d-b84e-89717ba9d60d"}
{"abstract": "Most software development approaches and curricular guidelines seem to ignore the fact that in many software systems the user interface is a decisive factor for product quality. As a result, it is often designed rather independently of the system\u2019s functionality. Chances are then that it does not get the attention it deserves. In the approach to software development we sketch, the design of the user interface and the design of the functionality go hand in hand. We give a number of examples of user interface problems, and illustrate how these can be caught early if a more integrated approach is taken. We conclude with an outline of a minimal course on humancomputer interaction that we feel should be part of everyone\u2019s software engineering or computer science curriculum.", "authors": ["Gerrit C. van der Veer", "Hans van Vliet"], "n_citation": 15, "references": ["18ef1bc3-e72e-48f4-b2a1-dea684412c39", "33462e3e-49f7-451b-9713-8aff8607a86b", "af3dfc6f-6cab-44fd-9b1e-cf7528d891a1", "d22afdcc-ee76-4c82-881c-d774a623af9f", "d97f0ada-871e-4631-838c-83408a25679a", "dee73ccd-efd0-417d-918e-45f57103e46f", "f31f4111-55a4-4970-ba2c-db5f2b21d830"], "title": "A Plea for a Poor Man\u2019s HCI Component in Software Engineering and Computer Science Curricula; After all: The Human-Computer Interface is the System", "venue": "Computer Science Education", "year": 2003, "id": "c3e89f1d-653b-426d-b86f-c769e7347a1b"}
{"abstract": "Memory models are hard to reason about due to their complexity, which stems from the need to strike a balance between ease-of-programming and allowing compiler and hardware optimizations. In this paper, we present an automated tool, MemSAT, that helps in debugging and reasoning about memory models. Given an axiomatic specification of a memory model and a multi-threaded test program containing assertions, MemSAT outputs a trace of the program in which both the assertions and the memory model axioms are satisfied, if one can be found. The tool is fully automatic and is based on a SAT solver. If it cannot find a trace, it outputs a minimal subset of the memory model and program constraints that are unsatisfiable. We used MemSAT to check several existing memory models against their published test cases, including the current Java Memory Model by Manson et al. and a revised version of it by Sevcik and Aspinall. We found subtle discrepancies between what was expected and the actual results of test programs.", "authors": ["Emina Torlak", "Mandana Vaziri", "Julian Dolby"], "n_citation": 75, "references": ["22adafd4-9a2c-457f-95f7-caff6b128931", "3eaa8683-b6fe-4e2f-97b9-59e59b20e11e", "497316aa-1c70-4d6d-95b9-2a48af102663", "4d4ebe56-acba-49f8-aaa6-14ece5133c9f", "4ee368dd-be28-45d8-9650-35d73c467490", "5578b39f-84c0-4bbb-a4c8-c0ae30ab0deb", "558549b0-a893-4814-ae65-25ef111cbbc1", "5f7d6c88-c561-43b2-bcf1-95dc5d78cd80", "7f1dc63a-9064-4768-a30d-3383d52aa81e", "801f0553-588b-436e-9db6-a3dabd4dc279", "81338ff8-cfee-45c7-a8a2-038e2187fd00", "87eebd53-ce52-42fd-81c2-80b70bc318e4", "b54b0d6e-3879-4d5a-a4aa-bcc06626bf63", "c8573c5a-fdef-4713-8d67-aa327a144aa4", "cc7ca161-0410-4048-aad2-90703f5f6f82", "d0729d4a-ece0-4ecd-a39b-386eeb348654", "d98be66a-a722-4dd0-b117-7ce8c8fc9755", "dc2ac4d7-e7e5-4590-9937-e05daf9f80c1", "e32a4298-a50d-4813-86ce-656f35ff563c", "f90d8687-c6c7-4a90-8cf1-9ddf9ecf07c8", "f99f88b3-6cf8-48eb-b153-1e9b4b509199"], "title": "MemSAT: checking axiomatic specifications of memory models", "venue": "programming language design and implementation", "year": 2010, "id": "0a3112d2-c4c0-4b20-a33a-6bf56a09b506"}
{"abstract": "Localizing bugs is important, difficult, and expensive, especially for large software projects. To address this problem, information retrieval (IR) based bug localization has increasingly been used to suggest potential buggy files given a bug report. To date, researchers have proposed a number of IR techniques for bug localization and empirically evaluated them to understand their effectiveness. However, virtually all of the evaluations have been limited to the projects written in object-oriented programming languages, particularly Java. Therefore, the effectiveness of these techniques for other widely used languages such as C is still unknown. In this paper, we create a benchmark dataset consisting of more than 7,500 bug reports from five popular C projects and rigorously evaluate our recently introduced IR-based bug localization tool using this dataset. Our results indicate that although the IR-relevant properties of C and Java programs are different, IR-based bug localization in C software at the file level is overall as effective as in Java software. However, we also find that the recent advance of using program structure information in performing bug localization gives less of a benefit for C software than for Java software.", "authors": ["Ripon K. Saha", "Julia L. Lawall", "Sarfraz Khurshid", "Dewayne E. Perry"], "n_citation": 12, "references": ["078ad4b4-be30-4505-abb6-90945d2dda0c", "11303422-8d30-47e7-9657-ba8221875879", "1338131c-3973-41c7-bd07-38fd394d4709", "2b89fa83-9486-4f1a-963a-303b2e1abdda", "30d4f0ad-89c2-4c3e-8330-295a5cc80502", "3d80a35d-8a61-4cd3-a47f-a3ca626d368f", "46925b7f-d9a9-400a-a88d-7aa45706c725", "47c2c88f-17b8-4fda-83ba-f54382a7a3c4", "5a6b66a9-32ff-4a39-b99b-9fc296662ce2", "68453f24-4276-4d0c-b37e-19d23af549be", "6aec772b-ed45-4adc-b53f-c3dba2be760e", "7116b4d8-88ee-45bc-8120-da082d122a19", "9565c56f-ef1e-46fd-b8e0-91db8dd085d5", "a62ef6c8-be1a-4fc7-9cf4-c263ae104e1b", "ade81b32-b31b-4560-8324-07fe2be322f2", "b2f01741-c04b-4b30-ae6c-5aa3c995eee9", "df06e862-71cb-4db4-848e-436cc808d6e6", "f4b437b8-fff2-4419-95f6-ff73b2fd72a5"], "title": "On the Effectiveness of Information Retrieval Based Bug Localization for C Programs", "venue": "international conference on software maintenance", "year": 2014, "id": "2d9418ae-e77b-481c-8b2f-f03015ca7e9b"}
{"abstract": "In the autonomous environment of Vehicular Ad hoc NETwork (VANET), vehicles randomly move with high speed and rely on each other for successful data transmission process. The routing can be difficult or impossible to predict in such intermittent vehicles connectivity and highly dynamic topology. The existing routing solutions do not consider the knowledge that behaviour patterns exist in real-time urban vehicular networks. In this article, we propose a fuzzy-assisted social-based routing (FAST) protocol that takes the advantage of social behaviour of humans on the road to make optimal and secure routing decisions. FAST uses prior global knowledge of real-time vehicular traffic for packet routing from the source to the destination. In FAST, fuzzy inference system leverages friendship mechanism to make critical decisions at intersections which is based on prior global knowledge of real-time vehicular traffic information. The simulation results in urban vehicular environment for with and without obstacles scenario show that the FAST performs best in terms of packet delivery ratio with upto 32% increase, average delay 80% decrease, and hops count 50% decrease compared to the state of the art VANET routing solutions.", "authors": ["Rashid Hafeez Khokhar", "Rafidah Md Noor", "Kayhan Zrar Ghafoor", "Chih Heng Ke", "Asri Ngadi"], "n_citation": 50, "references": ["124c80c9-a75c-472b-b7b1-22949b54d895", "1545dfd3-2c25-4ff1-b43c-df4a2a501d06", "196d536b-812a-4a6c-ba46-e590b3d1ec1f", "2e50b6bd-f0f7-4839-a8b9-8f8874dee9a4", "4718a4d4-c53c-4986-b02a-2f824b5a2952", "5ff6c18d-d281-4618-b91e-8baa6b74e993", "80a5f0a6-d0d4-4d13-82f5-8d0452919e52", "89ffbf0e-0e89-4387-b120-4be1e93d1046", "994ba35c-08cd-4d00-abdb-0d136dd6ba44", "b1cce46a-b9cc-4bec-8eaa-beb8f0dc0586", "c0c6fb1b-1638-440f-9024-0755197a99bf", "c29606a5-7b4f-4ff8-b858-e66a53d368ad", "cbe09b55-c776-4ef9-94f4-c7cf073a3c89", "dbffe315-dfec-4972-9e27-3fdeb01e551a", "ec60e2db-2bdb-47b4-bf1a-643564edc715", "edd3aa8e-3408-4298-a67d-3ef6c6b30691", "ef034f54-e347-465d-963a-2e87538cf5e3"], "title": "Fuzzy-assisted social-based routing for urban vehicular environments", "venue": "Eurasip Journal on Wireless Communications and Networking", "year": 2011, "id": "8e1e8191-89c0-4177-9c5e-2f6192b22834"}
{"abstract": "Pustejovsky, J. and B. Boguraev, Lexical knowledge representation and natural language processing, Artificial Intelligence 63 (1993) 193-223. Traditionally, semantic information in computational lexicons is limited to notions such as selectional restrictions or domain-specific constraints, encoded in a \"static\" representation. This information is typically used in natural language processing by a simple knowledge manipulation mechanism limited to the ability to match valences of structurally related words. The most advanced device for imposing structure on lexical information is that of inheritance, both at the object (lexical items) and meta (lexical concepts) levels of lexicon. In this paper we argue that this is an impoverished view of a computational lexicon and that, for all its advantages, simple inheritance lacks the descriptive power necessary for characterizing fine-grained distinctions in the lexical semantics of words. We describe a theory of lexical semantics making use of a knowledge representation framework that offers a richer, more expressive vocabulary for lexical information. In particular, by performing specialized inference over the ways in which aspects of knowledge structures of words in context can be composed, mutually compatible and contextually relevant lexical components of words and phrases are highlighted. We discuss the relevance of this view of the lexicon, as an explanatory device accounting for language creativity, as well as a mechanism underlying the implementation of open-ended natural language processing systems. In particular, we demonstrate how lexical ambiguity resolution--now an integral part of the same procedure that creates the semantic interpretation of a sentence itself--becomes a process not of selecting from a pre-determined set of senses, but of highlighting certain lexical properties brought forth by, and relevant to, the current context.", "authors": ["James Pustejovsky", "Branimir Boguraev"], "n_citation": 212, "references": ["025b14d5-3d6e-464f-ba1f-8011da2d485b", "0891366f-f734-4295-b47c-bf80fbc66d06", "1092fbf0-6c20-4fef-9c7c-b4aafd061eb6", "10af6a12-8aa1-49b3-b2bd-9686235ac01e", "27938e31-9030-4342-b38c-40a1887f7291", "563837e5-eb7f-49dd-b8d3-c19bfacaa6cd", "581acdca-14f5-4dc7-965b-abdb0a805ceb", "64396b43-4219-48d3-8096-241a8379d5b6", "7c59931e-f1e7-4ca4-8262-1303b45e7c97", "8c1262d4-a568-4399-96da-b1cb3d7c4d7e", "a8b7656b-7f37-435d-9530-2915678463b0", "aff0bb11-5e14-4969-8d55-07d2bb3cb685", "bcb8800d-9dc5-4d3b-988c-10fe73eabd73", "d55b22d6-2cf2-48c2-ba9c-ae3cf440c3ad", "daa49e5d-3e5c-41a6-b6c1-59f0f438e336", "dbe5ae2e-bbc0-4508-8df5-3ec95c784fa8", "e7e5e58e-4821-44c8-96f3-74018ac7d0cb", "ee50c31c-e986-457b-a883-0c448339312b"], "title": "Lexical knowledge representation and natural language processing", "venue": "Artificial Intelligence", "year": 1993, "id": "2a856da1-00e5-4d8a-8ff7-a6d2b24c2c67"}
{"abstract": "Contemporary dance\u2014movement deliberately and systematically cultivated for its own sake\u2014is examined in the light of the procedural and declarative view of long-term knowledge. We begin with a description of two settings in which new works of contemporary dance are created and performed. Although non-verbal, contemporary dance can be a language declared through movement and stillness of the body. Ideas for new movement material come from objects, events or imaginings that are spoken, seen, heard, imagined, or felt. Declared through movement, the idea becomes visible. Communication in dance involves general psychological processes such as direct visual perception of motion and force, motor simulation via mirror neurons, and implicit learning of movement vocabularies and grammars. Creating and performing dance appear to involve both procedural and declarative knowledge. The latter includes the role of episodic memory in performance and occasional labelling of movement phrases and sections in rehearsal. Procedural knowledge in dance is augmented by expressive nuance, feeling and communicative intent that is not characteristic of other movement-based procedural tasks. Having delineated lexical and grammatical components in dance, neural mechanisms are identified based on Ullman\u2019s (Ullman in Cognition 92:231\u2013270, 2004) alignment of lexical knowledge with declarative memory and mental grammar with procedural memory. We conclude with suggestions for experiments to test these assumptions that concern thought in action in composition, performance and appreciation of contemporary dance.", "authors": ["Catherine J. Stevens", "Shirley McKechnie"], "n_citation": 88, "references": [], "title": "Thinking in action : thought made visible in contemporary dance", "venue": "Cognitive Processing", "year": 2005, "id": "db94f7ff-43c8-4b07-8df1-058c0eb66490"}
{"abstract": "Abstract#R##N##R##N#In this paper, we consider the Capacitated Arc Routing Problem (CARP), in which a fleet of vehicles, based on a specified vertex (the depot) and with a known capacity Q, must service a subset of the edges of a graph, with minimum total cost and such that the load assigned to each vehicle does not exceed its capacity. New lower bounds are developed for this problem, producing at least as good results as the already existing ones. Three of the proposed lower bounds are obtained from the resolution of a minimum cost perfect matching problem. The fourth one takes into account the vehicle capacity and is computed using a dynamic programming algorithm. Computational results, in which these bounds are compared on a set of test problems, are included.", "authors": ["Enrique Benavent", "Vicente Campos", "\u00c1ngel Corber\u00e1n", "Enrique Mota"], "n_citation": 151, "references": ["27a89ec5-c553-47fa-b019-c963cff8b751", "54bd2abd-f73b-41a5-9e9d-d87fc7b27bdd", "8b085b1c-14c7-481b-bd65-ac1492f307a0", "925cfcc5-8424-481b-9eeb-ee29f7e81ad0", "ab244bc4-1552-47be-9642-e0fbe22fa215", "b81f5134-cb92-428f-bc54-9d7fa39ff81f", "c2b6ae07-a8a8-4b58-b661-abb1d069421d", "d6b1513a-cae0-4b1a-9759-5288020e9744", "e3dd1514-8e65-4535-8ac2-99cca9d941f1"], "title": "The Capacitated Arc Routing Problem: Lower bounds", "venue": "Networks", "year": 1992, "id": "8e4fdbd6-83c7-44f6-856f-b26e296f34a6"}
{"abstract": "Recent research has shown that developers spend significant amounts of time navigating around code. Much of this time is spent on redundant navigations to code that the developer previously found. This is necessary today because existing development environments do not enable users to easily collect relevant information, such as web pages, textual notes, and code fragments. JASPER is a new system that allows users to collect relevant artifacts into a working set for easy reference. These artifacts are visible in a single view that represents the user's current task and allows users to easily make each artifact visible within its context. We predict that JASPER will significantly reduce time spent on redundant navigations. In addition, JASPER will facilitate multitasking, interruption management, and sharing task information with other developers.", "authors": ["Michael J. Coblenz", "Andrew J. Ko", "Brad A. Myers"], "n_citation": 50, "references": ["0d4a7a2b-a065-4757-aa1a-1af8d4015000", "4df004e1-b013-4da9-8157-0999add3a12b", "51b67cd3-9a64-4bf7-b16b-594a7e0af993", "5c1825a2-fde0-4f16-8072-0e4e45aa5f75", "972a762e-4c18-4dc3-8a74-0e9506be26c4", "a806bf78-4d4c-49a3-8425-666da3b08b73", "b9ebb475-e62b-4262-9fbf-a7e51a81d684", "badb3f72-38f0-4f89-81d5-0f5ca2c956bb", "bc3eee18-dec3-47c8-8908-d9dc1e1197ee", "c16b77fa-89d4-4926-bef6-6a849d370101"], "title": "JASPER: an Eclipse plug-in to facilitate software maintenance tasks", "venue": "eclipse technology exchange", "year": 2006, "id": "12c5c39d-2436-48c0-b450-6b80e5d73482"}
{"abstract": "Recently, an image scrambling encryption algorithm of pixel bit based on chaos map was proposed. Considering the algorithm as a typical binary image scrambling/permutation algorithm exerting on plaintext of size Mx(8N), this paper proposes a novel optimal method to break it with some known/chosen-plaintexts. The spatial complexity and computational complexity of the attack are only O(32.MN) and O(16.n\"0.MN) respectively, where n\"0 is the number of known/chosen-plaintexts used. The method can be easily extended to break any permutation-only encryption scheme exerting on plaintext of size MxN and with L different levels of values. The corresponding spatial complexity and computational complexity are only O(MN) and O(@?log\"L(MN)@?.MN) respectively. In addition, some specific remarks on the performance of the image scrambling encryption algorithm are presented.", "authors": ["Chengqing Li", "Kwok-Tung Lo"], "n_citation": 121, "references": ["058d618c-c1ea-45ed-b1dd-d12f2341e95f", "1ce1de40-dd04-4d59-87fd-eaf7645e7c0c", "1fe443b6-2510-445d-afb8-95b0583f8b92", "21a2e3b9-dea1-4559-b75a-98d2eca8ec0f", "25b85e9b-5190-4063-9567-a2e45dd7c8f4", "2a6daf41-8b4a-4684-927c-215d89baf911", "2e3bb369-6943-445a-8d0a-46bfa7a03c0a", "326fdaa2-dd45-40c2-8d62-9d2eae91b7af", "33bd0c02-621c-485c-9e87-a2f6770f1026", "55f5dcb2-8e78-42aa-830c-004a7759ada6", "6fb58cd2-791d-4fb5-98b6-9f03d2a6a71b", "7647ce2c-092b-403e-b0dd-bbef9abed2b8", "7ed85b3d-1ac7-4a9e-9b31-db3a90515055", "8386f77c-0ea0-4745-9654-101fa60306e8", "865b4c75-275d-4b7f-80a4-819e00da07ce", "8c9c5c59-7a1c-4cab-8b63-aceb79e331cf", "a6d958a7-d798-4ce0-92d6-1ac29e049f90", "aaac030a-7bbf-46bd-88d4-1350047f5ac0", "ac3a97bd-e24f-456d-ab73-7b307bfd07cc", "ad12b46f-7468-491b-8154-4dee2937b683", "b68fc787-7817-421e-8e66-8a98ab9db1ad", "bc9f8a4a-884f-4895-af95-658adb1132dd", "c8135055-4f8b-4862-9a44-6db2e217962c", "da172b35-779f-4cbf-b4c5-bf171ab27d56", "dd38f03f-0528-47fc-9cb2-16b0543c3c4e", "e90f4d06-4b7c-4c3e-9752-db8076c6fa21"], "title": "Optimal quantitative cryptanalysis of permutation-only multimedia ciphers against plaintext attacks", "venue": "Signal Processing", "year": 2011, "id": "576f0e48-3938-498d-8ade-869ddf5c2438"}
{"authors": ["Christine Ernoult", "Alan Mycroft"], "n_citation": 50, "references": ["691896fa-37a8-42de-85d1-54ff1caeff51", "724e7867-f575-4c40-b747-74697552b65c", "74024e51-dd77-4386-84b0-1dcbb298c024", "9e75cb6e-a1b8-447e-9c4c-b7d12d13e83c", "c3f19c08-bcb9-4843-ab0e-9c1c2e25f2fc"], "title": "Uniform ideals and strictness analysis", "venue": "international colloquium on automata, languages and programming", "year": 1991, "id": "ab966854-128f-4fb4-930b-63f03b40e3c5"}
{"authors": ["Ran Canetti", "Cynthia Dwork", "Moni Naor", "Rafail Ostrovsky"], "n_citation": 329, "references": ["117f61a6-59c7-45c1-b7b9-c23affbd823d", "7857fbf2-a419-4844-bdb8-6b1ce39a24fc", "d4a36a45-7e5f-48e2-8c58-0ac23b37a8dc", "d8dc0d21-c4d7-4408-9417-f300a7aeb4a7"], "title": "Deniable Encryption", "venue": "international cryptology conference", "year": 1997, "id": "c2f9a328-ef6e-43c4-a4d2-e27e6c870628"}
{"abstract": "Pervasive service ecosystems are a new paradigm for the design of context-aware systems featuring adaptivity and self-awareness. A theoretical and practical framework has been proposed for addressing these scenarios, taking primary inspirations from natural ecosystems and grounding upon two basic abstractions: \"live semantic annotations\" (LSAs), which are descriptions stored in infrastructure nodes and wrapping data, knowledge, and activities of humans, devices, and services; and \"eco-laws\", acting as system rules evolving the population of LSAs as if they were molecules subject to chemical-like reactions. In this paper, we aim at deepening how self-organisation can be injected in pervasive service ecosystems in terms of spatial structures and algorithms for supporting the design of context-aware applications. To this end, we start from an existing classification of self-organisation patterns, and systematically show how they can be supported in pervasive service ecosystems, and be composed to generate a self-organising emergent behaviour. A paradigmatic crowd steering case study is used to demonstrate the effectiveness of our approach.", "authors": ["Sara Montagna", "Mirko Viroli", "Jose Luis Fernandez-Marquez", "Giovanna Di Marzo Serugendo", "Franco Zambonelli"], "n_citation": 32, "references": ["05ebcfb0-423d-4c78-b6c5-eb0c68b51104", "0aced747-ef94-4b75-8edc-a55c804f182f", "131e6813-210a-444d-964d-d5b0a6401fe5", "16bc6bb0-748a-4272-ae22-32b5b1538321", "261444db-c84f-4275-92ed-b1c868ea499d", "2b7a9dfd-9708-4207-b200-9eec56971ec6", "4665fdbe-584a-4224-ab44-28aaea9c6b7f", "4ab80542-26ba-4a15-8daa-cdb450c14c3a", "4f9aa43c-6fe4-4e20-bc32-d513fb3f1206", "621d1071-8350-4386-b1e8-519c4dfa8c5d", "68e0f48f-6804-49da-ab57-288875a13105", "6b57de32-7320-4479-aa56-b0ec5e7f2227", "72232409-509b-4012-9cbf-afbe88126887", "7820a48c-c87a-44f5-91e6-58b42f19df03", "8520af38-9b72-4a5d-a21e-a68ff20d453d", "8724aad8-f99b-4eb7-ab7b-ca5439715f55", "8aa76695-da9f-46f3-8184-69190dc4372d", "a09e9438-f3d4-4b6c-8c42-252a8808b068", "a1b2cea2-7ea5-47d6-ba50-fa885b450a9c", "b43ce0b6-7002-426e-b1cc-ca36ea0d980c", "b58d1614-c671-4740-892a-344ae8cd95ce", "b621c475-7a8c-48bd-a7ee-c2489bf65918", "c0d58086-ce47-4ece-948f-bd4ca3b9abe7", "c422066c-4a63-420a-ada0-bd563a3144b7", "c5b1dce8-138e-47e2-99ea-c3db250c6a53", "ce57dee5-e012-4fc4-8b2c-9afe6dd08387", "da8b9bb5-d76e-40aa-a080-d1e9ac7b2ab1", "da8bd5ce-5c87-41cd-b446-3efad14aa6ca", "f706bef5-5020-4cb8-a63c-f7f277fa1570"], "title": "Injecting Self-Organisation into Pervasive Service Ecosystems", "venue": "Mobile Networks and Applications", "year": 2013, "id": "0e5cd384-d348-48fb-8932-2d8d07fc04b3"}
{"abstract": "Three types of floating-point arithmetics with error control are discussed and compared with conventional floating-point arithmetic. General multiplication and division shift criteria are derived (for any base) for Metropolis-type arithmetics. The limitations and most suitable range of application for each arithmetic are discussed.", "authors": ["W. G. Wadey"], "n_citation": 50, "references": ["b6315efe-a8f0-4c78-8a97-848379d2e047", "e46f17d8-7228-4cf5-90b1-4dba72544536"], "title": "Floating-Point Arithmetics", "venue": "Journal of the ACM", "year": 1960, "id": "84d49e9e-67f9-430f-958c-a5f14cd8ebc3"}
{"abstract": "People as news subjects carry rich semantics in broadcast news video and therefore finding a named person in the video is a major challenge for video retrieval. This task can be achieved by exploiting the multi-modal information in videos, including transcript, video structure, and visual features. We propose a comprehensive approach for finding specific persons in broadcast news videos by exploring various clues such as names occurred in the transcript, face information, anchor scenes, and most importantly, the timing pattern between names and people. Experiments on the TRECVID 2003 dataset show that our approach achieves high performance.", "authors": ["Jun Yang", "Ming-yu Chen", "Alexander G. Hauptmann"], "n_citation": 91, "references": ["0b4c0d6f-58fd-4704-98af-8c12de196ede", "11f7b6c4-2d32-460e-8ab9-dcae83e7ca6a", "53febd2f-cda9-43d5-a576-a2c3367883ad", "750b0ac1-2ac9-4273-a9c8-baad11e26fcd", "88aac5cb-119b-4c92-8271-d94d51e18b90", "e75d8e62-a86d-4241-953f-1b315005d920", "ed8a9624-3abe-4b5e-bffe-5b3ecc34e841"], "title": "Finding Person X: Correlating Names with Visual Appearances", "venue": "conference on image and video retrieval", "year": 2004, "id": "d3a5c78f-d0df-44b4-b2c6-f97bd3efb833"}
{"abstract": "Distance measurements are not the only geometric quantities that can be used for multi-agent formation shape control. Bearing measurements can be used in conjunction with distances. This article employs bearing rigidity for mobile formations, which was developed for robot and sensor network localisation, so that bearings can be used for shape control in mobile formations. The first part of this article examines graph theoretical models for formation network analysis and control law design that are needed to maintain the shape of a formation in two-dimensional space, while the formation moves as a cohesive whole. Bearing-based shape control for a formation of mobile agents involves the design of distributed control laws that ensure the formation moves, so that bearing constraints maintain some desired values. The second part of this article focuses on the design of a distributed control scheme for nonholonomic agents to solve the bearing-based formation shape control problem. In particular, a control law u...", "authors": ["Tolga Eren"], "n_citation": 55, "references": ["05dc7361-18e9-42d3-8948-f49f7017a3ef", "0ef2ab05-42c0-44a0-9549-ea210a552da4", "2b01c3f5-2970-4ec5-9af1-e05009691da5", "2c08c1a6-7909-47e0-8df2-88736068c6ad", "32f84086-f7ca-40c9-aeb9-f87be84fced9", "5acd9a3d-2c05-4cff-b26a-6e1d99aac239", "6394ff2e-3134-431d-9486-1569aa97d227", "6d879a38-fbf7-4c58-be4f-60e87a7efff7", "83c77265-778a-4387-8e7d-c25f8107f831", "85dabc9d-d167-40f5-aa3c-d88fb2db8df5", "8e8844d7-8e19-4565-81d5-1e99cb1cc9e6", "8ef81d20-5af0-49cb-9c42-859fb73e5e11", "978b9d05-f2d0-4908-9059-e3a730b7e396", "9d5da337-846a-40b6-8198-483f74265edb", "aeabc622-720d-44d0-888c-787e7d377f54", "afe289b3-e88c-4f1a-8632-0262bb475a15", "b30ef2cc-8283-402e-a054-6b5ffa4a6af9", "cb4d0f94-bb97-4fed-bd86-9f41f4d7429c", "e70ac212-5fc5-46a9-8c79-75fffca9be75", "fae27def-6db6-4ae0-9842-5cbabcf87790"], "title": "Formation shape control based on bearing rigidity", "venue": "International Journal of Control", "year": 2012, "id": "1ee9f295-cdf7-4b75-b5ab-3279994eda59"}
{"abstract": "The performance of off-line text-independent writer verification and identification increases when the documents contain more text. This relation was examined by repeatedly conducting writer verification and identification performance tests while gradually increasing the amount of text on the pages. The experiment was performed on the datasets Firemaker and IAM using four different features. It was also determined what the influence of an unequal amount of text in the documents is. For the best features, it appears that the minimum amount of needed text is about 100 characters.", "authors": ["Axel Brink", "Marius Bulacu", "Lambert Schomaker"], "n_citation": 51, "references": ["547df77d-7a4c-4bda-a0e3-45902af1db5b", "55b5741c-84aa-48c7-9956-21b03da16a6a", "560d147e-c6b2-4219-812b-54f0d44f395d", "a6f22c1b-8c55-4245-89dd-13eb51f8a0cd", "bcfb6de0-38b0-4202-b0d4-b49792ad1553", "fac8d70d-9925-4d8f-9d8c-4246c02de009"], "title": "How much handwritten text is needed for text-independent writer verification and identification", "venue": "international conference on pattern recognition", "year": 2008, "id": "a6865d0a-27a1-450d-b69d-c6109a6d8be1"}
{"abstract": "This paper discusses basic notions underlying fuzzy sets, especially gradualness, uncertainty, vagueness and bipolarity, in order to clarify the significance of using fuzzy sets in practice. Starting with the idea that a fuzzy set may represent either a precise gradual composite entity or an epistemic construction refereeing to an ill-known object, it is shown that each of this view suggests a different use of fuzzy sets. Then, it is argued that the usual phrase fuzzy number is ambiguous as it induces some confusion between gradual extensions of real numbers and gradual extensions of interval calculations. The distinction between degrees of truth that are compositional and degrees of belief that cannot be so is recalled. The truth-functional calculi of various extensions of fuzzy sets, motivated by the desire to handle ill-known membership grades, are shown to be of limited significance for handling this kind of uncertainty. Finally, the idea of a separate handling of membership and non-membership grades put forward by Atanassov is cast in the setting of reasoning about bipolar information. This intuition is different from the representation of ill-known membership functions and leads to combination rules differing from the ones proposed for handling uncertainty about membership grades.", "authors": ["Didier Dubois", "Henri Prade"], "n_citation": 240, "references": ["03693fa8-9e5f-43e5-b47d-7ba8c88809be", "0c10e810-f879-4ade-a528-d59d14b4cd7d", "0c55a1e2-5317-4834-b203-45e3febb29c6", "1abe307d-c89e-41f1-bc30-afc357ef4e73", "26153c60-a196-4885-96c1-58066e81e817", "312cacdc-2e2d-44a2-a5f0-61ea2dc34d34", "3839ee2f-93b7-43c9-bb4e-defd03fb0335", "3ac3eb34-c279-40bc-8543-40251f352a3f", "3c4206ca-fd9b-4f3d-af6d-e3b672908d4b", "402136a0-f632-41f1-9e9c-a2f724d47497", "4037b300-4ec9-4599-9d9f-fe95203c7dee", "490a8313-c5a8-4fff-8842-4a81e56df83d", "4bf3b810-f960-4ff5-a675-8078ef11c722", "4c5b77bc-c7b3-4f92-8686-2c9b514e383c", "4d469937-0090-48bc-84c9-874571bc1afc", "50939591-2b73-4335-ac04-3797f890b63c", "5115cbbb-012d-4604-be58-43408335b75e", "52d8b2ea-7eec-4981-8daf-62bcdee3810d", "5999137d-19fb-494f-85ae-42c4db105522", "5adb33d7-bb5c-4033-b48a-c4c3124ed8e4", "5b4d4a47-26da-43f8-bb5c-e9435108224f", "686aedd1-d00e-43f8-b835-e4209268cf68", "6eb1ed98-f7e7-43c8-9162-7c096db62713", "7a06000c-c3db-4f0d-a648-eb18d2c30626", "7c488d05-a0c9-471d-8059-a2dda09304f6", "7fb1ed1b-796e-4de4-8e60-45f50a26e618", "8956f034-e8c3-4b34-9254-8b780c11600e", "8a121148-2215-4867-8d6f-27885ee775da", "8ea5b856-82ec-4a2a-a759-acba40311a1d", "9274942b-f91c-4bbb-93b3-8d8fa3e10bfe", "9443fa54-866f-4dbb-b4be-90426831dd5b", "99b2a5e3-4dda-457e-a628-6cb4a0693903", "9bcb4fe6-aa0c-4838-b17a-b11377cc4784", "a92213e5-a2ac-4c24-9d84-1cbb43b4c89b", "ab05824f-946b-4155-99db-bcbd04a304ce", "b96d4bc0-4d70-4320-aa64-bf5bebbbedf4", "cb5abb8a-4f6f-4547-ad61-ee57cd636e0e", "cd13fec9-0a7b-4061-8f44-6b0b5c92defe", "d06f2bf3-42f6-44fa-bf92-146dfa53ea04", "d25dc95a-26d8-471b-9a9a-6f7ce4a68fc7", "de0b2b29-f418-4139-997a-584b2ca0120c", "e2270800-ee21-45ac-9c8e-5f2922dd5d83", "e739d933-76bd-4638-bc40-8425e9631ed3", "e9aa9687-d26b-4e4f-8d83-6ceeff772ed5", "ecef7394-5d84-49a6-bd97-82651f3df288", "f54b655d-0a6b-426d-9025-a0600f2c6bf9", "f608730b-b790-4232-94fe-937789140de9", "f951f7f4-a3ee-4929-9092-9a420f4c0785", "f9adbc7e-9ac5-4840-945b-91d2b68390fc", "fdb51759-5ea0-4478-b6f1-11b0443f0e80", "fe5a0723-d056-44c5-a3de-b5a9ea15ce80", "fffd1e07-0d58-4c9a-b445-77b163e2de07"], "title": "Gradualness, uncertainty and bipolarity: Making sense of fuzzy sets", "venue": "Fuzzy Sets and Systems", "year": 2012, "id": "2a6eba94-1434-46a0-a95a-b729a04d46eb"}
{"authors": ["Andrzej Ehrenfeucht", "Juhani Karhum\u00e4ki", "Grzegorz Rozenberg"], "n_citation": 90, "references": ["1097c6f6-5694-4791-b338-b2c93a827c30", "6ec6a75b-8da9-4311-9163-33242a97388d", "73b60425-657e-4d72-a452-c396092f3173", "9ffd4ae1-43f0-406d-8999-bc4728672bbb", "fc4220d2-7400-43f0-bfee-22705345bf7a"], "title": "The (generalized) post correspondence problem with lists consisting of two words is decidable", "venue": "Theoretical Computer Science", "year": 1982, "id": "2a6b5d7b-0ea2-437f-a1dd-6caf899b06a4"}
{"abstract": "Periodic global updates of dual variables have been shown to yield a substantial speed advantage in implementations of push-relabel algorithms for the maximum flow and minimum cost flow problems. In this paper, we show that in the context of the bipartite matching and assignment problems, global updates yield a theoretical improvement as well. For bipartite matching, a push-relabel algorithm that uses global updates runs in $O\\big(\\sqrt n m\\frac{\\log(n^2/m)}{\\log n}\\big)$ time (matching the best bound known) and performs worse by a factor of $\\sqrt n$ without the updates. A similar result holds for the assignment problem, for which an algorithm that assumes integer costs in the range $[\\,-C,\\ldots, C\\,]$ and that runs in time $O(\\sqrt n m\\log(nC))$ (matching the best cost-scaling bound known) is presented.", "authors": ["Andrew V. Goldberg", "Robert Kennedy"], "n_citation": 50, "references": ["0b6419e0-ba97-468c-bc05-07920c7d0de2", "56d40aa7-4f86-4085-86ec-8f2f88acdb76", "beaa5062-7993-444e-b1ac-75c9f4eea5bd", "c361df5c-7056-41eb-92db-c986075d01e1", "ce9c12b0-ff31-4f20-bd6b-2b3bd3f8c760", "ceb48415-4ff9-4097-a262-421b7ac93535", "ed4259cc-d6c2-4413-a7cd-702fd819f2d2", "f5de6b41-0df8-4270-8211-a67a081dad45"], "title": "Global Price Updates Help", "venue": "SIAM Journal on Discrete Mathematics", "year": 1997, "id": "1435f593-5c55-464a-8482-b36687e344d1"}
{"abstract": "We present the SPEED method to predict endpoints, based on analysis of the kinetic characteristics of the pointing gesture. Our model splits the gesture into an acceleration phase and a deceleration phase to precisely detect target. The first phase allows us to identify a velocity peak that marks the beginning of the second phase. This phase is approached with a quadratic model to predict gesture endpoint. A pilot study shows that SPEED predicts a target more precisely than other existing methods, for 1 D  tasks without distractors.", "authors": ["Jonathan Wonner", "J\u00e9r\u00f4me Grosjean", "Antonio Capobianco", "Dominique Bechmann"], "n_citation": 5, "references": ["026d4cab-2a9a-494a-ab26-8a270d615b53", "3d1ea4be-f048-49f2-97b8-01645f4d9e58", "3e3ed6db-94b8-40e4-bf71-ca9039d1c52a", "591ff3c1-ca61-4eab-b174-f7aaa395728d", "624db733-1274-4020-8767-b1e46f8c40dd", "6a5b0d47-970c-4f9e-b938-09d1416cae75", "7b6491ae-baf4-4420-bbfb-d042c11451af", "8172880d-5a5d-42b4-90f3-b60ab721c7ab", "b2d01da7-2456-40e0-a154-e30fcf51c9f1", "db356c77-615f-4f43-b44a-ca32a7ff37f8", "fb6f1760-7a7a-4851-9e43-54ea648af298"], "title": "SPEED: pr\u00e9diction de cibles", "venue": "", "year": 2011, "id": "e10082eb-bb76-44aa-92e6-00849edeaedd"}
{"abstract": "Security is a very important concern for software architecture and software components. Previous modeling approaches provide insufficient support for an in-depth treatment of security. This paper argues for a more comprehensive treatment based on software connectors. Connectors provide a suitable vehicle to model, capture, and enforce security. Our approach models security principal, privilege, trust, and context of architectural constituents. Extending our existing architecture description language and support tools, our approach can facilitate describing the security characteristics of an architecture generating enabling infrastructure, and monitoring run-time conformance. Initial results of applying this approach are illustrated through a case study. The contribution of this research is a deeper and more comprehensive treatment of architectural security through software connectors.", "authors": ["Jie Ren", "Richard N. Taylor", "Paul Dourish", "David F. Redmiles"], "n_citation": 35, "references": ["0bd76c78-eb33-4b30-ae81-931c5b6ea796", "0ce7a8cd-ba22-4ee6-ac2d-be261913b3cc", "2306490f-fad8-42d3-9c7c-7c96ea7d2063", "2903c345-08ef-4d3e-885a-2ca9d13d2917", "2e2a7569-33ae-424f-b859-1197994b8087", "407f5b6a-857d-4a6f-a3d8-b3094b269097", "581419e7-a15f-4662-ae31-5a8c152026ec", "61394dbb-e4c4-4b87-82e0-f0bf109afa4c", "6143e8c0-b936-4657-ab95-55a17caf48f7", "686f31e5-3651-4857-aa44-b84336c5e41f", "7ce56f88-3505-48fe-b322-e7af62e86b71", "80f0caf1-7801-4983-ae1b-cb32006947e1", "85c1de96-97f5-478f-aa27-3c8581595c15", "9c593087-daf0-4a86-b321-6301f0287d11", "b008ac33-33f2-4b50-bb46-62c83406375d", "cb0f1186-5ef9-4504-b72b-75d1161341c2", "ccc8afa9-3cec-4c56-9745-b6be349ac45c", "d5be731f-04af-4167-84b5-1d6d3cf9d0b0", "d5c07be8-069d-447f-b5f2-02a9a657276d", "ded73f0a-0715-469f-b384-a98cc070a908", "ecfb2022-e18c-4e5e-8733-d8bc6f4c8fc9", "f6af5e4a-1a75-4166-b45c-e6dd14a8e766", "fa74b179-bc4e-41f9-9e91-dc23620e5fe0", "fe2eab52-0ace-4887-8184-c8cdea36c100"], "title": "Towards an architectural treatment of software security: a connector-centric approach", "venue": "ACM Sigsoft Software Engineering Notes", "year": 2005, "id": "a62ac649-8feb-4851-b3f4-060eaad73a20"}
{"authors": ["Eui-Hong Han", "George Karypis", "Vipin Kumar", "Bamshad Mobasher"], "n_citation": 288, "title": "Clustering Based On Association Rule Hypergraphs.", "venue": "", "year": 1997, "id": "7ff41e6e-42c9-489f-acf7-46f42f04a5d2"}
{"abstract": "Future computer-aided design systems will provide a suite of tools capable of managing the entire product life cycle. Knowledge Based Engineering (KBE) systems will be used to support many aspects of the product life cycle. For a variety of reasons, we believe that CAD developers should not attempt to provide the required KBE functionality as part of their product. Rather, the CAD systems should be built with a fully open architecture to allow easy integration of a broad range of KBE software.", "authors": ["J. A. Penoyer", "George A. Burnett", "David Fawcett", "Shuh-Yuan Liou"], "n_citation": 72, "references": [], "title": "Knowledge based product life cycle systems: principles of integration of KBE and C3P", "venue": "Computer-aided Design", "year": 2000, "id": "4413f2ee-c723-4377-a498-eed0c2daf5c8"}
{"abstract": "Overfitting is the bane of data analysts, even when data are plentiful. Formal approaches to understanding this problem focus on statistical inference and generalization of individual analysis procedures. Yet the practice of data analysis is an inherently interactive and adaptive process: new analyses and hypotheses are proposed after seeing the results of previous ones, parameters are tuned on the basis of obtained results, and datasets are shared and reused. An investigation of this gap has recently been initiated by the authors in [7], where we focused on the problem of estimating expectations of adaptively chosen functions.#R##N##R##N#In this paper, we give a simple and practical method for reusing a holdout (or testing) set to validate the accuracy of hypotheses produced by a learning algorithm operating on a training set. Reusing a holdout set adaptively multiple times can easily lead to overfitting to the holdout set itself. We give an algorithm that enables the validation of a large number of adaptively chosen hypotheses, while provably avoiding overfitting. We illustrate the advantages of our algorithm over the standard use of the holdout set via a simple synthetic experiment.#R##N##R##N#We also formalize and address the general problem of data reuse in adaptive data analysis. We show how the differential-privacy based approach given in [7] is applicable much more broadly to adaptive data analysis. We then show that a simple approach based on description length can also be used to give guarantees of statistical validity in adaptive settings. Finally, we demonstrate that these incomparable approaches can be unified via the notion of approximate max-information that we introduce. This, in particular, allows the preservation of statistical validity guarantees even when an analyst adaptively composes algorithms which have guarantees based on either of the two approaches.", "authors": ["Cynthia Dwork", "Vitaly Feldman", "Moritz Hardt", "Toniann Pitassi", "Omer Reingold", "Aaron Roth"], "n_citation": 66, "references": ["021ce112-7d61-4235-8dce-70cab2c4581f", "063e2cb9-a717-4993-9707-eea0196630a7", "090da681-3903-48dd-ab58-f8751d7d775a", "0ddb2b14-27bc-448d-832d-0163fc3acd64", "254a151f-40f3-4af5-84b7-96a1312e958e", "2a4df8c4-87d6-485c-beef-5fd21a78bcbd", "32fd9fa0-0857-4bbc-8e40-b947c02e9d8b", "3abbef92-fcf5-4ed1-ba10-1262e929c8cd", "70ee2599-0921-4a79-b87a-7fadceb4357d", "735dfcd8-e6c9-4fe6-a609-a5d080dcf07c", "92031bfe-7728-41ae-a9f9-f323b522ef7f", "b72d6743-4e1d-42fc-8cc3-ef32a94d0a05", "c585699c-927c-4cb5-8518-d496b58bbe5d", "d3538f22-7036-43f2-a169-64f0c965d5e5", "dc667ef3-91f0-400e-b405-b0844931aec5", "dd38b522-cbfd-4111-897d-17c3bc38386e", "dec16f9d-2a5a-45d9-8a61-7d1bbdc6fabf", "f032e2ac-1afe-4f51-ad99-a5d8d50f8fdf", "f17d1b19-f730-43ff-abf1-c0777da26629", "fcaecd0d-369f-4eb6-9e3b-3c14bdbf623f"], "title": "Generalization in adaptive data analysis and holdout reuse", "venue": "neural information processing systems", "year": 2015, "id": "c13c3d13-d47d-437a-8edb-d0a8fac7e4bb"}
{"abstract": "Bluetooth is a new low-cost wireless technology that is going to play an important role in communications among small electronic devices and the access to wired networking infrastructure. Bluetooth stations that communicate directly form a piconet. In a piconet one station has the role of master and the others are slaves. The access to the medium is based on a TDD (time division duplexing) scheme controlled by the master. The master sends packets to slaves in even-numbered slots triggering a transmission from slaves in the subsequent slot. Slaves are allowed to send packets only in response to a master packet. The way in which the master schedules packets transmission to slaves or polls them determines system performance. We consider the problem of designing an efficient and simple polling and scheduling scheme for Bluetooth. We propose some practical schemes and compare their performance with some ideal schemes derived from known results for polling systems.", "authors": ["Antonio Capone", "Mario Gerla", "Rohit Kapoor"], "n_citation": 236, "references": ["0b0b413b-1cde-44dd-a219-c851eb052701", "330841ef-6d92-4fe7-aebe-c8e7abaf9cd2", "4302d087-c788-4ec1-8b79-3d947de2a02d", "53929745-fa35-4bae-82eb-ea03a68ea280", "aeb8815f-ac19-42c3-98e9-473c1025fc92", "e98d913f-7e57-46f9-b160-1884ffc7b733"], "title": "Efficient polling schemes for Bluetooth picocells", "venue": "international conference on communications", "year": 2001, "id": "16238c63-0cc3-483d-bd43-16ec07b7c31a"}
{"authors": ["Klaus Becker", "Uta Wille"], "n_citation": 398, "references": ["115ffe29-11aa-4069-980f-e06a52e04d03", "166779f5-4b9a-4705-86c6-a141a9886286", "5e562c5b-f61d-4d3e-8afd-875154850a7a", "6e265ae0-9df2-40ad-9378-c08d80547522", "7696cbf8-8b61-489b-ba3d-5e2a663abeba", "ca394e6a-59e0-466c-a66a-d976555db689", "ce1d0bde-d27f-462f-a0fd-06ca6c462b06"], "title": "Communication complexity of group key distribution", "venue": "computer and communications security", "year": 1998, "id": "b6155657-d652-4df2-be18-9c203c02e98d"}
{"abstract": "Partial differential equations can be solved efficiently by adaptive multigrid methods on a parallel computer. We report on the concept of hash-table storage techniques to set up such a program. The code requires substantial less amount of memory than implementations based on tree type data structures and is easier to program in the sequential case. The parallelization takes place by a space-filling curve domain decomposition intimately connected to the hash table. The new data structure simplifies the parallelization of the code substantially and introduces a cheap way to solve the load balancing and mapping problem. We report on the main features of the method and give the results of numerical experiments with the new parallel solver on a cluster of 64 Pentium II/400MHz connected by a Myrinet in a fat tree topology.", "authors": ["Michael Griebel", "Gerhard W. Zumbusch"], "n_citation": 104, "references": ["50a78e40-ef60-467a-86e6-261ac1acc585", "fe64d926-4165-4972-9aed-58ac395bd0ee", "fef1a21f-ffd5-40d6-9f43-64c005d48211"], "title": "Parallel multigrid in an adaptive PDE solver based on hashing and space-filling curves", "venue": "parallel computing", "year": 1999, "id": "2c94c7e9-ac5d-4dcc-9f19-584d4e924a77"}
{"abstract": "Traditional software teams consist of independently focused self-managing professionals with high individual but low team autonomy. A challenge with introducing agile software development is that it requires a high level of both individual and team autonomy. This paper studies the barriers with introducing self-organizing teams in agile software development and presents data from a seven month ethnographic study of professional developers in a Scrum team. We found the most important barrier to be the highly specialized skills of the developers and the corresponding division of work. In addition we found a lack of system for team support, and reduced external autonomy to be important barriers for introducing self- organizing teams. These findings have implications for software development managers and practitioners.", "authors": ["Nils Brede Moe", "Torgeir Dings\u00f8yr", "Tore Dyb\u00e5"], "n_citation": 117, "references": ["43647ff5-6e43-4184-8ac3-81ee12210108", "7f06ae15-949d-4023-a6aa-0c172e3d158c", "8c050c13-6bf8-4b1e-af62-60e99714453c", "8cf48925-11f1-4fd1-b3c6-7670ffb7fdc9", "a0544203-9a1b-4210-896f-9a32e457c8c1", "ace0a907-7981-4bc1-8ce1-b0b0d80bb18e", "c85e055b-869d-485e-82c8-65f39930ab93", "f4593e9d-babb-43c6-ab3f-465df23afb55", "f819bed7-616c-48b7-8bc2-be739b69e4b2"], "title": "Understanding Self-Organizing Teams in Agile Software Development", "venue": "australian software engineering conference", "year": 2008, "id": "866738f4-6860-4438-ad6d-5c9a76b96258"}
{"abstract": "In conventional multicast communication, the source carries a single conversation with all destination nodes. If a node on the path to any destination becomes congested, the throughput to all destinations is reduced, thus treating some destination nodes unfairly. We consider a window-controlled multipoint connection and study the use of destination set grouping, where the destination set can be split into disjoint subgroups with the source carrying independent conversations with each subgroup. We present a static grouping heuristic that can obtain near optimum grouping for static network environments and a dynamic grouping protocol which can adjust the grouping and the window sizes per group in response to changing network conditions. The performance of the static grouping heuristic and the dynamic grouping protocol are studied using simulation and compared with single-group multicasting.", "authors": ["Shun Yan Cheung", "Mostafa H. Ammar"], "n_citation": 55, "references": ["035cf122-5f4c-476d-8615-88ad3225bc45", "04c44d9f-2742-4a67-84fe-04dbc1ae62e2", "14eb9840-4f45-480e-baaa-61263377bb2f", "6037931e-5941-41d4-ba57-2abc72fbcc08", "98280f41-6e93-4d2e-b4cb-17a80985c062", "bbb1a8d5-f078-4b46-a131-48a251dbd5f5", "d29b395f-af6e-46ca-a894-60d9bcad0cc0"], "title": "Using destination set grouping to improve the performance of window-controlled multipoint connections", "venue": "Computer Communications", "year": 1996, "id": "7fb1f1b8-836d-4e12-9fca-6aea0390c976"}
{"abstract": "In this paper a set of sufficient conditions is developed in terms of controllability and observability functions under which a given state-space realization of a formal power series is minimal. Specifically, it is shown that positivity of these functions, in addition to a stability requirement and a few technical conditions, implies minimality. Using the nonlinear analogue of the Kalman decomposition, connections are then established between minimality, singular value functions, balanced realizations, and various notions of reachability and observability for nonlinear systems.", "authors": ["Jacquelien M.A. Scherpen", "W.S. Gray"], "n_citation": 61, "references": ["1f64fb93-8a2a-4e73-9293-9b9d277db6b2", "390c4de6-bfff-4c2f-819d-5a28e420673d", "c4a18a9f-afb0-41d2-bb50-e0f5fab88d07"], "title": "Minimality and local state decompositions of a nonlinear state space realization using energy functions", "venue": "IEEE Transactions on Automatic Control", "year": 2000, "id": "d64d5981-3c4e-41a0-bb54-12ced7fa31a4"}
{"abstract": "Mobile Ad hoc network consists of a collection of mobile nodes capable of forming instantaneous network with dynamic topology. Each node simultaneously acts as both router and host. Nodes can leave or join the network freely. Destination Sequence Distance Vector (DSDV) is a modification of the conventional Bellman-Ford routing algorithm for ad hoc networks. Dynamic topology of ad hoc networks makes them susceptible to attacks launched by malicious nodes. This paper provides an overview of the DSDV protocol and how DSDV can be exploited by malicious nodes. We propose two types of attacks on DSDV - Byzantine attack and a novel Broken Link attack. Byzantine attacks have mainly been studied with respect to reactive protocols. To the best of our knowledge, Broken Link attack has been proposed for the first time. In this paper we present a way to simulate these attacks and consequent effects on Packet Delivery Ratio (PDR). We observe that PDR falls after the onset of attacks. We observe that DSDV has natural reactiveness to attacks and sustaining an attack requires calculated effort. We also show experiments to study effect of Byzantine attack on Multiple Source Destination pairs which has not been done till now. It is observed that the probability of a source being affected increases if attacker moves in its vicinity.", "authors": ["Rajbir Kaur", "Manoj Singh Gaur", "Vijay Laxmi"], "n_citation": 50, "references": ["0779e2c2-d021-48cf-8ec2-addee8eb86f1", "54d83e82-81a9-4673-ba73-62d6fb3fe7a4", "60fb0dc2-bde3-4714-948e-de0ed12ab460", "94cf960f-b50b-4106-b4a2-d1a3c8377fac", "d330d506-3b9b-4a0e-9b38-6b3920109219"], "title": "A Novel Attack Model Simulation in DSDV Routing", "venue": "new technologies, mobility and security", "year": 2011, "id": "fd861d41-2331-4f47-b474-5299bbc393aa"}
{"abstract": "To discriminate among all possible diagnoses using Hou's theory of measurement in diagnosis from first principles, one has to derive all minimal conflict sets from a known conflict set. However, the result derived from Hou's method depends on the order of node generation in CS-trees. We develop a derivation method with mark set to overcome this drawback of Hou's method. We also show that our method is more efficient in the sense that no redundant tests have to be done. An enhancement to our method with the aid of extra information is presented. Finally, a discussion on top-down and bottom-up derivations is given.", "authors": ["Benjamin Han", "Shie-Jue Lee"], "n_citation": 50, "references": ["2691742e-e622-4600-8c2e-012df86994ed", "2a73f987-98cc-4d8b-bf27-9d8d0834c57c", "c0a69970-4b14-492a-adcc-6928988a9f2a"], "title": "Deriving minimal conflict sets by CS-trees with mark set in diagnosis from first principles", "venue": "systems man and cybernetics", "year": 1999, "id": "e36e791b-6f27-4b1d-99a1-e04eb0068308"}
{"abstract": "Social networking applications have become very important web services that provide Internet-based platforms for their users to interact with their friends. With the advances in the location-aware hardware and software technologies, location-based social networking applications have been proposed to provide services for their users, taking into account both the spatial and social aspects. Unfortunately, none of existing location-based social networking applications is a holistic system nor equips database management systems to support scalable location-based social networking services. In this paper, we present GeoSocialDB; a holistic system providing three location-based social networking services, namely, location-based news feed, location-based news ranking, and location-based recommendation. In GeoSocialDB, we aim to implement these services as query operators inside a database engine to optimize the query processing performance. Within the GeoSocialDB framework, we discuss research challenges and directions towards the realization of scalable and practical query processing for location-based social networking services. In general, we discuss the challenges in designing location- and/or rank-aware query operators, materializing query answers, supporting continuous query processing, and providing privacy-aware query processing for our three location-based social networking services.", "authors": ["Chi-Yin Chow", "Jie Bao", "Mohamed F. Mokbel"], "n_citation": 102, "references": ["045f39bb-3c9c-44a2-96ff-32c3699e8518", "12235f49-8896-442a-bbf1-a74088fff73d", "16ce2bb5-6531-4e64-a94b-3405c462c93d", "1af0f531-9c0d-45b3-b86b-62922db96fad", "23d70ede-4f2c-4bf5-b72f-d034751e6257", "2f0c9ae4-9a88-4f30-b9a9-066ed052acb3", "340b4636-6465-4828-b94f-6fe958402fd9", "39e9936c-16f0-4b9c-8323-e1a498529c69", "3d73de26-7429-41d5-b9ca-efd56e704ee7", "3dbb49ee-bc22-4f0b-b05e-2d66c212a6f5", "44e91111-b413-4143-85a9-81872a97fa9d", "4a01f0e4-0f01-4028-a0e4-d9a62010c1a5", "4b787a70-012a-415a-88f1-7ca16224d6f2", "5adbc7b1-c2dc-499b-83eb-40bbde93d68e", "6e425bce-a497-4c63-9eb0-b038e660a54f", "7b0c4405-cf77-44f8-a88f-69dfa759750c", "97255ebb-f07a-45be-9729-2ee7b3827cd6", "98b23182-8f51-428a-a4af-a91d280471ca", "9b602954-f960-46fe-87ae-41f06c486efc", "b4ca9e3f-d878-430d-a354-aa1731291b73", "b7149223-3a84-4c15-b860-981565c7708d", "c69ef004-087e-486c-97c9-9b4587d0b10a", "c9439cc9-90a2-4d31-836a-f0a33b4e75a8", "cfc9fffb-9e0f-4d69-bbc7-717b745b0837", "d3ec5b39-7147-440d-82b0-4c4d05e671c9", "d445d2c5-a50a-493f-ac4f-fb1db33dc155", "da51d010-0c5c-4ea0-81cf-f2df8411f681", "e84629cd-3f79-4882-932b-58c8cab6b6a7", "ea95ef01-dcdb-4bac-a734-70fa67c7d05c", "ed4c0d5d-5152-4915-b9bd-d0bd25f82674", "edd3dc54-319d-42b1-9fe8-82712f39a4f0", "f517581b-80da-4453-b52a-75b77359ba2b", "feddae21-3c05-4743-80fa-b8e101f1b93f"], "title": "Towards location-based social networking services", "venue": "International Journal of Geographical Information Science", "year": 2010, "id": "ccd322e4-1d98-4d57-930e-42f9b8857b29"}
{"abstract": "There has been important progress in constructing units and S-units associated to curves of genus 2 or 3. These approaches are based mainly on the consideration of properties of Jacobian varieties associated to hyper-elliptic curves of genus 2 or 3. In this paper, we construct a unit group of the ray class field k6 of Q(exp(2\u03c0i/5)) modulo 6 with full rank by special values of Siegel modular functions and circular units. We note that k6 = Q(exp(2\u03c0i/15), 5\u221a-24). Our construction of units is number theoretic, and closely based on Shimura's work describing explicitly the Galois actions on the special values of theta functions.", "authors": ["Takashi Fukuda", "Keiichi Komatsu"], "n_citation": 50, "references": [], "title": "On a unit group generated by special values of Siegel modular functions", "venue": "Mathematics of Computation", "year": 2000, "id": "3e08e098-8a8a-43d9-97cf-1eded71ace08"}
{"abstract": "Time series measured in real world is often nonlinear, even chaotic. To effectively extract desired information from measured time series, it is important to preprocess data to reduce noise. In this Letter, we propose an adaptive denoising algorithm. Using chaotic Lorenz data and calculating root-mean-square-error, Lyapunov exponent, and correlation dimension, we show that our adaptive algorithm more effectively reduces noise in the chaotic Lorenz system than wavelet denoising with three different thresholding choices. We further analyze an electroencephalogram (EEG) signal in sleep apnea and show that the adaptive algorithm again more effectively reduces the Electrocardiogram (ECG) and other types of noise contaminated in EEG than wavelet approaches.", "authors": ["Jianbo Gao", "Hussain Sultan", "Jing Hu", "Wen-wen Tung"], "n_citation": 151, "references": ["2743c246-a81a-481b-a1f3-e2377ccae541", "5daec208-b50a-4d7f-8814-0bdde9874156", "8e2d96b6-f141-405b-b755-d9e089491c4f", "cda3babf-99e8-4995-8e22-9728fba9c163"], "title": "Denoising Nonlinear Time Series by Adaptive Filtering and Wavelet Shrinkage: A Comparison", "venue": "IEEE Signal Processing Letters", "year": 2010, "id": "3d9e9abb-7493-4acd-bb5c-f5a30d046422"}
{"abstract": "We present a procedure for deciding whether two normed PA terms are bisimilar. The procedure is \"elementary,\" having doubly exponential non-deterministic time complexity.", "authors": ["Yoram Hirshfeld", "Mark Jerrum"], "n_citation": 59, "references": ["0404d020-5bd5-4054-8dc5-a5555712319f", "077b7c87-fbd3-48ce-95ea-2bda71256b7b", "86718b68-beb2-4201-8bce-845a80302bd2", "8cc2c39b-c323-4d59-b792-bbf23485de8e", "9647e4cb-6b06-4bbe-a55e-726158e2328d", "d36a4a0e-e91b-4749-948d-2105787e9e1b", "eb9ab356-5fed-4dd7-b31a-80161d29dc4c"], "title": "Bisimulation Equivanlence Is Decidable for Normed Process Algebra", "venue": "international colloquium on automata, languages and programming", "year": 1999, "id": "2e8629cc-b7af-4941-8086-21fb438cd4c7"}
{"authors": ["Masoud Farivar", "Steven H. Low"], "n_citation": 50, "title": "Branch flow model: Relaxations and convexification", "venue": "", "year": 2014, "id": "161c4eae-5b98-4d86-9731-0dcf79c43206"}
{"abstract": "In this paper, we take a concrete step towards materializing our long-term goal of providing a fully automatic end-to-end tuning infrastructure for arbitrary program components and full applications. We describe a general-purpose offline auto-tuning framework and apply it to an application benchmark, SMG2000, a semi-coarsening multigrid on structured grids. We show that the proposed system first extracts computationally intensive loop nests into separate executable functions, a code transformation called outlining. The outlined loop nests are then tuned by the framework and subsequently integrated back into the application. Each loop nest is optimized through a series of composable code transformations, with the transformations parameterized by unbound optimization parameters that are bound during the tuning process. The values for these parameters are selected using a search-based auto-tuner, which performs a parallel heuristic search for the best-performing optimized variants of the outlined loop nests. We show that our system pinpoints a code variant that performs 2.37 times faster than the original loop nest. When the full application is run using the code variant found by the system, the application\u00e2\u0080\u0099s performance improves by 27%.", "authors": ["Ananta Tiwari", "Jeffrey K. Hollingsworth", "Chun Chen", "Mary W. Hall", "Chunhua Liao", "Daniel J. Quinlan", "Jacqueline Chame"], "n_citation": 50, "references": ["14a89fb0-acf1-47d5-84bf-a4330c0f9829", "1601c7f8-8230-464c-8bde-1dc24a9a0294", "2f9f6c0a-3e12-4d50-9159-199c608e30cd", "387084b8-015b-4d00-9de6-a44b75884c01", "569ef6db-144d-4aff-b569-682a3c8df32f", "57deff7e-3a69-4ec8-808b-1f392c8bc3b1", "5a314885-d30e-4880-95d4-dd8d9fc6f865", "6b6ce3fc-c8fb-4853-83c2-921bb60de86e", "72393c74-4fd1-473b-9b06-2bce21880202", "733748da-2af7-4d35-bdfb-0fbef8d441af", "78f36606-07fc-4d3d-a523-22320515ec0e", "84557654-5a3b-4ef0-ae56-01f30257548f", "85b3538e-119e-4a34-b254-ad1814dce4a2", "87221c55-2dc0-4746-b2ab-04e8004aaee4", "884ebec0-ce8d-4133-be46-5e05f6ec88f5", "88f4908c-ad9d-45bc-a673-80971997916f", "915cea4a-3ebf-40bc-a885-92e34f661557", "9190e2e2-215b-44db-8023-2281867e40d1", "d092b18f-307f-4b7c-a0fa-7f50cbd96c68", "d25bb49c-de8f-4695-b1b9-141993f06bc1", "d2d4cb0c-afb6-4cde-880c-a895393d7e34", "dab6c64b-c53c-43d0-a38b-247fa1118ba5", "dd224dc9-6bf3-4fc4-be01-5ede9c18ca23", "f6d79a98-9d66-4be5-9b26-e07229afc778", "fb6dcc68-9541-4e20-8cd9-f92b2095916a"], "title": "Auto-tuning full applications: A case study", "venue": "ieee international conference on high performance computing data and analytics", "year": 2011, "id": "ca5e8433-986f-4627-994e-93537dba128f"}
{"abstract": "A simple decoding procedure for algebraic-geometric codes C/sub Omega /(D,G) is presented. This decoding procedure is a generalization of Peterson's decoding procedure for the BCH codes. It can be used to correct any ((d*-1)/2) or fewer errors with complexity O(n/sup 3/), where d* is the designed minimum distance of the algebraic-geometric code and n is the codelength. >", "authors": ["Gui Liang Feng", "T. R. N. Rao"], "n_citation": 282, "references": ["1d55a649-7da8-430a-8204-13dc4bbc0d91", "5d55f0e1-bf2b-495a-a918-fb8defc16a4e", "6ac184f6-8d9b-4a14-8353-e088ed88c615", "78961097-675f-42c6-b22e-b54da944cd08", "bc91bf8c-d823-466a-bd1e-346a9503a989", "ce220ec4-46be-4a79-b29c-964e3d47e30c", "d221922a-fb0b-49d6-bc3b-17330fa44bf5", "ebe886ba-0f11-4f8e-b030-44c0f0f66587"], "title": "Decoding algebraic-geometric codes up to the designed minimum distance", "venue": "IEEE Transactions on Information Theory", "year": 1993, "id": "04fc518d-bcb8-46ae-aae0-e762a4bd6b45"}
{"abstract": "Linearizer is one of the best known approximation algorithms for obtaining numeric solutions for closed-product-form queueing networks. In the original exposition of Linearizer, the computational cost was stated to be O(MK/sup 3/) for a model with M queues and K job classes. It is shown that with some straightforward algebraic manipulation, Linearizer can be modified to require a cost that is only O(MK/sup 2/). >", "authors": ["E. de Souza e Silva", "Richard R. Muntz"], "n_citation": 50, "references": ["1c26e228-57d2-4b2c-b0c9-8d5851c17fac"], "title": "A note on the computational cost of the Linearizer algorithm for queueing networks", "venue": "IEEE Transactions on Computers", "year": 1990, "id": "55744b23-bcc2-4675-8a3e-4c1eaf243c23"}
{"abstract": "We consider the problem of job scheduling on a variable voltage processor with $d$ discrete voltage/speed levels. We give an algorithm which constructs a minimum energy schedule for $n$ jobs in $O(d n\\log n)$ time. Previous approaches solve this problem by first computing the optimal continuous solution in $O(n^3)$ time and then adjusting the speed to discrete levels. In our approach, the optimal discrete solution is characterized and computed directly from the inputs. We also show that $O(n\\log n)$ time is required; hence the algorithm is optimal for fixed $d$.", "authors": ["Minming Li", "F. Frances Yao"], "n_citation": 120, "references": ["0e975a27-fb5e-493e-a3c6-f51b25477a99", "2be51a5d-49c6-46c4-92e9-17460c6ad3fe", "4a5d4005-601c-4116-a1e9-8e31f42a2dcd", "5c1edf7a-3877-41a0-b66b-e713e50c0623", "76605eb7-2cf0-4923-975a-e36a47864c4a", "76e8161d-f4c2-4672-837f-2b0fd48905cb", "acf04271-4572-4c59-8f72-d852eabd1fc2"], "title": "An Efficient Algorithm for Computing Optimal Discrete Voltage Schedules", "venue": "SIAM Journal on Computing", "year": 2005, "id": "36126073-e451-4ca7-8a84-b2b04e39d62a"}
{"abstract": "A  semantic file system  is an information storage system that provides flexible associative access to the system's contents by automatically extracting attributes from files with file type specific  transducers . Associative access is provided by a conservative extension to existing tree-structured file system protocols, and by protocols that are designed specifically for content based access. Compatiblity with existing file system protocols is provided by introducing the concept of a  virtual directory . Virtual directory names are interpreted as queries, and thus provide flexible associative access to files and directories in a manner compatible with existing software. Rapid attribute-based access to file system contents is implemented by automatic extraction and indexing of key properties of file system objects. The automatic indexing of files and directories is called \"semantic\" because user programmable transducers use information about the semantics of updated file system objects to extract the properties for indexing. Experimental results from a semantic file system implementation support the thesis that semantic file systems present a more effective storage abstraction than do traditional tree structured file systems for information sharing and command level programming.", "authors": ["David K. Gifford", "Pierre Jouvelot", "Mark A. Sheldon", "James O'Toole"], "n_citation": 645, "references": ["07194702-1044-48fa-8e3d-e95631650f36", "1ef648de-709d-47f3-8e85-11e9038168a7", "3ac61fef-7bd4-4d7f-9e1f-75075bbab07c", "bdcf84a6-d460-4c89-9f10-62cd4286c984", "c3aa6db1-6c60-4cc5-a4f3-14aaad6970b6", "c5538f2f-d744-4922-9fa6-4b5f0f5b49ac", "c7e51f1b-2404-4df1-895a-f4a6a430b98a", "e75d8e62-a86d-4241-953f-1b315005d920", "f9e2e9d8-7ab2-449d-9328-4f225bc658ef"], "title": "Semantic file systems", "venue": "symposium on operating systems principles", "year": 1991, "id": "93f501e9-78e2-41a1-ab3e-d7923995967c"}
{"abstract": "This study compares the structural contingency and risk-based perspectives regarding the effects of project coordination and requirements uncertainty on performance dimensions such as process control and product flexibility. The structural contingency perspective suggests that the fit between coordination and requirements uncertainty influences performance, where fit is conceptualized in three ways: mediation, interaction, and profile deviation. The risk-based perspective suggests that performance risk is an alternative mechanism that explains the effect of coordination and uncertainty on process control and product flexibility.A survey methodology based on sixty-four projects from banking and other industries was used to test the two perspectives and their relevant hypotheses. The results suggest lack of support for any of the three approaches to the structural contingency perspective, but some support for the role of software performance risk in explaining performance. In particular, software performance risk seems to mediate the effect of vertical coordination and requirements uncertainty on process control. Horizontal coordination appears to have a direct and unmediated positive effect on product flexibility but is unrelated to either software performance risk or process control.The findings suggest that practitioners could benefit from awareness of the different capabilities provided by the two coordination mechanisms: Vertical coordination enables project managers to bring projects to closure by reducing performance risks and increasing control over the process, whereas horizontal coordination leads to flexible software applications because it allows exploration of ideas and issues.", "authors": ["Sarma R. Nidumolu"], "n_citation": 130, "references": ["0ac6a782-659c-4925-8086-d4971be6e65d", "1e7d304b-25b0-4ca1-a440-b53d9e697275", "276bf965-5741-476d-a375-1f6106b74dfc", "34f5c3ed-36fa-44c5-a6e8-ca6577eff201", "39b65b89-1eed-484f-b343-cda9decbacfe", "3c610c54-8cea-403a-a579-170adf954ea7", "50d8def8-aa86-4450-9600-710c92870130", "5cc8bfc1-fc95-4957-bcc8-1c325f0d1d8e", "76c9f7b4-d868-4da4-829e-53535a746201", "7e7a986e-1d06-460a-bef5-44b4ea87dfbc", "7e8fefd0-c76b-4241-8482-aa9bccf9cf15", "829aa1ce-1431-43cf-82e9-389962c57fc2", "ad89ff75-7420-47c7-a354-74f6c5086830", "b541380f-8e36-4fd8-91b3-04cf1f8d2736", "d9be5c5a-f2ba-4ce4-9908-1549fd901608", "dc31f5b7-0343-47f8-a260-1745b3f05834", "ed25a1c0-6e93-494e-996d-6c848e7b2f83", "f1c2aa0a-a9c4-4a5b-b197-6adcdbfac662"], "title": "A comparison of the structural contingency and risk-based perspectives on coordination in software-development projects", "venue": "Journal of Management Information Systems", "year": 1996, "id": "b59a54a8-cf20-4bac-8624-9cd2a0a70b73"}
{"abstract": "In this paper we present  Netalyzr , a network measurement and debugging service that evaluates the functionality provided by people's Internet connectivity. The design aims to prove both comprehensive in terms of the properties we measure and easy to employ and understand for users with little technical background. We structure  Netalyzr  as a signed Java applet (which users access via their Web browser) that communicates with a suite of measurement-specific servers. Traffic between the two then probes for a diverse set of network properties, including outbound port filtering, hidden in-network HTTP caches, DNS manipulations, NAT behavior, path MTU issues, IPv6 support, and access-modem buffer capacity. In addition to reporting results to the user,  Netalyzr  also forms the foundation for an extensive measurement of edge-network properties. To this end, along with describing  Netalyzr  's architecture and system implementation, we present a detailed study of 130,000 measurement sessions that the service has recorded since we made it publicly available in June 2009.", "authors": ["Christian Kreibich", "Nicholas Weaver", "Boris Nechaev", "Vern Paxson"], "n_citation": 336, "references": ["07fb2501-f3d7-4f9e-9da4-722c8981fc93", "285fbbd0-42fb-4e34-ab0d-7e9cbb8a432c", "3eed43b4-d2cf-4be4-9d1d-5bc69fd37d16", "4c44394b-1d58-4aed-9c11-dc59a8afcf77", "641f6e00-7d44-4952-9c60-ccd1268650ba", "740922e7-d26a-4801-8cda-49e58ad65f1b", "92d05bb6-35a1-4dab-a6ee-2b38784e732c", "a071934e-8b94-4fc6-8d2b-0a3ff924f91a", "b24c26a0-2d89-4521-b0d3-b17e15b261e9", "dc39d850-52f1-4b0e-8f0c-9fdb415af34b", "e113e891-d97d-4ed7-a6d1-9a07b185047a", "e694d0cf-de46-4a36-9270-b68e6cc4fac8", "efdda73c-6e47-42e9-9fc9-3ab8840865b8", "f9d7ef3c-7999-4087-b092-4a604810a0c0"], "title": "Netalyzr: illuminating the edge network", "venue": "internet measurement conference", "year": 2010, "id": "d638feb8-78c4-4769-8b37-73bfb840c5f1"}
{"abstract": "Biogeography-based optimization (BBO) is an evolutionary algorithm that is based on the science of biogeography. Biogeography is the study of the geographical distribution of organisms. In BBO, problem solutions are represented as islands, and the sharing of features between solutions is represented as migration between islands. This paper develops a Markov analysis of BBO, including the option of elitism. Our analysis gives the probability of BBO convergence to each possible population distribution for a given problem. We compare our BBO Markov analysis with a similar genetic algorithm (GA) Markov analysis. Analytical comparisons on three simple problems show that with high mutation rates the performance of GAs and BBO is similar, but with low mutation rates BBO outperforms GAs. Our analysis also shows that elitism is not necessary for all problems, but for some problems it can significantly improve performance.", "authors": ["Daniel J. Simon", "Mehmet Ergezer", "Dawei Du"], "n_citation": 109, "references": ["20e996ee-3877-42ce-adcc-0479d955b8cd", "80b6213e-fff9-4baf-ba44-ae32a7d9e1db", "935a9cce-b59b-41e6-945f-e09155df5792"], "title": "Population distributions in biogeography-based optimization algorithms with elitism", "venue": "systems, man and cybernetics", "year": 2009, "id": "611c7a8f-10dd-4989-982a-d6253d071797"}
{"abstract": "The paper describes an improved hierarchical model for the assessment of high-level design quality attributes in object-oriented designs. In this model, structural and behavioral design properties of classes, objects, and their relationships are evaluated using a suite of object-oriented design metrics. This model relates design properties such as encapsulation, modularity, coupling, and cohesion to high-level quality attributes such as reusability, flexibility, and complexity using empirical and anecdotal information. The relationship or links from design properties to quality attributes are weighted in accordance with their influence and importance. The model is validated by using empirical and expert opinion to compare with the model results on several large commercial object-oriented systems. A key attribute of the model is that it can be easily modified to include different relationships and weights, thus providing a practical quality assessment tool adaptable to a variety of demands.", "authors": ["Jagdish Bansiya", "Carl G. Davis"], "n_citation": 801, "references": ["3b71d962-7fee-41fb-96b9-86f8260ba9b4", "57af1f08-da6a-466f-97a2-99e98a992768", "59dd769c-347b-4085-a5cc-7714999d440a", "ab5e7e72-cbab-4018-b2ae-459fff0a4b88", "d32786fc-ea8d-41f0-a803-5d00e550329c", "d4c3a0a8-80f6-4450-b678-639692543e25", "dbdf8e6d-42f2-4258-ac23-9b3682cea7d6", "e580b2d9-3e7c-4122-9932-f2cf985040cd", "ff03f243-f307-4c5a-969b-ed2235e10c3e"], "title": "A hierarchical model for object-oriented design quality assessment", "venue": "IEEE Transactions on Software Engineering", "year": 2002, "id": "ef8424b4-dbf5-4184-bdcb-c569f4ba28b9"}
{"abstract": "This paper formalises a semantics for statements and expressions (in sequential imperative languages) which includes non-termination, normal termination and abrupt termination (e.g. because of an exception, break, return or continue). This extends the traditional semantics underlying e.g. Hoare logic, which only distinguishes termination and non-termination. An extension of Hoare logic is elaborated that includes means for reasoning about abrupt termination (and side-effects). It prominently involves rules for reasoning about while loops, which may contain exceptions, breaks, continues and returns. This extension applies in particular to Java. As an example, a standard pattern search algorithm in Java (involving a while loop with returns) is proven correct using the proof-tool PVS.", "authors": ["Marieke Huisman", "Bart Jacobs"], "n_citation": 162, "references": ["055323bb-1b49-4141-829e-76f3d06766e3", "1765bad8-cb86-4dd0-a09f-34f379b7cb40", "357ef03b-3ad5-4793-a593-888b84bc6848", "37a740ee-af33-4ac8-8aee-a327fa51eb57", "65ce6248-373f-4f99-865a-77a9e4a602c5", "78827057-fb57-4979-93a7-b1189688f534", "7a3313aa-f30a-4f59-9d37-fcb48cc1eca8", "7f1dc63a-9064-4768-a30d-3383d52aa81e", "9af3a2a7-06b5-4100-843d-59d385300246", "b6d8eaeb-78c3-4e0c-9739-caa31d8a657d", "b95506c8-4dd0-4245-b96b-e65f076d7c84", "fd3c0d46-0bfd-4635-bf91-21eb295a9fb2"], "title": "Java Program Verification via a Hoare Logic with Abrupt Termination", "venue": "fundamental approaches to software engineering", "year": 2000, "id": "80ab79c1-34a0-4a15-b85b-37fdf063a4d4"}
{"abstract": "Many applications in such domains as computer-aided design require the capability to define, store and retrieve as a single unit a collection of related objects known as a composite object. A composite object explicitly captures and enforces the IS-PART-OF integrity constraint between child and parent pairs of objects in a hierarchical collection of objects. Further, it can be used as a unit of storage and retrieval to enhance the performance of a database system.  This paper provides a formal definition of the semantics of composite objects within an object-oriented data model, and describes their use as units of integrity control, storage and retrieval, and concurrency control in a prototype object-oriented database system we have implemented.", "authors": ["Won Kim", "Jay Banerjee", "Hong-Tai Chou", "Jorge F. Garza", "Darrell Woelk"], "n_citation": 326, "references": ["25b46064-0d14-4675-a8e7-ab20f1199e54", "37cb69a6-b727-4b53-91bb-44ebf64a0132", "8cd7f12b-af69-4535-8bf3-ab3054d64ff8", "b4d3eace-3201-48a3-8395-408616b884f8", "bcfa87fb-47c7-43c2-94c4-ffda08ecc9b7", "d9f21d08-1c20-415d-ad31-110bcad9e9c3", "e3ba6428-74ba-41c2-9bd7-148a2c6308a8", "f99c3014-e522-426d-b9c2-22d3d3bb2697"], "title": "Composite object support in an object-oriented database system", "venue": "conference on object oriented programming systems languages and applications", "year": 1987, "id": "f3f11528-372c-4e1f-9e64-29dfa3c4215d"}
{"abstract": "This paper presents a framework for detecting and tracking moving objects in a sequence of images. Using a statistical approach, where the inter-frame difference is modeled by a mixture of two Laplacian or Gaussian distributions, and an energy minimization based approach, we reformulate the motion detection and tracking problem as a front propagation problem. The Euler-Lagrange equation of the designed energy functional is first derived and the flow minimizing the energy is then obtained. Following the work by Caselles et al. (1995) and Malladi et al. (1995), the contours to be detected and tracked are modeled as geodesic active contours evolving toward the minimum of the designed energy, under the influence of internal and external image dependent forces. Using the level set formulation scheme of Osher and Sethian (1988), complex curves can be detected and tracked and topological changes for the evolving curves are naturally managed. To reduce the computational cost required by a direct implementation, of the formulation scheme of Osher and Sethian (1988), a new approach exploiting aspects from the classical narrow band and fast marching methods is proposed and favorably compared to them. In order to further reduce the CPU time, a multi-scale approach has also been considered. Very promising experimental results are provided using real video sequences.", "authors": ["Nikos Paragios", "Rachid Deriche"], "n_citation": 180, "references": ["417d1684-e1ae-4fc4-8505-74db0d282011", "82eb55e6-39a8-4968-8be6-e2bfbb439a40", "b2de99a5-01d1-4359-be11-10c2ce130a05", "c423adc5-2a32-46c2-b5f9-b73ba523a589", "f21d6bad-8b86-4a41-ac98-11778f1e9094"], "title": "A PDE-based level-set approach for detection and tracking of moving objects", "venue": "international conference on computer vision", "year": 1998, "id": "d5deaeda-e87c-42de-9d28-b18b29b13778"}
{"authors": ["Ian Horrocks", "Peter F. Patel-Schneider"], "n_citation": 50, "references": ["949e4ea6-7657-457f-8ae5-651d6eedb3bb", "da94bf1d-6565-4095-b02b-ff01d8cd3a1a"], "title": "Reducing OWL Entailment to Description Logic Satisfability.", "venue": "", "year": 2003, "id": "2e3c2728-dacb-4ad1-ae06-05c25a127a0b"}
{"abstract": "Mobility has become a new factor of complexity in the construction and evolution of software systems. In this paper, we show how architectural description techniques can be enriched to support the incremental and compositional construction of location-aware systems. In our approach, the process of integrating and managing mobility in architectural models of distributed systems is not intrusive on the options that are made at the level of the other two dimensions -- computation and coordination. This means that a true separation of concerns between computation, coordination and distribution can be enforced at the level of architectural models.", "authors": ["Ant\u00f3nia Lopes", "Jos\u00e9 Luiz Fiadeiro"], "n_citation": 41, "references": ["0010e0ef-1af7-4e96-8b52-9f7828f78791", "025d61f4-edd0-41af-aa91-3b2cfc5ec390", "25508aa7-03c7-4132-a881-4ccb2e34a086", "27b73cc1-03d8-445a-a6b5-cd73aa96f64f", "28c3496e-54c8-419c-a0ec-d4f91bf9dbd3", "42ca4968-70cb-4f5b-ab34-df392a502b70", "45bf941b-5765-4cfe-b912-e570c1aa99e7", "4c0a3d19-7842-4bd8-b68e-b15b4e74b642", "61394dbb-e4c4-4b87-82e0-f0bf109afa4c", "628b8c44-efa4-4b87-bce1-d876346e5fac", "7db36938-8082-4ce5-906f-9a1ebbce42f6", "855f93cf-1ece-4235-8677-130ba294ce62", "950d0926-c0ec-4615-857e-1efc855a4e58", "9b54a3e8-e4f9-4ec4-a384-c1f749f5f3eb", "9f965d2a-2cbe-4aee-8754-d8227ea46f51", "c051d87b-4760-421a-93e4-2305f7d29f38", "c127da7d-9be4-4f5d-9f81-d70b9e46a503", "c1300ce8-ed11-4dab-8334-b5aa810dd047", "c5b67474-e7d2-4198-a7a0-67f651e4c891", "d1c112a0-4efe-4661-9e82-ae4d5538df9d", "d96f6d0a-609b-4763-852d-50d9f785d8ab", "db74da93-6b92-4965-93bc-7f195afccc42", "dfa4da24-2c6e-4016-9a08-9885717126fa", "f6f6f4ba-9478-46af-bc9e-0fb7d8e5596b", "fad12f90-6625-4d4e-a298-a9fe25bbf077"], "title": "Adding mobility to software architectures", "venue": "Science of Computer Programming", "year": 2006, "id": "8244d82d-0aab-4324-9940-503e4af6516a"}
{"abstract": "The present paper introduces a very specific and pragmatic approach to segmentation. It is driven by a particular application context: in the framework of mixed-reality, Tranfiction (\"transportation into fictional spaces\") is designed to mix synthetic and natural images in real time while allowing users to interact in these input/output screens. Segmentation is therefore used to provide both the immersion and interaction capabilities. The former aspect is achieved by composing the image of the user within the projected virtual scenes, while the later is achieved thanks to basic body/gesture analysis on the segmented silhouettes. According to indoor or outdoor usages, two real-time techniques are developed. Results are analyzed with respect to the overall application, not only in terms of absolute quality but also in terms of perception by the users.", "authors": ["Xavier Marichal", "Toshiyuki Umeda"], "n_citation": 18, "references": ["fd7db136-592f-4877-a2c3-5e581378b131"], "title": "Real-time segmentation of video objects for mixed-reality interactive applications", "venue": "visual communications and image processing", "year": 2003, "id": "c78192ff-6157-4f64-9ab1-cc4d7073fed7"}
{"abstract": "Anti-windup compensators are widely used in control systems in order to minimize the negative effects of actuators saturations on stability and performance. But, despite recent theoretical advances in this field, the computation of such compensators is often realized by a trial-and-error simulation-based approach. An alternative method is proposed in this paper which is essentially devoted to the presentation of a new MATLAB copy  toolbox. This freely-available software implements a collection of routines which are based on recent results in anti-windup analysis and synthesis techniques. Moreover, a userfriendly SIMULINK copy  interface has been developed in order to fasten the definition of anti-windup design and simulation diagrams.", "authors": ["Jean-Marc Biannic", "Clement Roos"], "n_citation": 4, "references": ["470de320-b9f0-4044-97c1-1c2e2ba26100", "812731ea-3849-42f6-809d-cbc8d355d564", "8ca70f98-3d82-49bd-bdb8-095842e62ee8", "9c577691-8699-42dd-8a19-22837ee252cb", "a818ce47-7c76-4473-8eb9-95c4f665b46f", "c029a2a1-5771-4ad9-a830-0c18b264e541"], "title": "Introduction to AWAST : the anti-windup analysis and synthesis toolbox", "venue": "", "year": 2008, "id": "e8d3698e-fe4f-49e4-8cae-cc3592a987f0"}
{"abstract": "In the IBM CueVideo project we study various aspects of fully automated video indexing, browsing and retrieval. The technical aspects include audio processing, speech recognition, image processing and information retrieval. Equally important, however, is exploring user expectations and conducting user studies. We focus on the field of video for Training and Education, including Distributed Learning, Remote Education, and Just-in-Time Learning. This paper describes the use of audio processing technology, namely audio Time Scale Modification (TSM), for the novel application of fast video browsing and efficient video-based learning. The paper provides a brief overview of the CueVideo system, technical background of TSM technology, and the way it is being used in our system. The results of our usability study on the effect of TSM on speech comprehension indicate that TSM is very useful for fast video browsing.", "authors": ["Arnon Amir", "Dulce B. Ponceleon", "Brian Blanchard", "Dragutin Petkovic", "Savitha Srinivasan", "G. Cohen"], "n_citation": 88, "references": ["23595483-e796-4aa1-ac8e-8eb82cb7611b", "35218285-82b7-4e07-9777-d1cf9b7ac398", "42e500ad-02df-4f8c-899f-732aa91acffc", "4ecdda42-06c4-4562-809d-0093dcbc3dbd", "74592f74-33bc-40c5-a5a5-2a88539488ab", "9fa6ec4b-9a31-4448-b7ae-774f79fd5954", "a606f1ff-1005-43f3-bf52-a0f55b37eb23", "a7c2f5bb-0db3-4907-9902-9f1c5d5290f2", "b09f237c-f136-42f5-8f9c-653e2f921475", "c1cc9d96-1d9a-4931-a091-befc059a2d53", "db24cbf4-bb4a-40cf-8acb-dbb142640edd", "deaa8440-8de1-4dc1-9514-471c20026e7d"], "title": "Using audio time scale modification for video browsing", "venue": "hawaii international conference on system sciences", "year": 2000, "id": "9100a4c8-144e-4421-8267-a525b5787240"}
{"abstract": "Using three dimensional graph structure and DNA self-assembly we show that theoretically 3-SAT and 3-colorability can be solved in a constant number of laboratory steps. In this assembly, junction molecules and duplex DNA molecules are the basic building blocks. The graphs involved are not necessarily regular, so experimental results of self-assembling non regular graphs using junction molecules as vertices and duplex DNA molecules as edge connections are presented.", "authors": ["Nata\u0161a Jonoska", "Phiset Sa-Ardyen", "Nadrian C. Seeman"], "n_citation": 36, "references": ["43de3699-77eb-4557-9982-94cc6fb1f615", "98fb8746-f1a7-40fa-912b-acec64a2048a", "9c9d0aad-22a2-4bf7-8a00-01d73096a7cb", "a9bbe3f7-8f65-4e1c-b3ed-e3e57c2909af", "cc1ac4d3-7ab1-480d-9f93-b1ebb7629b54"], "title": "Computation by Self-assembly of DNA Graphs", "venue": "Genetic Programming and Evolvable Machines", "year": 2003, "id": "f26f607b-1f8b-42b9-bc34-b15fecf40c52"}
{"abstract": "Abstract#R##N##R##N#Wide range of applications such as disaster management, military and security have fueled the interest in sensor networks during the past few years. Sensors are typically capable of wireless communication and are significantly constrained in the amount of available resources such as energy, storage and computation. Such constraints make the design and operation of sensor networks considerably different from contemporary wireless networks, and necessitate the development of resource conscious protocols and management techniques. In this paper, we present an energy-efficient, scalable and collision-free MAC layer protocol for sensor networks. The approach promotes time-based arbitration of medium access to limit signal interference among the transmission of sensors. Transmission and reception time slots are prescheduled to allow sensors to turn their radio circuitry off when not engaged. In addition, energy consumption due to active to sleep mode transitions is minimized through the assignment of contiguous transmission/reception slots to each sensor. Scalability of the approach is supported through grouping of sensors into clusters. We describe an optimization algorithm for energy conscious scheduling of time slots that prevents intra-cluster collisions and eliminates packet drop due to buffer size limitations. In addition, we also propose an arbitration scheme that prevents collisions among the transmission of sensors in different clusters. The impact of our approach on the network performance is qualified through simulation.. Copyright \u00a9 2004 John Wiley & Sons, Ltd.", "authors": ["Gaurav Jolly", "Mohamed F. Younis"], "n_citation": 74, "references": ["0f1d0353-2c63-49e9-b29c-4d258cf2a445", "12f34183-7342-46da-8415-b04267a373dc", "1e4e8925-3328-4af5-be88-56eef2f6aa8f", "404bd423-3ffa-4af6-9aa6-6f7b3b050035", "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b", "570a3ffb-e95c-4947-924d-b1d760316471", "5d765053-ffcd-4eee-89fb-6db946b2762d", "6858fa05-89cf-48b9-ab78-507b868de4bd", "85352dec-58be-43db-a428-f3f574ff96ec", "90b80d6a-d4e1-445a-a42e-cf37ccc650b7", "9e063b41-0ada-4db8-8846-6e5153a0de55", "dfc9f1b0-a952-42e2-bc5e-c5d78c053d2d", "e6f7ed2a-1957-4ac3-ae19-c2ec358b9fd9", "febc63b8-9f14-4e2b-b7d9-bc3a20b02f02"], "title": "An energy-efficient, scalable and collision-free MAC layer protocol for wireless sensor networks", "venue": "Wireless Communications and Mobile Computing", "year": 2005, "id": "41a1652a-a8c1-441f-83e4-317eec0cbade"}
{"authors": ["R. Ravi", "Ajit Agrawal", "Philip N. Klein"], "n_citation": 86, "references": ["0275b2e6-4b18-4d13-985d-790b60271a14", "57ce8bc9-ff60-4cff-9599-756d2f3ee1ec", "63139dcf-11e2-4b8e-bcbd-ebd1f0511389", "8110182e-b1fc-455d-83ff-4d51a55d02a5"], "title": "Ordering Problems Approximated: Single-Processor Scheduling and Interval Graph Completion", "venue": "international colloquium on automata languages and programming", "year": 1991, "id": "1333bf86-48db-4166-a048-ce0df561dcb1"}
{"abstract": "Argumentation enables agents to justify their actions and to reach stable situations faster, due to the amount of information that is exchanged. Logic and, in special, Extended Logic Programming (ELP) provides a way to develop arguments which are mathematically correct and close to a working prototype. Logic-based argumentation exhibits a set of unparalleled features such as: adequacy to logic-based approaches to pre-argument reasoning, similarity to the human reasoning processes, reasoning with incomplete information, and argument composition and extension, among many others.Electronic Commerce (EC) poses new challenges to argumentation due to the presence of heterogeneous environments. The ontological problems raised by such environments have been approached by the use of eXtensible Markup Language (XML) frameworks. Thus, solving the problem of argument exchange in heterogeneous environments should build on such frameworks. CommerceNet's eCo framework provides a 7-layer framework on which an argumentation service can be easily built.", "authors": ["Lu\u00eds Brito", "Jos\u00e9 Neves"], "n_citation": 7, "references": ["1b7e92d9-7ff6-4109-9762-b29b3d524d54", "28ad042b-1a4b-4520-9b46-67c8aaf73b41", "41b016af-8de4-4e3d-837c-d2c7de4234ee", "4813df54-9b8e-4975-a216-7297634d240a", "4ef470ee-a43d-4bf5-a052-bd05fe6c5b26", "9694949b-6194-4a17-9521-6a1f58c3a411", "a3c72933-e4b2-45f4-bc5c-1a4fdd30e780", "a609d868-8ce8-4134-824a-1f2b441ab9d7"], "title": "Argument exchange in heterogeneous electronic commerce environments", "venue": "adaptive agents and multi-agents systems", "year": 2002, "id": "909235b9-c1ed-4611-bdc8-b32586be86ae"}
{"abstract": "Given a program P, an unfold/fold program transformation system derives a sequence of programs P = P 0 , P 1  P n , such that P i+1  is derived from P i  by application of either an unfolding or a folding step. Existing unfold/fold transformation systems for definite logic programs differ from one another mainly in the kind of folding transformations they permit at each step. Some allow folding using a single (possibly recursive) clause while others permit folding using multiple non-recursive clauses. However, none allow folding using multiple recursive clauses that are drawn from some previous program in the transformation sequence. In this paper we develop a parameterized framework for unfold/fold transformations by suitably abstracting and extending the proofs of existing transformation systems. Various existing unfold/fold transformation systems can be obtained by instantiating the parameters of the framework. This framework enables us to not only understand the relative strengths and limitations of these systems but also construct new transformation systems. Specifically we present a more general transformation system that permits folding using multiple recursive clauses that can be drawn from any previous program in the transformation sequence. This new transformation system is also obtained by instantiating our parameterized framework.", "authors": ["Abhik Roychoudhury", "K. Narayan Kumar", "C. R. Ramakrishnan", "I. V. Ramakrishnan"], "n_citation": 22, "references": ["022ab479-169e-4342-8608-3e8cded30da2", "182c90f7-b1e9-418b-9614-3a284a560a96", "23a2a7d0-fb7b-4467-9e4a-30debc754564", "58d7e1fa-ffc7-4487-85fb-aebcba51f3fa", "59102808-1d84-4e91-8bc5-80fd4cca410b", "9072f2e0-f8a8-4aa1-96cc-f295020a36f2", "91858b1e-5318-4dae-ad1e-02a118fdabc1", "ce462e4c-2ce8-4cb5-a36c-073deae2499e", "da018e85-960d-4e74-a31e-709ca376ed48"], "title": "A Parameterized Unfold/Fold Transformation Framework for Definite Logic Programs", "venue": "principles and practice of declarative programming", "year": 1999, "id": "a4ff89fb-0d88-4b71-95ea-b2f729c1c093"}
{"abstract": "Reduced communication costs can motivate programmers to use mobile agent technology. The authors analyze the use of mobile agents for filtering distributed information resources and present an approach for coordinating mobile agent dissemination that minimizes communication costs.", "authors": ["Wolfgang Theilmann", "Kurt Rothermel"], "n_citation": 50, "references": ["172f9f68-8417-43bb-8fe5-b377d569f6b6", "2750a7ac-fc78-4787-be59-22a6c93f4e03", "4a17f26e-5fe6-4078-ac52-c9eea264b25c", "51f18f84-2e08-4a85-93b1-d8b16557f726", "5320bc98-beb8-4b2c-b906-3a05df4e018c", "5fa0709f-7330-417f-8da7-3ab31d91da5b", "8664d60b-41e7-4cbc-b5c8-410a497ae98a", "942b6da5-c3e8-4b3e-a3aa-6c5bdb27461f", "986a7403-21f6-4158-8ccb-8736d6eafb0b", "b6f66651-2b00-4434-bbc6-90338db8f503", "e846a3cd-7c55-4695-a448-97caaab66ce0", "ff63c31d-92fe-4aac-8b8e-7cca090e60b3"], "title": "Optimizing the dissemination of mobile agents for distributed information filtering", "venue": "IEEE Concurrency", "year": 2000, "id": "c73088d8-5289-419e-9e65-0d6c7c5f12c9"}
{"abstract": "Mobile computing has been mainly utilized for point-to-point communication services, such as E-mail or FAX among people. To advance this field, the challenge is to encourage group communication by providing information that encourages community formation. As the first step towards this goal, we experimentally implemented the  community viewer,  which dynamically visualizes the communication interaction among people in the community. To design the community viewer, we introduced (1) the  party room metaphor,  which provides a virtual place for representing various community activities, and (2) the  reflector icon,  which reflects the activity of the corresponding individual while protecting his/her privacy. The static relationship among people and their dynamic activities are displayed in the spatial arrangement of reflector icons in the party room. We report our experiments on implementing and testing the community viewer in an international conference using 100 personal digital assistants.", "authors": ["Toshikazu Nishimura", "Hirofumi Yamaki", "Takaaki Komura", "Toru Ishida"], "n_citation": 24, "references": ["051f5254-819e-461f-8d0e-d974b586d56e", "59954a6b-0e1b-4b35-a587-694c79e0e106", "96bc4639-df62-49cf-af41-9565bb0a1b89", "a2f9d716-e3a3-4d09-8660-57c39b0c07ed", "b321beac-98a8-4dac-86bb-229202f019ed", "d56f7f7f-f734-4e85-b12b-ab2505d198f3"], "title": "Community viewer: visualizing community formation on personal digital assistants", "venue": "ACM Sigapp Applied Computing Review", "year": 1998, "id": "4a7e2e25-b243-4637-b874-b1bebca10569"}
{"abstract": "We expect a future where we are surrounded by embedded devices, ranging from Java-enabled cell phones to sensor networks and smart appliances. An adversary can compromise our privacy and safety by maliciously modifying the memory contents of these embedded devices. In this paper, we propose a softWare-based attestation technique (SWATT) to verify the memory contents of embedded devices and establish the absence of malicious changes to the memory contents. SWATT does not need physical access to the device's memory, yet provides memory content attestation similar to TCG or NGSCB without requiring secure hardware. SWATT can detect any change in memory contents with high probability, thus detecting viruses, unexpected configuration settings, and Trojan Horses. To circumvent SWATT, we expect that an attacker needs to change the hardware to hide memory content changes. We present an implementation of SWATT in off-the-shelf sensor network devices, which enables us to verify the contents of the program memory even while the sensor node is running.", "authors": ["Arvind Seshadri", "Adrian Perrig", "L. van Doorn", "Pradeep K. Khosla"], "n_citation": 585, "references": ["1dd8c68d-3b20-4171-9245-3a12c64c2838", "337b40b4-e924-4ed2-b86f-997e28535f16", "80c518ab-98df-4bc6-afe7-b7f868b1624d", "985955b2-c630-4b07-bd3c-1df38d93957a", "b87e9428-992a-4323-8dcc-f4129ca79c6e", "c48e73e6-928f-4ec2-9658-5d7055d739f7", "c5209079-6f19-463e-8470-fce6110a12c4", "e1ef8f50-df99-4d30-8224-0459bfccb40c"], "title": "SWATT: softWare-based attestation for embedded devices", "venue": "ieee symposium on security and privacy", "year": 2004, "id": "0d6e12db-e1f4-4bbf-ab8f-9435754609b3"}
{"abstract": "Non-parametric belief propagation (NBP) is a well-known message passing method for cooperative localization in wireless networks. However, due to the over-counting problem in the networks with loops, NBP\u2019s convergence is not guaranteed, and its estimates are typically less accurate. One solution for this problem is non-parametric generalized belief propagation based on junction tree. However, this method is intractable in large-scale networks due to the high-complexity of the junction tree formation, and the high-dimensionality of the particles. Therefore, in this article, we propose the non-parametric generalized belief propagation based on pseudo-junction tree (NGBP-PJT). The main difference comparing with the standard method is the formation of pseudo-junction tree, which represents the approximated junction tree based on thin graph. In addition, in order to decrease the number of high-dimensional particles, we use more informative importance density function, and reduce the dimensionality of the messages. As by-product, we also propose NBP based on thin graph (NBP-TG), a cheaper variant of NBP, which runs on the same graph as NGBP-PJT. According to our simulation and experimental results, NGBP-PJT method outperforms NBP and NBP-TG in terms of accuracy, computational, and communication cost in reasonably sized networks.", "authors": ["Vladimir Savic", "Santiago Zazo"], "n_citation": 50, "references": ["0e6a18ae-4600-43f8-97b9-6e7d7c0a8fc7", "1eadf267-28ed-4e6f-a5e9-6adf2b179b89", "2ff66c8e-0c07-4aab-9a4e-89569f1dbc3c", "3174d418-a4a9-47e2-b69a-d251bb0b0fe2", "38f6ec28-5c9f-409d-8868-f49c792c7cff", "3afead06-3b81-4104-8499-e0594b90a5b1", "3d159dbd-05c3-47ce-8b2a-41e83d124017", "400299f5-6b73-4ea9-b1cc-c4460f8b60c4", "409873f5-5da0-4771-8086-6116d697cb45", "51657f5d-8e60-4a5f-9797-d7bd64609284", "527187d3-e96a-4e67-b947-a5911f51804f", "5e64ac8c-9504-45cc-9be8-22e3eaf2e623", "5f67c0fb-fac5-4aea-8427-30c34800898b", "61d33af6-2ee6-4460-b3a4-22211cc52f45", "656df84d-f946-478c-ae6e-53d8c7c8283f", "743d5a70-0aab-4039-934f-6503ebbfb541", "76f32b95-b5b1-4762-a7f8-30bfb03b0df3", "790f294d-ed44-442d-bd71-3b54fad7f260", "99c38516-e79c-4b98-86ef-571ca361bc8d", "9dacb89e-3fd1-444b-b436-36410084152a", "af07f7a2-fbbe-4328-acda-87d336e5aa7f", "b29264f8-c622-46c0-abe5-07de4a4e8f7a", "c9725d67-08f5-4270-8242-725047bc16a6", "d1561346-65e1-41a0-98e7-b8d8ce832407", "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706", "d4023974-5418-4ec1-8b9b-16ee6bf9be37", "d8116977-0962-4d4d-832d-f9b0a095c75c", "df9fc4e4-69b1-4b09-8b2e-bbd6688a6f91", "e8a213a4-a353-479c-a216-43169ff21e3b", "eecdda1c-fa3b-4b9a-a3b2-44fe375a5941"], "title": "Nonparametric generalized belief propagation based on pseudo-junction tree for cooperative localization in wireless networks", "venue": "EURASIP Journal on Advances in Signal Processing", "year": 2013, "id": "aef9f3a7-9435-4961-95cb-28d5ef2e3876"}
{"abstract": "This dissertation analyses the computational properties of current performance-models of natural language parsing, in particular Data Oriented Parsing (DOP), points out some of their major shortcomings and suggests suitable solutions. It provides proofs that various problems of probabilistic disambiguation are NP-Complete under instances of these performance-models, and it argues that none of these models accounts for attractive efficiency properties of human language processing in limited domains, e.g. that frequent inputs are usually processed faster than infrequent ones. The central hypothesis of this dissertation is that these shortcomings can be eliminated by specializing the performance-models to the limited domains. The dissertation addresses \"grammar and model specialization\" and presents a new framework, the Ambiguity-Reduction Specialization (ARS) framework, that formulates the necessary and sufficient conditions for successful specialization. The framework is instantiated into specialization algorithms and applied to specializing DOP. Novelties of these learning algorithms are 1) they limit the hypotheses-space to include only \"safe\" models, 2) are expressed as constrained optimization formulae that minimize the entropy of the training tree-bank given the specialized grammar, under the constraint that the size of the specialized model does not exceed a predefined maximum, and 3) they enable integrating the specialized model with the original one in a complementary manner. The dissertation provides experiments with initial implementations and compares the resulting Specialized DOP (SDOP) models to the original DOP models with encouraging results.", "authors": ["Khalil Sima'an"], "n_citation": 15, "references": ["0110ac7e-ab13-4bc5-8695-bd5fc03a282a", "01de859b-ca0b-4c99-b1f2-552038becb70", "038d2cd7-728e-4437-9ba3-48c955f1217c", "0c35895c-9f13-4678-80f3-9310652446e0", "0e802246-bbf3-4e78-b31e-1863d10ea5d8", "13d822dc-44f0-41bf-b111-c578c476eff8", "15e2f3a7-d05f-4fb9-9e4c-cc85220dfc58", "180844de-c4e0-41c5-a335-0ba9e4a4ce2d", "236370fa-df44-4ead-bf3c-73fb90876df5", "23c17580-c9d7-4b7e-aa0f-d815bb74fd26", "25b75899-1e9e-4ef6-bf15-0c941aeddf17", "3048db9a-58e9-4ac2-9a63-2cc1d23f9259", "33094d83-148a-4f35-8f7b-6caf84d5b770", "3595fa71-68db-476e-9cb7-ad6ece6f446e", "415a2d69-2015-42e0-8dc5-589676d65aa7", "43a9097c-b66d-4ede-a326-5efb8b241b4a", "472ac1e6-d556-456a-9c79-d8e243cf4a72", "4ec36265-5224-4162-8c3a-aba0d36d2a23", "584bb07d-c9f1-48ad-9159-f41fe1dfdbe2", "654f29e1-52a4-4a7c-9495-3a97cc8c4fd5", "66c5269e-d948-4de6-9715-1e467460592c", "689fff30-25d7-442b-80b1-b0fc3051b796", "80fa2024-e935-44a6-8e36-39af74a76dfe", "81d5fbdd-5030-4505-92d2-e0a16cf93919", "8264330c-b1e4-4ec1-88b8-cb03d0407d5c", "834c2723-a300-4d85-88e4-747aa9ced723", "8ecb8698-52ea-4ca2-80fa-705f4121e26a", "8ed78f97-f118-457b-a994-b027fef4e511", "97709fc2-ed01-48ac-8e12-2eda51170cec", "a206f98c-b2d0-4857-a0c0-3dfeb03c99cc", "ac237969-3fd5-4303-83b7-a67e02afe976", "bf222f4d-8086-4b42-b758-86f9e2013e9d", "c10f971c-d725-4aee-b747-cafc29ba4f06", "c9f17f31-98d0-4d82-aee5-c1ade4c0aa34", "ce014776-c6c6-464f-ae2b-86ce933ab5ac", "d67da751-078c-48ba-9871-819e4e0c5526", "d6f238ef-431c-4117-a101-0f91f95446aa", "daf63e8f-3c6f-46ba-96a0-0e5d8bf8d668", "df6b02f0-d263-46e0-9a96-93d91cb8bcfb", "e3971331-d654-44f2-9cf7-e2806d0c1d21", "ea3b4551-ba70-4934-af40-4e44228b4ae6", "ef4d7453-018e-4d2a-884a-f5be20756be8", "efc0f8d3-3633-4e89-95de-18ffa0efddde", "f5132ee6-d57b-40e4-b7e5-c5c3a56ce7b0", "fb2a6bd1-6db8-4ec5-8da2-f9ea07019cfc", "fbc3d782-27f7-4174-a174-cc4de8292b58", "fc0730cf-b701-43c2-87e8-e19965dce046"], "title": "Learning Efficient Disambiguation", "venue": "arXiv: Computation and Language", "year": 1999, "id": "d7e8b4a0-751b-461e-af3f-8a6a71a1b2f7"}
{"abstract": "Various hard, fuzzy and possibilistic clustering criteria (objective functions) are useful as bases for a variety of pattern recognition problems. At present, many of these criteria have customized individual optimization algorithms. Because of the specialized nature of these algorithms, experimentation with new and existing criteria can be very inconvenient and costly in terms of development and implementation time. This paper shows how to reformulate some clustering criteria so that specialized algorithms can be replaced by general optimization routines found in commercially available software. We prove that the original and reformulated versions of each criterion are fully equivalent. Finally, two numerical examples are given to illustrate reformulation. >", "authors": ["Richard J. Hathaway", "James C. Bezdek"], "n_citation": 264, "references": ["2af26c56-4f35-494d-8921-b0174dc41589", "3f241300-4bbb-49d7-94e0-2948624da446", "42c953f1-3bae-481f-b683-3d4b22fa8184", "53c1a55b-36dc-4f3a-bcba-88c7b6c4b513"], "title": "Optimization of clustering criteria by reformulation", "venue": "IEEE Transactions on Fuzzy Systems", "year": 1995, "id": "3902e39c-0e6e-4df2-abb8-caee09a8f543"}
{"abstract": "The goal of this paper is to review the state-of-the-art progress on visual tracking methods, classify them into different categories, as well as identify future trends. Visual tracking is a fundamental task in many computer vision applications and has been well studied in the last decades. Although numerous approaches have been proposed, robust visual tracking remains a huge challenge. Difficulties in visual tracking can arise due to abrupt object motion, appearance pattern change, non-rigid object structures, occlusion and camera motion. In this paper, we first analyze the state-of-the-art feature descriptors which are used to represent the appearance of tracked objects. Then, we categorize the tracking progresses into three groups, provide detailed descriptions of representative methods in each group, and examine their positive and negative aspects. At last, we outline the future trends for visual tracking research.", "authors": ["Hanxuan Yang", "Ling Shao", "Feng Zheng", "Liang Wang", "Zhan Song"], "n_citation": 476, "references": ["00fb8632-b5d6-4635-bb8a-32253e277d57", "01be4836-749a-43b5-8dd2-4c56a047ee65", "0289a1a7-579b-42a8-8795-45bb59850e67", "050c56f0-4365-475b-863b-2f2338b1c7a8", "05c99d31-32c1-431d-99ce-0dfcd6ca805c", "06717cdf-1318-4ec2-8248-b37a2e8d27ef", "0ae61c32-f756-46b3-8932-b40313e48939", "0ae63e30-e2ae-41f1-94e7-14f2a5867a0c", "0b622dc5-655a-4cc8-a11f-b80f7754bd12", "0c91906e-3357-4d73-beaf-b18c0733a725", "0db2b002-ae2f-4032-b702-7a0f001184c7", "0e990b95-b398-403e-aaf1-8f1bc1198f11", "0fc4e5cf-35a3-4d79-9b5a-eb2ef2bb1cb4", "1198ea86-66cb-43a6-9540-07d3bb2da292", "1378b67e-57fe-4213-8ea8-2c381ff8707d", "1804fbfc-2ae4-453d-a4e2-c8ab074ad3f7", "1b40cd27-25d0-4c28-b406-ce88578beebb", "1dd7809f-069a-44a4-99e2-fb49719005ee", "25a86c3c-a09c-4a75-83dc-b3bcb386f8ac", "2a885d85-88fb-4e36-ad37-2a20b46f166b", "2c77b91f-c508-4bf2-9a27-b30c36f54bcc", "2d6c9f60-ea78-44a8-b5f9-6964575dd196", "2d827f70-c656-4f00-8ca9-bbcaf8de2f03", "2d9e409d-0bd2-4405-9ca2-9d858d8d9a9a", "32378409-c3aa-4ba2-950f-8e06d2d5d96f", "32948877-48a6-46a0-bdef-a1895952d4c7", "33523940-e8f9-455e-b256-272b176bde57", "344563bf-8da7-4d8a-88e6-598033528547", "3593ec78-983b-424c-b46c-994d10d72c90", "38e55a7b-d9b2-4338-8820-9e07b9fc54ab", "39a43e5f-f376-4bd3-873a-50407f5e3c56", "3bd33d67-1ec1-4209-bbf5-404b104c520a", "3d306a4d-d011-4074-b14e-5436176df420", "3ed17ffd-b416-470a-973a-77d7085a3503", "400299f5-6b73-4ea9-b1cc-c4460f8b60c4", "41bbef85-2f0b-40c4-ada3-5d0d5ab39ffd", "4763f653-5be4-4d80-947d-1394c5b63f85", "47b09a19-0c16-452b-8459-4348cde02256", "4afe4481-1694-4147-ac59-13d2ad6bfdac", "4b4c59f7-6cb0-477c-95c1-cf2c1e3f1822", "4bec3b26-94f6-40f7-a77b-59e4f8c5fb7f", "4d94dde2-08b3-4b7e-9299-b408eaa871d8", "4db6c10f-b1bb-49c2-b00c-bca8425aa979", "4f446740-bfa5-456b-b8dd-b78371b18ca1", "52dbf565-81ab-439e-a9af-6c4d6ae302f8", "53242913-3362-4355-a081-f4b53b4e9641", "53d11bac-0032-40a4-b814-3d40a20345b7", "544fd72d-a0da-4ba9-8d78-48c2ce8a3f5e", "55238f17-071f-42a8-bcab-eeb5bf5f548e", "55709fac-e4b6-4550-bd85-f57c131d24c5", "586d57c3-6eac-4511-b9b8-6b16ac93d14c", "59b31740-3fbc-4672-a1cb-de34c05f08cf", "5f146a05-3f37-4bc7-9112-e858b5fe4794", "6018a516-8149-4bce-bc33-5449d86e58c2", "6071bba1-9f00-4e8a-b588-86f2727bb395", "62a46780-e1d9-4186-babe-6179735d785e", "6421b691-4ea2-4b53-9705-64cd5ca65d7d", "665bfb21-ee40-4dfd-90c6-9bfdb33c9e39", "6ad0e1b1-4a8d-4d9e-8404-6fb2a01194de", "6b466cbb-14e4-4aa4-8396-166775939a2d", "732f1cb3-c0c3-40de-bdd0-40de75ec3a66", "73b2e4e8-4f95-4764-8673-929f30176bef", "767319b3-1d27-402f-b411-7a158ad19ae5", "76f22025-9e92-44cd-96ca-8675372ed61d", "802974dc-d0dc-421e-b0de-65bb5a90aac3", "8174913d-2c94-4344-9fd5-383246be7cb3", "82e1820f-4a9c-4769-bd38-2aff2732acb1", "87709380-478a-4767-a10a-cd273fde19a1", "87853d33-64f5-4585-8596-39d041cfac07", "910a223b-1f53-4100-a600-6cce47c85f1d", "9253be8c-ea36-467d-97d7-263ae83d031a", "93f0cbdd-c2a0-4e9e-9342-d8c8ab8e37c0", "9865c15a-f4e9-4b5f-a53d-319b31aaf8a2", "98916c1f-4030-4ac0-a186-2e2e60188701", "98c55614-da23-4dba-852f-65fce0705a22", "9a3e0797-e011-450e-8f61-16e88b378c50", "9b503f5f-ae39-4ad7-8833-e8cbb4946069", "9b8a49b5-a5cb-4c61-8c60-3bde6d310009", "9d3d6b5b-3ce4-4503-8aa7-c596dd65644f", "9ec391e9-e310-4908-965d-a480d72fd80d", "a1030981-404f-4091-a056-c4a3178e9642", "aee9cf96-5ca3-46b4-a654-5e54ad5be9bb", "aff35665-ad99-4174-a688-536680d61788", "b596a763-3ba9-4c9e-87a6-db9d1229b2ac", "b7e1a921-5b8a-401d-896e-7bd841a1e5ae", "baacc24e-3c39-4df8-8404-b1a3d9f0db1e", "bbe9d7f7-6a0f-4a40-a5db-cfe90b5124ee", "c0c66769-d283-489a-82db-832a2f32687e", "c455fb04-4566-4648-ad6f-3cf2245e507c", "c5360ce9-89ea-494f-b58e-59c76568823b", "c9341997-fe49-4d96-9f98-613fa9624f47", "ca7322cd-eb60-4663-b358-ad05f3102df7", "caf1e41b-77f0-4be9-adb6-3f92322b6d0e", "cb66e49d-077b-4adf-873c-2bc39f78fca6", "cce9db4c-00e2-49a4-b9d4-126c78623091", "d4096c82-a4ad-41c8-a3c6-4aa2924dfcbb", "d4cbee29-75fd-46ea-aecd-07f6906ae2d7", "d7f51f52-f7c3-4129-bcd2-59178ede073a", "d8116977-0962-4d4d-832d-f9b0a095c75c", "d8fe555f-d2ab-4a08-b9e7-ad7e98bab1ff", "d9921be4-51af-4a78-a27a-054c0d70cbdd", "dc530f5b-3d53-4a76-b344-d17d8ebb6dba", "dd096bb0-7c91-4c01-93a2-e9ffeb89705c", "dd152af3-53d0-4881-8ea4-5bf34c50e328", "dd83785a-dd19-41e3-9b25-ebabbd48d336", "e2204e92-e6dc-4884-9bbc-200029491fc7", "e3fcf74c-8254-4d0e-9404-219399bb0bea", "e649a9fd-f6d9-4aac-b428-29b82c20a484", "e9f5e156-5766-4494-ae9a-33ffbc4ef53b", "ea17814c-e763-457e-bdc1-80f0eefbd885", "ed835ca3-7120-4646-afaf-20c04a57c698", "ee9a02c2-f9a5-4b0a-8980-1625cb464f22", "f225f439-4389-4312-a503-f8c1b0aa02de", "f451ab11-53c2-4a0b-ba7d-be655ff3675d", "f5fa7f4b-cc14-42ce-8e8d-9bc4e6d9ab54", "f6436085-506b-4278-ad44-11ed2464fe84", "f73902f6-b895-4452-b2e9-cb5e067e3f9c", "fb366046-0620-4e4e-a7ac-409d8296a0ac"], "title": "Recent advances and trends in visual tracking: A review", "venue": "Neurocomputing", "year": 2011, "id": "923af80d-0396-4d1d-8b6d-b809fe37a96a"}
{"abstract": "High-level control of dynamic positioning systems on marine vessels using hybrid controller is developed to extend the operational weather window for marine operations to harsh environments. The types of hybrid controller considered are multi-output PID controllers with position measurements, and multi-output PID and acceleration feedback controllers with position and acceleration measurements. Numerical simulations and experiments in addition to stability proof are conducted to verify the proposed hybrid-controller dynamic positioning system in varying environmental conditions from calm to extreme seas.", "authors": ["Trong Dong Nguyen", "Asgeir J. S\u00f8rensen", "S. T. Quek"], "n_citation": 107, "references": ["0302cab5-675b-4dff-a8e9-08183888ebae", "3b775690-afd8-4c7a-bc03-8505d30f7c4e", "c1b919ee-e96c-4ab4-998f-a98991442c0c", "ced8a2a3-408a-4b76-a8af-446b17bc74dc", "d9d11b15-4d7a-4b4c-b062-61f8a869082b"], "title": "Design of hybrid controller for dynamic positioning from calm to extreme sea conditions", "venue": "Automatica", "year": 2007, "id": "28108bf4-5198-478d-9f9f-05b1570d7563"}
{"abstract": "A cooperation paradigm and coordination protocol for a distributed planning system consisting of a network of semi-autonomous agents with limited internode communication and no centralized control is presented. A multistage negotiation paradigm for solving distributed constraint satisfaction problems in this kind of system has been developed. The strategies presented enable an agent in a distributed planning system to become aware of the extent to which its own local decisions may have adverse nonlocal impact in planning. An example problem is presented in the context of transmission path restoration for dedicated circuits in a communications network. Multistage negotiation provides an agent with sufficient information about the impact of local decisions on a nonlocal state so that the agent may make local decisions that are correct from a global perspective, without attempting to provide a complete global state to all agents. Through multistage negotiation, an agent is able to recognize when a set of global goals cannot be satisfied, and is able to solve a related problem by finding a way of satisfying a reduced set of goals. >", "authors": ["Susan E. Conry", "Kazuhiro Kuwabara", "Victor R. Lesser", "Robert A. Meyer"], "n_citation": 346, "references": ["3a2ca8c5-400c-4497-803b-82fe9af0f78d", "604822ac-cb3d-4f6b-bec0-735addd21851", "735b4bb6-c6d2-41ff-9fcb-060179cb84e3", "e39b641b-105c-427d-8209-1ddb37645750", "ec94ce2e-d066-4783-b7dd-ec7af6c64c6c"], "title": "Multistage negotiation for distributed constraint satisfaction", "venue": "systems man and cybernetics", "year": 1991, "id": "66829cc0-5092-4541-853e-cb4d18c9c573"}
{"abstract": "Association rule mining, studied for over ten years in the literature of data mining, aims to help enterprises with sophisticated decision making, but the resulting rules typically cannot be directly applied and require further processing. In this paper, we propose a method for actionable recommendations from itemset analysis and investigate an application of the concepts of association rules--maximal-profit item selection with cross-selling effect (MPIS). This problem is about choosing a subset of items which can give the maximal profit with the consideration of cross-selling effect. A simple approach to this problem is shown to be NP-hard. A new approach is proposed with consideration of the loss rule--a rule similar to the association rule--to model the cross-selling effect. We show that MPIS can be approximated by a quadratic programming problem. We also propose a greedy approach and a genetic algorithm to deal with this problem. Experiments are conducted, which show that our proposed approaches are highly effective and efficient.", "authors": ["Raymond Chi-Wing Wong", "Ada Wai-Chee Fu", "Ke Wang"], "n_citation": 68, "references": ["16cfe3ba-63ae-4048-86a5-4d926372741d", "1bb127d4-4c69-4e3d-809e-48e7c2826ab0", "1fe699bc-6db9-45b9-a769-e951d1d2bc60", "24188611-1420-4eb7-8ca3-3466ef9b7f0a", "34b7e270-80d7-46d5-a6f1-e50087a8d045", "3d8be443-b3ac-4d83-8125-d2cd0e0ef394", "40fe27e5-e613-4eee-9c65-698a1db2c001", "5095491d-1ed7-414f-8082-58639d406b7b", "537f4b0f-8ed1-4abf-a3c9-d01480c766b3", "5a9d8711-4599-410b-bcfa-8e437a5a32ab", "8103ce41-33c5-43eb-91e3-c0c6566651d0", "8f9e92cf-f266-4e51-807f-c098a260a0dc", "b442aff7-d7ce-4af9-8b6b-783aefc82625", "c4710c73-497d-44f0-ae10-64613eca18d4", "cc72f406-7f47-43bd-90df-9efe42aac82b", "ecd6a845-8439-49b0-abe8-f71fff81da23", "f49e5508-8202-44bc-a2b8-2c7a6522459f"], "title": "Data Mining for Inventory Item Selection with Cross-Selling Considerations", "venue": "Data Mining and Knowledge Discovery", "year": 2005, "id": "d496a2e4-a0cd-4b80-aaad-e79c36a0d55e"}
{"authors": ["Edson Alves de Oliveira Junior", "Itana Maria de Souza Gimenes", "Jos\u00e9 Carlos Maldonado"], "n_citation": 1, "title": "A Meta-Process to Support Trade-Off Analysis in Software Product Line Architecture.", "venue": "software engineering and knowledge engineering", "year": 2011, "id": "6dfbf42e-506f-49f7-b688-46793cf93ef9"}
{"abstract": "A complete and detailed (full) Design Rationale Documentation (DRD) could support many software development activities, such as an impact analysis or a major redesign. However, this is typically too onerous for systematic industrial use as it is not cost effective to write, maintain, or read. The key idea investigated in this article is that DRD should be developed only to the extent required to support activities particularly difficult to execute or in need of significant improvement in a particular context. The aim of this article is to empirically investigate the customization of the DRD by documenting only the information items that will probably be required for executing an activity. This customization strategy relies on the hypothesis that the value of a specific DRD information item depends on its category (e.g., assumptions, related requirements, etc.) and on the activity it is meant to support. We investigate this hypothesis through two controlled experiments involving a total of 75 master students as experimental subjects. Results show that the value of a DRD information item significantly depends on its category and, within a given category, on the activity it supports. Furthermore, on average among activities, documenting only the information items that have been required at least half of the time (i.e., the information that will probably be required in the future) leads to a customized DRD containing about half the information items of a full documentation. We expect that such a significant reduction in DRD information should mitigate the effects of some inhibitors that currently prevent practitioners from documenting design decision rationale.", "authors": ["Davide Falessi", "Lionel C. Briand", "Giovanni Cantone", "Rafael Capilla", "Philippe Kruchten"], "n_citation": 28, "references": ["0e3021d1-e61b-4692-9b7a-8f18e5d794d0", "0f2f794c-12e3-4377-9be1-f8e7b7c779c0", "12c2355f-12a1-4e82-a287-28455ec428bb", "183eb84b-3be6-4faa-8f74-91b85ecfbfd7", "2ac9225a-232d-4694-815e-530d8558fa63", "2e3f0264-2e6e-45aa-9e2e-3be078027aba", "2ea8b43a-4431-484f-a5bb-355710c65203", "37368283-7520-4840-a268-4f15fae71c93", "3be10bda-1cef-4dd0-bb9c-adfbadb0b730", "40f450ed-f816-42e4-8825-b076bb886541", "477ddef5-f405-4749-8876-8fab949078d9", "484c25cf-f8f6-417a-93eb-e0e80b0edb3e", "5141258d-d4a9-40f8-a694-526e78c6d0b1", "529da776-31c3-41b9-83b6-f74920701c3c", "55329090-1481-48cd-9744-14a42f80bb94", "5d2f5f96-4970-4360-95a3-796f820cd614", "64f9caaa-6e34-4195-8272-13aacabbb2d1", "6a87eb31-9ca9-4677-a681-478c12a776d2", "747b7ad8-96dd-493a-8888-d9ecf57e8c6e", "79f53881-467f-4e3d-9a8b-467de496ff4c", "7d3bd76b-3539-44e3-bc38-551d0b518ba6", "86f68007-3bbb-497c-bce8-43e62e2dae90", "87eb02e6-dd3c-40cd-8c81-e77fabb1d21d", "92b361bf-1a8f-40e3-b1ae-25701d3f2cc8", "946be971-6e11-40f5-baaa-bc36f9ac72d3", "97f74ec8-2e42-4272-a035-88103aba8923", "9dbca92d-e80b-455b-a890-01d6e7efc8e9", "a1a5a9a2-bcf6-485b-8b21-42861c4e096c", "b0581eaa-31da-4749-ae09-2e9c13fd1c4b", "b4cac501-1d54-49d4-938b-74fe93fd615d", "b6119300-30d7-4d88-bee6-11bcf280ac3e", "b75c0b61-7d06-4587-be47-10ca339751c8", "b9e9605c-93f2-477a-9a4d-b4941c2e5700", "be71c5f9-0333-46b1-9990-c926a5b7b389", "cb381aa6-ae20-4acf-8ea7-9f28645e275f", "cbeb3214-aaef-4f40-86f5-31cc6500e0f3", "d3f504cd-3381-4bba-b2e2-0cb21e364a71", "d6fe35ef-3c46-4caa-8a76-3a956a181090", "da3d9db0-f713-4a30-88e8-52d5066bc07c", "eb612ce6-813a-42a6-8e64-c7c99ab1d4b8", "ec30c7ce-74a0-473d-8162-ef61b4c2dc53", "eef34eab-88fd-448d-a9ec-eff280261c06", "ef723311-5d50-4552-aa79-678889ae6786", "f165d960-af33-4588-8319-b90fce361d80"], "title": "The value of design rationale information", "venue": "formal methods", "year": 2013, "id": "6a70d041-6c33-4fad-8e1a-287b6b6bfa8a"}
{"abstract": "Interface definition languages (IDLs) serve to specify module and interface names, as well as operation signatures. However, IDLs lack a means to express aspects, such as synchronization constraints, pre- and post-conditions, invariants, quality-of-service annotations and real-time annotations. We develop a framework to specify the IDL and a given IDL extension in a combined modeling language based on XML. We show how this specification can serve to obtain tools to process the extended IDL. We study this approach along the lines of the OMG IDL and the CORBA middleware platform. The specification of semantic aspects and the specification of the IDL is based on XML document type definitions.", "authors": ["Hans-Arno Jacobsen", "Bernd J. Kr\u00e4mer"], "n_citation": 16, "references": ["335658fe-c51d-4dcd-9d4f-659403422e53", "65a3e0af-4a35-4267-bbf9-c6a6413e5bb3", "68f04e42-d62e-4562-a4be-685eabd866cf", "6cc148bb-0321-40b3-bad7-9c48a69ff1bf", "726a2730-1df7-4e37-906e-4226c2043207", "8d9d39c8-051d-47a1-ae45-0a8997ffb402", "949266eb-25fc-4c13-b71d-1a0a6523ecd9", "a88ee590-a43b-4046-a574-eeb81f9ebac9", "a9e96d54-2e84-484c-9a84-d7c648034f8f", "b56ecdc3-6a75-4fce-b8ae-820363d77753", "d4f6ae69-94c0-4ca5-b975-818a094b71b8", "d6285e34-13fa-4327-b4f9-203181baa8c6"], "title": "Modeling interface definition language extensions", "venue": "", "year": 2000, "id": "c73190b6-7a09-4d56-b8f0-29b121cd5a92"}
{"abstract": "How can a RFID (Radio Frequency Identification Devices) system prove that two or more RFID tags are in the same location? Previous researchers have proposed yoking-proof and grouping-proof techniques to address this problem - and when these turned out to be vulnerable to replay attacks, a new existence-proof technique was proposed. We critique this class of existence-proofs and show it has three problems: (a) a race condition when multiple readers are present; (b) a race condition when multiple tags are present; and (c) a problem determining the number of tags. We present two new proof techniques, a secure timestamp proof (secTS-proof) and a timestamp- chaining proof (chaining-proof) that avoid replay attacks and solve problems in previously proposed techniques.", "authors": ["Chih-Chung Lin", "Yuan-Cheng Lai", "J. D. Tygar", "Chuan-Kai Yang", "Chi-Lung Chiang"], "n_citation": 55, "references": ["42b5cbb9-c3c0-45e8-823f-8f360a933032", "7b6e5376-83f9-4a32-9481-090078137db6", "a53f70c6-7997-4a1c-a518-4a3c84ae0f2d", "dade127f-99ef-40d9-be5f-fafce31be297", "e4b523da-7c9f-4fc3-99a7-7a9de1b151e2"], "title": "Coexistence Proof Using Chain of Timestamps for Multiple RFID Tags", "venue": "asia-pacific web conference", "year": 2007, "id": "1d0f451f-d512-4011-8705-9feafcc0b73c"}
{"abstract": "The aspect-oriented programming (AOP) approach is supposed to enhance a system's features such as modularity, readability and simplicity. Owing to a better modularisation of crosscutting concerns, the developed system implementation would be less complex, and more readable. Thus, software development efficiency would increase, so the system would be created faster than its object-oriented programming (OOP) equivalent. An empirical study of a web-based system development is carried out to examine AOP against OOP approach with regard to software development efficiency and design quality. The study reveals that the AOP approach appears to be a fullfledged alternative to the pure OOP approach. Nevertheless, the impact of AOP on software development efficiency and design quality was not confirmed. In particular, it appeared that design quality metrics were not significantly associated with using AOP, instead of OOP. It is possible that the benefits of AOP will exceed the results obtained in the present study for experiments with larger number of subjects.", "authors": ["Lech Madeyski", "Szala"], "n_citation": 50, "references": ["07ebe43c-f4ff-4093-a247-4d298c74f527", "10e8e35f-7774-47ea-a5d9-52175b5cd771", "2295cb3e-109a-4bac-869c-d3edfb6a0fc5", "283a47a0-f895-4185-b433-fe7a35408aca", "33e516aa-0bc6-4200-a6e3-034a3fb244a1", "367de6c1-e09a-4ea4-83f9-c07bdbe769e4", "4a73c537-573c-44e6-9212-76e1e9f89e56", "4d125692-cdb1-45ff-9f70-55bba7493bdf", "6f83eeda-ef9e-4164-a7a3-53b3139e94fb", "6fafa162-bb5f-409e-a204-a444fc2bc20c", "845b8566-3003-4c39-afb4-f299e027f6aa", "8b57a3d5-2a29-4cd8-9a8b-ab04ea2fbcf2", "c9915ad0-21f7-4f59-9360-203a1097c1d7", "cec76223-64d9-4bb2-bee3-7d561edeeb44", "d32786fc-ea8d-41f0-a803-5d00e550329c", "e3ca3686-b725-4f9e-b82d-4e7006c40fc4"], "title": "Impact of aspect-oriented programming on software development efficiency and design quality: an empirical study", "venue": "IET Software", "year": 2007, "id": "6254399f-945f-46c3-9213-8089890bd78d"}
{"abstract": "One of the challenges in ubiquitous computing is that of mobility, which typically requires interaction between intelligent environments in different domains of administration. We present a highly distributed and collaborative system that enables context-aware applications to obtain context information about mobile entities (users or devices) independent of the domain that produces this information. The added value of the system is that it enriches the amount of available context information about these entities in a way that is transparent for applications. In addition, the system shares context information across domains in a controlled manner by taking privacy policies into account, both of the mobile entity as well as of the domains it visits. We discuss the system's architecture, its implementation, and the way we deployed it.", "authors": ["Cristian Hesselman", "Henk Eertink", "Martin Wibbels", "Kamran Sheikh", "Andrew Tokmakoff"], "n_citation": 11, "references": ["005d4d3e-2859-42ed-a7e9-9d34488b960c", "0ba721cb-3f8c-44de-9585-1b146696ebb2", "0edcbac4-3680-493e-a1ed-2c0c810a5fee", "3df8edb8-f22c-4780-a491-3843dce5d186", "5b4ee599-0c56-4dec-b3c5-4120a41c1837", "9aeb6334-e2e1-4ecb-8013-302cb3946eae", "a5b54d70-d144-4164-8812-1196d80ff0e5", "b3c27fc9-0004-4f00-a875-034612fc2681", "bcad230e-8ec2-405a-ab78-85609f1c44df", "c9b0efe5-e7cc-421c-86c0-d8debfa0fda2", "da1cb7b5-5c19-47fb-88c2-df743d7df6c3", "e2593748-76d0-41b2-ac6b-1f72abea0652"], "title": "Controlled Disclosure of Context Information across Ubiquitous Computing Domains", "venue": "international conference on sensor networks", "year": 2008, "id": "70c1e06c-822e-420c-9760-e8e73ce14f89"}
{"abstract": "Service-based wireless devices like wireless telephones require users to interact with aspects of the technology beyond the hardware and software of the handset. By entering into contractual relationships with service-providers, and by using network-based services, users interact with a larger  system ---one that has social and technological components. The operation of the wireless telephone requires the assimilation of heterogeneous sources of information from the device manufacturer, sales people, customer service representatives, marketing people, and members of the popular media, among others, which can easily confound users' understanding of this new class of technology. Opportunities for usability problems therefore scale beyond the handset, as do opportunities for better design. We report the results of a study of 19 novice wireless phone users who were closely tracked for the first 6 weeks after service acquisition. Taking a technology-as-system analytical approach, we describe the wireless telephony system as four socio-technical components: hardware, software, \"netware,\" and \"bizware.\" This particular organization of the system is intended for the practical application of designing for usability.", "authors": ["Leysia Palen", "Marilyn C. Salzman"], "n_citation": 103, "references": ["29f08f1d-565b-47dc-90d7-b1bef4e72a4f", "73e642f0-e13c-424b-82b9-1a9fc43175fe", "85c6e39c-6aed-4635-906e-56d16e52754f", "a8920e4d-005b-46c4-97b0-d955b336474b", "a9c6434c-e06e-4073-9267-09ee3feb9aa7", "c349c23a-ee8e-4e1d-9eb4-5490d05719d1", "e804bd00-63f2-40a4-8991-3c3681036108"], "title": "Beyond the handset: designing for wireless communications usability", "venue": "ACM Transactions on Computer-Human Interaction", "year": 2002, "id": "901e2ac3-c555-424a-8137-b4f096d7e1ea"}
{"abstract": "In this paper a method for the automatic generation of pronunciation lexicons including multiple word pronunciation is presented. This method is based on the application of a set of rules for grapheme-to-phone conversion for Mexican Spanish. The generation of multiple word pronunciations is based on the introduction of pronunciation variants by applying allophonic rules. The performance of a speech recognition system using a pronunciation lexicon with and without multiple word pronunciations is also presented.", "authors": ["Esmeralda Uraga", "Luis Alberto Pineda"], "n_citation": 50, "references": ["4d2ce564-d18a-43fb-af82-fad85b384345", "9423b9b3-6896-4773-81e0-35202f91bde7", "da4153b9-5345-4bb4-a42f-2ea926c0aad5"], "title": "Automatic Generation of Pronunciation Lexicons for Spanish", "venue": "international conference on computational linguistics", "year": 2002, "id": "bdc13258-7b49-4b5f-8cbc-b109b3d5f22d"}
{"abstract": "We propose electronic contract negotiation-a sub-part of the more general area of electronic commerce-as an example application for mobile agents. We start by presenting a set of requirements that an application should fulfil in order to take advantage of mobile agents and show that not all distributed applications meet these requirements. We then present contract negotiation, an example of an application that can potentially take full advantage of mobile agents. The paper also contains an introduction to a mobile agent system being developed at Hamburg University and show how it can be used to implement contract negotiation.", "authors": ["Frank Griffel", "M.T. Tu", "M. Munke", "Michael Merz", "Winfried Lamersdorf", "M. Da Silva"], "n_citation": 50, "references": ["08cfc806-dea2-4e64-88da-312d73e55b50", "17ff6847-db70-4ea6-bcbf-d24145ea68a3", "21155d4c-3b54-4e2e-be37-7672f5837367", "2d102ed2-7f97-426d-85e1-ee324d5cf0a1", "352d0531-d578-41e6-ba8d-cc98bcfa85fb", "47d0e8d9-79e9-4584-bffb-35937bcd29d3", "54ddd8e2-c74a-4409-b217-5b5f979e47fb", "8814cd3a-6058-4e52-b033-d9fff48f85cb", "a4d227fc-da17-4bd8-996d-9053c3a03e2f", "b75c31b4-53d4-4f73-a4ea-734e7ee023e3", "c4b1897c-767e-476b-a3ff-308447525e39", "d6e944ff-550c-44a6-b069-61704fd8f5c5", "d9c7cc6d-0067-4dae-848b-fcbe35b4aec9", "e268650f-3d95-439b-bb12-2a0219692762", "e903c12a-b59e-4638-8ed7-8456cf6bc303", "e9197e99-743f-46e2-abff-ed901fa84c80", "ee6e18d5-483c-43a3-b191-96402462b623"], "title": "Electronic contract negotiation as an application niche for mobile agents", "venue": "enterprise distributed object computing", "year": 1997, "id": "eb437ad4-c1c6-472c-b7e8-4b262cad6a55"}
{"abstract": "An inherent dilemma exists in the design of high-functionality applications (such as repositories of reusable software components). In order to be useful, high-functionality applications have to provide a large number of features, creating huge learning problems for users. We address this dilemma by developing intelligent interfaces that support learning on demand by enabling users to learn new features when they are needed during work. We support learning on demand with information delivery by identifying learning opportunities of which users might not be aware. The challenging issues in implementing information delivery are discussed and techniques to address them are illustrated with the CodeBroker system. CodeBroker supports Java programmers in learning reusable software components in the context of their normal development environments and practice by proactively delivering task-relevant and personalized information. Evaluations of the system have shown its effectiveness in supporting learning on demand.", "authors": ["Yunwen Ye", "Gerhard Fischer"], "n_citation": 71, "references": ["0985a776-3353-4997-9ea0-451ae8900b4c", "1a6033d8-2c81-433c-aa18-763aa85f5fdf", "26fef6f9-b352-4266-a01b-90ba8eadff5b", "27c0a072-01d6-40ae-8796-aaae0d2d66bc", "38d28e05-02cb-4df2-809e-fbf5f6cfd900", "3e8ebcc9-c4d8-4491-83ae-8ed29629841a", "50fd58c0-dadb-40d1-8039-d65cb4866642", "6562aae3-f221-4370-9146-fcd5bb65c365", "6fbfc3d2-b1b1-4995-bd26-f881598da618", "7384cc17-6e37-47f5-a5d1-3082d35dca3f", "742c51f4-8aa1-48d2-a555-a51f3e25a638", "7c94e63b-fd68-404a-b6ec-b244da32194d", "8645a93a-af3f-49a9-bbc5-06a68154a678", "9ae0142d-b12f-42b1-ac48-d655fdec233f", "b830746b-b58e-44c2-85b5-e325c13a53bb", "d32786fc-ea8d-41f0-a803-5d00e550329c", "ea89ced8-e205-4c33-9855-6fe150bdc158", "f2bd0d0c-83d9-4f80-9ec8-d64fee767352", "f6d4d483-1efe-4899-a384-814cf3148320"], "title": "Information delivery in support of learning reusable software components on demand", "venue": "intelligent user interfaces", "year": 2002, "id": "f9bb47dc-2882-4231-a28f-ea2e9ecc9a95"}
{"abstract": "Abstract   This paper is concerned with finding complete axiomatizations of probabilistic processes. We examine this problem within the context of the process algebra ACP and obtain as our endresult the axiom system  pr  ACP \u2212   l  , a version of ACP whose main innovation is a probabilistic asynchronous interleaving operator. Our goal was to introduce probability into ACP in as simple a fashion as possible, Optimally, ACP should be the homomorphic image of the probabilistic version in which the probabilities are forgotten, We begin by weakening slightly ACP to obtain the axiom system ACP \u2212   l  . The main difference between ACP and ACP \u2212   l   is that the axiom  x  + \u03b4 =  x , which does not yield a plausible interpretation in the generative model of probabilistic computation, is rejected in ACP \u2212   l  . We argue that this does not affect the usefulness of ACP \u2212   l   in practice, and show how ACP can be reconstructed from ACP \u2212   l   with a minimal amount of technical machinery.  pr  ACP \u2212   l   is obtained from ACP \u2212   l   through the introduction of probabilistic alternative and parallel composition operators, and a process graph model for  pr  ACP \u2212   l   based on  probabilistic bisimulation  is developed. We show that  pr  ACP \u2212   l   is a sound and complete axiomatization of probabilistic bisimulation for finite processes, and that  pr  ACP \u2212   l   can be homomorphically embedded in ACP \u2212   l   as desired. Our results for ACP \u2212   l   and  pr  ACP \u2212   l   are presented in a modular fashion by first considering several subsets of the signatures, We conclude with a discussion about adding an iteration operator to  pr  ACP \u2212   l  .", "authors": ["Jcm Jos Baeten", "Jan A. Bergstra", "Scott A. Smolka"], "n_citation": 145, "references": ["0abfd983-f80c-4f3a-9a01-5333a50ba7a6", "11d43d08-d930-4f95-ae8f-30ad403a3ece", "12b0448e-8d0b-442f-8a9b-b16a7c66f4f1", "63d1c97d-6dc5-460a-8a65-cdd3600ee387"], "title": "Axiomatizing probabilistic processes: ACP with generative probabilities", "venue": "Information & Computation", "year": 1995, "id": "3b6786dd-7080-4dcd-8817-bafa8f19c2ed"}
{"abstract": "In this paper, we aim to provide a point-of-interests (POI) recommendation service for the rapid growing location-based social networks (LBSNs), e.g., Foursquare, Whrrl, etc. Our idea is to explore user preference, social influence and geographical influence for POI recommendations. In addition to deriving user preference based on user-based collaborative filtering and exploring social influence from friends, we put a special emphasis on geographical influence due to the spatial clustering phenomenon exhibited in user check-in activities of LBSNs. We argue that the geographical influence among POIs plays an important role in user check-in behaviors and model it by power law distribution. Accordingly, we develop a collaborative recommendation algorithm based on geographical influence based on naive Bayesian. Furthermore, we propose a unified POI recommendation framework, which fuses user preference to a POI with social influence and geographical influence. Finally, we conduct a comprehensive performance evaluation over two large-scale datasets collected from Foursquare and Whrrl. Experimental results with these real datasets show that the unified collaborative recommendation approach significantly outperforms a wide spectrum of alternative recommendation approaches.", "authors": ["Mao Ye", "Pei Feng Yin", "Wang Chien Lee", "Dik Lun Lee"], "n_citation": 601, "references": ["18e2f228-893c-44fe-bd1b-354c416e1671", "20419644-0389-42d9-a21d-1396f6fd5d68", "3cf667e4-b285-48e6-9816-085ce9c56f8c", "487cabdb-6a18-426b-b66b-d5abca8d2747", "496813ab-768a-4c8e-b2c9-5ca5756f1e8e", "50e0fcf4-57d9-4ed6-ad7d-c9eb2bad8e42", "6df92a4c-0939-4cf7-895b-cca53196712f", "7dd93364-c1a0-49c0-a061-7fa6159e1dfa", "950f4d31-5399-492c-a394-85f1d68abeea", "98b23182-8f51-428a-a4af-a91d280471ca", "9ae0142d-b12f-42b1-ac48-d655fdec233f", "a3322191-42ee-4c40-bfe0-9a86aa2e3828", "ba180a82-d553-4c2f-b4ad-fcf0b4cb91e5", "c8f966ec-f42a-44a3-9177-36a7c57cdbf0", "d445d2c5-a50a-493f-ac4f-fb1db33dc155", "e08119e5-40ff-48e7-913c-1db729bd967b", "e57f499d-afaf-4fce-afa7-07473db65542", "e5e1e41c-774c-4bb4-a087-bcd02fd37b0f", "ea9087d8-58c0-4637-a905-208aa6910cc7", "ed4c0d5d-5152-4915-b9bd-d0bd25f82674", "f782a72e-eeca-4757-ace9-670012f961a8", "fb697d1e-0314-4f36-bbbb-1d5d8f610dca", "feddae21-3c05-4743-80fa-b8e101f1b93f"], "title": "Exploiting geographical influence for collaborative point-of-interest recommendation", "venue": "international acm sigir conference on research and development in information retrieval", "year": 2011, "id": "f0b28832-6fc3-4389-9f5e-3130bd00dbd7"}
{"abstract": "A processor with three concurrent and data-shared execution units is described in detail in this paper. The functionality, resources, and data sizes of the execution units, implemented with Xilinx FPGA chips, are user-configurable in order to best fit the application being run. A Harvard-type architecture allows a very large instruction word (128 bits) and, therefore, a real parallel utilization and control of resources. We also present the results of the implementation of two applications, the game of Life and the Abingdon Cross benchmark.", "authors": ["Christian Iseli", "Eduardo Sanchez"], "n_citation": 55, "references": ["3026a128-a6d9-43ac-b78a-b96556de6438", "7ecdab35-2d20-46c1-bd68-783ba5582d0f", "852c69aa-b2a1-40d0-805e-c0844045abd5", "b2c845ec-995a-43eb-9ef7-c0e15bf87f6d", "ed2a2d8d-d908-4760-8959-4544a1b731ca"], "title": "Spyder: a SURE (SUperscalar and REconfigurable) processor", "venue": "field programmable gate arrays", "year": 1995, "id": "aac8f54f-84eb-4bc1-a1ca-50bb6017f53e"}
{"abstract": "We present a method for translating Boolean formulas to CNF by identifying gates with fanout count of 1, and merging them with their fanout gate to generate a single set of equivalent CNF clauses. This eliminates the intermediate CNF variable for the output of the first gate, and reduces the number of CNF clauses, compared to the conventional translation to CNF, where each gate is assigned an output variable and is represented with a separate set of CNF clauses. Chains of nested ITE operators, where each ITE is used only as else-argument of the next ITE, are similarly merged and represented with a single set of clauses without intermediate variables. This method was applied to Boolean formulas from formal verification of microprocessors. The formulas require up to hundreds of thousands of variables and millions of clauses, when translated to CNF with the conventional approach. The best translation reduced the CNF variables by up to 2/spl times/ the SAT-solver decisions by up to 5/spl times/ the SAT-solver conflicts by up to 6/spl times/ and accelerated the SAT checking by up to 7.6/spl times/ for unsatisfiable formulas, and 136/spl times/ for satisfiable ones.", "authors": ["Miroslav N. Velev"], "n_citation": 61, "references": ["01c6379b-d54f-499c-9dee-8c34eb15ad03", "01edec75-d04a-4aa1-820c-5901f7568015", "08324d9f-4c53-40bb-8a10-fcdf90f7f3c3", "0e31d790-85db-452f-be27-9ae35a77e4fc", "0f240b6c-40a3-4fad-9352-2a554b31e5ca", "0fdbe674-1a52-4db9-9341-e7dcb7f0b698", "1bfe97b2-d44c-43c6-9c42-d5f7a22421aa", "1c750a3c-9296-421f-9a56-446d287a92df", "1c935c56-098c-4c36-9f84-b5f8dfb23e82", "328e835d-54f3-4b4f-b791-c1ad59a5d8c9", "355cf657-835e-4d29-b0e7-8894d9eeb939", "3fff71d1-ee5c-49a1-951c-757251af4564", "46c0b79d-63fe-407e-9c9c-6686069c2e0e", "46c42998-f958-4d9f-abbe-366c8dbbd5b7", "4b4cd2a0-e4ff-4911-9087-4b4f42f36ab3", "4c53cd25-a88a-4651-8064-b6a9f37714c5", "529f2ff9-37ea-4e2c-9aff-00907da69015", "538e8589-311e-416c-a708-16a9f18c8731", "5a88cd02-2073-4c95-8eb6-b0b2d995b8b9", "5a9bf89e-3584-4023-a4cc-de4a9f049971", "6086c701-a855-4106-baad-d795ad27bb02", "694b427e-a957-4ab7-9639-a6ecb67ef619", "7139a403-139d-4f92-b83a-b7b578510483", "92acd163-fd4f-41a7-8093-34f5c539defe", "96ff09f7-e819-4de9-aaf8-9eac2f5fa751", "9d826763-53f1-4bfd-a7f9-6a27fc26a8ae", "aa7282d5-0cb9-4ae7-8a55-752937435be4", "af945b68-12e1-432d-ace9-89a72cb20177", "be6bf4ad-d3aa-4d8f-a0a9-30561737c326", "cacbb408-defc-40b3-8f08-7b21217e5fcd", "d86ce52e-ea05-4e0f-83a3-b28c9f827a65", "e0b742ca-b06c-4078-968b-0db636a8e77d", "e8d788e8-f8da-4183-9817-ae756a852c31", "ec59a0e8-5c61-4b20-8708-0a7c2a195977", "f3329cc9-9afa-4c34-80a2-98748eac422c"], "title": "Efficient translation of boolean formulas to CNF in formal verification of microprocessors", "venue": "asia and south pacific design automation conference", "year": 2004, "id": "43e47041-a4df-4177-8c4d-c4784f81e79b"}
{"abstract": "This paper describes a generic proof method for the correctness of refine- ments of Abstract State Machines based on commuting diagrams. The method gener- alizes forward simulations from the refinement of I/O automata by allowing arbitrary m:n diagrams, and by combining it with the refinement of data structures. Abstract state machine (ASM) refinements have been used in many case studies based on Gurevich's (Gur95) definition, e.g. in (BR95) (BM96), (BS98), (BS00b). ASM refinements are usually verified using an informal notion of commuting diagrams to structure correctness proofs. Commuting diagrams are also used in approaches to the refinement of data structures (such as data refinement (dRE98)) as well as in simulation approaches for I/O automata (LV95), which focus on the refinement of control structure. Since refining one ASM by another may modify the data as well as the control structure, a generic proof technique for the verification of ASM refinements must necessarily combine the proof tech- niques used in both domains.", "authors": ["Gerhard Schellhorn"], "n_citation": 81, "references": ["0d995f1f-d3ea-4c1b-b0cc-3fa301ec010e", "1662d7f5-7b76-477a-a981-8468633b964b", "35c8c06c-2ad0-46b4-9e92-2d684f3abd94", "455c4b60-9f04-4115-8446-6fd500022823", "6108d3a5-dca2-4b9c-96c8-317c9997b987", "72b5a8c8-60b8-45b1-b13b-aa385eb9bdf8", "758c4b4f-af8f-4ac9-865c-dd9669d9bd00", "79de76a0-072e-41a4-8353-411e4fb1c6a7", "8e10eaa1-a6c6-4d8a-8505-81a95232888a", "97a7bf11-fbb6-4000-85b7-fbe569539acc", "b137eab1-0c25-43b3-8f1b-2a4364bcf6c4", "b4800a38-66ee-4e05-adaf-07cd94e7d10b", "c63208be-ad17-4700-8619-f19fe5a1e780", "d59a74e8-fec0-4b8d-a2ac-5695932159be", "eaede5ff-125c-4f4e-b9a2-b4a987937592", "f293f960-ec6e-447d-85d0-8c32ca31e0cb"], "title": "Verification of ASM Refinements Using Generalized Forward Simulation", "venue": "Journal of Universal Computer Science", "year": 2001, "id": "aa93a16b-121a-4b1a-aa9c-8cc41d11fd20"}
{"abstract": "We develop an application architecture for interactive, bilateral, semi-structured, multi-attribute electronic negotiations in business-to-business environments. We analyze the information and the process flow for this type of negotiations. We introduce the 'Negotiation Engine' as the core component of the application and discuss its functionality. We analyze relevant application scenarios and use a reference example from the oil industry to demonstrate the practical benefit of the application.", "authors": ["Michael Rebstock"], "n_citation": 16, "references": ["0b26107a-4cae-4e76-bef0-7526dc1e97f8", "5422832f-3877-48d2-bc47-937d8677fcd5", "c2c7eb91-2011-400b-859e-6e9d7d86e9cc", "cd742805-dc3b-4c62-a607-23ba0788158f", "d78b087e-998f-442e-a9cd-68256aab966e", "ec41e92c-c73d-4969-a7d9-d7d9c71e10aa"], "title": "An Application Architecture for Supporting Interactive Bilateral Electronic Negotiations", "venue": "electronic commerce and web technologies", "year": 2001, "id": "dbf74a1c-fd89-4ee6-a602-daacc378eccf"}
{"abstract": "Chip-level power and thermal implications will continue to rule as one of the primary design constraints and performance limiters. The gap between average and peak power actually widens with increased levels of core integration. As such, if per-core control of power levels (modes) is possible, a global power manager should be able to dynamically set the modes suitably. This would be done in tune with the workload characteristics, in order to always maintain a chip-level power that is below the specified budget. Furthermore, this should be possible without significant degradation of chip-level throughput performance. We analyze and validate this concept in detail in this paper. We assume a per-core DVFS (dynamic voltage and frequency scaling) knob to be available to such a conceptual global power manager. We evaluate several different policies for global multi-core power management. In this analysis, we consider various different objectives such as prioritization and optimized throughput. Overall, our results show that in the context of a workload comprised of SPEC benchmark threads, our best architected policies can come within 1% of the performance of an ideal oracle, while meeting a given chip-level power budget. Furthermore, we show that these global dynamic management policies perform significantly better than static management, even if static scheduling is given oracular knowledge.", "authors": ["Canturk Isci", "Alper Buyuktosunoglu", "Chen-Yong Cher", "Pradip Bose", "Margaret Martonosi"], "n_citation": 648, "references": ["012de24f-6441-4492-8a2f-a9c332b0f36e", "12a96f6d-eb93-4cc8-8a5c-67faaacb8637", "1342f340-04dd-433c-9ef9-a71d11e33985", "2230c9cd-bcc3-42b2-af77-c686c30b9b99", "22bd4192-82d8-4e08-8b0b-f6b36dca7417", "24d4297f-8116-4c3d-9fc6-58dab60489b0", "2bdb4891-05e0-4d9f-8ed1-6a326a8b21f1", "370c62f4-f2a1-40f8-ab9b-8918064ca86c", "45a65cf9-de25-4237-9607-0b1b1491b50d", "52b0d062-0fb1-4fc4-96e0-7c6e951c4441", "591c9ed6-b518-4d51-8061-22e2f86f2450", "6e546246-e8d4-49c1-96e3-b1618ea6ddcc", "7a457a24-0f5d-4154-9c66-96220a9f58c4", "7e2995c3-e3ad-4885-9a97-0fb0aa6d3d5e", "8c746d39-fe27-447b-8574-5b44e81628a3", "ad291d0a-408c-4f84-8749-c34c65dc645f", "aeb856f7-f929-4d4c-990d-6300ec812f9b", "af02d7f0-5983-475b-8538-61e54dad76f1", "b219795c-bc95-4c9e-9407-c0cc79bbae2a", "c11ea1c5-ab9a-406f-bce1-02b46ee2a706", "c2dc4b00-fb1f-4c3e-b9f4-addd7ca807b3", "ce7233b0-6170-428d-bc5e-620f7a285c78", "d51b0206-66e1-472b-8094-87cea0a9db45", "e567bc8b-14f6-4532-9283-bafaa398a336", "e829a185-6ede-4cc0-a921-10aecae18a16", "eae4b2bc-799b-4957-92dc-d3a6a1b4b751", "fa80fa82-cec9-4a6d-ae62-d9e11ff4de47"], "title": "An Analysis of Efficient Multi-Core Global Power Management Policies: Maximizing Performance for a Given Power Budget", "venue": "international symposium on microarchitecture", "year": 2006, "id": "4872edf4-5694-44ad-978e-4109cfef6907"}
{"abstract": "Passivity indices are defined in terms of an excess or shortage of passivity, and they have been introduced in order to extend the passivity-based stability conditions to more general cases for both passive and non-passive systems. While most of the work on passivity-based stability results in the literature focuses on employing the feedback interconnection of passive or non-passive systems, our results focus on a passivity measure for cascade interconnection. In this paper, we revisit the results on secant criterion from the perspective of passivity indices and we show how to use the secant criterion to measure the excess/shortage of passivity for cascaded Input Strictly Passive/Output Strictly Passive systems; we also propose a method to measure passivity for cascaded dissipative systems, where each subsystem could be passive or non-passive. Furthermore, we study the conditions under which the cascade interconnection can be directly stabilized via output feedback.", "authors": ["Han Yu", "Panos J. Antsaklis"], "n_citation": 50, "references": ["1d201bb8-0b81-4328-bc50-6231db711222", "25179d12-e933-4da4-b61e-0281ed7c2126", "6fae01aa-4c46-419e-82d5-29109bea3b18", "933f4aff-a283-4592-95e1-e934dd1ce2d8"], "title": "A passivity measure of systems in cascade based on passivity indices", "venue": "conference on decision and control", "year": 2010, "id": "40c09a0c-aad8-47dd-810c-0dd359b97b23"}
{"abstract": "Abstract   Even though the two IFIP WG8.1 working conferences on the comparative review and feature analysis of information systems methodologies (ISDMs) have made an important contribution, there is a need for supplementary longer-term comparative research which might gradually produce empirically-based knowledge about what are to be regarded as sound principles of IS design in various circumstances. Due to its scope, this research should take the form of broad international cooperation based on a reasonably common research framework, one close in spirit to that of Ives, Hamilton and Davis. A research framework of this kind should include as one element a profound conceptual model for IS design as a process, an area which is left relatively unanalyzed in the model of Ives et al. For that purpose the paper outlines a framework based on the sociocybernetic metamodel for IS design as a starting point for discussion and hopefully a more elaborate framework.", "authors": ["Juhani Iivari"], "n_citation": 41, "references": ["39af5771-7499-441b-bc3c-27c4a7fd7912", "43e74ea3-85e6-42af-9109-e6b4665c5b84", "9b9b35bb-bdb8-4a1b-b16e-179c963bc0dc", "f70b19fe-1c4c-4ad7-bca6-7bb462d6718c"], "title": "Dimensions of information systems design: A framework for a long-range research program", "venue": "Information Systems", "year": 1986, "id": "fb57281f-10bf-4f6e-8c9d-c2a1b4075389"}
{"abstract": "Subspace-based methods for system identification have attracted much attention during the past few years. This interest is due to the ability of providing accurate state-space models for multivariable linear systems directly from input-output data. The methods have their origin in classical state-space realization theory as developed in the 1960s. The main computational tools are the QR and the singular-value decompositions. Here, an overview of existing subspace-based techniques for system identification is given. The methods are grouped into the classes of realization-based and direct techniques. Similarities between different algorithms are pointed out, and their applicability is commented upon. We also discuss some recent ideas for improving and extending the methods. A simulation example is included for comparing different algorithms. The subspace-based approach is found to perform competitive with respect to prediction-error methods, provided the system is properly excited.", "authors": ["Mats Viberg"], "n_citation": 665, "references": ["00fea4f7-c264-4c14-a2cf-bcee6ad51437", "03bd31c7-6041-465d-842e-a77c39a555fb", "144191cb-a839-4e67-ad78-11f9a852ef47", "1d709f9b-ee64-4259-9cb8-bb3bf6380f81", "25c71c3f-473f-4259-9c38-4cbd1bf3a67a", "298d0264-c963-408b-b833-4bbaa0c9eb15", "2d579b24-cb7d-46a0-8b90-abb3deb0a882", "3b6add51-3df4-41d8-b28d-0cdf7ae983fc", "738c462f-8706-4a45-9af2-a8e1724ceac1", "9a994ade-1d0f-49d5-baea-367cb5865993", "ae4156ac-916a-42c8-b7d2-c8a248159bff", "b4c5f87e-6678-4e20-9894-f6e4d840092a", "baa5e386-c7a1-4abf-a611-3fbb40d8533b", "d55f269f-e5a7-4439-9643-6b0c131dbaa4", "edfe97f5-c285-42eb-9fd1-c631fcf61d24"], "title": "Subspace-based methods for the identification of linear time-invariant systems", "venue": "Automatica", "year": 1995, "id": "f16bd8e8-b1cf-41e3-8709-62da17caa0c6"}
{"abstract": "We present a framework for concurrency control and availability in multi-datacenter datastores. While we consider Google's Megastore as our motivating example, we define general abstractions for key components, making our solution extensible to any system that satisfies the abstraction properties. We first develop and analyze a transaction management and replication protocol based on a straightforward implementation of the Paxos algorithm. Our investigation reveals that this protocol acts as a concurrency prevention mechanism rather than a concurrency control mechanism. We then propose an enhanced protocol called Paxos with Combination and Promotion (Paxos-CP) that provides true transaction concurrency while requiring the same per instance message complexity as the basic Paxos protocol. Finally, we compare the performance of Paxos and Paxos-CP in a multi-datacenter experimental study, and we demonstrate that Paxos-CP results in significantly fewer aborted transactions than basic Paxos.", "authors": ["Stacy Patterson", "Aaron J. Elmore", "Faisal Nawab", "Divyakant Agrawal", "Amr El Abbadi"], "n_citation": 58, "references": ["03cbb7e0-4672-4f5f-9d5f-c53b52f0f2f5", "1cfe1703-9933-4e68-a3e3-84f757b1b0f6", "26ca14cc-72cd-4c71-91d0-ca332ed674b7", "2a25de10-ea33-410c-8f32-69feae4030ab", "5002dd27-9ce6-4abb-a3d0-2ac112f58c37", "73b8ae11-60b8-4669-af49-51832880f697", "75eb5f1c-a6ee-4425-ba73-5c6e030a42d7", "7fdc02f3-ed29-46a8-acf5-9c644da25e25", "81ad8d98-8e9c-492c-9f0e-dc4b1e6d3d8b", "86a23d98-a29c-4164-b800-615ce920f001", "9eb8b989-d5e9-45d5-8a3a-13e28b60b3dc", "c482afd5-93a8-4ebb-857e-e3cb6339ab7b", "d9c271a7-a67d-4fb4-940d-012282c83b79", "e46be615-01d7-4d38-9190-914f978383e5"], "title": "Serializability, not serial: concurrency control and availability in multi-datacenter datastores", "venue": "very large data bases", "year": 2012, "id": "8cfee550-f0f0-468b-96bd-2fa580ca7f76"}
{"abstract": "A shape representation technique suitable for tasks that call for recognition of a noisy curve of arbitrary shape at an arbitrary scale or orientation is presented. The method rests on the describing a curve at varying levels of detail using features that are invariant with respect to transformations that do not change the shape of the curve. Three different ways of computing the representation are described. They result in three different representations: the curvature scale space image, the renormalized curvature scale space image, and the resampled curvature scale space image. The process of describing a curve at increasing levels of abstraction is referred to as the evolution or arc length evolution of that curve. Several evolution and arc length evolution properties of planar curves are discussed. >", "authors": ["Farzin Mokhtarian", "Alan K. Mackworth"], "n_citation": 1143, "references": ["010e8977-1ff2-4c21-b2c6-3d15a6788d09", "07d1d33d-fc47-40bb-82a9-499a6ebf08cf", "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5", "43aa0ddc-a25b-4bbb-a53c-27ab216529f0", "49492afc-ee5a-4a3a-8ff8-ef6a7f3ef65f", "4e631ef0-fad7-4dc0-901a-29af722c2169", "7d5e97d2-5ebe-4be2-ac67-3c15fcde2c8d", "8d07ce25-0352-44ee-9098-cb04aaa180d6", "ac129832-39b9-407d-aff3-582c209145f3", "bd52e156-edc5-4898-bb7d-229c5035d281", "de2f8877-b361-47f5-b67c-cbef580bf4d1", "e389fa97-0461-4d42-876f-31d67c0690ca", "e46bb6ea-7b67-4edf-8cd4-a51ce64cff19", "e71f8dbd-14fe-4696-8f3e-b1e4342651f9", "ebc5df46-f49d-45cd-8e59-0ff00686c523"], "title": "A theory of multiscale, curvature-based shape representation for planar curves", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 1992, "id": "d3b8e209-d1a4-4900-a51f-da5abd8aa096"}
{"abstract": "Although well understood in the single-agent framework, the use of traditional reinforcement learning (RL) algorithms in multi-agent systems (MAS) is not always justified. The feedback an agent experiences in a MAS, is usually influenced by the other agents present in the system. Multi agent environments are therefore non-stationary and convergence and optimality guarantees of RL algorithms are lost. To better understand the dynamics of traditional RL algorithms we analyze the learning process in terms of evolutionary dynamics. More specifically we show how the Replicator Dynamics (RD) can be used as a model for Q-learning in games. The dynamical equations of Q-learning are derived and illustrated by some well chosen experiments. Both reveal an interesting connection between the exploitation-exploration scheme from RL and the selection-mutation mechanisms from evolutionary game theory.", "authors": ["Karl Tuyls", "Katja Verbeeck", "Tom Lenaerts"], "n_citation": 94, "references": ["e0f3a738-4ab2-40d1-ba44-506d81c1d230"], "title": "A selection-mutation model for q-learning in multi-agent systems", "venue": "adaptive agents and multi-agents systems", "year": 2003, "id": "00889c02-03ee-4b7a-a47d-ae35d9adfa23"}
{"abstract": "As the processor-memory performance gap continues to grow, so does the need for effective tools and metrics to guide the design of efficient memory hierarchies to bridge that gap. Aggregate statistics of cache performance can be useful for comparison, but they give us little insight into how to improve the design of a particular component. We propose a different approach to cache analysis-viewing caches as filters-and present two new metrics for analyzing cache behavior: instantaneous hit rate and instantaneous locality. We demonstrate how these measures can give us insight into the reference pattern of an executing program, and show an application of these measures in analyzing the effectiveness of the second level cache of a particular memory hierarchy.", "authors": ["Dee A. B. Weikle", "Sally A. McKee", "William A. Wulf"], "n_citation": 38, "references": ["064f24ad-e57a-4ff3-893d-119d5766ccda", "065b746f-ef58-472b-bac8-80ea22ffbf2f", "130b7dfc-af33-4a27-8246-be9ec649be40", "18b5ddf1-b68b-4273-a1e2-7ba76230f210", "1d9b804d-a125-4c4e-8e7a-bcdf4fc2dbe4", "24cd1d7f-490f-424b-b1f5-7882a015beaf", "34295085-d2e9-4e5c-b807-aaff00071a05", "4ddea13b-2705-43ec-9f58-711b7d01c297", "8bdbbf48-c593-445d-9a39-1c0564133330", "9f2d49bf-e7ed-4c68-8926-04e9a9e2a9f1", "ce40fb65-ae42-4970-b7bf-0518ad35ce70", "ee598f63-e801-4350-bd5f-27e750a87c63", "f0e87b11-6f0d-4e57-b8f4-58cdf52ad227"], "title": "Caches as filters: a new approach to cache analysis", "venue": "modeling analysis and simulation on computer and telecommunication systems", "year": 1998, "id": "265882b7-ff88-4cce-aa70-86b3720c7a4c"}
{"abstract": "Data generation, handling and its processing have emerged as the most reliable source of understanding and discovery of new facts, knowledge and products in the world of natural and material sciences. The emergence of the most efficient techniques in statistical or bioinformatics situations has therefore become a routine practice in research and industrial sectors. Under practical conditions, dealing with large datasets, it's likely to have inconsistencies and anomalies of all kinds to prevent to know real outcomes for practical problems. For accurate data mining computer based techniques of data pre-processing offer solutions that help the data under processing to conform normal structures which in turn considerably improve the performance of machine learning algorithms. In this process, accurate determination of outliers, extreme values and filling up gaps poses formidable challenges. Multiple methodologies have therefore been developed to detect these deviated or inconsistent values called outliers. Different data pre-processing techniques discussed in this paper could offer most suitable solutions for handling missing values and outliers in all kinds of large datasets such as electric load and weather datasets.", "authors": ["Asma Saleem", "Khadim Hussain Asif", "Ahmad Ali", "Shahid M. Awan", "Mohammed A. Alghamdi"], "n_citation": 4, "references": ["552df209-784d-4b6f-b0ff-cd9c9078f1c0", "aa581f46-77fd-46fe-8ffc-1854c1430d3d"], "title": "Pre-processing Methods of Data Mining", "venue": "ieee international conference on cloud computing technology and science", "year": 2014, "id": "b4d65353-c817-4612-944a-3e45cba0be1e"}
{"abstract": "Multichannel recordings of the electromagnetic fields emerging from neural currents in the brain generate large amounts of data. Suitable feature extraction methods are, therefore, useful to facilitate the representation and interpretation of the data. Recently developed independent component analysis (ICA) has been shown to be an efficient tool for artifact identification and extraction from electroencephalographic (EEG) and magnetoencephalographic (MEG) recordings. In addition, ICA has been applied to the analysis of brain signals evoked by sensory stimuli. This paper reviews our recent results in this field.", "authors": ["Ricardo Vig\u00e1rio", "Jaakko S\u00e4rel\u00e4", "V. Jousmiki", "Matti H\u00e4m\u00e4l\u00e4inen", "Erkki Oja"], "n_citation": 688, "references": ["0400f185-d501-4eac-86cc-fff1ff9b5ba0", "0ddbfee1-8cc2-49f6-be79-59276f496884", "1038af56-9bce-420c-8985-f2762b5b3627", "6c8cffb5-1552-434d-8941-d5fa38cfdfec", "ada27ede-4400-4e7d-aee5-1b5e62fe1800", "aec3237b-b440-4d97-91a7-f57c249f82d6", "c61711cb-2ab0-493f-83a2-51d83aa6bc61", "e57e068c-471f-4e93-af72-ae80231ed002", "f9de8a43-0312-48c7-9d91-4564c5558ffd"], "title": "Independent component approach to the analysis of EEG and MEG recordings", "venue": "IEEE Transactions on Biomedical Engineering", "year": 2000, "id": "6040eaf4-8897-4c87-a875-b6611339b0ad"}
{"abstract": "With the emergence of broad-coverage parsers, quantitative evaluation of parsers becomes increasingly more important. We propose a dependency-based method for evaluating broad-coverage parsers that offers more meaningful performance measures than previous approaches. We also present a structural pattern-matching mechanism that can be used to eliminate inconsequential differences among different parse trees. Previous evaluation methods have only evaluated the overall performance of parsers. The dependency-based method can also evaluate parsers with respect to different kinds of grammatical relationships or different types of lexical categories. An algorithm for transforming constituency trees into dependency trees is presented, which makes the evaluation method applicable to both constituency grammars and dependency grammars.", "authors": ["Dekang Lin"], "n_citation": 266, "references": ["2cb1c41b-b9f6-41e7-9b8f-b55ff20903a8", "2f5a8966-588b-42aa-bccb-fc08f295aec1", "33094d83-148a-4f35-8f7b-6caf84d5b770", "6d98fde5-810f-4280-a1f6-a220bdbc909c", "c10f971c-d725-4aee-b747-cafc29ba4f06", "ccd5b8e1-152a-40fb-ae6d-5b9575212d73", "ea3b4551-ba70-4934-af40-4e44228b4ae6"], "title": "A dependency-based method for evaluating broad-coverage parsers", "venue": "Natural Language Engineering", "year": 1998, "id": "28a56be5-7fa1-48f9-b259-5b8677046cc5"}
{"abstract": "This paper introduces two neural network based software fault prediction models using Object-Oriented metrics. They are empirically validated using a data set collected from the software modules developed by the graduate students of our academic institution. The results are compared with two statistical models using five quality attributes and found that neural networks do better. Among the two neural networks, Probabilistic Neural Networks outperform in predicting the fault proneness of the Object-Oriented modules developed.", "authors": ["S. Kanmani", "V. Rhymend Uthariaraj", "V. Sankaranarayanan", "P. Thambidurai"], "n_citation": 140, "references": ["01570ac6-ab0a-4e78-a145-d65ff4e4ec22", "493f51c9-d389-4555-afb2-30aa84e56649", "49a0cd67-ab53-4fe3-88f1-744dceda55df", "57af1f08-da6a-466f-97a2-99e98a992768", "58481a5b-3647-4585-b603-34a054ebd67c", "73443e03-6f1a-4ee9-90b7-4d7b9c92ae36", "845b8566-3003-4c39-afb4-f299e027f6aa", "85ebe862-55a2-4a78-919e-9418b3de0a35", "8991e403-e7e0-422a-9998-ae33055b1a04", "a64e45d0-9dfd-46ab-ad32-3b226ccdc944", "b91db22a-4bd6-4cc5-9fca-9be4fb567f15", "bd9e7600-482a-47d1-9513-45a778f7bd21", "c210fdae-8472-44d8-88a2-314316700e05", "d32786fc-ea8d-41f0-a803-5d00e550329c", "d52b6b91-b922-4118-b45a-ed486a3591b5", "dc93fce8-8041-4004-a505-7799747b7359", "e580b2d9-3e7c-4122-9932-f2cf985040cd"], "title": "Object-oriented software fault prediction using neural networks", "venue": "Information & Software Technology", "year": 2007, "id": "8981b455-88ce-4f9b-a958-25581782b1b3"}
{"abstract": "Software documentation is usually expressed in natural languages, which contains much useful information. Therefore, establishing the traceability links between documentation and source code can be very helpful for software engineering management, such as requirement traceability, impact analysis, and software reuse. Currently, the recovery of traceability links is mostly based on information retrieval techniques, for instance, probabilistic model, vector space model, and latent semantic indexing. Previous work treats both documentation and source code as plain text files, but the quality of retrieved links can be improved by imposing additional structure using that they are software engineering documents. In this paper, we present four enhanced strategies to improve traditional LSI method based on the special characteristics of documentation and source code, namely, source code clustering, identifier classifying, similarity thesaurus, and hierarchical structure enhancement. Experimental results show that the first three enhanced strategies can increase the precision of retrieved links by 5%~16%, while the the fourth strategy is about 13%.", "authors": ["Xiaobo Wang", "Guanhui Lai", "Chao Liu"], "n_citation": 35, "references": ["0bf79ef4-1a2d-4a1d-ad92-898d8ccaa9e9", "375f02a0-6985-4ea9-93df-1a0e53e8499f", "68453f24-4276-4d0c-b37e-19d23af549be", "6e198e5e-9655-418f-9abe-f2507c87ad91", "b014ee14-69b1-434d-8d42-204ee437e768", "c0750866-66e3-4872-ba7c-bf48595d1c54", "e21d1d88-931f-478a-9547-06636fefd7c5", "e427f800-7a52-4845-a774-fd5c823634d2", "fc7501b7-c92d-4d28-bf2f-56a053e384e8"], "title": "Recovering Relationships between Documentation and Source Code based on the Characteristics of Software Engineering", "venue": "Electronic Notes in Theoretical Computer Science", "year": 2009, "id": "1fdde95a-fa32-4b0e-a3cc-ed4215e5a55c"}
{"abstract": "We describe the generation of a large pose-mosaic dataset: a collection of several thousand digital images, grouped by spatial position into spherical mosaics, each annotated with estimates of the acquiring camera's 6 DOF pose (3 DOF position and 3 DOF orientation) in an absolute coordinate system. The pose-mosaic dataset was generated by acquiring images, grouped by spatial position into nodes (essentially, spherical mosaics). A prototype mechanical pan-tilt head was manually deployed to acquire the data. Manual surveying provided initial position estimates for each node. A back-projecting scheme provided initial rotational estimates. Relative rotations within each node, along with internal camera parameters, were refined automatically by an optimization-correlation scheme. Relative translations and rotations among nodes were refined according to point correspondences, generated automatically and by a human operator. The resulting pose-imagery is self-consistent under a variety of evaluation metrics. Pose-mosaics are useful \"first-class\" data objects, for example in automatic reconstruction of textured 3D CAD models which represent urban exteriors.", "authors": ["Satyan R. Coorg", "Neel Master", "Seth J. Teller"], "n_citation": 75, "references": ["0e3c573b-8cfc-44b7-9582-0bd52924d470", "33fe8461-d465-4487-b9fa-8270a2d5865f", "60985c9a-ca14-4324-882d-95cedabefdeb", "7bedd079-985f-48ce-9648-21cdccde839c", "80246878-7728-43e0-a293-02ab79571d12", "86df4969-6945-4090-852b-f0c5af957ced", "90483bd3-a6a7-4799-93cf-af14e991335c", "905461e4-643b-4da0-a669-f52318b9e126", "a10e1f01-b28f-4d77-8aec-6252f7174575", "f33d2cea-11ac-49e3-8052-b26d228f35b8"], "title": "Acquisition of a large pose-mosaic dataset", "venue": "computer vision and pattern recognition", "year": 1998, "id": "2208bb93-b29d-44d2-986a-26d956a13a8b"}
{"abstract": "We introduce a formalism for optimal sensor parameter selection for iterative state estimation in static systems. Our optimality criterion is the reduction of uncertainty in the state estimation process, rather than an estimator-specific metric (e.g., minimum mean squared estimate error). The claim is that state estimation becomes more reliable if the uncertainty and ambiguity in the estimation process can be reduced. We use Shannon's information theory to select information-gathering actions that maximize mutual information, thus optimizing the information that the data conveys about the true state of the system. The technique explicitly takes into account the a priori probabilities governing the computation of the mutual information. Thus, a sequential decision process can be formed by treating the a priori probability at a certain time step in the decision process as the a posteriori probability of the previous time step. We demonstrate the benefits of our approach in an object recognition application using an active camera for sequential gaze control and viewpoint selection. We describe experiments with discrete and continuous density representations that suggest the effectiveness of the approach.", "authors": ["Joachim Denzler", "Chris Brown"], "n_citation": 252, "references": ["02f27ba9-491d-4c46-b8b6-7f4426b8e3e1", "037b9625-bad7-41d3-be15-3d6d109298c2", "17789398-d1e5-491e-bf0d-6f658005c5ba", "18d831ee-2edb-4f74-8baa-11bcfc3c02b0", "41b26b0a-076d-464e-a3b9-5a20aee27b84", "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c", "8735c7ea-f5c6-4310-b250-bc0d1bf5e834", "96a2b29f-1fc2-4b2e-91ba-cfc2973929cc", "97571808-28e5-400a-8793-5ca824c4fc6e", "b7943213-a47d-43de-9f9a-ce2658ceb6bd", "bcd991b1-0750-4598-8cd7-78832553a2d2", "c86ab37a-6baa-47fb-a885-bfbb7f23d973", "d96d1150-8b82-4dcf-a8eb-397fe2347073", "dc4d3009-9af5-4b82-b064-dde24bb8d20b", "f2d742df-9ac7-4b2f-9a8c-5d2880d4a431"], "title": "Information theoretic sensor data selection for active object recognition and state estimation", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2002, "id": "a3dfca63-dba5-4eee-a70d-ef1992b36af5"}
{"abstract": "Improving the performance of the transmission control protocol (TCP) in wireless Internet protocol (IP) communications has been an active research area. The performance degradation of TCP in wireless and wired-wireless hybrid networks is mainly due to its lack of the ability to differentiate the packet losses caused by network congestions from the losses caused by wireless link errors. In this paper, we propose a new TCP scheme, called TCP-Jersey, which is capable of distinguishing the wireless packet losses from the congestion packet losses, and reacting accordingly. TCP-Jersey consists of two key components, the available bandwidth estimation (ABE) algorithm and the congestion warning (CW) router configuration. ABE is a TCP sender side addition that continuously estimates the bandwidth available to the connection and guides the sender to adjust its transmission rate when the network becomes congested. CW is a configuration of network routers such that routers alert end stations by marking all packets when there is a sign of an incipient congestion. The marking of packets by the CW configured routers helps the sender of the TCP connection to effectively differentiate packet losses caused by network congestion from those caused by wireless link errors. This paper describes the design of TCP-Jersey, and presents results from experiments using the NS-2 network simulator. Results from simulations show that in a congestion free network with 1% of random wireless packet loss rate, TCP-Jersey achieves 17% and 85% improvements in goodput over TCP-Westwood and TCP-Reno, respectively; in a congested network where TCP flow competes with VoIP flows, with 1% of random wireless packet loss rate, TCP-Jersey achieves 9% and 76% improvements in goodput over TCP-Westwood and TCP-Reno, respectively. Our experiments of multiple TCP flows show that TCP-Jersey maintains the fair and friendly behavior with respect to other TCP flows.", "authors": ["Kai Xu", "Ye Tian", "Nirwan Ansari"], "n_citation": 297, "references": ["0ce4877b-6e18-455c-9ee5-7ca93715a88f", "1442c01e-d9ff-4c6d-88cc-efb2d5c5c1d4", "4854b363-f03e-4667-abad-2de7ca3d2315", "4d0f2c57-7f08-416a-9721-eb333c88433e", "503c5e5f-67af-48e7-a8cb-bf62fe238db4", "553db688-bb98-4ed0-a2a4-42f1e5678559", "6af44776-cd08-4180-b9ac-ac954a61fc0c", "6f9e1127-b4f4-4396-a980-19e9ed315ac1", "7ad7f8f2-d3e5-4272-a88b-f3be40a0dc5b", "cc126569-9928-4973-a014-7d8d563d9eff", "d29b395f-af6e-46ca-a894-60d9bcad0cc0", "d2b7db5d-bc47-48c7-a173-865fed9bff96", "d4e06d94-9c48-4b5d-8a51-a3753424a6bf", "e95f8b9d-85de-41a1-ae2c-901d01b8754d", "ed353db8-a1b3-472f-b136-79480f8f6dfc", "efe13988-b78c-4097-9781-adbecb84ebc4", "fe7fdbd1-72ba-4138-b10b-72128731d905"], "title": "TCP-Jersey for wireless IP communications", "venue": "IEEE Journal on Selected Areas in Communications", "year": 2004, "id": "078c540a-c8b6-4310-8e01-d282895bda22"}
{"authors": ["Julien M. Hendrickx", "Karl Henrik Johansson", "Rapha\u00ebl M. Jungers", "Henrik Sandberg", "Kin Cheong Sou"], "n_citation": 3, "title": "An Exact Solution to the Power Networks Security Index Problem and its Generalized Min Cut Formulation", "venue": "", "year": 2012, "id": "450655cf-131a-4f6d-9102-395c71cc44b5"}
{"abstract": "In software product family engineering reusable artifacts are produced during domain engineering and applications are built from these artifacts during application engineering. Modeling variability of current and future applications is the key for enabling reuse. The proactive reuse leads to a reduction in development costs and a shorter time to market. Up to now, these benefits have been realized for the constructive development phases, but not for testing. This paper presents the ScenTED technique (Scenario based TEst case Derivation), which aims at reducing effort in product family testing. ScenTED is a model-based, reuse-oriented technique for test case derivation in the system test of software product families. Reuse of test cases is ensured by preserving variability during test case derivation. Thus, concepts known from model-based testing in single system engineering, e.g., coverage metrics, must be adapted. Experiences with our technique gained from an industrial case study are discussed and prototypical tool support is illustrated.", "authors": ["Andreas Reuys", "Erik Kamsties", "Klaus Pohl", "Sacha Reis"], "n_citation": 103, "references": ["a1b54b7d-3417-4041-9798-762a75b6102b", "c7ac16a4-6556-4225-865b-481667c291f4", "db680839-374a-45a2-ba65-31590b859464", "f9ae80d0-4a8f-4062-a320-f3a88902438b"], "title": "Model-based system testing of software product families", "venue": "conference on advanced information systems engineering", "year": 2005, "id": "d3bd86aa-42f7-49bc-8d4f-3ce544a1c88b"}
{"abstract": "Successful software process improvement depends on the ability to analyze past projects and determine which parts of the process that could become more efficient. One source of such an analysis is the faults that are reported during development. This paper proposes how a combination of two existing techniques for fault analysis can be used to identify where in the test process improvements are needed, i.e. to pinpoint which activities in which phases that should be improved. This was achieved by classifying faults after which test activities that triggered them and which phase each fault should have been found in, i.e. through a combination of orthogonal defect classification (ODC) and faults-slip-through measurement. As a part of the method, the paper proposes a refined classification scheme due to identified problems when trying to apply ODC classification schemes in practice. The feasibility of the proposed method was demonstrated by applying it on an industrial software development project at Ericsson AB. The obtained measures resulted in a set of quantified and prioritized improvement areas to address in consecutive projects.", "authors": ["Lars-Ola Damm", "Lars Lundberg"], "n_citation": 11, "references": ["087929d5-88dd-457a-9b30-7f9df22892d9", "1c26b981-a162-433e-bb46-efff8f0da749", "29ea1350-128e-4ca4-8b5b-0393da979614", "2b7f9e50-a52a-4f9c-a152-5d3a191cfe26", "2deaa050-86d0-4ddc-a55d-53a0a9629ac6", "2f2561d5-0049-4b6f-8f5e-2424d5f62ed5", "3fbd9287-1905-4c42-a924-65f4c02f1d52", "3fd9a0c0-2349-4537-9ca9-f2e41f0f0bef", "43cc0d54-c4b0-4fb3-bf75-5ffc4e2a8dde", "4f2d5968-7eb7-42c9-aec1-e3cf51b8b880", "6a55e1c3-5822-4b6c-a73a-21f0b59e4918", "8ae4a854-7668-4fa3-bfb2-7485172ac055", "8eddc940-58bd-4b0a-a918-c6292576f0c4", "92f39c41-5539-4fc3-a67d-e5aa28b25e83", "c33107a9-3eea-4249-8a31-f4cc1d4f6b47", "c6124a3d-b7a9-44fc-9081-b2cdbb488bc9", "c79ae786-3667-467c-a8c7-03d2c44a8c66", "cb63a1a0-67dc-46c3-b51b-c1c362477973", "cf216dbc-d892-4904-bd9a-cf8a50086805", "e4c292ad-1a29-4671-b2ce-0418655ac7c1", "f120aa6e-bd0d-4847-84b0-e2b7e3291d5f"], "title": "Identification of test process improvements by combining fault trigger classification and faults-slip-through measurement", "venue": "", "year": 2005, "id": "015146f1-0935-4bb5-a1c9-b05891e88f53"}
{"abstract": "A singularity-induced bifurcation (SIB) describes the divergence of one eigenvalue through infinity when an equilibrium locus of a parameterized differential-algebraic equation (DAE) crosses a singular manifold. The present note extends the analysis of this behavior to cover double SIB points, for which two eigenvalues diverge. The key assumption supporting this phenomenon is that the Kronecker index jumps by two at the singularity. In this situation, double SIB points are shown to undergo generically a transition from a spiral to a saddle in the linearized problem, after restricting the analysis to the corresponding invariant subspace. Typical examples arise in the context of nonlinear RLC circuits. The setting for the study is that of semi-explicit DAEs in Hessenberg form with arbitrary index.", "authors": ["Ricardo Riaza"], "n_citation": 50, "references": ["e1b2f6b4-ec17-49d4-9f10-d0df17df7c44", "ea38e4ed-3d3f-4fa0-b318-674b81a8b84d"], "title": "Double SIB points in differential-algebraic systems", "venue": "IEEE Transactions on Automatic Control", "year": 2003, "id": "944ceb10-3414-4bd1-be0a-6e4c94f0ab56"}
{"abstract": "In this article, we present a programming language for expressing classificatory problem solvers. CSRL (Conceptual Structures Representation Language) provides structures for representing classification trees, for navigating within those trees, and for encoding uncertainly judgments about the presence of hypotheses. We discuss the motivations, theory, and assumptions that underlie CRSL. Also, some expert systems constructed with CSRL are briefly described.", "authors": ["Tom Bylander", "Mittal Sk"], "n_citation": 188, "references": ["0f8e8887-c17a-409a-a8f2-2c30d5856d86", "3757bbb4-9c8a-4f08-b3e9-9d54fe625381", "4530763e-cfd0-4cc0-9d26-f777c575d3a2", "8e2320ea-cb9e-4be0-8c92-bd27badd2837", "8ead959b-cd09-44d5-bd6d-ac281f95b418", "917d1050-cca5-4dae-9b03-887812fb1686", "ab5a3494-802a-4a2a-8ed5-66fe85a94db7", "d55b22d6-2cf2-48c2-ba9c-ae3cf440c3ad", "f210cb90-427f-42df-89d7-7c964b37aa28", "fc59a430-efc0-4d55-a37f-9a9ec635a95a"], "title": "CRSL: A language for classificatory problem solving and uncertainty handling", "venue": "Ai Magazine", "year": 1986, "id": "d87db69f-5ec0-4328-9ef5-3dba7c37b038"}
{"abstract": "The notion of effective bandwidths has provided a useful practical framework for connection admission control and capacity planning in high-speed communication networks. The associated admissible set with a single linear boundary makes it possible to apply stochastic-loss-network (generalized-Erlang) models for capacity planning. We consider the case of network nodes that use a priority-service discipline to support multiple classes of service, and we wish to determine an appropriate notion of effective bandwidths. Just as was done previously for the first-in first-out (FIFO) discipline, we use large-buffer asymptotics (large deviations principles) for workload tail probabilities as a theoretical basis. We let each priority class have its own buffer and its own constraint on the probability of buffer overflow. Unfortunately, however, this leads to a constraint for each priority class. Moreover, the large-buffer asymptotic theory with priority classes does not produce an admissible set with linear boundaries, but we show that it nearly does and that a natural bound on the admissible set does have this property. We propose it as an approximation for priority classes; then there is one linear constraint for each priority class. This linear-admissible-set structure implies a new notion of effective bandwidths, where a given connection is associated with multiple effective bandwidths: one for the priority level of the given connection and one for each lower priority level. This structure can be used regardless of whether the individual effective bandwidths are determined by large-buffer asymptotics or by some other method.", "authors": ["Arthur W. Berger", "Ward Whitt"], "n_citation": 144, "references": ["0c4a3c25-35a3-46d4-a5a3-4a98bb8b478c", "1a1a0179-a3ea-4be2-b9dd-6c34ff850e5f", "1bc99b39-2dc3-4882-9a99-eb73e65f4161", "1d79b8a1-d2e6-4722-996e-dafe812d5737", "21b7f23c-7676-49d0-91c1-cd957338df66", "3001a907-4e5b-47e0-959a-12451926a5b9", "3a95b7a1-5398-4a34-9dbc-d4c2c2082e00", "5237ed7f-6cf4-4775-8a28-cc30faa14859", "56904468-b807-4f2b-87c8-c145b59bfdd7", "5a996882-ded3-4fae-a59d-29bce8090f5c", "713f89cf-9406-4d2f-8b06-dbac1b97537f", "883d16bd-c2bd-4a5c-b4d5-8449cd1945b2", "938e19a3-c657-4740-926e-65f6f334f422", "d1371098-aee9-4a7f-946e-3af596ac052a", "d4f14196-0149-4298-b45a-e33f66a8dfb2", "dd8d51e8-31a7-48db-a4ff-5a746edc7e03", "e0ce36cf-c743-462b-8801-45f6e1e4602c", "e977fe06-34a0-4bc7-baa8-2ab386b962e8", "f3875007-af9f-45eb-9191-2c04e2e19830", "f68cdb83-5b00-4ad0-a492-a54fcaaa9541", "fd8ec282-0b1c-4315-9478-c8185709cb1d"], "title": "Effective bandwidths with priorities", "venue": "IEEE\\/ACM Transactions on Networking", "year": 1998, "id": "7af38b2f-21d3-464f-a288-92861700e766"}
{"authors": ["David C. Rine"], "n_citation": 28, "references": ["03052150-4eb0-4831-bf3f-1b87574ecc25", "1881977e-6cec-434b-863d-e332fdbaf916", "2fc313c9-b78e-4818-a9d4-5fe31f7fdaf8", "46ed8cfc-9750-46a8-8492-e4702c5dfb1b", "572aa09a-2f66-456a-9fdc-3e47d34597f9", "706dae66-5418-4f3e-954b-d81b3c8d06ff", "8ff42efa-b46f-437d-8b25-2f43c004572e", "b4543b98-923f-4128-a489-294c254fe254", "bbc5f90b-ed9f-4b28-a439-f55260858ed1", "d282fd6c-19f2-43d8-b337-415c0ebaa335"], "title": "Success factors for software reuse that are applicable across domains and businesses", "venue": "acm symposium on applied computing", "year": 1997, "id": "208131e6-2b5c-4082-bf81-7d82f6eab471"}
{"abstract": "The term \u2018crowdsourcing\u2019 was initially introduced in 2006 to describe an emerging distributed problem-solving model by online workers. Since then it has been widely studied and practiced to support software engineering. In this paper we provide a comprehensive survey of the use of crowdsourcing in software engineering, seeking to cover all literature on this topic. We first review the definitions of crowdsourcing and derive our definition of Crowdsourcing Software Engineering together with its taxonomy. Then we summarise industrial crowdsourcing practice in software engineering and corresponding case studies. We further analyse the software engineering domains, tasks and applications for crowdsourcing and the platforms and stakeholders involved in realising Crowdsourced Software Engineering solutions. We conclude by exposing trends, open issues and opportunities for future research on Crowdsourced Software Engineering.", "authors": ["Ke Mao", "Licia Capra", "Mark Harman", "Yue Jia"], "n_citation": 50, "references": ["003136a2-6a65-40dd-a037-83b6538a6f8c", "02e0861c-780d-45f8-84ea-1afb45d0a854", "051e72cd-5637-4d96-8b2a-e223d9ee14ea", "05c4fabc-daf4-4889-8a9a-a03da9906364", "05ebc39b-f191-46b5-92b3-aaa92d1940d1", "069a7a19-17a8-4e7e-ac8e-edec7c76ec80", "075249f4-dddd-4ec0-aa89-e5c526bdc4ff", "076c2382-2a71-4401-be30-bc2b76f0bcf7", "090415ab-44cc-47fc-8ae6-ddfb43fbbb79", "09dced28-4ad9-47a3-a2b8-4c7190cf58ea", "0abce20e-feb1-407c-acbf-bc88dd1d16a1", "0c127ff1-fd51-4c37-a8dd-ce966ca9d96c", "0c962fe8-f2d3-4997-8653-52d79a932bbb", "0cdd99ec-6f71-48c2-a830-581a84741064", "0e357739-72c0-4f60-b322-b3ed77471662", "0ee5bab3-c977-4a14-a2ce-bb9a478836d8", "0f0fbed5-8853-479b-a9cd-acee3f9cd491", "111746a5-9f85-4890-98ab-328e42716c0c", "12f91ba3-a9b5-4ec8-b9d4-a15c502efbb7", "15ef1f3a-75d3-478f-8a95-8fd408072f3a", "1710ce55-8c6c-49cb-8dfc-024ca3f1b7ed", "19847e0d-aa3c-41b8-8326-567ed52a6b0a", "1b648568-7608-4bba-aa5d-7fbad3c725e5", "1ebb6d29-ef62-494a-9d32-b53bf10dc6cf", "1fc065a1-07a2-4bb5-bbce-a34122a9a792", "222263e9-1df1-441d-80e7-d2ce3f5eca31", "22f525d4-8d7d-4fa3-bd7c-12cf18eb606b", "25061b92-ea65-432d-a59f-23a3e58a28fc", "279847c2-f47a-46e1-9649-9020b89c0b69", "27e88222-758a-440e-b072-506a63698dba", "2872c6e4-a55c-4248-aec6-ffb53f2e0884", "2924b486-f56c-4df5-b080-dbb9230cb202", "2b4ef9c0-8534-4afc-b588-934f049895e7", "2bc058bb-d00a-4fa6-b768-adc3d496c8a9", "2c23b7ed-b461-403e-8f52-caf8a6f3a991", "2ccece8a-287a-4dc2-aad1-b5e110726b80", "312236d2-d0ef-4802-b85b-407cd3463dc3", "31916a3f-5247-44ae-b32c-fdc7cab42f16", "33759810-976d-48ac-8282-d8beb23dfa54", "34187a9d-df39-4162-913b-3e3ee5dac8eb", "34a5db73-7696-47e0-ac64-5b28b1a858fa", "35734dbb-8e31-417c-8950-a08eeda35016", "359cc531-69d9-40d4-b363-73db823a418b", "36d52ed5-6188-4ff1-a463-a14c110b4f19", "373dbaad-b567-491b-8356-9daea6110361", "37c854ab-691c-4416-aa0b-58b136014d45", "38bc3f6d-0921-4c17-bb77-9cf401d1da56", "3953501e-9af9-41b6-8466-b2c608d856ec", "39d143a3-4974-4297-9a94-199a83195cc4", "3ddf8245-810b-4404-881d-921589dd4e42", "3e991b02-bb09-49f1-af7d-3871e4431f12", "3fe788ee-6fd0-4f82-8e02-15511b8691c9", "42d38f12-3f08-41c8-8be8-95fe07b70e0c", "43370a7d-6907-44e3-a43f-426c58f4bb2a", "4456fae7-43d0-4426-bd36-6d962d7678c1", "47bfa9dc-3e80-406b-be1f-084548ea1ba7", "4931551b-0b44-403a-888e-09fd94d29fd4", "4fcbd72e-9f16-4ff5-917c-3b47c5143c4d", "5031a136-1446-4de2-b520-ad1ce4ab0171", "50368dfe-d3e1-48f5-a248-06834973a4ac", "51dfef09-7b12-4c27-a494-435acbc7acd7", "54c08fa4-dc1b-495a-ab3d-04bf45599581", "54eee38b-dd25-47a7-9f4b-526341975fe1", "57a4d024-d665-4bc8-9295-e92d08b2d2e7", "58bdc119-d37c-43a1-a003-7d1e07d2d217", "58c167a2-c255-44df-9ca0-63ce8afd19d9", "5fe65112-16a5-436e-a072-0f03a77d7a54", "601bc64c-1db6-4c24-86fe-99d63e210401", "62310616-3031-46b1-822c-98ff04e84ac4", "635a0ee0-739b-42d9-b31d-365dc21f2f5d", "6471ad16-7eb6-4531-926a-ac2ecb83360b", "6573c0b3-ffdd-4cda-9f86-915fc8bee9c0", "65d031b9-2a84-43d9-a23a-300bcccad40d", "662d8ae5-a35c-424c-8eab-092b1738a1c2", "6b69d224-3eff-458a-9a0e-7507f0ca1391", "6bfa75c9-ce12-4f7f-8b8f-741f6a5483b7", "6c2f7c40-e8c4-43ee-95be-0b6f6ae55f28", "6d868893-713d-4e04-901e-0323e7426c88", "6e00918b-fbcb-4be6-b39b-10a52ada9893", "733c5450-3f32-4fb1-a327-ce0d122d0dcf", "7669c229-4655-42f3-8944-4c75b8728e15", "79252d05-c529-4d30-a426-8eddeae66ff8", "7a492ead-dc86-4a16-a34a-772537b59baa", "7e1ac1d0-5589-4a71-832f-36cf693736da", "7e866492-9887-462d-be1b-b982f5e2c4ae", "818f142a-1881-499f-aaeb-27343e7bcf6b", "8251cdfa-6a54-4eb6-bcd5-034e829350c1", "826dcc00-1f9f-4ff5-b7f6-78607d418a39", "82e1cdf0-667a-4151-827e-fd7f475b1678", "859c711a-6be9-4160-86d0-6a2ac9e040bd", "879bab0b-c63d-4c84-80e1-3e554ef228b4", "8811d3cb-9b03-4c28-a09c-ea537db10c94", "88197d71-999e-4f2c-b7de-4004c0ac0e09", "8825fa8c-917d-4175-b8ab-8038d047a1e6", "88e92677-1b43-4973-ae41-77d2db7bca77", "890633ad-bdb2-4e26-9126-f11a86164491", "895ab26c-6a35-4cd3-887f-37bdd7f91bce", "8ed8542f-8072-4325-a7b9-f0ec0a957ed2", "8f06238c-41b4-4422-a250-b4a7e716b77e", "8f647372-612e-4c00-90f1-39f247b74a86", "92ced7c1-11a4-4898-8005-69564881c2e9", "9314bd1a-8f14-4ee0-b574-740df93e08bd", "935ec0de-3042-425f-aef5-4ee47b7d18e9", "93b79d7e-7ce9-4e41-9c4c-8ba6530899f0", "93d5fb9e-cec8-442f-8152-bc8c29813a3d", "9748db53-c534-4e6e-b3ac-27d43b1a960c", "9798f841-517c-40b8-b8d4-93e2cee66245", "9825642e-b464-43bd-bf9a-3fbb9f3fb7ed", "9a2390ac-513f-4218-8dcb-e12837173f00", "9b4376ba-1f28-4313-9fe9-68ffda1c35f8", "9c190f3b-ef74-4d05-a85a-cfaf4db6ada2", "9d5873a7-66a5-4099-86bd-642c4bf591b9", "9dfd418e-173e-4b47-a61a-55b507f0d952", "9e5b7f40-7774-4ab7-99c1-874b085223a8", "a03d7f63-5026-464a-b67f-c65f1756fa9e", "a6260ebd-32cc-4509-bdc2-91f35d607a72", "a626ee83-f9ff-40f2-bbdb-728773e8c47e", "a893dd54-4ad6-43db-bf8c-f815f60f1592", "a9b2a2ab-ebca-4e91-bcb0-12a25b3b8dae", "abe4ba54-426b-434b-b18f-2355a19a27e8", "aeeb96a8-e85c-41e2-a632-25cec4bff8c6", "b2bcd806-e600-4978-9118-b31bbc6e7528", "b2f9d2d3-a685-4ee7-90dc-d9a0b8b46cfb", "b58a4fa8-9b90-4687-8614-c69a11c1b790", "b7924971-7129-4e0c-a9d3-8a1ab9bdce19", "b7b76287-1ca6-45ba-9bf7-a1b7e62a6d33", "b8986291-9158-4d59-9d8e-7b4ee76f8611", "ba32024b-5b67-4682-a64e-2d4520cd12da", "bb25209f-f1a9-42c1-b3d4-7ca8a45fa3fd", "bb26e925-6c71-4af2-83ca-f73474d8ec23", "bb8a384e-6c5f-4c86-b55b-a08ace653922", "bc3df1b1-8dd1-4f7f-a01d-7a373cc15c3c", "bd16754c-45c2-462e-a9fb-1a5f54a2c903", "bd27e5ce-6300-4d6e-8a8c-4614f0d835f7", "bea5955a-3c8e-44a5-b4c9-b7092434c6a7", "bf325a9b-a30f-4c97-acd1-396e2e4e8b7f", "c018b8a3-9a56-415a-86cd-9c6617c7551f", "c0b0d97a-219b-4eee-a281-88223a258874", "c7bab162-4bd6-4946-ba3a-1c34dae7bbac", "cb157fcd-f3d4-4cc5-b199-ab52ff2f55c5", "cc9ef42c-859a-44d8-9b2e-8bc3f0f74812", "d003bc0e-14f3-4557-b164-a91ebc6a5f2d", "d3753361-af9a-41d8-b890-92678df73288", "d3bcd200-7556-4e25-b2b0-14bb785faa47", "d4e2d583-7449-4601-a5d8-6a65ff7b8812", "d5de2e3c-f534-410c-889d-4ae5583f80c7", "d63696d5-72c5-41b1-98f9-8d922717c000", "d7e4a913-d38f-4802-b8a5-85715bf8265e", "d80e3e99-48d7-45aa-8e0c-b098dc3da26f", "d81501bf-030c-43d5-963a-06afa725595c", "d883826c-2bcc-47cc-94ca-c8cf849e2810", "d991c097-ce38-4ce4-b7fa-9f729efb7f3f", "d9c3de2e-3324-4bb9-be7e-8d8a615a51b9", "da598a8f-5d4d-4b37-9294-4fe96f3566ee", "da74423c-112d-4651-836a-b8b7bed0104c", "dd5282f5-58c9-43ad-85ba-c868323cbbc4", "e05a8775-d6a0-4d6b-b700-8ede44e22735", "e10e451c-24d0-47df-8e6d-6f8e6eaa6c68", "e36fafb8-55b3-46f4-885b-8096894d2fd2", "e60e1bf0-1b15-41e2-8948-676d862a74ac", "eac24a19-7f80-40b8-91c9-e8b8930d3203", "eb28ffb2-31e8-4373-8af8-dad5321769bd", "eb425755-6081-45c1-a4ee-15c878bf106d", "ec6199d9-1d93-4b68-a9a9-196664458e30", "ef6f5e54-1248-4641-b9a1-6c2803fa3f63", "f0899184-ff2d-49e5-808f-4217ff5ef651", "f1fa9023-bf31-46ef-ada7-479e3b9883ff", "f3e2b0e0-86ae-4c5f-9f14-df7b819fbdea", "f4fc0dda-b2fa-4176-a350-68e995652b53", "f59db560-d404-4a9e-8727-f150ac7797f2", "f8f4581c-b367-40d4-8837-b90fda0ca81e", "f9c9c246-31c6-43a1-a48f-20d82bb2634c", "fa84d596-c647-4ce5-8a9c-3a786f5a12a7", "fc1e93bf-8fac-4bea-916c-20a011248767", "fc578aca-1859-4b1b-8745-bec59fc6b3f2", "fe3bc2f0-a043-457c-95fe-460805c77032", "feb4ddca-de0f-4c73-a8da-c409ca377a0c", "ff456593-2b0f-454a-b321-c16eb4339d35"], "title": "A survey of the use of crowdsourcing in software engineering", "venue": "Journal of Systems and Software", "year": 2017, "id": "fed8c353-5157-41d2-a88a-94c7bd99601a"}
{"abstract": "A fundamental challenge for parallel computing is to obtain high-level, architecture independent, algorithms which efficiently execute on general-purpose parallel machines. With the emergence of message passing standards such as MPI, it has become easier to design efficient and portable parallel algorithms by making use of these communication primitives. While existing primitives allow an assortment of collective communication routines, they do not handle an important communication event when most or all processors have non-uniformly sized personalized messages to exchange with each other. We focus in this paper on the h-relation personalized communication whose efficient implementation will allow high performance implementations of a large class of algorithms. While most previous   h-relation algorithms use randomization, this paper presents a new deterministic approach for h-relation personalized communication with asymptotically optimal complexity for  h>p 2  . As an application, we present an efficient algorithm for stable integer sorting.   The algorithms presented in this paper have been coded in Split-C and run on a variety of platforms, including the Thinking Machines CM-5, IBM SP-1 and SP-2, Cray Research T3D, Meiko Scientific CS-2, and the Intel Paragon. Our experimental results are consistent with the theoretical analysis and illustrate the scalability and efficiency of our algorithms across different platforms. In fact, they seem to outperform all similar algorithms known to the authors on these platforms.", "authors": ["David A. Bader", "David R. Helman", "Joseph J\u00e1J\u00e1"], "n_citation": 21, "references": ["0a91c7de-3ca2-40c7-ab99-5af7b119bf28", "0bc49e54-49cc-48c7-9798-344753f77c9e", "14338716-f7d9-4518-8023-af92d5a0fd47", "14524cab-ce67-4970-8981-c2e47700aafe", "1599d063-cd3b-41df-9a45-1f3c7c7516f5", "1e3d132a-4f86-4e52-9257-178d2a6d3847", "1ea1ca4d-d383-4416-8026-73c83ab58fa8", "28494c07-111e-4a8f-bffe-4d9157ee682f", "2c2b4cb0-e0ce-4bcf-b8a5-34fbfb03e929", "50e5e4fc-57b4-4a6a-95ad-33f5dd77efd5", "6198b5c7-94cc-4e40-ae15-c3ee8ac1ea4e", "694e8368-b9a4-49d4-96ba-e0f852ef9c2e", "8c200f0d-365f-4a49-8dcf-4492f12e075b", "933d0d61-8583-4024-9320-22e0a9a5e7cc", "986248f2-9d6b-4ec0-9c0c-499a0f7f6651", "9bd408eb-a3c2-4a00-a500-6e79a7c0eafc", "9e7f3a14-e586-4bad-aab9-0c36173e441d", "a0bd7049-39e1-4ab6-afd8-d67f9ec15d5f", "a4f95e3a-17b0-46ed-a588-341d2bc53a33", "ef58286c-baab-4b44-9cdb-5a928326c70e", "f907ccb0-2abe-47fd-b06a-f796909d4798"], "title": "Practical parallel algorithms for personalized communication and integer sorting", "venue": "ACM Journal of Experimental Algorithms", "year": 1996, "id": "97611aca-e7b8-4420-a43c-a57286480468"}
{"authors": ["Christoph F. Eick", "Peter C. Lockemann"], "n_citation": 40, "references": ["4382d7d7-1d9b-4f25-9131-b068c54de687", "5899eb6c-2e22-4d79-a2be-15fe67911177", "a334818b-9e22-4b37-bec7-9e040b9c5b87"], "title": "Acquisition of terminological knowledge using database design techniques", "venue": "international conference on management of data", "year": 1985, "id": "a3d65e26-5cdb-4203-a83b-1181ff8fab0b"}
{"abstract": "Quality attribute requirements are important both for customer and end-user satisfaction and for driving software system design. Yet asserting their importance raises many other questions. In particular, using quality attribute information in practice isn't obvious. Here, we consider two aspects of using such information: communicating with stakeholders about quality attributes and incorporating quality attribute requirements into existing analysis and design methods.", "authors": ["Ipek Ozkaya"], "n_citation": 74, "references": ["1ebe04f7-0d52-449a-a230-5316831deef9", "528985e5-7986-48ca-a2be-46a55c24f643", "e1cf5879-05c0-4397-bbf9-9c4f8307c5ce"], "title": "Making Practical Use of Quality Attribute Information", "venue": "IEEE Software", "year": 2008, "id": "c081ed21-f0de-4a6f-9a2a-1d08b4e8f740"}
{"abstract": "The analysis of time-oriented data is an important task in many application scenarios. In recent years, a variety of techniques for visualizing such data have been published. This variety makes it difficult for prospective users to select methods or tools that are useful for their particular task at hand. In this article, we develop and discuss a systematic view on the diversity of methods for visualizing time-oriented data. With the proposed categorization we try to untangle the visualization of time-oriented data, which is such an important concern in Visual Analytics. The categorization is not only helpful for users, but also for researchers to identify future tasks in Visual Analytics.", "authors": ["Wolfgang Aigner", "Silvia Miksch", "Wolfgang M\u00fcller", "Heidrun Schumann", "Christian Tominski"], "n_citation": 266, "references": ["0c66ece5-fc9a-4373-b11d-5f04afa4313c", "112b8a3a-29be-4c1d-a957-2b8518451fd2", "140344f3-5f8c-477b-a4b6-1fa83eb626fd", "238a97a7-9ce0-40d5-9b74-1a6fffb245de", "25352a11-5132-483e-9132-6c88ec0da284", "29ac64ba-bc24-495c-95ef-dc6a2d480868", "38f63cb6-03f5-4e4f-99e6-0bfdf78595d3", "443df85b-2509-46e6-bd73-703f81c68d44", "4dd10792-e93b-4415-8627-f14b1c2d5ba8", "5125dcd6-42bc-44c9-8c6b-0c96df90a120", "59513cc3-9b35-40e6-8aee-de5303ee9e0a", "5fe17db0-e43b-4996-8969-93553450cded", "67bc5445-b518-42e0-8b9b-0b7fa1ba82be", "74722916-d8ff-4949-8781-e86a0eeaaa4e", "8e34b9ea-e947-41f3-a097-5964b058bdc8", "99ecd67f-71d1-4e09-b2e9-baf393989055", "9b470fe4-260e-47bd-bd5d-647d5824f61c", "a2589cd6-3ba0-4525-bf03-b875d6f9d905", "a4e12b0b-9d42-41e8-8efa-f77fcfa5c22d", "a96c09a1-1498-4ec4-a612-deb34e50809f", "d64f8f03-596c-44db-a19d-997c17f22958", "dbe5ae2e-bbc0-4508-8df5-3ec95c784fa8", "ddd8e18f-87a0-4593-a02c-c9d38d43deb9", "df1d03d6-68b3-46d2-bae8-d42937b15d17", "f0f7727d-dace-4696-9d24-d7c0cad7e628", "fc7cc344-e25b-471d-8831-55b267c7822d"], "title": "Visualizing time-oriented data-A systematic view", "venue": "Computers & Graphics", "year": 2007, "id": "67c2f7b5-f78a-459b-9977-39c4d2ea4e74"}
{"authors": ["Robert E. Kraut", "Mark D. Miller", "Jane Siegel"], "n_citation": 244, "references": ["1b26f956-9093-41bc-8572-b95638514494", "4f644674-a888-436d-a462-b9ff6df8a7cf", "820df3cd-cc69-49b3-a6ac-158080e17d59", "be0f8248-56be-4ee1-91bf-86ca0557d55e"], "title": "Collaboration in performance of physical tasks: effects on outcomes and communication", "venue": "conference on computer supported cooperative work", "year": 1996, "id": "d020c78f-a496-4c64-ae44-c6f3d3cd205d"}
{"abstract": "A model of purely reactive planning is proposed based on the concept of reactive action packages. A reactive action package, or RAP, can be thought of as an independent entity pursuing some goal in competition with many others at execution time. The RAP processing algorithm addresses the problems of execution monitoring and replanning in uncertain domains with a single, uniform representation and control structure. Use of the RAP model as a basis for adaptive strategic planning is also discussed.", "authors": ["R. James Firby"], "n_citation": 595, "references": ["10856ea1-7e46-41b7-b1a8-01292a2ffac9", "ac45cc64-5419-4aa2-a228-922b8dee828c", "fe537d93-5826-48ec-a1c5-8728d60b2167"], "title": "An investigation into reactive planning in complex domains", "venue": "national conference on artificial intelligence", "year": 1987, "id": "02a46801-c4d8-42cc-9361-7e77e983157d"}
{"authors": ["James P. Delgrande", "Torsten Schaub"], "n_citation": 41, "references": ["2165976f-a725-44ab-8901-aaec0ad8171d", "4c675fc8-2244-42f0-91c3-eaba4b1537a5", "6dcf9f47-7a83-40b6-890b-9f6bc8585986", "9f58b6de-3ce7-4e2f-bf2b-2140b3e5a57f", "a665f512-85cd-4423-8a7a-26bff3123971", "b19e5079-3587-4039-8b40-6b8b6a175763", "ca1adb3a-ddc9-40d6-8816-0e823fb1ecfd", "dae4fa38-2aaa-45dd-a731-28eb7b82c9c1"], "title": "Compiling Reasoning with and about Preferences into Default Logic.", "venue": "international joint conference on artificial intelligence", "year": 1997, "id": "9070e1d3-89b2-40e7-8d67-cc4c35a7c982"}
{"abstract": "In many vision applications, the practice of supervised learning faces several difficulties, one of which is that insufficient labeled training data result in poor generalization. In image retrieval, we have very few labeled images from query and relevance feedback so that it is hard to automatically weight image features and select similarity metrics for image classification. This paper investigates the possibility of including an unlabeled data set to make up the insufficiency of labeled data. Different from most current research in image retrieval, the proposed approach tries to cast image retrieval as a transductive learning problem, in which the generalization of an image classifier is only defined on a set of images such as the given image database. Formulating this transductive problem in a probabilistic framework the proposed algorithm, Discriminant EM (D-EM) not only estimates the parameters of a generative model but also finds a linear transformation to relax the assumption of probabilistic structure of data distributions as well as select good features automatically. Our experiments show that D-EM has a satisfactory performance in image retrieval applications. D-EM algorithm has the potential to many other applications.", "authors": ["Ying Wu", "Qi Tian", "Thomas S. Huang"], "n_citation": 255, "references": ["0500ddbe-e274-477b-bb6b-54a7269e4577", "057e5c13-bfd9-4aa0-9300-1d8093749691", "13b91eb0-0857-4556-b32a-0f85a1cf43f6", "261aefde-fbe5-494f-afd7-c771aff03127", "2950b285-f9c7-4eb0-bfc7-fe4df52ccac0", "56d6466f-28bc-429c-a969-9b9609398481", "62a46780-e1d9-4186-babe-6179735d785e", "7bc911cc-6027-4e4c-9a45-44218616fab1", "ada79c60-f8d7-41d3-a8dc-7a88d22ea37d", "e37185ff-428f-49b5-a976-9b8fdd8b19b2", "f9eb4ac4-ddf9-4e7a-a40b-1b54a56eda8c"], "title": "Discriminant-EM algorithm with application to image retrieval", "venue": "computer vision and pattern recognition", "year": 2000, "id": "7e7d82ae-865f-46eb-9a38-ad180c1d1d60"}
{"abstract": "Technological directions for innovative HPC software environments are discussed in this paper. We focus on industrial user requirements of heterogeneous multidisciplinary applications, performance portability, rapid prototyping and software reuse, integration and interoperability of standard tools. The various issues are demonstrated with reference to the PQE2000project and its programming environment Skeleton-based Integrated Environment (SkIE). SkIEincludes a coordination language, SkIECL, allowing the designers to express, in a primitive and structured way, efficient combinations of data parallelism and task parallelism. The goal is achieving fast development and good efficiency for applications in different areas. Modules developed with standard languages and tools are encapsulated into SkIECLstructures to form the global application. Performance models associated to the coordination language allow powerful optimizations to be introduced both at run time and at compile time without the direct intervention of the programmer. The paper also discusses the features of the SkIEenvironment related to debugging, performance analysis tools, visualization and graphical user interface. A discussion of the results achieved in some applications developed using the environment concludes the paper.", "authors": ["Bruno Bacci", "Marco Danelutto", "Susanna Pelagatti", "Marco Vanneschi"], "n_citation": 119, "references": ["023f889e-03c3-41bd-b522-bcc11143c287", "12826b73-be05-4c96-9999-e933d5e6b835", "20bb293e-b185-49e2-a87f-79fe7b4236ad", "29fb4215-67a2-4edc-9f50-8fdf144480c1", "2af2b6e8-d7aa-477a-abee-2e304c5164e9", "30cab2c8-ff8a-4ce4-a036-67b121d035a5", "4b0f9fe8-0c52-45c9-8def-312b50313c88", "7171b024-9e5a-4550-88a5-4dad2703ad27", "73ad12a5-0e1a-435d-bb5f-040c9aa9568f", "7faa4ff1-fde3-49ed-af59-09975bc6c211", "8033f596-16a4-47dc-8a5f-835545d093ad", "914f569a-7301-4e7a-801a-35aba945d1e7", "a5636c72-10ee-4c45-8a01-4115c0ec5881", "c5848b74-4030-4146-bb0a-94454c63fa26", "ce5453cf-28e1-4877-b28a-89a0d9dddead", "e0b204a9-df7e-41c8-8859-f8f705773663", "e41a9e39-f68c-4d4c-a01e-5f615e26078f", "ecd6a845-8439-49b0-abe8-f71fff81da23"], "title": "SkIE: a heterogeneous environment for HPC applications", "venue": "parallel computing", "year": 1999, "id": "64b48e47-b65a-43d8-a8ee-d272bfdeda4f"}
{"abstract": "HighlightsWe present a design rule specification language for aspect-oriented systems.We explore its benefits to supporting the modular development of classes and aspects.We discuss how our language improves crosscutting modularity without breaking class modularity.We present a Compiler for LSD and AspectJ (COLA), a tool to automate design rules checking.We evaluate it using a real case study and compare it with other approaches. Aspect-oriented programming is known as a technique for modularizing crosscutting concerns. However, constructs aimed to support crosscutting modularity might actually break class modularity. As a consequence, class developers face changeability, parallel development and comprehensibility problems, because they must be aware of aspects whenever they develop or maintain a class. At the same time, aspects are vulnerable to changes in classes, since there is no contract specifying the points of interaction amongst these elements. These problems can be mitigated by using adequate design rules between classes and aspects. We present a design rule specification language and explore its benefits since the initial phases of the development process, specially with the aim of supporting modular development of classes and aspects. We discuss how our language improves crosscutting modularity without breaking class modularity. We evaluate it using a real case study and compare it with other approaches.", "authors": ["Alberto Costa Neto", "Rodrigo Bonif\u00e1cio", "M\u00e1rcio Ribeiro", "Carlos Eduardo Pontual", "Paulo Borba", "Fernando Castor"], "n_citation": 12, "references": ["150b39ec-d8ec-45aa-9744-c61638d9002c", "1623e909-f646-4bcf-bddf-5a3cb34aac0c", "1b200fff-a83b-45bb-b601-066ccae12555", "395cb19b-a02d-4038-9b34-afaa062874ee", "47f5e5fa-7d03-4451-9ace-53b6975fa14d", "482f4330-445f-4719-8ebf-9093f5ea01b8", "57d09d8b-0aec-4f37-b64a-78dfc654a976", "5bbcfa28-3503-4624-8f2c-06d23d7c1718", "60a20f02-351d-47e7-b4a1-b2f5bce4f5a7", "663c008e-1327-4846-8936-f7a9cafbd9de", "6adc9bbd-81c7-44a3-8ac6-731c3bff4506", "710fe17b-57e0-4e1f-8fcf-75125fdfeb36", "76dc35cc-8186-4280-9028-a2cee7f6a083", "7ab910c3-8ee0-4e40-aaea-d312875ef45b", "7da83421-378b-4056-a97c-ff5ef55735b4", "7db36938-8082-4ce5-906f-9a1ebbce42f6", "80b630c0-db28-4494-b124-d5d89f26defb", "86ecd9f0-087c-4739-a09c-3145d1896d65", "86f7678c-106e-40bb-b734-64e959dacfe6", "8a3b1444-7869-4f58-899a-3284c27ddb49", "8b57a3d5-2a29-4cd8-9a8b-ab04ea2fbcf2", "91a576f2-6f4e-4e93-8b9a-2910f93e7b8d", "9e8048b1-731a-478d-937a-23760edcdd20", "b5e0d4f5-e2c4-4246-b2ce-50f65d53e767", "cdaf6922-6389-460c-b335-1067d71c851e", "ce4c29b6-deff-4556-bbf0-b51fe37cd7d8", "d002cd75-6922-4e7b-8088-2a57bcb572ef", "d6285e34-13fa-4327-b4f9-203181baa8c6", "df85b4a2-72d3-4ff2-b804-e2c07d1379ec", "e46ac323-a7cb-493d-a10d-54a61e4b3d64", "e483ec57-d0c7-4b88-9d25-ec334550dfdc", "e75e98af-1095-4615-b9bf-268a0e210e92", "fa52eada-074b-4de5-966c-e296d6222079", "fd3c0d46-0bfd-4635-bf91-21eb295a9fb2"], "title": "A design rule language for aspect-oriented programming", "venue": "Journal of Systems and Software", "year": 2013, "id": "238f807f-c94d-4a52-89ed-7ebb69108a23"}
{"authors": ["Jan A. Bergstra", "Jan Willem Klop"], "n_citation": 27, "title": "Strong normalization and perpetual reductions in the lambda calculus", "venue": "Journal of Automata, Languages and Combinatorics", "year": 1982, "id": "a495a521-04a8-4cd6-8eea-b29e02b2e42b"}
{"abstract": "This paper addresses complexity issues for important problems arising with disjunctive logic programming. In particular, the complexity of deciding whether a disjunctive logic program is consistent is investigated for a variety of well-known semantics, as well as the complexity of deciding whether a propositional formula is satisfied by all models according to a given semantics. We concentrate on finite propositional disjunctive programs with as well as without integrity constraints, i.e., clauses with empty heads; the problems are located in appropriate slots of the polynomial hierarchy. In particular, we show that the consistency check is \u03a32p-complete for the disjunctive stable model semantics (in the total as well as partial version), the iterated closed world assumption, and the perfect model semantics, and we show that the inference problem for these semantics is \u03a02p-complete; analogous results are derived for the answer sets semantics of extended disjunctive logic programs. Besides, we generalize previously derived complexity results for the generalized closed world assumption and other more sophisticated variants of the closed world assumption. Furthermore, we use the close ties between the logic programming framework and other nonmonotonic formalisms to provide new complexity results for disjunctive default theories and disjunctive autoepistemic literal theories.", "authors": ["Thomas Eiter", "Georg Gottlob"], "n_citation": 310, "references": ["05f59ebe-6fcf-435e-ad81-a13583c94c23", "082f2e87-aae4-4b53-92d1-c1c432588f6f", "09c19ddd-b0a4-477d-bc0b-025882bca35a", "0c78762f-24a1-49a6-aaab-6f5313c600c7", "122e315e-6030-408e-a232-4c28c4abd699", "1669e386-de39-492f-bf82-f3abe62910b3", "2043a707-afaa-4bbb-8777-d4c60a9b671c", "33bafefd-2634-4585-9cc7-b7ff2ea42c4e", "349b4cb0-7d84-4aa8-bd0c-055804f8db1f", "4253a753-6e4b-48b9-8657-7f40fae10b48", "43959b1e-98f1-45c5-a7eb-cfeb9ce364d9", "5122ac01-29ec-465c-8aab-81710078eae4", "56d4c644-ea3f-4d44-8693-92347357b749", "5a729ab1-c3d9-4fe1-b2f5-9a28e3360771", "63a954b4-8c86-4a66-9b3a-6b0c6b75d538", "669d4af4-ce85-40c1-bb35-19f122debda4", "7618d7f5-d8e5-497c-9d00-80cc8813c6a0", "77bcbb3a-6ecb-41e5-8273-56fd75c66bbc", "78ca296c-a180-4354-bb98-3b62578d737e", "90c00545-9035-4046-bee9-f80a25af1d37", "92681c52-f5cd-478d-8654-1488c4a3003a", "9eab0b38-27d3-4026-9168-b3cb4b15e15a", "a8ab769d-10fb-432a-b045-a3a29ac8f947", "acb9848b-f1f7-4dfd-8410-3486c10dca71", "b220e307-d5d2-45fc-986e-7083dab2120f", "b7b3b1e7-ff7d-455c-aa61-86c50ea972fc", "b86ff135-5f40-483d-9d85-62e21878b5e4", "c5dc72b8-5aee-47c2-b7b0-045abb1dac51", "cbf4ea3f-a8be-4569-b5ed-e5a4ae405f4e", "db658327-1f48-4f80-8f7d-09d88096f297", "dc1927e0-056c-4548-b60b-fdcce5c7ba8f", "dee6984f-75aa-478c-a413-5442908310f7", "e22908da-10e5-49ec-93ed-2d7b1e1e8da3", "e6f5c743-13e8-4a51-b832-8ab1ee2de219", "eba510ad-c220-44a3-8c66-306d6cb45d2e", "f577584e-f69c-450a-9308-cc545c7b6d1f", "f9745577-116f-4a8f-a630-c459f84c360d"], "title": "On the Computational Cost of Disjunctive Logic Programming: Propositional Case", "venue": "Annals of Mathematics and Artificial Intelligence", "year": 1995, "id": "f0315c60-9807-477b-bec5-9058f58f58aa"}
{"abstract": "The rise in popularity of social networking sites such as Twitter and Facebook has been paralleled by the rise of unwanted, disruptive entities on these networks- \u2014 including spammers, malware disseminators, and other content polluters. Inspired by sociologists working to ensure the success of commons and criminologists focused on deterring vandalism and preventing crime, we present the first long-term study of social honeypots for tempting, profiling, and filtering content polluters in social media. Concretely, we report on our experiences via a seven-month deployment of 60 honeypots on Twitter that resulted in the harvesting of 36,000 candidate content polluters. As part of our study, we (1) examine the harvested Twitter users, including an analysis of link payloads, user behavior over time, and followers/following network dynamics and (2) evaluate a wide range of features to investigate the effectiveness of automatic content polluter identification.", "authors": ["Kyumin Lee", "Brian Eoff", "James Caverlee"], "n_citation": 159, "references": ["042dd086-682e-4935-89e7-beb140146da5", "062909bb-7855-4357-a88b-1e7cb756db21", "0f115eea-2272-431f-9f21-6d6789b2bbc9", "1d0a3d3b-cd06-4b5c-82d6-faa74a7f33c6", "27831621-2eb6-4d5f-aae8-f593c6ad86ec", "2e499e1a-df4d-4149-888b-0cd98980e5ed", "3471d0a7-d8c0-4f29-b6c5-baddf9bd1290", "353722fa-1f5b-48d5-93b7-6a3868a5b0b4", "408f95bf-bae8-4146-ba25-feb2f59a78a7", "40d9a6c9-b99e-43cc-90eb-5259cf4416a0", "4725458c-f1c3-4c96-ad12-1c0f1e2fe198", "66da5f88-fae3-4574-b099-effdf4a5a597", "693c3fe4-600e-4af9-823a-405629e4f22f", "75b077ca-a9ba-4a46-88e7-e55611443446", "9f4995af-e704-48ab-8717-6972a3d4455b", "a20ced4b-1f9c-4c0b-979d-e1a3c7b37847", "b5bc4e0b-5bfc-416e-b3a8-0748482bb82e", "c6c515b0-ea70-49aa-b906-4c9d4bd6ea81", "da773e14-5247-4600-8da8-2452699899d9", "db26488d-78be-44b1-a343-e896f43c5d29", "e9f868ad-7254-4925-b6fc-385bee5dea45", "ffeeeb29-c4fd-4d3b-aa22-55ae0154bb51"], "title": "Seven Months with the Devils: A Long-Term Study of Content Polluters on Twitter.", "venue": "international conference on weblogs and social media", "year": 2011, "id": "e0fe45c0-9607-4dfa-88df-159c129e27c0"}
{"abstract": "Early type-safe operating systems were hampered by poor performance. Contrary to these experiences we show that an operating system that is founded on an object-oriented, type-safe intermediate code can compete with MMU-based microkernels concerning performance while widening the realm of possibilities. Moving from hardware-based protection to software-based protection offers new options for operating system quality, flexibility, and versatility that are superior to traditional process models based on MMU protection. However, using a type-safe language-such as Java-alone, is not sufficient to achieve an improvement. While other Java operating systems adopted a traditional process concept, JX implements fine-grained protection boundaries. The JX System architecture consists of a set of Java components executing on the JX core that is responsible for system initialization, CPU context switching and low-level domain management. The Java code is organized in components which are loaded into domains, verified, and translated to native code. JX runs on commodity PC hardware, supports network communication, a frame grabber device, and contains an Ext2-compatible file system. Without extensive optimization this file system already reaches a throughput of 50% of Linux.", "authors": ["Michael Golm", "E. Kleinder", "Frank Bellosa"], "n_citation": 20, "references": ["09717162-5655-46c3-8ca9-172479bc309b", "115ce5c8-8c08-46b1-a100-f6aaa68f20d5", "40353a40-877d-4588-9b0f-1e719acc5547", "5268dd27-cea9-4f6e-8d1b-24bff534d700", "60564e43-8c94-4887-a95f-f71d263f2113", "6dc71be7-44ed-40e0-a4c3-6b5f46fe8e78", "960f7d7c-175f-47f5-a1e3-829637d8d3a3", "b96d7b20-ecc6-43f4-a0da-1c45ef12d05a"], "title": "Beyond address spaces-flexibility, performance, protection, and resource management in the type-safe JX operating system", "venue": "ieee international conference on requirements engineering", "year": 2001, "id": "d3031c52-f42d-4d36-afcc-37d796987c98"}
{"abstract": "Modern organizations have invested in collections of descriptive and/or normative process models, but these rarely describe the actual processes adequately. Therefore, a variety of techniques for conformance checking have been proposed to pinpoint discrepancies between modeled and observed behavior. However, these techniques typically focus on the control-flow and abstract from data, resources and time. This paper describes an approach that aligns event log and model while taking all perspectives into account (i.e., also data, time and resources). This way it is possible to quantify conformance and analyze differences between model and reality. The approach was implemented using ProM and has been evaluated using both synthetic event logs and a real-life case study.", "authors": ["Massimiliano de Leoni", "Wil M. P. van der Aalst"], "n_citation": 50, "references": ["06d1afa4-dedb-4c16-9ed8-a7f1ab391516", "15c67eca-f869-457a-b844-cd174e4ac3af", "47840751-177a-4ca3-86bf-6d0849ebe390", "494fdd79-19b3-4785-bbac-8849747910b4", "5eb91813-afd2-4e25-9d4d-f25bd1e07b0d", "62d08f68-dcfe-4156-b9bd-5b19393d93e7", "81aa483f-80b6-4cc2-a7bf-a434ab9e2e4a", "822fd357-5794-44a5-adc6-4b1453b41524", "922f7177-8c19-4487-859f-7367a233fa58", "acadb400-10fd-42c3-9308-6f105711711e", "b83dd342-a0a6-4352-9a06-e8ae14ae123e", "bb23ef6a-9659-47c6-a7f6-88092fb0b3ea", "ef8de76a-262e-4875-b2fd-b2253bc73df4"], "title": "Aligning event logs and process models for multi-perspective conformance checking: an approach based on integer linear programming", "venue": "business process management", "year": 2013, "id": "96ab8d2e-0816-453b-b8a7-9408393b324b"}
{"abstract": "A critical problem faced by a network intrusion detection system (NIDS) is that of ambiguity. The NIDS cannot always determine what traffic reaches a given host nor how that host will interpret the traffic, and attackers may exploit this ambiguity to avoid detection or cause misleading alarms. We present a lightweight solution, active mapping, which eliminates TCP/IP-based ambiguity in a NIDS analysis with minimal runtime cost. Active mapping efficiently builds profiles of the network topology and the TCP/IP policies of hosts on the network; a NIDS may then use the host profiles to disambiguate the interpretation of the network traffic on a per-host basis. Active mapping avoids the semantic and performance problems of traffic normalization, in which traffic streams are modified to remove ambiguities. We have developed a prototype implementation of active mapping and modified a NIDS to use the active mapping-generated profile database in our tests. We found wide variation across operating systems' TCP/IP stack policies in real-world tests (about 6700 hosts), underscoring the need for this sort of disambiguation.", "authors": ["Umesh Shankar", "Vern Paxson"], "n_citation": 214, "references": ["32023d73-8f09-4373-ad28-265433ef25fa", "9193238c-cd88-4334-b53f-c3d18ce59f02", "a59be9de-2672-4f92-8ff6-636b3afbce68", "eff9cf9d-018e-4cb0-b29b-fc290c5cef35"], "title": "Active mapping: resisting NIDS evasion without altering traffic", "venue": "ieee symposium on security and privacy", "year": 2003, "id": "c744ed02-6599-4840-a45d-7366f52a3d16"}
{"authors": ["Edsger W. Dijkstra"], "n_citation": 50, "title": "EWD 1308: what led to notes on structured programming", "venue": "", "year": 2002, "id": "4da415d6-5710-44cb-870b-df641f299280"}
{"abstract": "Many systems for tasks such as question answering, multi-document summarization, and information retrieval need robust numerical measures of lexical relatedness. Standard thesaurus-based measures of word pair similarity are based on only a single path between those words in the thesaurus graph. By contrast, we propose a new model of lexical semantic relatedness that incorporates information from every explicit or implicit path connecting the two words in the entire graph. Our model uses a random walk over nodes and edges derived from WordNet links and corpus statistics. We treat the graph as a Markov chain and compute a word-specific stationary distribution via a generalized PageRank algorithm. Semantic relatedness of a word pair is scored by a novel divergence measure, ZKL, that outperforms existing measures on certain classes of distributions. In our experiments, the resulting relatedness measure is the WordNet-based measure most highly correlated with human similarity judgments by rank ordering at = .90.", "authors": ["T. J. R. Hughes", "Daniel Ramage"], "n_citation": 184, "references": ["11d6d688-f542-4d4e-8a9e-50150c7f08e3", "36ff38a3-f0fd-403b-a9eb-cb69dd67da14", "3e1c7e71-b0ee-4ddd-8fb9-09a6bf51181f", "3fd6eb96-c103-4d42-971f-9267a70cc14d", "415ebf33-abfc-4d11-97a9-6db94db271ec", "51bd8299-2450-4387-aa6f-bfff35b61db2", "540f653d-dc81-4160-9755-3cd96bc46bb0", "693f01b1-a59e-4e2c-bbde-f2e0923e39b8", "6d4f935d-fbf4-4570-a50e-b08ec80701f5", "7d8b89ee-ec9a-4584-8259-20267d8dc0a6", "7e645996-0aa3-4316-b506-03e013d0989f", "89f7c1b8-fd2a-41db-bb13-9bdaf250a746", "a9b6de50-1484-4584-8989-82b15c522b1b", "ab68780d-3419-4b9f-be4a-354c01e6ca6c", "af421dd3-1938-4035-9182-2d3a9e573b14", "b3fb146b-a8aa-42aa-8dba-7c705c139bff", "ccd672d4-2f77-471e-abfc-cae8abd6ec16", "cdba266b-03f0-4752-8c37-91e4d997a3e4", "df454ecc-0d54-49db-b958-a5acf48f20a5", "e1fb6fae-859f-4498-b587-1a7d23b27e45"], "title": "Lexical Semantic Relatedness with Random Graph Walks", "venue": "empirical methods in natural language processing", "year": 2007, "id": "b4ed0609-6e96-424e-94d2-3218225a4b5e"}
{"abstract": "As most 'real-world' data is structured, research in kernel methods has begun investigating kernels for various kinds of structured data. One of the most widely used tools for modeling structured data are graphs. An interesting and important challenge is thus to investigate kernels on instances that are represented by graphs. So far, only very specific graphs such as trees and strings have been considered. This paper investigates kernels on labeled directed graphs with general structure. It is shown that computing a strictly positive definite graph kernel is at least as hard as solving the graph isomorphism problem. It is also shown that computing an inner product in a feature space indexed by all possible graphs, where each feature counts the number of subgraphs isomorphic to that graph, is NP-hard. On the other hand, inner products in an alternative feature space, based on walks in the graph, can be computed in polynomial time. Such kernels are defined in this paper.", "authors": ["Thomas G\u00e4rtner", "Peter A. Flach", "Stefan Wrobel"], "n_citation": 666, "references": ["01f15552-88f8-48ca-a75a-663822a6199a", "2f29f0ff-02ad-43ea-a1b6-519bfb322db0", "39ed6f99-cd63-45fe-a915-00bf32713038", "3e5fd33f-1fd0-4815-a47a-3c41a26a538a", "6b3483b2-504d-454e-8f03-e58ad4c7f4b0", "dbae7bb7-6db4-45e2-b942-a07b03c538ad", "f006e236-59ad-4647-a59f-4f46dc2c85be"], "title": "On Graph Kernels: Hardness Results and Efficient Alternatives", "venue": "computational learning theory", "year": 2003, "id": "f5c7eec7-f583-4244-b109-9fdfd40279ae"}
{"abstract": "The purpose of this paper is to propose a distributed control scheme to maximize area coverage by a mobile robot network while ensuring reliable communication between the members of the team. The information that is generated at the sensors depends on the sensing capabilities of the sensors as well as on the frequency at which events occur in their vicinity, captured by appropriate probability density functions. This information is then routed to a fixed set of access points via a multi-hop network whose links model the probability that information packets are correctly decoded at their intended destinations. The proposed distributed control scheme simultaneously optimizes coverage and routing of information by sequentially alternating between optimization of the two objectives. Specifically, optimization of the communication variables is performed periodically in the dual domain. Then, between communication rounds, the robots move to optimize coverage. Motion control is due to the solution of a distributed sequential concave program that handles efficiently the introduced nonlinearities in the mobility space. Our method is illustrated in computer simulations.", "authors": ["Yiannis Kantaros", "Michael M. Zavlanos"], "n_citation": 27, "references": ["142d0355-af90-43c6-997e-0fba45592173", "2369f277-3fb8-45c7-a2c3-062f73dda3d1", "2ba10166-89ad-4ca9-a41f-6269226fa7e9", "2e30b3f0-2b6c-4b21-9405-eef486f96dfb", "33988d4f-33fb-40a1-9247-f56fc620ab99", "3aa7cbab-d199-41ea-bfa4-e34aa9917cb2", "476a961f-8066-4605-bfa4-440db4d7fcef", "595edf13-3cec-4608-b655-711d776522c2", "5b1632f1-f773-4e47-b882-4c691a682b80", "67f7da9b-757f-4908-8c41-df6934f95b36", "6cb99a50-eb26-4ddb-a86c-dbdedc193814", "72c91fb5-af0f-4a96-ba5a-22e135f4b604", "79c828d8-2e79-45b1-8eff-06f7e9fd3105", "88953eab-5ffc-494e-b7f8-714917b76a98", "9ce15202-c6b6-4af9-85c8-7cc2cbb0daa5", "b1cb9c2a-19d0-42b8-8711-2ac99bd8665d", "c267034b-d857-4343-939b-a7255b324665", "cd3f397e-5048-40ca-a871-89f625583c2a", "d00d8e40-85ec-414b-8c0a-0ab738204236", "d63aeb27-62f3-4d6e-a6df-aed1f6a74609", "e51351dc-b262-42d7-b1bb-21171b3c9c53", "eae1a5ad-fc85-47c7-87a2-07511e98dafa", "efa15b9e-ef36-43b1-8ef9-6726bc3f88c4", "efed0c9f-6b90-4c0a-ba67-65d4b2bee0de", "fa6c5029-3f78-433c-8de5-df068b1b5513"], "title": "Distributed communication-aware coverage control by mobile sensor networks", "venue": "Automatica", "year": 2016, "id": "e934b6b7-a3c7-4d62-89d0-615a0c9a7009"}
{"abstract": "We present a logical framework that is able to deal with variability in product family descriptions. The temporal logic MHML is based on the classical Hennessy-Milner logic with Until and we interpret it over Modal Transition Systems (MTSs). MTSs extend the classical notion of Labelled Transition Systems by distinguishing possible (may) and required (must) transitions: these two types of transitions are useful to describe variability in behavioural descriptions of product families. This leads to a novel deontic interpretation of the classical modal and temporal operators, which allows the expression of both constraints over the products of a family and constraints over their behaviour in a single logical framework. Finally, we sketch model-checking algorithms to verify MHML formulae as well as a way to derive correct products from a product family description.", "authors": ["Patrizia Asirelli", "Maurice H. ter Beek", "Alessandro Fantechi", "Stefania Gnesi"], "n_citation": 60, "references": ["1561610b-280d-4435-b3df-45e5d1588466", "16ed4414-8450-4865-b05e-0cb212335690", "27f1e1a2-045c-4944-a71c-8bbac426fd6e", "28c49b78-9398-4832-baa9-0207cba36e12", "38a2a420-0009-4a97-bfe7-8300dff9149b", "39b0462a-ea6f-4911-bbc2-32908de99d72", "3ac62a82-475e-436d-9cb2-2ff40e7c52c2", "48138409-6776-43d0-b054-d4e901cdfeaa", "4814eca2-167a-48bd-a7e6-60150e7a54e3", "51dc0300-ad75-43cf-8918-43d69f45bc6f", "5b1f615a-1fe4-4d1d-87fc-eecbb56069ff", "5bd2b010-0668-4b03-a6ab-ade8c5760e1f", "646f3f6c-04b6-4258-940e-40d653a3cae1", "737de1cf-5cf6-4496-87da-3523f4228eba", "86e5cdca-c679-4129-8f03-e5a50d071ae2", "af441cc5-1428-4eed-be6a-aefdd6246676", "bb272fc8-eaaf-4b68-856a-44188d9fd00d", "c00bbb49-6e29-4103-8883-55acd23c248b", "c0c7dcbd-12c1-4c9e-902d-b20805fd6c1c", "dfc66cbb-b353-4b61-8ae8-0762b1031f11", "ec558db3-fb8a-4939-b69a-aa0e412e6eaf", "f3396477-6279-4a16-acdf-2841cb84ec38", "f947314b-9a49-4b41-825b-b5b9b53a7370", "fd248406-c25d-4178-8d99-36f7adef5479"], "title": "A logical framework to deal with variability", "venue": "integrated formal methods", "year": 2010, "id": "49e2ccc5-9782-4c6d-b59b-d0959405e8a2"}
{"abstract": "Despite much progress, developing a pervasive computing application remains a challenge because of a lack of conceptual frameworks and supporting tools. This challenge involves coping with heterogeneous devices, overcoming the intricacies of distributed systems technologies, working out an architecture for the application, encoding it in a program, writing specific code to test the application, and finally deploying it. This paper presents a design language and a tool suite covering the development life-cycle of a pervasive computing application. The design language allows us to define a taxonomy of area-specific building-blocks, abstracting over their heterogeneity. This language also includes a layer to define the architecture of an application, following an architectural pattern commonly used in the pervasive computing domain. Our underlying methodology assigns roles to the stakeholders, providing separation of concerns. Our tool suite includes a compiler that takes design artifacts written in our language as input and generates a programming framework that supports the subsequent development stages, namely, implementation, testing, and deployment. Our methodology has been applied on a wide spectrum of areas. Based on these experiments, we assess our approach through three criteria: expressiveness, usability, and productivity.", "authors": ["Damien Cassou", "Julien Bruneau", "Charles Consel", "Emilie Balland"], "n_citation": 50, "references": ["02e0342a-33d3-4d3f-9f1d-b14081edbc39", "0799b394-2cf5-4e9a-a15b-9882c15e3f4c", "14d015a9-1d86-4fd2-b547-68dec15851a1", "18344ce8-faba-4078-a074-a81f5ebdd469", "1b560815-0d8d-44be-915b-af39eb7395e6", "26da3a50-03e4-467d-bdef-0e6f69119eb2", "419af669-5c37-4931-b118-938512f6c78d", "471b5c22-84de-4277-bc07-0cbbb881c340", "55aed14e-b9e3-4b03-9637-5b0ae22f88b5", "5900419d-1657-40c5-8bca-6842e3d71d95", "71dfb143-e90a-45bf-ba58-92d771997f7b", "7bd448c7-b4ea-448d-9646-5a467f6698e6", "7db36938-8082-4ce5-906f-9a1ebbce42f6", "93cb9069-4644-4291-a77d-6cdf1ed9ada9", "ab274ed1-1e70-4f68-9b5c-f74565629791", "c069c256-4bb6-47f4-ab26-ad160161d03d", "c229a616-8d72-4507-aad7-84997557c584", "c49025b2-3a45-4ce4-855b-5c228f8c7fff", "cf945fd5-9398-4ad8-bac3-cf4709eecde6", "d27fcf24-e16e-42b7-aeb6-e5e786eeabb3", "d44718a2-420f-4c16-aed0-2002d5a39d14", "d6285e34-13fa-4327-b4f9-203181baa8c6", "d897f49c-d25f-43cf-ab58-4facde92b539", "d99cee8d-2dd8-4adc-b771-3138e29a48bb", "dbb9b570-9eff-408b-9e8f-e7f6939cf330", "ded73f0a-0715-469f-b384-a98cc070a908", "e14d1e7b-3ccd-40d3-a83e-979d9076809f", "e2593748-76d0-41b2-ac6b-1f72abea0652", "e5831f0d-3495-429b-b2d3-6c5e046d341a", "e8725699-9fbd-4979-9533-3c240bbd3ce1", "e8b4f43f-469d-4b3b-b2a6-8e1ed0c25c06", "f0345418-7ef0-4115-a839-11a70048263a", "fd43ff1a-8079-4041-977d-d27b1b3efd3f"], "title": "Toward a Tool-Based Development Methodology for Pervasive Computing Applications", "venue": "IEEE Transactions on Software Engineering", "year": 2012, "id": "72e62fab-2cfc-4bf7-86eb-6318888fa148"}
{"abstract": "In this paper, we present a logic based approach to temporal decentralized authorization administration that supports time constrained authorization delegations, both positive and negative authorizations, and implicit authorizations. A set of domain-independent rules are given to capture the features of temporal delegation correctness, temporal conflict resolution and temporal authorization propagation along the hierarchies of subjects, objects and access rights. The basic idea is to combine these general rules with a set of domain-specific rules defined by users to derive the authorizations holding at any time in the system. In addition, some important semantic properties including the unique answer set property are further investigated.", "authors": ["Chun Ruan", "Vijay Varadharajan", "Yan Zhang"], "n_citation": 50, "references": ["347d7773-8c4e-42e4-ae41-d10c1421c432", "4712f9b8-647b-4106-8fa2-271b11300b1d", "4d723c6b-e17f-437c-928c-8ac4267c0872", "52df11aa-1ed2-405f-a24b-62cad8ef25da", "59efb068-0be4-45bd-8fcb-be6c7a0b1fe5", "a4383572-c3ad-4d79-a3e3-250a814e6cf1", "c2c880cd-1519-4385-8a12-64a101084a19", "d7f83f01-08c2-4d60-9b0d-cc24ebc213fa", "da0d129a-feab-4700-8104-d3165622e938", "db658327-1f48-4f80-8f7d-09d88096f297", "e22908da-10e5-49ec-93ed-2d7b1e1e8da3", "fe26781b-7333-4003-b925-70fcfb2caf6e", "ff983a0b-99f6-46bc-a620-daf60938c3a3"], "title": "A Logic Model for Temporal Authorization Delegation with Negation", "venue": "", "year": 2003, "id": "008bb62c-fa03-4f68-8fb8-e7c850fd412e"}
{"abstract": "We introduce a family of kernels on graphs based on the notion of regularization operators. This generalizes in a natural way the notion of regularization and Greens functions, as commonly used for real valued functions, to graphs. It turns out that diffusion kernels can be found as a special case of our reasoning. We show that the class of positive, monotonically decreasing functions on the unit interval leads to kernels and corresponding regularization operators.", "authors": ["Alexander J. Smola", "Risi Kondor"], "n_citation": 727, "references": ["05bbaec3-7980-4941-8638-2bbfa4ac8be0", "29f196b0-3df4-43c9-bf33-6411f5adf879", "3a93a291-d083-4939-9c52-8ab19590a389", "549f0527-0f13-4447-9dc0-ca699e2dc219", "8f9e92cf-f266-4e51-807f-c098a260a0dc", "9438a773-c15c-4ef2-a97c-54f643ce6082", "d78003db-ad8a-48d2-be57-1c50e95cef72"], "title": "Kernels and Regularization on Graphs", "venue": "computational learning theory", "year": 2003, "id": "5fc7c376-5895-490a-8ea2-989442940c7b"}
{"abstract": "Currently, most traffic in the Internet backbone and access networks is World Wide Web (WWW) traffic. On the basis of recent long-time traffic traces we present characteristics of WWW traffic for different flow levels, namely port-to-port, host-to-host, and total client access. Using flow duration distributions, we obtain estimates for the point in time when a shortcut connection should be established. Investigations of the correlation structure of different flow characteristics reveal that symmetrical connections occur even at high bit rates. A large number of TCP connections can therefore benefit from symmetric access network bandwidths although HTTP traffic on an average is asymmetric.", "authors": ["Joachim Charzinksi"], "n_citation": 37, "references": ["33ff77ad-01bc-40b1-b91c-e075f06de6e1", "67329801-1879-4c85-bb43-1995f7753261", "7e841d64-a6a9-49fc-8415-a949b904cc44", "ca106b76-be9d-4c41-9acb-9397ad3cae44", "e629b6d2-ce61-48ba-b6cf-f238969873ff", "fedbd231-5cf4-44dc-9103-c07c555a79b8"], "title": "HTTP/TCP connection and flow characteristics", "venue": "Performance Evaluation", "year": 2000, "id": "888ec757-9e2a-4bcb-80fd-761f0cbef5c4"}
{"authors": ["Marco Lovera"], "n_citation": 39, "references": ["436af28a-9aab-45b1-858f-eedd619a5c1a", "dd8d68e0-86c9-44c8-b357-d7e80a180c68"], "title": "Optimal Magnetic Momentum Control for Inertially Pointing Spacecraft", "venue": "European Journal of Control", "year": 2001, "id": "73b50e81-9ed4-4799-a8b2-98f030c27fba"}
{"abstract": "The tautology problem is the problem to prove the validity of statements. In this paper, we present a calculus for this undecidable problem on graphical conditions, prove its soundness, investigate the necessity of each deduction rule, and discuss practical aspects concerning an implementation. As we use the framework of weak adhesive HLR categories, the calculus is applicable to a number of replacement capable structures, such as Petri-Nets, graphs or hypergraphs.", "authors": ["Karl-Heinz Pennemann"], "n_citation": 50, "references": ["06d666fd-e68a-498e-9211-316bbd9f2052", "112eeff7-c265-4808-aef5-55f592540e40", "12c2d1b7-3581-4486-baab-085b77e95c52", "21d8de86-a4e4-4f23-9c8c-49c09fb6bcd4", "3e463040-e697-4c3c-a555-5635b90ef134", "4b631e92-e0ad-4d33-a772-d06b8f585e62", "585f1202-6edd-4b39-a16d-84076d494ac6", "5c759cf4-9b03-4b71-9864-2982764f6f0b", "6b84ef39-b141-48d4-bee1-93fec4204f5c", "a3dc4316-1f82-4330-b56b-9f3de8c6f1f5", "a6bdd45c-c00b-4e88-a6ad-f7e3780a2310", "d41d0fd9-2859-438e-9021-f6dbb30e51aa", "d654b82c-e698-4736-a77f-5b2d4cb39397", "d6accf73-1eba-425f-b263-6cac10135bb5", "e091ebd6-a426-4601-b08e-66d9a66db7f3"], "title": "Resolution-Like Theorem Proving for High-Level Conditions", "venue": "international conference on graph transformation", "year": 2008, "id": "e23adb6d-570a-4d44-9831-1a8f73b1fba9"}
{"abstract": "This paper compares the LOTOS and Z refinement relations. The motivation for such a comparison is the use of multiple viewpoints for specifying complex systems defined by the reference model of the Open Distributed Processing (ODP) standardization initiative. The ODP architectural semantics describes the application of formal description techniques (FDTs) to the specification of ODP systems. Of the available FDTs, Z is likely to be used for at least the information, and possibly other, viewpoints, whilst LOTOS is a strong candidate for use in the computational viewpoint. Mechanisms are clearly needed to support the parallel development, and integration of, viewpoints using these FDTs. We compare the LOTOS bisimulation relations and the reduction relations to the Z refinement relation showing that failure-traces refinement corresponds closely to refinement in Z.", "authors": ["John Derrick", "Howard Bowman", "Eerke Albert Boiten", "Maarten Steen"], "n_citation": 50, "title": "Comparing LOTOS and Z refinement relations", "venue": "formal techniques for (networked and) distributed systems", "year": 1996, "id": "1b097ce0-6329-440c-9071-7fc0ddade735"}
{"abstract": "Dynamic domains are domains quickly created, used and discarded. Today, there are no facilities available to support dynamic domains in most network management systems. This paper introduces two new languages to deal with dynamic domains. The first language is used to define new domains through the selection of managed objects. The second language, on its turn, is used to visualize already created dynamic domains. Both languages are explained through examples and implementations details are presented.", "authors": ["M\u00e1rcio Bartz Ceccon", "Lisandro Zambenedetti Granville", "Maria Janilce Bosquiroli Almeida", "Liane Margarida Rockenbach Tarouco"], "n_citation": 7, "references": ["0725e671-6c11-41a2-b5f6-1eee47ba1b65", "2a46a856-9e29-4cc3-bf02-43715931293d", "31e3be53-21e1-4a97-89dc-61cb2918972f", "a933c991-b10a-46df-af79-47a9a78392b3", "d45213d5-4aef-4dc3-a1fb-0634f60d657c", "e7d8959f-a57c-4185-ad74-c9744834a3b7"], "title": "Definition and Visualization of Dynamic Domains in Network Management Environments", "venue": "international conference on information networking", "year": 2003, "id": "d05b22da-4b42-45d5-b004-0c953d91567a"}
{"abstract": "In this paper we consider generic algorithms for computational problems in cyclic groups. The model of a generic algorithm was proposed by Shoup at Eurocrypt '97. A generic algorithm is a general-purpose algorithm that does not make use of any particular property of the representation of the group elements. Shoup proved the hardness of the discrete logarithm problem and the Diffie-Hellman problem with respect to such algorithms for groups whose order contains a large prime factor. By extending Shoup's technique we prove lower bounds on the complexity of generic algorithms solving different problems in cyclic groups, and in particular of a generic reduction of the discrete logarithm problem to the Diffie-Hellman problem. It is shown that the two problems are not computationally equivalent in a generic sense for groups whose orders contain a multiple large prime factor. This complements earlier results which stated this equivalence for all other groups. Furthermore, it is shown that no generic algorithm exists that computes p-th roots efficiently in a group whose order is divisible by p 2  if p is a large prime.", "authors": ["Ueli Maurer", "Stefan Wolf"], "n_citation": 88, "references": ["0075dca5-5503-410e-8fbc-31d793a79b50", "04264dff-324a-4514-bd0a-c163387d26f2", "ca394e6a-59e0-466c-a66a-d976555db689", "e20ba63d-f74d-4929-b3ac-bc3c0ab611f9", "e796f5bf-73b8-4473-9e9c-716887059a92", "f94d2182-f2f1-4c5c-b87b-b227146802bb"], "title": "Lower bounds on generic algorithms in groups", "venue": "theory and application of cryptographic techniques", "year": 1998, "id": "caa17f7e-1188-485b-b693-ff7eecc545ca"}
{"abstract": "Facial occlusion is a critical issue in many face recognition applications. Existing approaches of face recognition under occlusion conditions mainly focus on the conventional facial accessories (such as sunglasses and scarf) and thus presume that the occluded region is dense and contiguous. Yet due to the wide variety of natural sources which can occlude a human face in uncontrolled environments, methods based on the dense assumption are not robust to thin and randomly distributed occlusions. This paper presents the solution to a newly identified facial occlusion problem - sparse occlusion in the context of face biometrics in video surveillance. We show that the occluded pixels can be detected in the low-rank structure of a canonical face set under the Robust-PCA framework; and the occluded part can be inpainted solely based on the nonoccluded part and a Fields-of-Experts prior via spatial inference. Experiments demonstrate that the proposed approach significantly improve various face recognition algorithms in presence of complex sparse occlusions.", "authors": ["Rui Min", "Jean-Luc Dugelay"], "n_citation": 5, "references": ["27505f5b-d81f-4b85-b85e-bd357aaa8468", "298f79d4-2040-43eb-8c95-bdff3daf15b3", "2f0af42d-4ce9-469e-b240-b4cad5962dcd", "6018a516-8149-4bce-bc33-5449d86e58c2", "7236dbb7-f0b2-4e28-bb7c-6de187c32d64", "7373c683-3709-4b29-b5b7-c82639e0109f", "79985a61-c881-41b2-8a18-effeeeeb3760", "a81d35e6-d5cd-4eef-9144-b0755ef268d1", "c79fa5f7-bd43-4fb6-97cc-e1c56e044062"], "title": "Inpainting of sparse occlusion in face recognition", "venue": "international conference on image processing", "year": 2012, "id": "8507e52f-845f-41e9-a4ca-7094c0317dcf"}
{"abstract": "We present a discrete simulation model for software projects which explicitly takes a scheduling strategy as input. The model represents varying staff skill levels, component coupling, rework caused by design changes, and changing task assignments. The simulation model is implemented in the ModL language of the general-purpose graphical simulation tool EXTEND. The simulations provide quick feedback about the impact which the scheduling strategy will have on the progress and completion time of a given software project. Using the model, a manager can compare different strategies and choose the one which is best for his next project. As an illustration how to apply the simulation model, we systematically study the performance of various list policies for a small sample project. We provide a detailed analysis of the task assignments which actually occur in the simulations. In addition, the example provides clear evidence that strategies which are more adaptive to the current project state than list policies will yield improved schedules. This result suggests to apply dynamic optimization techniques when scheduling software projects.", "authors": ["Frank Padberg"], "n_citation": 10, "references": ["8650e609-7b6a-4fdf-aa02-cfaa92788f94", "abb008ab-69ad-470b-be48-7bf910b7c301", "c166fce5-baf5-46a7-8382-6e10f7808432"], "title": "Using process simulation to compare scheduling strategies for software projects", "venue": "asia-pacific software engineering conference", "year": 2002, "id": "b89e506f-5110-458e-b3a4-5b099137e3a9"}
{"authors": ["Andrea Maggiolo-Schettini", "Adriano Peron"], "n_citation": 50, "references": ["0d261b6a-c94a-4d5e-b44e-eb6ae46581fc", "4971b75e-529f-442f-8473-c098a9fb62b0", "b215f194-a0ce-4699-9d46-69ad938c6c4d", "e4126aa2-66a8-4e6f-b4f8-51a0e8f0af17"], "title": "Semantics of Full Statecharts Based on Graph Rewriting", "venue": "", "year": 1993, "id": "67283000-ee95-44e0-852e-8ac88f853bcd"}
{"abstract": "In this paper, the stability analysis problem for a class of switched positive linear systems (SPLSs) with average dwell time switching is investigated. A multiple linear copositive Lyapunov function (MLCLF) is first introduced, by which the sufficient stability criteria in terms of a set of linear matrix inequalities, are given for the underlying systems in both continuous-time and discrete-time contexts. The stability results for the SPLSs under arbitrary switching, which have been previously studied in the literature, can be easily obtained by reducing MLCLF to the common linear copositive Lyapunov function used for the system under arbitrary switching those systems. Finally, a numerical example is given to show the effectiveness and advantages of the proposed techniques.", "authors": ["Xudong Zhao", "Lixian Zhang", "Peng Shi", "Ming Liu"], "n_citation": 359, "references": ["122dd05e-8f61-46ab-9857-01cd4af09a04", "451dafd3-c7e0-4826-838a-b9a01e2bf4a2", "4ba38782-38f5-458f-bfb1-42244e9ffcbd", "4e10c8c3-0bda-4c38-8840-1e877df1ae1a", "683bf889-31f5-4fb9-86cf-e33297945b2f", "689a4378-f07f-4c02-b6c2-0f97afe38445", "6cd084da-db53-4925-b3b4-4e552addb92f", "7e73891a-30d8-4cdf-960a-d6169477ea70", "8f95ab31-6eb7-4dea-983c-9ed6dcfdb359", "9ba03a18-3806-4e19-8335-2d39c3627c22", "af543661-2d05-4795-9087-80f5965b501c", "c0cca070-a100-4104-8717-b9c0c2246353", "c0fa193e-27a3-4bb4-91d1-eb2b4553b027", "cc964be4-912c-4405-b041-206cabfa14ab", "e6e4f36d-1751-425c-9b7d-4a142b829478", "e9e60556-ed1a-485b-b2c4-81978acf893e", "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9", "f9fedf37-7130-40d3-ad1b-581c924f3d57"], "title": "Brief paper: Stability of switched positive linear systems with average dwell time switching", "venue": "Automatica", "year": 2012, "id": "e1128a21-bd10-45e4-a107-63dbb5899553"}
{"abstract": "A continuous nearest neighbor (CNN) search retrieves the nearest neighbors corresponding to every point in a given query line segment. It is important for location-based services such as vehicular navigation tools and tourist guides. It is infeasible to answer a CNN search by issuing a traditional nearest neighbor query at every point of the line segment due to the large number of queries generated and the large overhead on bandwidth. Algorithms have been proposed recently to support CNN search in the traditional client-server service model. In this paper, we conduct a pioneering study on CNN search in wireless data broadcast environments. We propose two air indexing techniques, namely, R-tree air index and Hilbert curve air index, and develop algorithms based on these two techniques to search CNNs on the air. A simulation is conducted to compare the proposed air indexing techniques with a naive broadcast approach. The result shows that both of the proposed methods outperform the naive approach significantly. The Hilbert Curve air index is superior for uniform data distributions, while the R-tree air index is a better choice for skewed data distributions.", "authors": ["Baihua Zheng", "Wang-Chien Lee", "Dik Lun Lee"], "n_citation": 38, "references": ["0cb61938-314e-4046-a5fa-d546c988523d", "2e4e507b-bf78-45ae-889f-27a3d7296ae4", "5d1de1a8-a6e1-4d59-bb4b-81c47179afce", "70986d27-7345-4c25-83c7-d069850a8896", "86ba4add-56f4-42d8-87ef-45350e1f8d43", "a9db97cf-852e-4269-8c4a-19842fd6d28d", "ee4b3d9b-325f-4999-ba79-febddb6b4067"], "title": "Search continuous nearest neighbors on the air", "venue": "international conference on mobile and ubiquitous systems networking and services", "year": 2004, "id": "5047a242-749e-40cc-94db-5d6789b0649d"}
{"abstract": "This paper discusses algorithms which transform expression trees into code for register machines. A necessary and sufficient condition for optimality of such an algorithm is derived, which applies to a broad class of machines. A dynamic programming algorithm is then presented which produces optimal code for any machine in this class; this algorithm runs in time linearly proportional to the size of the input.", "authors": ["Alfred V. Aho", "Stephen C. Johnson"], "n_citation": 326, "references": ["102b0cd8-7426-42f5-b32d-3d6e7386aea3", "172f9f68-8417-43bb-8fe5-b377d569f6b6", "380a352b-204a-4828-b27f-3c2c5af806d6", "3a74bc0f-924d-4fda-b2dd-89185a8571fd", "766c401d-1d6d-440d-8676-ff214eeaee9b", "8d09527f-b5ad-4902-ba34-5583f6759d3b", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "c0dfde03-c4f3-4611-8511-cd757e60ad72", "e510b99f-d1e4-4e56-82a5-f0388b9ce98d", "f0fcfbe5-c35f-41fa-baba-592a7efb6ef9"], "title": "Optimal Code Generation for Expression Trees", "venue": "Journal of the ACM", "year": 1976, "id": "ce853622-efbc-42ba-b435-a83e3d4ae7fb"}
{"abstract": "Problem orientation is gaining interest as a way of approaching the development of software intensive systems, and yet, a significant example that explores its use is missing from the literature. In this paper, we present the basic elements of Problem Oriented Software Engineering (POSE), which aims at bringing both nonformal and formal aspects of software development together in a single framework. We provide an example of a detailed and systematic POSE development of a software problem: that of designing the controller for a package router. The problem is drawn from the literature, but the analysis presented here is new. The aim of the example is twofold: to illustrate the main aspects of POSE and how it supports software engineering design and to demonstrate how a nontrivial problem can be dealt with by the approach.", "authors": ["Jon G. Hall", "Lucia Rapanotti", "Michael Jackson"], "n_citation": 84, "references": ["176c4aaa-f2c1-4d30-bf5d-d39b5ada43ff", "2d29dea7-81bb-4e56-b5f2-8581101f8cd7", "3a00acf8-b94d-4478-9637-54aff577ade1", "3b8d8731-2b70-4454-a354-6ed9485098e2", "48f8c23c-b55e-47be-b80b-abbcdf51a46a", "6c1c1d90-1c48-442a-9665-840fe2da0a48", "6cf52f95-aa02-4cb5-b48a-1ead3f18b6dd", "6d4458b3-1a92-4f84-b4ed-556be7407c05", "79aeaba1-8974-4f10-bee4-77a2fe011669", "893304de-9a61-42cc-8c1b-2ac35c6ef1e9", "8d7eafb5-92a7-46cf-8c99-3f14535a89d3", "a5e10ae5-6b28-4ae5-8677-a3e9da345b1f", "adf8a988-6703-4d44-8039-24c0ffdc9efd", "ba6e7aa2-8961-41a9-afb2-56e233a4c420", "fe8b6639-5345-444d-93ad-e3fbcf3e6239"], "title": "Problem Oriented Software Engineering: Solving the Package Router Control Problem", "venue": "IEEE Transactions on Software Engineering", "year": 2008, "id": "0909a28a-6a32-490b-84e6-148fc65ad108"}
{"abstract": "Nanotechnology is an emerging field of science devoted to provide new opportunities in a vast range of areas. In this paper, different techniques are proposed to enable the long range interconnection of nano-machines, deployed over distances from a few centimeters up to several meters. Long range nano-communications will enable the development of applications that could not be implemented using other techniques. The usage of both short-range nano techniques and long range micro techniques are not practical or are unfeasible for a huge application scope. Biologically inspired research provides promising features to long range communication, such as very low power consumption and biocompatibility. In this paper, several bio-inspired techniques are discussed following a twofold taxonomy divided according to whether a fixed physical link is required for signal propagation or not, i.e., either wired or wireless communication. In the first group, pheromones, spores, pollen and light transduction are discussed. In the second group, neuron-based communication techniques and capillaries flow circuit are explored. All proposed techniques offer a good framework for long-range molecular communication, and their components and test-beds can benefit from different research expertise, e.g., entomology for pheromones, mycology for spores, neuroscience for axons, and biochemistry for capillaries.", "authors": ["Llu\u00eds Parcerisa Gin\u00e9", "Ian F. Akyildiz"], "n_citation": 235, "references": ["32f0af48-21d5-441d-b6d9-15174c97ba5f", "44c2589a-82c3-40b8-baf9-9aefb6261390", "4c070b03-5ded-4c88-9107-2d54b57c3cdc", "8105e905-7e75-4bf8-aafe-ebb0dbfc974f", "8d1b355e-cb2a-4f12-b809-132781f9a417", "936d72fb-ad57-4541-98c8-691b12212062", "fcebf124-ad21-47c9-be8c-def8ed6823e0"], "title": "Molecular communication options for long range nanonetworks", "venue": "Computer Networks", "year": 2009, "id": "a6f9cdb2-a007-4635-88a5-4faa5194c712"}
{"abstract": "This paper addresses the problem of voltage regulation in power distribution networks with deep-penetration of distributed energy resources (DERs), e.g., renewable-based generation, and storage-capable loads such as plug-in hybrid electric vehicles. We cast the problem as an optimization program, where the objective is to minimize the losses in the network subject to constraints on bus voltage magnitudes, limits on active and reactive power injections, transmission line thermal limits and losses. We provide sufficient conditions under which the optimization problem can be solved via its convex relaxation. Using data from existing networks, we show that these sufficient conditions are expected to be satisfied by most networks. We also provide an efficient distributed algorithm to solve the problem. The algorithm adheres to a communication topology described by a graph that is the same as the graph that describes the electrical network topology. We illustrate the operation of the algorithm, including its robustness against communication link failures, through several case studies involving 5-, 34- and 123-bus power distribution systems.", "authors": ["Albert Y. S. Lam", "Baosen Zhang", "Alejandro D. Dominguez-Garcia", "David Tse"], "n_citation": 32, "title": "Optimal Distributed Voltage Regulation in Power Distribution Networks", "venue": "arXiv: Optimization and Control", "year": 2012, "id": "ca455bcc-0e52-4c17-851e-f7a65c98718a"}
{"abstract": "A real time 3D pupil position detection system necessary for non-contact and remote eye gaze detection allowing head displacement was developed. So far, methodology had been proposed that estimates 3D positions of eyes from their 2D positions detected from the face images captured by two stereo cameras. However, using eye position detection is not prospective for precise and stable eye gaze detection. In the method proposed in the present study, several near-infrared LEDs were arranged around the apertures of two cameras. These two sets of light sources were alternately switched on and off synchronously with the even/odd signal. After differentiating the bright and dark pupil images obtained from each of the two cameras, the center coordinates of the two pupils were detected. An image processing algorithm for precise and stable pupil detection, including the pupil detection method utilizing a blink, is described. In one of the experiments, the 3D position of the pupil of one eye was measured by the two stereo cameras. Another narrow camera, which detects the centers of both pupil and corneal reflection images necessary for eye gaze direction determination, placed on a pan-tile unit could be automatically directed toward the 3D pupil position.", "authors": ["Yoshinobu Ebisawa"], "n_citation": 50, "references": ["53f163d2-3f09-4395-84c6-49eb328d5645", "566f3f8b-94f0-4afd-a58d-5af2fc225dca", "60985c9a-ca14-4324-882d-95cedabefdeb", "c6fdee75-2cc7-46a2-b2a7-619b58b1402d"], "title": "Realtime 3D position detection of human pupil", "venue": "virtual environments human computer interfaces and measurement systems", "year": 2004, "id": "e17dbc10-9d79-4554-9a14-8af75449cffb"}
{"abstract": "Test suite minimization techniques try to remove redundant test cases of a test suite. However, reducing the size of a test suite might reduce its ability to reveal faults. In this paper, we present a novel approach for test suite reduction that uses an additional testing criterion to break the ties in the minimization process. We integrated the proposed approach with two existing algorithms and conducted experiments for evaluation. The experiment results show that our approach can improve the fault detection effectiveness of reduced suites with a negligible increase in the size of the suites. Besides, under specific conditions, the proposed approach can also accelerate the process of minimization.", "authors": ["Jun-Wei Lin", "Chin-Yu Huang"], "n_citation": 50, "references": ["0fb82a2a-6caa-4322-8470-e6c36a4eda19", "1d79213f-ba17-4cb7-90fb-59132ae38391", "21968dec-82d4-40b7-ad92-0bc41c9a9c56", "30521aed-580e-4260-8074-24f470294419", "392c42e1-b894-4c08-a2a2-d9f1481c5d3a", "39edd2ce-9466-44e6-9de6-13f50d7435f6", "43a4d168-8449-4599-b2c3-750b5c0d5ca7", "4a1e0ca0-605c-4ad9-891e-303ed0a11d98", "53577a95-d855-41b3-9ac2-6287b4f0262b", "59e5af7b-f85b-451c-b24d-bc93f06eb38f", "5ca853a0-5405-4126-917b-a17941ee4a08", "5f323d30-52ec-446e-b800-fb332b73da72", "5fcfd132-e4b8-40cf-8447-db956065c4c7", "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "7e0e4a8d-a9df-4375-87f9-49b2289f5dc7", "8ba5783c-0839-4264-acd5-f856ea8cfc20", "8dbcce9e-fef4-4f1e-a64b-3b9de65f676d", "9450b632-2288-4e85-8daf-206d1c95ece9", "9fe654b4-8dc2-4bc2-8fa5-e232cfac26e3", "bf6c6d3f-980d-4b60-a863-05bcb88658bd", "c716bf6a-8185-4d7e-9ca3-5e5af10e2d3e", "cd1f4a53-5ab5-408b-bb60-55b67e81d8d7", "eada5d05-24bc-4f1b-9ff3-6d646ccfda4f", "f1a1e8b5-f589-4c38-b4c9-195a2bedaad2"], "title": "Analysis of test suite reduction with enhanced tie-breaking techniques", "venue": "Information & Software Technology", "year": 2009, "id": "be9f13ce-8291-4e98-bd4d-69329b1938d2"}
{"abstract": "We introduce an entropic prior for multinomial parameter estimation problems and solve for its maximum a posteriori (MAP) estimator. The prior is a bias for maximally structured and minimally ambiguous models. In conditional probability models with hidden state, iterative MAP estimation drives weakly supported parameters toward extinction, effectively turning them off. Thus, structure discovery is folded into parameter estimation. We then establish criteria for simplifying a probabilistic model's graphical structure by trimming parameters and states, with a guarantee that any such deletion will increase the posterior probability of the model. Trimming accelerates learning by sparsifying the model. All operations monotonically and maximally increase the posterior probability, yielding structure-learning algorithms only slightly slower than parameter estimation via expectation-maximization and orders of magnitude faster than search-based structure induction. When applied to hidden Markov model training, the...", "authors": ["Matthew Brand"], "n_citation": 75, "references": ["005220dc-1c97-4858-bbdd-05d5f7874afa", "161136e2-2c4c-4b12-97c2-550ebf1b3bcc", "34b35b59-9b66-49b2-a8ac-6326cbc4f01d", "37844054-e97e-4d76-bc24-11a9d9335301", "3c504b40-d5a7-4be4-8432-cf458053364f", "3fff50e3-6a11-415b-8c8d-6f2c651f658d", "54b41c44-8b0f-48d3-98a8-e4e0dc1084eb", "560af244-ddcb-4f86-bcd0-c85ee9223079", "5bde5552-01ff-4b99-a3ff-e7651d3e3478", "60f2a508-6947-4452-b875-eb2c057a9d32", "6372b6b3-4826-4338-b4c3-1cd5bd9fc8b7", "644ccb4d-72ee-4f03-88cb-6ff18b98dc32", "6bce238c-31af-4a32-b946-33ea41106c39", "75688d20-068c-4c13-ae88-dde5f3b4abaa", "87cc3f42-fc5f-4ea4-81b6-506ebd68e0ff", "8da74064-a12f-4c2e-8533-de5473f1ee8d", "a57b2fad-f4af-4da4-a751-08f211895e40", "a925c4c6-15fa-4552-b598-559cfefe1b06", "bdf5e155-954f-4435-9483-43c5e27859e6", "cbf3652c-3d45-488c-9347-9408caec92fe", "cc6ae83e-94cd-4ca6-8e34-e786fb486ade", "fabab9f6-088b-446f-bf43-1c3f1e856bd4"], "title": "Structure learning in conditional probability models via an entropic prior and parameter extinction", "venue": "Neural Computation", "year": 1999, "id": "be1a657a-5317-4b2c-8b24-f363e6ca69bc"}
{"abstract": "A multidatabase system provides integrated access to heterogeneous, autonomous local databases in a distributed system. An important problem in current multidatabase systems is identification of semantically similar data in different local databases. The Summary Schemas Model (SSM) is proposed as an extension to multidatabase systems to aid in semantic identification. The SSM uses a global data structure to abstract the information available in a multidatabase system. This abstracted form allows users to use their own terms (imprecise queries) when accessing data rather than being forced to use system-specified terms. The system uses the global data structure to match the user's terms to the semantically closest available system terms. A simulation of the SSM is presented to compare imprecise-query processing with corresponding query-processing costs in a standard multidatabase system. The costs and benefits of the SSM are discussed, and future research directions are presented.", "authors": ["Myron Bright", "Ali R. Hurson", "S. H. Pakzad"], "n_citation": 312, "references": ["037bc6c7-e1ad-455d-a71d-73b82a48b508", "053e1cba-e411-42c5-8e2d-ac18fc4e0d57", "0dc6feda-4747-441f-835d-90ca28abf802", "13f34e3a-5a07-44e3-a784-e0104bcdd110", "28dc7c8d-7258-4bc5-ad19-71fc1d43070f", "38d6b53a-698a-435f-97dd-efd06b086f9e", "3a07e7e1-87eb-451c-bfcf-f7fe28637b0a", "4c6cf9d7-5968-45b7-a2fa-6b73092f0049", "51b52a79-0d0a-4d4f-bab9-7ad1b6a5b3cc", "5c081357-b0cb-42eb-b06d-95bd629a834c", "822c95f0-5df9-4219-ad70-b44ca6b4c23d", "956c6250-c1d5-4f70-bbc7-8e8901b7885a", "c317ef4f-13cf-4116-ba22-a4c143b93219", "c597629c-a869-4a90-bd35-cffedf40fe3d", "cacfd6d7-9812-47ba-a51c-123eca3e90e7", "d5f817a8-f895-4c4c-92b6-696614e77255", "e5dd24b0-4022-4830-843f-d642aa5e7c21", "f47687ef-397f-4414-96e1-97d0b5cd43b0", "f6e0c9cc-ca7b-4bbf-9236-b841d14251c8", "ffbf182a-9392-436a-b20d-be89183625f8"], "title": "Automated resolution of semantic heterogeneity in multidatabases", "venue": "ACM Transactions on Database Systems", "year": 1994, "id": "d82fd0ba-ab68-4524-b2b1-9e406a166d01"}
{"abstract": "This paper proposes a method that acquires robots' behaviors based on the estimation of the state vectors. In order to acquire the cooperative behaviors in multi-robot environments, each learning robot estimates the local predictive model between the learner and the other objects separately. Based on the local predictive models, the robots learn the desired behaviors using reinforcement learning. The proposed method is applied to a soccer playing situation, where a rolling ball and other moving robots are well modeled and the learner's behaviors are successfully acquired by the method. Computer simulations and real experiments are shown and a discussion is given.", "authors": ["Eiji Uchibe", "Minoru Asada", "Koh Hosoda"], "n_citation": 50, "references": ["0cdd9d08-e006-4373-a902-1842b308daef", "56e5ed17-8b83-4493-898c-3282c07c4013", "7d4aa8eb-58cc-4a7c-8f54-8498c9e309b5", "89c85bde-908e-4103-8cf2-07437543967e", "c7d01273-632a-4c99-aacd-ba3b98abb712", "da57a418-dc52-4f96-9599-31ccef02e9c7"], "title": "Cooperative behavior acquisition in multi-mobile robots environment by reinforcement learning based on state vector estimation", "venue": "international conference on robotics and automation", "year": 1998, "id": "413d401c-0188-49af-92c8-7ffee0088f5d"}
{"abstract": "This paper provides either security proofs or attacks for a large number of identity-based identification and signature schemes defined either explicitly or implicitly in existing literature. Underlying these are a framework that on the one hand helps explain how these schemes are derived, and on the other hand enables modular security analyses, thereby helping to understand, simplify and unify previous work.", "authors": ["Mihir Bellare", "Chanathip Namprempre", "Gregory Neven"], "n_citation": 571, "references": ["07f03577-fc1f-4578-a7fa-6f961900c46c", "13c2d290-8d8c-4143-a844-ef9b37c77c9f", "1e7e39e3-3221-46e0-a63d-46c5a68a2508", "367d97b7-21f2-404e-94d1-edbc49888596", "48256bd6-01d8-41f8-828e-d2d0876d47e8", "4ad98a43-a825-4ae2-9d2e-7f4530ae9b52", "85fcfea7-7537-48ad-b341-088d1df85666", "8d0805df-03fe-4adc-b5ed-713580093469", "91839b3c-bc93-4051-b06c-3ff91c4b59ec", "93b84c61-0636-4d00-8d2b-ce6353f8c8d6", "ac0db18c-141b-499a-9499-bc11ed2a61bc", "acd3f571-3433-4527-9a8a-d0ff83b69a7e", "af961647-7865-416c-b00c-fdc570b9517b", "b07624fa-01fb-4c1f-a9a7-71ed1b7fddcc", "b10fd24d-6a42-4821-9517-da6d1e14b17b", "ba4d1a67-fbc8-4ad7-8091-f286c105aa28", "bbe2ad92-fb6d-48c4-8ba8-a7caf05b6e4c", "d893a420-a00d-4756-b447-2862ed178eaa", "e3d68028-2580-4c97-b747-e75c72ae686d", "ed804c0f-dad5-4ce5-9da3-f69da43f137a", "eff680ef-6d1a-4486-b2c6-45d0ac83dd2f", "f31fd2e0-c0bd-4301-8868-0b73fc7bb5dd", "f5a0a1dc-4927-477f-aad8-872ec0d2851b"], "title": "Security Proofs for Identity-Based Identification and Signature Schemes", "venue": "theory and application of cryptographic techniques", "year": 2004, "id": "ef44d5a0-394b-4e6f-a9c5-4de28b87710f"}
{"authors": ["Dirk B\u00e4umer", "Rolf Knoll", "Guido Gryczan", "Heinz Z\u00fcllighoven"], "n_citation": 6, "title": "Large Scale Object-Oriented Software-Development in a Banking Environment: An Experience Report", "venue": "european conference on object oriented programming", "year": 1996, "id": "9e95b994-2659-41a3-a6be-5583431622be"}
{"authors": ["Hendrik Dahlkamp", "Adrian Kaehler", "David Stavens", "Sebastian Thrun", "Gary R. Bradski"], "n_citation": 166, "references": ["51027266-8f2a-4d93-be01-415cc5eb3c0d", "53b2e0ba-cff5-4456-b3af-ea4bb94f5b38", "630a30fd-3d18-4cf0-963c-530ae4b17165", "7aea093c-81d7-45fd-9118-68a506add50a", "91a315e8-e712-467d-8068-9eeab4c5ac9e", "ff412ddc-8857-440f-a861-2fb6c741480c"], "title": "Self-supervised Monocular Road Detection in Desert Terrain.", "venue": "robotics: science and systems", "year": 2006, "id": "cb66cbaa-cbac-4d9f-b915-eaab50967722"}
{"abstract": "This paper presents the idea of Software Architecture Oriented Requirements Engineering, a complementary approach to existing requirements engineering processes and methods. The main objective is to introduce concepts and principles of software architecture into requirement analysis and requirement specification, supporting requirement reuse, traceability between requirement specifications and system design, and consistency in the whole software development process more effectively. The paper views connectors as the first-class entities in the problem space, not just in the solution space as most of current research on software architecture does, hence the connector recognition and specification are same important as component recognition and specification in requirements engineering. Based on this idea, the paper presents a new software development process and corresponding requirements engineering process, gives some guidelines for connector recognition, and borrows the notations of software architecture description to specify the functional and behavioural requirements at a high abstraction level. It must be pointed out that the approach presented in this paper is not a substitute for existing ones, but a complement to them from another perspective and at a different abstraction level.", "authors": ["Hong Mei"], "n_citation": 18, "references": ["33f9ebe7-a105-4290-aed5-988484ccd0db", "862ffbaa-7123-411a-ad1b-00b4204ad2bd", "a8840afa-a1ab-49f3-990e-e86a398da051", "e5026ad9-f584-49fc-9908-f33acf3a2a69"], "title": "A complementary approach to requirements engineering\u2014software architecture orientation", "venue": "ACM Sigsoft Software Engineering Notes", "year": 2000, "id": "02fd97b1-548a-4e45-96cb-f0b66a978841"}
{"abstract": "This paper describes a generative theory of bugs. It claims that all bugs of a procedural skill can be derived by a highly constrained form of problem solving acting on incomplete procedures. These procedures are characterized by formal deletion operations that model incomplete learning and forgetting. The problem solver and the deletion operator have been constrained to make it impossible to derive \u201cstar-bugs\u201d\u2014algorithms that are so absurd that expert diagnosticians agree that the alogorithm will never be observed as a bug. Hence, the theory not only generates the observed bugs, it fails to generate star-bugs.#R##N##R##N##R##N##R##N#The theory has been tested on an extensive data base of bugs for multidigit subtraction that was collected with the aid of the diagnostic systems buggy and debuggy. In addition to predicting bug occurrence, by adoption of additional hypotheses, the theory also makes predictions about the frequency and stability of bugs, as well as the occurrence of certain latencies in processing time during testing. Arguments are given that the theory can be applied to domains other than subtraction and that it can be extended to provide a theory of procedural learning that accounts for bug acquisition. Lastly, particular care has been taken to make the theory principled so that it can not be tailored to fit any possible data.", "authors": ["John Seely Brown", "Kurt VanLehn"], "n_citation": 816, "references": ["443aff6d-32ba-41e2-b651-35801aab802b", "61b5ef78-6b5a-44a1-bdbc-9ad7f7865b64", "c1f3743f-2d02-4c13-aee4-b9ab06b35945"], "title": "Repair theory: A generative theory of bugs in procedural skills", "venue": "Cognitive Science", "year": 1980, "id": "c39f4090-28af-4825-b44e-575e769fae1a"}
{"abstract": "We present a new approach for conformance testing of protocols specified as a collection of communicating finite state machines (FSMs). Our approach uses a guided random walk procedure. This procedure attempts to cover all transitions in the component FSMs. We also introduce the concept of observers that check some aspect of protocol behavior. We present the result of applying our method to two example protocols: full-duplex alternating bit protocol and the ATM-adaptation-layer-convergence protocol. Applying our procedure to the ATM adaptation layer, 99% of component FSMs edges can be covered in a test with 11692 input steps. Previous approaches cannot do conformance test generation for standard protocols (such as asynchronous transfer mode (ATM) adaptation layer) specified as a collection of communicating FSMs.", "authors": ["David Lee", "Krishan K. Sabnani", "David M. Kristol", "Sanjoy Paul"], "n_citation": 109, "references": ["2e7e6746-5551-449c-b0b4-c1a493dc2a48", "5f562bea-1abd-4f5f-a8a2-fd9f4504fb5c", "ca37793a-edf8-4334-ac03-6bce8a801623", "daff79a4-9d36-46f0-a8ea-e723a3ad5d04", "dd7578f8-0d68-430b-98d8-984c278efcdc"], "title": "Conformance testing of protocols specified as communicating finite state machines-a guided random walk based approach", "venue": "IEEE Transactions on Communications", "year": 1996, "id": "df8c4039-72cb-4e9b-b6f9-141137964f17"}
{"abstract": "In this paper, we present a new class of protocols called completely specified protocols. Each protocol is represented as a system of Communicating Finite State Machines. The class of completely specified protocols is such that each message that can be received by a Finite State Machine, can also be received in every local state of the Finite State Machine. These protocols are important because they allow for modelling unbounded fifo channels and make it possible to decide the Termination Problem, that is whether the reachability tree is finite or not. An example of our techniques is given using a practical problem concerning link protocols.", "authors": ["Alain Finkel"], "n_citation": 84, "references": ["1f9f0648-c68c-4362-b6d2-d7bba39ef2f9", "22bf363a-dba5-4e97-9215-e9827fe45702", "67f8b466-f5ef-42e6-834b-840b06c6b13e", "752a0858-0023-45c4-a29f-0410496164bb", "7914a8d8-005e-458a-ac26-9b919d99da8c", "7f3e4e71-8717-4456-b960-4272bbafc779", "93fe999f-af16-46ef-8439-b7502dcbd934", "963d941e-ffae-41af-93f4-6023a921677b", "9b85976b-47b2-4989-83c1-e78cdd007e11", "9ca2e998-742c-4b39-8c45-4b54c68ab510", "a6a5b672-8a9c-4a0e-80f0-1077626f4713", "c93c4770-327e-4123-8316-5652e8a87940"], "title": "Decidability of the termination problem for completely specified protocols", "venue": "Distributed Computing", "year": 1994, "id": "20a69de0-12ec-40bd-a76a-4a6cffbcba10"}
{"abstract": "We address long\u2013term coalitions that are formed of both customer and vendor agents. We present a coalition formation mechanism designed at the agent level as a decision problem. The proposed mechanism is analyzed at both system and agent levels. Our results show that the coalition formation mechanism is beneficial for both the system\u2014it reaches an equilibrium state\u2014and for the agents\u2014their gains highly increase over time.", "authors": ["Julita Vassileva", "Silvia Breban", "Michael C. Horsch"], "n_citation": 51, "references": ["22670bb7-717f-4457-9318-fa46419ba674", "452894d1-3e56-4ee0-b7aa-6ac646c2d048", "68ef3690-d8d7-472b-976a-329a111c5ecc", "6a35b9e5-4c62-49a9-a26c-82c9562a6a38", "6b8caca2-ce9a-47a6-af3c-e3efbda4f73c", "e0b0e31a-e5ea-434d-929d-f12db6d2e149", "ee9bbc54-9ed3-4ecc-8cfc-181af184e2d2"], "title": "Agent Reasoning Mechanism for Long\u2013Term Coalitions Based on Decision Making and Trust", "venue": "computational intelligence", "year": 2002, "id": "e1c4c5ef-160c-4493-9916-0ea808c7431c"}
{"abstract": "Many robotic systems, like surgical robots, robotic hands, and exoskeleton robots, use cable passing through conduits to actuate remote instruments. Cable actuation simplifies the design and allows the actuator to be located at a convenient location, away from the end effector. However, nonlinear frictions between the cable and the conduit account for major losses in tension transmission across the cable, and a model is needed to characterize their effects in order to analyze and compensate for them. Although some models have been proposed in the literature, they are lumped parameter based and restricted to the very special case of a single cable with constant conduit curvature and constant pretension across the cable only. This paper proposes a mathematically rigorous distributed parameter model for cable-conduit actuation with any curvature and initial tension profile across the cable. The model, which is described by a set of partial differential equations in the continuous time-domain, is also discretized for the effective numerical simulation of the cable motion and tension transmission across the cable. Unlike the existing lumped-parameter-based models, the resultant discretized model enables one to accurately simulate the partial-moving/partial-sticking cable motion of the cable-conduit actuation with any curvature and initial tension profile. The model is further extended to cable-conduit actuation in pull-pull configuration using a pair of cables. Various simulations results are presented to reveal the unique phenomena like backlash, cable slacking, interaction between the two cables, and other nonlinear behaviors associated with the cable conduits in pull-pull configuration. These results are verified by experiments using two dc motors coupled with a cable-conduit pair. The experimental setup has been prepared to emulate a typical cable-actuated robotic system. Experimental results are compared with the simulations and various implications are discussed.", "authors": ["Varun Agrawal", "William J. Peine", "Bin Yao"], "n_citation": 56, "references": ["19805ee0-7d86-4534-9dce-0da9902223bf", "6f482e74-a68b-448b-af85-6b3f8492e07f", "718e7d1e-3488-4128-aabc-fe7150314855", "7d1a84bc-fdea-41d9-ad69-3c6e7e27dede", "ac88f0fb-aee8-45bb-9c68-9fb112a32e9a", "ae6027e5-2a74-401f-8c63-88bb74c9e9ae", "ba536cc4-fbdc-491b-939d-0454bcb71bd5", "d5050764-b526-4df0-8823-424101a93306", "e484835f-cd49-48d9-9584-39bca60fc343"], "title": "Modeling of Transmission Characteristics Across a Cable-Conduit System", "venue": "IEEE Transactions on Robotics", "year": 2010, "id": "c4dc2445-e866-4e6c-a8f3-d82c1e1de4dd"}
{"abstract": "Domain-specific information retrieval normally depends on general search engines, or systems which support browsing using handcrafted organisation of documents, but such systems are costly to build and maintain. An alternative approach for specialised domains is to build a retrieval system incrementally and dynamically by allowing users to evolve their own organisation of documents and to assist them in ensuring improvement of the system's performance as it evolves. This paper describes a browsing mechanism for such a system based on the concept lattice of Formal Concept Analysis (FCA) in cooperation with incremental knowledge acquisition mechanisms. Our experience with a prototype suggests that a browsing scheme for a specific domain can be able to be collaboratively created and maintained by multiple users over time. It also appears that the concept lattice of FCA is a useful way of supporting the flexible open management of documents required by individuals, small communities or in specialised domains.", "authors": ["Mihye Kim", "Paul Compton"], "n_citation": 50, "references": ["0effe776-213d-47c2-8455-5998f7365d73", "21e6c5b4-b587-4735-9c73-f50f6e9996e6", "2574323d-6e0f-4f8e-b1af-16be244d464f", "2fa89208-874a-4fb9-9386-b6a366913fab", "308de098-b87f-4cc2-90a7-4c071d52850c", "5ca1a507-c774-4121-8993-0eb15bf707b8", "730f2812-48ba-47ce-a85a-be2518c927a4", "bae38a13-7226-45d4-b9b9-d8f516272e0d", "d15b726e-c2f6-4699-ab3e-bfb653d942cc", "eac692d3-ae85-4051-b714-b49026eaa1e2", "ec3d63ba-4f71-4c02-a7f0-ea3e07c9fec2"], "title": "Formal Concept Analysis for Domain-Specific Document Retrieval Systems", "venue": "australian joint conference on artificial intelligence", "year": 2001, "id": "bb6f790f-f0d7-4cc9-b5c4-935ca06de63a"}
{"abstract": "Tailorability (or adaptability) of software becomes more important with the increasing use of off-the-shelf-software. On the other hand, computers support the work of many groups which in turn have to tailor a commonly used software to support individual as well as group needs. This includes not only groupware, i. e., software that directly supports collaborative work, but also single user software. Research has shown that often adaptations to single user software are distributed among colleagues, thus leading to a systematization in a group's adaptations. Based on this observation an empirical field-study on the collaborative tailoring habits of users of a particular word processor was carried out. Based on these and literature research an add-on to this word processor was developed which provides a public and a private repository for adaptations as well as a mailing function for users to exchange adaptations. Some notification and annotation mechanisms are also provided. Results of two forms of evaluation indicate that users of different levels of qualification are able to handle the tool and consider it a relevant alternative to existing mailing mechanisms.", "authors": ["Helge Kahler"], "n_citation": 13, "references": ["1778f8ea-3ad9-448a-80da-dc5d188a7f01", "26c75e2e-724c-4d32-9491-4cd7d8fada89", "2e01c794-9294-4f3c-ae62-71e23ee15cbf", "30c2c713-b998-4738-bdb8-e68c7dfea934", "39308b24-1d57-4942-9faf-1d02a619d2aa", "39c8815a-3ee7-4db6-8800-87bb4dcd9151", "4f1f72a7-1541-433d-a69d-7e89b1338b4f", "4f79d542-af8f-4747-b408-94971692deff", "a37d8100-7fb5-4fd2-b1cd-f8f0e1f14f38", "a65db099-0d8b-415a-ab60-f318552140ae", "c86db7de-7331-48f7-9ee8-01bd770b482a", "ddd5e1ac-f71a-4647-942a-ef5c3ae19c1b"], "title": "More Than WORDs Collaborative Tailoring of a Word Processor", "venue": "Journal of Universal Computer Science", "year": 2001, "id": "558c454d-1593-453a-a18a-d6ed72f316bf"}
{"abstract": "This paper presents a model-based approach to system-software co-engineering which is focused on aerospace systems but is relevant to a much wider class of dependable systems. We present the main ingredients of the SLIM modeling language and give a precise interpretation of SLIM models by providing a formal semantics using networks of event-data automata. The major distinguishing aspects of this component-based approach are the possibility to describe nominal hardware and software operations, hybrid (and timing) aspects, as well as probabilistic faults and their propagation and recovery. As our approach bears strong resemblance to the standardized AADL (Architecture Analysis and Design Language), a secondary contribution of this paper is a formal semantics of a large fragment of AADL including its Error Model Annex.", "authors": ["Marco Bozzano", "Alessandro Cimatti", "Marco Roveri", "Joost-Pieter Katoen", "Viet Yen Nguyen", "Thomas Noll"], "n_citation": 50, "references": ["040d2f50-1fbf-4c9f-b4ab-0650c279ea8a", "0d261b6a-c94a-4d5e-b44e-eb6ae46581fc", "15453c5e-cdfb-4003-9295-cda10cc8c38d", "252b9e3e-4e30-426b-b4fc-2859b4e5503c", "27f1a095-b875-436a-bec7-6d88e53f6ab7", "2e5a9d09-5688-4a8f-9b89-8d0527062a78", "30d5e5dd-8bdf-4db8-900a-7bacf60c29bf", "38852247-c2e6-4d6c-a31b-17a4b32aefc3", "4941745e-f61b-4929-ac2a-ed8501439081", "503d057b-7be1-43f6-b6cd-8bf2ef24133b", "78ba44d3-7160-488a-989a-4cb641530e7c", "8519989b-714b-4b8d-b625-96b451094589", "87cda163-eab6-4b12-8cd0-c733ca121f07", "93b22478-94f8-4c15-ae03-ed98a856f60c", "93cedb56-748e-4a11-b48d-087069c52de8", "9a7e8549-bc5a-4fac-bba9-c4951f655a31", "9c83d335-e6c4-4e15-ae49-1dcd2dbc3dc2", "a576d312-f82a-4356-bbae-efc3f9c8fcc2", "a867bd7e-fa2a-4750-8f85-258bc724267c", "acb50193-6274-4601-892b-c7306adc46e2", "b3035117-2e8f-4738-bff1-1ae434873cf5", "bf2300fa-2717-4acd-9c5d-ac30b7ea203b", "d4633091-aadd-4a27-accd-344d3e773ac8", "e33506ac-40dc-4b54-93a6-d128e986ef01", "e9a1aa8f-4c76-496e-a498-26b8a0de0cf6", "ef9882f9-8b7b-4087-be6d-b5c16758cbd8", "f191ea70-1f5f-47eb-aacb-47e027071feb", "fd8d4876-0f76-49f2-b605-a301973012bb"], "title": "Codesign of dependable systems: a component-based modeling language", "venue": "formal methods", "year": 2009, "id": "6cea122d-e7a4-4816-8e71-23982b1af434"}
{"abstract": "Abstract   Simulations of interacting particles are common in science and engineering, appearing in such diverse disciplines as astrophysics, fluid dynamics, molecular physics, and materials science. These simulations are often computationally intensive and so are natural candidates for massively parallel computing. Many-body simulations that directly compute interactions between pairs of particles, be they short-range or long-range interactions, have been parallelized in several standard ways. The simplest approaches require all-to-all communication, an expensive communication step. The fastest methods assign a group of nearby particles to a processor, which can lead to load imbalance and be difficult to implement efficiently. We present a new approach, suitable for direct simulations, that avoids all-to-all communication without requiring any geometric clustering. We demonstrate its utility in several parallel molecular dynamics simulations and compare performance against other parallel approaches. The new algorithm proves to be fastest for simulations of up to several thousand particles.", "authors": ["Bruce Hendrickson", "Steve Plimpton"], "n_citation": 55, "title": "Parallel many-body simulations without all-to-all communication", "venue": "Journal of Parallel and Distributed Computing", "year": 1995, "id": "daecc75b-0b93-4030-8c02-0249281cb9a6"}
{"abstract": "The supervision of dynamic systems is essential in industrial applications. The decentralization of such systems makes their supervision more difficult. In this article, we tackle the supervision problem by using a temporal scenario recognition approach. The supervision is performed by a society of agents, where an agent is considered as a watching process that is responsible for a subset of possible scenarios of the functioning of the system. The cooperation among agents is based on interaction protocols as well as dependence networks.", "authors": ["Mohamad K. Allouche", "Claudette Sayettat", "Olivier Boissier"], "n_citation": 7, "references": ["0840c076-7518-43e6-b618-cfee9c0b39d5", "4c8b52cd-a4d7-46ed-a1e1-9da001b53106", "59efb068-0be4-45bd-8fcb-be6c7a0b1fe5", "9118daef-8652-438c-848f-695b84b5bc45", "dbba840d-df0f-4540-b9e3-ec52129c52af"], "title": "Towards a multi-agent system for the supervision of dynamic systems", "venue": "international symposium on autonomous decentralized systems", "year": 1997, "id": "383f09b0-2657-4b8f-8414-469f7c617312"}
{"abstract": "Caching at proxy servers is one of the ways to reduce the response time perceived by World Wide Web users. Cache replacement algorithms play a central role in the response time reduction by selecting a subset of documents for caching, so that a given performance metric is maximized. At the same time, the cache must take extra steps to guarantee some form of consistency of the cached documents. Cache consistency algorithms enforce appropriate guarantees about the staleness of the cached documents. We describe a unified cache maintenance algorithm, LNC-R-WS-U, which integrates both cache replacement and consistency algorithms. The LNC-R-WS-U algorithm evicts documents from the cache based on the delay to fetch each document into the cache. Consequently, the documents that took a long time to fetch are preferentially kept in the cache. The LNC-R-W3-U algorithm also considers in the eviction consideration the validation rate of each document, as provided by the cache consistency component of LNC-R-WS-U. Consequently, documents that are infrequently updated and thus seldom require validations are preferentially retained in the cache. We describe the implementation of LNC-R-W3-U and its integration with the Apache 1.2.6 code base. Finally, we present a trace-driven experimental study of LNC-R-W3-U performance and its comparison with other previously published algorithms for cache maintenance.", "authors": ["Junho Shim", "Peter Scheuermann", "Radek Vingralek"], "n_citation": 278, "references": ["0ee5c447-1765-4dc5-a37c-5821d5591c27", "162e4e22-2ad7-42b0-a566-83c65ec46bd2", "1afcf3f9-e5f6-4372-ad42-5da5ffca4a78", "1e68ea78-6b84-4c4f-aa97-08b808fc2d5d", "5932b561-7e51-4971-beb8-3231e1dec7f4", "5eeb077a-57f1-449b-9347-fcfdd7311222", "5fa0709f-7330-417f-8da7-3ab31d91da5b", "5fa79bc6-4203-442f-a3e8-99abe8bd542a", "649da42f-ddb5-4703-9c66-cec32fee922a", "6b36c1e4-5377-49da-a572-5d61005f09dd", "84809f0c-f5aa-41cf-b364-9395d69abc62", "8ab79b37-5990-42d8-b93d-5db692120bd9", "912bd9d0-b225-457a-99b0-ec850c0ac89c", "b001c2c0-80b5-4aa1-b5b3-783aaaa8f2f1", "b678bada-3feb-43ac-b4b2-0115f76c28d3", "c5ab640d-0872-46f8-bf53-e890c295adeb"], "title": "Proxy cache algorithms: design, implementation, and performance", "venue": "IEEE Transactions on Knowledge and Data Engineering", "year": 1999, "id": "3c27b372-42ce-4a8f-a933-2be9451998bc"}
{"abstract": "Abstract   It is shown that the permanent function of (0, 1)-matrices is a complete problem for the class of counting problems associated with nondeterministic polynomial time computations. Related counting problems are also considered. The reductions used are characterized by their nontrivial use of arithmetic.", "authors": ["Leslie G. Valiant"], "n_citation": 2297, "references": ["172f9f68-8417-43bb-8fe5-b377d569f6b6", "4388f138-8b70-45c7-890a-18ccc4390e2b", "5539290f-8c10-49f7-95bf-d57f8c445a06", "64b790be-5b45-4f8c-995a-20a85369546a", "6e2f37b5-96b3-415f-988d-f91f7bcdfd2d", "8d09527f-b5ad-4902-ba34-5583f6759d3b", "9d02bb86-bf86-4f07-8989-e05d59819a6f", "9f41ff40-d946-410d-9ffb-f27d8a4336fa", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "c5368c25-5748-4af2-8b0f-f2cca8dbb4f0", "ceb48415-4ff9-4097-a262-421b7ac93535"], "title": "The complexity of computing the permanent", "venue": "Theoretical Computer Science", "year": 1979, "id": "54277585-284a-4e84-8feb-9840dedc3d81"}
{"abstract": "A hierarchical module system is an effective tool for structuring large programs. Strictly hierarchical module systems impose an acyclic ordering on import dependencies among program units. This can impede modular programming by forcing mutually-dependent components to be consolidated into a single module. Recently there have been several proposals for module systems that admit cyclic dependencies, but it is not clear how these proposals relate to one another, nor how one might integrate them into an expressive module system such as that of ML.To address this question we provide a type-theoretic analysis of the notion of a recursive module in the context of a \"phase-distinction\" formalism for higher-order module systems. We extend this calculus with a recursive module mechanism and a new form of signature, called a  recursively dependent signature , to support the definition of recursive modules. These extensions are justified by an interpretation in terms of more primitive language constructs. This interpretation may also serve as a guide for implementation.", "authors": ["Karl Crary", "Robert Harper", "Sidd Puri"], "n_citation": 130, "references": ["0c66bc00-bede-4c8f-9216-717fad194fae", "23c82e3b-76e3-401a-835b-7b7cc9e708c0", "369b23c3-5ca8-4d66-aa1a-aa40a14231bc", "4d4e183d-7cca-4e23-8ecb-c5445c96faca", "5de56286-91f3-49cb-ab3a-6e98b4abf0d8", "639bc67d-ead6-43c7-a7f1-0fc3027fba8e", "6b8e6943-b5da-4c6e-8c3b-5688a1b306d3", "7efb35fb-4a85-4990-8694-f74c155f392c", "91c35818-86ab-48b7-865e-35387db50e77", "9a99ff5d-fd00-429f-9f7d-087ee23b5d5b", "a4e39a60-7224-4b47-a371-1de04beac23a", "a80f245f-2906-42f4-9b2b-f5a131248665", "e62ee8a3-2ea5-450e-9496-2c07899bf7c4", "e9fbf820-8f20-4d21-bfbc-5ada78d59ba5", "fdf7a23e-1718-4269-a2e8-b9d2b63913ff"], "title": "What is a recursive module", "venue": "programming language design and implementation", "year": 1999, "id": "d0206178-2f87-420e-afa5-30311d9bcbd9"}
{"abstract": "The recent extensive availability of \"big data\" platforms calls for a widespread adoption by the formal verification community. Cloud computing platforms represent a great opportunity to run massively parallel jobs, yet classical formal verification tools/techniques must undergo a deep technological transformation in order to exploit the new available architectures. This has raised an increasing interest in deploying verification techniques on parallel/distributed frameworks. In this paper we introduce a framework to ease the adoption of a distributed approach to verification of Computation Tree Logic (CTL) formulas on very large state spaces. The approach exploits/integrates a recently developed, parametric state-space builder. The whole framework adopts M AP R EDUCE as core computational model, and can be tailored to different modelling formalisms. The outcomes of several tests performed on (Petri-nets based) benchmark specifications are presented, thus showing the convenience of the proposed approach.", "authors": ["Matteo Camilli", "Carlo Bellettini", "Lorenzo Capra", "Mattia Monga"], "n_citation": 8, "references": ["09555474-98b4-4b86-b545-12bc24fab9f6", "12adf7b4-b9f8-4311-83e4-15167eca5061", "2bb33756-67db-4329-8c0d-f3c5fdab2367", "2f2a347d-cc88-483a-9723-7767c6046ee0", "3f7981eb-7e84-449e-bced-7a7dabba788c", "40670a68-abf3-441c-ab11-1c5bd1d1b6c6", "40829e15-851e-460b-a7af-4bf38a133bd9", "49bb7b2d-32a0-4335-a3b6-9d606685cd7f", "5002dd27-9ce6-4abb-a3d0-2ac112f58c37", "5fc85625-a447-43eb-a567-71c5424d7308", "6247ede7-7917-46cc-807c-ec2cb68ca06d", "64df1833-928f-443a-81e0-4ded006e1477", "662a88dc-635b-425f-b315-9140bd794332", "6e1947dd-2997-481b-9726-2921960e677f", "700197de-ce65-4187-99ef-7a1ebc270525", "8873cda3-f462-4b6f-a70c-1271f2f00664", "8c6773dc-0196-40b4-9859-37d598079892", "9456e320-55a6-44ce-954f-bf8f7ddd701f", "a0e01511-9865-4416-b87f-0a4dc5fb10bc", "b1a82cb5-5952-4d1f-a82f-8873412fedbe", "bbb09230-dcdc-43a2-b371-218d8d47c62c", "bbee2f29-f141-4c6f-9f36-e8254e492acb", "c00bbb49-6e29-4103-8883-55acd23c248b", "db1dbd30-7a91-4089-8928-a5bf06978d0d", "e26a39ae-3560-4de2-ae61-7048db79b930", "e593d137-a92d-4318-9c91-50886c32b685", "f0348a50-fd74-4269-a81d-4dc272a8e31a", "f26e130f-ea49-4e03-985c-f69a0214a7a2"], "title": "CTL Model Checking in the Cloud Using MapReduce", "venue": "symbolic and numeric algorithms for scientific computing", "year": 2014, "id": "c5cfe100-0a18-4124-889c-0e438c3ad95d"}
{"abstract": "Automatic face location in complex scenes is extremely challenging in human face recognition systems. Further more, the facial features detection also plays an important role. The paper presents a scheme for robust face and eyes detection from an image. The scheme uses the Gaussian steerable filter to search and detect the facial feature (preattentive feature) roughly in an image. The face model is investigated to locate the whole face and facial features, such as eyes, nose and mouth. Here, multiple evidences are used in the face location and eyes detection. One important feature is the structural information of the face, i.e. facial components of certain structure. The other is the symmetry property of the face, here only the front face with certain pose variation is considered. It will reduce the computation greatly. For facial components detection, some image features and PCA features are used for verification from the candidates detected before. Experiments show that the algorithm is robust and fast.", "authors": ["Weimin Huang", "Qibin Sun", "Chian-Prong Lam", "Jiankang Wu"], "n_citation": 18, "references": ["20f2dbb4-11c7-4242-ac7f-d529a736b51d", "36800655-b2ff-4eb7-9070-c6be304c4baa", "5de25331-b39f-4667-a074-b30c99f9a720", "648675c6-6ea7-4fa5-a91d-9d3156d09692", "64fa74e8-db02-4190-87d7-bf23e9859a7c", "9076efa2-15f0-4d85-bdca-00c87cb0c368", "f769518e-b3d5-4dee-87dd-debcd57b1387"], "title": "A robust approach to face and eyes detection from images with cluttered background", "venue": "international conference on pattern recognition", "year": 1998, "id": "cbf01b67-50a3-4b78-ab9f-b683408ebc4c"}
{"abstract": "Abstract   System identification takes a space of possible models and a stream of observational data of a physical system, and attempts to identify the element of the model space that best describes the observed system. In traditional approaches, the model space is specified by a parameterized differential equation, and identification selects numerical parameter values so that simulation of the model best matches the observations. We present SQUID, a method for system identification in which the space of potential models is defined by a semi-quantitative differential equation (SQDE): qualitative and monotonic function constraints as well as numerical intervals and functional envelopes bound the set of possible models. The simulator SQSIM predicts semi-quantitative behavior descriptions from the SQDE. Identification takes place by describing the observation stream in similar semi-quantitative terms and intersecting the two descriptions to derive narrower bounds on the model space. Refinement is done by refuting impossible or implausible subsets of the model space. SQUID therefore has strengths, particularly robustness and expressive power for incomplete knowledge, that complement the properties of traditional system identification methods. We also present detailed examples, evaluation, and analysis of SQUID.", "authors": ["Herbert Kay", "Bernhard Rinner", "Benjamin Kuipers"], "n_citation": 75, "references": ["00db237e-21bd-4622-8233-08fdfd645447", "110d4c4b-776e-4695-bd2f-7c7adacd5ba9", "1d81717e-2cea-4c9c-a7a7-390822a46ab7", "2a73f987-98cc-4d8b-bf27-9d8d0834c57c", "2fa2e5ba-11d3-4691-91e1-807b8ef7d8a5", "5506c2ad-553a-41f1-aea1-9ab723b477d9", "55faeea3-202a-45b5-bab6-1dfe8eb1a04b", "75b9b763-2e59-4f0d-9f1c-ab363854fbd9", "8a05fc28-2bb0-4dec-8c4e-ee7158413ac1", "a2dbd476-4d29-4c23-9470-f6ef1ac35159", "c1d22939-7390-478a-b3ea-074435e2e5cb", "d8f20d8f-7e3d-4cea-ac3a-e9b96875461a", "efdc80ba-6b0c-4d67-9b00-9ba8438a965a", "f7156d36-aec1-4cee-8dbe-a2301a417d5f", "f7979994-46d5-4a7b-b7eb-7309d2492b9d"], "title": "Semi-quantitative system identification", "venue": "Artificial Intelligence", "year": 2000, "id": "6dc6ad17-a05d-4cdc-af93-aa6d896eb75f"}
{"authors": ["Davide Sangiorgi"], "n_citation": 20, "references": ["1391b327-8f4c-4b9e-b7fb-f015ef6d5e57", "3023929a-c93e-49c5-b03f-7fb0414d94df", "400895f6-bde9-4314-a623-65a7a12e4d22", "6f45828a-82d4-4306-bc4f-f7fb31d4298e", "941ef1e2-15ef-4dc1-a6b7-15d1b96376a5", "9801a8a7-90c9-4f54-abea-35bfaa48ecb7", "e60b9f31-a356-4ad5-ab6b-d4ff2d5709d9"], "title": "Internal Mobility and Agent-Passing Calculi", "venue": "international colloquium on automata languages and programming", "year": 1995, "id": "b3f30888-ecfd-4ae2-b3d2-b228aaff5ce8"}
{"abstract": "We present a self-stabilizing solution to a new version of the dining philosophers problem. We call this problem mobile philosophers problem because the philosophers can move around a logical ring formed out of a dynamic network.", "authors": ["Ajoy Kumar Datta", "Maria Gradinariu", "Michel Raynal"], "n_citation": 50, "references": ["33de8856-0b19-450b-b18c-c38288e941ec", "3e5eaa50-7b6e-40d5-a177-c5a08ba0275d", "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4", "b3b22868-7ed9-44f3-83b8-00c87ee79899", "ca2a4557-87c1-42ff-9edd-79b657948809", "d02e1976-4f84-455a-9b9d-fda2df5b259f", "fa115597-6101-4fee-aa8c-f2501397c738"], "title": "Stabilizing mobile philosophers", "venue": "Information Processing Letters", "year": 2005, "id": "cd389dda-f07f-4285-b235-619b0262f828"}
{"abstract": "The authors consider five common myths about automatic programming and expose the fallacies on which they rest. They attempt to provide an accurate picture of these systems in terms of what the user sees, how the system works, and what the system knows. They describe commercially available systems and discuss what is on the horizon. >", "authors": ["Charles Rich", "Richard C. Waters"], "n_citation": 180, "references": ["4f014564-367f-4dbc-845d-ea254ad60314", "5edb99f2-cc75-468e-9ca0-28ce7a1e709d", "91dc9071-57cf-43ca-a85d-c019a8d076a6", "a9d193ab-dae8-4876-a0b0-eac4f6134a36", "c4b1b8cd-2f52-4770-b461-241a7d16da95", "d0a025e2-5f9a-4a52-a061-7c809050ece1", "dc812e13-965d-4720-b0b6-ee6e409e2ec4", "e18bfb3a-c346-4594-b419-8e7c4bcb8e0d", "ea8d8e8f-d8df-4722-935b-401665ea6fbc"], "title": "Automatic programming: myths and prospects", "venue": "IEEE Computer", "year": 1988, "id": "6e453365-004a-4c74-8d96-ae4718e8dfca"}
{"abstract": "This paper describes an ongoing partnership between the Seidenberg School of Computer Science and Information Systems at Pace University, a Registered Education Provider (REP) for IEEE and the Information Technology Division at Bank of New York Mellon. The goal of the project is to deliver at the bank's location, a high quality, customized, graduate program in software engineering as well as to reflect on its strong and weak points and improve it. More importantly, through intense interaction with the Bank's IT Management, to ensure that the academic program matches their actual needs. The technology transfer, the customized training and the challenges are discussed.", "authors": ["Sotiris Skevoulis"], "n_citation": 50, "references": ["914799b9-34a9-4f27-b7c6-a5c55f339481", "b4a46082-dc2d-402a-800c-9ef6bdc2398e", "deb3fae4-d77c-4d05-a058-91c46416db00"], "title": "Engineering a successful partnership between academia and the financial industry: A software engineering program for IT professionals", "venue": "", "year": 2011, "id": "9d79b3fb-d093-413d-9f17-2ab9e1e45495"}
{"abstract": "We address the problem of texture segmentation by using a novel affine invariant model. The introduction of affine invariance as a requirement for texture analysis goes beyond what is known of the human performance and also beyond the psychophysical theories. We propose to compute texture features using affine invariant intrinsic neighborhoods and affine invariant intrinsic orientation matrices. We discuss several possibilities for the definition of the channels and give comparative experimental results where an affine invariant Mumford-Shah type energy functional is used to compute the multichannel affine invariant segmentation. We prove that the method is able to retrieve faithfully the texture regions and to recover the shape from texture information in images where several textures are present. The numerical algorithm is multiscale.", "authors": ["Coloma Ballester", "Manuel Revuelta Gonz\u00e1lez"], "n_citation": 50, "references": ["1aab6663-cc0a-425c-83b4-2ac5d8b5e052", "1f03298f-3522-40d4-937a-23c97750278a", "270de21e-f73e-44bb-a424-43441369f827", "27f226a4-66ff-4fd7-bf4b-94d5bea4e4ab", "48c4df8b-249a-4ca2-bf93-4df44200b7a6", "4c0ae3e7-45b4-441e-81b2-7b325af64e32", "536bae3c-3a30-4855-ac10-411930bd11ad", "5b84e2fc-3ba7-42e7-8c21-dd98add58f6f", "611be2d9-59fd-4dc3-82cb-c8e7c0ed2b03", "61960382-eb74-4fbf-81c8-cc22ffcecc19", "667a288c-8631-460d-98e2-8e014f5d0b2f", "6ac00351-112e-42f5-96f7-3144dd6fc95f", "77422639-d382-4455-b4ad-b2b47b44f2f5", "775d8200-d1e0-40ac-8c47-a6edf4b6be72", "84e45367-a551-40c0-ba18-8c4ebba7944a", "89c28928-67d0-4cd3-8cb4-edc71d1f9699", "9cef868f-eb6d-4189-acd1-43eac87cf81e", "ab2cb905-a1a4-481c-83be-e156ebff3288", "b20fb115-14dc-4edd-b312-73a7ff53aedf", "c16563e5-f2bc-4182-b0a1-cf0c75e4ed04", "c233b742-ec5c-4600-8e6d-1f747bef3a5c", "dbda5e2e-32b1-49fa-a264-0316edb5c9d0", "e2ebd9ae-ed07-4a4a-acf2-9dee7f02192d", "e67a2018-8781-4ac1-a987-751b21108517", "f534affc-459f-4b62-8f2d-7fabc355afb4"], "title": "Affine Invariant Texture Segmentation and Shape from Texture by Variational Methods", "venue": "Journal of Mathematical Imaging and Vision", "year": 1998, "id": "2733a789-f151-4385-9eea-a57a96a38e96"}
{"abstract": "We propose a security model for Vehicular Ad-hoc Networks (VANETs) to distinguish spurious messages from legitimate messages. In this paper, we explore the information available in a VANET environment to enable vehicles to filter out malicious messages which are transmitted by a minority of misbehaving vehicles. More specifically, we introduce a message filtering model that leverages multiple complementary sources of information to construct a multi-source detection model such that drivers are only alerted after some fraction of sources agree. Our filtering model is based on two main components: a threshold curve and a Certainty of Event (CoE) curve. A threshold curve implies the importance of an event to a driver according to the relative position, and a CoE curve represents the confidence level of the received messages. An alert is triggered when the event certainty surpasses a threshold. We analyze our model and provide some initial simulation results to demonstrate the benefits.", "authors": ["Tiffany Hyun-Jin Kim", "Ahren Studer", "Rituik Dubey", "Xin Zhang", "Adrian Perrig", "Fan Bai", "Bhargav R. Bellur", "Aravind Iyer"], "n_citation": 50, "references": ["407261fa-0f0f-4ec1-9197-5f956450e896", "4a00dc68-401d-4cbf-b5b0-1ea2cab3d396", "6a8bcfc5-4fb7-4fb2-a2c7-9c7d9ef4c92e", "737161c5-916e-4dbb-bf7d-e74e00a2dbce", "816fc857-87aa-46b6-9a69-0226be5e0872", "8c5ae52c-4c47-43c2-9f27-0cdd46a9dccf", "ad464f36-209e-4a79-aa04-6ce44e66a340", "c81a251c-8f5d-4f50-a89b-70e52c37d340", "c9de7509-9b72-4132-9154-483a2a7186ae", "e4cf4340-00af-4dc3-bbc1-c3cb5b7b6899", "e6a47841-d603-441b-a95c-f4fd35a8ea88", "f2545d97-ac1e-4e4d-9f84-b264cb7345b6"], "title": "VANET alert endorsement using multi-source filters", "venue": "ad hoc networks", "year": 2010, "id": "520e0419-7775-47cc-8f4a-2a1b80b8687f"}
{"abstract": "We select candidates for process change on the basis of quantified Software Engineering Laboratory (SEL) experiences and clearly defined goals for the software. After we select the changes, we provide training and formulate experiment plans. We then apply the new process to one or more production projects and take detailed measurements. We assess process success by comparing these measures with the continually evolving baseline. Based upon the results of the analysis, we adopt, discard, or revise the process. >", "authors": ["Victor R. Basili", "Marvin V. Zelkowitz", "Frank E. McGarry", "Jerry L. Page", "Sharon Waligora", "Rose Pajerski"], "n_citation": 116, "references": ["428adab0-e700-410c-ab1f-07face240174", "68734730-8262-47e2-a8a1-6d67cbdf32f8", "a6ee8425-3dd3-40fd-b9bb-214632f04a1a"], "title": "SEL's software process improvement program", "venue": "IEEE Software", "year": 1995, "id": "8d3d2fbb-64a3-49bb-96b2-fd349669457f"}
{"abstract": "TLS has been formally analyzed with the OTS/CafeOBJ method. In the method, distributed systems are modeled as transition systems, which are written in terms of equations, and it is verified that the models have properties by means of equational reasoning. TLS is the latest version, or the successor of SSL, which is probably the most widely deployed security protocol. Among the results of the analysis are that pre-master secrets cannot be leaked, when a client has negotiated a cipher suite and security parameters with a server, the server has really agreed on them, and client cannot be identified if they do not send their certificates to servers", "authors": ["Kazuhiro Ogata", "Kokichi Futatsugi"], "n_citation": 50, "references": ["23634361-c27f-4cd6-b795-c933e1a41c84", "41236602-0290-40b2-8776-c075562d5616", "7d45ad45-f777-40d0-ab60-c64f1ea845e0", "804cb992-d1ab-4d00-a6d4-db8f089f1c69", "9539bfba-c066-401c-bd7a-3be1323b5b21", "f99efcca-ee26-40fa-8660-19b910a7fb2a", "fe47ca98-b780-47c9-a4df-b420bb8ca86a"], "title": "Equational Approach to Formal Analysis of TLS", "venue": "international conference on distributed computing systems", "year": 2005, "id": "28518cf7-ad22-4170-bc8f-36ff6350f51c"}
{"abstract": "Maintainability is a key quality attribute of successful software systems. However, its management in practice is still problematic. Currently, there is no comprehensive basis for assessing and improving the maintainability of software systems. Quality models have been proposed to solve this problem. Nevertheless, existing approaches do not explicitly take into account the maintenance activities, that largely determine the software maintenance effort. This paper proposes a 2-dimensional model of maintainability that explicitly associates system properties with the activities carried out during maintenance. The separation of activities and properties facilitates the identification of sound quality criteria and allows to reason about their interdependencies. This transforms the quality model into a structured and comprehensive quality knowledge base that is usable in industrial project environments. For example, review guidelines can be generated from it. The model is based on an explicit quality metamodel that supports its systematic construction and fosters preciseness as well as completeness. An industrial case study demonstrates the applicability of the model for the evaluation of the maintainability of Matlab Simulink models that are frequently used in model-based development of embedded systems.", "authors": ["Florian Deissenboeck", "Stefan Wagner", "Markus Pizka", "Stefan Teuchert", "Jean-Fran\u00e7ois Girard"], "n_citation": 119, "references": ["02e0342a-33d3-4d3f-9f1d-b14081edbc39", "262d8c93-5bce-48c3-ab4d-d363edca951f", "2f210db7-d968-4266-a489-f193e6d75cc6", "4f736331-4663-4b8b-8317-c04c59b32a25", "4f99076f-c891-4529-8eb8-297c62e57c9d", "56fac13c-f5f7-4da7-ab12-ebabc59c9bf5", "8edbd95f-9cfe-4cd6-bd13-b4f8d80edb1c", "94924865-1b8f-4d84-8738-e914f431b530", "9d9630c2-08ad-42ee-b7d2-4af68761979a", "d7e4a57d-fc8b-4018-8a22-b2b9502d0e7e", "dbdf8e6d-42f2-4258-ac23-9b3682cea7d6", "e25ddd19-ec1d-4f25-beb5-27d9573656dc", "f3ab64f5-c214-4869-9854-bf7511a2a10b"], "title": "An Activity-Based Quality Model for Maintainability", "venue": "international conference on software maintenance", "year": 2007, "id": "b9b8414e-bc2d-46bf-8cb4-dfe3cd3cd41e"}
{"abstract": "Bounded model checking (BMC) of C and C++ programs is challenging due to the complex and intricate syntax and semantics of these programming languages. The BMC tool LLBMC presented in this paper thus uses the LLVM compiler framework in order to translate C and C++ programs into LLVM's intermediate representation. The resulting code is then converted into a logical representation and simplified using rewrite rules. The simplified formula is finally passed to an SMT solver. In contrast to many other tools, LLBMC uses a flat, bit-precise memory model. It can thus precisely model, e.g., memory-based re-interpret casts as used in C and static/dynamic casts as used in C++. An empirical evaluation shows that LLBMC compares favorable to the related BMC tools CBMC and ESBMC.", "authors": ["Florian Merz", "Stephan Falke", "Carsten Sinz"], "n_citation": 123, "references": ["0278bce3-e509-4ae6-b130-87a283a4b819", "0a0cdabe-ff30-4d1c-b6a0-2e979bf8b138", "178cdef3-deaa-45d3-93f7-861b22ec6e19", "25b87b5d-6e8d-436a-a9c0-316b4552a6ab", "3b3b3235-9963-45b4-af35-1a9096458206", "609a695e-c9ab-4315-8c61-4b233fe190e2", "63335c25-3ee6-467a-84eb-3f47174d4812", "71209296-e207-422b-bb8b-7ebbc2672068", "714bfb60-ccc8-4d41-b79b-0b5c7fe559d5", "71c47dd0-a7ff-4b97-a640-1186dd9ac968", "8d6dc616-8728-49a3-8962-71a2530d16bc", "9625d092-26fd-43b7-ba44-e26b302d2b25", "97d357fa-0172-497d-a172-f269491dc1cd", "9849d9c4-a97f-452f-882c-42a8c6cab0b5", "a7181fe9-cefe-4579-a094-389fdbc43f07", "c036912f-ac89-48b8-85b4-ceff1d08e32a", "c5915f4a-6cfa-4695-9179-e3cb70041c4a", "d2ef7cda-1172-4e20-a3be-c27ddb97bb88", "d50cac03-25bc-47fd-9a27-2be1052bd5e9", "d689cdc0-b6b5-4c31-a360-3b6b4240cd39", "f9a74ec0-71d7-4d99-87e9-4df9236ebe5f", "fece8efc-7f35-422f-904c-bf9a80b3f83b"], "title": "LLBMC: bounded model checking of C and C++ programs using a compiler IR", "venue": "verified software theories tools experiments", "year": 2012, "id": "db19d27d-7a68-4575-863d-9c3b4ee2dca3"}
{"abstract": "Stochastic Petri nets have been used to analyze the performance and reliability of complex systems comprising concurrency and synchronization. Various extensions have been proposed in literature in order to broaden their field of application to an increasingly larger range of real situations. In this paper we extend the class of Markov regenerative stochastic Petri nets* (MRSPNs*), removing the restriction that at most one generally distributed timed transition can be enabled in any marking. This new class of Petri nets, which we call concurrent generalized Petri nets (CGPNs), allows simultaneous enabling of immediate, exponentially and generally distributed timed transiiions, under the hypothesis that the latter are all enabled at the same instant. The stochastic process underlying a CGPN is shown to be still an MRGP We evaluate the kernel distribution of the underlying MRGP and define the steps required to generate it automatically. The methodology described is used to assess the behavior of a system in both steady-state and transient functioning conditions. 0 1998 Elsevier Science B.V.", "authors": ["Antonio Puliafito", "Marco Scarpa", "Kishor S. Trivedi"], "n_citation": 52, "references": ["109c983e-31a6-45d2-afbb-a6a4a6cc39c5", "449bb650-8461-4228-b22c-9265768a3bb2", "6a34e189-6f03-4314-a727-1b1686690482", "96a0c9fb-563c-4495-be56-6a3da956a71e", "c2a0ccc3-b1fa-4068-8432-bee0f1be43de", "d33d5c41-6dc3-4835-b86b-7b219b9d712b", "e1161405-6718-4983-8717-1354ecac5401"], "title": "Petri nets with k simultaneously enabled generally distributed timed transitions", "venue": "Performance Evaluation", "year": 1998, "id": "b1e42260-ff87-44ad-94e7-f5c4fdd582dc"}
{"abstract": "A neural network NN ensemble is a very successful technique where the outputs of a set of separately trained NNs are combined to form one unified prediction. An effective ensemble should consist of a set of networks that are not only highly correct, but ones that make their errors on different parts of the input space as well; however, most existing techniques only indirectly address the problem of creating such a set. We present an algorithm called ADDEMUP that uses genetic algorithms to search explicitly for a highly diverse set of accurate trained networks. ADDEMUP works by first creating an initial population, then uses genetic operators to create new networks continually, keeping the set of networks that are highly accurate while disagreeing with each other as much as possible. Experiments on four real-world domains show that ADDEMUP is able to generate a set of trained networks that is more accurate than several existing ensemble approaches. Experiments also show ADDEMUP is able to incorporate prior...", "authors": ["David W. Opitz", "Jude W. Shavlik"], "n_citation": 364, "references": ["0e19f258-9fed-4e5c-ae34-83be9cccae31", "1d48d76c-e82c-4ba5-a354-5db0b1ce05da", "1defeff4-5a9b-491d-84b0-30b990d6c121", "3213ae6b-6091-41e6-9a25-5eeb48600d90", "4e80450b-37ed-440c-87cc-d17d27e0d892", "5206bed9-d48d-44ab-b0cd-4731dfe5679c", "6565053d-ddb6-4e27-967a-ea8f8021df4b", "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "6c68311c-2745-446f-9c09-df4632392a78", "84806dbe-fa0e-47c0-b1f2-00fb2eed25a7", "b889d6ec-330d-406f-87b6-ea34804fadfd", "db26488d-78be-44b1-a343-e896f43c5d29", "f5769af3-dc6c-4a61-8b2c-7972719db66f", "fc603eb6-d237-4584-842c-c80805f31370"], "title": "Actively Searching for an Effective Neural Network Ensemble", "venue": "Connection Science", "year": 1996, "id": "7cd3d1bf-4df0-46c8-9e75-701534e5d93c"}
{"abstract": "Searching the Web and other local resources has become an every day task for almost everybody. However, the currently available tools for searching still provide only very limited support with respect to categorization and visualization of search results as well as personalization. In this paper, we present a system for searching that can be used by an end user and also by researchers in order to develop and evaluate a variety of methods to support a user in searching. The CARSA system provides a very flexible architecture based on web services and XML. This includes the use of different search engines, categorization methods, visualization techniques, and user interfaces. The user has complete control about the features used. This system therefore provides a platform for evaluating the usefulness of different retrieval support methods and their combination.", "authors": ["Korinna Bade", "Ernesto William De Luca", "Andreas N\u00fcrnberger", "Sebastian Stober"], "n_citation": 50, "references": ["1cc6e607-1013-4ca7-9146-9486787ed7f0", "2257bf90-72d5-418b-89cd-a0044d6f32ff", "2a856c55-fea1-4160-a7dc-3a48c7321d75", "4a7227f2-e92a-4eaa-9257-b0bf4b2948de", "57037984-9851-411e-b477-bd268950b7fb", "5f02e7c1-95dd-4c9b-b977-2f8bf079c296", "6ec2b89b-a06b-4e3d-999a-decfddb12224", "979e23d0-bc5d-444f-8c89-33d3b998f9fd", "9918782e-182b-47a4-a989-a364cd3576d1", "b0fdfc12-d29b-4468-bc18-a5cf8b63014b", "b71f43e1-4ba1-4321-a441-60553544a313", "c0116ed9-3fb8-42b7-83f3-e67143d5b82b", "d4999c78-c732-4186-aa2d-5e0d52d37fec", "dddfbe50-c5c7-4fe7-8f92-02e8f10db47f", "dee5188e-7eea-4bac-89f0-6bbca54d341f", "e9abffef-c6bf-44da-a673-be480773dbbb"], "title": "CARSA \u2013 an architecture for the development of context adaptive retrieval systems", "venue": "adaptive multimedia retrieval", "year": 2005, "id": "1694b3d7-077a-44f2-aaaa-05173c08776b"}
{"abstract": "The DARPA Internet uses the Domain Name System (DNS), a distributed database, to map host names to network addresses, and vice-versa. Using a vulnerability first noticed by P.V. Mockapetris, we demonstrate how the DNS can be abused to subvert system security. We also show what tools are useful to the attacker. Possible defenses against this attack, including one implemented by Berkeley in response to our reports of this problem, are discussed, and the limitations on their applicability are demonstrated.#R##N##R##N#This paper was written in 1990, and was withheld from publication by the author. The body of the paper is unchanged, even to the extreme of giving the size of the Internet as 200,000 hosts. An epilogue has been added that discusses why it was held back, and why it is now being released.", "authors": ["Steven Michael Bellovin"], "n_citation": 183, "references": ["aabd8f07-c961-4df7-98b9-759c8667497c"], "title": "Using the domain name system for system break-ins", "venue": "usenix security symposium", "year": 1995, "id": "9036662c-b239-43b8-8c7e-9e1ba83870ea"}
{"abstract": "We give a randomized fixed parameter tractable algorithm to approximately count the number of copies of a k-vertex graph with bounded treewidth in an n vertex graph. As a consequence, we get randomized algorithms with running time kO(k) nO(1), approximation ratio 1/kO(k), and error probability 2-nO(1) for (a) approximately counting the number of matchings of size k in an n vertex graph and (b) approximately counting the number of paths of length k in an n vertex graph. Our algorithm is based on the Karp-Luby approximate counting technique [8] applied to fixed parameter tractable problems, and the color-coding technique of Alon, Yuster and Zwick [1]. We also show some W-hardness results for parameterized exact counting problems.", "authors": ["Vikraman Arvind", "Venkatesh Raman"], "n_citation": 70, "references": ["0eafcdc6-0843-4eff-82a8-7774f3cd4736", "29e062a2-42bd-4466-8152-e72a53fa1ba4", "317b1b37-7d67-49f4-b549-03f4f8961f07", "767b7eb5-60a8-4905-bf23-2318557cae62", "afbb98b6-55d3-4bc8-8fa0-c89760819da6", "b9d22933-f130-48ae-8e37-278289013c1c", "c80e9ce4-9af2-48fd-9b87-07d4bfe97bcc", "d5dfe354-6058-405d-9cec-3cb7b441072b", "e4d0df0e-4513-405a-a8c6-a01ba3835a7d", "fde43cf4-b1b3-480b-8e40-ab25e85382ad"], "title": "Approximation Algorithms for Some Parameterized Counting Problems", "venue": "international symposium on algorithms and computation", "year": 2002, "id": "aa4acee1-574e-45c8-9eab-57d3514a7dfc"}
{"abstract": "Free and Open Source Software (FOSS) offers a transparent development environment and community in which to involve students. Students can learn much about software development and professionalism by contributing to an on-going project. However, the number of FOSS projects is very large and there is a wide range of size, complexity, domains, and communities, making selection of an ideal project for students difficult. This paper addresses the need for guidance when selecting a FOSS project for student involvement by presenting an approach for FOSS project selection based on clearly identified criteria. The approach is based on several years of experience involving students in FOSS projects.", "authors": ["Heidi J. C. Ellis", "Michelle Purcell", "Gregory W. Hislop"], "n_citation": 9, "references": ["029302c1-e136-4fc6-bf62-42df11d21a47", "19f615b8-278e-4dd2-afd3-e011140e97f7", "24d706ed-c55e-478f-84df-684ef5d9172d", "3dfa1b06-2aa1-47f1-8ac2-7b5ff38d5965", "49f8d6c1-915e-4e60-b9bd-d444c20e0ba6", "4b964c15-aede-49b6-a537-a73b90a6dc32", "4f7047e5-e823-4e8f-a3be-8c1fc1b71913", "67f3e2c8-6cc7-4f5f-bf56-112536b50c1a", "68d7221c-6c16-4949-8c19-1a0820f8dafa", "74afdfde-b521-4080-9388-6d165fcbf626", "adbbf35b-837b-48aa-814d-308bb34112ba", "e845de16-252f-451d-b3d1-d4fe3a0d1d28", "fc488fd5-6e2e-481e-811f-dee13adfa67f", "fd22db03-0a03-45c0-ba56-02f2b6e8fb65"], "title": "An approach for evaluating FOSS projects for student participation", "venue": "technical symposium on computer science education", "year": 2012, "id": "a99842cb-6294-4010-ab4c-0c143fc1f458"}
{"abstract": "The interpretation of instantaneous frequency has been a subject of interest for many years. One interpretation is that it is the average frequency at each time in the signal. We prove that instantaneous frequency equals the average frequency at each time only when there is symmetry in the instantaneous spectrum, as previous empirical evidence has suggested. Also, when there is such symmetry, the average frequency at each time equals the median frequency at each time.", "authors": ["Wonchul Nho", "Patrick J. Loughlin"], "n_citation": 73, "references": ["2d7d4713-8aeb-44b6-a309-af405289ee73"], "title": "When is instantaneous frequency the average frequency at each time", "venue": "IEEE Signal Processing Letters", "year": 1999, "id": "57ca7c4b-e056-468e-8b78-2aed0e92d85d"}
{"abstract": "The WS-Mediator framework employs an off-the-shelf mediator architecture and resilience-explicit computing in pursuit of dependable, dynamic Web services integration. Web services and service-oriented architectures (SOAs) represent a new paradigm for building distributed computing applications. Web services offer advantages over conventional distributed computing middleware platforms. Web services' loosely coupled architecture, combined with their standardized interoperability, lead to a new computing paradigm that supports the construction of more flexible and dynamic distributed applications", "authors": ["Yuhul Chen", "Alexander Romanovsky"], "n_citation": 50, "references": ["27d3d33d-9d5e-456d-a77d-d32a558a9924", "7d858c10-2f60-4a71-b51c-be58827083d8", "f363945e-cc25-49b6-848d-91d8a624323d"], "title": "Improving the Dependability of Web Services Integration", "venue": "It Professional", "year": 2008, "id": "cca68e1d-d6c4-4a7b-8e08-cab24e8ffe6c"}
{"abstract": "We present a novel approach to improving the security of passwords. In our approach, the legitimate user's typing patterns (e.g., durations of keystrokes, and latencies between keystrokes) are combined with the user's password to generate a  hardened password  that is convincingly more secure than conventional passwords against both online and offline attackers. In addition, our scheme automatically adapts to gradual changes in a user's typing patterns while maintaining the same hardened password across multiple logins, for use in file encryption or other applications requiring a longterm secret key. Using empirical data and a prototype implementation of our scheme, we give evidence that our approach is viable in practice, in terms of ease of use, improved security, and performance", "authors": ["Fabian Monrose", "Michael K. Reiter", "Susanne Wetzel"], "n_citation": 591, "references": ["07b28c34-57cb-4d8b-989e-e6d9b05e9895", "2a6b32c5-1b47-4da9-8eff-0bb3ee034643", "2d22ea79-c8cf-46d1-a6f0-582ccd7cdd63", "37bcc709-9224-46cd-b4cc-f9ac2b6b5107", "55f52eea-6390-47d9-ae51-bbd5220ebe58", "6b27840d-0f06-4de4-903e-f9cbe2ab3cc6", "85d69ae6-04d8-4dc6-a405-16806893171d", "8f5a422e-8509-441b-9548-556bc5bfde56", "98f543e3-d61c-4099-ae96-237816472592", "ab7e90ed-d23b-4e68-a1ac-7e4e865991d2", "b55a6c56-02de-4ebc-84e0-78b75dbb7c9b", "b68fc787-7817-421e-8e66-8a98ab9db1ad", "c1504695-1ba1-47ec-8cf3-b2aa4f484666", "d3329bd3-51c9-461d-b373-09d174ba9966", "e84c7452-3e18-4597-ae26-49d8ff7551bb", "fb981fc0-c085-4864-8fd8-8eed3435e97c", "ffb6d74d-773d-41e1-9f2f-3bc0c4c5a24f"], "title": "Password hardening based on keystroke dynamics", "venue": "computer and communications security", "year": 1999, "id": "688dbaf9-9990-484a-8ea9-8e80474d6a1b"}
{"abstract": "Abstract   The theory of stack filtering, which is a generalization of median filtering, is used in two different approaches to the detection of intensity edges in noisy images. The first approach is a generalization of median prefiltering: a stack filter or another median-type filter is used to smooth an image before a standard gradient estimator is applied. These prefiltering schemes retain the robustness of the median prefilter, but allow resolution of finer detail. The second approach, called the Difference of Estimates (DoE) approach, is a new formulation of a morphological scheme [Lee  et al., IEEE Trans. Robotics Automat .  RA-3,  Apr. 1987, 142-156, Maragos and Ziff,  IEEE Trans. Pattern Anal. Mach. Intell .  12 (5), May 1990.] which has proven to be very sensitive to impulsive noise. In this approach, stack filters are applied to a noisy image to obtain local estimates of the dilated and eroded versions of the noise-free image. Thresholding the difference between these two estimates yields the edge map. We find, for example, that this approach yields results comparable to those obtained with the Canny operator for images with additive Gaussian noise, but works much better when the noise is impulsive. In both approaches, the stack filters employed are trained to be optimal on images and noise that are \"typical\" examples of the target image. The robustness of stack filters leads to good performance for the target image, even when the statistics of the noise and/or image vary from those used in training. This is verified with extensive simulations.", "authors": ["Ji-Sang Yoo", "Charles A. Bouman", "Edward J. Delp", "Edward J. Coyle"], "n_citation": 50, "title": "The nonlinear prefiltering and difference of estimates approaches to edge detection: applications of stack filters", "venue": "Graphical Models \\/graphical Models and Image Processing \\/computer Vision, Graphics, and Image Processing", "year": 1993, "id": "7a2cbb98-5a2d-4238-876b-14cb347fa3a3"}
{"abstract": "Testing denotes a set of activities that aim at discovering discrepancies between actual and intended behaviors of a system. Often, the intended behavior is known only implicitly, which renders the process of testing unstructured, unmotivated in its details, and barely reproducible. The use of explicit and executable models to describe the intended behavior promises to solve these problems. We use an industrial case study|a smart card application|to present a method for automatically generating test cases from such explicit models. The test cases are used both to validate the model and verify the actual card.", "authors": ["Jan Philipps", "Alexander Pretschner", "Oscar Slotosch", "Ernst Aiglstorfer", "Stefan Kriebel", "Kai Scholl"], "n_citation": 57, "references": ["029ec76f-4b8c-476a-8c77-3036d6b7b1f6", "3d47d8fd-6237-436a-b403-1b02a5c7aa5e", "3da02d67-05a7-4df5-99a2-50186cd29fa9", "3f1b4f3a-0707-4b35-94ff-b1b8cb30eca2", "9f87fbe7-00ca-48f3-89a7-4766f045edac", "c5ec1c87-2aa7-4178-a048-53a43de44145", "d0938309-5648-4b16-acf0-d66d4b313cde", "e726de71-edfe-4ba7-b191-6fd75beefa3a", "fb61b7b1-9a4d-4aa6-b16f-7b2bea74a7f3", "fcfaa33f-1187-44ba-a806-34b1e2c5b963", "fecadbfe-1bff-439a-8ed6-aa7fbcc59984"], "title": "Model-Based Test Case Generation for Smart Cards1", "venue": "Electronic Notes in Theoretical Computer Science", "year": 2003, "id": "ea7fe015-de3e-4730-8d7d-f99d3e577134"}
{"abstract": "We develop a new model-based extraction process guided by biomechanical analysis for walking people, and analyse its data for recognition capability. Hierarchies of shape and motion yield relatively modest computational demands, while anatomical data is used to generate shape models consistent with normal human body proportions. Mean gait data is used to create prototype gait motion models, which are adapted to fit individual subjects. Our approach is evaluated on a large gait database, comprising 4824 sequences from 115 subjects, demonstrating gait extraction and description capability in laboratory and real-world capture conditions. Recognition capability is illustrated by an 84% CCR in laboratory conditions, which is reduced for real-world (outdoor) data. Preliminary results from a statistical analysis of the extracted gait parameters, suggest that recognition capability is primarily gained from cadence and from static shape parameters, although gait is the cue by which these are derived.", "authors": ["David Kenneth Wagg", "Mark S. Nixon"], "n_citation": 234, "references": ["2bdf4d4c-baf1-4695-9d86-d4b0ba17f93c", "51089d3a-d015-4b84-955e-e5681ffb5fed", "6cf0caf0-1545-41dc-b890-d1c8928661bf", "7276750a-42f3-4baf-9aa3-86daad3e70f4", "8553f82e-487e-4d57-be72-4da7b5c44dfb", "9e4ce720-a6e2-4d63-b768-559b69adf32f", "a64f715b-97a1-4a78-ad48-e143b4618741", "a7070a6d-e3cd-4c70-8698-31d60ec9092c", "b409eeed-0367-45bb-a499-5a8c3e214613", "b5a01de8-3365-4d61-94e8-99aa3235aefa", "b8b45ca3-1a80-47f5-a045-eafbd6d9cdad", "bc922ab9-ad34-4e92-8e3f-832f442fb5e6", "c21c324a-e578-4231-afbb-49fa0fed0203", "c77024c2-955a-44be-a2ef-471f0ce30a83", "e9c2568f-8277-4938-886a-b229968484c3"], "title": "On automated model-based extraction and analysis of gait", "venue": "ieee international conference on automatic face and gesture recognition", "year": 2004, "id": "c524d80b-2e58-4bd5-87cf-6d58c0a1ae04"}
{"abstract": "Abstract   Skewed symmetry is the type of pattern that emerges when viewing a mirror symmetric, planar shape obliquely. This paper discusses the orthographic case, but also briefly comments on perspective skewing. Orthographically skewed symmetry is characterized by two features which are also present in perfect mirror symmetry and that are preserved under the skewing, i.e., that are invariant under affine transformations. These are parallelism of the chords, the lines joining corresponding points on each side of the symmetric shape are parallel; and collinearity of the midpoints, the points lying in the middle of each of the corresponding point pairs are collinear so that they form a straight symmetry axis. These two constraints (the parallelism constraint and the collinearity constraint) are taken as point of departure and it is shown how they relate to a set of invariants, which skew mirrored point pairs or contour segments should satisfy if they are to make up corresponding point pairs of a skewed symmetry. Although a method based on such invariants is presented, the major outcome is that the previous constraint pair is equivalent to another one, which does not require a priori knowledge of point correspondence.", "authors": ["Luc J. Van Gool", "Theo Moons", "Dorin Ungureanu", "Andr\u00e9 Oosterlinck"], "n_citation": 54, "title": "The characterization and detection of skewed symmetry", "venue": "Computer Vision and Image Understanding", "year": 1995, "id": "f11ced8b-afea-4c0f-8834-390a28d014aa"}
{"abstract": "Smartphones are nowadays used to store and process many kinds of privacy-sensitive data such as contacts, photos, and e-mails. Sensors provide access to the phone's physical location, and can record audio and video. While this is convenient for many applications, it also makes smartphones a worthwhile target for attackers providing malicious applications. Current approaches to runtime enforcement try to mitigate unauthorized leaks of confidential data. However, they are often capable of enforcing only a very limited set of policies, like preventing data leaks only within single components or monitoring access only to specific sensitive system resources. In this work, we present Droid Force, an approach for enforcing complex, data-centric, system-wide policies on Android applications. Droid Force allows users to specify fine-grained constraints on how and when which data may be processed on their phones, regardless of whether the malicious behavior is distributed over different colluding components or even applications. Policies can be dynamically exchanged at runtime and no modifications to the operating system nor root access to the phone are required. Droid Force works purely on the application level. It provides a centralized policy decision point as a dedicated Android application and it instruments a decentralized policy enforcement point into every target application. Analyzing and instrumenting an application takes in total less than a minute and secured applications exhibit no noticeable slowdown in practice.", "authors": ["Siegfried Rasthofer", "Steven Arzt", "Enrico Lovat", "Eric Bodden"], "n_citation": 60, "references": ["00f4c1d6-7224-4c69-8bf7-08f1478594dc", "0f784273-a511-4e73-b7db-c2f542805d4c", "2f96468d-190c-4d80-92f6-c64eeea9040a", "3aa016c2-372a-4afd-9870-1c05bb6fcb55", "42d98f3e-68d9-464a-9296-9ad8fa2e0d27", "45e3f2ca-cedc-404e-bebd-37870319b538", "47b04fc1-5f76-4454-b744-db2709840a5f", "55aff4dc-b94a-47da-8fa2-74274f12c75d", "60f32cb8-b61a-464b-a20a-b98f14e20aab", "63a766ae-a993-4fc0-86ce-4d4d08b4e734", "6c35a1d8-2433-4538-a910-e46bbb04eed3", "89656952-a4d4-480b-8862-0076c2fdc98a", "8e8918df-1513-4dd5-bd08-db75ebc3489b", "ab1be39f-85f5-45f3-a2d8-9be182f95e6a", "ba4866fa-6e65-424c-93dc-4d0834396b10", "d226eb31-3043-449c-927f-81a41c252b73", "de4c2acb-1a93-42d7-9aac-fe237e480627", "ed736576-1c48-4474-b716-fad258521f69"], "title": "DroidForce: Enforcing Complex, Data-centric, System-wide Policies in Android", "venue": "", "year": 2014, "id": "9c79dd78-4bf6-4bf2-aea8-5f60a91cb4ec"}
{"abstract": "An organization faces many challenging decisions when transitioning to product line development: What is the best way to adopt a product line approach? How can we avoid disrupting regular product development? Once adopted, how should we evolve the product line? The article discusses how to optimize a product line's economic benefits by considering the adoption context and using product line scoping techniques.", "authors": ["Klaus Schmid", "Martin Verlage"], "n_citation": 180, "references": ["1d48df53-cdda-4c06-a276-a5a8bbce1a93", "30856e48-ab29-4cd8-b03a-eb546e34f474", "7a05c67c-1534-41f3-993a-0e799b9dd291", "ece05e38-e5b9-46ee-ad44-64a10481c444", "f62f7fec-60eb-408b-8b00-690d8cd0df01"], "title": "The economic impact of product line adoption and evolution", "venue": "IEEE Software", "year": 2002, "id": "cfc50ad3-eb34-4e2c-abdf-eaae072153ad"}
{"abstract": "Mutual information is a good indicator of relevance between variables, and have been used as a measure in several feature selection algorithms. However, calculating the mutual information is difficult, and the performance of a feature selection algorithm depends on the accuracy of the mutual information. In this paper, we propose a new method of calculating mutual information between input and class variables based on the Parzen window, and we apply this to a feature selection algorithm for classification problems.", "authors": ["Nojun Kwak", "Chong-Ho Choi"], "n_citation": 544, "references": ["2430d105-9797-43da-ae3f-85eb05580219", "3d11baad-0e0f-4837-af8a-527a3ecb6840", "81501a41-02ee-4d59-a404-9fbf09e65877", "ae79f154-9bc5-46c5-84cf-4647ae102f28", "b2b59d97-bafb-4632-8997-f87030a49c69", "b4d3f5d2-83f9-4240-adcd-3a985b53bf48", "be3e5be3-7644-400f-9f3b-216255fea3cb", "dc886b64-9f42-46da-b4a2-66f2dbb2d844"], "title": "Input feature selection by mutual information based on Parzen window", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2002, "id": "81c7f6c5-8b63-42f0-af04-da18fa49a0de"}
{"abstract": "Writing unit test code is labor-intensive, hence it is often not done as an integral part of programming. However, unit testing is a practical approach to increasing the correctness and quality of software; for example, the Extreme Programming approach relies on frequent unit testing.In this paper we present a new approach that makes writing unit tests easier. It uses a formal specification language's runtime assertion checker to decide whether methods are working correctly, thus automating the writing of unit test oracles. These oracles can be easily combined with hand-written test data. Instead of writing testing code, the programmer writes formal specifications (e.g., pre- and postconditions). This makes the programmer's task easier, because specifications are more concise and abstract than the equivalent test code, and hence more readable and maintainable. Furthermore, by using specifications in testing, specification errors are quickly discovered, so the specifications are more likely to provide useful documentation and inputs to other tools. We have implemented this idea using the Java Modeling Language (JML) and the JUnit testing framework, but the approach could be easily implemented with other combinations of formal specification languages and unit test tools.", "authors": ["Yoonsik Cheon", "Gary T. Leavens"], "n_citation": 355, "references": ["07b16fb2-2659-40e2-8ec2-51b0c4f92da3", "0d995f1f-d3ea-4c1b-b0cc-3fa301ec010e", "0e648979-16b3-45bd-a96f-ebcefa9511ed", "29679f73-c20b-4453-be97-a16bf3f00d3c", "2a7fd527-d2e4-41c6-a16f-311ed89282cf", "2b47a5ec-fd51-4b53-bd29-f6fc5e44da8a", "32d5ee80-64a3-4a02-844e-a0095607a482", "3b7aab51-6441-46bc-9842-f0aa5ed16352", "3d15988d-d90d-4c7e-ae81-2ca459554aed", "42650f77-43c1-433b-95cc-116cdbe2e4dc", "43d4e543-796a-4e70-93e9-b99b4916ef2a", "4d6e1bd8-932c-4605-9b44-1cde1d406559", "52a2bed2-8631-4948-90d6-934e7c7f3103", "64ec1e30-79b8-44ec-be3d-4d6e60893a2d", "73700952-2347-48f8-b728-d9e4faf727d5", "7ff26de3-fad3-4adc-a480-375f565e2e9d", "91ab327c-9299-49d0-94cc-57247851c2c3", "949266eb-25fc-4c13-b71d-1a0a6523ecd9", "9b6d5c1e-9304-4657-adc9-07f0732d04e0", "a17269d9-c8f6-4a8b-aaca-3a5d28f58532", "ab87c3ea-2a25-4f6e-a043-0bbc0852267f", "ac3d5cbf-62a9-474a-83da-708c9af951ef", "ccd000e4-cd34-4170-a51a-36be6f6b3814", "ce426213-60a4-44e1-8bab-9f2a5e412816", "cf2b5da2-f2e0-4803-b772-e51ac576e7b4", "db95dfa1-c93c-43b3-808d-bb9e528a6dee", "edf18626-b3c9-4fdc-b7d9-e92945ddc27c", "f1ae8452-2a6b-4b2f-852c-e03a24cbfcea", "fb531518-ae7a-4d2d-ac04-a848cd588692", "fd3c0d46-0bfd-4635-bf91-21eb295a9fb2"], "title": "A Simple and Practical Approach to Unit Testing: The JML and JUnit Way", "venue": "european conference on object oriented programming", "year": 2002, "id": "3d400399-dbe9-4fb5-98b4-68d8a0ba7932"}
{"abstract": "This paper describes a comparative study of texture features, with particular emphasis on the applicability to unsupervised image segmentation. A benchmark test is introduced in which a set of 20 simple bipartite images, combining different stochastic textures separated by a stochastic boundary, is used for feature extraction and segmentation. The accuracy of the segmentation result, expressed in the mean boundary error, is used as an evaluation criterion. From the seven feature extraction methods tested, the Haralick, Laws and Unser methods gave best overall results. Results obtained also show that direct feature statistics such as the Bhattacharyya distance are not appropriate evaluation criteria if texture features are used for image segmentation. A small experiment on visual boundary tracking revealed that boundary error obtained here are similar to those obtained by machine segmentation.", "authors": ["J. M. H. du Buf", "M. Kardan", "M. Spann"], "n_citation": 175, "references": ["0ccb131b-88a3-45f1-bfc5-34a77ffeea3e", "3c4e8d07-47e2-4942-8197-59b613634ce4", "48c4df8b-249a-4ca2-bf93-4df44200b7a6", "536bae3c-3a30-4855-ac10-411930bd11ad", "5ebc8117-0e62-4b17-8dd6-abf0248d07a9", "61960382-eb74-4fbf-81c8-cc22ffcecc19", "69b6d290-efca-43dc-85b2-5b11f86c7ab7", "9205abb2-a53a-4d16-b3d5-ebb3c6a6640b", "988e51d5-75de-4102-8659-b2d9a87db947", "9cef868f-eb6d-4189-acd1-43eac87cf81e"], "title": "Texture feature performance for image segmentation", "venue": "Pattern Recognition", "year": 1990, "id": "66ef956f-ea06-4527-8cb1-a71a9e00f9b5"}
{"abstract": "Peer-to-peer systems and applications are distributed systems without any centralized control. The core operation in most peer-to-peer systems is efficient location of data items. The current well-known peer-to-peer systems like Napster and Gnutella have scalability problem in location of data items. To solve the scalability problem, some scalable peer-to-peer lookup services show up, such as CAN, Chord, Pastry and Tapestry. In this paper we propose a self organizing hierarchical virtual network infrastructure, called Grapes, for peer-to-peer lookup services. Hierarchical approach of Grapes brings two benefits. First, a node can find data in its subnetwork with the high probability due to the data replication in its subnetwork. Second, the hierarchical structure makes lookup hops shorter than those of the flat one.", "authors": ["Kwangwook Shin", "Seunghak Lee", "Geun-Hwi Lim", "Hyunsoo Yoon", "Joong Soo Ma"], "n_citation": 52, "references": ["09765842-b246-49fb-91b9-f6d494d10468", "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4", "d06f8723-1b89-4684-99c9-c1045ddfb85c", "e1263ada-afda-498c-a37d-9b545293118a", "f14df1ed-e3e9-4348-9040-fc06e3411b95"], "title": "Grapes: topology-based hierarchical virtual network for peer-to-peer lookup services", "venue": "international conference on parallel processing", "year": 2002, "id": "eb2ceaa0-d717-43c9-a5fa-e10ebd3fb503"}
{"abstract": "This paper explores a novel interface to a system administration task. Instead of creating an interface  de novo  for the task, the author modified a popular computer game, Doom, to perform useful work. The game was chosen for its appeal to the target audience of system administrators. The implementation described is not a mature application, but it illustrates important points about user interfaces and our relationship with computers. The applications relies on a computer game vernacular rather than the simulations of physical reality found in typical navigable virtual environments. Using a computer game vocabulary may broaden an application's audience by providing sn intuitive environment for children and non-technical users. In addition, the application highlights the adversarial relationships that exist in a computer and suggests a new resource allocation scheme.", "authors": ["Dennis L. Chao"], "n_citation": 118, "references": ["123c0f7a-4341-4a95-bb80-824a969eda20", "934a1d9a-2204-4a17-b2c6-1ce279e29629", "ddd9e1f7-9721-40cf-8b5c-1d8fe3c351cd", "f31e08c4-32c3-4e61-8893-ac6c2ac2c951"], "title": "Doom as an interface for process management", "venue": "human factors in computing systems", "year": 2001, "id": "88c6c75b-75f5-47ad-ab18-83ad21fc0777"}
{"abstract": "In this paper, we propose a high-performance and memory-efficient pipeline architecture which performs the one-level two-dimensional (2-D) discrete wavelet transform (DWT) in the 5/3 and 9/7 filters. In general, the internal memory size of 2-D architecture highly depends on the pipeline registers of one-dimensional (1-D) DWT. Based on the lifting-based DWT algorithm, the primitive data path is modified and an efficient pipeline architecture is derived to shorten the data path. Accordingly, under the same arithmetic resources, the 1-D DWT pipeline architecture can operate at a higher processing speed (up to 200 MHz in 0.25-/spl mu/m technology) than other pipelined architectures with direct implementation. The proposed 2-D DWT architecture is composed of two 1-D processors (column and row processors). Based on the modified algorithm, the row processor can partially execute each row-wise transform with only two column-processed data. Thus, the pipeline registers of 1-D architecture do not fully turn into the internal memory of 2-D DWT. For an N/spl times/M image, only 3.5N internal memory is required for the 5/3 filter, and 5.5N is required for the 9/7 filter to perform the one-level 2-D DWT decomposition with the critical path of one multiplier delay (i.e., N and M indicate the height and width of an image). The pipeline data path is regular and practicable. Finally, the proposed architecture implements the 5/3 and 9/7 filters by cascading the three key components.", "authors": ["Bing-Fei Wu", "Chung-Fu Lin"], "n_citation": 69, "references": ["0fa45bed-ed87-4501-b9be-fb568c61235c", "1551433c-f1db-4e83-9021-4537cd476453", "1f372c87-859a-4d9c-9a33-948887367932", "2b49f372-d437-401c-8c4a-1c38655b38c4", "436878c4-9ea0-4d9c-be2a-639ee2de4839", "4e89442f-3503-483d-888f-769d4bfbac6d", "4eec245a-826a-4fdf-8f9c-1f2d687c3e24", "54c02492-a327-4b48-8f1f-4b5b84315704", "62209ce2-fc6d-456e-82d0-fcc023d84621", "7014140b-5481-458e-a280-6b72ea7d02a5", "76d57dd2-eb07-436c-8301-57306d57820f", "8168bd68-d26d-4007-9a86-5ed2319ea0ea", "828387d9-270b-476e-8006-6df50121cc04", "8f0ef49e-b17e-4c7c-a837-ce2bbcb06981", "c97a2d11-54ef-42c0-95af-6bdb57c39119", "cd09ef4f-edd4-4134-8b93-9535d190e329", "e1a6e9b1-72c0-490b-add8-1b4a0480ebf3"], "title": "A high-performance and memory-efficient pipeline architecture for the 5/3 and 9/7 discrete wavelet transform of JPEG2000 codec", "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "year": 2005, "id": "73b5356d-ba20-452e-8d32-8d4c93902764"}
{"abstract": "Consider a set of   $N$   agents seeking to solve distributively the minimization problem    $\\inf_{x}\\sum_{n=1}^{N}f_{n}(x)$   where the convex functions    $f_{n}$   are local to the agents. The popular Alternating Direction Method of Multipliers has the potential to handle distributed optimization problems of this kind. We provide a general reformulation of the problem and obtain a class of distributed algorithms which encompass various network architectures. The rate of convergence of our method is considered. It is assumed that the infimum of the problem is reached at a point    $x_{\\star}$  , the functions    $f_{n}$   are twice differentiable at this point and    $\\sum\\nabla^{2}f_{n}(x_{\\star}) >0$   in the positive definite ordering of symmetric matrices. With these assumptions, it is shown that the convergence to the consensus    $x_{\\star}$   is linear and the exact rate is provided. Application examples where this rate can be optimized with respect to the ADMM free parameter    $\\rho$   are also given.", "authors": ["Franck Iutzeler", "Pascal Bianchi", "Philippe Ciblat", "Walid Hachem"], "n_citation": 50, "references": ["1e290e39-afb5-453e-9eaa-727768550623", "21b7e952-d559-4fb8-8e0e-f9ae7dda156e", "2521804a-a15e-4d98-b8bb-2987ae1fb626", "2bcc2730-1b2e-4d43-ad5e-594081dcef4b", "2ca8a212-1179-4f68-bc20-8f2d8848585a", "34953a53-e320-49d0-b3bc-819de1124699", "3da8b237-f45e-4c6c-9760-9fff49ce6fc2", "48f47fcc-1887-4d89-96e7-df1d73af68d9", "4a78d773-7703-4de6-9881-2bcef9e336ea", "5ab1529e-c6f9-4fa9-a461-9294e5639748", "5dd23ae9-9bb2-440b-8d95-d17d30292815", "5e379cd2-5fad-4cab-9a16-cb3757d20edf", "7a7b52f0-82db-4e16-9df0-d3f5b5c7b5c5", "8b1da533-6c6a-4f4c-aa1a-aa4369a94654", "8fa19349-60f5-48dc-a87f-777bbb7e34b4", "944811fb-3615-4505-9848-2c9832612f1a", "a394e019-8378-4364-b760-7d9b27fe40e9", "b8321e4f-ccae-433a-984e-7567535ff293", "be62075a-9bbe-4b4a-b876-281cb5594880", "c213d148-4028-45df-9934-cf2f6f9f3fab", "cbc19168-c44b-4a2c-bb10-7ebe3dce97c9", "ce7b6a10-6f34-45cf-af41-a0b84aed62c9", "d340974e-775f-48f4-a83d-754e7d5b35db", "e0280877-486b-4c83-b7cb-fa67d7270c1f", "e537d143-155e-4ca0-8ae8-66b777a77fea", "fbad35e7-1df9-489e-9121-ca730f442909", "fe252ade-99f7-46c9-80b2-0fcdf2fe112a"], "title": "Explicit Convergence Rate of a Distributed Alternating Direction Method of Multipliers", "venue": "IEEE Transactions on Automatic Control", "year": 2016, "id": "72841fb4-2df5-43ba-b7d2-f2293f70b43a"}
{"abstract": "The problem of efficient data structures for IP lookups has been well studied in the literature. Techniques such as LC tries and extensible hashing are commonly used. In this paper, we address the problem of generalizing LC tries, based on traces of past lookups, to provide performance guarantees for memory suboptimal structures. As a specific example, if a memory-optimal (LC) trie takes 6 MB and the total memory at the router is 8 MB, how should the trie be modified to make best use of the 2 MB of excess memory? We present a greedy algorithm for this problem and prove that, if for the optimal data structure there are  b  fewer memory accesses on average for each lookup compared with the original trie, the solution produced by the greedy algorithm will have at least 9 \u00d7  b /11 fewer memory accesses on average (compared to the original trie). An efficient implementation of this algorithm presents significant additional challenges. We describe an implementation with a time complexity of  O (\u03be( d ) n log  n ) and a space complexity of  O ( n ), where  n  is the number of nodes of the trie and  d  its depth. The depth of a trie is fixed for a given version of the Internet protocol and is typically  O (log  n ). In this case, \u03be( d ) e  O (log 2   n ). We also demonstrate experimentally the performance and scalability of the algorithm on actual routing data.", "authors": ["Ioannis Ioannidis", "Ananth Grama", "Mikhail J. Atallah"], "n_citation": 50, "references": ["35bf84dd-82f4-4a45-a114-bfe8c635c2c4", "3637239e-cef8-4be4-a62c-d25400343cf9", "51f41289-2e32-4cf8-92f7-dbd6343918f0", "54dda14f-01d4-411e-97fa-5d27389e566c", "56fad217-58da-4f8a-8898-dc293ebc2002", "9457f127-08c2-4aac-abfc-d47146abf035", "97948059-a0d5-475d-9647-832f07c105a8", "a78162dd-7ced-4c1a-a72c-abdb76d97675", "ae1235cf-d8a1-4a9f-876f-b7f31b6e5b22", "ae941637-b658-4a15-be8d-f32109e5f510", "b644af56-2e6c-42e7-9830-3b59e2cc5036", "cb9ecaa2-69e2-4fd6-8884-27c83c150760", "e401b22f-f2eb-483a-ad16-3b36bba814a4", "e7d9c6a5-e87f-4899-b884-157c91fc60c0", "e80c59fb-2f00-48b1-845a-a46e18afca99", "ef8d1d29-6395-47a0-a1b4-91169df0741e"], "title": "Adaptive data structures for IP lookups", "venue": "ACM Journal of Experimental Algorithms", "year": 2005, "id": "912502b6-1978-4963-9a7d-68428ad115fb"}
{"authors": ["Moreno Falaschi", "Giorgio Levi", "Maurizio Martelli", "Catuscia Palamidessi"], "n_citation": 91, "title": "A New Declarative Semantics for Logic Languages", "venue": "", "year": 1988, "id": "13b51346-7194-4bb0-a5de-104c46de4c51"}
{"abstract": "Software processes comprise many steps; coding is followed by building, integration testing, system testing, deployment, operations, among others. Software process integration and automation have been areas of key concern in software engineering, ever since the pioneering work of Osterweil; market pressures for Agility, and open, decentralized, software development have provided additional pressures for progress in this area. But do these innovations actually help projects? Given the numerous confounding factors that can influence project performance, it can be a challenge to discern the effects of process integration and automation. Software project ecosystems such as GitHub provide a new opportunity in this regard: one can readily find large numbers of projects in various stages of process integration and automation, and gather data on various influencing factors as well as productivity and quality outcomes. In this paper we use large, historical data on process metrics and outcomes in GitHub projects to discern the effects of one specific innovation in process automation: continuous integration. Our main finding is that continuous integration improves the productivity of project teams, who can integrate more outside contributions, without an observable diminishment in code quality.", "authors": ["Bogdan Vasilescu", "Yue Yu", "Huaimin Wang", "Premkumar T. Devanbu", "Vladimir Filkov"], "n_citation": 70, "references": ["003136a2-6a65-40dd-a037-83b6538a6f8c", "0243f4c3-a3f3-4403-8afe-dc404c128beb", "0457247b-8ea3-4926-ad2c-2aefd58dea4e", "0661538a-1b42-4908-b9d1-99e93dd151f1", "10752912-29ce-411f-9c0e-f4ec740c3e6b", "1142cd18-6b20-4bd7-b156-83545133c8de", "1ef6ec6f-cbbb-4126-9530-422c879095a6", "211bc579-f4d3-4ae8-8e38-654f28e3b004", "27ebe384-2797-450c-89ca-9e0ff14a8ff8", "2a3803a8-410d-405d-90a9-dc4c6802ab39", "2c037879-e659-4d7e-94f5-20d12d376905", "31c37ef2-4e9f-4409-a4e2-90e765cafe64", "3777bbf3-1d71-47a5-b2fc-9ce09a9a889a", "37f52436-0c3a-4ead-aca2-a365b88ada4a", "44df7ff7-f92b-450e-a252-2a071c002ab7", "4e232861-adeb-4f86-a5d5-afe51189abd2", "5f24f1d0-d2c4-4440-89f0-bda5ce91f59f", "64ff9292-b671-475e-8351-44a08dc21f92", "718953b8-3f84-4675-acc6-efff39fa1fde", "71deb4fc-ca5d-42b4-bbf3-3bbcf10de196", "8577d758-88d3-468b-a532-00b03c8488f0", "913092bd-6dc4-4fa1-bd57-3d9cfdf3efbb", "9e5b7f40-7774-4ab7-99c1-874b085223a8", "a21a46dd-85e1-42ab-9e4a-5398eaee92cb", "a4c12cb7-ebe7-4fc6-bcb0-bf4206fcd984", "aeab89f5-7e72-4e55-b138-0ae6bf3fe338", "b2f9d2d3-a685-4ee7-90dc-d9a0b8b46cfb", "b8774530-26af-495e-b0d9-168bedf38a1f", "c506f723-bdb5-4247-a36a-e544e65dae42", "d8d0ae7e-4a7c-4666-8834-1f1c915cd576", "e787484e-239c-4231-b063-7e1619f72a83", "edc4d1f5-a838-4525-b227-81fbed9e4c62", "ee8cbdb2-de16-40b8-8493-8bf1ddf53ce6", "f2792009-12bb-474f-a1e4-7b0734d255a4", "f4261029-1b8b-4b64-828e-fde3b3b739b6"], "title": "Quality and productivity outcomes relating to continuous integration in GitHub", "venue": "foundations of software engineering", "year": 2015, "id": "960d2696-7c08-436e-b764-656d48d70c5b"}
{"abstract": "We present a new, pivot based data structure with dynamic capabilities to insert/delete both database elements and pivots. This feature is useful for applications where the database is not stationary, and the pivots must be changed from time to time. The spaghettis data structure can be thought of as a \"flat\" representation of a tree; but unlike it, a full representation of the distances can be used, instead of discretizing them.", "authors": ["Edgar Ch\u00e1vez", "Jose L. Marroquin", "Ricardo A. Baeza-Yates"], "n_citation": 93, "references": ["07c804bf-b60d-4b5d-b004-8f4652e7d81b", "105edb54-d48b-4470-a4dc-528270ee4c4a", "3286745d-7221-4601-befc-7e121fc09349", "3c281c4e-8302-4c37-96d7-1e615167c5f5", "70ef7109-0b98-42dc-9bc8-6c60c446b0dd", "8244d53e-daa4-418d-aaa8-b0aef6a64308", "8ed9afc1-6e6c-4b4a-b970-7cefe0f1b4d0", "938d4320-d40b-4c63-a899-d7a03df35964"], "title": "Spaghettis: an array based algorithm for similarity queries in metric spaces", "venue": "string processing and information retrieval", "year": 1999, "id": "0b179fe0-d523-4d71-b4da-9e873331cd7f"}
{"authors": ["John A. Hughes", "Valerie King", "Tom Rodden", "Hans H.K. Andersen"], "n_citation": 236, "references": ["3fb68aec-e588-4f39-b36f-247d778ec82d", "469da27e-37f9-48b7-bcf4-c1dd150df938", "c23d9b8a-2537-4d63-a928-247c7e7f621a", "c49ea9f3-b8e3-41c3-84a4-3631a218382e", "e927699f-c24e-49fa-9cff-db1e77776285"], "title": "The role of ethnography in interactive systems design", "venue": "Interactions", "year": 1995, "id": "ee141bd9-8f60-4d4f-861c-dfc0c3d4f708"}
{"abstract": "A tutorial introduction to the complex structured singular value (\u201e) is presented, with an emphasis on the mathematical aspects of \u201e. The \u201e-based methods discussed here have been useful for analyzing the performance and robustness properties of linear feedback systems. Several tests for robust stability and performance with computable bounds for transfer functions and their state-space realizations are compared, and a simple synthesis problem is studied. Uncertain systems are represented using Linear Fractional Transformations (LFTs) which naturally unify the frequency-domain and state-space methods. Subtitle: A tutorial introduction to the complex structured singular value (\u201e) is presented, with an emphasis on computable bounds and robust stability and performance tests for transfer functions and their state-space realizations.", "authors": ["Andrew Packard", "John C. Doyle"], "n_citation": 1553, "references": ["05f2a0d3-0ab0-45ad-abf0-1da52f750835", "250e37f2-f924-4480-af69-ea7550743603", "dc1033fc-ede5-462e-95dc-8b0cdba2e6df"], "title": "The complex structured singular value", "venue": "Automatica", "year": 1993, "id": "19c7669e-a01a-46e0-900a-90395015e438"}
{"abstract": "The Ramsey number of a graph G is the least number t for which it is true that whenever the edges of the complete graph on t vertices are colored in an arbitrary fashion using two colors, say red and blue, then it is always the case that either the red subgraph contains G or the blue subgraph contains G. A conjecture of P. Erdos and S. Burr is settled in the affirmative by proving that for each d \u2265 1, there exists a constant c so that if G is any graph on n vertices with maximum degree d, then the Ramsey number of G is at most cn.", "authors": ["C. Chvat\u00e1l", "Vojtech R\u00f6dl", "Endre Szemer\u00e9di", "William T. Trotter"], "n_citation": 160, "references": [], "title": "The Ramsey Number of a Graph with Bounded Maximum Degree", "venue": "Journal of Combinatorial Theory", "year": 1983, "id": "d96b22d1-105e-4bcb-b7bb-4ebe05478234"}
{"abstract": "In the past couple of years interest in decompilation has widened from its initial concentration on reconstruction of control flow into well-founded-in-theory methods to reconstruct type information. A. Mycroft (1999) described Type-Based Decompilation and S. Katsumata and A. Ohori (2001) described Proof-Directed Decompilation. The article summarises the two approaches and identifies their commonality, strengths and weaknesses; it concludes by suggesting how they may be integrated.", "authors": ["Alan Mycroft", "Atsushi Ohori", "Shin-ya Katsumata"], "n_citation": 50, "references": ["2448f6ce-230a-495c-8cab-21a8bf2865eb", "44c12a3d-8438-4f83-9eaf-56e82622b635", "4b162c17-1f27-4c98-9f83-cfacf9a63f7f", "b2add0b2-ac68-4785-bc87-8d8d40bba6b4", "c47553c2-a60b-4426-8581-b65b87478353", "e0a94f31-c2d9-4a7d-a5db-70f59356c289"], "title": "Comparing type-based and proof-directed decompilation", "venue": "working conference on reverse engineering", "year": 2001, "id": "33980c0e-bfc5-47e9-b4be-3d1cc8684896"}
{"abstract": "Note onset detection and localization is useful in a number of analysis and indexing techniques for musical signals. The usual way to detect onsets is to look for \"transient\" regions in the signal, a notion that leads to many definitions: a sudden burst of energy, a change in the short-time spectrum of the signal or in the statistical properties, etc. The goal of this paper is to review, categorize, and compare some of the most commonly used techniques for onset detection, and to present possible enhancements. We discuss methods based on the use of explicitly predefined signal features: the signal's amplitude envelope, spectral magnitudes and phases, time-frequency representations; and methods based on probabilistic signal models: model-based change point detection, surprise signals, etc. Using a choice of test cases, we provide some guidelines for choosing the appropriate method for a given application.", "authors": ["Juan Pablo Bello", "Laurent Daudet", "Samer A. Abdallah", "Chris Duxbury", "Mike E. Davies", "Mark B. Sandler"], "n_citation": 891, "references": ["0fe42d07-30d7-46f6-acae-f7d0f778a126", "180bbc64-4873-4b31-a364-438f5c8cb50e", "1f18d22a-782a-4d52-9d51-da2c73ee5339", "36a85b76-9589-4034-8b90-402b24239a28", "40dcf72d-56e9-4991-8856-4b83ab8f7392", "492220b1-7fa7-41a0-a87a-04456aa97fd2", "51e6f34d-4f1d-4386-87d8-855b30247937", "60dc7a75-4cbc-4a94-be0c-b11173a146a7", "6dd03562-995d-4dc5-9dda-4085e71cd7f5", "7f07a066-184e-4f44-9361-6587d7a3b911", "91ad48f2-2de6-4ce8-96ad-feb74f82bf0e", "a2f736e2-937a-4654-9e6a-033688a6b8fe", "e1d76a94-0d7c-431f-a4d1-d20b351b92c5", "e6d75cd5-f580-4225-a323-ecfba2ee2753", "f279b2db-1754-4b5d-af4c-e36b4ddf1033"], "title": "A tutorial on onset detection in music signals", "venue": "IEEE Transactions on Speech and Audio Processing", "year": 2005, "id": "953b9a06-5702-4e11-9a60-04d89373b0f3"}
{"authors": ["Tomi Kinnunen", "Evgeny Karpov", "Pasi Fr\u00e4nti"], "n_citation": 20, "references": ["0e7117bc-a0a4-473c-87c3-3b97741b5891", "1058279b-3ded-4e23-9236-6439baa97210", "1d2f2dea-cdfd-4074-9c01-3fbc383b54d5", "24e32b3d-efb7-4acf-bcd0-c0f76a641df6", "42a298b5-7a7c-470e-a2df-17776909dc85", "5773a93c-37cf-4b7e-952b-fa034d7a25c9", "6eb271eb-7939-43c2-84c7-cc1208761a99", "bc0ed01a-c589-4dd7-9105-ca6baec71e9b", "be3978a9-1bb7-4d0e-b414-c0dd3ca78d66", "cb46e014-e7f6-41ac-8fba-7ac93db08a11", "ce30f337-3881-42ca-beb3-ed57a4d5d21d", "dfc34e58-a065-47d5-a6f3-530d129b6c70", "e1217e8f-fa23-4284-997d-98781f967370"], "title": "Efficient online cohort selection method for speaker verification.", "venue": "conference of the international speech communication association", "year": 2004, "id": "a0ea532e-5977-4a91-b576-1ef53096442a"}
{"abstract": "Users in ubiquitous computing environments need to be able to make serendipitous use of resources that they did not anticipate and of which they have no prior knowledge. The Speakeasy recombinant computing framework is designed to support such ad hoc use of resources on a network. In addition to other facilities, the framework provides an infrastructure through which device and service user interfaces can be made available to users on multiple platforms. The framework enables UIs to be provided for connections involving multiple entities, allows these UIs to be delivered asynchronously, and allows them to be injected by any party participating in a connection.", "authors": ["Mark W. Newman", "Shahram Izadi", "W. Keith Edwards", "Jana Z. Sedivy", "Trevor F. Smith"], "n_citation": 71, "references": ["2d399561-3c6c-425a-ade6-1bf5173dbc26", "3b44e784-c356-45a8-af90-64e926577870", "3c5d3079-6f14-49c9-9bc6-eef7e39e350f", "503cdac5-121c-4f1b-b4af-6e219de74b84", "5ef1d3b1-f564-4b7c-b518-9cc8a768c9dd", "7780cf6b-b23c-49fb-87fc-24c96282465d", "83cff325-43e0-4161-aedd-01bd59463cc7", "884c6dea-fb7e-421a-a102-aa89c9a4abd3", "9277c882-84b3-4ade-ad7f-29bb4e1c291f", "a22e26b6-62e5-4989-aa93-018b0fe08af2", "b519773f-ef1a-4378-b2ca-0e37310233f6", "bd6ac4c9-affc-4df8-8b1b-07557dcc4304", "cb4f222c-a40f-49d4-8c68-96e591579022", "feff5fa6-3a91-4462-8004-e41dffed073a"], "title": "User interfaces when and where they are needed: an infrastructure for recombinant computing", "venue": "user interface software and technology", "year": 2002, "id": "b55213c2-aa32-45eb-9bcc-057cf2304e7d"}
{"abstract": "Our experience with semi-exhaustive verification shows a severe degradation in usability for the comer-case bugs, where the tuning effort becomes much higher and recovery from dead-ends is more and more difficult. Moreover, when there are no bugs at all, shifting semi-exhaustive traversal to exhaustive traversal is very expensive, if not impossible. This makes the output of semi-exhaustive verification on non-buggy designs very ambiguous. Furthermore, since after the design fixes each falsification task needs to converge to full verification, there is a strong need for an algorithm that can handle efficiently both verification and falsification. We address these shortcomings with an enhanced reachability algqrithm that is more robust in detecting corner-case bugs and that can potentially converge to exhaustive reachability. Our approach is similar to that of Cabodi et al. in partitioning the frontiers during the traversal, but differs in two respects. First, our partitioning algorithm trades quality for time resulting in a significantly faster traversal. Second, the subfrontiers are processed according to some priority function resulting in a mixed BFS/DFS traversal. It is this last feature that makes our algorithm suitable for both falsification and verification.", "authors": ["Ranan Fraer", "Gila Kamhi", "Barukh Ziv", "Moshe Y. Vardi", "Limor Fix"], "n_citation": 39, "references": ["0bc91cdf-6602-4b6e-b753-60297dd20f0d", "0ce1f056-0709-4d5a-8781-040bc9cb4f7e", "13aa790c-0b37-4a38-ae4b-f1ad174c0fc3", "168b9773-c06b-4440-af4a-41d6c4d79c43", "1f15253d-83a8-4702-b5a0-92631c3c657a", "2e9ef947-a588-49f8-a8c5-1b9ac03cdb62", "5d9550f0-6848-4225-82c5-2a7ffbd37b9c", "628b1f50-90cc-4bb8-b40a-aa3ca701b52b", "7c3b375b-2e9e-45fc-8655-6dffcb23e333", "7d540def-748d-4621-9ec5-592b9517668f", "8dc4640f-fa7b-42ba-8441-10fde70b87e6", "a60c5520-6b22-4ba0-b627-0d4a2e82e550", "aa73f87f-a607-4bbc-9008-0729d4831e74", "e24a04f3-ef7a-4d78-b81a-42c0212d15ca"], "title": "Prioritized Traversal: Efficient Reachability Analysis for Verification and Falsification", "venue": "computer aided verification", "year": 2000, "id": "0758ecb5-7709-43d0-ac2f-692225de9e98"}
{"abstract": "A new secret sharing scheme based on a particular type of discrete delay dynamical systems: memory cellular automata, is proposed. Specifically, such scheme consists of a (k,n)-threshold scheme where the text to be shared is considered as one of the k initial conditions of the memory cellular automata and the n shares to be distributed are n consecutive configurations of the evolution of such cellular automata. It is also proved to be perfect and ideal.", "authors": ["A. Mart\u00edn del Rey", "J. Pereira Mateus", "G. Rodr\u00edguez S\u00e1nchez"], "n_citation": 20, "references": ["07026d0f-7160-4228-8d2d-a913fc01042e", "1c1683fc-d4d0-44b1-9099-deab34514ef9", "21eccade-7cee-4b8d-9201-3c7412b48d12", "4f66849a-1a2d-48b4-b98e-a23dccb6a267", "98f543e3-d61c-4099-ae96-237816472592", "b1583182-8f73-4234-8684-c7699347f5db", "b68fc787-7817-421e-8e66-8a98ab9db1ad", "f156b91f-4858-47cb-bacc-8844c704b8ae"], "title": "A secret sharing scheme based on cellular automata", "venue": "Applied Mathematics and Computation", "year": 2005, "id": "009242ac-7726-46d7-9cf8-eff199c3e4f6"}
{"abstract": "Action refinement provides a mechanism to design a complex reactive system hierarchically. This paper is devoted to action refinement from a logical point of view, and to combining the hierarchical implementation of a complex system with the hierarchical specification of the system in order to verify it in an easy way. To this end, we use a TCSP-like language with an action refinement operator as a modeling language, and an extension of the modal \u00b5-calculus, called FLC (Fixpoint Logic with Chop) [18], as a specification language. Specifications in FLC can be refined via a mapping that takes as arguments an abstract specification ? for the process P, an action a of P and a specification ? for the process Q that may refine a and produces a refined specification. We prove under some syntactical conditions: if Q ? ? then P ? ? iff P[a ? Q] satisfies the refined specification. Therefore our approach supports 'a priori' verification in system design and can be used to decrease substantially the complexity of verification.", "authors": ["Mila E. Majster-Cederbaum", "Naijun Zhan", "Harald Fecher"], "n_citation": 3, "references": ["1dab6af7-70a2-4a40-aa37-0a1369510f71", "1f279124-053d-408c-88e1-d7834f88b2ad", "3023929a-c93e-49c5-b03f-7fb0414d94df", "54e1610c-edc8-45af-bdfd-f2c1fff1f3ea", "599e318f-1ec2-4445-8a6b-8833427c008f", "67dcc200-fc7b-43a0-af9c-888d805c06b8", "79de76a0-072e-41a4-8353-411e4fb1c6a7", "8d25f8ed-1eef-48b6-8c78-8fe68e168efe", "8e08be93-c3d3-46d6-aa00-ad3308cd28f4", "afcbaade-1ac3-4745-938b-32ead0768fc3", "c6b48bb8-7a57-41b8-b413-78ce36fe683c", "e39cdebe-ced5-4d35-992d-2e48c456c0f5", "f2b674cc-857c-4658-beeb-53a092e184b1", "f3eba696-462a-4d0a-a999-fb9e099d0e06"], "title": "Action Refinement from a Logical Point of View", "venue": "verification model checking and abstract interpretation", "year": 2002, "id": "c48980eb-2759-4083-893d-ad9ad49079a7"}
{"abstract": "Abstract    MultiLanguage systems  ( ML systems ) are formal systems allowing the use of multiple distinct logical languages. In this paper we introduce a class of ML systems which use a hierarchy of first-order languages, each language containing names for the language below, and propose them as an alternative to modal logics. The motivations of our proposal are technical, epistemological, and implementational. From a technical point of view, we prove, among other things, that the set of theorems of the most common modal logics can be embedded (under the obvious bijective mapping between a modal and a first-order language) into that of the corresponding ML systems. Moreover, we show that ML systems have properties not holding for modal logics and argue that these properties are justified by our intuitions. This claim is motivated by the study of how ML systems can be used in the representation of beliefs (more generally, propositional attitudes) and provability, two areas where modal logics have been extensively used. Finally, from an implementation point of view, we argue that ML systems resemble closely the current practice in the computer representation of propositional attitudes and metatheoretic theorem proving.", "authors": ["Fausto Giunchiglia", "Luciano Serafini"], "n_citation": 443, "references": ["15845260-17fe-4d2e-a9e9-b58ad24474a6", "1c4800e1-d98c-4872-a02b-740473307e69", "1cba300e-7762-44bc-94d1-3fa284367113", "3b92893f-6dc0-4c7c-bbd7-fbb52af9743e", "511a4d84-ac17-4f9c-a476-e610370f00da", "64748a35-d6e2-4479-920c-e0a30b42e792", "6721cba3-7b11-459f-94f4-133c6c71164c", "7b2aee04-3290-4274-99fa-335e8076c5d9", "ca2f93ce-ffb3-40f8-94c8-b8f7ab7b0dbb", "cb4375d7-7799-4706-9472-441cf32a2912", "dd4857e7-084b-4131-ace2-3aae697b6ed6"], "title": "Multilanguage hierarchical logics, or: how we can do without modal logics", "venue": "Artificial Intelligence", "year": 1994, "id": "b6e436c6-d4c1-4303-90ed-3b173a420013"}
{"abstract": "There are many people who find the standard computer input devices?the keyboard and mouse?difficult to use due to a motor disability. A number of keyboard and mouse configuration options designed to overcome physical difficulties exist. However, formal empirical evaluation of such facilities is rare. There is, in fact, little data available on the precise nature of physical difficulties with input devices. Hence, it is difficult to gauge the adequacy of existing access provision. This paper presents an empirical study of the keyboard and mouse errors encountered in a sample of 20 computer users with motor disabilities, and six without disabilities. Six important classes of keyboard difficulty are identified, involving significant correction time for participants with disabilities. Difficulties with all aspects of mouse usage were observed, particularly pointing and dragging. Many of the difficulties observed would be amenable to automatic detection. It is hoped that these results will help to inform the development of more accessible software and hardware.", "authors": ["Shari Trewin", "Helen Pain"], "n_citation": 165, "references": ["3411dd45-0c16-453b-a130-aa906564413c", "346c130d-7c7d-4a28-a467-b244c021273a", "634ed4e3-2fc9-4d06-8c9e-fdea67fd360f", "6ea533e9-8103-4b48-8da2-0bb47113209c", "70fe0e33-a92e-4bfc-9191-cf1435faf233", "ac1b9af1-16ef-4146-9d44-02c3f58c4c8d", "c8323642-f362-4ef3-bcc6-7ed07536c658", "d3df6394-2e7e-429d-85f1-c416706b518e", "dbf5795c-dba7-4282-97d6-ca73e9ad5c2a", "f0b4a16d-a350-4e9a-a90e-b9f9c3728a7d"], "title": "Keyboard and mouse errors due to motor disabilities", "venue": "International Journal of Human-computer Studies \\/ International Journal of Man-machine Studies", "year": 1999, "id": "e4eeaf31-e9f4-4d42-9020-a037446c3f99"}
{"abstract": "In this paper, we present a system that integrates fully automatic scene geometry estimation, 2D object detection, 3D localization, trajectory estimation, and tracking for dynamic scene interpretation from a moving vehicle. Our sole input are two video streams from a calibrated stereo rig on top of a car. From these streams, we estimate structure-from-motion (SfM) and scene geometry in real-time. In parallel, we perform multi-view/multi-category object recognition to detect cars and pedestrians in both camera images. Using the SfM self-localization, 2D object detections are converted to 3D observations, which are accumulated in a world coordinate frame. A subsequent tracking module analyzes the resulting 3D observations to find physically plausible spacetime trajectories. Finally, a global optimization criterion takes object-object interactions into account to arrive at accurate 3D localization and trajectory estimates for both cars and pedestrians. We demonstrate the performance of our integrated system on challenging real-world data showing car passages through crowded city areas.", "authors": ["Bastian Leibe", "N. Cornelis", "K. Cornelis", "L. Van Gool"], "n_citation": 359, "references": ["026b471e-dbf3-45e8-9a29-c2a821e89ed6", "0289a1a7-579b-42a8-8795-45bb59850e67", "0431dc00-17ca-48b6-98f7-fdd1d92bc432", "28874bff-144e-4867-9710-2ca07f464298", "4155e8ce-b23a-41aa-bca2-eeb074b577ba", "652ca64a-46b8-4cc4-90e5-d71de3973201", "8d8e7d51-3223-4776-bf6a-40306774b8a1", "95acddd4-ccc3-4157-a3ab-fe1c3a87f322", "9922cf7c-094c-4894-9d51-63959a5e9678", "9a3e0797-e011-450e-8f61-16e88b378c50", "9f012bff-d69c-44f9-8039-82bba4c05ead", "a038c689-e988-4cd8-a142-fb4501bd9ab2", "aec0c97d-ccad-4b2b-a278-df35396f7223", "b944f77f-113b-4a02-ae5e-d4a124b8fd5b", "c17b4778-a9d9-4213-8967-c5e8ed708ea0", "db65c740-38a8-43ce-b267-6714b444190a", "dd83785a-dd19-41e3-9b25-ebabbd48d336", "e1f2a353-af70-48c2-aba6-a0e0a71fdffc", "f3959783-a9aa-48a2-9fcc-978879de365e", "fb366046-0620-4e4e-a7ac-409d8296a0ac"], "title": "Dynamic 3D Scene Analysis from a Moving Vehicle", "venue": "computer vision and pattern recognition", "year": 2007, "id": "a2efc94d-c253-42a0-a87a-adff2217edef"}
{"abstract": "Pen-based user interfaces are becoming ever more popular. Gestures (i.e., marks made with a pen to invoke a command) are a valuable aspect of pen-based UIs, but they also have drawbacks. The challenge in designing good gestures is to make them easy for people to learn and remember. With the goal of better gesture design, we performed a pair of experiments to determine why users find gestures similar. From these experiments, we have derived a computational model for predicting perceived gesture similarity that correlates 0.56 with observation. We will incorporate the results of these experiments into a gesture design tool, which will aid the pen-based UI designer in creating gesture sets that are easier to learn and more memorable.", "authors": ["A. Chris Long", "James A. Landay", "Lawrence A. Rowe", "Joseph Michiels"], "n_citation": 195, "references": ["2295e96b-706f-4d69-9b2b-d54210509791", "4e96e830-7148-4a45-97bc-fc76f62cb8ea", "5386198c-c5dc-4b24-9466-59586f6a68bb", "54715fd6-40f8-40a5-a0e5-4b0e3bd92848", "6ba589bf-43c3-4a53-98c5-d8fb48f796ac", "73b2dc35-1bcb-420c-8371-6cb36f05816c", "9da40ad5-5709-4894-92a9-9823d78d82b6", "b0705b86-3f3f-4ff0-9e9f-d43b0c8ba8c2", "c0cc908b-c799-46b2-84ab-8bf81aaba439", "c2aa1db2-a46d-4493-9fc2-717316cb12d8", "e2f50d9c-394d-49a6-931e-82b389fd1464", "e7ffd247-7e50-4eba-9951-b2d4297b4352"], "title": "Visual similarity of pen gestures", "venue": "human factors in computing systems", "year": 2000, "id": "fc8ac5bf-88b7-424b-aaae-981e1364e89d"}
{"abstract": "We propose a framework to address an important issue in the context of the ongoing adoption of the \"Web 2.0\" in science and research, often referred to as \"Science 2.0\" or \"Research 2.0\". A growing number of people are linked via acquaintances and online social networks such as Twitter 1 allows indirect access to a huge amount of ideas. These ideas are contained in a massive human information flow [35]. That users of these networks produce relevant data is being shown in many studies [1][2][28][36]. The problem however lies in discovering and verifying such a stream of unstructured data items. Another related problem is locating an expert that could provide an answer to a very specific research question. We are using semantic technologies (RDF 2 , SPARQL 3 ), common vocabularies(SIOC 4 , FOAF 5 , SWRC 6 ) and Linked Data (DBpedia 7 , GeoNames 8 , CoLinDa 9 ) [3][4][5] to extract and mine the data about scientific events out of context of microblogs. Hereby we are identifying persons and organization related to them based on entities of time, place and topic. The framework provides an API that allows quick access to the information that is analyzed by our system. As a proof-of-concept we explain, implement and evaluate such a researcher profiling use case. It involves the development of a framework that focuses on the proposition of researches based on topics and conferences they have in common. This framework provides an API that allows quick access to the analyzed information. A demonstration application: \"Researcher Affinity Browser\" shows how the API supports developers to build rich internet applications for Research 2.0. This application also introduces the concept \"affinity\" that exposes the implicit proximity between entities and users based on the content users produced. The usability of a demonstration application and the usefulness of the framework itself are investigated with an explicit evaluation questionnaire. This user feedback led to important conclusions about successful achievements and opportunities to further improve this effort.", "authors": ["Laurens De Vocht", "Selver Softic", "Martin Ebner", "Herbert M\u00fchlburger"], "n_citation": 20, "references": ["06a4a854-14c6-4b09-a149-e51e906ec49e", "15158158-6389-430d-a813-d48faf68c366", "1c4b91cd-ce9a-4f7a-a06b-0fde3914d80f", "28994c1f-f220-4156-a6da-17cff4a55a61", "3315a1dd-9426-4e38-a34f-6aa92c61df57", "47247064-976f-47d1-b2e7-312f0a665ca0", "49f637fe-1cee-43a7-b2c0-df186fc37f2f", "50554fb5-8d58-40db-a3b5-6af3d65ef411", "642f1dc6-c11c-4657-bcb6-948b60723fac", "91075dd2-4b40-430b-ac95-8320889324a0", "94cc06c8-0e99-49eb-aea3-4be2cf0e47fd", "9ec1269e-a605-425f-9be6-ae9ce3b7f7ad", "9f5074e9-456f-486f-bd1f-9634047187dd", "9f8c6b77-c4aa-4d99-b753-61c7e0103d44", "a10112f0-9f66-4d46-be71-edcb91018356", "b112d246-add3-409a-9a09-03d4ef07ef00", "cfef9d18-8c33-4b41-b7a4-59444323dca6", "f0a41697-4da1-4205-ac97-52f21943c9a3", "fc9e5217-51fd-457d-9d09-680925082f56"], "title": "Semantically driven social data aggregation interfaces for Research 2.0", "venue": "", "year": 2011, "id": "fcd0e752-8d25-4231-ba3e-b7fefe6133cc"}
{"abstract": "The creation of OFDM based Wireless Personal Area Networks (WPANs) has allowed the development of high bit-rate wireless communication devices suitable for streaming High Definition video between consumer products, as demonstrated in Wireless-USB and Wireless-HDMI. However, these devices need high frequency clock rates, particularly for the OFDM, FFT and symbol processing sections resulting in high silicon cost and high electrical power. The high clock rates make hardware prototyping difficult and verification is therefore very important but costly. Acknowledging that electrical power in wireless consumer devices is more critical than the number of implemented logic gates, this paper presents a Double Data Rate (DDR) architecture for implementation inside a OFDM baseband codec in order to reduce the high frequency clock rates by a complete factor of 2. The presented architecture has been implemented and tested for ECMA-368 (Wireless- USB context) resulting in a maximum clock rate of 264MHz instead of the expected 528MHz clock rate existing anywhere on the baseband codec die.", "authors": ["Robert Simon Sherratt", "Oswaldo Cadenas"], "n_citation": 50, "references": ["4189f9ab-3dd2-4ed2-bd4d-8ff8a8d181a0"], "title": "A double data rate architecture for OFDM based wireless consumer devices", "venue": "IEEE Transactions on Consumer Electronics", "year": 2010, "id": "b7f5c1fd-41e2-4cba-b9f7-5d1f61a69538"}
{"abstract": "It is important to provide digitized manuscripts of old literature (in page image form) and their electronic text (in full-text form), with an automatic reference mechanism between the images and the text, on the Internet. As an essential step for creating such an automatic reference system, this paper describes the issue of extracting character areas from page images of old handwritten manuscripts. Page images of old manuscripts are usually terribly dirty and considerable large in size. To overcome the first problem, we propose a new effective method for separating characters from noisy background, since conventional threshold selection techniques are inadequate to cope with the image where the gray levels of the character parts are overlapped by that of the background. To solve the second problem, we propose an approach based on a downscaled image and a recursive labeling method for word extraction. This approach is suitable for large size images because it has the advantage of saving memory and reducing processing time.", "authors": ["Hideyuki Negishi", "Jien Kato", "Hiroyuki Hase", "Toyohide Watanabe"], "n_citation": 34, "references": ["692fb8da-c5c9-4415-b449-ecca18f24e6c"], "title": "Character extraction from noisy background for an automatic reference system", "venue": "international conference on document analysis and recognition", "year": 1999, "id": "5c4cf07d-9c43-45bf-9b5d-ad9237cd4770"}
{"abstract": "Data miners can infer rules showing how to improve either (a) the effort estimates of a project or (b) the defect predictions of a software module. Such studies often exhibit conclusion instability regarding what is the most effective action for different projects or modules.", "authors": ["Tim Menzies", "Andrew Butcher", "Andrian Marcus", "Thomas Zimmermann", "David R. Cok"], "n_citation": 112, "references": ["0fd86156-5972-4612-9403-4e2f8434eccd", "10e335c8-bee0-4171-8ad5-dce611e8ca0f", "12d0dbd4-4dd9-42b7-a321-14270882a619", "1eb3a4e4-e6a5-49ab-bb53-06c09eeda046", "2068a31e-93c4-497f-ad79-c0ca3bf88ab8", "2d1b5ca7-9df1-4cb5-97d3-ae6c967d1a12", "35f50f31-7518-4097-a8f9-c07c06aad087", "39449439-0015-4333-9969-5989880121b1", "42fe7a4d-02e2-46b5-852e-79f6a423cd6a", "43eadace-9dd9-42fd-befc-e796ded65ca2", "44f7084a-37d6-4a0f-8eb3-8d3c7b73d68d", "549234cb-5111-460c-bbf1-d8c134761b41", "62c48edb-fd85-48fa-9e22-e804c81efc7b", "64d948cd-d9ec-4653-8c78-c96135df838d", "77705cb6-95f2-4be0-a7bc-f0a90b0efdc0", "77e5ad21-7237-4aab-9291-0d170c10bbbc", "8f12b9c2-636a-434c-aaf7-367b00d8ea3a", "98bae12c-2a1a-44a5-8e3f-1637b4e7b2fe", "9d391f89-9fbd-438a-bbba-57f8fe085e0c", "a1853113-dd04-44ae-9e76-a0ddfbf49084", "b3545514-5ac3-47bd-b63c-80384a9a13bf", "d32786fc-ea8d-41f0-a803-5d00e550329c", "e7c16210-c323-422f-aa5c-3c5ca4031ecd", "ed4fcd27-06da-4bd9-af15-90f02acaa1f9", "ee93ef28-8456-4d4b-b06f-06f2dfa92be2", "fde1a431-09f2-4ae9-9816-f82a6228d057", "ffc5a774-7240-4851-9e55-79c23ad11c72"], "title": "Local vs. global models for effort estimation and defect prediction", "venue": "automated software engineering", "year": 2011, "id": "df1dc29f-937f-43bf-8945-b4a8ee4a56be"}
{"abstract": "Distance measures like the Euclidean distance are used to measure similarity between images in content-based image retrieval. Such geometric measures implicitly assign more weighting to features with large ranges than those with small ranges. This paper discusses the eects of v e feature normalization methods on retrieval performance. We also describe two likelihood ratio-based similarity measures that perform signican tly better than the commonly used geometric approaches like the Lp metrics.", "authors": ["Selim Aksoy", "Robert M. Haralick"], "n_citation": 273, "references": ["1017d9d4-9a4c-423d-ad40-6d9bebbd6b31", "13b91eb0-0857-4556-b32a-0f85a1cf43f6", "56d6466f-28bc-429c-a969-9b9609398481", "62a46780-e1d9-4186-babe-6179735d785e", "a8b6f20c-4cfa-43c1-882d-5380044bdcdf", "a9e04749-1c28-4e6a-b74e-41d11750d079", "d04017cf-d8ed-4a2f-8372-b6c9e741c85c", "f2281d46-788e-4c45-a594-81634febabb6", "fb5b7aa5-5d68-45b9-be8b-36d217d940d7"], "title": "Feature normalization and likelihood-based similarity measures for image retrieval", "venue": "Pattern Recognition Letters", "year": 2001, "id": "ffd17c26-e565-4fa8-b5ad-e2673c389999"}
{"abstract": "To update a performance model, its parameter values must be updated, and in some applications (such as autonomic systems) tracked continuously over time. Direct measurement of many parameters during system operation requires instrumentation which is impractical. Kalman filter estimators can track such parameters using other data such as response times and utilizations, which are readily observable. This paper adapts Kalman filter estimators for performance model parameters, evaluates the approximations which must be made, and develops a systematic approach to setting up an estimator. The estimator converges under easily verified conditions. Different queueing-based models are considered here, and the extension for state-based models (such as stochastic Petri nets) is straightforward.", "authors": ["Tao Zheng", "C. M. Woodside", "Marin Litoiu"], "n_citation": 142, "references": ["044f7926-4248-4ae0-b3d0-f41546505a75", "1a2eac11-e7cf-4c04-b2f1-2b54dda6ff1c", "39687de7-b667-48cb-a316-814e0e150b8d", "3eb7fb77-d85c-424c-b8e7-55c449b1f4f4", "4033b3e8-8f9f-42e6-a092-522fabacf53a", "47e40a7e-6668-4b04-abfe-44f7c547c64d", "581949bb-0499-4250-834d-68687e13e726", "69ac2b8e-1532-488a-87e3-6e8d7dd93377", "a2d9d904-dfe5-4ba0-919a-81550f7ff21b", "a4d5cb9d-c3a8-49b7-b6c8-effd7b6fa581", "b993a6e4-aab7-4ed6-967f-79425f682985", "ce30267f-324c-40fc-8e43-56285c08e2e4", "d852290a-e5d9-41fd-bb15-3fe2abf67cd1", "da673a1a-ac77-4150-b461-3e574a7c0a62", "ea22f8f0-d6ba-4ea9-9603-ab30b852cda2"], "title": "Performance Model Estimation and Tracking Using Optimal Filters", "venue": "IEEE Transactions on Software Engineering", "year": 2008, "id": "04416518-3067-4db6-9fd4-2ee99d7e177d"}
{"abstract": "The goal in computer vision systems is to analyze data collected from the environment and derive an interpretation to complete a specified task. Vision system tasks may be divided into data acquisition, low-level processing, representation, model construction, and matching subtasks. This paper presents a comprehensive survey of model-based vision systems using dense-range images. A comprehensive survey of the recent publications in each subtask pertaining to dense-range image object recognition is presented.", "authors": ["Farshid Arman", "Jake K. Aggarwal"], "n_citation": 325, "references": ["04840022-504b-4526-ad5d-06dd8737fe99", "07d1d33d-fc47-40bb-82a9-499a6ebf08cf", "092e1be2-34dc-4ae8-b86c-31d0c6097dd4", "0badf7be-7f89-40c4-b53a-8c4fc90f4247", "1017d9d4-9a4c-423d-ad40-6d9bebbd6b31", "11a01e81-de5d-4544-bb84-1804438ea49f", "11b7d696-b008-4267-8376-a749571870d0", "1ea855ae-7bea-44c9-b51b-74ab13db82a7", "293b10d1-fc8b-4d8b-b57d-75b1397c035d", "2979aa1f-bd73-4d52-a58a-67e85f2b8d30", "29be2e6b-44d1-471c-b794-a0d03bc4b524", "3506e615-ac38-45e5-99fc-1911e26f569a", "39536116-298e-4111-a0cc-de46bbc96632", "3f24a219-aebc-4bf8-a8f9-a9f5ef282d65", "5571a5c6-91e2-4a3e-abb3-6ee1919b89cf", "5d5a71eb-bf78-4083-bea1-47adb54e6be4", "62e70e96-1de9-4c0e-800f-30bb7a368aee", "6775ce2b-db8f-4bc1-9bae-8d444ce5ecee", "6918a417-fb0d-44e3-8a13-1b2a2e8429fb", "6fbd0c25-8a40-4af8-8698-4a27268a3765", "707861be-6948-40eb-8372-231834de3196", "7156750f-e0ed-48b5-8d96-199126a56cfb", "720d5d4b-a4e6-4f7b-b24d-301905987904", "755c9ea5-0e65-4865-a5ca-d7148153594f", "79bd9613-8976-41a1-b0b7-133b80b8477e", "81251c93-acf8-4031-8acc-4b570c5759cc", "89fdc869-32f1-451e-b4fd-c9e94133b74f", "8b1365a7-64ae-4a7f-ad4f-449b9ee78c7d", "8c0bdf2e-74bd-46c6-ae3d-784f37594c7f", "8d061740-afa9-437b-aef2-496d5a9c95a9", "8e7518b7-8bfc-4ef2-81ad-7ffc73f3b016", "9572124b-4045-44a9-969c-73350c5b6a3d", "95b2a1cb-8aaf-47dc-9084-5a7926745d8c", "98c35323-0b60-4069-808c-9e0eb4e917af", "9da111b0-826c-4b67-853d-4e2606aeba3d", "a54d0b46-d7ba-4036-abd2-d30c95130f35", "ac129832-39b9-407d-aff3-582c209145f3", "b608af66-6368-44dc-a670-2a3e42561ee1", "ba5244a4-9bc2-4a8f-8d1d-76bb53039545", "bd1be6f0-b5a3-48c9-92c5-093aeb9952ce", "bf1b59c6-2cf2-4f06-b9ab-47c8b1859386", "c0e06bb9-955c-4458-9a79-54ff724cca55", "c37e1181-a1ea-43b2-b707-009d1c549b1f", "c39c2ff9-1401-474d-917e-3776f528b204", "c70e520a-2d79-4107-a531-8caf1ec0a069", "c7fac587-c91b-4df1-ada7-18ad00ba850a", "caeecc11-ec92-47d8-b112-c43b88dd4491", "cefae0ad-15c2-4105-afb5-f2d66b7e82d6", "d086bf44-635e-4e8d-b3ad-d539a4e3b5d9", "da477527-493c-438f-b880-c78d95b5f4a8", "de298324-d01e-4b89-8d7d-dc25c39b08d6", "de6f98ad-845e-4d5f-9c4f-548ad77e560e", "e01575ae-c6ba-4fc4-9d92-d7068b13851f", "e1325953-1c0c-452f-8891-dc322e409576", "e2ecd275-fb31-4d5f-8cf4-e156391616c2", "e389fa97-0461-4d42-876f-31d67c0690ca", "eb2768b4-379a-4399-9c87-f4e76c5c591f", "ed9ca272-6f8d-49f5-92d1-88226c6a8253", "f2ad3569-be85-4a5e-a5ea-9f7875677c25", "fc95549e-7237-4ca0-8c96-924add128901", "fdbb090b-6807-41d1-81bb-dab4be952983"], "title": "Model-based object recognition in dense-range images\u2014a review", "venue": "ACM Computing Surveys", "year": 1993, "id": "d96ee988-33d2-4fe8-8feb-5f66b0efceb1"}
{"abstract": "Very few techniques have been proposed for estimating traffic matrices in the context of Internet traffic. Our work on POP-to-POP traffic matrices (TM) makes two contributions. The primary contribution is the outcome of a detailed comparative evaluation of the three existing techniques. We evaluate these methods with respect to the estimation errors yielded, sensitivity to prior information required and sensitivity to the statistical assumptions they make. We study the impact of characteristics such as path length and the amount of link sharing on the estimation errors. Using actual data from a Tier-1 backbone, we assess the validity of the typical assumptions needed by the TM estimation techniques. The secondary contribution of our work is the proposal of a new direction for TM estimation based on using choice models to model POP fanouts. These models allow us to overcome some of the problems of existing methods because they can incorporate additional data and information about POPs and they enable us to make a fundamentally different kind of modeling assumption. We validate this approach by illustrating that our modeling assumption matches actual Internet data well. Using two initial simple models we provide a proof of concept showing that the incorporation of knowledge of POP features (such as total incoming bytes, number of customers, etc.) can reduce estimation errors. Our proposed approach can be used in conjunction with existing or future methods in that it can be used to generate good priors that serve as inputs to statistical inference techniques.", "authors": ["Alberto Medina", "Nina Taft", "Kave Salamatian", "Supratik Bhattacharyya", "Christophe Diot"], "n_citation": 668, "references": ["1d548f58-1af8-4134-9da3-ffa4d66ebe2b", "91109dc7-752c-46b4-a760-e1c8546172de"], "title": "Traffic matrix estimation: existing techniques and new directions", "venue": "acm special interest group on data communication", "year": 2002, "id": "1ceb1318-5900-4f8e-b025-8252b0498054"}
{"abstract": "The paper presents an overview of the role of concepts in program comprehension. It discusses concept location, in which the implementation of a specific concept is located in the code. This process is very common and precedes a large proportion of code changes. The paper also discusses the process of learning about the domain from the code, which is a prerequisite of code reengineering. The paper notes the similarities and overlaps between program comprehension and human learning.", "authors": ["Vaclav Rajlich", "Norman Wilde"], "n_citation": 251, "references": ["053ce8a9-e0b4-4d89-b84d-2dd9f22d0826", "1a50cb82-42ee-4d26-b74c-cccf045855f0", "26ab716a-ca64-470a-9a6d-ea47c5d98ae8", "3e0370c4-e0b1-4c6f-a13c-b2b7ff9ceac0", "483261b9-66ae-4117-ac5e-78e3e5ea3892", "56159371-a48f-4a4c-8db6-9a1ee3ac6cbb", "5abfe0f3-0faa-4deb-8a49-e0af9c702748", "7277965d-e1ce-4be2-b419-945d684272f4", "acaed948-4739-4f84-8772-25d508024f6e", "bd04d88c-3350-4284-b3ed-5fc908ddb73a"], "title": "The role of concepts in program comprehension", "venue": "international conference on program comprehension", "year": 2002, "id": "9b86aec6-f6e4-45da-9e0e-a0ed07c49394"}
{"abstract": "Tools for quantifying teleoperation system performance and stability when communication delays are present are provided. A general multivariable system architecture is utilized which includes all four-types of data transmission between master and slave: force and velocity in both directions. It is shown that a proper use of an four channels is of critical importance in achieving high performance telepresence in the sense of accurate transmission of task impedances to the operator. It is also shown that transparency and robust stability (passivity) are conflicting design goals in teleoperation systems. The analysis is illustrated by comparing transparency and stability in two common architectures, as well as a recent passivated approach and a new transparency-optimized architecture, using simplified one-degree-of-freedom examples. >", "authors": ["Dale A. Lawrence"], "n_citation": 2164, "references": ["13832a9e-2ad4-445b-9708-ea3db7410293", "6f6987b9-6804-45a6-ba11-5a9e69c8511c", "75274d44-45c8-4e38-88c2-f67007b6b7d4", "8346b142-ba96-4ad1-be71-89aa28c07c29", "de4bdbf1-0dc6-4a31-8e93-03ad92dcd5c5"], "title": "Stability and transparency in bilateral teleoperation", "venue": "international conference on robotics and automation", "year": 1993, "id": "8511b05d-7c3a-4632-a937-d5afb50782b8"}
{"authors": ["Gary Cornell", "Cay S. Horstmann"], "n_citation": 140, "title": "Core Java", "venue": "", "year": 1996, "id": "eef19da8-67eb-47e7-834e-88acd33c9a43"}
{"abstract": "In this paper, the analysis of the differential kinematics and manipulability measures of robotic systems comprised of multiple cooperating limbs is considered. The goals of this study can be articulated in four points: 1) to enumerate the degrees of freedom of the manipulation system; 2) to describe analytically all possible first-order differential motions of the system at a given configuration; 3) to evaluate in the velocity domain the functionality of a manipulation system, with respect to the task it is required to perform; and 4) to calculate the bounds for the velocities achievable by the system, given bounds on the capabilities of joint actuators. The assumptions made on the robotic system are quite general, so that many complex devices (e.g., dextrous hands, legged vehicles, whole-arm manipulators, etc.) can be dealt with in a unified and convenient framework. >", "authors": ["Antonio Bicchi", "Claudio Melchiorri", "Daniele Balluchi"], "n_citation": 232, "references": ["151d1aa6-b34a-4ad1-ad20-072dee82dfaf", "1a9035a4-2c23-4486-af3e-773e96356897", "2c2509af-804b-4ed5-8160-2c8ac846b271", "4097b0f7-a701-46ad-aba7-7a05d97c4295", "638f28f4-ce78-47bf-bb01-5d71f1a31942", "793e8e95-80ae-48dd-ba87-0cbdb28978f8", "9cf832fb-ea30-44ca-8f51-f8802aaf9d02", "c02de7a0-2939-4240-9c85-193ed1b5dfee", "c17011f9-1234-46b7-a187-4c6e04ceb28b", "dc836a07-7a2b-46db-b799-7cf26ddb3ef8", "e0e0bac3-a443-49ff-ad8f-b8c85ade55c7", "e749e0cc-ab35-444f-afa5-120d7959bde1"], "title": "On the mobility and manipulability of general multiple limb robots", "venue": "international conference on robotics and automation", "year": 1995, "id": "ec11d6c3-5a6e-45c4-8080-639d1259fd32"}
{"abstract": "We derive a generalization bound for prototype-based classifiers with adaptive metric. The bound depends on the margin of the classifier and is independent of the dimensionality of the data. It holds for classifiers based on the Euclidean metric extended by adaptive relevance terms. In particular, the result holds for relevance learning vector quantization (RLVQ) [4] and generalized relevance learning vector quantization (GRLVQ) [19].", "authors": ["Barbara Hammer", "Marc Strickert", "Thomas Villmann"], "n_citation": 83, "references": ["0a4f84da-97f3-4041-9e2f-b4828b7f4d22", "30125a55-cddc-45a8-89cc-816a6a8b9f59", "413c86cd-2f48-422c-b561-eb10df66f0cd", "458f608f-ebea-4920-9789-4045224003ad", "50dd56db-151d-4d62-8576-65f0ef6f381b", "5bb27e87-24aa-485b-afea-dd7d73e0333d", "5df8a66b-20d1-4e6c-ab02-cffe9cb76a0f", "6b49efc2-8549-41af-9e43-11a160d077b5", "6eb09d5b-f959-4176-adb3-035ca125951e", "74f25b17-442f-4204-928c-6474d75ca225", "88c8352d-fd0a-42f1-b062-f65899f8ae79", "8bb47288-c305-4131-9a23-3635d1bc15ad", "8be8b196-5437-4edc-9823-d4779b4774a5", "9132939c-9d33-4065-b39a-dd1d284aa0c7", "a2672acf-569b-4b34-8834-3b956cc1a06c", "a87f974b-a5ac-4af5-9301-8e6c548da08e", "ac5715dc-05ba-45b6-873d-b06316a7bfd3", "bed7ec05-fec8-4eea-bf56-be9893724d89", "c61422d6-ec24-49ff-88d9-ed6e62573222", "cae8b728-f4b2-4d9d-b6bd-085034e3edd9", "e763ddb3-55d5-40a6-9c90-676afdfeb505", "fab009f6-19f4-4eed-af8c-62776947aef3", "fcbbc7ba-4789-4a23-837d-8f42854152c8", "fd371bb4-d8be-4e8c-a0a6-ce0fafb6b124", "fde98d06-222d-48e1-8984-82f193e30786"], "title": "On the Generalization Ability of GRLVQ Networks", "venue": "Neural Processing Letters", "year": 2005, "id": "217ec2a8-7ffa-4ed1-a7be-4da243724778"}
{"abstract": "Recently, many software visualization (SV) techniques and tools have become available. There is ample anecdotal evidence that appropriate visualization can significantly reduce the effort spent on system comprehension and maintenance, yet we are not aware of any quantitative investigation and survey of SV tools. This paper reports on a survey on SV tools which was conducted in spring 2000 with more than 100 participants. It addresses various functional, practical, cognitive as well as code analysis aspects that users may be looking for in SV tools. The participants of the survey rated the usefulness and importance of these aspects, and came up with aspects of their own. The participants were in general quite pleased with the SV tool they were using and mentioned various benefits. Nevertheless, a big gap between desired aspects and the features of current SV tools was identified. In addition, a list of improvements that should be done to current tools was assembled. Finally, the collected data tends to suggest that in general code analysis aspects were not highly supported by the tools.", "authors": ["Sarita Bassil", "Rudolf K. Keller"], "n_citation": 120, "references": ["03c45400-b6ee-458b-afc5-f44934ca4685", "20484f23-132a-4f7f-9547-2dc6db160894", "2b3e51e0-4d6f-4a33-a838-3c857d3caa31", "405d8a07-390a-44ce-9a7d-d9419eaa7ce9", "8187cc56-6bac-423e-bac3-fffcd2cf011c", "a0a43625-dd35-481a-9a65-670982beeab1", "a1e6b046-aa91-4544-98c6-d84dee61c8ec", "d034b27e-49f4-4a64-aa17-621b9091cac2", "dee73ccd-efd0-417d-918e-45f57103e46f", "e170e25b-b5bd-4a48-9732-27b77370b352"], "title": "Software visualization tools: survey and analysis", "venue": "international conference on program comprehension", "year": 2001, "id": "1bbb362e-8532-45d4-9d76-1d70b17f292e"}
{"authors": ["Mark A. Linton", "Paul R. Calder"], "n_citation": 50, "title": "The Design and Implementation of InterViews.", "venue": "", "year": 1987, "id": "68a09e98-b1e5-46c5-8060-b0e58ea3d1db"}
{"abstract": "We propose a face difference model that decomposes face difference into three components, intrinsic difference, transformation difference, and noise. Using the face difference model and a detailed subspace analysis on the three components we develop a unified framework for subspace analysis. Using this framework we discover the inherent relationship among different subspace methods and their unique contributions to the extraction of discriminating information from the face difference. This eventually leads to the construction of a 3D parameter space that uses three subspace dimensions as axis. Within this parameter space, we develop a unified subspace analysis method that achieves better recognition performance than the standard subspace methods on over 2000 face images from the FERET database.", "authors": ["Xiaogang Wang", "Xiaoou Tang"], "n_citation": 109, "references": ["32d158dc-6f9f-426a-973b-8edc5e4c5dad", "56f4b72a-ec39-47ac-8220-899296e7fb18", "61e615e7-f78f-4f1e-b604-343ecf4b2ec9", "bf1d8c69-aefb-4a7a-8b02-f815b754833c"], "title": "Unified subspace analysis for face recognition", "venue": "international conference on computer vision", "year": 2003, "id": "13f0ac10-8298-4644-8deb-73534aad3884"}
{"abstract": "Abstract The purpose of this paper is to describe a modeling methodology called multilevel flow modeling (MFM), which the author has developed for the representation of goals and functions of complex industrial plants. The idea of the methodology is to apply functional concepts to represent a plant at multiple interrelated levels of abstraction. MFM is currently used in supervisory control applications for aiding the operator in diagnosis and planning. It is also used in the conceptual analysis and synthesis of control systems. The paper provides an introduction to the basic concepts of MFM, details two modeling examples, and describes the object-oriented tool Abstractions used for the implementation of MFM models and for diagnosis and planning applications. Finally, the paper presents a review of the use of MFM in previous and ongoing international projects.", "authors": ["Morten Lind"], "n_citation": 406, "references": ["3ff04a77-f242-41d5-a392-1b632067bb47", "48652a22-f36e-4e05-8cc9-1f1b0aac54d7", "67e678f2-faeb-4310-b693-4f0af74a2da7", "d8f20d8f-7e3d-4cea-ac3a-e9b96875461a"], "title": "MODELING GOALS AND FUNCTIONS OF COMPLEX INDUSTRIAL PLANTS", "venue": "Applied Artificial Intelligence", "year": 1994, "id": "1aa6350c-6c9c-4716-9470-b85f6124d675"}
{"abstract": "Abstract   The NP-hard problem of packing items from a given set into bins so as to maximize the number of bins used, subject to the constraint that each bin be filled to at least a given threshold, is considered. Approximation algorithms are presented that provide guarantees of   1  2  ,   2  3  , and   3  4   the optimal number, at running time costs of  O ( n ),  O ( n log n ), and  O ( n log 2  n ), respectively, and the average case behavior of these algorithms is explored via empirical tests on randomly generated sets of items.", "authors": ["Susan F. Assmann", "David S. Johnson", "Daniel J. Kleitman", "Joseph Y.-T. Leung"], "n_citation": 156, "references": ["1e573014-c071-423d-9f79-0e8e20d60331", "236105f2-6a23-4a39-83d3-91d79ffdc341", "52359d07-831d-4636-ad9a-fd315b16085a", "5bb219b7-6a30-4fe3-8580-e47f00d83c5c", "78ba1cff-9572-4213-aecf-a777fa84318a", "79d7f867-b04a-441a-95bf-60c3fc7d65ca", "9bc4a5f1-a73a-47b2-8769-97520298e1b4", "a58a6f08-3e57-449f-8f15-ae9e82866e02", "b78de990-f555-491e-8218-1a9905847992", "cb5d41c3-5d92-479f-b55d-aa1c20996f62"], "title": "On a dual version of the one-dimensional bin packing problem", "venue": "Journal of Algorithms", "year": 1984, "id": "b6b58976-f996-471a-88cd-77cecd2f9158"}
{"abstract": "Constructing splines whose parametric domain is an arbitrary manifold and effectively computing such splines in real-world applications are of fundamental importance in solid and shape modeling, geometric design, graphics, etc. This paper presents a general theoretical and computational framework, in which spline surfaces defined over planar domains can be systematically extended to manifold domains with arbitrary topology with or without boundaries. We study the affine structure of domain manifolds in depth and prove that the existence of manifold splines is equivalent to the existence of a manifold's affine atlas. Based on our theoretical breakthrough, we also develop a set of practical algorithms to generalize triangular  B -spline surfaces from planar domains to manifold domains. We choose triangular  B -splines mainly because of its generality and many of its attractive properties. As a result, our new spline surface defined over any manifold is a piecewise polynomial surface with high parametric continuity without the need for any patching and/or trimming operations. Through our experiments, we hope to demonstrate that our novel manifold splines are both powerful and efficient in modeling arbitrarily complicated geometry and representing continuously-varying physical quantities defined over shapes of arbitrary topology.", "authors": ["Xianfeng Gu", "Ying He", "Hong Qin"], "n_citation": 67, "references": ["0aacd577-6c5d-4046-8a90-7a7d23308a2f", "0c87c142-c139-4d7f-8bac-84098c782fb3", "22a95bc8-757c-4fe4-9b0d-78b9f2c81f01", "320bfdb0-bb0a-4d6f-9b50-d7c72f02867c", "8a9e0e18-5978-4811-89e7-8200fcb99ba2", "8ab741ba-501e-43b4-926b-0ea36d077f69", "e059fb73-a8de-48d4-aac5-c7acef20b5c0", "e71e24b0-b840-47f1-834d-036cad71885e", "f35aa0cf-570a-4931-8f0e-0eba10bc6cc6", "f6f0fa83-4fa0-45f6-8e58-7c913ab05bf7", "fa633885-813d-4bbb-ba52-dd486fe35e01", "fbfd4acf-49ff-4e8f-a8f2-0d9117610414"], "title": "Manifold splines", "venue": "", "year": 2005, "id": "4714e999-94f6-49ec-bf9e-a6f1d5493df1"}
{"abstract": "As a major threat today, how to defense against APT (advanced persistent attack) effectively becomes a major issue for network security. APT is a combination of past attacks, not a new one. It's different from any one of previous attacks. Predicting the attack path of APT exactly would be a breakthrough for the future defense in Internet of things. Firstly, the paper proposes classifications of attack and defense for game model from the perspective of game theory. Then, we present the OAPG model, which uses attack path of APT as the attacker's strategy. Finally, according to the Nash equilibrium, we compute the optimal attack path for the attacker and best-response strategies for the defender.", "authors": ["Xupeng Fang", "Lidong Zhai", "Zhaopeng Jia", "Wenyan Bai"], "n_citation": 3, "references": [], "title": "A Game Model for Predicting the Attack Path of APT", "venue": "", "year": 2014, "id": "3134dca7-0da5-46fd-b598-e3d166186369"}
{"abstract": "This paper studies the distributed containment control problem for networked multiple quadrotors with multiple stationary leaders under a directed graph which is the communication topology between the leaders and the followers for arbitrary initial states. Necessary and sufficient conditions on the communication topology are shown. The model of a quadrotor is divided into two subsystems, one is under-actuated with the states of horizontal coordinates, the other is fully-actuated with the states of vertical position and the yaw angle. For the first subsystem, we present a new control law using backstepping technique such that all followers' states, horizontal coordinates, converge to the minimal hyperrectangle spanned by the corresponding states of the leaders asymptotically. For the second subsystem, due to the existence of uncertainties, a sidling-mode controller is given to compensate the uncertainty items. Furthermore, with the proposed controller, altitudes and the yaw angles of followers are driven to the minimal hyperrectangle formed by the leaders. Simulation results on networked multiple quadrotors are provided to show the effectiveness of the proposed protocols.", "authors": ["Yinqiu Wang", "Qinghe Wu", "Yao Wang"], "n_citation": 8, "references": ["0bf829c3-d555-4745-b1a5-7c5ce8acbff6", "13579f6c-1791-4e6c-ad10-f6fb154658d1", "1b449c68-2b9f-48dc-8b0c-9539613fe6ef", "2768199c-b9d6-4001-94d3-e6429c93bc5f", "34a6a69e-79d6-4dff-af41-81b7d08d1397", "363975b2-4a39-42c2-99de-ba32feae7bd1", "417765cf-31bd-4e5a-b048-2d0cdcb881fb", "76cee6d5-8d17-4daa-af98-18e7d4f74249", "bcac4659-3dc4-4d8e-9254-440ac1ea27a7", "c4c7f847-20af-4547-a9db-d73eee35b11c"], "title": "Containment control for multiple quadrotors with stationary leaders under directed graphs", "venue": "conference on decision and control", "year": 2012, "id": "cffafe22-3be7-40a9-94ec-85798eb2c46f"}
{"abstract": "Alternating direction methods (ADMs) have been well studied in the literature, and they have found many efficient applications in various fields. In this note, we focus on the Douglas-Rachford ADM scheme proposed by Glowinski and Marrocco, and we aim at providing a simple approach to estimating its convergence rate in terms of the iteration number. The linearized version of this ADM scheme, which is known as the split inexact Uzawa method in the image processing literature, is also discussed.", "authors": ["Bingsheng He", "Xiaoming Yuan"], "n_citation": 428, "title": "On the $O(1/n)$ Convergence Rate of the Douglas-Rachford Alternating Direction Method", "venue": "SIAM Journal on Numerical Analysis", "year": 2012, "id": "2bcc2730-1b2e-4d43-ad5e-594081dcef4b"}
{"abstract": "Single superclass inheritance enables simple and efficient table-driven virtual method dispathc. However, virtual method table dispatch does not handle multiple inheritance and interfaces. This complication has led to a widespread misimpression that interface method dispatch is inherently inefficient. This paper argues that with proper implementation techniques, Java interfaces need  not  be a source of significant performance degradation.", "authors": ["Bowen Alpern", "Anthony Cocchi", "Stephen J. Fink", "David Grove"], "n_citation": 114, "references": ["0f7cde81-008a-4068-afbe-90daf0292fe0", "183292a9-9b90-4bdd-82c4-cd9c98062d18", "2482cf2b-2bf4-4edc-a2d6-d245a1392b8d", "28a54f16-d3d2-4163-b414-058f6fe02032", "2a033182-f746-45b0-96ce-2b3248c46c5e", "39d0867f-f7c6-47f3-99b8-a7fa7fb14197", "4b1e7034-1c69-4277-95f2-dc835a3fb22c", "533aba6f-63f6-4e9f-8427-fcd95fa29132", "5ede8760-7898-40fb-a35c-d95dfa521d8a", "60275022-4bb4-4cac-b2d9-c63c85173ec5", "66a71fc4-c0aa-4bb8-a484-360a1933cf7e", "7a20c8c9-ca50-4aaa-81ce-46e489967e02", "7f1dc63a-9064-4768-a30d-3383d52aa81e", "94dbbe06-3920-4b02-9c60-d04e3f73f276", "988972c4-0b93-40e5-839a-e9f47887a421", "9e89998a-6623-4393-90cf-05a247020292", "a691140a-2638-4788-9ad4-6460127efb47", "aa831718-dd1b-44db-b3ca-24c79337b500", "ad72a4b3-693a-4f00-878b-aa81dbc66ac0", "c328caa5-d2c3-47cc-b75e-71e716d5cd2a", "d0e6ef11-4692-4b6a-a349-f9b3c7642351", "d5777874-7857-47f9-aa72-b05585a60061", "f1544ea7-8724-4684-a5bc-b7381fadfd44", "f23fdbbc-a170-4433-81b5-66ef3cbf6a34", "fba244e2-43cc-4b78-b754-5adabeaa8cf8"], "title": "Efficient implementation of Java interfaces: Invokeinterface considered harmless", "venue": "conference on object-oriented programming systems, languages, and applications", "year": 2001, "id": "a85d3e78-fab5-46a3-a685-27640e01955e"}
{"abstract": "This paper is concerned with the filtering problem for a class of discrete-time uncertain stochastic nonlinear time-delay systems with both the probabilistic missing measurements and external stochastic disturbances. The measurement missing phenomenon is assumed to occur in a random way, and the missing probability for each sensor is governed by an individual random variable satisfying a certain probabilistic distribution over the interval [01]. Such a probabilistic distribution could be any commonly used discrete distribution over the interval [01]. The multiplicative stochastic disturbances are in the form of a scalar Gaussian white noise with unit variance. The purpose of the addressed filtering problem is to design a filter such that, for the admissible random measurement missing, stochastic disturbances, norm-bounded uncertainties as well as stochastic nonlinearities, the error dynamics of the filtering process is exponentially mean-square stable. By using the linear matrix inequality (LMI) method, sufficient conditions are established that ensure the exponential mean-square stability of the filtering error, and then the filter parameters are characterized by the solution to a set of LMIs. Illustrative examples are exploited to show the effectiveness of the proposed design procedures.", "authors": ["Guoliang Wei", "Zidong Wang", "Huisheng Shu"], "n_citation": 281, "references": ["107debb0-8a08-444b-85cf-2a036c07d4b2", "321eba93-ee1f-4bb3-b962-ba2c9b48dad3", "415e66a9-3d62-411c-9736-467b62457df6", "64112ce5-2e46-4b8b-b6fb-f1a46c821e9a", "8074db5e-0445-4a35-98b0-0d2423838ed2", "82ab6448-7cf2-42e2-a71d-57ad9d24d92a", "bc877106-ea29-406e-8719-1d15f3d02400", "c8bceca2-d9b5-4958-8739-1aafd2d1616d", "f2d7d14b-bd97-4157-8cba-32dd6aff38a5", "fcf4075d-0cda-4ac6-b3e9-9b08594c744b"], "title": "Brief paper: Robust filtering with stochastic nonlinearities and multiple missing measurements", "venue": "Automatica", "year": 2009, "id": "89fc2a83-57d5-4df3-8205-ce46d2b236f9"}
{"abstract": "Mobile Ad Hoc Networks (MANETs) are composed of a set of communicating devices which are able to spontaneously interconnect without any pre-existing infrastructure. In such kind of networks, broadcasting becomes an operation of capital importance for the own existence and operation of the network. Optimizing a broadcasting strategy in MANETs is a multi-objective problem targeting three goals: reaching as many devices as possible, minimizing the network utilization, and reducing the duration time of the broadcasting process. In this paper, we study the fine-tuning of broadcasting strategies by using a cellular multi-objective genetic algorithm (cMOGA) which computes a Pareto front of solutions to empower a human designer with the ability of choosing the preferred configuration for the network. We define two formulations of the problem, one with three objectives and another one with two objectives plus a constraint. For our tests, a benchmark of three realistic environments for metropolitan MANETs has been defined. Our experiments using a complex and realistic MANET simulator reveal that cMOGA is a promising approach to solve the optimum broadcasting problem.", "authors": ["Enrique Alba", "Bernab\u00e9 Dorronsoro", "Francisco Luna", "Antonio J. Nebro", "Pascal Bouvry", "Luc Hogie"], "n_citation": 99, "references": ["0b50946c-c7bd-436e-b943-cf964498e3a8", "1d236b00-209e-4fdd-8670-81846f4169eb", "1f5b4b74-9c6f-43c8-b490-447ae33d6157", "622f962e-f94f-4287-987d-5d41adda8601", "63f921d3-eca5-4985-a3f3-06ca235229fe", "65d5ccdc-7022-45b0-adf9-0385273b1283", "6cc8c9bb-0b17-401e-bc56-a5a17851ee7b", "72018370-f0a0-4471-aa19-3fa31c994ee8", "779c96d1-210e-47fd-bfe0-cc60208340de", "8b902577-bda2-4bd2-95d5-edfc434adee7", "9f9332c3-e3f4-4b52-9786-2866c291f65f", "ec2274b4-6f06-40fd-b04e-51068aca7721", "f81a4b32-88c2-4b93-8c85-26511c679b9d", "ff064ff6-996c-413d-999b-c62b9c293ad2"], "title": "A cellular multi-objective genetic algorithm for optimal broadcasting strategy in metropolitan MANETs", "venue": "Computer Communications", "year": 2007, "id": "4bb874a8-ef7f-46d7-9d14-88e749d9b6c1"}
{"abstract": "Abstract   The number of people getting in and out of a bus is an important parameter to allocate the proper number of buses for each connection-line of a public transport service. On the other hand, the correct distribution of the available buses over the different paths, is fundamental to obtain an optimization of the whole transport network, and to reduce costs. In this paper, an automatic system using dynamic image sequence processing to count people getting in and out of a bus is presented. Some fast algorithms are used to detect motion, estimate its direction, and validate the presence of moving people. The system can deal with vibrations, lighting fluctuations and environmental variations. The main advantages are the execution speed and the reliability of the counting process, is performed correctly even if people flow in a chaotic and very clustered way.", "authors": ["Franco Bartolini", "Vito Cappellini", "Alessandro Mecocci"], "n_citation": 36, "references": ["8349d797-4006-445b-a0d5-bb58395f0860", "c349411e-b528-42ba-b046-b2598b22fff7", "c7e45d01-93dc-4912-a686-9191d1a91e81", "d755208e-425d-4f3e-b9c6-8ff4be136c13"], "title": "Counting people getting in and out of a bus by real-time image-sequence processing", "venue": "Image and Vision Computing", "year": 1994, "id": "acdc5fee-0edf-440b-8f72-de68471ddb8d"}
{"abstract": "This paper describes the design of an interactive system for the semi-automatic transformation of FORTRAN 77 programs into parallel programs for the SUPERNUM machine. The system is characterized by a powerful analysis component, a catalog of MIMD and SIMD parallelization transformations, and a flexible dialog facility. It contains specific knowledge about the parallelization of an important class of numerical algorithms.", "authors": ["Hans P. Zima", "Heinz-J Bast", "Michael Gerndt"], "n_citation": 439, "references": ["026511da-cdf8-410c-afbb-1c2aa47e3ae3", "0a5782c5-80f5-49ea-aa26-71209897e19e", "1a1c611b-7f6d-4584-9799-4c2935463fb3", "4471935f-8285-4408-bf32-e6db36e0d9f3", "5c798661-8c7a-46d0-ab1f-3f1966546e0a", "85fa35f5-b583-44b5-a870-b122f2335258", "b276bee4-12cf-47f1-9667-f1c4a30dbba5", "b9c0442d-b702-4caa-8000-706bd9c132a5", "bea8e17c-2307-429d-a0d7-779c2f67ab57", "dc1974e3-a7bd-4bd4-89e4-9ace37130d68", "fecc9394-c6a5-4023-ab8e-23029138de77"], "title": "SUPERB: A tool for semi-automatic MIMD/SIMD parallelization\u2606", "venue": "parallel computing", "year": 1988, "id": "a752294f-3584-471c-b6f0-e5cffe601db5"}
{"abstract": "The development of practical, localization algorithms is probably the most needed and most challenging task in wireless ad-hoc sensor networks (WASNs). Localized algorithms are a special type of distributed algorithms where only a subset of nodes in the WASN participate in sensing, communication, and computation. We have developed a generic localized algorithm for solving optimization problems in wireless ad-hoc networks that has five components: ( i ) data acquisition mechanism, ( ii ) optimization mechanism, ( iii ) search expansion rules, ( iv ) bounding conditions and ( v ) termination rules. the main idea is to request and process data only locally and only from nodes who are likely to contribute to rapid formation of the final solution. The approach enables two types of optimization: The first, guarantees the fraction of nodes that are contacted while optimizing for solution quality. The second, provides guarantees on solution qualities while minimizing the number of nodes that are contacted and/or amount of communication. The localized optimization approach is applied to two fundamental problems in sensor networks:  location discovery  and  exposure -based coverage. We demonstrate its effective-ness on a number of examples", "authors": ["Seapahn Meguerdichian", "Sasha Slijepcevic", "Vahag Karayan", "Miodrag Potkonjak"], "n_citation": 263, "references": ["06d5ee43-254e-4c7c-a401-b6bc29b08579", "0ee82a7e-46ff-4d6c-bf90-5ec6ab8c43b3", "1027598e-b6bd-4218-94e4-849b6c502a99", "136c4780-2f25-4068-90a5-aed6afaf2890", "2b53a7fd-c6f4-461c-801f-bb0c206a172a", "3023929a-c93e-49c5-b03f-7fb0414d94df", "32b7988a-f873-44c9-bacb-0d660fe12f01", "3657876a-6f24-47e3-bbba-62e4b3f7ab05", "47cc806c-a905-4355-9bfa-d1a49bf7034b", "4ad0f79e-f73a-457b-9a42-252e953fb61a", "4f5530bf-de86-4f1d-a55f-24202a7aa691", "542b2f0c-9f74-49b6-9a87-1eb932b77063", "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b", "5f0e3bf6-a29f-456d-81be-f4c89bd62912", "5fd22977-137c-4b3b-904c-f05e02f4fb31", "6500989e-b1e1-4b02-a921-21ec25685b73", "89253643-14dd-4793-b95a-a54bc59e72ff", "afc06b7c-7fb3-4f88-942b-3076ed77920e", "b3d4dca5-2287-4652-8103-8f362fc79627", "be14f3b9-556f-4361-816c-8a66c75f34a3", "dcb26109-fb57-4942-83d8-3d15540d83e6"], "title": "Localized algorithms in wireless ad-hoc networks: location discovery and sensor exposure", "venue": "mobile ad hoc networking and computing", "year": 2001, "id": "310fcebe-c94f-4af6-8547-879ed732778d"}
{"abstract": "Boolean satisfiability is probably the most studied of the combinatorial optimization/search problems. Significant effort has been devoted to trying to provide practical solutions to this problem for problem instances encountered in a range of applications in electronic design automation (EDA), as well as in artificial intelligence (AI). This study has culminated in the development of several SAT packages, both proprietary and in the public domain (e.g. GRASP, SATO) which find significant use in both research and industry. Most existing complete solvers are variants of the Davis-Putnam (DP) search algorithm. In this paper we describe the development of a new complete solver, Chaff which achieves significant performance gains through careful engineering of all aspects of the search-especially a particularly efficient implementation of Boolean constraint propagation (BCP) and a novel low overhead decision strategy. Chaff has been able to obtain one to two orders of magnitude performance improvement on difficult SAT benchmarks in comparison with other solvers (DP or otherwise), including GRASP and SATO.", "authors": ["Matthew W. Moskewicz", "Conor F. Madigan", "Ying Zhao", "Lintao Zhang", "Sharad Malik"], "n_citation": 3886, "references": ["24368035-5db2-4d01-b231-75582d8f7d0a", "2b8bae9d-40c1-4def-85c9-858688cac846", "3e5d18f4-a087-4eda-9d3f-96ae80cfd094", "4ec23a89-145e-4575-910a-b8c6c395c570", "527dd478-3ad0-494c-8c3d-3a5ac282f20e", "575b0b79-a1a9-485d-beb1-9a5344a6c8b2", "6da33f3e-bb59-4b0f-843a-25ba8541402d", "72b48de1-1b35-4e46-b05f-c66baa9dd457", "74703f80-bea9-4f83-910a-ff90285462b5", "7993cb55-046f-409e-bb5a-bb4b6f06e222", "81c6882d-1e6e-4757-b839-283520e94519", "8590b0eb-aa82-41d0-b50a-f0942ca1f658", "8ac3941f-4b9d-4cc6-bcd2-941653ea1579", "8c3cafc2-667a-4d43-b1a4-8fbfbfd902cc", "8d6dc616-8728-49a3-8962-71a2530d16bc", "94a54cdb-24cb-401c-9f12-b6e6e97d9cfe", "9d1ed045-51bd-44ee-8e2e-a370b02b4aae", "a9d0be6b-d4e5-4d78-bc9e-15501c4c9813", "ac39dba5-04ee-4ac3-9cc0-75bab50ad629", "b265a7bf-5e62-4626-a375-6c88f0ca9f4c", "b404f701-5c40-4d66-8ab0-4b74af40d9eb", "b51aef16-825c-479c-9cc8-36480e020143", "b5edf6d3-9177-4c78-aaf8-6171992fafaf", "c7635f59-061c-42f9-b956-a5542649c7b6", "c77fa96f-1a60-444c-ac23-d65ad48f68fb", "c9d38247-83ba-4f7c-979e-47a4ac52da04", "cf7f48dd-fc88-4f47-8f8e-f7b24e5de011", "d8d2eee8-8c8a-4ede-9b70-42dc155c34ba", "e8df1a74-0e2f-475a-ad50-33d398d89150", "ec59a0e8-5c61-4b20-8708-0a7c2a195977", "f5de6b41-0df8-4270-8211-a67a081dad45", "f72a4f45-05ec-4031-a4aa-ac29fdb4ef74", "f8c97eca-bf90-4c18-8e7f-44b831d0a995", "facd8e57-ecb8-4bfe-967c-8ffe059822bb", "fc17d09d-d231-45e5-b770-832ad81b7b0e", "ffb4183d-259e-4654-9b09-2368e49ded05"], "title": "Chaff: engineering an efficient SAT solver", "venue": "design automation conference", "year": 2001, "id": "9d826763-53f1-4bfd-a7f9-6a27fc26a8ae"}
{"abstract": "Since their discovery by Mandelbrot (The Fractal Geometry of Nature, Freeman, New York, 1977), fractals have experienced considerable success in quantifying the complex structure exhibited by many natural patterns and have captured the imaginations of scientists and artists alike. With ever-widening appeal, they have been referred to both as \u201cfingerprints of nature\u201d (Nature 399 (1999) 422) and \u201cthe new aesthetics\u201d (J. Hum. Psychol. 41 (2001) 59). Here, we show that humans display a consistent aesthetic preference across fractal images, regardless of whether these images are generated by nature's processes, by mathematics, or by the human hand.", "authors": ["Branka Spehar", "Colin W. G. Clifford", "Ben R. Newell", "R. P. Taylor"], "n_citation": 185, "references": ["1c745079-13ac-475b-8ec6-6aacbe60f287", "d12c8fca-a82c-45db-b29c-8fc7a47fce2e"], "title": "Universal aesthetic of fractals", "venue": "Computers & Graphics", "year": 2003, "id": "d95d5683-a37c-4a89-8f68-2ecb27c10750"}
{"abstract": "In cellular systems, there is usually an overlap cell coverage area (area covered by two or more base stations) which has valuable practical applications: soft handoff is an important feature of CDMA systems, and in hard handoff, the overlap area allows the queuing of handover requests as a handover prioritization scheme. While an extensive research effort has been done to model the terminal residence time in a cell and the channel holding time, the sojourn time in the overlap area is a topic that still requires further study. We propose a model of the sojourn time in the overlap area, along with a novel numerical method to derive its probability distribution. The obtained results show that the common assumption of exponential distribution for this time is not suitable, whereas it can be satisfactorily fitted by the hyper Erlang distribution.", "authors": ["Vicent Pla", "Vicente Casares-Giner"], "n_citation": 18, "references": ["23cf3ffc-5131-40a8-86c5-dad03f7f31e9", "3de86707-67a7-4dd9-b97a-e814a998c99e", "4746d63c-040e-4f50-b9ee-3553798645f3", "4d83ad56-0066-4de8-85fd-56f5b281b756", "888d7c80-218d-4a3a-9058-33e20520f1e9", "b32ded6f-5a4f-48eb-b4dc-540bb7dd240b", "bc692d04-3db3-489c-84c6-acadc79f99cb", "c6ac2e21-3449-44d9-b951-8b725afc6e45", "d3b2b7d7-1dbd-4f1e-b5fe-33a8a9674bd3"], "title": "Analytical-numerical study of the handoff area sojourn time", "venue": "global communications conference", "year": 2002, "id": "81a38fe0-b3a4-4716-b14d-d835b4bc1962"}
{"abstract": "Identity-based signcryption (IBSC) is a cryptographic primitive which combines both the functions of identity-based signature and identity-based encryption in a single logical step, but with the cost of computation and communication significantly less than those needed by the signature-then-encryption approach. The first proposal Yu et\u00a0al. (2009)\u00a0[12] for IBSC schemes without random oracles and its improvement Zhang (2010)\u00a0[15] were found insecure. Recently Li and Takagi (2011)\u00a0[16] presented an improved IBSC, but at the price of large signcryptext expansion and more exponentiation computation.#R##N##R##N#In this paper we reconsider the first (but insecure) IBSC proposal, and find that a small modification will result in a secure IBSC. Unlike that of Li and Takagi, our scheme does not sacrifice the bandwidth and computation efficiency to achieve the security goals. We use the proof techniques of Li and Takagi to prove in the standard model its indistinguishability against adaptive chosen ciphertext attack and existential unforgeability against adaptive chosen message attack. Through comparison of computational cost and communication overhead, our scheme is amongst the most efficient IBSC schemes without random oracles.", "authors": ["Xiangxue Li", "Haifeng Qian", "Jian Weng", "Yu Yu"], "n_citation": 23, "references": ["1e377011-b710-47da-9649-b65ca6f25433", "22eb6420-86e4-4b27-91e3-d957f6bb113d", "30ccf900-7f13-4b41-8743-39732cb887fa", "3ce6fb93-ff1f-46de-b16d-8cf02871a990", "4934c299-82dd-45bd-9696-8857ccec97f1", "82c5715c-5a98-4248-beb3-853e92c83096", "b05ed42c-5def-4b36-a22f-8915361c2af2", "b10fd24d-6a42-4821-9517-da6d1e14b17b", "b50bba47-f2d0-445a-ba90-a97a61cd0039", "cfced88a-c1fb-4cdf-86bc-6fd376734e15", "ea1d8311-d845-4558-a087-3f3a1f1eb671"], "title": "Fully secure identity-based signcryption scheme with shorter signcryptext in the standard model", "venue": "Mathematical and Computer Modelling", "year": 2013, "id": "9b14ae10-c41d-42e8-8d18-233fac6d480c"}
{"abstract": "Proofs by induction are important in many computer science and artifical intelligence applications, in particular, in program verification and specification systems. We present a new method to prove (and disprove) automatically inductives properties. Given a set of axioms, a well-suited induction scheme is constructed automatically. We call such and induction scheme a test set. Then, for proving a property, we just instantiate it with terms from the test set and apply pure algebraic simplifications to the result. This method needs no completion and explicit induction. However it retains their positive features, namely, the completeness of the former and the robustness of the latter. It has been implemented in the theorem-prover SPIKE.", "authors": ["Adel Bouhoula", "Emmanuel Kounalis", "Micha\u00ebl Rusinowitch"], "n_citation": 100, "title": "Automated Mathematical Induction", "venue": "Journal of Logic and Computation", "year": 1995, "id": "2ddee9fa-ad59-4d1a-99b9-35c085aa31c9"}
{"abstract": "Non-determinism in program execution can make program development and debugging difficult. In this paper, we argue that solutions to this problem should be on-demand, portable and parameterless. On-demand means that the programming model should permit the writing of non-deterministic programs since these programs often perform better than deterministic ones for the same problem. Portable means that the program should produce the same answer even if it is run on different machines. Parameterless means that if there are machine-dependent scheduling parameters that must be tuned for good performance, they must not affect the output.   Although many solutions for deterministic program execution have been proposed in the literature, they fall short along one or more of these dimensions. To remedy this, we propose a new approach, based on the Galois programming model, in which (i) the programming model permits the writing of non-deterministic programs and (ii) the runtime system executes these programs deterministically if needed. Evaluation of this approach on a collection of benchmarks from the PARSEC, PBBS, and Lonestar suites shows that it delivers deterministic execution with substantially less overhead than other systems in the literature.", "authors": ["Donald Nguyen", "Andrew Lenharth", "Keshav Pingali"], "n_citation": 35, "references": ["0b0fc983-bc68-4d1e-8f57-14ef9816b297", "1e777dd9-8d78-43d1-a5ed-acb86d198c83", "2a1a717b-356a-44f6-a7cb-749ebcece1ef", "3c4bc7bd-7e63-4dfb-8438-a5be60c8bff1", "3da0a127-5eff-4706-9109-4ae166d9e232", "59e8e711-4ce2-454c-916c-5a070f573ec1", "5c159b20-e221-4bdb-b7f9-b811a81e5d99", "61aeacf0-ef74-4c91-87a5-2fe22e30753d", "710748f5-8032-4fa6-9204-0aff13df12ec", "776ea667-15f5-4b54-984d-d4116f74701e", "81a796c2-d91a-4749-aaa2-993d72474a72", "897fbd3b-d963-4fa1-aacc-8a6324391b91", "a53254d3-f77a-4bb4-ad71-c15d5d7a315f", "a676a66d-37ff-4651-bb43-96250c5e03a3", "af4cc774-cab4-4888-9bcf-f29449a58e56", "bcfb1417-4781-4c66-a6a0-ca2c8e1261a6", "cd8a32a8-0642-484f-9669-9f05dad17cce", "d2ebc645-06b6-427b-b083-952b3a6feef5", "e17f43c5-7b29-4ea4-92be-b309c56289ee", "f5de6b41-0df8-4270-8211-a67a081dad45", "f7e7ca9d-467f-448e-aa99-2dfd4935a8ed", "f902cc0f-6c80-42cc-a96a-168819d444b8"], "title": "Deterministic galois: on-demand, portable and parameterless", "venue": "architectural support for programming languages and operating systems", "year": 2014, "id": "fcbc232e-3754-473e-8985-5163eeaee765"}
{"abstract": "This paper presents a method for real-time 3D hand tracking in images acquired by a calibrated, possibly moving stereoscopic rig. The proposed method consists of a collection of techniques that enable the modeling and detection of hands, their temporal association in image sequences, the establishment of hand correspondences between stereo images and the 3D reconstruction of their contours. Building upon our previous research on color-based, 2D skin-color tracking, the 3D hand tracker is developed through the coupling of the results of two 2D skin-color trackers that run independently on the two video streams acquired by a stereoscopic system. The proposed method runs in real time on a conventional Pentium 4 processor when operating on 320times240 images. Representative experimental results are also presented", "authors": ["Antonis A. Argyros", "Manolis I. A. Lourakis"], "n_citation": 43, "references": ["10253a0d-227c-4ccd-b34c-9e8d05f880ba", "1f77def6-2b9a-4384-8f43-1e55af95ae78", "387c51d5-f2b3-4b1f-8b30-1088147aff8b", "44d91dea-fe91-408d-810c-63e5889f7c8a", "56cd3fdb-73ff-431e-8945-d673f9469f33", "64fb9cdf-4088-4800-9b07-10f8c6a833cb", "67cfb6a4-846a-4f7d-9fca-1fc9337663cd", "89de68ef-e557-404b-87da-8cd81c61fca2", "96986f12-78a9-4024-bdc6-b157177b6c9d", "a7a01782-8e14-4dd6-9336-60718abbfc0b", "c4283157-ef58-4cf5-9b95-7e6e76bea77e", "ceb3f0ba-9e88-47f6-a173-40dba1f7271c", "e9939b8b-6fcb-4ded-ac64-43c7fdfb52d6"], "title": "Binocular Hand Tracking and Reconstruction Based on 2D Shape Matching", "venue": "international conference on pattern recognition", "year": 2006, "id": "51476f59-d131-4a4c-8d8b-c5c7bfb4e7e8"}
{"abstract": "Lotteries with the unique maximum property and the unique winner property are considered. Tight lower bounds are proven on the domain size of such lotteries.", "authors": ["Eyal Kushilevitz", "Yishay Mansour", "Michael O. Rabin"], "n_citation": 4, "title": "On Lotteries with Unique Winners", "venue": "SIAM Journal on Discrete Mathematics", "year": 1995, "id": "3a0f7fdd-77f9-4bfe-b9c5-1f3ab5b5aaa4"}
{"abstract": "Treatment management in critically ill patients needs to be efficient, as delay in treatment may give rise to deterioration in the patient's condition. Ventilator-associated pneumonia (VAP) occurs in patients who are mechanically ventilated in intensive care units. As it is quite difficult to diagnose and treat VAP, some form of computer-based decision support might be helpful. As diagnosing and treating disorders in medicine involves reasoning with uncertainty, we have used a Bayesian network as our primary tool for building a decision-support system for the clinical management of VAP. The effects of antibiotics on colonisation with various pathogens and subsequent antibiotic choices in case of VAP were modelled in the Bayesian network using the notion of causal independence. In particular, the conditional probability distribution of the random variable that represents the overall coverage of pathogens by antibiotics was modelled in terms of the conjunctive effect of the seven different pathogens, usually referred to as the noisy-AND gate. In this paper, we investigate generalisations of the noisy-AND, called noisy threshold models. It is shown that they offer a means for further improvement to the performance of the Bayesian network.", "authors": ["Stefan Visscher", "Peter J. F. Lucas", "Marc J. M. Bonten", "Karin Schurink"], "n_citation": 50, "references": ["05a79478-6f20-4bd4-879c-562f03801c81", "13d447d7-96c0-41ed-9c72-de18f89dacd6", "1484b028-2c2d-4e21-a20c-99ebc387454c", "2731c1ba-146f-486e-b0a1-9894c26e69bb", "4762f5b0-e07d-414d-a604-a283a68864b4", "4b1722c2-0bff-4224-8e37-0fa6455ae487", "60601cb8-b29a-43a4-b4d4-207c19e7b89f", "67a91b82-2442-405e-98af-247eb76523ce"], "title": "Improving the therapeutic performance of a medical bayesian network using noisy threshold models", "venue": "", "year": 2005, "id": "0d87de03-dfff-4705-96e9-60416de9a081"}
{"abstract": "At the German Distance Learning University, collaborative synchronous exercises have been recently identified by students and teachers as an important future form of collaborative learning in the university's virtual learning space. The main requirements of collaborative exercises in a distance learning university include support for preparation of exercises, learning group management, collaborative learning sessions, and learning management. We support such collaborative exercises in the FUB system by providing groupware tools for each phase of collaborative exercises. Especially important is the support of complex problem solving processes. Results of a trial use indicate that our approach works, and identify some needs further improvement. The implications of our approach and our experiences for the design of next generation learning platforms are discussed.", "authors": ["J\u00f6rg M. Haake", "Till Sch\u00fcmmer", "Anja Haake"], "n_citation": 20, "references": ["3504f662-bedf-4333-b73f-d4ead21f5acb", "404438d9-1099-483f-a120-2129a7521d7e", "4359d518-6b23-4824-b39b-de115f0dce1a", "4c2017f4-ccd0-45fd-8ae4-9f1e9158174e", "aa7b3494-001d-44c1-af74-9938b41956d4", "aef7ef83-cd33-43ef-856f-2245f46c703f", "bd1d57f9-2b04-4034-8c9d-b493f3ec6ed3", "c3abaac2-d5e2-405f-951e-01a995b8b60c"], "title": "Supporting collaborative exercises for distance education", "venue": "hawaii international conference on system sciences", "year": 2003, "id": "1c8e21e0-70cd-4a63-9662-9ee60038e0c7"}
{"abstract": "Abstract   Subsumption\u2014determining whether one concept is more general than another\u2014is known to be NP-hard for all reasonably expressive terminological logics, but, up to now, the decidability of subsumption for terminological logics used in current knowledge representation systems such as NIKL remained unknown. This paper shows that subsumption in the terminological logic of NIKL is undecidable and thus that there are no complete algorithms for subsumption or classification in NIKL.", "authors": ["Peter F. Patel-Schneider"], "n_citation": 124, "references": ["14a77a71-3e0c-41fd-87b7-2333d76f87d0", "153825db-12f6-488e-9cb3-3658927f8837", "216f0956-56fa-4263-b5bb-315e1209e99b", "3188ab63-993f-427d-9e78-50b76abc543b", "344e9826-8d3e-438d-8985-d8e357bf69f8", "c7167a94-b4ad-41a0-9ae8-27dc85ba744b", "d55b22d6-2cf2-48c2-ba9c-ae3cf440c3ad"], "title": "Undecidability of subsumption in NIKL", "venue": "Artificial Intelligence", "year": 1989, "id": "3cb33bf1-2787-4a94-a7d5-78931804d0a9"}
{"abstract": "ABSTRACT In order to properly calibrate an electronic camera for a variety of illuminants it is necessary to estimate the spectralsensitivity of the camera. This spectral characterisation is obtained by measuring a set of samples of known spectral reflectances and by inverting the resulting system of linear equations. In the presence of noise, this system inversion is not straightforward. We describe several approaches to this problem. In particular we show that the choice ofsamples is of great importance for the quality of the characterisation, and we present an algorithm for the choice ofa reduced number of samples.Keywords: Spectral sensitivity, image input device characterisation, metamerism, colour target design 1. INTRODUCTION For the colorimetric characterisation of electronic image input devices, it is a current practice to use standard colour targets such as the 1T8.7/2 chart and to apply analytical models for the mapping of the input device data into astandardised device independent colour space. The mapping function is typically obtained by minimising the meansquare error of a set of measurements by polynomial regression, see e.g. Berns,' Hardeberg et al.,2 as well as thesurveys by Johnson3 and Kang.4 An important limitation of such methods is that, for a given experimental setup ofthe lighting conditions and for a given choice of the illuminant, individual characterisation data have to be obtainedfor each type of input media, the failure to do this resulting in considerable errors due to metamerism. Furthermore,these methods are merely mathematical, they do not take into account the physical characteristics of the colourimage input device.For a more complete characterisation, the knowledge of the physical characteristics of the different optical and", "authors": ["Jon Yngve Hardeberg", "Hans Brettel", "Francis Schmitt"], "n_citation": 91, "title": "Spectral characterisation of electronic cameras.", "venue": "", "year": 1998, "id": "9358f678-5c3f-4165-9eb7-b1a5d97454bd"}
{"abstract": "A metamodel is used to define the abstract syntax (i.e., entities, attributes, and relations) of a Domain-Specific Modeling Language (DSML). In addition, a metamodel also defines constraints and static semantics that provide additional information about the modeling language beyond the abstract syntax. In many cases, the specification of a new metamodel is highly dependent on the designer's background and experiences. Thus, metamodel designs often differ from designer to designer, even for recurring design problems (i.e., there is more than one way to specify a modeling language with a metamodel). The quality of a metamodel design may also vary according to the designer's domain knowledge and modeling language expertise. To provide consistent solutions for recurring metamodel design issues, design patterns applied to metamodels may offer key insights, especially to new language designers who have less experience. In this paper, we motivate the need for design patterns for metamodels and provide a few examples of the concept.", "authors": ["Hyun Cho", "Jeff Gray"], "n_citation": 36, "references": ["5678bb4e-312a-4504-ac50-7e003f7abfb7", "71694e3a-11a9-4780-bce2-bcad0ccdab51", "7a926abd-3cdb-410d-a2c9-e23447601f12", "a579744f-929d-4ae5-891b-0212d3886147", "afb3701a-f62d-4442-91b2-7dc8293ec62a", "b652bf61-af9c-4032-b5bd-93d98acd56e1", "fb1f1efb-5a02-40c7-9ae8-b20483e669a1"], "title": "Design patterns for metamodels", "venue": "acm conference on systems programming languages and applications software for humanity", "year": 2011, "id": "2e3e415c-3bdc-4224-a9f4-f1bcf2285373"}
{"abstract": "A wide range of database applications manage time-varying data. Many temporal query languages have been proposed, each one the result of many carefully made yet subtly interacting design decisions. In this article we advocate a different approach to articulating a set of requirements, or desiderata, that directly imply the syntactic structure and core semantics of a temporal extension of an (arbitrary) nontemporal query language. These desiderata facilitate transitioning applications from a nontemporal query language and data model, which has received only scant attention thus far.  The paper then introduces the notion of  statement modifiers  that provide a means of systematically adding temporal support to an existing query language. Statement modifiers apply to all query language statements, for example, queries, cursor definitions, integrity constraints, assertions, views, and data manipulation statements. We also provide a way to systematically add temporal support to an existing implementation. The result is a temporal query language syntax, semantics, and implementation that derives from first principles.  We exemplify this approach by extending SQL-92 with statement modifiers. This extended language, termed ATSQL, is formally defined via a denotational-semantics-style mapping of temporal statements to expressions using a combination of temporal and conventional relational algebraic operators.", "authors": ["Michael H. B\u00f6hlen", "Christian S. Jensen", "Richard T. Snodgrass"], "n_citation": 87, "references": ["0e09d1cc-d530-42b4-a036-d2e2657f6aaf", "1f9d31e9-c9bd-4c05-9bec-92bcd47bc1a6", "30936503-0a68-40f4-ac6e-c3a750c62cf2", "44719a40-dde5-48a9-801e-99da803e8d47", "50293624-a1fb-44e3-b3c7-57c6413bfb94", "54d68b11-d5a1-480b-9902-4008e609d9a1", "607c05cf-df79-4b56-b6b4-8c6c008a7c24", "640ddf66-4fc2-4c62-bd93-45e3d141d2ad", "64fc6404-55f9-4a82-9800-6c49472d4295", "6776bc5d-2358-4d94-af8e-6bfdafc6df32", "6d414d60-113c-4b0f-86ae-d11cb9cdba32", "7cbeddd5-65f2-4ce1-a642-7837cd298af9", "83ccea67-9335-409e-80c2-44d2f25be8c1", "90e0e227-311b-42da-a144-b06f67d560de", "93157a4c-5d29-4ca2-97bd-d32f427676e0", "9505b840-176e-488a-bbfc-e488442e45e8", "9afafca1-2ddb-4338-a080-a9b93397e010", "9b77a1fe-654a-4bac-a420-479331e0b10d", "9c699356-9c62-460d-a6a2-4ccc88de879b", "a52c089c-9222-4085-91c7-93b217adc8a8", "ac799cbd-72c6-4f60-b41c-de2c6099df2a", "b63cf6e1-4dea-4cba-b4d4-7f05789d510a", "b8d398ef-111f-41c3-83b6-7b88c089f644", "b97e43de-3de2-4dd9-9c11-048b0d8b940e", "c987bba4-4202-4524-acf9-8f1920ef5387", "db348c25-fd66-4f91-b676-6d9402cefaa2", "dbe5ae2e-bbc0-4508-8df5-3ec95c784fa8", "e3ec3b5a-db81-4325-b30c-b670bd7c0e54", "e7d875ac-e3bf-4100-92a9-21642569614d", "f268e0c2-8154-475a-bfbc-3995be2140b5", "f52bc858-c6e8-4193-bb39-347349dd0783", "ff30cdc5-e1aa-454a-89f8-e5535f61047f"], "title": "Temporal statement modifiers", "venue": "ACM Transactions on Database Systems", "year": 2000, "id": "2d131a55-48fc-4315-b79f-dd9fcdf24ce6"}
{"abstract": "KEY WORDS AND PHRASES: fuzzy logic, fuzzy sets, first order predicate calculus, problem-solving systems, question-answering systems, resolution principle, uncertainty, completeness theorems", "authors": ["Richard C. T. Lee"], "n_citation": 381, "references": ["05047c5b-1e4c-42a0-8457-50a006cab718", "112eeff7-c265-4808-aef5-55f592540e40", "168bbfbf-bbdc-4d9b-9eac-da43f778c5a3", "18b2832b-8c62-4be9-9b16-b166601ba1c5", "a52526a3-cbf2-4677-b896-78f186c2137a", "b232ba92-71f8-45d7-a798-410a383143ff", "b6fd16e1-15d3-4c18-80cb-17f59af51c20", "c0a69970-4b14-492a-adcc-6928988a9f2a", "d917b682-6e42-4c13-9b09-3e107d93dd1e"], "title": "Fuzzy Logic and the Resolution Principle", "venue": "Journal of the ACM", "year": 1972, "id": "d2affa8b-810c-47b1-8e45-cd9f7a929811"}
{"abstract": "The robustness of peer-to-peer (P2P) networks, in particular of DHT-based overlay networks, suffers significantly when a Sybil attack is performed. We tackle the issue of Sybil attacks from two sides. First, we clarify, analyze, and classify the P2P identifier assignment process. By clearly separating network participants from network nodes, two challenges of P2P networks under a Sybil attack become obvious: i) stability over time, and ii) identity differentiation. Second, as a starting point for a quantitative analysis of time-stability of P2P networks under Sybil attacks and under some assumptions with respect to identity differentiation, we propose an identity registration procedure called self-registration that makes use of the inherent distribution mechanisms of a P2P network.", "authors": ["Jochen Dinger", "Hannes Hartenstein"], "n_citation": 133, "references": ["4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4", "51af4708-b81c-4362-b4ee-7bdf7ace609f", "532a17ef-5f37-4ead-9f4d-2fd31369966e", "5a310c77-7694-4f16-b291-834362bac909", "6fb25839-b544-4a4a-82ad-e61696df0799", "73246ea8-b105-488d-8473-47af4f1ad3c1", "a3a44806-1b80-4340-a0e2-b0be96f09fc8", "abd6a55f-f326-4e8d-9102-47c5309ec7f2", "d06f8723-1b89-4684-99c9-c1045ddfb85c", "e52af44f-5d8c-4cd3-b5e5-c6918e0b480f", "e944d388-c034-4419-bcdd-f671deebd211", "f14df1ed-e3e9-4348-9040-fc06e3411b95", "fedae089-5dc7-41b8-8454-579df5a68846"], "title": "Defending the Sybil attack in P2P networks: taxonomy, challenges, and a proposal for self-registration", "venue": "", "year": 2006, "id": "6e0b92e8-1cb1-4bcc-bb16-07b6d2ad95f3"}
{"authors": ["Rob Barrett", "Paul P. Maglio"], "n_citation": 122, "references": ["1b7418af-1aba-4090-bad4-0dd0e900f5aa", "2cceeaaf-b840-467a-a6c8-6be85dbb1dfe", "5f02e7c1-95dd-4c9b-b977-2f8bf079c296", "757bb786-cf86-407f-994b-5a5a4e0fe24c", "a02293cc-9a25-463e-a000-53f48aef1c70", "dddfbe50-c5c7-4fe7-8f92-02e8f10db47f", "e849a9b6-01b8-4fc5-8e91-3036b2b802ec", "f1011b3e-1a8f-4cd2-bdb8-d5b6dce8f77a"], "title": "Intermediaries: an approach to manipulating information streams", "venue": "Ibm Systems Journal", "year": 1999, "id": "eaacd40d-fca0-4968-af5d-c8410525caf8"}
{"abstract": "This paper describes a general approach to signal detection with uncertainty in signal and/or background distributions. Attention is restricted to binary decision problems where the hypotheses can be expressed as signal-present vs signal-absent, but otherwise the treatment is general. Many familiar results come out as special cases.", "authors": ["Harrison H. Barrett", "Craig K. Abbey"], "n_citation": 50, "references": ["80c53d7f-c4e7-454b-a0c5-eb9111260e32"], "title": "Bayesian Detection of Random Signals on Random Backgrounds", "venue": "information processing in medical imaging", "year": 1997, "id": "8de19684-44aa-42ef-98aa-305510cc7c1b"}
{"abstract": "A voxel-based method for flattening a surface in 3D space into 2D while best preserving distances is presented. Triangulation or polyhedral approximation of the voxel data are not required. The problem is divided into two main parts: Voxel-based calculation of the minimal geodesic distances between points on the surface and finding a configuration of points in 2D that has Euclidean distances as close as possible to these distances. The method suggested combines an efficient voxel-based hybrid distance estimation method, that takes the continuity of the underlying surface into account, with classical multidimensional scaling (MDS) for finding the 2D point configuration. The proposed algorithm is efficient, simple, and can be applied to surfaces that are not functions. Experimental results are shown.", "authors": ["Ruth Grossmann", "Nahum Kiryati", "Ron Kimmel"], "n_citation": 52, "references": ["016677ef-9c85-4006-ad5c-05f3f8c759ad", "2b5051e6-6e1b-4169-a8b1-9ff2c5b26f97", "6987be66-e662-40a5-bf6c-d29e47d1acc7", "771f1df6-a252-48ad-bcd3-2afd04df006c", "83414b2a-ff37-44e1-909d-c7db3c1a4187", "8d74dcf1-88e9-4fc9-8f91-015c4ae30d6c", "b204577e-771c-4a77-bd97-586d7562f1a1", "b77f5d2a-b99f-4f38-a142-deedd685d77a", "dff823b8-6efa-4ef4-b1f1-21f237f81a79", "e4392102-2856-4d70-83e2-1ccadb3f8df3", "e72e2d54-5221-4abb-9d3a-ca4ef6236581", "ec188295-94e4-4655-b2d2-3842fa151488", "f50cd2d3-0753-4ab9-b9a7-b2b59c35a056"], "title": "Computational surface flattening: a voxel-based approach", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2002, "id": "f8916fb1-8c7e-41ff-aa05-bbf58ee3885d"}
{"abstract": "Effective, professional quality work is essential for success in many fields of endeavor, yet software engineering students often gain, at best, a limited and cursory level of expertise through their normal curricula. In particular, students often fall short in the areas of communication and project tracking. This paper discusses an approach that has proved successful in two graduate level software engineering courses. The approach requires them to produce professional grade documents and to use earned value management techniques for keeping track of their work. Two key elements of the approach are to set an expectation for professional grade student work products and to provide opportunities for the student to produce drafts that are rigorously reviewed.", "authors": ["Dennis J. Frailey"], "n_citation": 50, "references": [], "title": "Bringing Realistic Software Engineering Assignments to the Software Engineering Classroom", "venue": "", "year": 2006, "id": "9b6e127b-9dd5-4f06-a86b-fcfd260ad8ff"}
{"abstract": "A Bayesian filter for rotation groups in 2D and 3D is derived. The prior, propagator, and measurement probability densities are all assumed to be bandlimited functions on SO(2) or SO(3), expressed as a Fourier series on these compact Lie groups. The posterior, which has a higher bandlimit, is computed and then low-pass filtered, resulting in a bandlimited approximation. The benefits and drawbacks of the Fourier approach presented here are examined in contrast to the Gaussian approach designed for small error covariances. While the Gaussian approach is much faster, it breaks down for large error covariances. The point where the Gaussian approach breaks down is analyzed with the Fourier method, indicating the range of error sizes where the switch to Fourier methods is required.", "authors": ["Jin Seob Kim", "Gregory S. Chirikjian"], "n_citation": 3, "title": "Bayesian filtering for orientational distributions: A fourier approach", "venue": "", "year": 2015, "id": "8f05e470-227b-4013-9329-7d7b4ad27947"}
{"abstract": "The state-of-the-art of local search heuristics for the traveling salesman problem (TSP) is chiefly based on algorithms using the classical Lin-Kernighan (LK) procedure and the stem-and-cycle (S&C) ejection chain method. Critical aspects of implementing these algorithms efficiently and effectively rely on taking advantage of special data structures and on maintaining appropriate candidate lists to store and update potentially available moves. We report the outcomes of an extensive series of tests on problems ranging from 1000 to 1,000,000 nodes, showing that by intelligently exploiting elements of data structures and candidate lists routinely included in state-of-the-art TSP solution software, the S&C algorithm clearly outperforms all implementations of the LK procedure. Moreover, these outcomes are achieved without the use of special tuning and implementation tricks that are incorporated into the leading versions of the LK procedure to enhance their computational efficiency. y.", "authors": ["Dorabela Gamboa", "C\u00e9sar Rego", "Fred Glover"], "n_citation": 50, "references": ["0770d8f8-b856-48a2-9bd5-3dd876cdc4da", "28ef9ca1-5514-4df5-9af3-4808b03e8871", "36051f29-9f0a-47cc-a241-d905a9c3fd08", "529fc0c1-8b0b-4d30-a985-1ef0a7b05d33", "59c19773-e3e6-4e81-9afa-b542ef8c2529", "69129e1f-70c7-4af8-b0e3-3d986d6057ff", "95a3854f-12e5-4c2e-a143-bab6bb054a6b", "9a116e60-b816-413a-a801-b234c3d81a46", "b89d3dae-abf8-45e1-b702-17eff570e286", "dcdb2bc3-f976-4435-80e7-adad286d4cf1", "e260bcfb-dda0-43da-8f0b-4e56f39eaa9f", "f86ac5ed-6f45-4151-802b-7189f3df9233"], "title": "Implementation analysis of efficient heuristic algorithms for the traveling salesman problem", "venue": "Computers & Operations Research", "year": 2006, "id": "5bc9565c-3a6b-4ad0-9711-e2bcfc7b8cd5"}
{"abstract": "Distributed teams face the challenge of staying connected. How do team members stay connected when they no longer see each other on a daily basis? What should be done when there is no coffee corner to share your latest exploits? In this paper we evaluate a microblogging system which makes this possible in a distributed setting. The system, WeHomer, enables the sharing of information and corresponding emotions in a fully distributed organization. We analyzed the content of over a year of usage data by 19 team members in a structured fashion, performed 5 semi-structured interviews and report our findings in this paper. We draw conclusions about the topics shared, the impact on software teams and the impact of distribution and team composition. Main findings include an increase in team-connectedness and easier access to information that is traditionally harder to consistently acquire.", "authors": ["Kevin Dullemond", "Ben van Gameren", "Margaret-Anne D. Storey", "Arie van Deursen"], "n_citation": 17, "references": ["023338b5-6441-4b2c-88ce-15fc011c3fce", "15a69081-0624-4563-a263-80ad0a1766be", "28f1d245-497c-4743-9cf4-6b76f454fcb9", "6da8118d-7109-48a8-a871-2b9fc91c2c29", "807701ce-f549-48c5-a670-069b1aaca0d6", "86667d77-a67c-4843-9ee1-5c9070cf07cf", "91999ffb-89f1-4fc0-8b41-ffda2845d0e7", "954fc7af-d7d8-4d8b-97ca-b91d86b7e0a9", "9e5b7f40-7774-4ab7-99c1-874b085223a8", "c12a61f0-64dd-4a55-8162-4d3879531677", "d2738c3d-028f-4b84-9aaa-dd8f764e5909", "da380ec6-32df-49d3-a4aa-ca8edd55f857", "e834b292-0191-411b-9707-a433542b6753", "ed05629a-dfa9-414e-ae19-704a8865f737", "ef5e5223-9d71-453c-adbc-41da4c263c73", "f42b2290-226d-4163-897c-7329c1d0d575", "fc9e5217-51fd-457d-9d09-680925082f56"], "title": "Fixing the \u2018Out of sight out of mind\u2019 problem one year of mood-based microblogging in a distributed software team", "venue": "mining software repositories", "year": 2013, "id": "3542f665-0663-479d-b7e4-aaae522995fe"}
{"abstract": "A reduced-order globally convergent observer to estimate the depth of an object projected on the image plane of a camera is presented, assuming that the object is planar or has a planar surface and the orientation of the plane is known. A locally convergent observer can be obtained when the plane unit normal is unknown, and the latter is estimated together with the depth of the object. The observer exploits the image moments of the object as measured features. The estimation is achieved by rendering attractive and invariant a manifold in the extended state space of the system and the observer. The problem is reduced to the solution of a system of partial differential equations. The solution of the partial differential equations can become a difficult task, hence it is shown that this issue can be resolved by adding to the observer an output filter and a dynamic scaling parameter.", "authors": ["Mario Sassano", "Daniele Carnevale", "Alessandro Astolfi"], "n_citation": 12, "references": ["4d130722-2556-4704-a445-18d0e32d8a0d", "62feb8b5-e46d-4eb3-aed5-0ba92b5f0ed1", "7c61d0bf-920e-4f5b-a15e-238b4bad929d", "7cd425ce-b540-42e2-b3be-ec516b6b5543", "8b706a1c-426c-41b4-86e4-c7727cf33713", "8d49da1c-64e5-4907-ac3d-ffcd8b13d1c7", "ceead810-0287-4d6a-b3e0-dfb11049e4b4", "dbf78aff-2d5f-4caa-a797-2719ae1e4812", "e7969468-2394-4c7a-b24e-942741fcb153", "e9e50026-16c9-4969-b058-18ecfb225b49", "ed37b7b4-2f52-4d36-a53e-a5b5f958f386", "effa5816-7bd6-4302-9d3d-7e6c845e7b33", "f3868715-abb3-4115-b57b-dc6d874f02d1"], "title": "Brief paper: Observer design for range and orientation identification", "venue": "Automatica", "year": 2010, "id": "9c2f0bf4-3344-4db5-9cb5-efc4f8d7cefa"}
{"abstract": "While sleep states have existed for mobile devices and workstations for some time, these sleep states have not been incorporated into most of the servers in today's data centers. High setup times make data center administrators fearful of any form of dynamic power management, whereby servers are suspended or shut down when load drops. This general reluctance has stalled research into whether there might be some feasible sleep state (with sufficiently low setup overhead and/or sufficiently low power) that would actually be beneficial in data centers.", "authors": ["Anshul Gandhi", "Mor Harchol-Balter", "Michael A. Kozuch"], "n_citation": 72, "references": ["095d680a-628c-4c69-86c2-e4fc4410e16d", "0fdf952f-5e22-4fd2-be24-c739cf4d9b15", "6668401c-dc1d-46bd-926d-96c24e93453b", "6d64c632-b552-4a0b-9cd6-32e7220f2d3c", "7d474b86-3a9b-4e43-bb76-709630db3724", "82e05028-b3df-492a-9909-e4ea7b5a3e8a", "851200ac-5b42-4570-83e5-8b2d217bb10c", "911ca73e-d0fc-471f-97b9-e53c92c0d2bb", "a6b672a7-d0bb-4da1-8666-6eba3f77ae4d", "ad2166ad-c57e-4300-9eb2-8ca5368f6f1d", "b329e26e-aa0c-4669-8560-91bab673bf73", "bf643acf-cefb-404e-8e00-6f04c7747b6d", "c1f13d21-9542-4877-b2c3-28e364c68b0a", "c46b3a26-60af-4f1d-9486-9dbafb359c18", "c5c3fedf-833f-4ea3-9317-64b6c8f2dbe5", "c7f0ccf6-296a-4ce8-987b-1abc56a41c3f", "dc3235c0-2455-4411-8af0-9713052f5dfe", "e0c8849c-305e-49f6-be62-b153106f9cb4", "e19d7227-0976-46ac-b967-09509206191f", "e556d501-f8b0-4499-865a-cc900e7390f8", "ec51d5be-d7f4-4c9b-8ac2-c0d5d64100b6"], "title": "Are sleep states effective in data centers", "venue": "", "year": 2012, "id": "7c32b648-ea5e-4fb0-b41d-d2aff2a366ab"}
{"abstract": "In this paper, we consider the evolution of telephone networks from time-division multiplexing circuit switching to packet switching and, in particular, to packet switching-based on Internet Protocol (IP-supported telephony). We analyze IP-supported telephony design solutions by proposing a layered reference model in which each layer is associated to a subset of the functions that support telephony. We use the reference model to establish a terminology and a framework for the comparison of the design solutions. We group the design solutions in scenarios and compare them in terms of the reference model proposed. We then focus on IP telephony, in which IP is used in telephone company networks, and on Internet telephony, in which the Internet is used to support telephony. We show that they both can be seen as implementations of the same architecture, which consists of a set of components, associated to functions, and of the interactions among these components. We then consider the issue of voice-data integration and analyze the variety of design solutions that can be adopted to integrate voice and data.", "authors": ["Massimo Maresca", "Nicola Zingirian", "Pierpaolo Baglietto"], "n_citation": 50, "references": ["53f4000f-bceb-4dbf-a3d6-bb7fe14b9d37", "7b71de68-66aa-4713-97aa-f7260c65e7a3", "9842ab7a-f73e-45a4-addc-736008f4e117", "a1f419fb-0e64-4188-9b40-231a409fe304"], "title": "Internet protocol support for telephony", "venue": "Proceedings of the IEEE", "year": 2004, "id": "3f217570-202c-4be5-a81f-ea74084205e0"}
{"abstract": "Service composition is core to service oriented architectures. In the Web, mainstream composition is practiced in client-side or server-side mashups, such as providing visual widgets on top of Google Maps results. This paper presents an explicit, workflow based composition model for Web applications called Bite. In contrast with prior attempts to bring workflow capabilities to the Web environment, Bite can deal with data integration as well as interactive, asynchronous workflows with multi-party interactions, and is architected to support protocols currently in use by Web applications. The Bite development model is designed for simplicity and short development cycle by taking a scripting approach to workflow development.", "authors": ["Francisco Curbera", "Matthew J. Duftler", "Rania Khalaf", "Douglas Lovell"], "n_citation": 85, "references": ["1d691754-64ef-41cc-adf4-44efa3437b65", "5e0f09b6-9791-42a9-9a53-db086deb70b2", "8fe1240d-7fda-45a0-b62b-2fd0796a8712"], "title": "Bite: Workflow Composition for the Web", "venue": "international conference on service oriented computing", "year": 2007, "id": "fb0e5934-58cf-429b-b718-528ee993dc9d"}
{"abstract": "The emergence of a database technology in recent years has focused interest on the subject of data models. A data model is the class of logical data structures which a computer system or language makes available to the user for the purpose of formulating data processing applications. The diversity of computer systems and languages has resulted in a corresponding diversity of data models, and has created a problem for the user in selecting a data model which is in some sense appropriate to a given application. An evaluation procedure is needed which will allow the user to evaluate alternative models in the context of a specific set of applications. This paper takes a first step toward such a procedure by identifying the attributes of a data model which can be used as criteria for evaluating the model. Two kinds of criteria are presented: use criteria, which measure the usability of the model; and implementation criteria, which measure the implementability of the model and the efficiency of the resulting implementation. The use of the criteria is illustrated by applying them to three specific models: an  n -ary relational model, a hierarchic model, and a network model.", "authors": ["William C. McGee"], "n_citation": 50, "references": ["2b541a01-08b5-463d-a70d-9d629ab88b90", "648b848b-0d19-410a-ac61-5a7983447a51", "72ba03d2-65ae-4a41-aea7-092ae37d0003", "841d5ce4-76a0-4a1f-a772-6b1794d66a3c", "e3e95a2b-5e51-4c58-91fa-057e5db2fe3f", "e930195e-baa4-4d42-9d5f-e042fcaf5a9e", "fb69e954-dbdf-4244-a8f5-f58734237503"], "title": "On user criteria for data model evaluation", "venue": "ACM Transactions on Database Systems", "year": 1976, "id": "b8447f0a-095f-4c3e-97f6-ab4143ae3dd1"}
{"abstract": "This paper presents several algorithmic innovations and a hybrid programming style that lead to highly scalable performance using shared memory for a new computational fluid dynamics flow solver. This hybrid model is then converted to a strict message-passing implementation, and performance results for the two are compared. Results show that using this hybrid approach our OpenMP implementation is actually marginally faster than the MPI version, with parallel speedups of up to 599 out of 640 using OpenMP and 486 with MPI.", "authors": ["Marsha J. Berger", "Michael J. Aftosmis", "David D. Marshall", "Scott M. Murman"], "n_citation": 50, "references": ["0f3d07b7-b380-4a7b-93b0-0add1db3787c", "3a9aaaed-ac12-407e-84b6-993f0438c427", "477e9455-9712-4594-acaf-813ef5309d1f", "66745f91-ae97-4a28-b636-87df2d91bdac", "c0c31403-588f-4237-8246-e958cdd15765", "cede414d-501e-4247-a650-42240f00a401", "d005867d-ac53-4720-9842-9cbbea366a55", "d6ffd0e7-61aa-4dea-9fe0-4345e2382e96"], "title": "Performance of a new CFD flow solver using a hybrid programming paradigm", "venue": "Journal of Parallel and Distributed Computing", "year": 2005, "id": "ee7c220e-ac46-425f-8f96-97af5d33c55c"}
{"abstract": "The combination of predictive data-driven models with frequent glucose measurements may provide for an early warning of impending glucose excursions and proactive regulatory interventions for diabetes patients. However, from a modeling perspective, before the benefits of such a strategy can be attained, we must first be able to quantitatively characterize the behavior of the model coefficients as well as the model predictions as a function of prediction horizon. We need to determine if the model coefficients reflect viable physiologic dependencies of the individual glycemic measurements and whether the model is stable with respect to small changes in noise levels, leading to accurate near-future predictions with negligible time lag. We assessed the behavior of linear autoregressive data-driven models developed under three possible modeling scenarios, using continuous glucose measurements of nine subjects collected on a minute-by-minute basis for approximately 5 days. Simulation results indicated that stable and accurate models for near-future glycemic predictions (<60 min) with clinically acceptable time lags are attained only when the raw glucose measurements are smoothed and the model coefficients are regularized. This study provides a starting point for further needed investigations before real-time deployment can be considered.", "authors": ["A. Gani", "Andrei V. Gribok", "Srinivasan Rajaraman", "Whitney Ward", "J. Reifman"], "n_citation": 108, "references": ["13dbf2e0-89bc-4351-a382-7aaf49f5b00d", "a39df635-8eb8-45cb-870c-6f16f3a6b3c9", "e84d5a9c-36ff-468b-a6a7-0c4e01443935"], "title": "Predicting Subcutaneous Glucose Concentration in Humans: Data-Driven Glucose Modeling", "venue": "IEEE Transactions on Biomedical Engineering", "year": 2009, "id": "79e4c003-1312-46b9-a754-da239b3ff6ab"}
{"authors": ["Israel Cidon", "Ornan Ori Gerstel", "Shmuel Zaks"], "n_citation": 51, "references": ["0ea2170d-e4bf-4666-bddc-f458b7a520d7", "13471c5c-b682-41f1-8e2e-72a95623448c", "25528195-0438-4c47-8ba9-ba942a3fc66d", "49b2a668-a17c-4c93-baec-20f6d2306de5", "519267f1-c071-4462-9064-e18ac5b940fe", "62aefa79-e309-4670-a914-8754e873af05", "c0f17aeb-b1aa-41ee-a66e-06285117065c"], "title": "A Scalable Approach to Routing in ATM Networks", "venue": "", "year": 1994, "id": "e681baf4-0b21-4cbd-bc27-f2e1f417e65a"}
{"abstract": "To effectively model complex applications in which constantly changing situations can be represented, a database system must be able to support the runtime specification of structural and behavioral nuances for objects on an individual or group basis. This paper introduces the role mechanism as an extension of object-oriented databases to support unanticipated behavioral oscillations for objects that may attain many types and share a single object identity. A role refers to the ability to represent object dynamics by seamlessly integrating idiosyncratic behavior, possibly in response to external events, with pre-existing object behavior specified at instance creation time. In this manner, the same object can simultaneously be an instance of different classes which symbolize the different roles that this object assumes. The role concept and its underlying linguistic scheme simplify the design requirements of complex applications that need to create and manipulate dynamic objects.", "authors": ["Mike P. Papazoglou", "Bernd J. Kr\u00e4mer"], "n_citation": 52, "references": ["1704fca3-0af5-4d32-835e-9efdd3e5a18c", "2663892c-0198-4550-8587-edbc3d3f7fb0", "3006f98a-9a97-4038-a503-1b6d68895188", "3363efb4-6c07-4833-9890-87430b25a01a", "3532f513-0ff6-4455-a779-d7c67dd6feec", "377bf8fc-58f8-4457-beb0-07c247dec24d", "39126ab5-3217-4bcf-86ad-03475569af7e", "3a7fd94c-18e8-4cd7-9708-d7c53be28cff", "3fac4a85-0bba-4a1c-aad5-759e2a0ce8c6", "4c57590f-ddc3-4758-a82e-5cae5a39131a", "5c32b10a-de2f-4e89-8651-a5235a68863a", "5e19f6b4-7405-4868-bfe7-d50ee4d637a3", "5e3e420c-6408-478c-b569-9ed1292836d1", "6b4fc66f-e888-467a-a8de-2f71ab1f68f0", "79b15730-feb1-4d01-9d19-98af0a324e32", "8292e051-b7df-4679-b1a0-079a612537f8", "8d8d3f87-08bb-4c23-8562-c06734446005", "b6cfbe21-5bf7-4a0b-bf42-5d66ab566518", "bcfa87fb-47c7-43c2-94c4-ffda08ecc9b7", "c157db84-adc4-44a4-aff4-cdb5d3255dda", "df963a47-a9cc-4165-bc46-35cf960d6ef0", "e03e59f0-2696-4074-a086-9aabd69e2535", "fe3c4ab4-f3dc-4348-a958-5d13886a5d81"], "title": "A database model for object dynamics", "venue": "very large data bases", "year": 1997, "id": "71006cb5-3b76-4165-b945-a3297e52dec3"}
{"abstract": "Torque is an important quantity in combustion engine test bench control but unfortunately very difficult to measure. Observers can be used as an alternative to sensors to estimate the torque based on a nonlinear model and the available measured output signals, engine speed and dynamometer speed. In this paper three nonlinear observers are designed for a combustion engine test bench simulator including combustion oscillations as well as noisy measurements and disturbed inputs. The well known extended Kalman filter (EKF), a high gain observer (HGO) and a sliding mode observer (SMO) are compared in terms of the quadratic estimation error, computing time and convergence rate.", "authors": ["Peter Ortner", "Engelbert Gruenbacher", "L. del Re"], "n_citation": 50, "references": ["8984999e-13ea-4a73-8ec3-6bc4f2583f38", "c023333e-e3dc-4d55-b6ea-f3f194cbcbc6"], "title": "Model based nonlinear observers for torque estimation on a combustion engine test bench", "venue": "", "year": 2008, "id": "dd9c208f-fac5-4dd9-87b7-cb41ea8be16a"}
{"abstract": "An extension to two dimensions of recent results in continuum neural field theory (CNFT) in one dimension is presented here. Focus is placed on the treatment of receptive fields and of learning on afferent synapses to obtain topographic maps.", "authors": ["John G. Taylor"], "n_citation": 53, "references": ["26b084b1-08a4-47c7-b433-c899999d9518", "a264908b-8fa1-435e-8d45-679df2d0c402", "c89fc993-43ff-4050-82e3-5c3bf48bf63e"], "title": "Neural 'bubble' dynamics in two dimensions: foundations", "venue": "Biological Cybernetics", "year": 1999, "id": "353f4694-63f6-402b-8b6e-761acef97a72"}
{"abstract": "The design of optimum morphological and other non linear filters based in set, rank and logic is a non trivial task. The search space of possible solutions grows very rapidly with the number of filter parameters such as window size and signal bit depth. One of the simplest methods to estimate optimum parameters is to use the iterative search technique known as genetic algorithms. This paper will describe a new tighter bound for the convergence of genetic algorithms. It will also present an approach to the design of morphological filters using genetic algorithms. It uses iterative search techniques to probe the solution space in a way which models evolution in nature. Both practical and theoretical results achieved in this area will be included: 1. A new improved upper bound, which has recently been derived by the authors, gives the number of GA generations required to guarantee (with a pre-specified certainty) that the optimal solution has been located. Unlike the previously accepted bound it reduces with increasing population size. 2. Results using soft morphological filters designed by genetic algorithms in film restoration will be shown. The GA method is simple in its approach and bypasses the need for highly complex models of the process. As well as providing an interesting perspective to the non linear design debate, solutions found in this way may prove to be complementary to more analytical approaches by both confirming and even prompting new solutions by these routes.", "authors": ["Stephen Marshall", "Neal R. Harvey", "David Greenhalgh"], "n_citation": 50, "references": ["af3ab576-5f1e-4ce1-8537-e619cb89752d", "e0418ec3-244e-40a4-afe0-46bc6f60fb52", "eb8decc0-7c50-459b-9634-d7d3f72925e7"], "title": "Design of morphological filters using genetic algorithms", "venue": "", "year": 2000, "id": "09448f50-0185-4ecd-aa27-a893d37d2bd5"}
{"abstract": "Unlike \"mainframe healthcare,\" personal wellness technologies can scale with the needs of an aging population. They can also drive a demanding specification for the requirements of ubiquitous, proactive computing in everyday life. Ultimately, aging-in-place research supports a broader vision of \"personal wellness systems\" that provide highly individualized support for home based healthcare to all age groups.", "authors": ["Eric Dishman"], "n_citation": 181, "references": [], "title": "Inventing wellness systems for aging in place", "venue": "IEEE Computer", "year": 2004, "id": "4fb4231a-c8b7-4802-9e8e-30dee2f09ae2"}
{"abstract": "This paper introduces shortly into the security and privacy issues of RFID systems and presents a simple approach to greatly enhance location privacy by changing traceable identifiers securely on every read attempt. The scheme gets by with only a single, unreliable message exchange. By employing one-way hash functions the scheme is safe from many security threats. It is intended for use in item identification but is useful in other applications as well.", "authors": ["Dirk Henrici", "Paul M\u00fcller"], "n_citation": 62, "references": ["02343dbf-14f5-496b-b210-b6eaf9e6bdc1", "3738cf1d-2184-4ee9-b4f2-ae73080cd405", "4e203151-1ee5-4e2b-b23e-29843244ef99", "6131042a-0fe6-4691-bdd6-209b5a0919ac", "8d8e8efd-3091-4481-8bb2-4980455216ca", "bb8860c1-b707-4409-a912-f33128ff5391", "edff2e62-c01d-445f-b960-f2a8a527a9a1", "f07d49ac-9795-4fbc-ba62-43714bcd4dae"], "title": "Tackling Security and Privacy Issues in Radio Frequency Identification Devices", "venue": "international conference on pervasive computing", "year": 2004, "id": "1a1df3ce-740a-4016-b0f6-40746e3b2abb"}
{"abstract": "\u25a0 The recent advances in computer speed and algorithms for probabilistic inference have led to a resurgence of work on planning under uncertainty. The aim is to design AI planners for environments where there might be incomplete or faulty information, where actions might not always have the same results, and where there might be tradeoffs between the different possible outcomes of a plan. Addressing uncertainty in AI, planning algorithms will greatly increase the range of potential applications, but there is plenty of work to be done before we see practical decision-theoretic planning systems. This article outlines some of the challenges that need to be overcome and surveys some of the recent work in the area.", "authors": ["Jim Blythe"], "n_citation": 168, "references": ["061d05a6-ea07-45f6-9556-4ad1448ae463", "070411a5-a7b2-4bbf-b904-d63dd7deb521", "0e4c1528-6e83-4e8e-b20d-397a4728e3d2", "16948dd3-abba-4643-81e7-28b0a11c720e", "1aae8dda-25f9-4d26-9d00-562605408512", "207f6244-886c-4573-b68c-fd358cbd0e8a", "24d170fd-181e-4cbe-8186-db727d128531", "2d1afc3c-8274-4433-83c2-04596523ee1e", "3263650c-e4df-4333-9e93-857af5f74a70", "35b3ba4d-615d-4355-a841-3c03592934db", "387395e6-6712-4dda-9cb7-cf0fd7de42c7", "3a92d54a-94bf-4ca7-945b-71475faf7f39", "536301ca-f90a-4990-b856-aa8a902ac832", "57355a15-c462-4e24-a52a-367c8aaa9557", "655507f7-3586-432a-8dba-ecf5a0955513", "78177b8f-531b-40f0-8656-9ea74ec3e0d5", "7ad05cd9-5eba-43d2-afa2-3e72c56493c4", "824e7d7b-74f8-48c6-80d0-daec28fb6856", "83bf7cab-6aeb-43cc-95a6-7e2dab59da36", "8a50b7c7-1552-4167-a476-6047a279ea2b", "8abc1e16-a996-4217-b11c-d4b45a41e51a", "8b6432e5-a825-40f8-b240-a22f038344c8", "8e41c1a6-0505-4ab4-a359-ba85392bf6fd", "92fd0328-b76d-422f-8a1c-6faf8d3298ed", "ac77a839-de14-472c-87a6-95fcfcd80120", "ad702c72-d17a-41c8-90d6-49af4b6ee5df", "b0baa5eb-ab5f-41ee-b13c-608c0b378b52", "b0d19b05-f3e9-4c4e-8179-990139f415f8", "b5edf6d3-9177-4c78-aaf8-6171992fafaf", "b814a9e5-fa98-4953-aa1d-3e0656324abd", "bf717395-74d1-424d-8f33-b0cba4ecc5c8", "d695fb0d-1b38-42bc-9e8b-0750081eac94", "dc2bd2b8-b000-4c7c-bc48-204e88e30534", "de785736-6f18-4b87-8748-cc4a14073b2e", "de9470be-55ec-41ee-aac7-5d0ea89a9b6b", "e09adcf5-b687-4169-b5d2-75ce0f6d15aa", "e688492c-9f2a-4acb-bd25-6a80b0022383", "e7a4dfe5-dd09-4984-9213-3449c71cb93a", "f01c2813-d7ba-413e-ab79-f613842e71ac"], "title": "Decision-theoretic Planning", "venue": "Ai Magazine", "year": 1999, "id": "2a96506f-3756-4b11-92ad-d96a96328bdc"}
{"abstract": "The paper describes an algebra for use with parallel object databases, and in particular ODMG compliant databases with OQL. Although there have been many proposals for parallel relational database systems, there has been much less work on parallel object databases, and on parallel query processing for object databases. The parallel algebra presented in the paper is an extension of an existing physical algebra for OQL, and has an important role during query optimization, and for describing execution plans. The paper presents not only the algebra, but also its role in the architecture of a parallel database.", "authors": ["S.deF. Mendes Sampaio", "Norman W. Paton", "Paul Watson", "James V. Smith"], "n_citation": 50, "references": ["08d6bcd4-61b6-4887-80c1-8c5293f90c14", "143cb3e1-c2ad-4039-8e30-c3b5ef592e3a", "17723ea7-4e79-40ef-8b8c-0d0be3d335ae", "1af1444c-a527-487c-90cf-84a0e5ea7d96", "26027297-6c96-4bd6-9ffb-c02022756eaa", "353237e6-d645-4768-bfa2-7c245aa00e44", "3920b1f1-3989-44cd-a3d8-3806116ebe92", "3de5ae10-f362-4653-aac3-5e722fc1c477", "676deef6-18b1-4393-918b-366c582d7828", "6c45a827-8aaf-4327-8a3f-a6da8a2d3447", "cd090107-b600-4f62-854c-79b9715002d2", "d10f840c-1003-48b5-8aec-3ecc0957c658", "febce32b-363a-47a4-a7b2-302713c0cb3a"], "title": "A parallel algebra for object databases", "venue": "database and expert systems applications", "year": 1999, "id": "ad135d83-3a94-4ce8-8c13-84beb96e18c1"}
{"abstract": "A common method for texture representation is to use the marginal probability densities over the outputs of a set of multi-orientation, multi-scale filters as a description of the texture. We propose a technique, based on independent component analysis, for choosing the set of filters that yield the most informative marginals, meaning that the product over the marginals most closely approximates the joint probability density function of the filter outputs. The algorithm is implemented using a steerable filter space. Experiments involving both texture classification and synthesis show that compared to principal components analysis, ICA provides superior performance for modeling of natural and synthetic textures.", "authors": ["Roberto Manduchi", "Javier Portilla"], "n_citation": 66, "references": ["0c7c7fe9-5688-4b80-885b-cbdd174463c1", "0ddbfee1-8cc2-49f6-be79-59276f496884", "10d5ee98-134d-46be-b7af-dc0d5acc1405", "15b97643-1763-4c9b-bfd5-873f62e1ad88", "1c99f86a-da88-47ed-ab16-e8b3323749aa", "2f76d037-8da2-42e3-a17e-7ed7bb08971c", "36800655-b2ff-4eb7-9070-c6be304c4baa", "400c7d3d-a4e9-49a1-821c-3646904d44ed", "42609520-598f-421d-8f8c-3dbb26081d95", "59135305-4445-4506-8aad-52b0de9ca850", "627c74ef-59d8-43b5-a68d-e60e4ac75c0a", "62a46780-e1d9-4186-babe-6179735d785e", "6610284f-1f5a-4460-95d6-b0ad690e171d", "7ccbdf09-a84e-4ad2-ab20-cb28b6c41155", "c54f5e9b-8ee1-4c6d-934f-84c1f2413015", "f124eb8f-149b-47a0-b048-6b0a12226d32", "f4e766ac-f68f-4829-a5f8-bc8751f57948", "f769518e-b3d5-4dee-87dd-debcd57b1387"], "title": "Independent component analysis of textures", "venue": "international conference on computer vision", "year": 1999, "id": "5c331847-c8e1-4057-8477-0f3e443dd06b"}
{"abstract": "We study bipartite, first-order networks where the nodes take on leader or follower roles. Specifically, we let the leaders' positions be static and assume that leaders and followers communicate via an undirected switching graph topology. This assumption is inspired by the swarming behavior of silkworm moths, where female moths intermittently release pheromones to be detected by the males. The main result presented here states that if the followers execute the linear agreement protocol, they will converge to the convex hull spanned by the leaders' positions as long as the time-varying undirected graph defining the communication among all agents is jointly connected. The novelty of this research is that we use LaSalle's Invariance Principle for switched systems, and additionally, the result is shown to hold for arbitrary state dimensions.", "authors": ["Giuseppe Notarstefano", "Magnus Egerstedt", "Musad A. Haque"], "n_citation": 157, "references": ["1ac25f96-929a-478d-98b6-ef1c9961f8d1", "1cd81b2c-8c9f-4097-a1a6-7c1d2c9e4ec6", "223edc15-f2f7-4796-8b91-9fab63eda279", "288f7fde-26ac-430d-8edb-689a66294034", "3793e29b-85b6-4879-9fc4-c677b492b9f7", "8c581627-0fe3-46cf-99cf-c5e3c9af272e", "e705da15-0db2-4ba6-969e-2526c0a341c6", "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9"], "title": "Brief paper: Containment in leader-follower networks with switching communication topologies", "venue": "Automatica", "year": 2011, "id": "5ac31728-4605-42b7-adbe-c6ad897acaf9"}
{"abstract": "The functional difference between a diffuse wall and a mirror is well understood: one scatters back into all directions, and the other one preserves the directionality of reflected light. The temporal structure of the light, however, is left intact by both: assuming simple surface reflection, photons that arrive first are reflected first. In this paper, we exploit this insight to recover objects outside the line of sight from second-order diffuse reflections, effectively turning walls into mirrors. We formulate the reconstruction task as a linear inverse problem on the transient response of a scene, which we acquire using an affordable setup consisting of a modulated light source and a time-of-flight image sensor. By exploiting sparsity in the reconstruction domain, we achieve resolutions in the order of a few centimeters for object shape (depth and laterally) and albedo. Our method is robust to ambient light and works for large room-sized scenes. It is drastically faster and less expensive than previous approaches using femtosecond lasers and streak cameras, and does not require any moving parts.", "authors": ["Felix Heide", "Lei Xiao", "Wolfgang Heidrich", "Matthias B. Hullin"], "n_citation": 54, "references": ["222a6691-bab9-47ed-b96f-29b548152bf4", "2e97b161-da87-4069-a26d-e722407a0b54", "4ba624bc-bdda-4d9c-bb29-3c325f0d57e8", "678638d8-e525-42b5-83c9-36872383847d", "722fbd8c-4953-4c54-bfa3-5d40f9cd65ba", "8fa0a362-6522-48fc-bd5e-24de00ed6511", "ba52878a-13a0-45d4-9c6a-0b1ddd5a0e51", "bf163c20-9d1e-4034-9f4c-b8a200db823b", "c974b624-3d45-427b-8628-a58f70268e50", "f9314040-c04f-4966-aa99-3503d7829286"], "title": "Diffuse Mirrors: 3D Reconstruction from Diffuse Indirect Illumination Using Inexpensive Time-of-Flight Sensors", "venue": "computer vision and pattern recognition", "year": 2014, "id": "1aa8a2ce-e18f-4e90-9a65-b81f56d4c93c"}
{"authors": ["Carlo Zaniolo"], "n_citation": 95, "references": ["09c19ddd-b0a4-477d-bc0b-025882bca35a", "19ac2523-01b1-49d5-94db-f5b824264366", "1d4d545b-8551-4541-aa83-80ddd43e8532", "226d90a0-fe58-4b66-90d8-7a0c479a968b", "2c763af0-dbcb-44ae-a9da-132dd456ddc7", "360a1395-9457-46e9-a460-4e87406ad8ad", "40a47468-7202-4911-a033-790b444f122c", "493cda6b-a010-41f7-b507-9057e846001f", "4cbfa0fd-b5db-4dc1-8ce2-1093af208d1d", "5f95cd21-8122-43ca-9b2b-cbabdb0888c2", "7ed4f860-209f-4162-8444-b0765b087acd", "8d6430dc-a8ca-40ed-bead-a523aa31850c", "8d83481d-8b17-4a14-90e3-5b29b56b6a51", "997e2b1f-327d-4212-a71f-a5936b723772", "a5212e52-4640-484f-b003-e131a9d6341d", "abd8710b-ef44-4ee6-92dd-34ceffe11a16", "b70206c7-d406-4d8f-b6b2-9c5cb1866b40", "e8ccb3c1-5591-4a6b-8993-4077833bb1e6"], "title": "A Unified Semantics for Active and Deductive Databases", "venue": "", "year": 1994, "id": "49954c38-aec9-41db-bee8-2b7546a26bba"}
{"abstract": "We investigate defeasible logics using a technique which decomposes the semantics of such logics into two parts: a specification of the structure of defeasible reasoning and a semantics for the meta-language in which the specification is written. We show that Nute's Defeasible Logic corresponds to Kunen's semantics, and develop a defeasible logic from the well-founded semantics of Van Gelder, Ross and Schlipf. We also obtain a new defeasible logic which extends an existing language by modifying the specification of Defeasible Logic. Thus our approach is productive in analysing, comparing and designing defeasible logics.", "authors": ["Michael J. Maher", "Guido Governatori"], "n_citation": 75, "references": ["03341eb1-d162-4f03-b835-63782fc81248", "09c19ddd-b0a4-477d-bc0b-025882bca35a", "5433d670-a509-4c57-ab8f-4e0ab39d7ba0", "5a568ce9-f7db-4f4c-a604-094cb719e5b4", "61faa2d7-1216-42b7-b0f7-e4951612f04b", "628d114a-8e9c-49d4-ace1-2504ed977447", "9764f729-f204-478a-ac0c-0d2b18b2241c", "9a68ece9-e08e-494e-85b7-5a69117f956f", "de280bf4-41e4-41f0-9154-41bc9e6c9a0b", "e22908da-10e5-49ec-93ed-2d7b1e1e8da3"], "title": "A semantic decomposition of defeasible logics", "venue": "national conference on artificial intelligence", "year": 1999, "id": "23578560-6364-4236-8718-fd478e66e1af"}
{"abstract": "Information about the user's environment offers new opportunities and exposes new challenges in terms of time-aware, location-aware, device-aware and personalized applications. Such applications constantly need to monitor the environment - called context - to allow the application to react accordingly to this context. Context-awareness is especially interesting in mobile scenarios where the context of the application is highly dynamic and allows the application to deal with the constraints of mobile devices in terms of presentation and interaction abilities and communication restrictions. Current context-aware applications often realize sensing of context information in an ad hoc manner. The application programmer needs to deal with the supply of the context information including the sensing of the environment, its interpretation and its disposal for further processing in addition to the primary purpose of the application. The close interweavement of device specific context handling with the application obstructs its reuse with other hardware configurations. Recently, architectures providing support for context-aware applications have been developed. Up to now such architectures are not trimmed to the special requirements of mobile devices regarding particularly the limitations of network connections, limited computing power and the characteristics of mobile users. This paper proposes an architecture and a software framework - the hydrogen context framework -which support context-awareness for considering these constraints. It is extensible to consider all kind of context information and comprises a layered architecture. To prove the feasibility the framework has been implemented to run on mobile devices. A context-aware postbox is realized to demonstrate the capabilities of the framework.", "authors": ["Thomas H\u00f6fer", "Wieland Schwinger", "Mario Pichler", "Gerhard Leonhartsberger", "Josef Altmann", "Werner Retschitzegger"], "n_citation": 437, "references": ["081b1c58-3040-4c57-9758-d213c6646b83", "1d8c3fcb-c18d-4ede-9a9c-a8538c9014c4", "220698b7-f035-4a84-87b7-1fd9d0e43c3f", "2b8c4575-897f-40ee-8023-9b4ce82f6fce", "3a595a03-733e-4bd6-a054-3e75aa2d8f4b", "3c99e025-5543-4e3d-aef8-9e55e3b6eb81", "779000e1-bfe6-40f7-ac5a-f0f9dab2f9d9", "81670e6f-2424-48e2-bce7-99496c68c521", "bfd7e012-b018-47e6-ba7c-11ba7d74f2f7", "c6e1488d-3717-42d9-8e93-f91c100fa70d", "f02855d8-0b70-4e16-bda9-fe31b6221b9b"], "title": "Context-awareness on mobile devices - the hydrogen approach", "venue": "hawaii international conference on system sciences", "year": 2003, "id": "47055d85-fcba-4f63-9e9e-886278170c18"}
{"abstract": "Associative classification mining is a promising approach in data mining that utilizes the association rule discovery techniques to construct classification systems, also known as associative classifiers. In the last few years, a number of associative classification algorithms have been proposed, i.e. CPAR, CMAR, MCAR, MMAC and others. These algorithms employ several different rule discovery, rule ranking, rule pruning, rule prediction and rule evaluation methods. This paper focuses on surveying and comparing the state-of-the-art associative classification techniques with regards to the above criteria. Finally, future directions in associative classification, such as incremental learning and mining low-quality data sets, are also highlighted in this paper.", "authors": ["Fadi Abdeljaber Thabtah"], "n_citation": 217, "references": ["05268346-81e5-4a59-b6e6-9e7d0ca204eb", "07f57c70-0572-4daa-ab9d-c07a1df9dd15", "11629718-af3d-4a01-96b8-7e705d9e5d28", "150e8cf7-1123-4da1-b211-00f42811e53b", "1c6858b7-6e2f-4460-943f-ff38b9e03dfd", "21a70f97-daf1-4d27-b1ed-32373acb10b4", "285779de-f00e-4430-bc88-008ab52cd54e", "2d842695-6ffd-4b57-940e-195dfe48b4cf", "2f4102ea-cab4-4789-8eae-ebfc38257b40", "32315e8f-ed4b-47eb-b2f4-0c35a8aa8bc9", "32e9e118-57fa-4d3d-8791-580b1a19db8e", "34b7e270-80d7-46d5-a6f1-e50087a8d045", "35eac0c4-13a0-4cae-9cb0-b8ef256d5812", "37089c5d-1576-4dae-8baa-7b13aa197041", "43ab1aa0-9cc7-4212-860c-e9299d10add4", "46f6963a-2459-4e2c-8667-a8d0fcde43e9", "594b4fe8-54fe-4f3c-aa4f-cdec07b9be2b", "6096566f-20da-4a87-9ceb-4074af2728a3", "62549bc2-e0b3-46e8-8d32-390dded105d5", "63a9e80b-42d1-43bb-89ea-844ea8b1f798", "64c52060-f573-4a4c-9d15-029997df0813", "671df166-8fb2-4d2a-9ed0-a2a5bfae0a49", "6bd1fab6-a628-47c7-9e41-865a20bcf845", "6cc7450c-fc0f-4525-80db-9b7628a856d0", "6d903194-6be4-4780-9ccf-d60916e00770", "7c9ddeea-2d0b-467d-9527-e393db5f132d", "7f60f284-50e8-4bf3-92c5-db7ef4975434", "802816ab-35a3-49de-97bb-2d43f287546f", "8761cd87-be91-4dcc-83b0-d1a273cecd7f", "904409d9-a815-4a6a-ba8c-e0e638dd3e31", "9a388ac4-d5eb-4994-96ee-61b6c43f66e4", "a3940078-f3ac-4dad-b41b-2cec1fea9c43", "ad9073e1-7871-46f9-9af4-91c013fad58f", "c4710c73-497d-44f0-ae10-64613eca18d4", "c512fe3b-b9c4-40a1-a205-8ca01effdeb0", "d8ddd4ae-16ab-4702-b4f5-65aff0e33533", "d8f66da3-1fb0-4b7c-8ab5-390c837ff9f2", "db71bdd0-0013-42bb-a968-b20f40d2b3eb", "e3039c68-7d0e-4863-9f14-40550c092ad3", "e8ab235f-d709-4d84-87d4-c2dba5b73d32", "ecd6a845-8439-49b0-abe8-f71fff81da23", "f09431dd-0dc4-4a43-aaf3-9fa6de6012d1"], "title": "A review of associative classification mining", "venue": "Knowledge Engineering Review", "year": 2007, "id": "8dbe416e-9595-4996-a0b0-427be550c73c"}
{"abstract": "Commercial software development is a complex task that requires a thorough understanding of the architecture of the software system. We analyze the Windows Server 2003 operating system in order to assess the relationship between its software dependencies, churn measures and post-release failures. Our analysis indicates the ability of software dependencies and churn measures to be efficient predictors of post-release failures. Further, we investigate the relationship between the software dependencies and churn measures and their ability to assess failure-proneness probabilities at statistically significant levels.", "authors": ["Nachiappan Nagappan", "Thomas Ball"], "n_citation": 182, "references": ["118d3afc-32c9-49ad-a25b-2ea688d2018e", "11df7d57-bad8-4b0b-8ce8-e26c6d9eb2b0", "2cde3231-5ee8-409b-99ff-9c54547be4e3", "33e516aa-0bc6-4200-a6e3-034a3fb244a1", "3c4b614f-3b85-41f1-8ae7-195e4fbd966a", "57af1f08-da6a-466f-97a2-99e98a992768", "5be480f2-f2d3-4a62-b819-ad13259aa4fe", "8991e403-e7e0-422a-9998-ae33055b1a04", "97badbeb-818b-4d7b-863f-3d0c6c4870c7", "abed179f-56b3-4cc6-975d-7177f879b97e", "bcba862e-5145-454e-a8b5-398d3b499cb4", "c1353eb5-bf8f-4497-836e-404e1d5381a6", "d32786fc-ea8d-41f0-a803-5d00e550329c", "dbd96fa7-ad70-4374-80a2-8a5abd8dffd3", "ded73f0a-0715-469f-b384-a98cc070a908", "e6836f8f-8e5b-456c-afb4-29c5c0f7cf68"], "title": "Using Software Dependencies and Churn Metrics to Predict Field Failures: An Empirical Case Study", "venue": "empirical software engineering and measurement", "year": 2007, "id": "1d48da5f-8d99-47a0-a7ba-c2062af1c87e"}
{"abstract": "On modern processors, hardware-assisted virtualization outperforms binary translation for most workloads. But hardware virtualization has a potential problem: virtualization exits are expensive. While hardware virtualization executes guest instructions at native speed, guest/VMM transitions can sap performance. Hardware designers attacked this problem both by reducing guest/VMM transition costs and by adding architectural extensions such as nested paging support to avoid exits.#R##N##R##N#This paper proposes complementary software techniques for reducing the exit frequency. In the simplest form, our VMM inspects guest code dynamically to detect back-to-back pairs of instructions that both exit. By handling a pair of instructions when the first one exits, we save 50% of the transition costs. Then, we generalize from pairs to clusters of instructions that may include loops and other control flow. We use a binary translator to generate, and cache, custom translations for handling exits. The analysis cost is paid once, when the translation is generated, but amortized over all future executions.#R##N##R##N#Our techniques have been fully implemented and validated in recent versions of VMware products. We show that clusters consistently reduce the number of exits for all examined workloads. When execution is dominated by exit costs, this translates into measurable runtime improvements. Most importantly, clusters enable substantial gains for nested virtual machines, delivering speedups as high as 1.52\u00d7. Intuitively, this result stems from the fact that transitions between the inner guest and VMM are extremely costly, as they are implemented in software by the outer VMM.", "authors": ["Ole Agesen", "Jim Mattson", "Radu Rugina", "Jeffrey W. Sheldon"], "n_citation": 55, "references": ["0643a8bc-1332-42f9-8d84-393ee3987dd8", "32a51fd4-29ce-4400-8da6-02126cdf5adb", "499cddf6-45e5-46ca-b194-b55500c32bb6", "53d92775-1f7b-4a39-af24-804bf269e8e2", "78991392-db9c-45a4-86a2-b4ce93ab0ec0", "7d3f6134-d7d9-44a0-9aec-fd900acac178", "84ef850e-7daf-468e-8f00-72473c0d37e4", "f67bf40c-fdad-4215-942b-b23b2a017115"], "title": "Software techniques for avoiding hardware virtualization exits", "venue": "usenix technical conference", "year": 2012, "id": "ac328b00-68a4-4241-92e5-a0e4bfca8a54"}
{"abstract": "A race condition is a situation where two threads manipulate a data structure simultaneously, without synchronization. Race conditions are common errors in multithreaded programming. They often lead to unintended nondeterminism and wrong results. Moreover, they are notoriously hard to diagnose, and attempts to eliminate them can introduce deadlocks. In practice, race conditions and deadlocks are often avoided through prudent programming discipline: protecting each shared data structure with a lock and imposing a partial order on lock acquisitions. In this paper we show that this discipline can be captured (if not completely, to a significant extent) through a set of static rules. We present these rules as a type system for a concurrent, imperative language. Although weaker than a full-blown program-verification calculus, the type system is effective and easy to apply. We emphasize a core, first-order type system focused on race conditions; we also consider extensions with polymorphism, existential types, and a partial order on lock types.", "authors": ["Cormac Flanagan", "Mart\u00edn Abadi"], "n_citation": 198, "references": ["0062bc07-38e7-4e08-82da-773e95fc6914", "0f4009ac-4024-419e-b26a-e7c9b41533b4", "119162d6-0403-4980-8096-f6fa5d9fc228", "2001c63f-3a13-4498-88ac-de76423e29eb", "2230c340-e108-418b-a1ab-c40ef3eaefe5", "29597bd7-43bd-4d38-89f8-cc2393958ccc", "2bbed8f2-4738-4f76-a186-a1d2d53f99ac", "65ae2bdf-a3b3-4876-a5bb-d5e9f0d49cdd", "68710711-e569-4b5f-a2df-7dbea65d97d3", "7f1dc63a-9064-4768-a30d-3383d52aa81e", "869eac2d-cbed-4604-9098-80e9cdcc459f", "87e4c27b-6e41-44bc-8bcf-ba77945da596", "8dafcd59-76af-4cfe-834e-ebdd8503bce1", "93672072-a749-47c6-b866-8ff2da2902ca", "a02cb3c9-080b-4966-988e-760d9fbbb4d0", "a6e2c70d-0585-4f13-8f28-45831696af3e", "b6c465ae-cc45-468a-8b2a-971bfc7af92d", "c34c7f60-07d0-462f-9377-6ceee6197e59", "c6087348-c3a1-470c-982f-e7c5e6def02d", "f10cfb56-1737-4597-87cf-75f35143a3e5"], "title": "Types for Safe Locking", "venue": "european symposium on programming", "year": 1999, "id": "0ded7f08-d0c1-4698-bee1-862a8c676440"}
{"abstract": "We present a necessary and sufficient condition for an ellipsoid to be an invariant set of a linear system under a saturated linear feedback. The condition is given in terms of linear matrix inequalities (LMIs) and can be easily used for optimization-based analysis and design.", "authors": ["Tingshu Hu", "Zongli Lin"], "n_citation": 131, "references": ["b423817d-b284-43c5-be50-8775fa6a4c1c"], "title": "Exact characterization of invariant ellipsoids for single input linear systems subject to actuator saturation", "venue": "IEEE Transactions on Automatic Control", "year": 2002, "id": "94c202ad-f8f0-45dc-a8c8-44ba6dba992c"}
{"abstract": "A new method for automated planning, refinement of skeletal plans, has been developed for the problem of experiment design in the domain of molecular biology. The method resulted from a study of the problem-solving behavior of scientists which showed that design usually consisted of look-up of abstracted plans followed by hierarchical plan-step refinement. The skeletal plan method has been implemented through two generations of problem-solving systems, the second generation involving a synthesis with the metaplanning approach of Stefik.", "authors": ["Peter Friedland", "Yumi Iwasaki"], "n_citation": 266, "references": ["2329ae1f-1062-4504-9ef1-45d9e5c0dd2e", "245d5a4c-d982-44bc-b30a-158e87024fca", "3d62d94c-939f-4e7a-92cd-1ce4db9e1c9d", "720bd2c7-2d4c-4779-8c6f-7321d877a75e", "bc49c36f-4247-4cdb-a2fb-f89ad8f8ea6c"], "title": "The concept and implementation of skeletal plans", "venue": "Journal of Automated Reasoning", "year": 1985, "id": "b0baa5eb-ab5f-41ee-b13c-608c0b378b52"}
{"abstract": "The ability to estimate the personnel time and costs required for the completion of programming and systems projects is an important managerial tool for the information systems department. This article presents a survey of the estimation techniques found in the literature by describing each technique and discussing its strengths and weaknesses. Some empirical evidenc3e on how the various program and programmer/analyst characteristics affect project time and cost are also reported.", "authors": ["Izak Benbasat", "Iris Vessey"], "n_citation": 46, "references": ["096dcec5-4853-4500-b6a4-ec8efe727985", "bc328964-b2d8-4c18-a11e-6d3e17bd409e", "e3bb8912-cf4c-4fdd-bf42-b5cc607b2fba"], "title": "Programmer and analyst time/cost estimation", "venue": "Management Information Systems Quarterly", "year": 1980, "id": "7a72a5a9-01a4-45db-89ab-6d163f2508ad"}
{"abstract": "Software engineering is an emerging discipline whose goal is to produce reliable software products in cost-effective manner. This discipline is evolving rapidly as the challenges faced by its practitioners keep extending their skills. This paper gives a quick tour of the main ideas and thrusts that have driven software engineering in its first 25 years and attempts to look ahead at the next set of advances.", "authors": ["Robert P. Goldberg"], "n_citation": 50, "references": ["2b20dc7a-7037-4d46-9568-be8b1feb068b", "2cf6ff36-ba64-4894-a7e0-2a7ff27fd421", "35c8c06c-2ad0-46b4-9e92-2d684f3abd94", "3bd1570d-c39c-4674-abb1-8af7b9cf4e6a", "3c85cb2d-e921-4b22-bd64-9eaea427879b", "43e74ea3-85e6-42af-9109-e6b4665c5b84", "48696925-9398-49dd-b272-8ba46c596252", "4a04a5e2-3058-4ece-bf56-6c61a5a8e7c8", "4fcb532c-0a44-4401-80bf-385bf195c80e", "5bdf575b-d089-4b5d-83ff-c8578449c76b", "6c12529a-0cdc-49f9-a174-3c01c6305749", "9f00617e-6f97-4353-b9c4-2d6cfe155160", "a3307bf0-7eb5-48f0-964d-fc2df9fb42be", "a9d193ab-dae8-4876-a0b0-eac4f6134a36", "ab26afb0-d452-4fe7-828b-955a8f662204", "b1a4e18b-5634-4a43-b73c-77c1a687b22a", "dbd8bf30-6fcb-4178-b61c-594e693c7471", "ea8d8e8f-d8df-4722-935b-401665ea6fbc"], "title": "Software engineering: an emerging discipline", "venue": "Ibm Systems Journal", "year": 1986, "id": "95096b38-e111-4e48-9807-04cc220e43cb"}
{"authors": ["Rajeev Alur", "Costas Courcoubetis", "Nicolas Halbwachs", "David L. Dill", "Howard Wong-Toi"], "n_citation": 240, "references": ["05187588-ada5-47d3-ab0d-a282be6fc447", "179a29ef-760c-428b-9322-2e8e547184d8", "1eb621bf-d554-429d-92e3-c50b4dcedfda", "28d937c6-0858-48a7-b004-1fbf22dfe342", "2bff8497-edb3-4079-9cb7-fa808efccf15", "4814eca2-167a-48bd-a7e6-60150e7a54e3", "4a3dfb0d-66d2-4aa7-a942-b7591b952575", "5d6b652d-9d18-46d3-a914-7bfae3c9f4bf", "65ea1b11-08f4-4cdd-ae8a-6cbc9a1fa0ac", "9277106c-ef7b-4854-a4fd-d58ef602a782", "a4799c38-84d0-4b52-84d6-18e493af3a3c", "c08253d7-d296-4f62-9498-835973cc1298", "c1102d81-fb2c-4701-94c6-47feea928648", "f1289e28-b103-4a9b-8a3f-903d7e8f5c60"], "title": "Minimization of Timed Transition Systems", "venue": "international conference on concurrency theory", "year": 1992, "id": "bb5f4e29-4ed5-4097-9702-cde7f2f4ffd9"}
{"abstract": "A logic LIS for complete information systems is proposed. The language of LIS contains constants corresponding to attribute and attribute-values. A sound and complete deductive system for the logic is presented. Decidability is also proved.", "authors": ["Md. Aquil Khan", "Mohua Banerjee"], "n_citation": 50, "references": ["31a598e9-27e9-49d0-a864-63753b82418a", "6546355a-8531-421c-999d-ac59e6b26818", "a4589cfe-15e7-4c34-9349-d002d1d2c9df", "aaf903a7-0431-4855-b3d5-f92d0d766641", "b396220c-b39b-4c21-89cf-b4a994f41236", "d2458f99-de48-479f-889e-5182c9894e24"], "title": "A Logic for Complete Information Systems", "venue": "european conference on symbolic and quantitative approaches to reasoning and uncertainty", "year": 2009, "id": "c7a98835-642b-4d09-8632-d58e4a1e64f3"}
{"authors": ["Myoung-Ah Kang", "Sylvie Servign"], "n_citation": 8, "references": ["93ad7eaa-e007-4105-a838-ff4572e463a8", "db489b7f-17fd-479d-8925-024da893e067"], "title": "Animated cartography for urban soundscape information", "venue": "advances in geographic information systems", "year": 1999, "id": "12f721f8-fd09-4ba6-9aea-2d11f8aef9a2"}
{"abstract": "This paper is an exposition of the theory of regular expressions and its applications to sequential circuits. The results of several authors are presented in a unified manner, pointing out the similarities and differences in the various treatments of the subject. Whenever possible, the terminology and notation of sequential circuit theory are used. The topics presented include: the relation of regular expressions to sequential circuits; algorithms for constructing sequential circuits and state diagrams corresponding to a given regular expression; methods for obtaining a regular expression from a state diagram of a sequential circuit, improper state diagrams, algebraic properties of regular expressions, and applications to codes.", "authors": ["Janusz Brzozowski"], "n_citation": 68, "references": ["179fde33-8e59-4fd9-bb57-adf2cb41eb7b", "70e19a57-78b6-4c5e-bce8-d1ceb1244bdf", "b0f6455a-6f99-42c5-8502-4fa535768ceb"], "title": "A Survey of Regular Expressions and Their Applications", "venue": "Ire Transactions on Electronic Computers", "year": 1962, "id": "d2fb92c8-e105-445f-b5b9-c017dcab9eee"}
{"abstract": "We define a new interactive differentially private mechanism --- the median mechanism --- for answering arbitrary predicate queries that arrive online. Given fixed accuracy and privacy constraints, this mechanism can answer exponentially more queries than the previously best known interactive privacy mechanism (the Laplace mechanism, which independently perturbs each query result). With respect to the number of queries, our guarantee is close to the best possible, even for non-interactive privacy mechanisms. Conceptually, the median mechanism is the first privacy mechanism capable of identifying and exploiting correlations among queries in an interactive setting.   We also give an efficient implementation of the median mechanism, with running time polynomial in the number of queries, the database size, and the domain size. This efficient implementation guarantees privacy for all input databases, and accurate query results for almost all input distributions. The dependence of the privacy on the number of queries in this mechanism improves over that of the best previously known efficient mechanism by a super-polynomial factor, even in the non-interactive setting.", "authors": ["Aaron Roth", "Tim Roughgarden"], "n_citation": 189, "references": ["1170000a-ee7c-4e2a-a2b3-d6e2944059da", "2e2ddf80-7c7b-4365-89b5-a1aab3dc6a80", "32fd9fa0-0857-4bbc-8e40-b947c02e9d8b", "396c6192-d592-41a9-a37e-9bc3efa5dfd7", "60d9f0b5-84f9-4bb2-a191-d1ef838db4e0", "8068b84d-1366-4ad5-943e-93b2a1079845", "9a9042ef-19fd-4cc4-90db-059122355179", "c33734e3-5289-4ec8-8d16-e6a5e534b660", "f6e345a5-8fc0-49da-891a-465f0234dc81"], "title": "Interactive privacy via the median mechanism", "venue": "symposium on the theory of computing", "year": 2010, "id": "70ee2599-0921-4a79-b87a-7fadceb4357d"}
{"abstract": "A key issue in the MDA approach is the transformation of platform independent models to platform specific models. Before transforming to a platform specific model, however, it is necessary to select the appropriate platform. Various platforms exist with different properties and the selection of the appropriate platform for the given application requirements is not trivial. An inappropriate selection of a platform, though, may easily lead to unnecessary loss of resources and lower the efficiency of the application development. Unfortunately, the selection of platforms in MDA is currently implicit and lacks systematic support. We propose to integrate so-called platform selection rules in the MDA approach for systematic selection of platforms. The platform selection rules are based on platform domain models that are derived through domain analysis techniques. We show that the selection of platforms is important throughout the whole MDA process and discuss the integration of the platform selection rules in the MDA approach. The platform selection rules have been implemented in the prototypical tool MDA Selector that provides automated support for the selection of a platform. The presented ideas are illustrated for a stock trading system.", "authors": ["Bedir Tekinerdogan", "Sevcan Bilir", "Cem Abatlevi"], "n_citation": 23, "references": ["28c49b78-9398-4832-baa9-0207cba36e12", "4fee1e35-5734-43b5-94fb-cfc0dc34c423", "5db62f3e-d72c-497d-bf90-19d4b4fdf55f", "89b774de-404f-4dd9-9b9f-46a7c322bdd3", "d6285e34-13fa-4327-b4f9-203181baa8c6", "eff9adf0-c70b-42cc-9d6d-47ec62958c23"], "title": "Integrating platform selection rules in the model driven architecture approach", "venue": "", "year": 2003, "id": "6b1d09b5-b5df-4b84-8d7e-ad8ecc53f8aa"}
{"abstract": "Our initial ideas on preventive maintenance of object-oriented systems were presented in [LHR88] which describes a set of guidelines called the \"Law of Demeter\". As a result of this publication we have received much feedback, as well as a detailed critique from [Sak89]. In this paper we expand on the initial ideas and present a new perspective with which to view the Law. This perspective is based on client/supplier relationships between methods and classes and allows a cleaner description of the benefits of the Law. This paper is also a reply to [Sak89] which was pointing out that the formulation of the Law for C++ needs additional work.At first sight, the idea of any rules or principles being superimposed on the creative mind seems more likely to hinder than to help, but this is really quite untrue in practice. Disciplined thinking focusses inspiration rather than blinkers it.", "authors": ["K. J. Lienberherr"], "n_citation": 50, "references": ["133982df-1fe4-40f3-8d8d-fe65cffbad99", "46e050ad-c758-47aa-81e5-1766c879f78a", "71394d85-f392-42e2-b223-a0f20e8b0406"], "title": "Formulations and benefits of the law of demeter", "venue": "Sigplan Notices", "year": 1989, "id": "64aded57-a35a-405c-a0fe-a806eb3947eb"}
{"abstract": "This paper presents a prototype system for pedestrian detection on-board a moving vehicle. The system uses a generic two-step approach for efficient object detection. In the first step, contour features are used in a hierarchical template matching approach to efficiently \"lock\" onto candidate solutions. Shape matching is based on Distance Transforms. By capturing the objects shape variability by means of a template hierarchy and using a combined coarse-to-fine approach in shape and parameter space, this method achieves very large speed-ups compared to a brute-force method. We have measured gains of several orders of magnitude. The second step utilizes the richer set of intensity features in a pattern classification approach to verify the candidate solutions (i.e. using Radial Basis Functions). We present experimental results on pedestrian detection off-line and on-board our Urban Traffic Assistant vehicle and discuss the challenges that lie ahead.", "authors": ["Dariu M. Gavrila"], "n_citation": 592, "references": ["01bc29a3-6183-4d58-809d-000d570a0b33", "317c0dcb-ccd2-40c4-a5cc-1d4f63221035", "923f5d0a-23a3-4fb1-bee7-ec72122709a4", "944dc4f4-07ba-47c7-948a-5d99e95733c2", "aa2adaf3-8f4c-487a-aa46-a09198d9045f", "d9752a5a-1603-45cc-9a21-7997750d429f", "e44dc0fd-dcf7-43b4-8f27-4cea26c6611c", "f3959783-a9aa-48a2-9fcc-978879de365e"], "title": "Pedestrian Detection from a Moving Vehicle", "venue": "european conference on computer vision", "year": 2000, "id": "dd096bb0-7c91-4c01-93a2-e9ffeb89705c"}
{"abstract": "The IEEE 802.11 network technology is the emerging standard for wireless LANs and mobile networking. The fundamental access mechanism in the IEEE 802.11 MAC protocol is the Distributed Coordination Function. In this paper, we present an analytical method of estimating the saturation throughput of 802.11 wireless LAN in the assumption of ideal channel conditions. The proposed method generalizes the existing 802.11 LAN models and advances them in order to take the Seizing Effect into consideration. This real-life effect consists in the following: the station that has just completed successfully its transmission has a better chance of winning in the competition and therefore of seizing the channel than other LAN stations. The saturation throughput of 802.11 wireless LANs is investigated by the developed method. The obtained numerical results are validated by simulation and lead to the change of the existing idea of the optimal access strategy in the saturation conditions.", "authors": ["Vladimir M. Vishnevsky", "Andrey I. Lyakhov"], "n_citation": 57, "references": ["cacd00e5-6e21-44d5-8cb0-6020a4fc24fa", "cb239f1b-663f-4337-a224-22c42a1f70d0", "df9da54d-7e74-472d-a5fa-19f5edd8e935", "e292b472-7d2c-4edb-b73e-c40a81f828e2"], "title": "IEEE 802.11 Wireless LAN: Saturation Throughput Analysis with Seizing Effect Consideration", "venue": "Cluster Computing", "year": 2002, "id": "b47e1d9a-6a6e-44a0-8952-4cd366a021ff"}
{"abstract": "We present a generic approach to readable formal proof documents, called Intelligible semi-automated reasoning (Isar). It addresses the major problem of existing interactive theorem proving systems that there is no appropriate notion of proof available that is suitable for human communication, or even just maintenance. Isar's main aspect is its formal language for natural deduction proofs, which sets out to bridge the semantic gap between internal notions of proof given by state-of-the-art interactive theorem proving systems and an appropriate level of abstraction for user-level work. The Isar language is both human readable and machine-checkable, by virtue of the Isar/VM interpreter.#R##N##R##N#Compared to existing declarative theorem proving systems, Isar avoids several shortcomings: it is based on a few basic principles only, it is quite independent of the underlying logic, and supports a broad range of automated proof methods. Interactive proof development is supported as well. Most of the Isar concepts have already been implemented within Isabelle. The resulting system already accommodates simple applications.", "authors": ["Markus Wenzel"], "n_citation": 160, "references": ["0093a4c7-7fa0-4b40-b0fc-f358740ff9eb", "02f1ed6f-07b3-4b11-9a20-1305f2b3866f", "0ae743a4-6101-4e1d-a01c-bb3fa8cecb6e", "10e36f78-f471-4a73-adb3-99734b9db924", "17270360-1f8e-43a7-aef4-228bad2af1e5", "3f96ce9f-135f-4b84-bcdc-20da2073a0b9", "3fca2601-6e10-463d-9741-87d3c18718e6", "ae17130f-0e4b-4b32-b59a-4f6a5902df36", "b1343042-c239-4718-a7f3-8747b8a9537b", "bed97612-5b7e-4479-ac2f-e94d1450722f", "c347fd9e-ebf6-4f75-8a9b-c8f11ed81114", "f9c504fc-08ee-4baf-88fe-1acb0875abe7"], "title": "Isar - A Generic Interpretative Approach to Readable Formal Proof Documents", "venue": "theorem proving in higher order logics", "year": 1999, "id": "44668c03-840c-4130-b48d-80fb380f3e61"}
{"abstract": "We introduce the notions of premonoidal category and premonoidal functor, and show how these can be used in the denotational semantics of programming languages. We characterize the semantic definitions of Eugenio Moggi's monads as notions of computation, exhibit a representation theorem for our premonoidal setting in terms of monads, and give a fibrational setting for the structure.", "authors": ["John Power", "Edmund Robinson"], "n_citation": 219, "references": ["0cb3d162-ff30-42f5-b51d-32f6893c9cbc", "41385c93-631e-468a-a90c-ff4a4ff693f8", "807b796c-5358-4c6e-8f12-9d22dcec4e5b", "aafba460-7c9d-47e3-b7c8-748abbfdf070", "e623ffd9-151d-42ca-a301-07dff667731d", "e93610df-27d7-4a0d-8447-9d66a781b3a4"], "title": "Premonoidal categories and notions of computation", "venue": "Mathematical Structures in Computer Science", "year": 1997, "id": "13727d43-41d0-44bc-b69c-9d295642f25a"}
{"abstract": "Collaborative spectrum sensing among secondary users (SUs) in cognitive networks is shown to yield a significant performance improvement. However, there exists an inherent trade off between the gains in terms of probability of detection of the primary user (PU) and the costs in terms of false alarm probability. In this paper, we study the impact of this trade off on the topology and the dynamics of a network of SUs seeking to reduce the interference on the PU through collaborative sensing. Moreover, while existing literature mainly focused on centralized solutions for collaborative sensing, we propose distributed collab- oration strategies through game theory. We model the problem as a non-transferable coalitional game, and propose a distributed algorithm for coalition formation through simple merge and split rules. Through the proposed algorithm, SUs can autonomously collaborate and self-organize into disjoint independent coalitions, while maximizing their detection probability taking into account the cooperation costs (in terms of false alarm). We study the stability of the resulting network structure, and show that a maximum number of SUs per formed coalition exists for the proposed utility model. Simulation results show that the proposed algorithm allows a reduction of up to 86.6% of the average missing probability per SU (probability of missing the detection of the PU) relative to the non-cooperative case, while maintaining a certain false alarm level. In addition, through simulations, we compare the performance of the proposed distributed solution with respect to an optimal centralized solution that minimizes the average missing probability per SU. Finally, the results also show how the proposed algorithm autonomously adapts the network topology to environmental changes such as mobility.", "authors": ["Walid Saad", "Zhu Han", "Merouane Debbah", "Are Hjorungnes", "Tamer Basar"], "n_citation": 201, "references": ["07d23b40-c838-45bc-919f-accf8b8e59e9", "1ed3c472-3958-47e3-b350-0b616d0b00e1", "7eec97d7-24a3-4cc4-a9d0-0a2eb481e4ca", "cc905096-7394-48f6-a0d8-5af0eac0a5d4", "f1e74152-3f7c-4c44-b628-cdf47a17587f"], "title": "Coalitional Games for Distributed Collaborative Spectrum Sensing in Cognitive Radio Networks", "venue": "international conference on computer communications", "year": 2009, "id": "d249660e-e486-4ad5-897b-6cd81222e453"}
{"abstract": "In IP-over-WDM networks, a logical IP network is routed on top of a physical optical fiber network. An important challenge here is to make the routing survivable. We call a routing survivable if the connectivity of the logical network is guaranteed in the case of a failure in the physical network. In this paper we describe FastSurv, a local search algorithm for survivable routing. The algorithm works in an iterative manner: after each iteration it learns more about the structure of the logical graph and in the next iteration it uses this information to improve its solution. The algorithm can take link capacity constraints into account and can be extended to deal with multiple simultaneous link failures and node failures. In a large series of tests we compare FastSurv with current state-of-the-art algorithms for this problem. We show that it can provide better solutions in much shorter time, and that it is more scalable with respect to the number of nodes, both in terms of solution quality and run time.", "authors": ["Frederick Ducatelle", "Luca Maria Gambardella"], "n_citation": 15, "references": ["0019362a-1f6f-4607-afaa-5f514e72aad7", "1eac41dd-d44e-4965-a021-a543341bb602", "23d44639-190f-4c0c-b60e-ceead16ddacb", "531d2e4e-9e70-4c08-bb51-c4c4aab97a88", "6a72578f-33fd-48a0-a306-89e3ea0d6a50", "8c48a61d-fbfb-4726-bcaa-bcd9d3e3b5a7", "a1fb7d8f-4b56-4dc0-9d42-652f67d6db65", "af3dcf0c-6e6f-4190-a9d6-9a9d2551e378", "c5f1550a-cbb5-4788-99ad-2d9e2d3c2679", "f7c6af95-e26d-4a3c-9137-c6f4a9839471", "fa62f967-bf47-43a3-a275-21af32fc28ff"], "title": "Survivable routing in IP-over-WDM networks: An efficient and scalable local search algorithm", "venue": "Optical Switching and Networking", "year": 2005, "id": "6ecef886-9961-4536-8f42-4e7c508fc4e4"}
{"authors": ["Tomi Janhunen", "Ilkka Niemel\u00e4"], "n_citation": 51, "references": ["3ec4052e-999b-489a-a966-76eb74af4aae", "5c50a384-c52c-4389-bee4-fc0b4cee9c7b", "db658327-1f48-4f80-8f7d-09d88096f297", "efc6a66b-ba30-421b-97a2-75ac8ea1569a", "f0315c60-9807-477b-bec5-9058f58f58aa"], "title": "GnT: A solver for disjunctive logic programs", "venue": "international conference on logic programming", "year": 2004, "id": "62b8a4cb-e4af-4a19-b4cc-0fe4f2dfbfc8"}
{"abstract": "This paper presents new techniques for slant and slope removal in cursive handwritten words. Both methods require neither heuristics nor parameter tuning. This avoids the heavy experimental effort required to find the optimal configuration of a parameter set. A comparison between the new deslanting technique and the method proposed by Bozinovic and Srihari was made by measuring the performance of both methods within a word recognition system tested on different databases. The proposed technique is shown to improve the recognition rate by 10.8% relative to traditional normalization methods. Moreover, a long exploration of the parameter space is avoided.", "authors": ["Alessandro Vinciarelli", "Juergen Luettin"], "n_citation": 120, "references": ["10217ead-c95b-41fc-a5b2-462406b3e6e0", "55b5741c-84aa-48c7-9956-21b03da16a6a", "9acbe275-c97e-46d4-a75d-73ddd5f3ccff", "a76de0fd-9ffe-4810-9ecb-014cbd4c405d", "b3519271-e743-4d4c-8a00-4357bcf9d4a3", "b43e405e-241b-4bcf-8c8e-6916de0ee6fd", "bf5a7e94-94c8-4fbf-a7bb-4b94cae58f5f", "e2334183-3e30-45f1-982d-338367af3fe0"], "title": "A new normalization technique for cursive handwritten words", "venue": "Pattern Recognition Letters", "year": 2001, "id": "bee6f5cd-6534-41d0-9aa1-bb089f4b355a"}
{"abstract": "We propose a new kind of programming language, with the following features:    a simple graph rewriting semantics,    a complete symmetry between constructors and destructors,    a type discipline for deterministic and deadlock-free (microscopic) parallelism.     Interaction nets  generalize Girard's  proof nets  of linear logic and illustrate the advantage of an  integrated logic  approach, as opposed to the  external  one. In other words, we did not try to design a logic describing the behaviour of some given computational system, but a programming language for which the type discipline is already (almost) a logic.  In fact, we shall scarcely refer to logic, because we adopt a naive and pragmatic style. A typical application we have in mind for this language is the design of interactive softwares such as editors or window managers.", "authors": ["Yves Lafont"], "n_citation": 428, "references": ["1bf17d1d-52cd-48da-858b-8c9c210b5864", "2dab6f63-88b6-45ef-883d-50c408b0e54e", "aa44dd48-8e1b-4c0e-b79e-95e3bf683345"], "title": "Interaction nets", "venue": "symposium on principles of programming languages", "year": 1989, "id": "69018a18-02ca-479b-8496-7e17ca432eda"}
{"abstract": "Engineering adaptable Web Information Systems (WIS) re- quires systematic design models and specification frameworks. A com- plete model-driven methodology like Hera distinguishes between the con- ceptual, navigational, and presentational aspects of WIS design and iden- tifies different adaptation \"hot-spots\" in each design step. This paper concentrates on adaptation in the presentation layer and combines the modeling power of Hera with the versatile presentation capabilities of the AMACONT project. After discussing different aspects of presenta- tion layer adaptation, the layout manager mechanism of AMACONT for describing the adaptable layout of ubiquitous Web presentations is in- troduced. Then the RDFS-based Hera schema for presentation models is presented, allowing to assign AMACONT layout descriptors to Hera slices. According to this formalization, Hera application model instances are automatically transformed to a component-based AMACONT im- plementation that can be adjusted to different end devices and output formats. The XML-based transformation process is explained in detail, and the resulting methodology is exemplified by a prototype application.", "authors": ["Zolt\u00e1n Fiala", "Flavius Frasincar", "Michael Hinz", "Geert-Jan Houben", "P Peter Barna", "Klaus Meissner"], "n_citation": 46, "references": ["06a65349-f77b-4b35-b0c8-5a1f11badd1a", "88514d59-116c-4e5d-ab86-0e4936144e8a", "95220f17-d29c-49ee-b556-96ca8624fc0b", "9df343f9-89ad-4aa1-bc2d-21235baa5035", "b24a446f-636d-4585-b1dd-a1116cf630ad"], "title": "Engineering the Presentation Layer of Adaptable Web Information Systems", "venue": "international conference on web engineering", "year": 2004, "id": "ba854432-7941-42e0-acc6-f98418d27057"}
{"abstract": "We show that the MEMS gyroscopes found on modern smart phones are sufficiently sensitive to measure acoustic signals in the vicinity of the phone. The resulting signals contain only very low-frequency information (<200Hz). Nevertheless we show, using signal processing and machine learning, that this information is sufficient to identify speaker information and even parse speech. Since iOS and Android require no special permissions to access the gyro, our results show that apps and active web content that cannot access the microphone can nevertheless eavesdrop on speech in the vicinity of the phone.", "authors": ["Yan Michalevsky", "Dan Boneh", "Gabi Nakibly"], "n_citation": 116, "references": ["142937f1-27cd-49fc-829e-de16d1e1e989", "3e727e45-e448-4f7e-902c-7f1a42a4c17c", "471886f8-7665-4842-82a5-669d0ea8c408", "50ceb126-690a-4c53-99fe-021b4a8068ae", "61aeb193-6b77-444d-9916-3b07cfb90f79", "7b86a407-77ca-424d-9775-cadb92f2458c", "8524f721-d51b-407c-8f16-a2cd042e8ceb", "97d04372-b0f9-4e83-8d66-a7239b89932a", "b0612876-2cb0-4ff3-a36f-ceb9b18731ac", "b7b85101-6a85-4ae3-aea2-4db576bb077f", "ba2af865-9a98-4fa2-87ed-cb35f59c720b", "ea9215da-5e81-440a-a49a-540a4ab8e318"], "title": "Gyrophone: recognizing speech from gyroscope signals", "venue": "usenix security symposium", "year": 2014, "id": "6bc23ebb-0ec7-41a0-94e7-8dc42534368d"}
{"abstract": "This paper analyzes two glucose-insulin models for diabetic patients: by Bergman and by Hovorka. Bergman?s model is nonlinear, and has relative degree three. It offers a good approximation of the system, but omits several important physiological functions, and insulin features, that are included in Hovorka?s Model. This is a nonlinear model with relative degree five. It includes most of physiological parameters of glucose system and insulin action. It has two glucose and insulin compartments. It describes in details the insulin action and the rate of appearance of subcutaneously injected insulin. An intestinal glucose absorption function is proposed to describe better the process of glucose production from ingested food. A renal excretion function is proposed in order to model kidneys filtration excretion. Hovorka?s non-insulin-dependent function has been smoothed to avoid discontinuities in the system. For both models homogeneous quasi-continuous controllers of order three and five are used giving a good performance from a medical point of view.", "authors": ["Gabriela Gallardo-Hernandez", "Leonid Fridman", "Sergio Islas-Andrade", "Yuri B. Shtessel"], "n_citation": 50, "references": ["0dc95f00-aa1f-46b9-be05-76801ca808fd", "5a416834-dd0b-4ab4-8449-da63216f0659", "67898dbb-1afc-4759-bc34-098b7b1c308e"], "title": "Quasi-continuous high order sliding modes controllers applied to glucose-insulin regulatory system models", "venue": "conference on decision and control", "year": 2008, "id": "dd7e52db-c8d1-4702-a152-15c97867ab48"}
{"abstract": "The purpose of this paper is devoted to revealing interconnection between rough sets and soft sets. We use the constructive and descriptive approaches of rough set theory and present a direct proof that Pawlak\u2019s and Iwinski\u2019s rough sets can be considered as soft sets.", "authors": ["Tutut Herawan", "Mustafa Mat Deris"], "n_citation": 43, "references": ["37cc00e5-06d6-4528-a11c-af54841193eb", "9fbb8fa1-a0e3-4792-a96a-31a7b8e36719", "a4589cfe-15e7-4c34-9349-d002d1d2c9df", "ed18e26d-3b63-4d1b-b173-3ecaa302a468"], "title": "A Direct Proof of Every Rough Set is a Soft Set", "venue": "", "year": 2009, "id": "bf13e369-f78a-46bd-9858-0058d0a2bdde"}
{"abstract": "Requirements assurance aims to increase confidence in the quality of requirements through independent audit and review. One important and effort intensive activity is assurance of the traceability matrix (TM). In this, determining the correctness and completeness of the many-to-many relationships between functional and non-functional requirements (NFRs) is a particularly tedious and error prone activity for assurance personnel to peform manually. We introduce a practical to use method that applies well-established text-mining and statistical methods to reduce this effort and increase TM assurance. The method is novel in that it utilizes both requirements similarity (likelihood that requirements trace to each other) and dissimilarity (or anti-trace, likelihood that requirements do not trace to each other) to generate investigation sets that significantly reduce the complexity of the traceability assurance task and help personnel focus on likely problem areas. The method automatically adjusts to the quality of the requirements specification and TM. Requirements assurance experiences from the SQA group at NASA's Jet Propulsion Laboratory provide motivation for the need and practicality of the method. Results of using the method are verifiably promising based on an extensive evaluation of the NFR data set from the publicly accessible PROMISE repository.", "authors": ["Daniel Port", "Allen P. Nikora", "Jane Huffman Hayes", "LiGuo Huang"], "n_citation": 11, "references": ["3f76a4ea-1394-4cbc-9e1d-eddb867b48da", "452b4ba8-a7b3-49db-919d-ebb08c9a0ab7", "6428af08-ad04-410b-8c5b-b4f3de7ed6bd", "6aea0481-7877-4e79-9bf1-5137d6b663f2", "6e198e5e-9655-418f-9abe-f2507c87ad91", "80c63bab-7331-4f78-a1c2-3a2a5b5b910e", "d82c3646-fbb2-4758-8b43-16ea40cd4b4e", "e427f800-7a52-4845-a774-fd5c823634d2"], "title": "Text Mining Support for Software Requirements: Traceability Assurance", "venue": "hawaii international conference on system sciences", "year": 2011, "id": "64250001-3ccd-4487-bdcb-6ce32cab0477"}
{"authors": ["Conor McBride"], "n_citation": 171, "references": ["112eeff7-c265-4808-aef5-55f592540e40", "12f8f9a6-a101-4027-9eab-57e38d57ee19", "2188694f-746e-4405-8be3-8d09ab312126", "23c82e3b-76e3-401a-835b-7b7cc9e708c0", "256c5797-5b28-4599-9093-1fdc7437ac01", "2c04adbe-7a6a-4562-817b-facb05b2fcb4", "33f6985c-5876-4bcc-aec6-ca3b130d6efe", "39b84d33-4d68-4d0f-82ec-3426e78060df", "40b5887a-c1a2-4267-a2ee-903c391168cc", "41385c93-631e-468a-a90c-ff4a4ff693f8", "4d6ddcd7-d67b-4838-ba56-600438b685f6", "58631863-757c-424f-b76c-95758e91cd36", "5cabfbfc-a629-49c0-abc8-36a697042f9f", "5fdf0aa2-049b-4432-82eb-c617ba57e1e0", "73e7debb-b80e-4332-b3b2-eddea02596a7", "8655d398-d47e-467c-b90f-8632c26f5046", "865fd42d-14d7-4089-b987-544518151dbd", "87e740d1-54d0-448b-a347-23a257f90478", "8b36d118-3402-46a2-a0d7-efe758cd5c60", "9868d134-5cbd-46d8-9a45-f3d84941ff3b", "98e38bda-53b0-415e-8724-f2e76ebfb5a9", "a9063810-eeee-425e-b7da-323335728ce3", "beecce0d-4540-4164-a653-61386e74c2f3", "c96937ce-fe4b-49b3-a924-986943bb2719", "cd6fe0f5-0956-4bb5-8d66-0b5b564dc8e3", "d51d7774-8362-482e-a755-70de6ea24e34", "d8c958a5-e203-4c92-87b5-505b2715c5e5", "e435c51c-247b-4386-8238-0f4d5d754eca", "e7366af9-ad8e-4dd6-aacb-4be62f35bc92", "f3dce363-577b-45b2-b9a5-2719749db98f", "f4d106c3-6929-4096-bf03-1b3a99a62552", "fc1432f8-7e2b-4d5c-963f-125a39bb11c5", "fec0e381-cba7-429d-99c0-ea176fe3c050"], "title": "Dependently Typed Functional Programs and their Proofs", "venue": "", "year": 2000, "id": "490a6e3e-e71f-424e-a075-5d574eb001b7"}
{"abstract": "Among mobile computing applications, location-based services are expected to be a big business for wireless operators. These services provide value added by considering the location of the user in order to give him/her more customized information. However, the processing of continuous location-dependent queries is still a subject of research. One of the key issues is how to update the answer presented to the user efficiently as it becomes obsolete very quickly. The goal of this paper is to analyze how to deal with situations where the answer cannot be updated with the desired frequency. We present several approaches to this problem and evaluate their performance.", "authors": ["Sergio Ilarri", "Eduardo Mena", "Arantza Illarramendi"], "n_citation": 50, "references": ["02cd77ef-1cbd-4f5c-93cf-1285bade333c", "0cb61938-314e-4046-a5fa-d546c988523d", "34dc8c98-9187-4efa-be8e-d2f8f7de36ab", "55a9c5fa-21bf-4091-b307-81ee74d435ff", "65374dfd-6d0b-4dfe-9a04-ffec27490f13", "b956c3c5-17a8-4c8f-b269-864c0a080931", "e0e0342d-ca34-4ca6-8b0f-29040a6070d0", "ed1db967-7ead-47fd-9382-c3bedc3f81be"], "title": "Dealing with continuous location-dependent queries: Just-in-time data refreshment", "venue": "pervasive computing and communications", "year": 2003, "id": "40982c72-9aa0-415d-9888-fda9b660c713"}
{"abstract": "We present a method for visual face tracking that is based on a wavelet representation of a face template. The wavelet representation allows: arbitrary affine deformations of the facial image; generalization from an individual face template to a rather general face template; and adapting the computational needs of the tracking algorithm to the computational resources available. The method presented was implemented on a Linux Pentium 450 MHz and runs off-line with 25 Hz, and online using an active camera mount at 22 Hz. We present experimental results on the off-line tests on several common image sequences including the salesman-sequence as well as on the online tests.", "authors": ["Volker Kr\u00fcger", "Alexander Happe", "Gerald Sommer"], "n_citation": 50, "references": ["1ba94a3f-ba8a-4aff-8151-3a855803711c", "397c2c5c-550a-4478-9d80-587fdee3f3f3", "762c9918-e579-42ef-80e5-4e464870a017", "920174c1-d25b-47e4-9221-93fdd42274ce", "a0e289f1-243c-4f05-909e-7a0077606430", "f3eb4ac3-9302-42aa-be89-7cf746f286fd"], "title": "Affine real-time face tracking using Gabor wavelet networks", "venue": "international conference on pattern recognition", "year": 2000, "id": "6e7d8571-0a48-4dcd-9756-042d2a193ee4"}
{"authors": ["Stefania Bandini", "Sara Manzoni"], "n_citation": 15, "references": ["1ed9b249-9712-4558-9405-d43fcc9e82ff", "be3fab9e-e823-410f-b8ac-821c291780a1", "c183c1ef-f2a0-491f-a852-6c688718b1ea", "ded361cf-6df4-46cc-b678-da6e3668a2f4", "e7f0e361-9abf-4e1d-9d1f-a7ea20f472a4"], "title": "Application of fuzzy indexing and retrieval in case based reasoning for design", "venue": "acm symposium on applied computing", "year": 2001, "id": "e1695d03-9341-4356-92ee-2874496ede2f"}
{"abstract": "In this paper we apply a machine learning approach to the problem of estimating the number of defects called Regression via Classification (RvC). RvC initially automatically discretizes the number of defects into a number of fault classes, then learns a model that predicts the fault class of a software system. Finally, RvC transforms the class output of the model back into a numeric prediction. This approach includes uncertainty in the models because apart from a certain number of faults, it also outputs an associated interval of values, within which this estimate lies, with a certain confidence. To evaluate this approach we perform a comparative experimental study of the effectiveness of several machine learning algorithms in a software dataset. The data was collected by Pekka Forselious and involves applications maintained by a bank of Finland.", "authors": ["Stamatia Bibi", "Grigorios Tsoumakas", "Ioannis Stamelos", "I. Vlahvas"], "n_citation": 57, "references": ["01b486c4-8955-403b-a0c6-1de74298b215", "02e0342a-33d3-4d3f-9f1d-b14081edbc39", "147d66ed-71a1-4744-b566-c224b484771b", "5e645ad2-e038-4b3f-9c61-62141e34ce12", "5fed1e5a-cf4c-45d3-8be7-b8daa5a558c8", "62549bc2-e0b3-46e8-8d32-390dded105d5", "845b8566-3003-4c39-afb4-f299e027f6aa", "9edb266e-b760-44fd-b95d-ff6d0014983d", "a1ffe673-7be6-49a1-b748-295d66cbb49f", "ac237969-3fd5-4303-83b7-a67e02afe976", "c64da505-b085-4094-b63d-8100450a0565", "d208cfec-8640-46b0-9eed-c66a43155018", "d6f70cf6-a9a6-47fa-81f6-bcbf95162cb4", "d8ddd4ae-16ab-4702-b4f5-65aff0e33533", "e3845bf5-3d43-4d74-ae57-54f6236f1bf7", "fcb41378-32f7-4aab-8458-fc5a99d74f92"], "title": "Software Defect Prediction Using Regression via Classification", "venue": "acs/ieee international conference on computer systems and applications", "year": 2006, "id": "87a37d5e-0f32-47e1-acb7-de563979c927"}
{"abstract": "In this paper we investigate a potential use of fluid approximation techniques in the context of stochastic model checking of CSL formulae. We focus on properties describing the behaviour of a single agent in a (large) population of agents, exploiting a limit result known also as fast simulation. In particular, we will approximate the behaviour of a single agent with a time-inhomogeneous CTMC which depends on the environment and on the other agents only through the solution of the fluid differential equation. We will prove the asymptotic correctness of our approach in terms of satisfiability of CSL formulae and of reachability probabilities. We will also present a procedure to model check time-inhomogeneous CTMC against CSL formulae.", "authors": ["Luca Bortolussi", "Jane Hillston"], "n_citation": 87, "references": ["045ee061-f35f-4785-a58c-a9ea4d812256", "0cebc33f-5f1e-4f5d-b797-03fb2c06ab80", "1a63ad71-c68a-443a-afd4-e83696e3d015", "24528701-2d54-4ed5-becd-97c46a6f5537", "247539cd-9405-461a-ac84-42fcf03f8f60", "24903b34-eb6e-4b71-b354-b67d04d93822", "34bb2555-8543-428f-864f-5014700030f9", "3fadbd85-cf70-4837-98d5-cae9d88ab6a7", "42fc844e-e582-45fa-8325-ca550ba37e6d", "4749aa6e-aad0-48ce-b0b3-eea342e385e0", "640e3371-808c-4edf-aef9-ac6634e6ede6", "6fa0203b-090f-450e-a0cd-f551f0e7790b", "7c3bec95-05ef-44da-931e-a3651160f36b", "8083af03-d725-4831-806c-5fedd3b6c193", "827a03fe-f4db-4c03-9067-00e8ef1b9598", "88af13cb-dd84-431f-b002-3d62904a4272", "9dbf0802-5eb0-4873-a199-244b2acc8c6a", "a1444bd2-1cda-411f-a86a-e462de91f7b1", "abf860ce-d3e6-497c-9411-01ed5593204b", "ad456e60-5a5d-44aa-be3a-4d1b4855222d", "b13f289b-a060-4f0a-921a-d7c8608f1f7f", "b1635334-53ce-48c3-8e87-b8e1ccc32b2d", "bd0176b7-6f08-42d6-8283-1ed915f03e71", "c3850097-908d-47fd-9bd9-571b23242479", "cd192c55-ae65-4c98-9345-4b6dc79af008", "db18bce4-1e7a-40c5-8500-e0d7699a7735", "df6a5b54-ac2a-4b38-9db1-6c3a3e430d95", "e0c3960f-9453-4ef8-9bbd-0815421fb8b2", "e6554eb7-44fb-45c2-bcbf-68b749e77db1", "e8c06489-748f-41dc-becc-2deecd3858a7"], "title": "Fluid model checking", "venue": "international conference on concurrency theory", "year": 2012, "id": "f68c4048-03a0-43a0-b5f4-6aa1cd942ecd"}
{"abstract": "Presents a theoretical framework for automatically partitioning parallel loops to minimize cache coherency traffic on shared-memory multiprocessors. While several previous papers have looked at hyperplane partitioning of iteration spaces to reduce communication traffic, the problem of deriving the optimal tiling parameters for minimal communication in loops with general affine index expressions has remained open. Our paper solves this open problem by presenting a method for deriving an optimal hyperparallelepiped tiling of iteration spaces for minimal communication in multiprocessors with caches. We show that the same theoretical framework can also be used to determine optimal tiling parameters for both data and loop partitioning in distributed memory multicomputers. Our framework uses matrices to represent iteration and data space mappings and the notion of uniformly intersecting references to capture temporal locality in array references. We introduce the notion of data footprints to estimate the communication traffic between processors and use linear algebraic methods and lattice theory to compute precisely the size of data footprints. We have implemented this framework in a compiler for Alewife, a distributed shared-memory multiprocessor. >", "authors": ["Anant Agarwal", "David A. Kranz", "Venkat Natarajan"], "n_citation": 164, "references": ["08c710de-10cc-4986-84e3-67acefd9c091", "0bf42e72-e9a5-4475-9d54-fd53e8e5138d", "1b02da42-6b4d-40fc-8bf7-2923dde3682f", "3734a77f-89f9-466b-ae08-850a969eccd6", "42fdbdef-7c37-4ef8-87d0-e06fa55b0a95", "502861bf-044d-42a0-bca9-5fb9d8497a58", "56ab8442-946a-41f4-8f17-b82d2aada70f", "965a8ca7-cd4b-467d-87e2-9105d6a0eff0", "ab14f900-a15c-45d4-bd90-f412fb075ad4", "d0350eed-b8ad-49b6-be28-98957ccb01e9", "d3558358-d8c8-49b7-ad20-6ae0dee2b040", "d8759d40-7707-443a-a7fa-039a5113a961", "da905f5d-682e-4e91-bd0d-9f7e658aa1b7", "e9072090-c9ba-4a3a-bf3b-ce369ee66bc9"], "title": "Automatic partitioning of parallel loops and data arrays for distributed shared-memory multiprocessors", "venue": "IEEE Transactions on Parallel and Distributed Systems", "year": 1995, "id": "4b9b6dde-3728-4511-8c85-7ef09f8e4599"}
{"abstract": "Owing to the low cost and convenience of identifying an object without physical contact, Radio Frequency Identification (RFID) systems provide innovative, promising and efficient applications in many domains. An RFID grouping protocol is a protocol that allows an off-line verifier to collect and verify the evidence of two or more tags simultaneously present. Recently, Huang and Ku (J. Med. Syst, 2009) proposed an efficient grouping protocol to enhance medication safety for inpatients based on low-cost tags. However, the Huang---Ku scheme is not secure; an attacker can easily make up fake grouping records to cheat the verifier. This weakness would seriously endanger the safety of inpatient medication safety. This paper will show the weaknesses, and then propose two RFID-based solutions to enhance medication safety for two different scenarios. The proposed schemes are practical, secure and efficient for medication applications.", "authors": ["Hung-Yu Chien", "Chia-Chuan Yang", "Tzong-Chen Wu", "Chin-Feng Lee"], "n_citation": 117, "references": ["03f2dd52-ad3e-43d8-856b-592105958b4a", "0486ac5f-307b-4b95-a2c0-57b5f0a53330", "0c1e3e45-ce78-4bb2-86e5-a6d793f7b6a0", "1bc14b7d-7ae4-48f5-ad18-07949408214e", "1e8b1868-cb11-43b0-ac08-998bd7de26b9", "2abed23f-93a9-4443-98cd-00dbfcd28f2b", "50571e94-e865-42f4-8f32-15c028020b70", "5a3c582b-71a4-4381-9f7f-bf8da5895e05", "5c6cf84d-fc5b-4ce4-9b42-1d66b3257f14", "7b6e5376-83f9-4a32-9481-090078137db6", "9eb699f6-df09-4640-b6ce-e31073164cf8", "dade127f-99ef-40d9-be5f-fafce31be297", "e4b523da-7c9f-4fc3-99a7-7a9de1b151e2"], "title": "Two RFID-based Solutions to Enhance Inpatient Medication Safety", "venue": "Journal of Medical Systems", "year": 2011, "id": "168971d7-09b9-46f9-9f17-17e94981ccf5"}
{"abstract": "The Source Code Control System (SCCS) is a software tool designed to help programming projects control changes to source code. It provides facilities for storing, updating, and retrieving all versions of modules, for controlling updating privileges for identifying load modules by version number, and for recording who made each software change, when and where it was made, and why. This paper discusses the SCCS approach to source code control, shows how it is used and explains how it is implemented.", "authors": ["Marc J. Rochkind"], "n_citation": 727, "title": "The source code control system", "venue": "IEEE Transactions on Software Engineering", "year": 1975, "id": "33dd7ce8-453e-4824-b700-6d29d69d5502"}
{"abstract": "It is shown that for any set of positive integers $\\{ n_1 ,n_2 , \\cdots ,n_p \\} $, there exists a procedure which computes $\\{ x^{n_1 } ,x^{n_2 } , \\cdots ,x^{n_p } \\} $ for any input x in less than $\\lg N + c\\sum_{i = 1}^P [\\lg n_i /\\lg \\lg (n_i + 2)]$ multiplications for some constant c, where $N = \\max _i \\{ n_i \\} $. This gives a partial solution to an open problem in Knuth [3, \u00a7 4.6.3, Ex. 32] and generalizes Brauer\u2019s theorem on addition chains.", "authors": ["Andrew Chi-Chih Yao"], "n_citation": 106, "title": "On the Evaluation of Powers", "venue": "SIAM Journal on Computing", "year": 1976, "id": "bfbe5c30-4840-4274-bc9c-872864ec3ec1"}
{"authors": ["Michael Philippsen", "Bernhard Haumacher", "Christian Nester"], "n_citation": 143, "references": ["0737d4bc-9976-49dd-896d-0fe88b11b541", "15e68bb6-3fb4-4071-9567-fb1e64787738", "22dc34f7-bd6a-4f3f-822c-6fe8d6d2bf43", "361701fa-c56d-40b5-b25f-2a0fae6564c6", "3fde9cbc-651b-4d22-9262-782c3f2bc4a6", "5131054c-2a54-4e33-9285-2fd76d4df543", "5b89135d-179d-427e-ac38-43d67eef909b", "7d6124eb-3b72-4797-bf12-6d4ab5eb9083", "a6f2067f-19c0-4847-a36d-bc7d49c719e2", "c3ce6916-38e6-48f5-9bc2-d6c32398f69f", "cad98767-8419-4148-9a37-e5bccf7ad071", "ce208c92-cb70-456d-b785-981ebb4bad34", "cfe24701-0afd-4415-9b09-ae01b233344f", "f04fcf11-8011-4ddd-b670-476c519ccb68"], "title": "More efficient serialization and RMI for Java", "venue": "Concurrency and Computation: Practice and Experience", "year": 2000, "id": "b626ee19-da0a-49a4-b9af-5c4cc767c79d"}
{"abstract": "We are living in a world where there is an increasing need for evidence in organizations. Good digital evidence is becoming a business enabler. Very few organizations have the structures (management and infrastructure) in place to enable them to conduct cost effective, low-impact and fficient digital investigations [1]. Digital Forensics (DF) is a vehicle that organizations use to provide good and trustworthy evidence and processes. The current DF models concentrate on reactive investigations, with limited reference to DF readiness and live investigations. However, organizations use DF for other purposes for example compliance testing. The paper proposes that DF consists of three components: Pro-active (ProDF), Active (ActDF) and Re-active (ReDF). ProDF concentrates on DF readiness and the proactive responsible use of DF to demonstrate good governance and enhance governance structures. ActDF considers the gathering of live evidence during an ongoing attack with a limited live investigation element whilst ReDF deals with the traditional DF investigation. The paper discusses each component and the relationship between the components.", "authors": ["Cornelia Petronella Grobler", "C. P. Louwrens", "S. H. von Solms"], "n_citation": 50, "references": ["04c18612-9c5e-4b69-b9cd-a2da38e72485", "2ba28aac-43c1-45a0-b123-f9ea6511538d", "2cf4a7d2-290b-423c-ad75-db48bdf67ba6", "7ee82bdf-5acb-4d0e-9582-99ff9b561283", "874f6c58-d6a5-4643-b0f2-0a67e05ad8e5", "8e458c54-7fa3-47fb-8628-10c6c2c37429", "9848c221-22bc-47ac-89fa-3ecf421c14dd", "a05f7c30-a60d-45d4-954e-085c14de1084", "cc6f0105-98eb-4ccb-b7a7-1b65a691ef09", "e64d39e5-6904-4d45-aed7-28723d45e96e"], "title": "A Multi-component View of Digital Forensics", "venue": "", "year": 2010, "id": "82369200-097b-41eb-a9e3-e6c50c720c50"}
{"abstract": "This paper introduces Cloud9, a platform for automated testing of real-world software. Our main contribution is the scalable parallelization of symbolic execution on clusters of commodity hardware, to help cope with path explosion. Cloud9 provides a systematic interface for writing \"symbolic tests\" that concisely specify entire families of inputs and behaviors to be tested, thus improving testing productivity. Cloud9 can handle not only single-threaded programs but also multi-threaded and distributed systems. It includes a new symbolic environment model that is the first to support all major aspects of the POSIX interface, such as processes, threads, synchronization, networking, IPC, and file I/O. We show that Cloud9 can automatically test real systems, like memcached, Apache httpd, lighttpd, the Python interpreter, rsync, and curl. We show how Cloud9 can use existing test suites to generate new test cases that capture untested corner cases (e.g., network stream fragmentation). Cloud9 can also diagnose incomplete bug fixes by analyzing the difference between buggy paths before and after a patch.", "authors": ["Stefan Bucur", "Vlad Ureche", "Cristian Zamfir", "George Candea"], "n_citation": 182, "references": ["069f4627-8091-4963-afca-a9b3395452bc", "1f61c1ee-fa4d-42d1-9542-a1e1a3ac2901", "22640ff1-e18b-42f7-ab18-3d39a2937709", "47719c03-913e-4acb-8fec-6767eaeef660", "4b6fa73e-a6a8-4add-aaf1-dfd08919253e", "5c3f1cb9-0ea2-4ebd-9271-19791e07702e", "71c47dd0-a7ff-4b97-a640-1186dd9ac968", "7c816204-72a6-43ca-a55e-5d1bfc4c4890", "7ee44c7c-2712-4d16-a9c6-cf4ac3575537", "8873cda3-f462-4b6f-a70c-1271f2f00664", "8bf79e19-cf6e-4c7b-96c9-72809cad1201", "b1a82cb5-5952-4d1f-a82f-8873412fedbe", "c6087348-c3a1-470c-982f-e7c5e6def02d", "c659438c-7f79-49c8-8fee-f86155373ca2", "cb752150-dd37-4c74-825b-80ac7843df48", "d57f08ef-fb06-453b-9fe0-b7f266681bf1", "f15d0ef1-865e-4537-8ce2-91a36d61d95d", "f530595d-b277-44fd-91fd-59b9e02547c2", "ff02b616-bcf2-411e-b744-8f635e36710e"], "title": "Parallel symbolic execution for automated real-world software testing", "venue": "european conference on computer systems", "year": 2011, "id": "ffed5767-3cb9-4f34-8bcc-a1425ade9fce"}
{"authors": ["David N. Yetter"], "n_citation": 89, "references": ["aa44dd48-8e1b-4c0e-b79e-95e3bf683345"], "title": "Quantales and (Noncommutative) Linear Logic", "venue": "Journal of Symbolic Logic", "year": 1990, "id": "dec0c3b7-5bc6-44a6-9d8b-d9e60e2dbc9f"}
{"abstract": "We design a distributed secondary frequency control scheme for both generators and controllable loads. The proposed scheme operates via local sensing and computation, and neighborhood communication. Equilibrium and stability analysis of the closed-loop system is performed with a power network model including turbines and governors of generators and nonlinear AC power flows. After a change in power supply or demand, the proposed scheme is able to stabilize the system, restore bus frequencies and net inter-area power exchanges, and minimize total generation cost minus user utility at equilibrium.", "authors": ["Changhong Zhao", "Enrique Mallada", "Steven H. Low"], "n_citation": 50, "references": ["1651a23b-9312-48d5-8b77-9dca364610f2", "583e16d7-20b6-4969-bd8c-ff37c240a8fd", "7b991d61-1c4b-43c5-a8f3-e29e5e316308", "8ebf1b3d-f70a-4591-8129-2322845c429e", "9585b01e-5123-4d5d-9d64-294c1564b036", "b72e31a3-b3a8-4589-8ea0-6f02d9424b44", "eb8ec11b-3251-41f0-a41e-d62a161da738", "ee9cf27d-f32c-41a3-8972-401d99d9231d"], "title": "Distributed generator and load-side secondary frequency control in power networks", "venue": "conference on information sciences and systems", "year": 2015, "id": "2a7be23f-3b95-4bc8-98d6-efd25a6ad5ac"}
{"abstract": "We propose an algorithm, CBM-Gen+, to refine case bases for hierarchical and incomplete domains. In these domains, the case bases are the main source of domain information because of the absence of a complete domain theory. CBM-Gen+ revises the existing cases when a new solution is captured. The main purpose of this revision is to reduce inconsistencies in the cases. We will prove that CBM-Gen+ is sound relative to the captured solutions. We also perform experiments showing that CBM-Gen+ is on average at least as efficient as a previous approach for constructing case bases for hierarchical domains.", "authors": ["Ke Xu", "H\u00e9ctor Mu\u00f1oz-Avila"], "n_citation": 5, "references": ["0989b1b1-6ec3-492d-9edb-09095ab95f00", "0d094654-b55e-4883-803f-02c3b35c2d67", "120457f6-4201-4000-b7ce-7dd292c031ee", "139aa333-a8b6-4f58-b7d9-d94edce83b11", "248cb9ab-f57f-4c36-bb0a-a59b7331dd57", "3c12e508-20d6-4447-9c96-119d52f1f7ed", "3e7d9d99-08e3-43ca-82ad-3de3cd2cd62a", "5f4ecb2e-5455-4ee8-8176-3a811dc774e0", "7e19e909-4aa6-4177-914a-62ac699ad5d7", "a1eed499-7e6f-47e0-9e58-e4418d3f24c7", "c1afacf8-aaf1-4750-a8b3-2b858dc694af", "e365f200-5d0d-41e9-a967-30f3e80b14f6"], "title": "CBM-Gen+: an algorithm for reducing case base inconsistencies in hierarchical and incomplete domains", "venue": "international conference on case based reasoning", "year": 2003, "id": "d248bd6a-0576-4dc2-b4ce-484a02990418"}
{"abstract": "We propose to synthesize a control policy for a Markov decision process (MDP) such that the resulting traces of the MDP satisfy a linear temporal logic (LTL) property. We construct a product MDP that incorporates a deterministic Rabin automaton generated from the desired LTL property. The reward function of the product MDP is defined from the acceptance condition of the Rabin automaton. This construction allows us to apply techniques from learning theory to the problem of synthesis for LTL specifications even when the transition probabilities are not known a priori. We prove that our method is guaranteed to find a controller that satisfies the LTL property with probability one if such a policy exists, and we suggest empirically that our method produces reasonable control strategies even when the LTL property cannot be satisfied with probability one.", "authors": ["Dorsa Sadigh", "Eric S. Kim", "Samuel Coogan", "Shankar Sastry", "Sanjit A. Seshia"], "n_citation": 50, "references": ["10faea31-cb77-4a47-8ec5-42f51c56c284", "208cb1e1-ba3f-4f12-9e85-60e60a4a89df", "20dcb28c-c54d-4b57-a521-6d7fe767830e", "252b9e3e-4e30-426b-b4fc-2859b4e5503c", "62a074d0-3ff5-405d-8e57-b22060f46a90", "804b4514-78c7-40fb-a625-aeae061ce45c", "83fa4cb3-9d63-4045-bfc2-06bfa8eec305", "ba03376f-9a4f-48df-9a8a-a6c96f1dd164", "c3e587aa-9c56-4cfc-8542-885ff4a2d13e", "cfa18e04-a6b2-47d7-ba59-e5b0b5917128"], "title": "A learning based approach to control synthesis of Markov decision processes for linear temporal logic specifications", "venue": "conference on decision and control", "year": 2014, "id": "de3589ac-497a-4534-9962-9f90955583d5"}
{"abstract": "Direct manipulation, which is the dominating \"interaction style\" for mobile computers, fails to meet the conditions of many mobile use situations. In particular, it demands too much visual attention of the user. We introduce a new, complementing interaction style (and system) for mobile computers, called MOTILE, which addresses three main requirements of interaction with mobile computers: (1) no visual attention needed; (2) structured, tactile input, and; (3) the use of audio feedback. MOTILE relies on only 4 buttons for user input and \"hands free\" audio for feedback.", "authors": ["Steinar Kristoffersen", "Fredrik Ljungberg"], "n_citation": 50, "references": ["0a3cee8d-86b8-47b0-96b6-f14a99f9d511", "0b6c99a4-74af-4b16-bef9-ae15961e2474", "6e21a886-ca9f-42b9-9eb9-08bfae47b27d", "a6a9a385-1a00-4465-b361-14e5ae98c4be", "ac1b9af1-16ef-4146-9d44-02c3f58c4c8d", "b53a4e8b-970b-4a62-9789-71e333441489", "c054b482-81e2-4e80-aea8-844066cb4b5c"], "title": "Designing Interaction Styles for a Mobile Use Context", "venue": "ubiquitous computing", "year": 1999, "id": "7449b630-8194-4dd1-8e11-ec7275af628a"}
{"abstract": "A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (\u201csemantic structure\u201d) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. initial tests find this completely automatic method for retrieval to be promising.", "authors": ["Scott Deerwester", "Susan T. Dumais", "George W. Furnas", "Thomas K. Landauer", "Richard A. Harshman"], "n_citation": 12530, "references": ["0311300d-abf0-4908-95f6-d2c34ba67242", "28d80fb2-745b-4c03-a8dc-829c46ddf3fb", "28dc7c8d-7258-4bc5-ad19-71fc1d43070f", "401f5e6f-0f6e-4415-8003-426aea537d53", "6d582fdc-b040-4c48-80d8-02c7cfd37fa2", "ad733e2e-168a-4419-8ff1-c39ba63286b8", "bacbfdeb-d4ac-433f-8a08-cf41d5a4b663", "d1ecaea6-5280-450e-aa48-70d1b7c4db7e", "e75d8e62-a86d-4241-953f-1b315005d920"], "title": "Indexing by Latent Semantic Analysis", "venue": "Journal of The American Society for Information Science", "year": 1990, "id": "ac14afe6-de4d-4056-b2ac-0f6e36f369a2"}
{"abstract": "Flexible queries facilitate, in a novel way, easy and concise querying of databases that have varying structures. Two different semantics, flexible and semiflexible, are introduced and investigated. The complexity of evaluating queries under the two semantics is analyzed. Query evaluation is polynomial in the size of the query, the database and the result in the following two cases. First, a semiflexible DAG query and a tree database. Second, a flexible tree query and a database that is any graph. Query containment and equivalence are also investigated. For the flexible semantics, query equivalence is always polynomial. For the semiflexible semantics, query equivalence is polynomial for DAG queries and exponential when the queries have cycles. Under the semiflexible and flexible semantics, two databases could be equivalent even when they are not isomorphic. Database equivalence is formally defined and characterized. The complexity of deciding equivalences among databases is analyzed. The implications of database equivalence on query evaluation are explained.", "authors": ["Yaron Kanza", "Yehoshua Sagiv"], "n_citation": 113, "references": ["1d521a67-921d-4448-aab7-6adb4b93a69b", "1dbba796-30d0-4d1c-adda-2d1a2eb0286d", "213730bd-8c27-437f-8364-c0e05abd5b4c", "3de95199-e946-464c-87a2-4c2e1393ea02", "4a4952ea-c4f2-4366-8f8f-d111338a5592", "4dfdc1cc-4ade-46f7-af48-4d03298ce40f", "537b67be-44c2-4861-a40e-dce69224bb87", "58db62cc-07af-406c-b787-bafe6fe41a1e", "5f0ab6ec-1d9a-4ae1-948e-ef00a535e4f4", "6185613c-cf04-48f7-a200-fb7d5dba3975", "62a2fb3a-8f37-4eb4-913c-1b9ce79a8ad2", "6931ca7d-c573-4631-8451-7da22ac3ff34", "6f87cc34-22a9-48ca-ab02-1caaea9af8d6", "701a48c4-ae21-4b87-9cfe-a4d752f4e84a", "75523088-6e3c-4b16-aa92-4bede52d5c28", "7aa62859-da2b-412b-b566-c01493aa3e9d", "815fad3f-ee6f-4c73-8487-79f8b3c1269c", "b406c0e2-f2a0-4c7e-aaca-dd8f0f63c1a2", "cde0827f-f48a-4310-8bb2-8222d97e1a56", "d7d5abf8-511b-4280-92fe-b9a5a98e2564", "ef78330f-d706-48b4-a37d-4a971ab0c1d5", "f8f6cfc8-cca2-436d-a15e-592c5d7d4c94"], "title": "Flexible queries over semistructured data", "venue": "symposium on principles of database systems", "year": 2001, "id": "d0d70571-8944-4cad-a2c9-06d332347f9f"}
{"abstract": "English: A new performance and performability modeling tool is introduced in this paper. PENELOPE is the first tool which incorporates evaluation and optimization algorithms. It is the result of a combination between the performability modeling concept and Markov decision theory. Different algorithms are adopted and included in the tool under the unifying paradigm of reconfigurability as the basis for adaptation and optimization. In addition to transient and steady-state performability measures, also transient and stationary control functions can be computed and graphically presented. Model specification and specification of transient or stationary control functions can be separately performed and deliberately combined with each other. Besides providing a new modeling paradigm, the tool supports model creation, experimentation, storage and presentation of results by means of an easily usable interface and an integrated model data base system. German: Es wird ein neues Softwaretool fur die Performability-Modellierung vorgestellt. PENELOPE ist das erste Tool, welches Analyse- und Optimierungsalgorithmen vereinigt. Es verbindet das Performability-Modellierungskonzept mit der Markov''schen Entscheidungstheorie. Im Tool sind verschiedene Algorithmen aufgenommen, die sich unter dem Paradigma der Rekonfiguration zur Optimierung einsetzen lassen. Neben transienten und stationaren Performability-Masen konnen auch transiente und stationare Kontrollfunktionen berechnet und graphisch dargestellt werden. Modelldefinition und Spezifikation transienter oder stationarer Kontrollfunktionen konnen getrennt durchgefuhrt und beliebig miteinander kombiniert werden. Neben der Realisierung eines neuen Modellierungs- und Optimierungskonzeptes untersutzt das Tool Modellerstellung, Experimentierung, Datenspeicherung und Ergebnisprasentation mittels einer benutzerfreundlichen, graphischen Oberflache und einem integrierten Datenbanksystem.", "authors": ["Hermann de Meer", "Hana \u0160ev\u010d\u00edkov\u00e1"], "n_citation": 50, "references": ["4e4f4901-df4c-4efa-9781-0436760a4c52", "4eebc8ad-4226-47a4-a521-b208cab11ead", "64783443-a830-4f7d-9063-026493942009", "d09fad3c-7d18-426a-b1f7-acd93d3527f0", "eb7a1c52-01a3-426c-8b80-cd91beb658c8", "fec7ad7f-5e53-45c7-9a3a-2e7500123d98"], "title": "PENELOPE: Dependability Evaluation and the Optimization of Performability", "venue": "", "year": 1997, "id": "cd166f3e-2682-486d-a4f5-7219431b5c80"}
{"abstract": "Software protection is an area of active research in which a variety of techniques have been developed to address the issue. Examples of such techniques are software watermarking, code obfuscation, and tamper detection. In this paper we present a novel dynamic software watermarking algorithm which incorporates ideas from code obfuscation and tamper detection. Our technique simultaneously provides proof of ownership and the capability to trace the source of the illegal redistribution. It additionally provides a solution for distributing pre-packaged, fingerprinted software which is linked to the consumer. Our technique is specific to programs compiled for the x86 Intel architecture, however, we have proposed an extension for use on Java bytecode.", "authors": ["Ginger Myles", "Hongxia Jin"], "n_citation": 50, "references": ["05eb9841-ca1b-49a1-9ced-6be149eea902", "13319371-cf85-4369-9d5a-df7b4d67e892", "4ce5e51a-c112-4d91-8387-a046b11486ba", "6d0e89c7-dde0-4e23-bf72-903365210d8c", "998f9031-c52b-4c5b-8097-110b15229dd1", "cc98aeb3-e9cc-46ba-b4bf-9b957f633183", "ec83d2a6-b348-4e77-ae5c-ae58b43d8330", "ef4a6cf6-1255-406c-a76f-a3b07cb7f56c"], "title": "Self-validating branch-based software watermarking", "venue": "information hiding", "year": 2005, "id": "df181be7-fa51-4fcb-8432-571278147e8a"}
{"abstract": "We develop tools for investigation of input-to-state stability (ISS) of infinite-dimensional control systems. We show that for certain classes of admissible inputs, the existence of an ISS-Lyapunov function implies the ISS of a system. Then for the case of systems described by abstract equations in Banach spaces, we develop two methods of construction of local and global ISS-Lyapunov functions. We prove a linearization principle that allows a construction of a local ISS-Lyapunov function for a system, the linear approximation of which is ISS. In order to study the interconnections of nonlinear infinite-dimensional systems, we generalize the small-gain theorem to the case of infinite-dimensional systems and provide a way to construct an ISS-Lyapunov function for an entire interconnection, if ISS-Lyapunov functions for subsystems are known and the small-gain condition is satisfied. We illustrate the theory on examples of linear and semilinear reaction-diffusion equations.", "authors": ["Sergey Dashkovskiy", "Andrii Mironchenko"], "n_citation": 48, "references": ["07bc7464-2b33-4a4b-b93c-6766efbdc62d", "0b595d8b-54f7-4d1f-8a02-872bd25557fc", "0e8c877b-ccac-4fc4-be97-43f39407b67d", "1f55ebf0-dc69-40aa-811e-9ae68690488f", "2467d6f5-0472-46b4-b007-57322ea78e4b", "37971b99-f57d-421b-9f27-1a8b6dae2245", "3b23bd1e-89f8-469d-a07e-3ac4e1b62a8a", "3ffc1845-eca6-4d14-8f3d-25b21c8e4edb", "47eae030-9214-4c4f-93d7-d5f12054ff2d", "53f55936-fb85-4862-aa86-5e9ee0573693", "6a01425f-7d6c-445a-8e63-a5f019166746", "752e1348-2775-4d9a-a1aa-534b7dc6a8b2", "873ba279-5c87-4469-a5ff-440340f20671", "8e1f94ec-71a9-47b4-a95d-1c9695f904db", "909fdd68-0533-466b-980f-fa733e617aa6", "90aa0b41-2234-43be-a0b3-3d9dab4f9477", "91a45ea8-5b6e-4f1d-9266-8497665c9209", "a1112fd8-c4b2-444d-a75b-b398e2e95415", "a5707d9c-e18a-441f-8471-dd95a020f8f3", "ae0be6b3-9ab8-4852-aa2b-cc40591cd868", "b8a5bf53-c613-40ae-9051-28a975a2ed21", "dbd17d6a-f282-4ce6-9ce3-c11870d246cc", "eb6c1205-d6dc-49e9-a805-c21fcdce3bab", "efe3fe52-5bc7-4e1a-89da-785a8cb5c551", "f29c5e75-7f6e-4498-9c12-e2868f74e844", "f75481c0-4ac7-4b23-85d1-a3bcd9263fe1", "ffa56098-da9d-4ecf-afcf-a099bb58cd90"], "title": "Input-to-state stability of infinite-dimensional control systems", "venue": "Mathematics of Control, Signals, and Systems", "year": 2013, "id": "f965ddb2-10b3-4d5d-b427-c358f65c4008"}
{"abstract": "A framework for object segmentation in vector-valued images is presented in this paper. The first scheme proposed is based on geometric active contours moving towards the objects to be detected in the vector-valued image. Objects boundaries are obtained as geodesics or minimal weighted distance curves in a Riemannian space. The metric in this space is given by a definition of edges in vector-valued images. The curve flow corresponding to the proposed active contours holds formal existence, uniqueness, stability, and correctness results. The technique is applicable for example to color and texture images. The scheme automatically handles changes in the deforming curve topology. We conclude the paper presenting an extension of the color active contours which leads to a possible image flow for vector-valued image segmentation. The algorithm is based on moving each one of the image level-sets according to the proposed color active contours. This extension also shows the relation of the color geodesic active contours with a number of partial-differential-equations based image processing algorithms as anisotropic diffusion and shock filters.", "authors": ["Guillermo Sapiro"], "n_citation": 95, "references": ["15fa9942-e476-407e-90b6-ac05717b6470", "1c63e1d5-b963-455b-829d-e4f3eb63a36a", "2ccb01b5-e59c-4ff4-b627-a76a72c9738c", "46257da0-7ebd-4f5d-8ead-0ecd6d52a0fc", "4d9628fc-d4fa-4751-8239-3cf44abb15c5", "56283580-b0b6-488d-9e30-fd65f6154e23", "567254ba-8465-4d6e-ae45-4e3fbb901944", "5db3ae5d-1bff-439d-b83f-147ba7ccacbb", "6c341eb6-f901-4353-b5ff-8da4ce990d11", "82eb55e6-39a8-4968-8be6-e2bfbb439a40", "89c28928-67d0-4cd3-8cb4-edc71d1f9699", "988e51d5-75de-4102-8659-b2d9a87db947", "ad23ca01-fa76-4f9a-ba68-27dc2c51784f", "b2de99a5-01d1-4359-be11-10c2ce130a05", "b608af66-6368-44dc-a670-2a3e42561ee1", "cdb46f0d-b34f-4987-a4b1-7a661c3f53b5", "ef330947-bc34-4f55-834b-40469ee33769", "f18355d4-bc52-48c8-bae0-309cb9d4307a"], "title": "Vector-valued active contours", "venue": "computer vision and pattern recognition", "year": 1996, "id": "f350600e-ae44-4969-92e4-1ce135f90993"}
{"abstract": "The lack of a method for developing programs from Z specifications is a widely recognized difficulty. In response to this problem, different approaches to the integration of Z with a refinement calculus have been proposed. These programming techniques are promising, but as far as we know, have not been formalized. Since they are based on refinement calculi formalized in terms of weakest preconditions, the definition of a weakest precondition semantics for Z is a significant contribution to the solution of this problem. In this paper, we actually construct a weakest precondition semantics from a relational semantics proposed by the Z standards panel. The construction provides reassurance as to the adequacy of the resulting semantics definition and additionally establishes an isomorphism between weakest preconditions and relations. Compositional formulations for the weakest precondition of some schema calculus expressions are provided.", "authors": ["Ana Cavalcanti", "Jim Woodcock"], "n_citation": 50, "references": ["080b0afe-fbf7-4a33-80f8-ae36d12cd90e", "29359074-2878-4430-a411-65b542160ddb", "3300b80c-20c9-45c4-8c9b-9cce4bb72030", "3e463040-e697-4c3c-a555-5635b90ef134", "3f88cee5-4566-47ac-95d6-cd19b56de0f0", "5c304829-f19b-4c02-b02b-a70027cba660", "5cef570a-cfa2-462e-820e-05682b0c91f3", "9086a437-bdde-48ba-963b-e9e6991d46f5", "91fa8ca4-6800-4a6b-a229-fe7388a46a61", "948ec2bd-aa9d-45a5-8b36-dcdfff23d808", "ba5b9fbf-47de-46c6-a8aa-86fd6cb4b70c", "dbda5440-1d8d-4c18-b2cf-bbc1bd385537", "e0fb7296-5f4a-4240-911d-d6edce3f33b8", "f0bc77f3-834c-47d8-bf08-e98a46e6ab3e"], "title": "A Weakest Precondition Semantics for Z", "venue": "The Computer Journal", "year": 1998, "id": "7ba8bed7-099e-4c19-8a7e-39efe43f6e52"}
{"abstract": "The problem of consistently engineering large, complex software systems of today is often addressed by introducing new, \"improved\" models. Examples of such models are architectural, design, structural, behavioral, and so forth. Each software model is intended to highlight a particular view of a desired system. A combination of multiple models is needed to represent and understand the entire system. Ensuring that the various models used in development are consistent relative to each other thus becomes a critical concern. This paper presents an approach that integrates and ensures the consistency across an architectural and a number of design models. The goal of this work is to combine the respective strengths of a powerful, specialized (architecture-based) modeling approach with a widely used, general (design-based) approach. We have formally addressed the various details of our approach, which has allowed us to construct a large set of supporting tools to automate the related development activities. We use an example application throughout the paper to illustrate the concepts.", "authors": ["Alexander Egyed", "Nenad Medvidovic"], "n_citation": 50, "references": ["207cfa96-d888-4f50-9c68-8332f68701b1", "39c72c08-2556-45fa-9963-aca832fe0f34", "7f98ff3f-83eb-4aaa-87d2-92df44d5aa68", "9f1e1f2a-cbf6-49c0-acbc-075c072bdcc4", "a13a126e-37f7-4fad-8cfe-a3184320d64a", "ba1b9b3f-d911-4ad6-bd03-afa54de2ccee", "c2b3f6cf-ea37-46c1-8143-8c454474f7fa", "d1c3f9f5-aed3-4eed-8783-2ecd71aa7bed", "d6285e34-13fa-4327-b4f9-203181baa8c6", "ded73f0a-0715-469f-b384-a98cc070a908", "f9e2163f-1816-4267-aaee-c152e723390c"], "title": "A Formal Approach to Heterogeneous Software Modeling", "venue": "fundamental approaches to software engineering", "year": 2000, "id": "53a359cf-aa54-4df9-b994-2813170d26ce"}
{"abstract": "Research on organization of Multiagent Systems (M.A.S.) has shown that by adapting its organization, a M.A.S. is better able to operate in dynamic environments. In this paper we describe an experiment with a M.A.S. that consists of agents where the capability to reorganize is integrated in their coordination mechanism. In the RoboCupRescue simulator we have implemented a M.A.S. where work can be coordinated according to three different coordination styles; direct supervision and standardization of skills with and without a reorganization extension. An experiment shows the effects of unknown workload distribution and incomplete information on the performance of the three styles. Results show significant interaction effects between both workload distribution and coordination mechanism, and completeness of information and coordination mechanism. Furthermore, results show that standardization of skills with reorganization performs better and is more robust to heterogeneous workload distribution and incompleteness of information.", "authors": ["Mattijs Ghijsen", "W.N.H. Jansweijer", "Bob J. Wielinga"], "n_citation": 50, "references": ["9cf7063a-7efd-4cee-bdbc-8b94881c28ca", "af008096-c627-4502-9553-ecdfc9593e35", "b18497b5-f562-4d2a-bf57-48f502dbd028"], "title": "The effect of task and environment factors on M.A.S. coordination and reorganization", "venue": "adaptive agents and multi-agents systems", "year": 2007, "id": "6b28fff4-7f41-41c3-b8b3-2337e80f76da"}
{"abstract": "In order to apply formal methods in practice, the practitioner has to comprehend a vast amount of research literature and realistically evaluate practical merits of different approaches. In this paper we focus on explicit finite state model checking and study this area from practitioner's point of view. We provide a systematic overview of techniques for fighting state space explosion and we analyse trends in the research. We also report on our own experience with practical performance of techniques. Our main conclusion and recommendation for practitioner is the following: be critical to claims of dramatic improvement brought by a single sophisticated technique, rather use many different simple techniques and combine them.", "authors": ["Radek Pel\u00e1nek"], "n_citation": 66, "references": ["03f56a8e-f568-496f-9b8f-a2057946e524", "058d284b-e1eb-4b5e-87b0-e6a9be081011", "06ec273c-32a2-4278-9781-d828d7cd4ff7", "11ebc58a-0005-4617-8a53-e61b4ee37c36", "1755ded2-098c-4c78-96a0-c346dd0192a4", "18fb136d-229f-4c03-94b3-bf02e0945adc", "1b30de90-c0ca-4e82-8ab9-f64c43093910", "1c894a99-d6ba-4604-af66-dd89f65446c0", "21729040-69fc-4f29-9889-5337a7495b08", "2483648e-0238-41ee-a94f-a5b4a5473b8e", "269ff4cd-9fc1-423e-a9db-a08a37c30f5a", "357293ec-a678-4046-aed2-974919b7a9d1", "3e5c9f17-7476-4707-9992-1f2af85870dc", "3f7981eb-7e84-449e-bced-7a7dabba788c", "42864c94-1428-4f59-987a-a12aaaaf8014", "4a4224ff-c974-4f53-9a80-39fb2934a09b", "521e0543-ce7e-4d41-bf1f-9bfd4ad37792", "56af74f2-31af-4c23-86e7-e7fcf7c6177e", "5a11bdba-a1e0-4fa3-b721-28881da79107", "5a126ceb-0ba0-496e-8318-2032e5902ee3", "5c6f8d0c-e480-448d-a292-14824f3f9b57", "5d8fd21e-2980-4c3c-b357-fc53d2df5d2d", "72933384-82e9-4a48-96ef-ae7b6ed0f224", "752a0858-0023-45c4-a29f-0410496164bb", "7ce20005-d12a-48af-9d4f-a575fcf12af5", "8093aa90-979b-4663-b394-138a0af0d5db", "8873cda3-f462-4b6f-a70c-1271f2f00664", "8e138c54-5ef0-4c06-87ea-3dddebbb26ae", "8f69c80b-e8eb-487d-bbad-e969d4b76cc9", "9395643e-168e-41fe-8bfd-59f21aee28e4", "9849d9c4-a97f-452f-882c-42a8c6cab0b5", "9b2f9fd4-1073-4512-8be2-e25b25e5c789", "9ca18d9e-d8ef-4a57-866d-6ba3ca746a5c", "a4d9a111-0bad-4e13-aee3-141120b89449", "a4e7bd67-4ed3-45a0-b2fc-3d045d9d0c92", "a57ffe4b-6269-4521-80c1-198859880b1f", "b01ffd39-796b-44d2-a12d-7d41409a7742", "b05ca4d9-5937-4736-b45a-a7387e236cb6", "c255f6c7-603c-417e-b716-41c1d104281b", "c28519b5-eff2-4644-8c2a-a95e1f8b2a24", "c9f17642-4c62-4b50-a439-700811f8a398", "cd96c7ec-6ef4-4fa8-ae09-c552d0d914c7", "cf0ca844-0d63-4eb3-b024-878184f92d6b", "cfe25beb-1f3a-41d2-b431-32d47b90dfab", "d0a9ff67-6042-4426-bb02-eb43391adf05", "d1d4917f-42af-40ce-b97d-fbb721ac8fa3", "d6ed166d-b201-41af-9f7d-863f38748da0", "dd733633-989c-4843-a2c7-e738ebddf3f3", "edf54b21-9e39-4c00-b856-016edce8596f", "f2e2f4d6-245a-4a14-9689-9ec6682fc7ec", "f6807106-cd8d-4649-a60c-705d4c14183d", "ff02b616-bcf2-411e-b744-8f635e36710e"], "title": "Fighting State Space Explosion: Review and Evaluation", "venue": "formal methods for industrial critical systems", "year": 2009, "id": "ec409c91-5db4-4bd9-81f7-640391351762"}
{"abstract": "Motion trajectories provide rich spatiotemporal information about an object's activity. This paper presents novel classification algorithms for recognizing object activity using object motion trajectory. In the proposed classification system, trajectories are segmented at points of change in curvature, and the subtrajectories are represented by their principal component analysis (PCA) coefficients. We first present a framework to robustly estimate the multivariate probability density function based on PCA coefficients of the subtrajectories using Gaussian mixture models (GMMs). We show that GMM-based modeling alone cannot capture the temporal relations and ordering between underlying entities. To address this issue, we use hidden Markov models (HMMs) with a data-driven design in terms of number of states and topology (e.g., left-right versus ergodic). Experiments using a database of over 5700 complex trajectories (obtained from UCI-KDD data archives and Columbia University Multimedia Group) subdivided into 85 different classes demonstrate the superiority of our proposed HMM-based scheme using PCA coefficients of subtrajectories in comparison with other techniques in the literature.", "authors": ["Faisal I. Bashir", "Ashfaq A. Khokhar", "Dan Schonfeld"], "n_citation": 277, "references": ["0984cfa0-857e-4a3e-98bf-81131038ce9e", "0e620975-8c4c-460d-8489-2623f074272f", "0f8ee3c0-2779-430c-879e-c5e76b110799", "28969f1a-d1b8-42fa-bfcb-d20ab5301584", "2e9a2ffa-b741-47df-a090-c912d3f4a4ff", "2eddba6d-82da-46ca-b6c3-8f1346b0091d", "35b43c28-1930-4d94-be6f-ace0c453bac5", "3680115b-efe3-4b2a-aefd-01b7ac5b5379", "5129753a-7fb2-46fc-b6f7-80d4c7ea0240", "528f4f4d-7995-48ca-8e9a-83182d9d1c36", "64ff61b0-aecc-408b-9da4-8f2b5defe143", "680dedc2-a949-4955-92e7-b768f0b6a759", "6e8cc926-79a1-4676-a2bd-f9d49f3144cf", "a0d90db8-3d64-4824-8776-39509d3ab85a", "a4ea0bc8-b259-4724-ad51-98b6cf47a8d1", "b8470031-8283-4ae2-93ee-99a5683e4909", "bb5904b2-8abb-4cb7-b174-d4f4931988c3", "bba9b523-df6e-48a3-8185-798a62203401", "bd0ea91f-bb7d-47a9-bf1e-7e593aa3d834", "bf3cddfb-735a-4471-8ecb-2aedad9219b8", "c474eadb-c454-4c27-90b3-62a49f1b798a", "c8d0198f-9b77-435a-a41a-bb5fb829d20d", "cb4bb5c1-a86a-45d5-874c-f73686bf0e1f", "cd9b7176-431d-4cf8-a2b2-5133d181b662", "d237b879-7c28-4ec6-a96d-ca45face03bc", "d4a86e67-ee14-4ff3-aa8d-d2bef09992b6", "d67a1289-645d-4c7b-9b46-154b97273a6b", "e6aa1bec-f118-42ca-8d8d-56ca229cb2e2", "e6df60a2-bfa7-4dbe-92c6-9782df430482", "f76155cd-999c-4914-adc7-7956d77c570b"], "title": "Object Trajectory-Based Activity Classification and Recognition Using Hidden Markov Models", "venue": "IEEE Transactions on Image Processing", "year": 2007, "id": "b2d6ff0f-0a46-4394-aab5-b9af5b101ea3"}
{"abstract": "Uniform random 3-SAT at the solubility phase transition is one of the most widely studied and empirically hardest distributions of SAT instances. For 20 years, this distribution has been used extensively for evaluating and comparing algorithms. In this work, we demonstrate that simple rules can predict the solubility of these instances with surprisingly high accuracy. Specifically, we show how classification accuracies of about 70% can be obtained based on cheaply (polynomial-time) computable features on a wide range of instance sizes. We argue in two ways that classification accuracy does not decrease with instance size: first, we show that our models' predictive accuracy remains roughly constant across a wide range of problem sizes; second, we show that a classifier trained on small instances is sufficient to achieve very accurate predictions across the entire range of instance sizes currently solvable by complete methods. Finally, we demonstrate that a simple decision tree based on only two features, and again trained only on the smallest instances, achieves predictive accuracies close to those of our most complex model. We conjecture that this two-feature model outperforms random guessing asymptotically; due to the model's extreme simplicity, we believe that this conjecture is a worthwhile direction for future theoretical work.", "authors": ["Lin Xu", "Holger H. Hoos", "Kevin Leyton-Brown"], "n_citation": 50, "references": ["288dce14-855c-4502-a7d2-cbc4dee2a31e", "29256780-b88c-483d-9e56-69ec63741886", "2ef10cbd-d6da-4efa-b616-c2c36dc5e267", "3f7125bf-1107-420f-acb9-13682e6e3209", "45147d7b-255d-45e0-85c6-5646b1f039c7", "7303f5df-2a0d-40bf-bd56-ff82f6a5da32", "83fea0ca-34a9-4415-8c56-89a17ceaaff9", "c6ff0ff3-54ee-44b2-9eba-165cb58b58bc", "d8d2eee8-8c8a-4ede-9b70-42dc155c34ba", "ef21f9ac-857f-4a86-8e2c-a1609c7d6bf2", "f6bd8b64-684d-429a-aab5-8ff3a2c23cd6"], "title": "Predicting satisfiability at the phase transition", "venue": "national conference on artificial intelligence", "year": 2012, "id": "c29b7435-98b7-4c56-92b8-8d629a173d1b"}
{"abstract": "The pinwheel is a hard-real-time scheduling problem for scheduling satellite ground stations to service a number of satellites without data loss. Given a multiset of positive integers (instance) A=(a/sub 1/, . . . a/sub n/), the problem is to find an infinite sequence (schedule) of symbols from (1,2, . . . n) such that there is at least one symbol i within any interval of a/sub i/ symbols (slots). Not all instances A can be scheduled; for example, no 'successful' schedule exists for instances whose density is larger than 1. It has been shown that any instance whose density is less than 2/3 can always be scheduled. Two new schedulers are proposed which improve this 2/3 result to a new 0.7 density threshold. These two schedulers can be viewed as a generalization of the previously known schedulers, i.e. they can handle a larger class of pinwheel instances including all instances schedulable by the previously known techniques. >", "authors": ["Mee Yee Chan", "Francis Y. L. Chin"], "n_citation": 89, "references": ["35c4b4ce-7453-46a6-81e5-2d5b988fe98d", "4a3bfb6e-81d2-4b67-9adf-91f9020822ab", "8a1a043c-28c9-4575-8e8d-afeee28a0069", "b1587c2d-8325-4c18-97c7-34808843297d", "c3302d0a-4a20-4cac-ab6a-5306eadcd538", "d1b76d8c-e7ff-4e72-a6c9-01566427977e", "e6706eca-4984-4c58-9791-f51794472403", "ff1c31e0-f95e-4a64-b8b0-53baeaf4627c"], "title": "General schedulers for the pinwheel problem based on double-integer reduction", "venue": "IEEE Transactions on Computers", "year": 1992, "id": "da5a4aad-9d69-4db8-b58d-202e19500e77"}
{"abstract": "With recent advances in wireless communication technology, mobile computing is an increasingly important area of research. A mobile system is one where independently executing components may migrate through some space during the course of the computation, and where the pattern of connectivity among the components changes as they move in and out of proximity. Mobile UNITY is a language and logic for specifying and reasoning about mobile systems, the components of which must operate in a highly decoupled way. In this paper it is argued that Mobile UNITY contributes to the modular development of system specifications precisely because of the decoupled and declarative fashion in which coordination among components is specified. The packet forwarding mechanism which is at the core of the Mobile IP protocol for routing to mobile hosts is taken as an example. A Mobile UNITY specification of packet forwarding and the mobile system in which it must operate is developed. Mobile hosts are the components that can disconnect from one location in the network and reconnect to another at any point during system execution. Finally, the role of formal program verification in the development of protocols like Mobile IP is discussed.", "authors": ["Peter J. McCann", "Gruia-Catalin Roman"], "n_citation": 22, "references": ["9231b581-6d14-4548-9bf9-0b9457331270", "d7825e13-b803-413c-924c-7aea5e2a1159", "ed9977e8-d3f0-4167-b03d-5bc52ffee44f"], "title": "Mobile UNITY Coordination Constructs Applied to Packet Forwarding for Mobile Hosts", "venue": "international conference on coordination models and languages", "year": 1997, "id": "c97e851b-98c8-4a9f-a7b2-a807c14f86e2"}
{"abstract": "We discuss two-party mutual authentication protocols providing authenticated key exchange, focusing on those using asymmetric techniques. A simple, efficient protocol referred to as the station-to-station (STS) protocol is introduced, examined in detail, and considered in relation to existing protocols. The definition of a secure protocol is considered, and desirable characteristics of secure protocols are discussed.", "authors": ["Whitfield Diffie", "Paul C. van Oorschot", "Michael J. Wiener"], "n_citation": 1375, "references": ["0067011d-0ba8-4987-9aa3-cc4f5fa4f83a", "1670d841-dee7-467a-b37e-78139fde2c6c", "22d48d67-ce3f-4664-baba-a15523a03906", "2c33bdb1-6f8e-4453-8e10-5153056ae70f", "3fb43b00-905c-4a08-934d-198ea4eb66c3", "42b5cbb9-c3c0-45e8-823f-8f360a933032", "4a38fab2-1904-4c1d-b747-b916566f0b1d", "5376f94d-6ba7-487c-ada2-e7f621c0ed50", "749d6a8c-d488-49cf-9a46-e9a6721e863f", "781b4760-3a16-4692-861f-7c4a6bd4b879", "84535f53-8dd0-4de9-a99f-e0c570454697", "8898d2b5-5959-44fe-b1a7-10026581ad9e", "a79302c1-68c6-43be-95ee-7ea7906268cc", "ac259f17-10a7-45b2-8a55-b7d5d9bc4dfa", "b10fd24d-6a42-4821-9517-da6d1e14b17b", "b214071f-59e2-450a-949e-eb92ef4ba2a9", "ca394e6a-59e0-466c-a66a-d976555db689", "d893a420-a00d-4756-b447-2862ed178eaa", "df741814-f66e-4212-80f5-bc72dcb938bd", "dfc4268d-4487-4e19-be4f-3f38a0a3cbc1"], "title": "Authentication and authenticated key exchanges", "venue": "Designs, Codes and Cryptography", "year": 1992, "id": "3be1572d-1fb3-4e2a-ad7d-c1dea10b53de"}
{"abstract": "Modern out-of-order processors tolerate long latency memory operations by supporting a large number of in-flight instructions. This is particularly useful in numerical applications where branch speculation is normally not a problem and where the cache hierarchy is not capable of delivering the data soon enough. In order to support more in-flight instructions, several resources have to be up-sized, such as the reorder buffer (ROB), the general purpose instructions queues, the load/store queue and the number of physical registers in the processor. However, scaling-up the number of entries in these resources is impractical because of area, cycle time, and power consumption constraints. We propose to increase the capacity of future processors by augmenting the number of in-flight instructions. Instead of simply up-sizing resources, we push for new and novel microarchitectural structures that achieve the same performance benefits but with a much lower need for resources. Our main contribution is a new checkpointing mechanism that is capable of keeping thousands of in-flight instructions at a practically constant cost. We also propose a queuing mechanism that takes advantage of the differences in waiting time of the instructions in the flow. Using these two mechanisms our processor has a performance degradation of only 10% for SPEC2000fp over a conventional processor requiring more than an order of magnitude additional entries in the ROB and instruction queues, and about a 200% improvement over a current processor with a similar number of entries.", "authors": ["Adri\u00e1n Cristal", "Daniel Ortega", "Josep Llosa", "Mateo Valero"], "n_citation": 139, "references": ["052ea89f-71d8-4267-bf91-7a516cc2b40a", "0dbd5ac8-7996-4bf2-8e98-9acfdf7384ef", "197c49da-2507-4900-87d1-c38f5aa6318b", "21caf714-9b5e-45fa-9e3b-51a60333da1f", "27baaa7d-3621-4e82-a15d-bdda817206ef", "298d302e-5f1d-4708-896f-1880d47f2539", "305a7657-890c-4fe2-97c2-02f61f65b67e", "356b2225-29b0-4cf6-bd14-e96c43a98e1e", "470cc79c-5749-4877-bf14-cb9d0957429a", "4da7323c-0af7-4d71-aadd-8f920e326918", "4dc7167f-0121-431d-9433-b75c1fc459c6", "5d7fce2a-234a-490e-9219-a9ae53fa9c11", "619effd9-6bbf-4622-87fc-14dcdeaddbc9", "63bb04d4-b7c2-49e4-a1a8-6d3f73449456", "81ec5ebf-3c03-402f-8b84-a4f561256494", "8a932d5c-d999-4328-97c3-4cbf99617d8a", "8b98d905-5ffb-40df-a3d1-955b3a088609", "96ff09f7-e819-4de9-aaf8-9eac2f5fa751", "abe6d51b-5095-425e-8e32-275966847c7a", "cc56d97e-60eb-48d4-b743-ef3c78e2ccab", "dd29c43d-f466-41a0-aba6-acba78ef504e", "f7bb68e2-19d4-44a8-aab6-ad4f5f376cd4"], "title": "Out-of-order commit processors", "venue": "high-performance computer architecture", "year": 2004, "id": "f52cac25-f1cb-4326-9f92-628c222282bf"}
{"abstract": "Distributed multimedia applications require a variety of levels of quality of service (QoS) from communication networks and end-systems which realize the multimedia interface with the human users or provide remotely accessed multimedia information. The management of these services has to take into account the available resources and the user's wishes concerning the desired quality and costs. Based on our experience with the construction of a News-on-Demand prototype, we present in this paper a few simple principles applying to QoS management for distributed multimedia applications. We discuss in particular ways in which an application can adapt to reduced network performance related to throughput, loss, delay or jitter, and we consider the situation where the configuration of the distributed application can be selected dynamically and be revised during the running of the application. We also comment on the handling of QoS in a layered system architecture and the use of performance models for QoS management.", "authors": ["Gregor von Bochmann", "Abdelhakim Hafid"], "n_citation": 73, "references": ["216bf43a-fa69-43f9-819d-467f93ed3e59", "5b27e1cc-4f86-4b69-94e9-3d25804e1264", "91beb017-891e-465f-8f69-9949e51de309", "93458056-47dd-41e8-9bae-cd824018935d", "a51c76bf-9554-446a-850d-e299d9ee5f72"], "title": "Some principles for quality of service management", "venue": "Distributed Systems Engineering", "year": 1997, "id": "46de8086-7071-46df-be97-c525790c123a"}
{"abstract": "In this paper we design a language and runtime support for isolation-only, multithreaded transactions (called tasks). Tasks allow isolation to be  declared  instead of having to be encoded using the low-level synchronization constructs. The key concept of our design is the use of a type system to support rollback-free and safe runtime execution of tasks.We present a first-order type system which can verify information for the concurrency controller. We use an operational semantics to formalize and prove the type soundness result and an isolation property of tasks. The semantics uses a specialized concurrency control algorithm, that is based on access versioning.", "authors": ["Pawe\u0142 T. Wojciechowski"], "n_citation": 22, "references": ["02676bfd-9b82-4f70-9596-f283acea12eb", "0ded7f08-d0c1-4698-bee1-862a8c676440", "0fae3ee7-c14a-4a7a-a64e-97ab9373809e", "14b79bfc-b11c-44d5-82ba-102d3a586a8c", "15315beb-6cf9-43c5-9090-41b31ac8b39f", "1788761f-4652-4e50-a778-9ed73b9f4828", "21d3fc3b-da3e-4b5a-9d72-ac72a15df43b", "23e95345-160d-404e-9c9a-33caf8de548d", "2a1a717b-356a-44f6-a7cb-749ebcece1ef", "2bef93c1-997e-4f45-a10d-fd4a3ebf3a65", "2d6f2382-4ed9-486a-baad-dc8279b0eafc", "3a055a43-9fc2-4ac3-85da-1465aa42d889", "566c9984-0ab4-4989-8a91-dd8b41846f30", "5ae21162-79ec-4c93-a2c1-b77c3ad94362", "6383e3a3-0715-46f2-a623-d3c3eb78ef4f", "684f80ac-4d7d-46eb-9d1b-2599bae23de6", "71aad699-2460-40ae-a47c-0a4944b078e0", "72ce85d6-4093-4f4e-bb4c-c38f5d3d52ce", "7f1dc63a-9064-4768-a30d-3383d52aa81e", "81ad8d98-8e9c-492c-9f0e-dc4b1e6d3d8b", "a0ca1415-6d13-42f9-8d1e-fd031d06c053", "a97daab8-b47b-401f-93ea-f7dab1cfcda7", "b191cacd-6391-4886-b33a-13195714d42a", "c4f3fc1c-0e3c-41c9-98ca-0a4fdd22c6e1", "c8cee386-0f8b-4634-9afc-819a65a0cb6a", "ddf60a93-c9dd-4e23-996c-90a3426150f4", "f29d1429-c158-45f6-bb06-cec76e221ae2", "f9a69bbd-5d5a-4efd-b658-24c0789a9cf6", "fc1d63b9-24c6-4bc8-85a8-ccc2fc7f6a7d"], "title": "Isolation-only transactions by typing and versioning", "venue": "principles and practice of declarative programming", "year": 2005, "id": "ea716d53-ab6c-43a2-885d-094da21544d6"}
{"abstract": "Keeping confidential who sends which messages, in a world where any physical transmission can be traced to its origin, seems impossible. The solution presented here is unconditionally or cryptographically secure, depending on whether it is based on one-time-use keys or on public keys, respectively. It can be adapted to address efficiently a wide variety of practical considerations.", "authors": ["David Chaum"], "n_citation": 1529, "references": ["8407778d-e0dc-4ba3-a91f-1bc7dac81690", "ca394e6a-59e0-466c-a66a-d976555db689"], "title": "The dining cryptographers problem: unconditional sender and recipient untraceability", "venue": "Journal of Cryptology", "year": 1988, "id": "f0eccc1a-c829-425d-a661-765c3fa2088a"}
{"abstract": "In this paper, a simple mathematical model is presented for studying the performance of the BitTorrent (1) file sharing system. We are especially interested in the distribution of the peers with different states of the download job completedness. With the model we find that in the stable state the distribution of the download peers follows a U-shaped curve, and the parameters such as the departure rate of the seeds and the abort rate of the download peers will influence the peer distribution in different ways notably. We also analyze the file availability and the dying process of the BitTorrent file sharing system. We find that the system's stability deteriorates with the clustering of the peers, and BitTorrent's built-in \"tit-for-tat\" unchoking strategy could not help to preserve the integrity of the file among the download peers when the size of the community is small. An innovative peer selection strategy which enables more peers to finish the download job and prolongs the system's lifetime is proposed, in which the peers cooperate to improve the stability of the system by making a tradeoff between the current download rate and the future service availability. Finally, experimental results are presented to validate our analysis and findings.", "authors": ["Ye Tian", "Di Wu", "Kam Wing Ng"], "n_citation": 152, "references": ["0ca413e9-22ee-435d-ba08-fc3868b20171", "27d1eb57-c32c-4244-8461-8bfd13534493", "479b6443-8ad6-4e1f-b07f-bccd7756639a", "4d4668bf-d17d-42e0-935b-da2305672094", "7a4f2d09-dee6-4dc2-9c8e-d400b8f00c9e", "83a69fff-56ee-475c-954f-b8298b9abd83", "8c9caf09-4a46-442e-abc1-aaa332d896ea", "8caa3277-06d4-48c8-9eba-00fe5253d1ed", "dfef3fae-06ac-4f3c-9b9d-8f605ad14c49", "e8a013b1-3728-47d6-bdd2-daff87011363", "ebca9f89-edba-4d8f-90f0-351fd96286f1", "ed5533a6-6b1a-4d50-a213-6e5a6eb6bce4"], "title": "Modeling, Analysis and Improvement for BitTorrent-Like File Sharing Networks", "venue": "international conference on computer communications", "year": 2006, "id": "a52c9753-1077-4187-b8ba-11b67fa31697"}
{"abstract": "The capacity and cutoff rate of frequency-shift keying (FSK) modulation and noncoherent reception when the signal is subject to Rician fading are calculated. Both hard and soft decisions with maximum likelihood combining are considered, as well as soft decisions with square-law combining. Optimal code rates are found that minimize the required signal-to-noise ratio for reliable communication.", "authors": ["Wayne E. Stark"], "n_citation": 87, "references": ["01e669a8-bd66-42cb-b730-676557dd8162", "299c33c4-e6b1-42d4-838e-0a08b87b7191", "3595fa71-68db-476e-9cb7-ad6ece6f446e", "4794e444-3728-4773-88d8-56a98cb0865d", "907d02bf-2cc1-449e-9954-2775b73b40b1"], "title": "Capacity and Cutoff Rate of Noncoherent FSK with Nonselective Rician Fading", "venue": "IEEE Transactions on Communications", "year": 1985, "id": "0875ac03-3529-4ed1-93da-5b2ec29ca344"}
{"abstract": "In this paper, we consider a multi-agent consensus problem with an active leader and variable interconnection topology. The state of the considered leader not only keeps changing but also may not be measured. To track such a leader, a neighbor-based local controller together with a neighbor-based state-estimation rule is given for each autonomous agent. Then we prove that, with the proposed control scheme, each agent can follow the leader if the (acceleration) input of the active leader is known, and the tracking error is estimated if the input of the leader is unknown.", "authors": ["Yiguang Hong", "Jiangping Hu", "Linxin Gao"], "n_citation": 1274, "references": ["2768199c-b9d6-4001-94d3-e6429c93bc5f", "888171fc-10d9-4230-a916-b9ab6d1910f5", "ab35dc68-62bd-4c54-81d3-9a8406827489", "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9"], "title": "Tracking control for multi-agent consensus with an active leader and variable topology", "venue": "Automatica", "year": 2006, "id": "c5f331e4-1be0-4e04-8854-e75c3734bfcc"}
{"abstract": "The business value of information technology (IT) has been debated for a number of years. While some authors have attributed large productivity improvements and substantial consumer benefits to IT, others report that IT has not had any bottom line impact on business profitability. This paper focuses on the fact that while productivity, consumer value, and bush ness profitability are related, they are ultimate1 Allen Lee was the accepting senior editor for this paper. 2 An earlier version of this paper appears in the", "authors": ["Lorin M. Hitt", "Erik Brynjolfsson"], "n_citation": 2007, "references": ["1d13bb3f-b6b6-43c6-a3c9-442e780af17c", "2d923c22-981b-4a50-8406-f2265601a4ff", "36b56ea0-6e82-4427-95ef-3b4b4d5980ff", "4de9372f-0974-4458-9903-1381ce09bc0a", "58e1bbc4-b551-44a9-9d66-45e515d44daa", "64acbf4d-fdc7-4aad-befd-cae979b5fb16", "976c0433-5e93-451d-9a38-d46fca9694df", "adb5ed5f-78c4-4494-9cc3-7b31c375f8dd", "ca8ceae7-35b3-4a07-93db-290b1660def6"], "title": "Productivity, business profitability, and consumer surplus: three different measures of information technology value", "venue": "Management Information Systems Quarterly", "year": 1996, "id": "17e49897-3782-420a-b48b-ef6463705657"}
{"abstract": "CLU is a new programming language designed to support the use of abstractions in program construction. Work in programming methodology has led to the realization that three kinds of abstractions, procedural, control, and especially data abstractions, are useful in the programming process. Of these, only the procedural abstraction is supported well by conventional languages, through the procedure or subroutine. CLU provides, in addition to procedures, novel linguistic mechanisms that support the use of data and control abstractions. This paper provides an introduction to the abstraction mechanisms in CLU. By means of programming examples, we illustrate the utility of the three kinds of abstractions in program construction and show how CLU programs may be written to use and implement abstractions. We also discuss the CLU library, which permits incremental program development with complete type-checking performed at compile-time.", "authors": ["Barbara Liskov", "Alan Snyder", "Russell R. Atkinson", "Craig Schaffert"], "n_citation": 1003, "title": "Abstraction mechanisms in CLU", "venue": "Sigplan Notices", "year": 1977, "id": "33bb3d3b-cf44-481b-a6a7-23c7cc2dd219"}
{"authors": ["Richard Sproat", "Julia Hirschberg", "David Yarowsky"], "n_citation": 97, "title": "A corpus-based synthesizer.", "venue": "", "year": 1992, "id": "07e69de2-70f9-4e4c-b1de-fa3a92b63d73"}
{"abstract": "Privacy-preserving data publishing addresses the problem of disclosing sensitive data when mining for useful information. Among the existing privacy models, \u2208-differential privacy provides one of the strongest privacy guarantees and has no assumptions about an adversary's background knowledge. Most of the existing solutions that ensure \u2208-differential privacy are based on an interactive model, where the data miner is only allowed to pose aggregate queries to the database. In this paper, we propose the first anonymization algorithm for the non-interactive setting based on the generalization technique. The proposed solution first probabilistically generalizes the raw data and then adds noise to guarantee \u2208-differential privacy. As a sample application, we show that the anonymized data can be used effectively to build a decision tree induction classifier. Experimental results demonstrate that the proposed non-interactive anonymization algorithm is scalable and performs better than the existing solutions for classification analysis.", "authors": ["Noman Mohammed", "Rui Chen", "Benjamin C. M. Fung", "Philip S. Yu"], "n_citation": 187, "references": ["02a155b1-2b00-42c1-96b2-6f05a735ea82", "04465a9c-73ab-4f14-b09d-be7aa4d02ae1", "0c3fa627-3215-4dd1-9f76-9a14c9bb8e0a", "2839aad4-d418-4663-ac31-5fc0bb9cadc7", "2d34b952-1d15-4cd3-9e1f-7337581e945c", "32fd9fa0-0857-4bbc-8e40-b947c02e9d8b", "37e60a24-5f71-4a57-883c-b3d58b44b09b", "396c6192-d592-41a9-a37e-9bc3efa5dfd7", "49425467-5ff3-4ac5-a25b-32d153a7252b", "4df03b0c-35cd-49f9-97f5-5cae14db3517", "4e589195-cadb-4d90-8082-cf4307d6e24f", "5367040f-3ed3-423f-bb18-2f66e673dad9", "59529b46-a4d1-4d48-8679-e6299b17dccf", "5deab4c2-8fff-43cf-bd0d-89d8a30f601b", "700672fd-23a3-4ac5-bbd5-9c6139a36507", "70ee2599-0921-4a79-b87a-7fadceb4357d", "70f4dcf0-2784-4627-899c-1463988a3f52", "857599dc-173f-47e0-91fa-6a9b2edce619", "86fce969-e42c-4065-9e5f-3acdff7fa981", "873ca6c8-cbb5-4235-9609-d012105e6294", "9a9042ef-19fd-4cc4-90db-059122355179", "9c3eabd3-3573-41b9-b1f1-de39a6e585a9", "a7fb44a1-527f-4ff8-a9ce-34ee8e031e4d", "acfb77cd-46c1-4998-96e0-324b53fd410c", "b0685b34-a7ee-43ba-86dd-a1476634f7f4", "b4123537-75d5-420f-ac0e-e69f16da1ae1", "b658b650-290f-46d9-b052-c3995b3bb24a", "ce23dfec-0178-47a4-a2cd-9125188da2bd", "d3b0635e-5447-435d-9975-a2582d19fc37", "db0b4ee1-46c8-44dc-bd4c-9fc08c037e5d", "dc5339e5-4561-4df2-9ebe-96925d2ce11d", "dc667ef3-91f0-400e-b405-b0844931aec5", "e410bdea-ea3a-4a74-b89f-8f0c77347dbb", "e6e377f5-1b4b-40ba-81b3-6f0d9f216b09", "e70060d4-8a81-461c-97a7-16c0f27e3646", "f6e345a5-8fc0-49da-891a-465f0234dc81"], "title": "Differentially private data release for data mining", "venue": "knowledge discovery and data mining", "year": 2011, "id": "50a80a10-3a3a-4ad1-af50-50a109c91a22"}
{"abstract": "LDA/QR, a linear discriminant analysis (LDA) based dimension reduction algorithm is presented. It achieves the efficiency by introducing a QR decomposition on a small-size matrix, while keeping competitive classification accuracy. Its theoretical foundation is also presented.", "authors": ["Jieping Ye", "Qi Li"], "n_citation": 62, "references": ["3cd186af-d2c8-4182-af10-b8879baa0410", "5eb1916a-bbf2-4413-b5ba-589c62877ac0", "7b393c45-6d41-464f-9b5c-a703ad88c3bc"], "title": "LDA/QR: an efficient and effective dimension reduction algorithm and its theoretical foundation", "venue": "Pattern Recognition", "year": 2004, "id": "63b99881-edac-4886-94f6-1a1ebf5659bd"}
{"abstract": "Supervised machine learning (ML) algorithms are increasingly popular tools for fMRI decoding due to their predictive capability and their ability to capture information encoded by spatially correlated voxels. In addition, an important secondary outcome is a multivariate representation of the pattern underlying the prediction. Despite an impressive array of applications, most fMRI applications are framed as classification problems and predictions are limited to categorical class decisions. For many applications, quantitative predictions are desirable that more accurately represent variability within subject groups and that can be correlated with behavioural variables. We evaluate the predictive capability of Gaussian process (GP) models for two types of quantitative prediction (multivariate regression and probabilistic classification) using whole-brain fMRI volumes. As a proof of concept, we apply GP models to an fMRI experiment investigating subjective responses to thermal pain and show GP models predict subjective pain ratings without requiring anatomical hypotheses about functional localisation of relevant brain processes. Even in the case of pain perception, where strong hypotheses do exist, GP predictions were more accurate than any region previously demonstrated to encode pain intensity. We demonstrate two brain mapping methods suitable for GP models and we show that GP regression models outperform state of the art support vector- and relevance vector regression. For classification, GP models perform categorical prediction as accurately as a support vector machine classifier and furnish probabilistic class predictions.", "authors": ["Andre F. Marquand", "Matthew Howard", "Michael Brammer", "Carlton Chu", "Steven J. Coen", "Janaina Mourao-Miranda"], "n_citation": 177, "references": ["01b486c4-8955-403b-a0c6-1de74298b215", "146d9083-edd7-432d-bb81-b53bd0770cd6", "2f00498c-01c7-4d3e-a1b0-956e677b9b35", "3308f756-9b71-4e7f-91d9-6b05e610da55", "388a076f-70b6-43f6-9f57-8837f74d647b", "3c383c6f-3503-458d-bdd7-a34cb8f4515f", "42cc6887-ce3d-4f71-9512-84b34ec1a6e4", "4682bab4-4d89-43a7-9493-ad04f38e5e32", "47a93521-1448-4694-9c00-f29ff91f9062", "6f691149-4328-4cde-85a1-1f4eb1b7b1fd", "8222dfa5-1549-4bce-a127-f930a516f744", "8bb47288-c305-4131-9a23-3635d1bc15ad", "965003b5-4713-4035-8396-0bfc6f507051", "a083a1b9-8dfb-45d6-99a9-fa30c4a6e9f5", "d5d60394-65a1-4fc5-a0e7-dad422a88bed", "dcd6762a-ff44-46aa-ab12-6b951955199c", "f006e236-59ad-4647-a59f-4f46dc2c85be", "fd4e8c45-be77-49de-a6a8-a8ab1acac344"], "title": "Quantitative prediction of subjective pain intensity from whole-brain fMRI data using Gaussian processes.", "venue": "NeuroImage", "year": 2010, "id": "6230c624-d033-44a3-b8ff-4d1322de75d8"}
{"abstract": "We describe a lattice attack on the Digital Signature Algorithm (DSA) when used to sign many messages, m_i, under the assumption that a proportion of the bits of each of the associated ephemeral keys, y_i, can be recovered by alternative techniques.", "authors": ["Nick Howgrave-Graham", "Nigel P. Smart"], "n_citation": 194, "references": ["123097a2-2c1f-4216-9b80-4646cf635dd7", "14c14268-2dac-4812-97c5-348cfa0f3dff", "2c33bdb1-6f8e-4453-8e10-5153056ae70f", "8cfd4d0d-5ddb-492f-939f-6d56e980df94", "ae98c1d7-b0e5-418f-a1fc-b1afe1aa0f24", "c7ddd1ae-6acc-4698-b172-d77a637d76cd"], "title": "Lattice Attacks on Digital Signature Schemes", "venue": "Designs, Codes and Cryptography", "year": 2001, "id": "50a9e0e2-6c6c-499d-948e-8de0a0166a98"}
{"abstract": "In this paper, we present a novel approach for human action recognition with histograms of 3D joint locations (HOJ3D) as a compact representation of postures. We extract the 3D skeletal joint locations from Kinect depth maps using Shotton et al.'s method [6]. The HOJ3D computed from the action depth sequences are reprojected using LDA and then clustered into k posture visual words, which represent the prototypical poses of actions. The temporal evolutions of those visual words are modeled by discrete hidden Markov models (HMMs). In addition, due to the design of our spherical coordinate system and the robust 3D skeleton estimation from Kinect, our method demonstrates significant view invariance on our 3D action dataset. Our dataset is composed of 200 3D sequences of 10 indoor activities performed by 10 individuals in varied views. Our method is real-time and achieves superior results on the challenging 3D action dataset. We also tested our algorithm on the MSR Action 3D dataset and our algorithm outperforms Li et al. [25] on most of the cases.", "authors": ["Lu Xia", "Chia-Chih Chen", "Jake K. Aggarwal"], "n_citation": 728, "references": ["05ac52a1-dfa2-4c32-9a54-6c1e58cfcca5", "0b2f71cc-6797-445a-82df-5be29945c0a7", "10e6b43e-139f-45a2-b428-86e9284052ed", "19b43236-483d-40cb-bc5c-bf8ec7613647", "22ffa941-f26c-43bc-990e-e5d3c859e410", "27319230-05e0-4c01-8620-a33fff091c77", "6018522a-423a-4d59-870f-fe8fe748dd3a", "7bf5b410-ec51-4257-b4ab-47445ea38673", "7ccce1bf-51b9-4eb1-a280-3ee73fb42023", "839d7fc6-6782-4086-8a11-5256f9eeaa57", "84bce541-29b3-42ca-8494-165b4a87e233", "8947ffba-a802-4081-94f4-4bc721b14c47", "97370ead-2763-41e5-8834-83165fee434f", "a2d6d2be-035d-4e9b-b5cb-a990f43836e6", "a41be306-a795-42b1-90d7-2bd1758c5baa", "acdea751-314b-4e2d-a096-934af2475722", "b7b6250a-2ae7-42cb-aa70-425eead247a5", "bb948ac3-8ffc-492f-b738-46ebe8c8093b", "c729d518-ede3-4188-9319-81fff84436ad", "ea0481c6-5a8d-40ea-b0d4-a25469d4cd07", "eb3429ed-ef9b-4bae-9874-1b9c0c489e56", "ff84b165-e6df-43a7-9925-e9dbf946f788"], "title": "View invariant human action recognition using histograms of 3D joints", "venue": "computer vision and pattern recognition", "year": 2012, "id": "a6ba0c8a-a283-462a-ad3b-e8a92164c041"}
{"authors": ["Viswam Nathan", "Ilge Akkaya", "Roozbeh Jafari"], "n_citation": 2, "references": ["1e92de9e-2d1e-4a29-b4b1-07aa28e18a45", "2fa5a978-157d-46c5-88ce-85ad1043a38c", "506d3dee-88e0-4beb-bac5-b976ae8cbdd5", "61fd0d06-0f68-45f9-927a-710102b3ca3a", "a662e3f9-21cc-4dfc-976f-2bc8d3daaeed", "d8116977-0962-4d4d-832d-f9b0a095c75c", "db42e661-1eaa-486d-8485-ab6fb0afa61e"], "title": "A particle filter framework for the estimation of heart rate from ECG signals corrupted by motion artifacts.", "venue": "international conference of the ieee engineering in medicine and biology society", "year": 2015, "id": "ee89bc6c-a11c-4d8e-a8e8-998f90cbfd60"}
{"abstract": "Is Winfree's abstract Tile Assembly Model (aTAM) \"powerful?\" Well, if certain tiles are required to \"cooperate\" in order to be able to bind to a growing tile assembly (a.k.a., temperature 2 self-assembly), then Turing universal computation and the efficient self-assembly of N \u00d7 N squares is achievable in the aTAM (Rotemund and Winfree, STOC 2000). So yes, in a computational sense, the aTAM is quite powerful! However, if one completely removes this cooperativity condition (a.k.a., temperature 1 self-assembly), then the computational \"power\" of the aTAM (i.e., its ability to support Turing universal computation and the efficient self-assembly of N \u00d7 N squares) becomes unknown. On the plus side, the aTAM, at temperature 1, is not only Turing universal but also supports the efficient self-assembly N \u00d7 N squares if self-assembly is allowed to utilize three spatial dimensions (Fu, Schweller and Cook, SODA 2011). In this paper, we investigate the theoretical \"power\" of a seemingly simple, restrictive variant of Winfree's aTAM in which (1) the absolute value of every glue strength is 1, (2) there is a single negative strength glue type and (3) unequal glues cannot interact (i.e., glue functions must be \"diagonal\"). We call this abstract model of self-assembly the restricted glue Tile Assembly Model (rgTAM). We achieve two positive results. First, we show that the tile complexity of uniquely producing an N \u00d7 N square in the rgTAM is O(log N). In our second result, we prove that the rgTAM is Turing universal.", "authors": ["Matthew J. Patitz", "Robert T. Schweller", "Scott M. Summers"], "n_citation": 50, "references": ["00d1f576-fc75-46eb-83e6-4738b92c6908", "239eccc0-3d4c-4e62-a1ba-2e8722bc5640", "264b3247-02a8-4381-9754-ef1d04d6b65e", "2b6d4027-d1ca-48fc-b5b1-1a7847b70a18", "2edce2cc-61dd-4426-91a0-7a7259661723", "750d4095-ad49-4d77-9eb9-0c9e3519ebef", "790b8877-b537-4299-b547-a7c072292d0b", "7dc0bd81-013d-47b9-a200-9e9c7019e4de", "93dc6fec-bec2-4ce4-ae93-bc13456763b2", "9bfa54ab-2906-47de-9454-73f99c4b406d", "c0ca5f33-4147-48d2-a2ec-85dd9c51f745", "cdcc12f0-cd2a-4ae9-a994-e798dc02426d", "cf0b0035-c087-4609-bcd3-b521d807d766", "d6098a48-5450-4e46-90da-a6a0748b2582", "e1659632-14b8-4291-b81e-45f9c986cee4", "faaf7bdd-89ed-495d-b44b-4121c72071e6"], "title": "Exact shapes and turing universality at temperature 1 with a single negative glue", "venue": "arXiv: Emerging Technologies", "year": 2011, "id": "401ff863-90c0-442d-a87d-add9055a951d"}
{"abstract": "The Colorful Motif problem asks if, given a vertex- colored graph G, there exists a subset S of vertices of G such that the graph induced by G on S is connected and contains every color in the graph exactly once. The problem is motivated by applications in computational biology and is also well-studied from the theoretical point of view. In particular, it is known to be NP-complete even on trees of maximum degree three (Fellows et al, ICALP 2007). In their pioneering paper that introduced the color-coding technique, Alon et al. (STOC 1995) show, inter alia, that the problem is FPT on general graphs. More recently, Cygan et al. (WG 2010) showed that Colorful Motif is NP- complete on comb graphs, a special subclass of the set of trees of max- imum degree three. They also showed that the problem is not likely to admit polynomial kernels on forests. We continue the study of the kernelization complexity of the Colorful Motif problem restricted to simple graph classes. Surpris- ingly, the infeasibility of polynomial kernelization persists even when the input is restricted to comb graphs. We demonstrate this by showing a simple but novel composition algorithm. Further, we show that the prob- lem restricted to comb graphs admits polynomially many polynomial kernels. To our knowledge, there are very few examples of problems with many polynomial kernels known in the literature. We also show hardness of polynomial kernelization for certain variants of the problem on trees; this rules out a general class of approaches for showing many polyno- mial kernels for the problem restricted to trees. Finally, we show that the problem is unlikely to admit polynomial kernels on another simple graph class, namely the set of all graphs of diameter two. As an appli- cation of our results, we settle the classical complexity of Connected Dominating Set on graphs of diameter two \u2014 specifically, we show that it is NP-complete.", "authors": ["Abhimanyu M. Ambalath", "Radheshyam Balasundaram", "H Chintan Rao", "Venkata Koppula", "Neeldhara Misra", "Geevarghese Philip", "M. S. Ramanujan"], "n_citation": 32, "references": ["172f9f68-8417-43bb-8fe5-b377d569f6b6", "2707ebdb-1a02-4487-948c-eafa80af21a0", "3f60fc3c-7c60-415a-80a8-04da91cf785a", "4623c23f-4f12-4699-9b41-38323ba942fe", "774a55e3-5398-4e4f-872f-c9e6f4a1f74a", "8107f43a-022c-4771-91df-82b69c96b8b6", "92074738-87a5-4e1b-ba65-d2c236d58b39", "93460177-06de-4d98-a540-25e1fcdf276c", "a9ec4e32-b61d-43dd-902f-ed1f794db0e8", "bfbd2e29-12a7-4d03-bf23-4c3201d23e76", "c7b6640f-0d4e-49e2-8705-74778902c853"], "title": "On the Kernelization Complexity of Colorful Motifs", "venue": "", "year": 2010, "id": "a14c6aa5-8bce-4132-9931-1dcb23c8fa9b"}
{"abstract": "We propose an abstract interpretation-based analysis for automatically detecting all potential interactions between the agents of a part of a mobile system, without much knowledge about the rest of it. We restrict our study to mobile systems written in the \u03c0-calculus, and introduce a non-standard semantics which restores the link between channels and the processes that have created them. This semantics also allows to describe the interaction between a system and unknown context. It is, to the best our knowledge, the first analysis for this problem. Wethen abstract this non-standard semantics into an approximated one so as to automatically obtain a non-uniform description of the communication topology of mobile systems which compute in hostile contexts.", "authors": ["J\u00e9r\u00f4me Feret"], "n_citation": 35, "references": ["0c06344e-f113-4dca-9421-7b19e9c77ff8", "2230c340-e108-418b-a1ab-c40ef3eaefe5", "585f1202-6edd-4b39-a16d-84076d494ac6", "6f45828a-82d4-4306-bc4f-f7fb31d4298e", "7bb71afa-91b8-46e7-9008-da84e0427b93", "838d99b5-5b05-41a8-adc7-a597195fefad", "8dafcd59-76af-4cfe-834e-ebdd8503bce1", "9957fcde-69de-4791-9743-67bd81614ee3", "9a4984f9-27d4-47eb-8bc8-0469bf540f94", "afa6d820-c762-4285-a25d-9dd985929ec3", "afddbf4f-1aa5-4764-a1ad-e4a369b80140", "b215f194-a0ce-4699-9d46-69ad938c6c4d", "b936400c-365f-4796-ab72-d6d4144cc60f", "d8a731a2-97b0-45a1-aea7-da9316fb8ecd", "eb3d4931-ea4f-4b50-87cc-002ad4941033"], "title": "Confidentiality Analysis of Mobile Systems", "venue": "static analysis symposium", "year": 2000, "id": "158896c4-1f11-4505-a980-9f1f17b7bedf"}
{"abstract": "Summary: Often competing hypotheses for biochemical networks exist in the form of different mathematical models with unknown parameters. Considering available experimental data, it is then desired to reject model hypotheses that are inconsistent with the data, or to estimate the unknown parameters. However, these tasks are complicated because experimental data are typically sparse, uncertain, and are frequently only available in form of qualitative if-then observations. ADMIT (Analysis, Design and Model Invalidation Toolbox) is a MatLab TM -based tool for guaranteed model invalidation, state and parameter estimation. The toolbox allows the integration of quantitative measurement data, a priori knowledge of parameters and states, and qualitative information on the dynamic or steady-state behavior. A constraint satisfaction problem is automatically generated and algorithms are implemented for solving the desired estimation, invalidation or analysis tasks. The implemented methods built on convex relaxation and optimization and therefore provide guaranteed estimation results and certificates for invalidity. Availability: ADMIT, tutorials and illustrative examples are available free of charge for non-commercial use at http://ifatwww.et.uni", "authors": ["Stefan Streif", "Anton Savchenko", "Philipp Rumschinski", "Steffen Borchers", "Rolf Findeisen"], "n_citation": 31, "references": ["41ec88a0-b8eb-45be-9ef1-1d09c823d2e1", "791b8f1a-4180-4915-8184-251db98156c1", "af231ffe-3678-4b41-8dcb-abdb2b98ebca", "eb35a605-0102-4e34-9fca-d63406434b62", "f3cde1e4-03af-477b-b3b9-aa56442be827"], "title": "ADMIT: a toolbox for guaranteed model invalidation, estimation and qualitative-quantitative modeling", "venue": "Bioinformatics", "year": 2012, "id": "499798ad-50f0-44c7-9f3d-f559f411ea46"}
{"abstract": "The sentence is a standard textual unit in natual language processing applications. In many language the punctuation mark that indicates the end-of-sentence boundary is ambiguous; thus the tokenizers of most NLP systems must be equipped with special sentence boundary recognition rules for every new text collection.As an alternative, this article presents an efficient, trainable system for sentence boundary disambiguation. The system, called Satz, makes simple estimates of the parts of speech of the tokens immediately preceding and following each punctuation mark, and uses these estimates as input to a machine learning algorithm that then classifies the punctuation mark. Satz is very fast both in training and sentence analysis, and its combined robustness and accuracy surpass existing techniques. The system needs only a small lexicon and training corpus, and has been shown to transfer quickly and easily from English to other languages, as demonstrated on Franch and German.", "authors": ["David D. Palmer", "Marti A. Hearst"], "n_citation": 211, "references": ["0657b8c8-357e-4850-ba64-e007833b2bb6", "0c35895c-9f13-4678-80f3-9310652446e0", "0c895f1e-1b38-47be-81c0-67c5300be640", "100d9f16-5fc5-468b-be7b-2fadaf9bcd02", "16805a55-eb05-490b-b364-b3520f37f36e", "20c0235e-ee74-4311-ad2e-ec5f82817910", "416a4f62-0b44-4150-a0e9-5f6fb49b4eba", "434c3edc-8c33-481d-b22d-2dd351299be3", "54081c29-8643-4814-8f40-a1fa8c28db57", "62549bc2-e0b3-46e8-8d32-390dded105d5", "7d11b22c-acaf-4a92-a27e-24e13a198916", "8f7f3488-46ba-438b-aac7-fc432c8b4839", "93573751-da40-47d6-99f9-e13fb7e5b65f", "a05838da-089f-4be8-a169-b0223ae4f0ac", "b49c1e2b-0cd0-4950-a724-00c698e5b49d", "c10f971c-d725-4aee-b747-cafc29ba4f06", "c5f091b9-47ff-4eb1-b701-848788b2f24a", "f65e44ee-5d84-4707-ac9d-1ebc0395a8c0", "f88b0a14-69aa-4748-a4a0-78635c4e4c11"], "title": "Adaptive multilingual sentence boundary disambiguation", "venue": "Computational Linguistics", "year": 1997, "id": "161e1083-624f-4e46-8555-893d1553f11d"}
{"abstract": "An important application of sparse representation is underdetermined blind source separation (BSS), where the number of sources is greater than the number of observations. Within the stochastic framework, this paper discusses recoverability of underdetermined BSS based on a two-stage sparse representation approach. The two-stage approach is effective when the source matrix is sufficiently sparse. The first stage of the two-stage approach is to estimate the mixing matrix, and the second is to estimate the source matrix by minimizing the 1-norms of the source vectors subject to some constraints. After estimating the mixing matrix and fixing the number of nonzero entries of a source vector, we estimate the recoverability probability (i.e., the probability that the source vector can be recovered). A general case is then considered where the number of nonzero entries of the source vector is fixed and the mixing matrix is drawn from a specific probability distribution. The corresponding probability estimate on recoverability is also obtained. Based on this result, we further estimate the recoverability probability when the sources are also drawn from a distribution (e.g., Laplacian distribution). These probability estimates not only reflect the relationship between the recoverability and sparseness of sources, but also indicate the overall performance and confidence of the two-stage sparse representation approach for solving BSS problems. Several simulation results have demonstrated the validity of the probability estimation approach.", "authors": ["Yuanqing Li", "Shun-ichi Amari", "Andrzej Cichocki", "Cuntai Guan"], "n_citation": 50, "references": ["05c85ace-c998-47cd-a285-f6ecfd72004d", "157a2881-c6cb-4d05-8f15-d9225e5751f5", "1d1fe4bc-ddc8-48c2-b195-d0d5d96a8e82", "20ebfc17-0fd5-462a-8e7d-363bb12caf77", "3ac239ca-de35-4269-9bd5-20d042fed9d2", "449bfdfc-f916-422c-ac0d-ebfdd2ab773a", "58df00c0-c4df-44bd-8bec-810164b323d3", "87a4faed-c1a5-45c8-81eb-3bf19ae19011", "90dc05d1-bfa0-4166-be98-d1fc81bbd743", "913bb59b-71fe-4bd1-8f97-1c974a93575c", "95e314d8-096a-4130-b34e-0454dcdf9147", "9c9f85b6-3c7d-433a-a464-437e7486d729", "9e062d9c-20d8-4fe5-af2e-c7edd65d67db", "d6457de8-9f03-4671-91da-f557a0ec20e0", "daee1a44-b444-4d3d-902c-3b033c3e3994", "db0244eb-d9ec-4713-a98b-fa38c1742ee9", "eb80a315-d861-40fe-b762-b5a7fd619862", "fb8dc2b8-753f-4f2d-a9a8-a9c0f320e125"], "title": "Probability estimation for recoverability analysis of blind source separation based on sparse representation", "venue": "IEEE Transactions on Information Theory", "year": 2006, "id": "92b7c5f5-04c9-46ea-8a0b-5da157516a13"}
{"abstract": "Abstract   We introduce an object recognition and localization system in which objects are represented as a sparse and spatially organized set of local (bent) line segments. The line segments correspond to binarized Gabor wavelets or banana wavelets, which are bent and stretched Gabor wavelets. These features can be metrically organized; the metric enables an efficient learning of object representations. It is essential for learning that only corresponding local areas are compared with each other; i.e., the correspondence problem has to be solved. We achieve correpondence (and in this way autonomous learning) by utilizing motor-controlled feedback, i.e., by interaction of arm movement and camera tracking. The learned representations are used for fast and efficient localization and discrimination of objects in complex scenes.", "authors": ["Norbert Kr\u00fcger", "Gabriele Peters"], "n_citation": 29, "references": ["00909251-9935-44f3-94a1-629023b5015b", "0de099ad-c87f-4b0f-8977-a48028d68972", "30b466e4-594d-4199-9ae4-c083b3cae02d", "36800655-b2ff-4eb7-9070-c6be304c4baa", "3bb5658b-131c-4072-9f9c-5f18a8272054", "55ddf46b-d2a3-409e-923f-3c29588a455e", "5650d6b1-9953-41b4-a8ed-683b36b28c3a", "5ebbd1f5-dfe5-4eec-9883-b8b5efea366c", "648675c6-6ea7-4fa5-a91d-9d3156d09692", "700061b6-54a5-4f50-a1ef-1d8de3015c43", "7b3f5f5b-a965-4656-9a6f-2f9740625176", "8678514b-e795-4972-b891-c0d31d0d46cf", "8d26e52c-b697-4e69-bb07-6a63ddeae5e4", "923f5d0a-23a3-4fb1-bee7-ec72122709a4", "9336ab77-f87d-449b-abd8-13fad8cc3c1b", "a00704dc-a2fa-4267-b7a6-427167d99521", "a7fc8f4a-ee78-461a-b15e-7a82e8e6d9b9", "c95f638a-4ce3-4cba-8028-24d2b213ad18", "d5ac8169-2a76-471d-a5ae-9e5d34d86e2c", "da4534a6-897c-4431-89ef-cd326bfaf9a8", "f769518e-b3d5-4dee-87dd-debcd57b1387"], "title": "ORASSYLL: Object Recognition with Autonomously Learned and Sparse Symbolic Representations Based on Metrically Organized Local Line Detectors", "venue": "Computer Vision and Image Understanding", "year": 2000, "id": "443255f7-9e6c-40ed-a7ad-b0de8e45095f"}
{"authors": ["Eckart Michaelsen", "Uwe Stilla"], "n_citation": 5, "references": ["2e7ac6e9-059c-420f-a170-a61c13d5d246", "634392ff-d55d-4d5a-aadb-704a76eece38", "c2472b10-d2ac-4e58-9005-d3e93eb1ec27", "ca304194-9785-4853-b5e4-98aa598d5865"], "title": "Ansichtenbasierte Erkennung von Fahrzeugen", "venue": "", "year": 2000, "id": "45d487b3-0de0-4942-9d3d-ae04ca6d5d87"}
{"authors": ["Mark R. Greenstreet", "Ian M. Mitchell"], "n_citation": 67, "references": ["265f9000-94eb-44bf-9408-9a1c62265f4c", "510eec1d-f82c-4b19-b116-b8fd4c66531a", "af3dcf0c-6e6f-4190-a9d6-9a9d2551e378", "d352ae9c-c34a-4615-abe4-317a1fa9bb93"], "title": "Integrating Projections", "venue": "", "year": 1998, "id": "829f1823-924b-42af-84f8-2feb08f945b9"}
{"abstract": "As current trends in programming encourage a high degree of modularity, the number of procedure calls and returns executed in a module continues to grow. This increase in procedures mandates the efficient testing of the interactions among procedures. In this paper, we extend the utility of data flow testing to include the testing of data dependencies that exist across procedure boundaries. An interprocedural data flow analysis algorithm is first presented that enables the efficient computation of information detailing the locations of definitions and uses needed by an interprocedural data flow tester. To utilize this information, a technique to guide the selection and execution of test cases, that takes into account the various associations of names with definitions and uses across procedures, is also presented. The resulting interprocedural data flow tester handles global variables, reference parameters and recursive procedure calls, and is compatible with the current intraprocedural data flow testing techniques. The testing tool has been implemented on a Sun 3/50 Workstation.", "authors": ["Mary Jean Harrold", "Mary Lou Soffa"], "n_citation": 185, "references": ["21aaed58-da31-4f73-9445-6f45614d6320", "2ac5fedd-db52-4207-ac12-b527da60b604", "2d57d615-1fe2-474d-81fe-f4ef1a07ed26", "57071747-069e-453f-b3e1-b16b417581ee", "66d779cf-d6bc-4d55-8865-8e946a7645b4", "73c1dcb8-e5c5-4c5d-9d79-b6561266c69d", "aa53709a-972b-47be-a10f-b76259fc3978", "c04b02d6-c45b-4052-ad13-b24e71f65809", "f90e1d45-eae7-464d-99e5-cd82bf77e368"], "title": "Interprocedual data flow testing", "venue": "ACM Sigsoft Software Engineering Notes", "year": 1989, "id": "94443d41-2ba7-47d0-b84f-5e781485b3ff"}
{"abstract": "One of many advantages of the cloud is the elasticity, the ability to dynamically acquire or release computing resources in response to demand. However, this elasticity is only meaningful to the cloud users when the acquired Virtual Machines (VMs) can be provisioned in time and be ready to use within the user expectation. The long unexpected VM startup time could result in resource under-provisioning, which will inevitably hurt the application performance. A better understanding of the VM startup time is therefore needed to help cloud users to plan ahead and make in-time resource provisioning decisions. In this paper, we study the startup time of cloud VMs across three real-world cloud providers -- Amazon EC2, Windows Azure and Rackspace. We analyze the relationship between the VM startup time and different factors, such as time of the day, OS image size, instance type, data center location and the number of instances acquired at the same time. We also study the VM startup time of spot instances in EC2, which show a longer waiting time and greater variance compared to on-demand instances.", "authors": ["Ming Mao", "Marty Humphrey"], "n_citation": 337, "references": ["342d32ae-9895-4c60-b4a5-e6249c0cc64a", "352636aa-b33e-4db7-bd82-a843a77a433d", "454f02e2-d285-4063-ad5d-88fdcdc3abf9", "54adcfa2-c1ea-450f-8ddb-a93f5ee7a8c5", "57cc8f8c-5d2c-47b4-a74f-18fa509078a7", "76ef98f6-7b6c-4ea2-870a-74da99dadff6", "8308836e-3f82-4cc9-a41b-f9d85fabc7c7", "967729e3-af56-4df6-a225-d2d2f5d1e8e5", "c1c91baf-9f3b-4ccc-b9c6-75702e437223", "e3432705-4df5-4fe2-92e4-4630926c2a96", "fdc28e1d-1257-45d8-b563-875a4d40d40d"], "title": "A Performance Study on the VM Startup Time in the Cloud", "venue": "international conference on cloud computing", "year": 2012, "id": "6306775d-88d9-4453-91f8-89e5f073a135"}
{"abstract": "Introduce a simple game-theoretic approach to satisfiability checking of temporal logic, for LTL (linear time logic) and CTL (computation tree logic), which has the same complexity as using automata. The mechanisms involved are both explicit and transparent, and underpin a novel approach to developing complete axiom systems for temporal logic. The axiom systems are naturally factored into what happens locally and what happens in the limit. The completeness proofs utilise the game-theoretic construction for satisfiability: if a finite set of formulas is consistent then there is a winning strategy (and therefore construction of an explicit model is avoided).", "authors": ["Martin Lange", "Colin Stirling"], "n_citation": 57, "references": ["173a85b4-5d7a-49be-8621-62ae548da345", "3115c994-96a4-4282-b51e-a5bfc6f4a54b", "3491feb2-bf31-4fde-b199-b652007cd999", "4814eca2-167a-48bd-a7e6-60150e7a54e3", "5fa3d032-bed9-415e-98ed-d725e1df5b62", "bfe08d69-b536-49b4-bae6-d8dee000e27a"], "title": "Focus games for satisfiability and completeness of temporal logic", "venue": "logic in computer science", "year": 2001, "id": "ec1a35e3-4cf7-4094-8da9-1108743651db"}
{"abstract": "This paper presents the combined use of meta-modelling and graph grammars for the generation of visual modelling tools for simulation formalisms. In meta-modelling, formalisms are described at a meta-level. This information is used by a meta-model processor to generate modelling tools for the described formalisms. We combine meta-modelling with graph grammars to extend the model manipulation capabilities of the generated modelling tools: edit, simulate, transform into another formalism, optimize and generate code. We store all (meta-)models as graphs, and thus, express model manipulations as graph grammars.", "authors": ["Juan de Lara", "Hans Vangheluwe", "Manuel Alfonseca"], "n_citation": 159, "references": ["0d261b6a-c94a-4d5e-b44e-eb6ae46581fc", "1509419f-cc0b-416f-8148-3944414ff068", "28c77e0b-4403-41f9-b2b5-e0e7fc167a71", "3350ea24-e7d9-4a1d-9e62-2104ef788a11", "a2f11d19-aac8-4c33-9867-167d58f25318", "c25abd24-471d-4795-9f59-c5f7e7ca542d", "c37de98f-0552-4d35-b23c-7644f670837b", "d6285e34-13fa-4327-b4f9-203181baa8c6", "d7920e53-0355-4b74-bce0-f2a713183bb5", "ec70908f-2f6c-4711-bbf7-1ff802e246fc"], "title": "Meta-modelling and graph grammars for multi-paradigm modelling in AToM3", "venue": "Software and Systems Modeling", "year": 2004, "id": "07bdfd0b-e23e-49e1-b92c-e09467ec7b6b"}
{"abstract": "Changeability (also called evolvability) is an essential property of software. Software change is the foundation for both new software development and legacy software maintenance, therefore a better understanding of software change is an important software engineering issue. This paper covers selected topics related to software change, including minicycle of change, partitioned annotations, and change propagation, and gives a brief overview of the field.", "authors": ["Vaclav Rajlich"], "n_citation": 50, "references": ["0808ecd3-1cdb-4f67-9ca4-a607dd6df318", "1491d9bc-6ac4-4e99-8f70-14bbc3ac2f9a", "1ba8dd6e-4537-43d1-afc3-bff4f43da28d", "316c5987-c85e-4fed-8414-620a3ecf6a4e", "3e0370c4-e0b1-4c6f-a13c-b2b7ff9ceac0", "40bb597c-f28a-4187-bab9-84bba177b993", "4816cd00-c706-4d7e-b4a9-ce61e9880209", "483261b9-66ae-4117-ac5e-78e3e5ea3892", "72a2db6c-8e9c-4ef1-9378-8ac0fd400edd", "cc1949cc-89fa-4c01-8b49-30a785d6ca4d", "cc4fc1af-166d-41a5-b584-2c2dd61918a5"], "title": "Software Change and Evolution", "venue": "conference on current trends in theory and practice of informatics", "year": 1999, "id": "a8c80c41-a845-4644-8259-f400593fd924"}
{"abstract": "In this paper, we propose a new approach to combine multiple features in handwriting recognition based on two ideas: feature selection-based combination and class dependent features. A nonparametric method is used for feature evaluation, and the first part of this paper is devoted to the evaluation of features in terms of their class separation and recognition capabilities. In the second part, multiple feature vectors are combined to produce a new feature vector. Based on the fact that a feature has different discriminating powers for different classes, a new scheme of selecting and combining class-dependent features is proposed. In this scheme, a class is considered to have its own optimal feature vector for discriminating itself from the other classes. Using an architecture of modular neural networks as the classifier, a series of experiments were conducted on unconstrained handwritten numerals. The results indicate that the selected features are effective in separating pattern classes and the new feature vector derived from a combination of two types of such features further improves the recognition rate.", "authors": ["Il-Seok Oh", "Jin-Seon Lee", "Ching Y. Suen"], "n_citation": 77, "references": ["18795f8c-8426-4d9c-81b6-5a2016b803c6", "46aae017-5087-42f1-b77c-3e753a3491ba", "4a29b56b-b74e-4945-9017-61a7ab844fd9", "4fa95ad7-531a-4695-b312-d76cd83d757a", "693a1be9-5e0a-4cf2-a4a5-6b64f90d78f3", "a21f5386-c3a8-4ce1-b1e8-978b0315e417", "a530b2e9-d9af-464a-a9ea-aea3031b5b95", "b86e014b-3772-4d67-bf87-4b9f2c625660", "bd89104a-7f1d-4813-a93c-2a5e9842c3ba", "c23c4c74-f59a-4ed7-8600-f6100358d4bd", "d120a352-5f1e-4a64-b65a-85fda703f3be"], "title": "Analysis of class separation and combination of class-dependent features for handwriting recognition", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 1999, "id": "042172f1-fe4c-463d-a017-e8edf64817cc"}
{"authors": ["Ben Taskar", "Daniel N. Klein", "Michael J. Collins", "Daphne Koller", "Christopher D. Manning"], "n_citation": 249, "references": ["06ba8c41-6f82-4722-b0af-4260612387c8", "094f9d37-c370-446f-988f-bbeb9542922f", "1c77c2f4-e6c0-4a3b-8518-ddedcd38b3bc", "218e9d40-0003-4504-beab-24f89b3341fc", "3fd6eb96-c103-4d42-971f-9267a70cc14d", "5538b634-04f3-4d09-bb4e-90055817e3b1", "932cee53-f2b6-4708-b48e-ddffbfdb5b14", "ae829318-5d10-461d-9c99-34a95a3f8732", "b474c853-4d5d-4813-a6a2-9429105ad503", "b74516d7-ce79-4cd6-ae33-513845e6b4ca", "f9e3e988-2e3d-4bca-9f31-2fed5dcf2116", "fa512d50-e535-4feb-91d0-42b071e08a4f"], "title": "Max-Margin Parsing.", "venue": "empirical methods in natural language processing", "year": 2004, "id": "8265ebd3-1d90-40f4-9fa1-5b8cfe75c3fc"}
{"authors": ["Rainer Schmidt", "Bernhard Heindl", "Bernhard Pollwein", "Lothar Gierl"], "n_citation": 50, "references": ["05c01cc1-af2d-4d2a-b0a1-59874c6c0ad8", "15683546-32e6-4467-837b-6d5e44d1bab3", "47d2826c-1c41-4efd-bdf9-1852e7c3d586", "59efb068-0be4-45bd-8fcb-be6c7a0b1fe5", "83a50ecd-cb13-4754-800d-562433b19c5d", "93116547-f002-403a-a762-29edaa3410d0", "a60a7ab2-d79b-4643-985d-9cc03a38d61b"], "title": "Abstractions of Data and Time for Multiparametric Time Course Prognoses", "venue": "", "year": 1996, "id": "eb6591b8-d428-44af-a78e-c9920ed26862"}
{"abstract": "An emerging breed of generators synthesize complex software systems from libraries of reusable components. These generators, called GenVoca generators, produce high-performance software and offer substantial increases in productivity. GenVoca is a blueprint for creating domain-specific software component technologies. Predator and Adage are based directly on GenVoca. Experimental evidence from the Predator project supports claims of performance and productivity with this model. >", "authors": ["Don S. Batory", "Vivek Singhal", "Jeffrey A. Thomas", "Sankar Dasari", "Bart J. Geraci", "Marty Sirkin"], "n_citation": 181, "references": ["6d8f9f73-2703-4142-93a2-2983e9b5f050", "746294f6-0356-4684-9b4b-480ad83d0e9a", "be5ca03f-895a-4835-94d7-498633556ee7", "e08f5dfa-db01-40bd-a176-d227e5851582", "ea8d8e8f-d8df-4722-935b-401665ea6fbc"], "title": "The GenVoca model of software-system generators", "venue": "IEEE Software", "year": 1994, "id": "0cc3cdb2-f289-464f-8dab-e79c82446a93"}
{"abstract": "The universal marker (i.e., universal quantifier) and the functional relation are two useful notations that make Conceptual Graph (CG') representations more concise in expressing universally quantified facts and functional dependencies, which are commonly used in knowledge bases, logic programs and data conceptual schemas. We introduce an expansion rule that formally defines the semantics of CGs containing universal markers and/or functional relations. On the basis of this formal semantics, we define two reasoning operations that are performed directly on CGs with these two notations to make them more useful. One operation is the universal CG projection defining the subsumption relation on the extended CGs. The other operation is the universal concept join performing universal instantiations and inheritances simultaneously in one graph operation. Both the operations are proved to be sound with respect to their described interpretations.", "authors": ["Th Cao", "Peter N. Creasy"], "n_citation": 50, "references": ["1b978417-c775-4777-bad6-ee3ee15f2025", "72509a38-849d-4b20-96ca-9fd5c033dd04", "763cf6bc-a92d-419e-bd8e-9bf9564cb6f0", "8eb094f7-0a38-4281-b2c2-d2556c96f82b", "989d940f-d05b-4644-aa91-49114aaf7245"], "title": "Universal Marker and Functional Relation: Semantics and Operations", "venue": "international conference on conceptual structures", "year": 1997, "id": "a25530f4-effd-44f1-b76c-941a36aaad20"}
{"abstract": "Input-to-State Stability (ISS) and the ISS-Lyapunov function are useful tools for the analysis and design of nonlinear systems. Motivated by the fact that many feedback control laws, such as model predictive or event-based control, lead to discontinuous discrete-time dynamics, we investigate ISS-Lyapunov functions for such systems. ISS-Lyapunov functions were originally introduced in a so-called   implication-form   and, in many cases, this has been shown to be equivalent to an ISS-Lyapunov function of   dissipative-form  . However, for discontinuous dynamics, we demonstrate via an example that this equivalence no longer holds. We therefore propose a stronger implication-form ISS-Lyapunov function and provide a complete characterization of ISS-Lyapunov functions for discrete-time systems with discontinuous dynamics.", "authors": ["Lars Gr\u00fcne", "Christopher M. Kellett"], "n_citation": 26, "references": ["464f28d6-004c-4fd4-8167-8ee350e7650c", "6ea71b99-657f-4767-8704-8b73b23c000c", "6ee48a92-fb6e-42eb-8d25-926aeb60d8ce", "7831e4f5-0700-4703-ba18-02b97930b08b", "90aa0b41-2234-43be-a0b3-3d9dab4f9477", "9af5ff7b-6d24-4bee-9d36-f1bed3fdf429", "9d7805c3-36dc-4545-a07c-dcc180030b66", "b2765652-8931-4193-ab30-0d1c4e37a609", "be93fa08-2dad-41fc-a91c-ad7a25d392d0", "c7621eb4-d889-4f22-958a-05eaa654f370", "ddcbcfa3-2dc2-4971-a8f5-595775d30517", "e01eca2e-f9ba-4dc3-8bfa-f6f9f2c4cd76", "e0fbb7f9-6535-42d4-b6cc-48e882e7ea0d", "e1fe9c15-9bcc-45d6-8188-48244d6ec486", "e1ff2cff-b775-491c-a75e-e31c92bd85ca"], "title": "ISS-Lyapunov Functions for Discontinuous Discrete-Time Systems", "venue": "IEEE Transactions on Automatic Control", "year": 2014, "id": "e7fb7835-1a16-4e3d-bbcf-7e38717c32a0"}
{"abstract": "Service Oriented Computing is emerging as a reference model for a new class of distributed computing technologies such as Web Services and the Grid. We discuss three main aspects of Service Oriented Computing (loose coupling, communication latency, and open endedness), and we relate them with traditional process algebra operators. We also indicate some new issues, raising from the combination of these three aspects, that require the investigation of suitable new process algebra operators.", "authors": ["Mario Bravetti", "Gianluigi Zavattaro"], "n_citation": 20, "references": ["012b395d-a76a-490e-9b38-e9b70ec89587", "029992bd-78db-427d-87fa-4a9e88ee7a7d", "12220ccf-ef71-4b43-95c1-3a42d3c06fc0", "14b79bfc-b11c-44d5-82ba-102d3a586a8c", "4207d0db-a5f5-44bb-a72d-ff734ae7e02b", "6dbe2b85-f3e3-454c-8ac3-17e92df46548", "7053f8cb-6652-49cd-90c7-970c7498eb0c", "a00293f3-1cac-47a1-85b3-0906b131a300", "c6c9d2bf-cf62-4a0a-926a-0da6d5ca04ac", "d6483a4b-c893-4f1e-a6a7-d8913baae24f", "db4e226a-5dd9-44d4-bac3-3ba3594ca4d7", "fecbe12b-88b2-48ab-a477-adb16301b9c4"], "title": "Service oriented computing from a process algebraic perspective", "venue": "The Journal of Logic and Algebraic Programming", "year": 2007, "id": "013a4b7a-04c2-479e-b9f7-09adef0e16b6"}
{"abstract": "A method is presented for automated segmentation of vessels in two-dimensional color images of the retina. This method can be used in computer analyses of retinal images, e.g., in automated screening for diabetic retinopathy. The system is based on extraction of image ridges, which coincide approximately with vessel centerlines. The ridges are used to compose primitives in the form of line elements. With the line elements an image is partitioned into patches by assigning each image pixel to the closest line element. Every line element constitutes a local coordinate frame for its corresponding patch. For every pixel, feature vectors are computed that make use of properties of the patches and the line elements. The feature vectors are classified using a kNN-classifier and sequential forward feature selection. The algorithm was tested on a database consisting of 40 manually labeled images. The method achieves an area under the receiver operating characteristic curve of 0.952. The method is compared with two recently published rule-based methods of Hoover et al. and Jiang et al. . The results show that our method is significantly better than the two rule-based methods (p<0.01). The accuracy of our method is 0.944 versus 0.947 for a second observer.", "authors": ["Joes Staal", "Michael D. Abr\u00e0moff", "Meindert Niemeijer", "Max A. Viergever", "B. van Ginneken"], "n_citation": 1895, "references": ["054802da-caa5-4bbb-aad9-53eaf2c5e29c", "0ef690c4-2292-44fd-a7dd-b705142ce19e", "1ddd1733-a97d-4127-adc7-32a5974385e2", "21b11e53-e4b0-4b00-9aa5-863d63be8591", "430bc284-02f1-4e45-81de-a1e1f12339c7", "4dc2a96f-9794-443b-8697-743c466efd1f", "5437c0a0-8f20-49c3-86e5-9d860f3e4f04", "c5450ef8-850d-40b1-97bc-5ac12593e395", "d26da4b8-e997-4dbd-b2fc-1a03cc8f8a8b", "f4c0d0cf-d204-43e6-834b-9c37628778ac", "f83ed20f-bd8a-4c57-a543-e3edf8cf8297"], "title": "Ridge-based vessel segmentation in color images of the retina", "venue": "IEEE Transactions on Medical Imaging", "year": 2004, "id": "b8271cdf-63b2-4461-bf2c-58bd33d7c35b"}
{"abstract": "We propose the first practical and secure way to integrate the iris biometric into cryptographic applications. A repeatable binary string, which we call a biometric key, is generated reliably from genuine iris codes. A well-known difficulty has been how to cope with the 10 to 20 percent of error bits within an iris code and derive an error-free key. To solve this problem, we carefully studied the error patterns within iris codes and devised a two-layer error correction technique that combines Hadamard and Reed-Solomon codes. The key is generated from a subject's iris image with the aid of auxiliary error-correction data, which do not reveal the key and can be saved in a tamper-resistant token, such as a smart card. The reproduction of the key depends on two factors: the iris biometric and the token. The attacker has to procure both of them to compromise the key. We evaluated our technique using iris samples from 70 different eyes, with 10 samples from each eye. We found that an error-free key can be reproduced reliably from genuine iris codes with a 99.5 percent success rate. We can generate up to 140 bits of biometric key, more than enough for 128-bit AES. The extraction of a repeatable binary string from biometrics opens new possible applications, where a strong binding is required between a person and cryptographic operations. For example, it is possible to identify individuals without maintaining a central database of biometric templates, to which privacy objections-might be raised", "authors": ["Feng Hao", "Ross J. Anderson", "John Daugman"], "n_citation": 709, "references": ["3d84d44c-6f51-4104-93f2-080de0d213ed", "459155a8-01e3-4758-b094-e48a35a9a9e4", "4ab0f031-c1e3-40c7-b4f5-7cea3e16bbc8", "539046d5-f94a-4d5c-8b96-a110cbef824a", "55589bd6-ad90-4aad-9917-39ac834fbf02", "688dbaf9-9990-484a-8ea9-8e80474d6a1b", "85d69ae6-04d8-4dc6-a405-16806893171d", "b0787ca6-7611-44f3-9a70-ffe777e51e9f", "d14738d9-7ba0-4e03-a9e1-1a15c4b61020", "faf6da43-12ac-4f81-8d78-3bab2d92cc98"], "title": "Combining Crypto with Biometrics Effectively", "venue": "IEEE Transactions on Computers", "year": 2006, "id": "ea6808a0-7bc5-407d-8c35-f10d41ff4db5"}
{"abstract": "An important drawback to the popular Belief, Desire, and Intentions (BDI) paradigm is that such systems include no element of learning from experience. We describe a novel BDI execution framework that models context conditions as decision trees, rather than boolean formulae, allowing agents to learn the probability of success for plans based on experience. By using a probabilistic plan selection function, the agents can balance exploration and exploitation of their plans. We extend earlier work to include both parameterised goals and recursion and modify our previous approach to decision tree confidence to include large and even non-finite domains that arise from such consideration. Our evaluation on a pre-existing program that relies heavily on recursion and parametrised goals confirms previous results that naive learning fails in some circumstances, and demonstrates that the improved approach learns relatively well.", "authors": ["Dhirendra Singh", "Sebastian Sardina", "Lin Padgham"], "n_citation": 50, "references": ["204f7504-443d-46e4-b29d-394b79a44f7d", "4339e7aa-682d-46dd-9e6d-c48cc409ea2c", "476af27a-91b4-4881-b2ed-acd0ec21aeef", "4f93c731-1c76-4a32-bbd8-c97001c57118", "56865899-5f05-479f-8e97-cfe68459f53b", "636f1cc2-5670-46b8-9567-a0cc08d9ed9c", "8de98042-38af-4abd-8e88-745cba7a5767", "95ccbfa6-3069-49e8-9761-dce4f9d76a75", "af55f019-02fd-4afa-b12c-455d42d5e758", "b15d2cb4-b14d-405e-9faa-2dca0c307fd5", "bb01a457-551e-4805-a013-8fa280df11bd", "d4f1ac36-177e-46f5-9dbc-22e065bc3466", "d68c2256-5e46-47d9-aa0b-ed871638f501", "e021468a-7ddc-4533-aa9d-7118efb3ab4c"], "title": "Extending BDI plan selection to incorporate learning from experience", "venue": "Robotics and Autonomous Systems", "year": 2010, "id": "7db268b4-8639-402e-b235-21d123f7d522"}
{"abstract": "Open shortest path first (OSPF) is the most widely used internal gateway routing protocol on the Internet. However, one shortcoming is that it does not take advantage of the existence of multiple equal-cost paths between source and destination nodes. A well-known variation of OSPF, OSPF-ECMP (ECMP, equal-cost multipath), does exploit the presence of multiple equal-cost paths, but only on a static basis. A variation of OSPF, OSPF-OMP (OMP, optimized multipath), attempts to dynamically determine the optimal allocation of traffic among multiple equal-cost paths based on the exchange of special traffic-load control messages. This paper briefly describes the OSPF-OMP algorithm and the design of a discrete event simulator that models its behavior. We then use this simulator to carry out three experiments that compare the performance of OSPF, OSPF-ECMP, and OSPF-OMP under a range of traffic loads and distributions. Our results show that OSPF-OMP produces improvements in both delivery time and the number of lost messages when compared with the other two protocols.", "authors": ["G. Michael Schneider", "Tamas Nemeth"], "n_citation": 50, "references": [], "title": "A simulation study of the OSPF-OMP routing algorithm", "venue": "Computer Networks", "year": 2002, "id": "4e55c663-48e2-4251-8daf-72e485141edc"}
{"abstract": "This article analyses how and why councillors blog on the government-funded civic-blogging platform, Read My Day. Through a mixture of content analysis and interviews, the article assesses the kinds of communication being facilitated and how the blogs were used during the 2007 local elections. The analysis and interpretations are framed by a critique of the normalisation hypothesis. The article concludes that blogs were largely used as tools of representation rather than for campaigning. The extent to which they strengthen representative practices is mixed. Many bloggers fail to exploit the networking potential of the medium such as creating blog rolls and engaging with the broader blogosphere; this leads to a danger that the politically-interested are talking to each other in isolation. Furthermore, the number of comments is limited, and councillors often do not reply to these: it is typically broadcast, one-way communication. However, there are potentially important positive changes that must be fully considered alongside this. If it is true to say that political communication is increasingly negative, attack-orientated, dominated by political leaders and lacking in substance, then the blogs on Read My Day do go some way to redress this: while it is an example of how technologies are being normalised, it is not quite politics as usual.", "authors": ["Scott Wright"], "n_citation": 50, "references": ["a8db8181-35bd-48f0-90d7-b91397bcdc0f", "cd1c1986-82e2-4932-ac92-cb6127b6ea5a", "d207acf5-121c-4175-a3cd-31a215d011d4"], "title": "Read My Day? Communication, campaigning and councillors' blogs", "venue": "", "year": 2008, "id": "8beddccc-7cd8-4046-9386-87d8e1e5e0fe"}
{"abstract": "This is a description of the Napier88 type system based on \u201cA Framework for Comparing Type Systems for Database Programming Languages\u201d by Albano et al.", "authors": ["Alan Dearle", "Richard C. H. Connor", "Fred Brown", "Ronald Morrison"], "n_citation": 80, "references": ["192a0fe0-b5ae-41a4-8e59-afbf21bd979e", "1cc071b5-2460-4213-b32b-973671d2b85a", "4706e594-31b9-4d45-a859-c83230b44ae7", "5c15b63a-6b03-4455-9d1f-11957ff8ecc5", "6a18ae3e-fec1-4f99-8da8-87752a8c5e7b", "79bd09c6-fc79-4564-aff8-ea94f20b4d42", "7c59931e-f1e7-4ca4-8262-1303b45e7c97", "a7740597-ff39-4069-a0eb-c9631986cf28", "c9daf25c-1900-4b85-be48-b81755c6486f", "e8349db7-99bb-4902-aa2f-4ca239ac1761", "efe524bc-8e0b-4384-9475-f46dec1ebd55", "f2df4d59-3f04-4bed-a0de-d23d8db240d7", "ff039cb0-875f-4ecc-862c-e8574ed258e2"], "title": "Napier88\u2014a database programming language?", "venue": "database programming languages", "year": 1989, "id": "261f9d1a-f2f4-41b6-bf03-2a8d07a96adc"}
{"abstract": "In this paper we describe COLIN, a forward-chaining heuristic search planner, capable of reasoning with COntinuous LINear numeric change, in addition to the full temporal semantics of PDDL2.1. Through this work we make two advances to the state-of-the-art in terms of expressive reasoning capabilities of planners: the handling of continuous linear change, and the handling of duration-dependent effects in combination with duration inequalities, both of which require tightly coupled temporal and numeric reasoning during planning. COLIN combines FF-style forward chaining search, with the use of a Linear Program (LP) to check the consistency of the interacting temporal and numeric constraints at each state. The LP is used to compute bounds on the values of variables in each state, reducing the range of actions that need to be considered for application. In addition, we develop an extension of the Temporal Relaxed Planning Graph heuristic of CRIKEY3, to support reasoning directly with continuous change. We extend the range of task variables considered to be suitable candidates for specifying the gradient of the continuous numeric change effected by an action. Finally, we explore the potential for employing mixed integer programming as a tool for optimising the timestamps of the actions in the plan, once a solution has been found. To support this, we further contribute a selection of extended benchmark domains that include continuous numeric effects. We present results for COLIN that demonstrate its scalability on a range of benchmarks, and compare to existing state-of-the-art planners.", "authors": ["Amanda Coles", "Andrew Coles", "Maria Fox", "Derek Long"], "n_citation": 92, "references": ["0217963b-9f28-447d-91b8-707da36ee40c", "098cf9d2-e55a-453a-ad0c-270d47019fef", "1326ccf1-037b-4bd0-8e9d-763ce37d2e81", "163bbca8-7e69-4318-9bc4-d5fe014e63de", "173ea8db-95e3-4e2c-ba16-7d42127c3af2", "1d01ee40-fe5d-4777-83de-1307f2c73256", "1f58e73c-912f-4a13-8c32-25d6ee610a03", "21f2616d-3132-4e89-8643-4950365a72bb", "27ba9e7c-14dc-48d6-bf43-0e1239dba82c", "29110bbb-4692-474e-ac6e-8e8c77f0b5d6", "2a83f028-e06a-4bce-8881-50077ccc2406", "2b53e0a8-deb2-412b-a571-39efeca2987e", "2caf93da-34ae-47a3-b2db-adb1f4ba0f2e", "300757b5-5fb4-40b0-9561-073eb0d42859", "311587d2-e110-4331-a960-643ebdedb0c1", "34b65806-2c47-4e98-9eea-c078b08f836d", "3ac36bc3-1319-4596-aa71-41d0e02f4ddf", "3e148cee-b6c4-419a-a2b1-6262de050260", "416199f3-ff0c-4e9b-8feb-286c46c9c1da", "48978913-7441-4636-8352-75a7bc484d23", "4e30a0b7-d71b-4a09-82af-4c156ed39d11", "4fe8f126-5f0d-4dae-bf77-35a1e2fe0cc3", "507d931e-d5bb-48a5-ae7d-90ca0420847e", "507e9c8b-fea4-4186-b16d-a75a65f6a839", "5e86eea9-77d3-4596-a453-08aa42f0bf2b", "5f31b575-495d-414d-9862-d2b5d5cff196", "5f842144-37ff-4070-9497-922e9acf96b1", "6ab44cb9-1702-45a0-8c4a-d3757b3f09a1", "71789ba2-1a14-494c-acfc-7260a5737472", "72f8a231-fd5b-4c77-b056-a8780c07098d", "759ced7c-b6cd-4c96-b525-b500bac41447", "78177b8f-531b-40f0-8656-9ea74ec3e0d5", "786511a9-1d3d-40d5-921a-e8e814ac8c17", "7e188ab2-e7a5-4fac-8b54-4cd899aa2478", "7e92ff67-3548-4fd2-852a-a4a898f30b2a", "80b63256-d911-4c3f-934d-08757bff8254", "8107528a-e743-46c6-a2e8-e857b56bb89a", "813f2afc-8000-467f-9bc3-bbed7d666b58", "82bbf74b-1531-414f-97fd-0296f1c13bd6", "88ad4d73-56e1-40df-afeb-a333e5d3f0ee", "8d0ab78a-c280-4ed5-84c9-36d052a42b77", "8f26e2f7-6b43-4841-ae69-b7ff5efdac31", "9ec31b09-eb4f-47c4-8457-f7f096934863", "acb50193-6274-4601-892b-c7306adc46e2", "b25b0156-76f0-4af0-ba3a-01e76c659fee", "b8c3f74a-5f01-4b36-84d6-242c9681440e", "c732b248-8c44-4dbe-bbac-1c7fa0842eda", "c7d422c3-e026-4891-afae-68f2a69fbf67", "da74447e-fdaf-49da-8dea-8400c9f878f6", "dba94232-ab72-426f-9ead-4ae3b23682fb", "dc84522b-7500-406e-b53f-b18d57a69a2b", "df7bfdcf-b724-47f1-8c2e-4b07860a5039", "e3cce451-4f19-4f03-b2a7-25ce8fc826b4", "ed60c1f8-c8c3-4bd8-98e2-d893a8a90994", "f0e1ce41-5b9e-479e-9df0-340d6d17d57f", "fc58ab3b-36a8-4e1f-abf6-6841fd94cff6", "ff2ceba7-b93e-4463-b63a-52c832612b1a"], "title": "COLIN: planning with continuous linear numeric change", "venue": "Journal of Artificial Intelligence Research", "year": 2012, "id": "b1eb9e86-9041-4159-a1c3-bec5ca16bc1a"}
{"authors": ["Thomas W. Reps"], "n_citation": 108, "references": ["08a1b4eb-e543-437d-8346-f1b70b8dc493", "2c08d317-3848-40af-9dfa-20c8ce584ce9", "414f37b8-385f-4982-a5bc-b4d215d979e4", "42924e90-9ca5-4858-a474-6cbf3578ff92", "528daae8-8412-4057-8b50-5510812e7cdc", "600707bb-3ffe-41db-9d8e-1d98090032d4", "66d779cf-d6bc-4d55-8865-8e946a7645b4", "73c1dcb8-e5c5-4c5d-9d79-b6561266c69d", "74f487b8-5648-4891-bf7f-84ea9fd6dc0f", "805b10c9-c873-4e24-9ebe-39e9eec5b94c", "9d114723-e82c-44af-b73f-ff9dd7b6730e", "a7f3ac80-bd0b-482d-a05c-1feeb7f6cec5", "abde5ea1-99dc-4812-aa90-50f17478138f", "b2eddbc1-021d-41cb-aa50-025eb10ed5c2", "ba04bb23-dd85-44a6-a7c5-8d22e2b4faaa", "c013fa51-aa00-4e66-ae09-ad4fb7b486e0", "c3ffb05e-167d-4ad5-ae3c-34cf8b17d103", "c407fa93-c2ae-4b48-9b56-7feb0134352d", "e0c1b56b-6574-4db0-92ed-4a3a337053bd", "e2e62de3-82aa-40a1-8377-c191f3dc715c", "ee4d7169-4ec5-4341-a649-0b2841268308", "f8beca93-c81c-4048-ba4e-f595ed3b637d", "f9fbe00e-2980-4c0e-a9b1-4e62fd5fa383"], "title": "Demand Interprocedural Program Analysis Using Logic Databases", "venue": "logic in databases", "year": 1995, "id": "d03711c3-398d-4206-b12f-0638dc8b28b3"}
{"abstract": "Constraint satisfaction problems have wide application in artificial intelligence. They involve finding values for problem variables where the values must be consistent in that they satisfy restrictions on which combinations of values are allowed. Recent research on finite domain constraint satisfaction problems suggest that Maintaining Arc Consistency (MAC) is the most efficient general CSP algorithm for solving large and hard problems. In the first part of this paper we explain why maintaining full, as opposed to limited, arc consistency during search can greatly reduce the search effort. Based on this explanation, in the second part of the paper we show how to modify MAC in order to make it even more efficient. Experimental results prove that the gain in efficiency can be quite important.", "authors": ["Daniel Sabin", "Eugene C. Freuder"], "n_citation": 68, "references": ["1570b9bb-3716-49eb-8d64-f9dafdda4dd2", "33879111-9bad-4b07-93fa-2c0fc30b8cd2", "4b8fa5eb-e6bc-4b03-932d-3daa07f89e24", "7a033746-d7f1-418e-ab14-5058be203597", "87c3a82c-3c88-455a-9b47-236661b2c032", "ac39dba5-04ee-4ac3-9cc0-75bab50ad629", "be657e8b-f27a-4917-a31e-cafe79f4f286", "c99224d3-84c5-464e-90e3-8d26cee0d31c"], "title": "Understanding and improving the MAC algorithm", "venue": "principles and practice of constraint programming", "year": 1997, "id": "1c3f3b58-6795-4bd0-872d-d259da84317a"}
{"abstract": "In Asiacrypt 2007, Vaudenay proposed a formal model addressing privacy in RFID, which separated privacy into eight classes. One important conclusion in the paper is the impossibility of achieving strong privacy in RFID. He also left an open question whether forward privacy without PKC is possible. In our paper, first we revisit the eight RFID privacy classes and simplify them into three classes that will address the same goal. Second, we show that strong privacy in RFID is achievable. Third, we answer the open question by pointing out the possibility to achieve forward privacy without PKC both within Vaudenay's model and in practice.", "authors": ["Ching Yu Ng", "Willy Susilo", "Yi Mu", "Reihaneh Safavi-Naini"], "n_citation": 75, "references": ["028fdd9c-a273-4edd-aa6a-33185c39a440", "06aacb87-5360-4502-9cec-fe73fc63c75b", "1e8b1868-cb11-43b0-ac08-998bd7de26b9", "2d34e860-c207-4523-8593-a1e69deedc44", "3738cf1d-2184-4ee9-b4f2-ae73080cd405", "4f5ba2d6-ad97-4667-9dd7-e6043f42e5fa", "62430b07-28bb-4038-a746-d89478cd9fe4", "b0d8db4e-53bc-413f-9296-9375d89b34bd", "b6ed8782-daef-4847-aaa0-65c6a32c4287", "bb8860c1-b707-4409-a912-f33128ff5391"], "title": "RFID Privacy Models Revisited", "venue": "european symposium on research in computer security", "year": 2008, "id": "0b7831a7-09ec-4dfb-b93e-5b814149cab6"}
{"abstract": "Opportunistic routing (OR) is an upcoming and promising routing technique for wireless multihop networks. The key concepts behind OR is overhearing and cooperation among relaying nodes; therefore, OR works well in wireless multihop networks with higher node density, such as mesh or sensor networks. OR enables multiple routes and dynamic relay selection, thus, it obtains higher link reliability and larger transmission range. This paper reviews the basic concepts and describes components of OR with examples. Current trends, issues and challenges of OR are also discussed.", "authors": ["Che-Jung Hsu", "Huey-Ing Liu", "Winston Khoon Guan Seah"], "n_citation": 78, "references": ["0bff1632-df0d-4980-8eb0-c1ff9e6b967b", "124a1a04-6063-4fc0-b582-9e810b1cdaa0", "125bb0a6-36d8-4e77-8a1e-43dbc9b4c0d8", "14a274e3-6ec3-40f7-80ad-334711dc3222", "16176385-ff42-463e-857e-c00d5ee2ba72", "1adaeca5-f04f-4e27-94ec-33933034d64a", "219eb71c-8684-433e-82aa-9983a25a0efa", "222e8196-b98b-47bc-a679-641bbf57b770", "433b1f4a-3c31-4873-8867-8161dbd39d7a", "494bbd75-ce27-4236-9550-b7e58ad71a52", "49837ec9-81ed-46cd-a6e4-20f98997c594", "56a71b1b-c052-49b7-922b-5330ab42f334", "669ebec4-0590-42f4-8a56-c6251d2c5435", "69fd45e1-719e-4b09-9024-6c7b876274d7", "7760b7ea-8680-43ba-9fa3-eadd69a1d229", "8887a80e-30da-4f99-b71d-35868515de98", "8db2b113-0c3c-4970-9f9b-8906cd36223d", "96b245c2-47a5-4aec-89f0-d2a362124845", "98101c90-3c35-4c54-a32b-f6df2272d3c2", "99c293b0-76d9-412b-b01e-4a06d7626477", "ad3c6616-e836-4855-9883-a66480d3d577", "b2b72511-505e-4730-a6dd-940f1f607e5c", "c4f7d027-8e8f-49db-bf4d-b839d01b4b0d", "cb532379-fecc-436d-a8ec-fb3a729c3d5c", "ebb18732-aec8-4a49-aad2-9bffd694239b", "f3d530a9-0e8d-4a92-b5f4-379f5e72e6f8", "f6ab44af-a546-4705-973e-9c643dcb899b"], "title": "Survey Paper: Opportunistic routing - A review and the challenges ahead", "venue": "Computer Networks", "year": 2011, "id": "977429e7-9327-46a1-886c-77962b5fda65"}
{"authors": ["Boris Magnusson", "Ulf Asklund"], "n_citation": 81, "references": ["240aec47-cb84-4392-851b-fb3092df4b3e", "33dd7ce8-453e-4824-b700-6d29d69d5502", "8ab3e0e0-0b4f-446f-8df2-385d56decb23", "8bc51ef3-25f5-4ee8-ac28-03af2289603e", "92315972-39b7-4a93-9269-5b3bd52b8cb6", "c764e4e5-d2af-4f36-8974-a5f6977377fe", "dd112b09-d832-4b48-866e-0c8eb485b972"], "title": "Fine Grained Version Control of Configurations in COOP/Orm", "venue": "", "year": 1996, "id": "530f8d1b-c2ba-4042-a4bb-1ea10554a02e"}
{"abstract": "In this paper we are concerned with the Waterloo variant of the index calculus method for the discrete logarithm problem in {\\Bbb F}_{2^n}. We provide a rigorous proof for the heuristic arguments for the running time of the Waterloo algorithm. This implies in studying the behavior of pairs of coprime smooth polynomials over finite fields. Our proof involves a double saddle point method, and it is in nature similar to the one of Odlyzko for the rigorous analysis of the basic index calculus.", "authors": ["Michael Drmota", "Daniel Panario"], "n_citation": 50, "references": ["04a6a70d-f802-4209-9bdc-5c99ef048041", "1670d841-dee7-467a-b37e-78139fde2c6c", "2c33bdb1-6f8e-4453-8e10-5153056ae70f", "53f60607-1b79-4e46-b3fc-f496a27db029", "b3e60a8a-11fd-414c-b24d-5eba034a15d2", "ca394e6a-59e0-466c-a66a-d976555db689", "e53cf47b-42d4-4624-9ea0-d1e1e9e889e7", "f79da521-cc8d-4a8d-a0f4-9478e1836fec"], "title": "A Rigorous Proof of the Waterloo Algorithm for the Discrete Logarithm Problem", "venue": "Designs, Codes and Cryptography", "year": 2002, "id": "e747d4a0-04d3-4698-a738-ebf510d7bbee"}
{"abstract": "Software testing is an important technique for assurance of software quality. Mutation testing has been identified as a powerful fault-based technique for unit testing, and there has been some research on automatic generation of test data for mutation testing. However, existing approaches to this kind of test data generation usually generate test data according to one mutant at one time. Thus, more test data that are needed for achieving a given mutation score. In this paper, we propose a new approach to generating one test data according to multiple mutants that are mutated at the same location at one time. Thus, our approach can generate smaller test suite that can achieve the same mutation testing score. To evaluate our approach, we implemented a prototype tool based on our approach and carried out some preliminary experiments. The experimental results show that our approach is more cost-effective.", "authors": ["Ming-Hao Liu", "You-feng Gao", "Jin-Hui Shan", "Jiang-hong Liu", "Lu Zhang", "Jiasu Sun"], "n_citation": 50, "references": ["0ffbd980-4779-4039-ad72-c37a8d41f79e", "1428f757-51e1-4de7-bb58-91917c0390b5", "1528084b-78d7-49e3-82b3-8b71d2d33dfd", "2b47a5ec-fd51-4b53-bd29-f6fc5e44da8a", "40291a5a-5cb0-4189-966e-8197facbd9bd", "42ddc421-4f79-412d-aa63-6b4944f827c5", "5e7712e2-3821-4610-944e-e6ddc75f96fc", "6e83a740-817b-4627-b54a-3e81c6386aec", "77ca595f-08ba-4715-a785-8cf76caef0a8", "7a7ef9db-62aa-4fff-90f8-73a18a2535c3", "7da49e37-374f-4f4a-bb6d-e5c732a0fd01", "8b4d85cc-17b5-4d68-9a48-ce258a47518c", "988a49ff-20c3-4170-88c0-3665aa3630c5", "a7122806-c66c-49e6-8876-70093d70f605", "a999b6c8-79f0-49b6-b20a-df07e2413d49", "b3e45955-eaeb-40d9-b038-40cbf44d67b2", "b97f40dc-edcc-47bd-906d-1c48d847b725", "c7b3516b-8144-4976-8b21-fe34afeed42d", "d9405b31-56bf-4319-8a83-4df4a0950e97"], "title": "An Approach to Test Data Generation for Killing Multiple Mutants", "venue": "international conference on software maintenance", "year": 2006, "id": "60537055-67d2-4d2c-ae7c-f7ebf4b85264"}
{"abstract": "There are several tools and techniques developed over the past decade for detecting duplicated code in software. However, there exists a class of languages for which clone detection is ill-suited. We discovered one of these languages when we attempted to use clone detection to find similar web service operations in service descriptions written in the Web Service Description Language (WSDL). WSDL is structured in such a way that identifying units for comparison becomes a challenge. WSDL service descriptions contain specifications of one or more operations that are divided into pieces and intermingled throughout the description. In this paper, we describe a method of reorganizing them in order to leverage clone detection technology to identify similar services. We introduce the idea of contextual clones -- clones that can only be found by augmenting code fragments with related information referenced by the fragment to give it context. We demonstrate this idea for WSDL and propose other languages and situations for which contextual clones may be of interest.", "authors": ["Douglas H. Martin", "James R. Cordy"], "n_citation": 50, "references": ["0690db41-a8e5-437e-b6bc-77b569d4d9d7", "14d6bcb0-97ad-47a0-970e-f828dde95f8b", "391e3351-f405-45cf-b507-075621b35326", "5548902a-d2b4-4319-985d-749de2f66ee5", "5f404ee1-1cb2-4751-8f04-14ffd62c1c9d", "6db76b27-52bc-403f-9147-efcca50711ae", "79cb637f-e548-4964-92ef-d0be9f215d40", "7ac221a5-ec95-44c8-ad9b-6851913e7570", "88dd06c7-16e0-4b9f-9e2d-27cd128b3b56", "c1398e57-1b31-4c53-afa6-c73bc51cb5c1", "e5e95121-5645-4827-9c27-7121ba3df0fb", "e7122dde-1430-49ce-8501-fd829649fea1", "ea1963b9-2542-484d-a567-b9f3a9c14f06"], "title": "Analyzing web service similarity using contextual clones", "venue": "", "year": 2011, "id": "157c392e-66ad-4aa9-a2c7-2cee38255831"}
{"abstract": "This paper studies the design and operation of energy integrated solid oxide fuel cell (SOFC) systems for in situ hydrogen production and power generation. Two configurations are considered: one where the hot effluent stream from the fuel cell is used directly to provide heat to the endothermic reforming reaction, and another where the hot effluent streams are mixed and combusted in a catalytic burner before the energy integration. A comparative evaluation of the two configurations is presented in terms of their design, open-loop dynamics and their operation under linear multi-loop controllers.", "authors": ["Dimitrios Georgis", "Sujit S. Jogwar", "Ali Almansoori", "Prodromos Daoutidis"], "n_citation": 50, "references": ["41dbfa00-a499-490c-91e2-664b75b91c83", "821844bc-a20e-4804-ab65-114f2f60b3d5"], "title": "Design and control of energy integrated SOFC systems for in situ hydrogen production and power generation", "venue": "Computers & Chemical Engineering", "year": 2011, "id": "62b33969-e653-45ff-b9b1-e4e00bad4814"}
{"abstract": "The United States faces a shortage of computer scientists. Despite the current economic downturn, the most recent estimate indicates a labor force shortage of IT professionals. The shortage of IT professionals, and especially of computer scientists, provides impetus for increasing the representation of women in computer science (CS). We examine why so few students, and particularly few women, choose to enter the beginning phase of the CS pipeline by choosing to try out CS courses. Women are seriously under-represented at this early juncture of the CS pipeline. If we are serious about making CS a more inclusive field, we need to make an impact at this early juncture. This is not to belittle the laudable efforts to reduce attrition among women CS majors. However, for maximum effect, interventions to increase the flow of women into the CS pipeline also need to occur before women declare their major.", "authors": ["Sylvia Beyer", "Kristina Rynes", "Susan M. Haller"], "n_citation": 71, "references": ["2216f272-3ac7-44f7-a178-90cb5ccb1828", "273c00b5-15be-4780-9a87-dfc8f3436a74", "675cc511-9a90-45b6-ae3d-53a547aad84a", "79b670ac-5f6c-4746-ace7-37e6864895a0", "819cb1cf-9bf5-4e6b-8cf6-6d4440135d86", "a2edaf30-89ae-43e5-acea-9619f67b3d86"], "title": "Deterrents to women taking computer science courses", "venue": "IEEE Technology and Society Magazine", "year": 2004, "id": "2a98b834-6f78-409e-9666-cdfee73ef826"}
{"abstract": "The software architecture of a distributed program can be represented  by a hierarchical composition of subsystems, with interacting processes at the leaves of the hierarchy. Compositional reachability analysis (CRA) is a promising state reduction technique which can be automated and used in stages to derive the overall behavior of a distributed program based on its architecture. CRA is particularly suitable for the analysis of programs that are subject to evolutionary change. When a program evolves, only the behaviors of those subsystems affected by the change need be reevaluated. The technique however has a limitation. The properties available for analysis are constrained by the set of actions that remain globally observable. Properties involving actions encapsulated by subsystems  may therefore not be analyzed. In this article, we enhance the CRA technique to check safety properties which may contain actions that are not globally observable. To achieve this, the state machine model is augmented with a special trap state labeled as \u03c0. We propose a scheme to transform, in stages, a property that involves hidden actions to one that involves only globally observable actions. The enhanced technique also includes a mechanism aiming at reducing the debugging effort. The technique is illustrated using a gas station system example.", "authors": ["Shing Chi Cheung", "Jeff Kramer"], "n_citation": 122, "references": ["07d56d86-aad9-4fe3-bad2-63501ea29989", "09d4f1c5-a20f-44a2-a911-a7709c9b8020", "10a7ed61-e367-4fd9-abb0-f7b911d988ce", "1412ff23-1344-4034-87ac-344cc850f0b3", "2001c63f-3a13-4498-88ac-de76423e29eb", "25d20461-5c89-4aee-9758-fa49a27c9acd", "29441e28-88d5-48c0-8678-ecc9b91b4a58", "29597bd7-43bd-4d38-89f8-cc2393958ccc", "2986cbde-d0fb-4599-84c4-c0efb845d7fe", "2d70108d-4238-4dba-a0c9-ec391a28cd33", "2fe13ed6-25c9-4182-b3f5-9f2107adcb64", "3023929a-c93e-49c5-b03f-7fb0414d94df", "34dc0d16-e150-4178-a576-b06e82c075f1", "3c7ec75f-6e45-4a58-bd35-6be16378261a", "3d6d3d14-fe5f-4e25-ac77-bdf0e362c8e0", "3d9ed97f-80eb-483f-ac53-e5f72e1b3494", "3e7e9364-c212-48fe-8e3e-495547440690", "3f4fbfdc-2b2c-48d5-a3db-4e5f0dd4e4d4", "41cf9713-ed76-43a6-8e9f-538abc2f787c", "444c2811-cf5a-4c5c-86fa-8f18a4c01386", "533369e5-45c8-4c36-865f-e47fa1b769e7", "6657d87b-869d-43f8-85d1-4634017c4139", "6fb1dedf-4888-4ec2-96a4-17afbcb963b2", "76b720a3-a402-4f69-86f4-72e31d328612", "77d2ea65-9174-464d-a871-60b33377035c", "7875ba51-0438-46d5-bc04-d0278f5e0fca", "823cf292-d2da-4a14-a27b-ade2fae949d2", "8bc1f31b-8589-4fe9-b3b2-0b3da2da7640", "91b5fdfc-9d65-4e06-9408-a7256e4dda37", "93672072-a749-47c6-b866-8ff2da2902ca", "9742b09e-7c8b-43e3-b4c3-0e41832f7d07", "9783285b-da3d-4d80-9b0d-8db511d5c1c0", "a248ffcb-3dab-4c0a-b5f6-4c98859d201c", "a29302a4-a170-4dc0-ac81-eaedfe2cb4c1", "a57ffe4b-6269-4521-80c1-198859880b1f", "b0bcde26-6720-4cb2-8f0b-e91657a66e5e", "b91d1677-3bd8-4ba6-ac48-100a9b0167d5", "ba0ffed5-3044-4547-a891-3891007c44de", "cb3cec59-ff10-4070-bda4-b440614d59b7", "e0438bd7-3d42-4f2f-83a4-f87078b0e2b1", "f423cfc9-ac99-4ccf-a71f-c88e233db726"], "title": "Checking safety properties using compositional reachability analysis", "venue": "ACM Transactions on Software Engineering and Methodology", "year": 1999, "id": "7673f009-bc22-459e-912f-1660406a0d98"}
{"abstract": "This paper presents a unified framework for automatic segmentation of intervertebral disks of scoliotic spines from different types of magnetic resonance (MR) image sequences. The method exploits a combination of statistical and spectral texture features to discriminate closed regions representing intervertebral disks from background in MR images of the spine. Specific texture features are evaluated for three types of MR sequences acquired in the sagittal plane: 2-D spin echo, 3-D multiecho data image combination, and 3-D fast imaging with steady state precession. A total of 22 texture features (18 statistical and 4 spectral) are extracted from every closed region obtained from an automatic segmentation procedure based on the watershed approach. The feature selection step based on principal component analysis and clustering process permit to decide among all the extracted features which ones resulted in the highest rate of good classification. The proposed method is validated using a supervised  k -nearest-neighbor classifier on 505 MR images coming from three different scoliotic patients and three different MR acquisition protocols. Results suggest that the selected texture features and classification can contribute to solve the problem of oversegmentation inherent to existing automatic segmentation methods by successfully discriminating intervertebral disks from the background on MRI of scoliotic spines.", "authors": ["Claudia Chevrefils", "Farida Cheriet", "Carl-Eric Aubin", "Guy Grimard"], "n_citation": 58, "references": ["239b579d-e792-4afd-843f-1a291fad5529", "269cef10-cdcd-4f69-a74e-2f3e8ad8835f", "2716411c-9fb7-4475-b544-28343299d112", "56ba3210-956f-41cf-b87e-a88115b7d40e", "5880d47f-8b99-416d-a743-28d6b49f7ba9", "5fadd790-4d5c-4a63-9d0c-39661713cf69", "69ec922e-1be6-4fa7-a0a4-a718bb568e6e", "76d006d3-1d42-42d9-a532-4a2284fcd462", "7b57db11-7c4d-4d1e-aa62-3a5d7d1f7987", "7fd867ac-75a1-4671-a10a-44ac0bd1bae5", "9cef868f-eb6d-4189-acd1-43eac87cf81e", "a58466ec-6627-4dc0-a285-292265df5d16", "b5b88306-3009-4c58-8612-dfa65c400936", "c24b709d-7a19-4361-8aec-419d1a3073de", "c58344ad-c6d5-42e8-b201-01c9ed83fd87", "ca577c08-3cb5-4945-98c1-869a268b6f68", "cda11090-a2ca-4523-955b-bccd967cb820", "dc79626b-19b3-4784-a853-1c398f7a7fea", "dca6eb35-0349-44b8-bd5c-e2524dac0e43", "dfb8bf07-b93b-44d1-bd5a-c2329aac465d", "e27dc6d5-97c0-4531-bdf2-2dd7bd4147b9", "e9e95647-0f14-4875-876e-653a09e483b1", "f56c05c5-6a35-46ee-9bde-a2633ae998c5"], "title": "Texture Analysis for Automatic Segmentation of Intervertebral Disks of Scoliotic Spines From MR Images", "venue": "international conference of the ieee engineering in medicine and biology society", "year": 2009, "id": "ea2a6286-6829-4ba7-b9ee-47aec70ab0e6"}
{"abstract": "This paper describes the design and implementation of a multi-cast transport protocol called RMTP. RMTP provides sequenced, lossless delivery of bulk data from one sender to a group of receivers. RMTP achieves reliability by using a packet-based selective repeat retransmission scheme, in which each acknowledgment (ACK) packet carries a sequence number and a bitmap. ACK handling is based on a multi-level hierarchical approach, in which the receivers are grouped into a hierarchy of local regions, with a designated receiver (DR) in each local region. Receivers in each local region periodically send ACKs to their corresponding DR, DRs send ACKs to the higher-level DRs, until the DRs in the highest level send ACKs to the sender, thereby avoiding the ACK-implosion problem. DRs cache received data and respond to retransmission requests of the receivers in their corresponding local regions, thereby decreasing end-to-end latency and improving resource usage. This paper also provides the measurements of RMTP's performance with receivers located at various sites in the Internet.", "authors": ["John C. Lin", "Sanjoy Paul"], "n_citation": 863, "references": ["07d17731-0d8d-4b56-a803-48651a8074a8", "0fcb4627-9476-4576-8964-be9a53e6a5dc", "19a6c722-ce16-4044-8469-273c0971ca03", "2915a22c-b1dd-46e9-9082-40793a90abf9", "48ff26df-3f32-43af-af22-2f241d67e480", "4b4c2f4d-3c81-488b-977e-b32c2093ad17", "5f5625dd-fa19-47ee-b5e8-319d570db9fb", "6aae28a7-10b9-45e5-a481-230dd19b73ff", "bbb1a8d5-f078-4b46-a131-48a251dbd5f5", "e2dafd56-ac59-4c48-802f-fc88318f3d76"], "title": "RMTP: a reliable multicast transport protocol", "venue": "international conference on computer communications", "year": 1996, "id": "d563bff2-b63b-470e-a53f-567f8927dbf4"}
{"abstract": "We apply the recently introduced method of stochastic extremum seeking to navigate a nonholonomic unicycle towards the maximum of an unknown, spatially distributed signal field, using only the measurement of the signal at the vehicle's location but without the measurement of the vehicle's position. Keeping the forward velocity constant and controlling only the angular velocity, we design a stochastic source seeking control law which employs excitation based on filtered white noise, rather than sinusoidal perturbations used in the existing work. We study stability with the help of stochastic averaging theorems that we recently developed for general nonlinear continuous-time systems with stochastic perturbations. We prove local exponential convergence, both almost surely and in probability, to a small neighborhood near the source. We characterize the convergence speed explicitly and provide design guidelines for maximizing it, as well as for minimizing the residual set near the source. We present a detailed simulation study, including a study of the effect of saturation on the steering input.", "authors": ["Shu-Jun Liu", "Miroslav Krstic"], "n_citation": 27, "references": ["0526a00d-8283-4dc7-a150-041e4f55261d", "163a8d04-4000-4c2f-8af5-40dff38574cc", "52634177-0b8a-4850-9399-88db99bb758f", "6c19dca0-60d8-4c1b-80e4-484ff2b1cd66", "7ce12951-ee83-4fea-9bc6-2759d64c09d0", "7f0596b7-5d66-4a45-adb7-96a6fa40ba57", "ad7d70bd-c9f3-4a36-94e8-3c2eb8089e4e", "e66d73b0-abb9-4693-864e-faec07c69738"], "title": "Brief paper: Stochastic source seeking for nonholonomic unicycle", "venue": "Automatica", "year": 2010, "id": "43855ebb-3eca-4e1c-9130-0ba29a2a4f97"}
{"abstract": "Present day parallel computers often face the problems of large software overheads for process switching and inter-processor communication. These problems are addressed by the Multi-Threaded Architecture (MTA), a multiprocessor model designed for efficient parallel execution of both numerical and non-numerical programs. We begin with a conventional processor, and add the minimal external hardware necessary for efficient support of multithreaded programs. The article begins with the top-level architecture and the program execution model. The latter includes a description of activation frames and thread synchronization. This is followed by a detailed presentation of the processor. Major features of the MTA include the Register-Use Cache for exploiting temporal locality in multiple register set microprocessors, support for programs requiring non-determinism and speculation, and local function invocations which can utilize registers for parameter passing. >", "authors": ["Herbert H. J. Hum", "Kevin B. Theobald", "Guang R. Gao"], "n_citation": 77, "references": ["20ec9c4d-c7ab-40ef-beac-47f6da764370", "38bc2646-a363-4160-84a2-e3fdc02ed96d", "5290691a-3b5b-4d31-add2-ad1a0c24c9ba", "5c5683bc-24b5-4237-986f-e366237d195f", "5cad5981-ccd7-4378-84dd-638538fad0f0", "80fdc9f5-b7a0-49cb-96ee-8fe162b6266a", "e3cdee6a-b72e-4d63-85c5-6754711be9a8"], "title": "Building multithreaded architectures with off-the-shelf microprocessors", "venue": "", "year": 1994, "id": "2d637e2e-65ad-4254-942a-b940da7097ec"}
{"authors": ["Steven J. Gortler", "Radek Grzeszczuk", "Richard Szeliski", "Michael F. Cohen"], "n_citation": 2824, "references": ["0464a53b-0d19-4bf7-9a94-307ce93105f4", "09410999-540a-409b-870c-d355c08e3619", "1d42c285-4fd6-4f55-9189-7c04d67b87ff", "28b8d07b-a802-4e3a-9dfb-2735d0ef7dfb", "33fe8461-d465-4487-b9fa-8270a2d5865f", "477909c4-4d70-4a7d-a156-4fab18ed1434", "4f42563c-a762-4eff-a4b9-303a5ab3e1b7", "60985c9a-ca14-4324-882d-95cedabefdeb", "936e0ae4-e6e1-4b3b-9d0a-a6bff589fc7b", "980ffb49-b842-439d-b309-6f8ee5e10b83", "9d96d55b-65a1-4872-9960-994fe14fd0e4", "a0860462-7103-4b99-9b66-2bb0fd0ef877", "c05717ef-0cd5-4f66-b355-c27cc584c286", "c0ba5d0d-89e3-4274-be9f-e59ad601f0e5", "c18f4630-af32-42b6-aa66-810d275b2981", "c3ec3b14-75be-4b18-af66-195537226585", "dfe377d1-9e27-4538-a69f-a802ead9f650"], "title": "The lumigraph", "venue": "international conference on computer graphics and interactive techniques", "year": 1996, "id": "87a3e0c6-9219-41ee-8638-ea7a86fb8ef3"}
{"abstract": "Most empirical studies about Open Source (OS) projects or products are vertical and usually deal with the flagship, successful projects. There is a substantial lack of horizontal studies to shed light on the whole population of projects, including failures. This paper presents a horizontal study aimed at characterizing OS projects. We analyze a sample of around 400 projects from a popular OS project repository. Each project is characterized by a number of attributes. We analyze these attributes statically and over time. The main results show that few projects are capable of attracting a meaningful community of developers. The majority of projects is made by few (in many cases one) person with a very slow pace of evolution.", "authors": ["Andrea Capiluppi", "Patricia Lago", "Maurizio Morisio"], "n_citation": 121, "references": ["2710ef00-fe7b-4518-a978-a064fe559cc5", "5821b7ac-4676-45fb-aff8-e9ff3e295f60", "aec3b978-3a42-4ba7-9b05-9fbeefbdfea8"], "title": "Characteristics of open source projects", "venue": "conference on software maintenance and reengineering", "year": 2003, "id": "77102f1e-9709-4c3d-a367-b1aa8aa2b085"}
{"abstract": "Abstract. Case adaptation, a central component of case-based reasoning, is often considered to be the most difficult part of a case-based reasoning system. The difficulties arise from the fact that adaptation often does not converge, especially if it is not done in asystematic way. This problem, sometimes termed the assimilation problem, is especially pronounced in the case-based designproblem solving domain where a large set of constraints and features are processed. Furthermore, in the design domain, multiplecases must be considered in conjunction in order to solve the new problem, resulting in the difficulty of how to efficiently co mbine thecases into a global solution for the new problem.In order to achieve case combination, we investigate a methodology which formalizes the process using constraintsatisfaction techniques. We represent each case as a primitive constraint satisfaction problem (CSP) with additional knowledge thatfacilitates retrieving, and apply an existing repair-based CSP algorithm to combine these primitive CSPs into a globally consistentsolution for the new problem. The run time is satisfactory for providing a quick and explicable answer to whether existing cases canbe adapted or if new cases would have to be created.We have tested our methodology in the configuration design and assembly sequence generation domains. Analysis ofperformance and results will be shown at the end of this paper.", "authors": ["Lisa S. Purvis", "Pearl Pu"], "n_citation": 90, "references": ["0e5a7cf0-701d-4acc-90f8-c9a9aabf1d2e", "4d31272e-5316-4b63-86eb-ce2c6049e4bc", "4e87e421-0bc9-433a-a403-eafc2b946e25", "5af8fa76-0083-4252-a8f1-f86125358010", "6f43812e-d464-4ecf-9599-64f86347feb3", "797343b9-4eea-4172-98e7-62a6c3537032", "8026ab23-489b-407b-922c-ab0faf92670b", "91d11947-e646-4222-9df4-c32b9d82b94f"], "title": "Adaptation Using Constraint Satisfaction Techniques", "venue": "international conference on case-based reasoning", "year": 1995, "id": "5cdf38d4-54dd-4940-9eb7-65775852e353"}
{"abstract": "Daikon is an implementation of dynamic detection of likely invariants; that is, the Daikon invariant detector reports likely program invariants. An invariant is a property that holds at a certain point or points in a program; these are often used in assert statements, documentation, and formal specifications. Examples include being constant (x=a), non-zero (x 0), being in a range (a@?x@?b), linear relationships (y=ax+b), ordering (x@?y), functions from a library (x=fn(y)), containment (x@?y), sortedness (xissorted), and many more. Users can extend Daikon to check for additional invariants. Dynamic invariant detection runs a program, observes the values that the program computes, and then reports properties that were true over the observed executions. Dynamic invariant detection is a machine learning technique that can be applied to arbitrary data. Daikon can detect invariants in C, C++, Java, and Perl programs, and in record-structured data sources; it is easy to extend Daikon to other applications. Invariants can be useful in program understanding and a host of other applications. Daikon's output has been used for generating test cases, predicting incompatibilities in component integration, automating theorem proving, repairing inconsistent data structures, and checking the validity of data streams, among other tasks. Daikon is freely available in source and binary form, along with extensive documentation, at http://pag.csail.mit.edu/daikon/.", "authors": ["Michael D. Ernst", "Jeff H. Perkins", "Philip J. Guo", "Stephen McCamant", "Carlos Pacheco", "Matthew S. Tschantz", "Chen Xiao"], "n_citation": 883, "references": ["029ec76f-4b8c-476a-8c77-3036d6b7b1f6", "0c808493-43c5-4199-9ae3-aaad17862955", "19cc1dca-7b33-4c22-8f90-306ce3781da2", "1b24a9fa-822b-4102-beb7-935bc1f9601c", "1f93ce29-5b9b-4d4e-9b51-457cb54349e1", "2268d4cf-b284-4e25-9a80-b92dc52daa19", "289715ea-8659-42d2-9c8d-b97e683beb2b", "34211840-59b8-4e4d-b2dc-40498dd821e2", "37ae9429-1bd8-4d66-8266-1360f2ec12c9", "37fb5f31-8fe4-497b-8316-f1a1d082234c", "39dace2f-4805-485b-918e-ec1bfc813faf", "3ad0693d-69cc-415a-81ae-283d89696a63", "3edb6562-76dd-47be-923e-7a88c3715041", "4051711f-8e85-4f3f-b0ba-5841e30a724f", "418681e8-3484-4954-84e7-ef0cb10542aa", "457a887b-0ff6-48f4-9413-c7785080fe86", "475bae33-d3a5-4041-a49f-3d85b6c1a3c1", "50303516-dc41-41d9-992b-ab288fecf300", "54fe2662-f4fe-4b27-903b-c9c84b1dc732", "70838b11-9aa9-41c0-bb4f-a9b2750138d3", "77de4794-bac0-414c-851b-42516c49804f", "795b3c5c-deeb-4281-b4de-d0f1b2d8478d", "7c6de665-9856-4ffa-8036-f00c766dd2fb", "7d2e962b-4abd-4b03-8082-33e4012db973", "8382fbf0-2a6b-4365-9d32-7d94fe7c0ab6", "8dbcce9e-fef4-4f1e-a64b-3b9de65f676d", "a37bac2e-5ffb-4607-b163-c26d23d30af6", "ab4562e5-00cf-4372-8992-5e276613fcbb", "abed179f-56b3-4cc6-975d-7177f879b97e", "b247346e-2469-42cc-bed9-e7a347e8b188", "b5908c84-39c7-45ce-8814-fb55e244b13e", "c4c36c4e-ece8-4f0c-9b12-cf2a0e40af42", "c7dda81c-0759-4906-9b8c-dc02aafacb05", "c9ff1f61-bd9c-46bb-84f0-158dd2ae17c8", "ce426213-60a4-44e1-8bab-9f2a5e412816", "d7f81437-caf4-4797-91ff-0391372af056", "f269abe9-56d9-406e-aa7e-12764edc3429"], "title": "The Daikon system for dynamic detection of likely invariants", "venue": "Science of Computer Programming", "year": 2007, "id": "331f9085-a480-4c61-a89b-37b94119cbca"}
{"abstract": "A description is given of an interface that was developed between Loops and Xerox Quintus Prolog. Loops is an extension to the Xerox AI environment to support object-oriented programming; Xerox Quintus Prolog is a version of Prolog that runs on Xerox Lisp machines. Such a bridge enables all the support tools of both environments to be accessed, and degradation of performance that occurs when one language is implemented top of another is avoided. The interface has three layers. At the lowest level, a set of Prolog predicates gives the Prolog programmer access to Loops objects. This lowest level is the bridge from Prolog to Loops. At the next level, programming tools in the Loops environment let object methods be defined in Prolog. At the highest level, the Prolog programmer can treat Prolog clauses as Loops objects that can be manipulated outside the Prolog database. Each layer can be used independently. >", "authors": ["Timothy Koschmann", "Martha W. Evens"], "n_citation": 50, "references": ["41532bf0-2af7-4ca0-b528-3888dbca8a16", "4bd8b61c-8a7b-4b7d-98e5-8d0ae123bbe6", "53cc6211-e3bd-4143-9ee7-e6a98d5f657d", "bbc9ca28-0988-4941-bf0d-bda548b7d661", "e3ba6428-74ba-41c2-9bd7-148a2c6308a8"], "title": "Bridging the gap between object-oriented and logic programming", "venue": "IEEE Software", "year": 1988, "id": "5ec72adf-0ba8-484a-b7c0-f696bde8e99a"}
{"abstract": "Short Messaging Service (SMS) texts behave quite differently from normal written texts and have some very special phenomena. To translate SMS texts, traditional approaches model such irregularities directly in Machine Translation (MT). However, such approaches suffer from customization problem as tremendous effort is required to adapt the language model of the existing translation system to handle SMS text style. We offer an alternative approach to resolve such irregularities by normalizing SMS texts before MT. In this paper, we view the task of SMS normalization as a translation problem from the SMS language to the English language and we propose to adapt a phrase-based statistical MT model for the task. Evaluation by 5-fold cross validation on a parallel SMS normalized corpus of 5000 sentences shows that our method can achieve 0.80702 in BLEU score against the baseline BLEU score 0.6958. Another experiment of translating SMS texts from English to Chinese on a separate SMS text corpus shows that, using SMS normalization as MT preprocessing can largely boost SMS translation performance from 0.1926 to 0.3770 in BLEU score.", "authors": ["Aiti Aw", "Min Zhang", "Juan Xiao", "Jian Su"], "n_citation": 210, "references": ["10b46196-2b40-45f6-8c27-89ac24eec0ac", "1268112c-a3a5-411d-9469-c9937aed533e", "2683cee5-d0a7-4cbd-ba98-6144360bab31", "4e1c8814-d64a-45b5-88cb-6581dd336cf3", "4eec767c-9f1d-49e4-a329-8f8c57a1421a", "5443ee2f-a083-4829-bfd3-b92e50b6d78e", "7be6da3b-c134-4802-8e5a-f39b8533b13c", "97eb89c9-d277-4e51-8586-71aa56c0e199", "a2530144-b6fd-4659-84f5-73a470275dd4", "b6f96238-c356-49c9-9638-53e39931954c", "c1c634fa-13aa-4e6e-8273-f1365b43b246", "c8323642-f362-4ef3-bcc6-7ed07536c658", "e4a51ce7-71d6-4872-b0a9-17d98524f12d"], "title": "A Phrase-Based Statistical Model for SMS Text Normalization", "venue": "meeting of the association for computational linguistics", "year": 2006, "id": "e41838f7-2a29-4bab-b68a-8eb1c0b5fa85"}
{"authors": ["Frank Dachille", "Kevin Kreeger", "Baoquan Chen", "Ingmar Bitter", "Arie E. Kaufman"], "n_citation": 116, "references": ["26162728-24a2-4d03-bb17-871f59a2e39c", "367467a0-5255-4c3b-ac23-e59d91104597", "61546d36-c2fa-450d-b51f-f062ede622f2", "882f8af2-571c-4b0a-b1aa-cb14cc19ef71", "c04deaa4-23f7-445c-955e-75ef866ef974", "c1c20278-a041-49fd-b43b-e8ff638730bf", "e922d9c9-0120-4c46-bac7-a8e5387378d3"], "title": "High-quality volume rendering using texture mapping hardware", "venue": "international conference on computer graphics and interactive techniques", "year": 1998, "id": "0c90a100-aa53-4f75-bbbd-d6e4eb18da63"}
{"abstract": "The Stewart platform is a fully parallel, six-degree-of-freedom manipulator mechanism. Although its inverse kinematics have been extensively studied, no solutions to the direct position kinematics problem have been previously presented in the literature. A solution of the direct kinematics problem of the case in which the six limbs form three concurrent pairs at either the base or the hand member is presented. Even though it is not the most general possible configuration, this case does include many arrangements that have been used in practical robot mechanisms. >", "authors": ["Prabjot Nanua", "Kenneth J. Waldron", "Vasudeva N. R. Murthy"], "n_citation": 411, "references": ["7061c3ce-ca67-4d4f-bdbc-c576634cf173"], "title": "Direct kinematic solution of a Stewart platform", "venue": "international conference on robotics and automation", "year": 1989, "id": "d57ba756-60a8-4d02-b453-bf09a1e31c95"}
{"abstract": "The problem of analyzing the finite time behavior of learning automata is considered. This problem involves the finite time analysis of the learning algorithm used by the learning automaton and is important in determining the rate of convergence of the automaton. In this paper, a general framework for analyzing the finite time behavior of the automaton learning algorithms is proposed. Using this framework, the finite time analysis of the Pursuit Algorithm is presented. We have considered both continuous and discretized forms of the pursuit algorithm. Based on the results of the analysis, we compare the rates of convergence of these two versions of the pursuit algorithm. At the end of the paper, we also compare our framework with that of Probably Approximately Correct (PAC) learning.", "authors": ["Kanagasabai Rajaraman", "P. S. Sastry"], "n_citation": 53, "references": ["3b2d19a3-29b8-4983-832a-08e489f13f38", "749cefe5-bcab-4f6c-aa62-c3001664c53a", "74c5113b-fb1f-4a45-83ad-6fe48abf270b", "82ececf6-4238-4036-a030-1f1be454bb7e", "adf48707-bbcc-4e84-a227-19bda4f4be0b", "c61bad33-aa9f-4a6e-ab8b-8e7eaa835492", "d8dc4aaa-7cab-4b69-a552-df5177d59b86"], "title": "Finite time analysis of the pursuit algorithm for learning automata", "venue": "systems man and cybernetics", "year": 1996, "id": "a97e7704-edd5-42cf-bd5f-6dcce2fd221e"}
{"authors": ["Michel Raynal", "G\u00e9rard Thia-Kime", "Mustaque Ahamad"], "n_citation": 8, "title": "From serializable to causal transactions (abstract)", "venue": "principles of distributed computing", "year": 1996, "id": "a35b40fc-dd8f-4109-8f43-ac79ed348e46"}
{"abstract": "Logical models of arguement formalize commonsense reasoning while taking process and computation seriously. This survey discusses the main ideas that characterize different logical models of argument. It presents the formal features of a few features of a few main approaches to the modeling of argumentation. We trace the evolution of argumentation from the mid-1980s, when argument systems emerged as an alternative to nonmonotonic formalisms based on classical logic, to the present, as argument in embedded in different complex systems for real-world applications, and allow more formal work to be done in different areas, such as AI and Law, case-based reasoning and negotiation among intelligent agents.", "authors": ["Carlos Iv\u00e1n Ches\u00f1evar", "Ana Gabriela Maguitman", "Ronald Prescott Loui"], "n_citation": 585, "references": ["05f59ebe-6fcf-435e-ad81-a13583c94c23", "158004d7-02a1-4302-9f36-7d79090d585b", "1c7ddbd7-046a-4333-aa6b-c4ce698d6fad", "221e5513-fdda-4ad2-8162-9e637efe013d", "2722f893-26be-4101-bd09-4794a956b7fc", "2da2445c-da6e-4a0a-83b9-d857e06dc853", "3067be8c-d0fa-4073-af12-577252ff94ca", "3b1891e6-66df-4c01-bd68-e86f316dded1", "3c22bf30-dd77-4959-bbb4-71557217f0dd", "3f76eb00-3cb3-4e78-9c01-f7c56ebe309f", "4062fafd-7b5e-4c5c-8e81-8ff891ac334f", "43c7e806-433f-4400-917e-d2be93422dab", "4781f1fe-b29f-4b02-adb5-78f0a72aa706", "49595ef9-ed4e-464a-bb94-bac3535c0930", "49d36df4-8612-4a4f-9de0-0d80644f839f", "4ae56c7d-111d-4872-86a8-5575aa1e1ee1", "4c46eb3b-e225-4068-bc54-c38ad61566bf", "4c675fc8-2244-42f0-91c3-eaba4b1537a5", "4d4b75e8-7dc7-4a86-b154-72a298372346", "4e215ae0-e4f9-4dda-a6c7-7fc40dbe44c6", "5066b9c2-8ae8-4b48-ba97-82c8b33a47fd", "50b0cee5-bd31-4616-891f-f79eb4e36974", "5a8fd323-18d6-404d-a25b-b08be87608cc", "68ca1795-045f-4ec2-9969-656643b92631", "69bfc62f-95f8-4eb2-a3f6-6abb68827acd", "6dcf9f47-7a83-40b6-890b-9f6bc8585986", "6e653774-6adb-49d7-bd59-b99e767bdf0a", "72a8b9eb-48d4-4328-99a8-7466d53f11ff", "7466bd88-1c73-4d94-8051-7986604b3b4a", "7575e8e6-7ac3-4bb9-b586-ee51e8a8f1da", "765a0f61-207a-4a20-9cd4-87c1eb69cb3f", "78ceaf4a-8ebb-4f2e-b557-0fa445232572", "79582d48-afa4-4e14-8848-c3892affe0eb", "7985dd47-c73e-443c-9ec7-36464b102dfb", "7ebf91fd-636d-445e-9921-5412f008da5f", "82abd140-4f16-48ba-8d35-0bbcdbd20141", "83820e31-c639-4969-a234-c2c621252898", "85d8f133-83a3-4d3a-91fa-b871bae53bf5", "8b645983-91ea-4e6d-8fb1-a339490d5737", "8c13c79a-0599-49f3-b093-9b732a9d2ea4", "8cd13325-7a61-4eb3-8abf-2be0a7f33d4a", "9261190c-f008-4c45-bd83-969376878024", "92df1f3d-9fb4-49a3-a059-1c95d46285c0", "9683ce5e-7e19-44b6-87d9-2ad39f62da32", "97949e7d-2ace-4d79-83fb-96690446ed29", "99b6af35-3d37-49bf-8cec-dd7f8d9ec37e", "a029db6e-97f3-49dc-9525-d0dc88da20bf", "a183fdcd-e68d-4afd-9cac-090b93667ef2", "a3c72933-e4b2-45f4-bc5c-1a4fdd30e780", "a4e95242-d73f-4366-a6e6-e2c348510b3e", "a709948e-81bc-4462-8acc-71ee5fb0a23b", "aea22ff4-3eee-4f0f-a7ef-618802c6f140", "b3a6f742-8207-4274-b7d6-cdbefa3e8938", "b6d5c627-e121-40ac-a850-e4c466916b55", "b9a980ee-5f63-498e-a33e-2923f7efcd41", "c26141e5-8499-4667-b15d-d68cd15f33a7", "c9551bfc-0372-4b91-8d57-02428b09afae", "c9e8d201-dd9d-4625-9d2c-c366c2413670", "cd9f471a-1700-49ef-83ee-3dda08ef6409", "d758d298-bce7-4dcf-89de-f4d1affdb038", "de600b58-6fcc-4de9-a24d-8c12896d72cb", "e210c134-962d-4aa3-a89b-14971e2f5400", "e2c4008f-05e1-4612-9f16-ec945902b411", "e5b21e06-eeb6-48d3-9c9d-cbecb118b5f6", "e98d6d1a-7800-4637-9651-88e8fe8a221b", "eb5aa983-ce6e-46da-9305-24defaaa584f", "ed472c0f-6306-4e73-b08c-4e299fda29ba", "f0fd0380-27ee-446e-a753-0effe106b6ff", "f5ac9450-c889-4973-93b7-665fc6902c51", "f77839ad-f2b4-4e46-a4bd-930c5780f9cb", "f82a6e8a-dd5f-4c72-b4a0-30f985b696b0", "fbc907ca-dab3-4a31-aef5-85cba1ff2a78", "fc594c69-2fb0-4c1b-8abf-268d4f30a774", "ffff9199-31cc-429b-a545-341c9cbb06e5"], "title": "Logical models of argument", "venue": "ACM Computing Surveys", "year": 2000, "id": "a812a62d-305d-485d-b2d0-99da602cb219"}
{"abstract": "Planning -- the ability to synthesize a course of action to achieve desired goals -- is an important part of intelligent agency and has thus received significant attention within AI for more than 30 years. Work on efficient planning algorithms still continues to be a hot topic for research in AI and has led to several exciting developments i the past few years. This article provides a tutorial introduction to all the algorithms and approaches to the planning problem in AI. To fulfill this ambitious objective, I introduce a generalized approach to plan synthesis called refinement planning and show that in its various guises, refinement planning subsumes most of the algorithms that have been, or are being, developed. It is hoped that this unifying overview provides the reader with a brand-name-free appreciation of the essential issues in planning.", "authors": ["Subbarao Kambhampati"], "n_citation": 121, "references": ["17d1ecd0-224c-484d-b35c-0d6d13e89558", "1d33b519-5dbe-4470-97b2-3ebf959be3e8", "1f211ea3-fe83-401a-b7ee-59295a821516", "275c9a63-84cc-44ed-8c94-b7d8c20bcbc3", "2a533123-954f-4694-b6e1-b471aa56e82e", "2c4cabe3-a106-4d89-a833-9aff653bb7da", "387395e6-6712-4dda-9cb7-cf0fd7de42c7", "4ed1c33d-41f8-462f-a9a2-4be69173c630", "4fdf83e0-147b-46ce-882a-64d65dcbf5cf", "507e9c8b-fea4-4186-b16d-a75a65f6a839", "58d623bf-03fe-4423-a7b2-85b8810ac3bf", "5bc18095-8d4c-40b1-91d1-f2f07db8e1b9", "644ef4f7-909a-49ee-9985-1998da69f47d", "68ea04b5-df82-4bc7-a1fb-1268072f4983", "6ce0e611-ebf7-46d6-8bc6-a9c7b6207e02", "7190e3c3-335e-4baa-b05f-e7174ed41c24", "735f3386-89eb-4c6d-8ff9-d1f08acff358", "7522d698-de11-4bf0-99a7-2fe0f6ea3006", "78177b8f-531b-40f0-8656-9ea74ec3e0d5", "7e19e909-4aa6-4177-914a-62ac699ad5d7", "7f6cdf52-3649-4aa1-b659-cd38115f9327", "8685a1b6-28de-4da5-8d98-1aafc4c1be04", "b196e60f-59e6-4733-acc0-bbbb191e6f8f", "b6fd16e1-15d3-4c18-80cb-17f59af51c20", "b7645583-7064-4940-8769-8d395a4f1710", "bdd72f1c-6df6-4069-bb3a-40a82dfc9065", "bf717395-74d1-424d-8f33-b0cba4ecc5c8", "c6ff0ff3-54ee-44b2-9eba-165cb58b58bc", "cf7f48dd-fc88-4f47-8f8e-f7b24e5de011", "de785736-6f18-4b87-8748-cc4a14073b2e", "e01f13a8-6162-4b5a-9e2c-3380dde6f2a7", "e5d0eb15-1678-4ea0-8fb3-51d647926e86", "f01c2813-d7ba-413e-ab79-f613842e71ac", "fa8a15e7-0e24-4022-9e5b-0b1f1c2906b8"], "title": "Refinement Planning as a Unifying Framework for Plan Synthesis", "venue": "Ai Magazine", "year": 1997, "id": "3027d10a-43e6-41da-ae20-98a6cb31304d"}
{"abstract": "The increasing performance and decreasing cost of processors and memory are causing system intelligence to move into peripherals from the CPU. Storage system designers are using this trend toward \u201cexcess\u201d compute power to perform more complex processing and optimizations inside storage devices. To date, such optimizations have been at relatively low levels of the storage protocol. At the same time, trends in storage density, mechanics, and electronics are eliminating the bottleneck in moving data off the media and putting pressure on interconnects and host processors to move data more efficiently. We propose a system called Active Disks that takes advantage of processing power on individual disk drives to run application-level code. Moving portions of an application\u2019s processing to execute directly at disk drives can dramatically reduce data traffic and take advantage of the storage parallelism already present in large systems today. We discuss several types of applications that would benefit from this capability with a focus on the areas of database, data mining, and multimedia. We develop an analytical model of the speedups possible for scan-intensive applications in an Active Disk system. We also experiment with a prototype Active Disk system using relatively low-powered processors in comparison to a database server system with a single, fast processor. Our experiments validate the intuition in our model and demonstrate speedups of 2x on 10 disks across four scan-based applications. The model promises linear speedups in disk arrays of hundreds of disks, provided the application data is large enough.", "authors": ["Erik Riedel", "Garth A. Gibson", "Christos Faloutsos"], "n_citation": 331, "references": ["0b8a2709-0063-4669-9f4b-0ddc97727562", "17f01f85-4909-41b7-bafd-88939c01894a", "1c7f6b4c-ea89-45d4-9778-8d64987f8a0f", "1d2b6cc7-fbd4-49e6-ad99-1fcaceb08edc", "1ffdf021-837a-40d0-89ce-72e57bd15de9", "2270949d-bc75-46d7-ab80-c266284070b4", "267324b4-a8ec-4524-ac2d-0d4fb35abfec", "34b7e270-80d7-46d5-a6f1-e50087a8d045", "37c8e2c4-de56-46ee-8413-659871cc852e", "40fbb7d2-8060-4a9b-be69-1b168c3e2fba", "5461e296-2bd8-4067-a61b-84baeae311e9", "5e8178df-9d85-4d22-bc83-860479038fdc", "707fdea7-fc59-4279-89af-6ae91e683358", "78a9d157-caa2-4792-9638-897c79c84bb5", "7f1dc63a-9064-4768-a30d-3383d52aa81e", "84b09d58-e211-4841-bafb-f19103f6781f", "8ce5aa42-c9f7-4e6b-87cd-a4f2e13b4aa8", "aa12afb7-9962-4b3b-8aaa-143429c3c6c6", "b2bd6d48-1840-4b7b-bb0e-387b315ae3ac", "b826aeb6-49f6-42a8-878b-4b45d69c9fbb", "b87860ce-71bf-4dea-a751-180eb22a8ff4", "c2159da2-ea97-4512-ab11-8021d1bc8af4", "caedea34-0d62-4fde-81e0-bf28bb00172c", "d2976d92-ae9e-403c-8e0b-ff7056a86eaf", "dfe956b4-b304-497f-8db3-40b2b990282e", "e7021ddd-fd9a-4910-8444-c210d7f29a61", "e883ae1e-0c54-4fcb-9c38-4165bb0fcc7a", "ea6cac6a-5df3-4d2c-b31d-d790b1370c73", "ec155938-7533-4af0-beef-14baf20052ac", "fbdedd40-b9f0-4d4f-9c44-a4f592d11342"], "title": "Active Storage for Large-Scale Data Mining and Multimedia", "venue": "very large data bases", "year": 1998, "id": "1105d54e-7412-4028-a815-2d4b0c355ed3"}
{"abstract": "Goguen categories were introduced as a suitable calculus for L-fuzzy relations, i.e., for relations taking values from an arbitrary complete Brouwerian lattice L instead of the unit interval [0, 1] of the real numbers. Such a category may provide some relational constructions as products, sums or subobjects. The aim of this paper is to show that under an assumption on the lattice L one may require without loss of generality that the related relations are crisp, i.e., all entries are either the least element 0 or the greatest element 1 of L.", "authors": ["Michael Winter"], "n_citation": 10, "references": ["d9c82775-d390-453d-94ab-ffabeb365edc", "ff8fed48-56be-4383-b40f-58b032178b26"], "title": "Relational Constructions in Goguen Categories", "venue": "", "year": 2001, "id": "45a3b849-4bdb-4e1c-945a-8d4b7fcd743d"}
{"abstract": "The application range of UAVs (unmanned aerial vehicles) is expanding along with performance upgrades. Vertical take-off and landing (VTOL) aircraft has the merits of both fixed-wing and rotary-wing aircraft. Tail-sitting is the simplest way for the VTOL maneuver since it does not need extra actuators. However, conventional hovering control for a tail-sitter UAV is not robust enough against large disturbance such as a blast of wind, a bird strike, and so on. It is experimentally observed that the conventional quaternion feedback hovering control often fails to keep stability when the control compensates large attitude errors. This paper proposes a novel hovering control strategy for a tail-sitter VTOL UAV that increases stability against large disturbance. In order to verify the proposed hovering control strategy, simulations and experiments on hovering of the UAV are performed giving large attitude errors. The results show that the proposed control strategy successfully compensates initial large attitude errors keeping stability, while the conventional quaternion feedback controller fails.", "authors": ["Takaaki Matsumoto", "Koichi Kita", "Ren Suzuki", "Atsushi Oosedo", "Kenta Go", "Yuta Hoshino", "Atsushi Konno", "Masaru Uchiyama"], "n_citation": 12, "references": ["41e6008d-fe84-484c-82ed-d00324cc4e75", "cdd498ca-175f-4d50-af66-33befe239cd5", "f6614ed6-36f7-446e-a8d4-5b70de52f8ac"], "title": "A hovering control strategy for a tail-sitter VTOL UAV that increases stability against large disturbance", "venue": "international conference on robotics and automation", "year": 2010, "id": "1279aaab-9b18-45b9-95fa-644736be3949"}
{"abstract": "This paper presents a class of minimum mean-square error (MMSE) estimators for enhancing short-time spectral coefficients of a noisy speech signal. In contrast to most of the presently used methods, we do not assume that the spectral coefficients of the noise or of the clean speech signal obey a (complex) Gaussian probability density. We derive analytical solutions to the problem of estimating discrete Fourier transform (DFT) coefficients in the MMSE sense when the prior probability density function of the clean speech DFT coefficients can be modeled by a complex Laplace or by a complex bilateral Gamma density. The probability density function of the noise DFT coefficients may be modeled either by a complex Gaussian or by a complex Laplacian density. Compared to algorithms based on the Gaussian assumption, such as the Wiener filter or the Ephraim and Malah (1984) MMSE short-time spectral amplitude estimator, the estimators based on these supergaussian densities deliver an improved signal-to-noise ratio.", "authors": ["Rainer Martin"], "n_citation": 117, "references": ["181e4698-bd6f-4361-8e24-6edb9bf213c1", "1daa6c20-91bf-482d-a4c5-1b8efa91cdb0", "29e12728-acc8-43e1-bb49-19fa98023326", "57c7271a-495a-4c59-8307-0f4e63fddaa6", "a38001c2-4cd8-4222-bb92-905f8fdaafb9", "b0866ed2-2d6f-4303-8be1-7968421a8ca6", "c0e172bf-7f26-46e3-815c-7aab73f80c19", "c292e047-4deb-4575-ba0a-fe51c8799393", "d0cdae49-bd69-4558-8d98-bc9701f3c9bd", "d16486c0-59a4-457e-ac10-48d73d0c1f26", "d1a6f7e2-0f37-4721-8903-067b9969e133"], "title": "Speech enhancement based on minimum mean-square error estimation and supergaussian priors", "venue": "IEEE Transactions on Speech and Audio Processing", "year": 2005, "id": "ac91d9ea-4079-4722-aeeb-70d18cb6b9cf"}
{"abstract": "We discuss the design of an object-oriented database extension to Trellis/Owl, a strongly-typed object-oriented programming language developed at Digital. We use the abstract data typing mechanisms of Trellis/Owl to provide a database collection type which enables programs to share objects in a distributed workstation environment. The database is an object repository which enables Trellis/Owl programs to coordinate the sharing of persistent objects. The object-oriented database is not intended for conventional database applications such as online transaction processing, but rather for applications which have complex data structuring requirements, and which access relatively \u201clarge\u201d objects over \u201clong\u201d periods of time.", "authors": ["Patrick Karl O'Brien", "Bruce Bullis", "Craig Schaffert"], "n_citation": 48, "title": "Persistent and shared objects in Trellis/Owl", "venue": "", "year": 1986, "id": "e8f886f7-8947-4d06-aacb-e38b88a6bd15"}
{"authors": ["Jean -Claude Fernandez", "Claude Jard", "Thierry J\u00e9ron", "C\u00e9sar Viho"], "n_citation": 263, "references": ["32cc28b7-9c8b-4226-83e5-eea55fba7ad5", "4a47b889-325b-4f02-82cb-92c204edf81e", "5b9a938d-ba70-4a5b-a1dc-09086d96f8a3", "5fd2c45b-9be0-4805-a635-c23a04cf1f66"], "title": "Using On-The-Fly Verification Techniques for the Generation of test Suites", "venue": "computer aided verification", "year": 1996, "id": "3da02d67-05a7-4df5-99a2-50186cd29fa9"}
{"abstract": "Changes in a dynamical process are often detected by monitoring selected indicators directly obtained from the process observations, such as the mean values or variances. Standard change detection algorithms such as the Shewhart control charts or the cumulative sum (CUSUM) algorithm are often based on such first- and second-order statistics. Much better results can be obtained if the dynamical process is properly modeled, for example by a nonlinear state-space model, and then the accuracy of the model is monitored over time. The success of the latter approach depends largely on the quality of the model. In practical applications like industrial processes, the state variables, dynamics, and observation mapping are rarely known accurately. Learning from data must be used; however, methods for the simultaneous estimation of the state and the unknown nonlinear mappings are very limited. We use a novel method of learning a nonlinear state-space model, the nonlinear dynamical factor analysis (NDFA) algorithm. It takes a set of multivariate observations over time and fits blindly a generative dynamical latent variable model, resembling nonlinear independent component analysis. We compare the performance of the model in process change detection to various traditional methods. It is shown that NDFA outperforms the classical methods by a wide margin in a variety of cases where the underlying process dynamics changes.", "authors": ["Alexander Ilin", "Harri Valpola", "Erkki Oja"], "n_citation": 50, "references": ["3399c14b-637b-4cf4-9caf-3cc4dc6e384d", "4d52662f-0f45-4794-8e46-02b31e8d6cd1", "68b2ca23-0259-4c7e-9b62-1c3a4e8ef62a", "91600a85-3187-4b97-afe2-58fad195ec76", "a24b04bd-66bc-496c-80b0-11e596a50034", "c8a617d5-66fb-4f12-bd3d-cf049da09293", "ccb2942a-f121-4a82-aa23-a3ab0da32e0b", "ecf7b9b6-e8f4-4dcf-a70b-60d71d469e3e", "f3edea9b-3ad4-4586-9d37-010af08128d9", "fb3eeea2-1d83-4e4d-85d0-0c8a283a8ce1"], "title": "Nonlinear dynamical factor analysis for state change detection", "venue": "IEEE Transactions on Neural Networks", "year": 2004, "id": "031d7d5c-3dbc-4478-b9b8-4e4f4275ec09"}
{"abstract": "This paper describes an efficient algorithm to model the light attenuation due to a participating media with low albedo. Here, we consider the light attenuation along a ray, as well as the light attenuation emanating from a surface. The light attenuation is modeled using a splatting volume renderer for both the viewer and the light source. During the rendering, a 2D shadow buffer accumulates the light attenuation. We first summarize the basic shadow algorithm using splatting. Then, an extension of the basic shadow algorithm for projective textured light sources is described. The main part of this paper is an analytic soft shadow algorithm based on convolution techniques. We describe and discuss the soft shadow algorithm, and generate soft shadows, including umbra and penumbra, for extended light sources.", "authors": ["Caixia Zhang", "Roger Crawfis"], "n_citation": 50, "references": ["033a26fc-f399-419f-87ae-72f40cb49306", "0e502062-d733-4105-8837-ef5e6e233f19", "121c6e09-a957-43d5-8931-4091808f2427", "252b1a42-c3d9-4d3b-8de2-77a172889e44", "27716ec0-8d71-4637-82f1-f8353c0b0351", "2f933710-65b2-4abe-8b23-8569644142db", "364cfa04-7e3f-43df-9527-93efcd7e580e", "50a2c839-5d25-4826-a119-6c650bfc4a6b", "53ce4b6a-e36f-496d-a85c-c7d6790077db", "573fd78e-fe31-413b-9de8-b0962f59f0f2", "5cf4a773-96f5-4997-9386-ad096b7d4393", "7669e972-5f5d-4184-be92-e5f1eb00b690", "794095cf-df7a-441b-bfce-e03b52245eaf", "7d9e2f84-5809-4c8d-9b4f-fecf4f3ffef7", "92f35612-97cb-4967-9115-e80270bdd353", "9d9b470d-6d5e-4472-b6bc-6581a1db839f", "a3972e39-534d-4d71-93dd-fab66eb5d56a", "b2c84391-2580-4204-ac94-ea37070ffd9a", "bb46aa6d-570d-4923-9b35-cbc567c9b6f5", "cabe558e-aebb-4eea-b562-d63ad764673c", "d9c4b8df-7ac4-4bfa-a7bd-d0be3b67d59e", "e84f4eda-e104-4844-aaad-190bd35d7696", "ef966b01-6ab2-42c7-9d37-262e62859f9d", "fce1228c-399a-4000-8074-619b80515b51"], "title": "Shadows and soft shadows with participating media using splatting", "venue": "IEEE Transactions on Visualization and Computer Graphics", "year": 2003, "id": "b40f0f5e-95ac-49c4-9291-33cb3d571883"}
{"authors": ["William Leinberger", "Vipin Kumar"], "n_citation": 77, "title": "Information power grid: The new frontier in parallel computing?", "venue": "IEEE Concurrency", "year": 1999, "id": "f03ab657-7b28-4857-b94c-6c195bb4f506"}
{"abstract": "Trends such as the massive increase in information available via electronic networks, the use of on-line product data by distributed concurrent engineering teams, and dynamic supply chain integration for electronic commerce are placing severe burdens on traditional methods of information sharing and retrieval. Sources of information are far too numerous and dynamic to be found via traditional information retrieval methods, and potential consumers are seeing increased need for automatic notification services. Matchmaking is an approach based on emerging information integration technologies whereby potential producers and consumers of information send messages describing their information capabilities and needs. These descriptions, represented in rich, machine-interpretable description languages, are unified by the matchmaker to identify potential matches. Based on the matches, a variety of information brokering services are performed. We introduce matchmaking, and argue that it permits large numbers of dynamic consumers and providers, operating on rapidly-changing data, to share information more effectively than via traditional methods. Two matchmakers are described, the SHADE matchmaker, which operates over logic-based and structured text languages, and the COINS matchmaker, which operates over free text. These matchmakers have been used for a variety of applications, most significantly, in the domains of engieeering and electronic commerce. We describe our experiences with the SHADE and COINS matchmaker, and we outline the major observed benefits and problems of matchmaking.", "authors": ["Daniel R. Kuokka", "Larry Harada"], "n_citation": 87, "references": ["9bd80b1e-61f4-41f6-b6b2-46f9e02eefc7", "e2915bb6-41fc-4186-a0bb-fa7aeecb89d0"], "title": "Integrating information via matchmaking", "venue": "intelligent information systems", "year": 1996, "id": "a2112a59-f5b4-4bc4-b989-d8fe02972e70"}
{"abstract": "We propose a model reduction method for positive systems that ensures the positivity of the reduced-order model. In the standard as well as in the descriptor case, for continuous-time and discrete-time systems, our approach is based on constructing diagonal solutions of Lyapunov inequalities. These are linear matrix inequalities (LMIs), which are shown to be feasible. Positivity and stability are preserved, and an error bound in the $\\mathcal{H}_\\infty$-norm is provided.", "authors": ["Timo Reis", "Elena Virnik"], "n_citation": 21, "references": ["26c6f93c-ed16-4894-a5c7-e74371f0e766", "4ba38782-38f5-458f-bfb1-42244e9ffcbd", "fb198864-b832-4985-ba56-7d047786b9cf"], "title": "Positivity Preserving Balanced Truncation for Descriptor Systems", "venue": "Siam Journal on Control and Optimization", "year": 2009, "id": "f286af0c-f7c5-4cb3-b16c-768f8b253599"}
{"abstract": "Motivated by the design of observers with good performance and robustness to measurement noise, the problem of estimating the state of a linear time-invariant system in finite time and robustly with respect to measurement noise is considered. Using a hybrid systems framework, a hybrid observer producing an estimate that converges to the plant state in finite time, even under unknown piecewise-constant noise, is presented. The stability and robustness properties of the observer are shown analytically and validated numerically.", "authors": ["Yuchun Li", "Ricardo G. Sanfelice"], "n_citation": 5, "references": ["12d1d7fa-f70f-48da-a118-42520f84ac37", "24a184cb-a6a9-4a6e-a06b-c3b3e4b3178c", "3c62de32-c9eb-4cc0-9cf7-fe8b0d3a9a73", "4d8c1f78-6c3f-4b9a-a010-0f1d2b71cea4", "5aa1fefa-5eaf-4a20-8bc4-293881f819b5", "5f0edc05-4109-4869-982f-e47ab6550bd8", "9b9b0736-8ebc-43b9-9679-0b58aeb3fc42", "b1c20c7d-6a2e-4fd1-bbcc-fbf02649fc52", "b74ec4eb-0a14-4b83-bd53-168a6b376233", "c343cf06-6d4f-48a7-aa89-4826ac4737cf", "c8423fdd-1f5b-4319-b7c2-146eba87eddf", "daf75540-e75f-4999-8c36-d1a4ea15bc77", "fded4355-19b6-4fa0-adde-01a564bf1c6b"], "title": "A finite-time convergent observer with robustness to piecewise-constant measurement noise", "venue": "Automatica", "year": 2015, "id": "15770e6a-db53-4410-90e3-e00c9b1bab2e"}
{"abstract": "Abstract   We give an illustration of a construction useful in producing and describing models of Girard and Reynolds' polymorphic \u03bb-calculus. The key unifying ideas are that of a Grothendieck fibration and the category of continuous sections associated with it, constructions used in indexed category theory; the universal types of the calculus are interpreted as the category of continuous sections of the fibration. As a major example a new model for the polymorphic \u03bb-calculus is presented. In it a type is interpreted as a Scott domain. In fact, understanding universal types of the polymorphic \u03bb-calculus as categories of continuous sections appears to be useful generally. For example, the technique also applies to the finitary projection model of Bruce and Longo, and a recent model of Girard. (Indeed the work here was inspired by Girard's and arose through trying to extend the construction of his model to Scott domains). It is hoped that by pin-pointing a key construction this paper will help towards a deeper understanding of models for the polymorphic \u03bb-calculus and the relations between them.", "authors": ["Thierry Coquand", "Carl A. Gunter"], "n_citation": 113, "references": ["018b0db2-9f49-4bdb-a022-f3ce2c2c1d96", "17e51698-5ddc-443a-9887-cd63c1405f16", "688d3e03-f9d2-49e1-b982-76b0c13612ea", "7e2f7b51-4417-461f-90b0-6c93836ee3a2", "8081d99d-4c0a-42a0-be23-44fee0fd2225", "84cd96d8-e748-4620-a752-a1a4f7f36fe5", "8a19d900-fb03-418a-a54c-186f23bf8621", "9a34ef2c-c051-4f3a-963c-51eb515b41d4", "afbf313c-e828-43db-931f-f70abca4e3cf", "b14a2e71-34d6-44ed-997a-50304ce96fbe", "cc65e7d4-e24c-4c69-8528-12a938915362", "d44a654b-49a4-433a-b44e-03fb5eeecfd6", "e520970c-da39-4a0f-b406-598c4958024d", "f5fa2887-0e1f-4c42-b32e-f9f4abc6d0b0"], "title": "Domain theoretic models of polymorphism", "venue": "Information & Computation", "year": 1989, "id": "78c769c4-6814-4c84-9c9d-9144d9bea90e"}
{"abstract": "In a previous work we have introduced a multifractal traffic model based on so-called stochastic L-Systems, which were introduced by biologist A. Lindenmayer as a method to model plant growth. L-Systems are string rewriting techniques, characterized by an alphabet, an axiom (initial string) and a set of production rules. In this paper, we propose a novel traffic model, and an associated parameter fitting procedure, which describes jointly the packet arrival and the packet size processes. The packet arrival process is modeled through a L-System, where the alphabet elements are packet arrival rates. The packet size process is modeled through a set of discrete distributions (of packet sizes), one for each arrival rate. In this way the model is able to capture correlations between arrivals and sizes. We applied the model to measured traffic data: the well-known pOct Bellcore, a trace of aggregate WAN traffic and two traces of specific applications (Kazaa and Operation Flashing Point). We assess the multifractality of these traces using Linear Multiscale Diagrams. The suitability of the traffic model is evaluated by comparing the empirical and fitted probability mass and autocovariance functions; we also compare the packet loss ratio and average packet delay obtained with the measured traces and with traces generated from the fitted model. Our results show that our L-System based traffic model can achieve very good fitting performance in terms of first and second order statistics and queuing behavior.", "authors": ["Paulo S. Salvador", "Ant\u00f3nio Nogueira", "Rui Valadas"], "n_citation": 50, "title": "Framework based on stochastic L-systems for modeling IP traffic with multifractal behavior", "venue": "", "year": 2003, "id": "d01d5d09-103f-4086-8c12-cc3b08be62a7"}
{"abstract": "The primary goal of this study is to devise a method to express mutations to state in a modern (higher order, polymorphic, nonstrict) functional language, without sacrificing referential transparency, and with a simple, easy-to-reason-about semantics. Although collectively these properties seem contradictory, a satisfactory solution is found. Aside from the fundamental property of referential transparency, the two key properties that the authors maximize are simplicity and expressiveness. The system must be easy to use: expressing mutations to state should be natural, and the resulting behavior should be easy to reason about. >", "authors": ["Juan Carlos Guzman", "Paul Hudak"], "n_citation": 132, "references": ["0ae1bce8-7965-45f9-9a2b-f3f26a36b92c", "112eeff7-c265-4808-aef5-55f592540e40", "5434e88f-afe5-4e52-b302-15e819a10c02", "a02cb3c9-080b-4966-988e-760d9fbbb4d0", "a43fa38b-ae64-48e1-95e2-f3e9112f10af", "aa44dd48-8e1b-4c0e-b79e-95e3bf683345", "edb7a8e6-909c-42eb-9a92-b3653fbefa83"], "title": "Single-threaded polymorphic lambda calculus", "venue": "logic in computer science", "year": 1990, "id": "4517eb00-f860-4eec-b27a-c4759ded802b"}
{"abstract": "We pose and answer several questions concerning the number of ways to fold a polygon to a polytope, and how many polytopes can be obtained from one polygon; and the analogous questions for unfolding polytopes to polygons. Our answers are, roughly: exponentially many, or nondenumerably infinite.", "authors": ["Erik D. Demaine", "Martin L. Demaine", "Anna Lubiw", "Joseph O'Rourke"], "n_citation": 50, "references": ["303a53ce-a951-45fa-b206-60e125455924", "35607655-b051-49ed-92ab-dee3477a4489", "9a18d7cf-2edf-41ec-8a83-b92fa37f17e0", "a6353e50-c5ff-45a8-842b-02eeaaa772ad", "e3fb1d1a-380e-47ac-9917-e1988c63cda5"], "title": "Enumerating Foldings and Unfoldings between Polygons and Polytopes", "venue": "Graphs and Combinatorics", "year": 2002, "id": "a1fd7120-cae5-4c52-9628-eb56443237c6"}
{"abstract": "In this paper, new results are derived for the high-rate performance of source coding for symmetric error channels (i.e., a channel where all index errors are equally likely) for a large class of distortion measures. Expressions are derived for the expected distortion including the effect of channel errors as the number of quantization levels N gets large. It is shown that the distortion can asymptotically be approximated as the sum of the source quantization distortion and the channel error induced distortion. In addition, the expressions obtained can be used to glean key insights on the relative amounts of source and channel coding necessary to attain a balanced system, i.e., one where neither the distortion caused by the source quantization nor the distortion caused by channel errors dominate the performance. Optimization of the codebook for minimizing the expected distortion is also considered, and theoretical expressions are derived for the optimal point density.", "authors": ["Chandra R. Murthy", "Bhaskar D. Rao"], "n_citation": 50, "references": ["0bfd1f3f-6a46-46e1-b5ee-c85d5cd9ff61", "3027eafe-243e-44d3-b27c-d8391c0d9686", "610bb493-d41e-49b7-933e-7f9050f43165", "6f868fbb-24d7-49d3-bf80-42aa693c8439", "9ba74674-2280-4b06-883e-a3b43d3c67ce", "bc1e8c68-7062-46b8-9f60-50fbdca29ead", "f2ecd9c2-7150-4c8e-9180-5a960b05cc24"], "title": "High-rate analysis of source coding for symmetric error channels", "venue": "data compression conference", "year": 2006, "id": "86af86d0-e76c-4160-8b46-5b8f0576844f"}
{"abstract": "BAliBASE is a database of manually refined multiple sequence alignments categorized by core blocks of conservation sequence length, similarity, and the presence of insertions and N/C-terminal extensions. Availability: From http://www-igbmc.u-strasbg.fr/BioInfo /BAlibase/", "authors": ["Julie D. Thompson", "Fr\u00e9d\u00e9ric Plewniak", "Olivier Poch"], "n_citation": 422, "title": "BAliBASE: a benchmark alignment database for the evaluation of multiple alignment programs.", "venue": "Bioinformatics", "year": 1999, "id": "e3d24655-feff-4e3b-a63f-a9a2066cca38"}
{"abstract": "The benefits of CBR methods in domains where cases are text depend on the underlying text representation. Today, most TCBR approaches are limited to the degree that they are based on efficient, but weak IR methods. These do not allow for reasoning about the similarities between cases, which is mandatory for many CBR tasks beyond text retrieval, including adaptation or argumentation. In order to carry out more advanced CBR that compares complex cases in terms of abstract indexes, NLP methods are required to derive a better case representation. This paper discusses how state-of-the-art NLP/IE methods might be used for automatically extracting relevant factual information, preserving information captured in text structure and ascertaining negation. It also presents our ongoing research on automatically deriving abstract indexing concepts from legal case texts. We report progress toward integrating IE techniques and ML for generalizing from case texts to our CBR case representation.", "authors": ["Stefanie Br\u00fcninghaus", "Kevin D. Ashley"], "n_citation": 69, "references": ["0a93eec5-84e5-412a-9232-d859e67c3439", "0cf55950-7c08-4c9a-bca0-b2134180229f", "3693f72f-3016-40e9-a641-4e7a759cf1cf", "5e2348b2-d733-4b6a-aed6-a86c57a1a28d", "60ec7d99-718d-48e8-abb7-3c21d964702d", "845557aa-8760-4e84-8bc9-89e228488d99", "a5e45f48-d860-4cd5-a638-6122a2d331fe", "c1afacf8-aaf1-4750-a8b3-2b858dc694af", "ccafb7af-4e09-42ca-8c11-aa041d67e57b", "d425457a-d3dc-4d6b-aa3e-3b1170974af1", "e1136cd7-3556-4a92-b105-04b8c50ce4a8", "ea0fcae3-3086-4b1a-9b67-40e9d566edbf"], "title": "The Role of Information Extraction for Textual CBR", "venue": "international conference on case based reasoning", "year": 2001, "id": "87669516-feb2-4945-b193-9eafe207f1aa"}
{"abstract": "We propose a static analysis framework for concurrent programs based on reduction of thread interleavings using sound invariants on the top of partial order techniques. Starting from a product graph that represents transactions, we iteratively refine the graph to remove statically unreachable nodes in the product graph using the results of these analyses. We use abstract interpretation to automatically derive program invariants, based on abstract domains of increasing precision. We demonstrate the benefits of this framework in an application to find data race bugs in concurrent programs, where our static analyses serve to reduce the number of false warnings captured by an initial lockset analysis. This framework also facilitates use of model checking on the remaining warnings to generate concrete error traces, where we leverage the preceding static analyses to generate small program slices and the derived invariants to improve scalability. We describe our experimental results on a suite of Linux device drivers.", "authors": ["Vineet Kahlon", "Sriram Sankaranarayanan", "Aarti Gupta"], "n_citation": 38, "references": ["02f428f6-4dd5-43db-b487-c1ccd0d795b1", "041f661d-7510-4f53-b630-b7fc3788fb59", "0d69faba-7596-4254-85c7-ff9a032bc232", "1b23724d-cf16-408c-9510-75a032c36081", "224076d5-2793-4ba2-a0f9-36574d613be5", "2bb33756-67db-4329-8c0d-f3c5fdab2367", "34d67173-5d3f-4dbe-8c4c-1c2af7509fc0", "6b82d3a0-ef6f-4356-a4ef-37dfd54415fe", "74024e51-dd77-4386-84b0-1dcbb298c024", "7bb71afa-91b8-46e7-9008-da84e0427b93", "7f0f937c-f854-47ff-b5fb-aca9314414b9", "821ac711-6a5d-4bd7-a425-847c8b5a994a", "846fb8fa-6bf7-4847-b3e2-d3843775546d", "94db4e53-faec-445b-b598-1afeeeec17fe", "9849d9c4-a97f-452f-882c-42a8c6cab0b5", "9a4984f9-27d4-47eb-8bc8-0469bf540f94", "afddbf4f-1aa5-4764-a1ad-e4a369b80140", "b05ca4d9-5937-4736-b45a-a7387e236cb6", "b5894e8e-1774-45b2-9b34-23d2330878d0", "bed97152-67c3-4673-a46a-e25a2318888b", "c3d0854d-b720-438a-8809-d0a44f5e04c9", "c76e99d7-8465-4acc-8d20-fa28318a1476", "c97a21c5-f5bc-43d8-a82c-40542f1b6e64", "d1c52eff-d2a2-4b7f-bca3-ddfd18fc3c6d", "dc492c37-ce50-4729-bd27-6ce0f1b057cc", "fd43ff1a-8079-4041-977d-d27b1b3efd3f"], "title": "Semantic Reduction of Thread Interleavings in Concurrent Programs", "venue": "tools and algorithms for construction and analysis of systems", "year": 2009, "id": "dec00a0e-3a18-481f-a86a-1d2dc11bdd4f"}
{"abstract": "Self-adaptive software continually evaluates and modifies its own behavior to meet changing demands. One of the key issues in constructing such software is that of planning when and what kinds of adaptations are appropriate. In this paper, we present an architecture-centric knowledge-based approach for specifying and enacting architectural adaptation policies as the main driver for self-adaptive behavior. Our work applies explicitly represented knowledge-based policies for the definition and enactment of software adaptation at the architectural level. A key benefit of our approach is the decoupling of adaptation policy from system implementation as well as the independent and dynamic evolution of policies themselves. We elaborate our overall approach, present prototype tools and techniques for its support, and discuss future research directions.", "authors": ["John C. Georgas", "Richard N. Taylor"], "n_citation": 58, "references": ["1662ff09-0eab-4389-a0b2-fd466742c37c", "28c3496e-54c8-419c-a0ec-d4f91bf9dbd3", "63164cea-83c8-462d-8658-9d509d693dcc", "8292d169-f379-4939-a8dd-67f6bfafa956", "865a2b47-8a86-41ad-8b96-08085d8fde9a", "b485133a-7ebb-4ce5-b2db-a8903fde39ab"], "title": "Towards a knowledge-based approach to architectural adaptation management", "venue": "foundations of software engineering", "year": 2004, "id": "6aac92e7-4550-42c0-8311-cb385f8338ef"}
{"abstract": "Pattern classification using neural networks and statistical methods is discussed. We give a tutorial overview in which popular classifiers are grouped into distinct categories according to their underlying mathematical principles; also, we assess what makes a classifier neural. The overview is complemented by two case studies using handwritten digit and phoneme data that test the performance of a number of most typical neural-network and statistical classifiers. Four methods of our own are included: reduced kernel discriminant analysis, the learning k-nearest neighbors classifier, the averaged learning subspace method, and a version of kernel discriminant analysis.", "authors": ["Lasse Holmstr\u00f6m", "Petri Koistinen", "Jorma Laaksonen", "Erkki Oja"], "n_citation": 179, "references": ["01570ac6-ab0a-4e78-a145-d65ff4e4ec22", "09b6e04e-ca5e-40ce-bd92-73502563e488", "20fb61d7-108f-4045-a45f-1c7db93c3476", "2c44d3f7-1ede-42e6-95e4-b3fe1607a4b7", "3a840ede-1ae4-4c57-909c-f1a7b2f645a0", "4a2748a7-2d68-4487-8661-fe5d6fa77a44", "4a29b56b-b74e-4945-9017-61a7ab844fd9", "5aa9b5c6-1398-4004-beed-3af970292649", "66d77bed-65af-4b73-a5cd-a5cdf1949825", "6dfd5bec-b651-4dfb-915d-a284335b47ea", "70caa088-db95-482e-8d60-b1b95ae48081", "756f67c1-6a02-439d-a873-eda27c5d262e", "81501a41-02ee-4d59-a404-9fbf09e65877", "83a5e51f-1e47-4fe1-8b6e-fa5bfcec3b98", "857f05d7-f312-454a-843e-089f33caf862", "878a4432-5911-49e3-985c-ac8908f97777", "88d7302f-5435-41b8-8506-a23d53c6ec28", "90951460-27a9-4fab-8d0c-d4cc6faed6c9", "96c6efd2-7bfd-4327-9008-21e1fc863b3c", "9c01a502-04f3-4adb-9bde-f06253818cb9", "9d211498-cd9d-4333-9feb-895140c8e870", "ae3e7593-586f-495f-9416-4b50ed1fcd10", "c940458b-bf3c-4483-a252-bc4cdcc36a25", "cb731238-55b6-4404-a8d7-2b386fae4623", "ccfd3cd5-14ad-4717-adc5-200a41885c80", "cd64c9d8-0c0f-48df-a63b-74206887a6a8", "d5ec2cb1-0594-4156-bf45-08136be81ed2", "eb25b330-623b-422a-bc23-9957c522d152"], "title": "Neural and statistical classifiers-taxonomy and two case studies", "venue": "IEEE Transactions on Neural Networks", "year": 1997, "id": "69e5215c-a851-4498-9617-27ab7fa70cef"}
{"abstract": "Composite Symbolic Library is a symbolic manipulator for model checking systems with heterogeneous data types. Our current implementation uses two basic symbolic representations: BDDs for boolean and enumerated variables, and polyhedra for (unbounded) integers. These basic representations are imported to the Composite Symbolic Library using a common interface and are combined using a disjunctive composite representation. In this paper, we present several heuristics for efficient manipulation of this composite representation. Our heuristics make use of the following observations: 1) efficient operations on BDDs can be used to mask expensive operations on polyhedra, 2) our disjunctive representation can be exploited by computing pre and post-conditions and subset checks incrementally, and 3) size of a composite representation can be minimized by iteratively merging matching constraints and removing redundant ones. We present experimental results that illustrate efficiency of our algorithms.", "authors": ["Tuba Yavuz-Kahveci", "Tevfik Bultan"], "n_citation": 7, "references": ["12c9fc70-d3ed-4079-9a3a-b662d5cb3f7c", "18049fa9-5d9f-4846-9ef9-a44e276e160a", "3d5cc0b1-90a7-4b8f-9c96-b1167357e73f", "5f04688c-f150-44d5-9314-333715bbbf0e", "6167d78a-c1e4-4651-84c0-01f33a66ad8a", "66aea8d0-a2f0-4d5f-80d7-fdea9d6871ac", "8a6f1922-9ccb-4366-9f05-349eab53e2de", "a14fc2fc-c4e5-4388-b539-46b3e640f86a", "b03b9036-1ff5-4678-af56-8d62e9680d5f", "b91d1677-3bd8-4ba6-ac48-100a9b0167d5", "c00bbb49-6e29-4103-8883-55acd23c248b", "c30025e8-5f20-418b-a883-06368f978d75", "eb80a68d-4fb8-41d2-9f44-c0496be8dc1d", "f203d22f-04dd-4fb5-a204-258a7b0cd46c"], "title": "Heuristics for Efficient Manipulation of Composite Constraints", "venue": "frontiers of combining systems", "year": 2002, "id": "be315881-03c3-4024-a4e8-241d00ebc399"}
{"abstract": "Biomolecular systems, composed of networks of proteins, underlie the major functions of living cells. Compartments are key to the organization of such systems. We have previously developed an abstraction for biomolecular systems using the \u03c0-calculus process algebra, which successfully handled their molecular and biochemical aspects, but provided only a limited solution for representing compartments. In this work, we extend this abstraction to handle compartments. We are motivated by the ambient calculus, a process algebra for the specification of process location and movement through computational domains. We present the BioAmbients calculus, which is suitable for representing various aspects of molecular localization and compartmentalization, including the movement of molecules between compartments, the dynamic rearrangement of cellular compartments, and the interaction between molecules in a compartmentalized setting. Guided by the calculus, we adapt the BioSpi simulation system, to provide an extended modular framework for molecular and cellular compartmentalization, and we use it to model and study a complex multi-cellular system.", "authors": ["Aviv Regev", "Ekaterina M. Panina", "William A. Silverman", "Luca Cardelli", "Ehud Y. Shapiro"], "n_citation": 561, "references": ["1ef74256-a040-47b4-81a2-8ab106c83bb7", "32c07bd4-52c7-4427-81a2-7dcdf2221452", "5455c4ce-cfcc-4bb6-a619-deca4ad140da", "5c6763a2-1976-4b45-a174-fa9fcc330ebe", "8db6729e-1d21-4dd1-920a-4496171daa96", "949a78af-3beb-449e-bc52-a37ef53bc7f3", "bc76246b-690d-4c19-871e-23d150b51a1d", "d015f0a5-5d7b-4e71-baa7-cc2a4409910a"], "title": "BioAmbients: an abstraction for biological compartments", "venue": "computational methods in systems biology", "year": 2004, "id": "2361d667-5a57-4f9f-8a7f-f4344a454c3d"}
{"abstract": "As the \"software space\" of source code, documentation, models, and other programming artifacts continue to grow in size and complexity, programmers face the challenge of navigating this space, as well as documenting and sharing their journeys for other developers and future successors. Current navigational structures are either closely tied to the semantics of the software or are constructed in a constrained top-down fashion to match the architecture or requirements of the system. In this paper, we introduce the notion of combining waypoints from geographical positioning and social tagging from shared bookmark systems to allow programmers to create shared, tagged points in software space. We report preliminary progress on our prototype (tagSEA), and discuss our future plans.", "authors": ["Margaret-Anne D. Storey", "Li-Te Cheng", "R. Ian Bull", "Peter C. Rigby"], "n_citation": 50, "references": ["22cba7e6-658b-4785-89b7-3658575dcb2d", "5c1825a2-fde0-4f16-8072-0e4e45aa5f75", "6c4d90c8-cc2a-47c6-a6fc-361c36d01ddc", "a806bf78-4d4c-49a3-8425-666da3b08b73", "ed44b7ef-906b-4ec7-8de8-91c20f0036e7", "f5b9c097-3f3d-4ad6-b975-4bbfaaf0cda6"], "title": "Waypointing and social tagging to support program navigation", "venue": "human factors in computing systems", "year": 2006, "id": "4b098b46-5856-480e-8c99-81d86e982d32"}
{"abstract": "Association rule algorithms can produce a very large number of output patterns. This has raised questions of whether the set of discovered rules \"overfit\" the data because all the patterns that satisfy some constraints are generated (the Bonferroni effect). In other words, the question is whether some of the rules are \"false discoveries\" that are not statistically significant. We present a novel approach for estimating the number of \"false discoveries\" at any cutoff level. Empirical evaluation shows that on typical datasets the fraction of rules that may be false discoveries is very small. A bonus of this work is that the statistical significance measures we compute are a good basis for ordering the rules for presentation to users, since they correspond to the statistical \"surprise\" of the rule. We also show how to compute confidence intervals for the support and confidence of an association rule, enabling the rule to be used predictively on future data.", "authors": ["Nimrod Megiddo", "Ramakrishnan Srikant"], "n_citation": 126, "references": ["8761cd87-be91-4dcc-83b0-d1a273cecd7f", "8a6a4c08-fdc8-49c4-8e73-23e7fdb466d6", "ecd6a845-8439-49b0-abe8-f71fff81da23"], "title": "Discovering predictive association rules", "venue": "knowledge discovery and data mining", "year": 1998, "id": "b96b123a-d47f-4ea1-b61f-c1a28b18cbcb"}
{"abstract": "We propose the use of crowdsourcing and human computation to help solve difficult problems in verification and debugging that can benefit from human insight. As a specific scenario, we explain how non-expert humans can assist in the verification process by finding patterns in portions of simulation or execution traces which are represented as images. Such patterns can be used in a variety of ways, including assertion-based verification, improving coverage, bug localization, and error explanation. Several related issues are discussed, including privacy and incentive mechanisms.", "authors": ["Wenchao Li", "Sanjit A. Seshia", "Somesh Jha"], "n_citation": 50, "references": ["331f9085-a480-4c61-a89b-37b94119cbca", "98f543e3-d61c-4099-ae96-237816472592", "ad6d819d-27e8-4076-b31f-5f2f40e558c0", "b0829c9d-7d8d-48d7-8c12-91a5a66cfe69", "d8b98e10-4431-40b1-a518-f1018a1f3156", "f9f081f6-bb34-4bf7-b2a1-9336a6bf399a", "fba0a445-604e-47d5-9717-3f42d23aeec7"], "title": "CrowdMine: towards crowdsourced human-assisted verification", "venue": "design automation conference", "year": 2012, "id": "fe3bc2f0-a043-457c-95fe-460805c77032"}
{"abstract": "Distributed programming has shifted from private networks to the public Internet and from using private and controlled services to increasingly using publicly available heterogeneous Web services (e.g., REST, SOAP, RSS, and Atom). This move enables the creation of innovative end-user-oriented composed services with user interfaces. These services  mashups are typically point solutions to specific (specialized) problems; however, what is missing is a programming model that facilitates and accelerates creation and deployment of mashups of  diverse services. In this paper we describe a domain-specific language that unifies the most common service models and facilitates service composition and integration into end-user-oriented Web applications. We demonstrate our approach with an implementation that leverages the Ruby on Rails framework.", "authors": ["E. Michael Maximilien", "Hern\u00e1n Wilkinson", "Nirmit Desai", "Stefan Tai"], "n_citation": 136, "references": ["91bd5bed-21b6-4344-a446-917b483f5827", "d5c64fdf-b394-48e5-9556-50517853cfd3"], "title": "A Domain-Specific Language for Web APIs and Services Mashups", "venue": "international conference on service oriented computing", "year": 2007, "id": "c24c1579-671d-45dd-8b47-8d2e2d529258"}
{"abstract": "Web performance impacts the popularity of a particular Web site or service as well as the load on the network, but there have been no publicly available  end-to-end  measurements that have focused on a large number of popular Web servers examining the components of delay or the effectiveness of the recent changes to the HTTP protocol. In this paper we report on an extensive study carried out from many client sites geographically distributed around the world to a collection of over 700 servers to which a majority of Web traffic is directed. Our results show that the HTTP/1.1 protocol, particularly with pipelining, is indeed an improvement over existing practice, but that servers serving a small number of objects or closing a persistent connection without explicit notification can reduce or eliminate any performance improvement. Similarly, use of caching and multi-server content distribution can also improve performance if done effectively.", "authors": ["Balachander Krishnamurthy", "Craig E. Wills"], "n_citation": 145, "references": ["162e4e22-2ad7-42b0-a566-83c65ec46bd2", "5fa79bc6-4203-442f-a3e8-99abe8bd542a", "7b7fd255-e31a-4289-b448-fa1887272cde", "c7f0ccf6-296a-4ce8-987b-1abc56a41c3f", "c940e462-1199-4bab-89d4-df0bab6ba45d", "ca498e1b-5b65-489e-b21b-79e1df5b310e", "ceaeaf9c-a427-4edd-97a6-6c22562d92e2"], "title": "Analyzing factors that influence end-to-end Web performance", "venue": "international world wide web conferences", "year": 2000, "id": "d59ec8b8-145a-4570-a91c-38587a3613a5"}
{"abstract": "The design of reduced order controllers under specific performance and structure requirements is dealt in this contribution. Two controllers are designed and compared. The first one was designed using H \u221e  theory whereas the latter one is designed departing from a parametric-optimisation via a two-stage algorithm. The time spent by the designer using our second approach is largely reduced. An active suspension system is selected as a case study. The performance of both controllers is tested experimentally in the active suspension set-up. The experimental results show that the parametric-optimisation controller practically meets the desired performance specifications. Meanwhile, the H \u221e  controller cannot accomplish the imposed constraints just in the low-frequency range.", "authors": ["Daniel U. Campos-Delgado", "Ricardo Femat", "Eduardo Ruiz-Velazquez"], "n_citation": 3, "references": ["738c462f-8706-4a45-9af2-a8e1724ceac1", "f051701e-6ae8-4530-8405-7cbd68eccbce"], "title": "Design of reduced-order controllers via H\u221e and parametric optimisation: Comparison for an active suspension system", "venue": "European Journal of Control", "year": 2003, "id": "8d900ee3-325b-4820-8081-6ac55d8e1739"}
{"authors": ["Jon L. Christensen", "Joe Marks", "J. Thomas Ngo"], "n_citation": 31, "references": ["036be3f9-d3a4-4436-a5b4-14dec87f9d1a", "07a1e164-72da-4732-b8ff-2fc8b58e7be3", "1d84757b-86a9-4015-9c8e-1e255521e3c8", "2eb0f5b5-4ec0-48d9-8525-066dca10adef", "498e5514-68b7-4332-9571-ef29957a6862", "5471da7d-3a4c-43ab-9af9-e4db475d0122", "560f48df-41f4-40f2-9b97-3759952e122f", "5999ccaa-aa2f-42eb-84fc-97d63227e4ad", "5ec54b43-3896-4cc6-b8b5-efde0c41789e", "6c2c6205-e92c-42d7-93e7-4a95175bda7a", "9bcc973a-64f5-4eee-a756-e4d294c6abb7", "b28ba49b-bc61-416e-b0cd-dbfeda216217", "c87c9843-8197-49bd-8ee9-53fd893967d9", "d8c6ea0a-d9aa-43ca-9394-1fe8761bab1f", "f73615b6-f09f-45df-8176-61f00078de2c"], "title": "Automatic motion synthesis for 3D mass-spring models", "venue": "The Visual Computer", "year": 1997, "id": "363855d4-3cd1-4b9d-bb3d-2043d3380dda"}
{"authors": ["Bertrand Meyer", "Alexander Kogtenkov", "Emmanuel Stapf"], "n_citation": 17, "references": ["167c6962-5f96-4b77-afc9-8e60d52a90d2", "624b45db-4935-417f-89d2-b59720834f09", "e2299cdc-41d2-4f50-8a6a-e2cfe569c7ba"], "title": "Avoid a Void: The Eradication of Null Dereferencing", "venue": "", "year": 2010, "id": "789273e0-a009-47eb-85c4-c0e812cfa377"}
{"abstract": "This paper presents a new interactive tool for making local adjustments of tonal values and other visual parameters in an image. Rather than carefully selecting regions or hand-painting layer masks, the user quickly indicates regions of interest by drawing a few simple brush strokes and then uses sliders to adjust the brightness, contrast, and other parameters in these regions. The effects of the user's sparse set of constraints are interpolated to the entire image using an edge-preserving energy minimization method designed to prevent the propagation of tonal adjustments to regions of significantly different luminance. The resulting system is suitable for adjusting ordinary and high dynamic range images, and provides the user with much more creative control than existing tone mapping algorithms. Our tool is also able to produce a tone mapping automatically, which may serve as a basis for further local adjustments, if so desired. The constraint propagation approach developed in this paper is a general one, and may also be used to interactively control a variety of other adjustments commonly performed in the digital darkroom.", "authors": ["Dani Lischinski", "Zeev Farbman", "Matthew T. Uyttendaele", "Richard Szeliski"], "n_citation": 254, "references": ["0803f987-5ed2-497e-ac37-e42475b15c94", "27ee5120-fd19-4165-86ca-f251fc2921f0", "311f4d3b-b903-4676-a20d-82084f41bcfa", "34d4e37b-e575-4316-847b-d8a661b51473", "4511ce52-0e25-483d-9a68-60f4820ad877", "4a813fb8-759b-4bf1-a735-529716ae84ad", "5ffadf36-4496-4be6-b8a8-828fa37f7757", "68cd36a2-6db7-455a-8897-ed6d464d5032", "726b8a8b-3036-4765-8975-88b80421ae7c", "73e49fb8-9519-4d4f-88c3-fc5f107bd00e", "744de9c6-bb83-44e4-9290-ba0d4dba8eda", "7c78306f-870f-422c-9c71-4d21c0ae7692", "875f9a92-af0a-4a1b-8d1a-6dc5cfba544e", "980c2408-e691-4d79-a2fd-6a6cd0ed2d5f", "b3527d67-9dc9-49d2-a93a-7b945a76ed55", "b51f42e5-e02c-4e1d-b0b6-49fc57e4207e", "be8f13bc-3cdc-4fb2-9e0c-9603d7446bdb", "e291932e-2a5d-4c96-9ae7-c2326764c154", "e6ae6152-0d5c-45d4-99e1-b0fd3a02a860", "eed2c08f-a7e6-4e2b-8379-2f7d57ac82df", "f948c6a9-e292-4d61-872f-5ad6164c1f54", "f9b13a82-887a-4ae4-9103-6f921f74059a"], "title": "Interactive local adjustment of tonal values", "venue": "international conference on computer graphics and interactive techniques", "year": 2006, "id": "eefbda17-25b8-484a-aa7a-5ebf5fea2cc3"}
{"abstract": "We present and explore the effectiveness of sev- eral variations on the All-Moves-As-First (AMAF) heuristic in Monte-Carlo Go. Our results show that: Random play-outs provide more information about the goodness of moves made earlier in the play-out. AMAF updates are not just a way to quickly initialize counts, they are useful after every play-out. Updates even more aggressive than AMAF can be even more beneficial.", "authors": ["David P. Helmbold", "Aleatha Parker-Wood"], "n_citation": 39, "references": ["3a293de2-b0f9-4f1c-a49e-22334ab46e61", "f0230884-1958-4733-8323-2f01d7dd3f3f", "f2fee27d-66bb-48f6-affa-c0826c8a8ea2"], "title": "All-Moves-As-First Heuristics in Monte-Carlo Go", "venue": "", "year": 2009, "id": "9a68830d-8537-497f-aa41-73917beb99f4"}
{"abstract": "IT SPIRAL is a collaborative project by nine universities and four industries to develop a common curriculum for teaching software engineering. It combines existing foundation educational practices at the individual universities, a shared DVD library on advanced software engineering topics, and common intensive sessions led by industry participants. It aims to develop advanced IT skills in top-level students, shared educational skills and materials among the universities, and practical cooperation with industry to focus and advance masters level software engineering education. IT SPIRAL combines fundamentals, advanced topics, and a practical focus in a scalable approach to developing world-class software engineers.", "authors": ["Michael Barker", "Katsuro Inoue"], "n_citation": 50, "references": ["89de4d1a-90a2-413a-98ac-4b817f0c84e0", "d7ce82bb-846f-4541-9b9a-882b3ea1692a", "e4690314-a7d1-4540-a34e-e50cdd6cb1e4", "fa694681-f024-4a54-86b3-09ad92462c09"], "title": "IT SPIRAL: A Case Study in Scalable Software Engineering Education", "venue": "", "year": 2009, "id": "aa45546d-8fa2-401a-ac2b-0108bbeb1bc1"}
{"abstract": "Current reliable multicast protocols do not have scalable congestion control mechanisms and this deficiency leads to concerns that multicast deployment may endanger stability of the network. We present a sender-based approach for multicast congestion control targeted towards reliable bulk data transfer. We assume that there are a few bottleneck links in a large scale multicast group at any time period and these bottlenecks persist long enough to be identified and adapted to. Our work focuses on dynamically identifying the worst congested path in the multicast tree and obtaining TCP-friendly throughput on this selected path. We use the network simulator (NS2) to validate and evaluate our congestion control algorithm with both drop-tail and RED gateways.", "authors": ["Sherlia Y. Shi", "Marcel Waldvogel"], "n_citation": 68, "references": ["01a09d2c-f8d3-40e4-bfee-211533b3f526", "0695070f-320e-4d26-9c68-2c8faa20c944", "14dbcb0a-b6a3-4407-9a3c-0ce575e268c9", "32ad8389-7548-4c17-8c91-9f1ba6e82e7c", "386a49a9-d157-4e11-b4a7-18535c14cb94", "4feceaa2-b680-4e7b-929a-e267fb9277f9", "5705a07b-ffd5-47e8-bffb-471744b2c171", "5d32feec-e30a-4603-bb26-9e0e7cc45271", "686b1f97-3cb7-47a6-bbd2-e8ba891dc1b5", "6877599a-dd3e-4153-80ae-d71018cde6d9", "6a9c2062-e8eb-4584-8d40-35f8ed4e40d2", "9771c887-0cd9-4416-a8ca-be5170e4246e", "b0b8f6c8-daa5-4226-88ce-6aeab42b786d", "b46af373-5147-4193-9c1d-70adb1f5a527", "bca24aff-d6ba-4f1c-b82a-ffbc52815148", "d29b395f-af6e-46ca-a894-60d9bcad0cc0", "f6fc4443-7a98-4f9f-92e8-e4e5d94521a7", "f945601b-9036-4edc-98cd-8cc79f58c6e6"], "title": "A rate-based end-to-end multicast congestion control protocol", "venue": "international symposium on computers and communications", "year": 2000, "id": "0e89dada-683c-4d40-8347-f41b1bc289d1"}
{"abstract": "In the last years a lot of work has been done on color, textural, structural and semantic indexing of \"content-based\" video databases. Motion-based video indexing has been less explored, with approaches generally based on the analysis of optical flows. Compressed videos require the decompression of the sequences and the computation of optical flows, two steps computationally heavy. In this paper we propose some methods to index videos by motion features (mainly related to camera motion) and by motion-based spatial segmentation of frames, in a fully automatic way. Our idea is to use MPEG motion vectors as an alternative to optical flows. Their extraction is very simple and fast; it doesn't require a full decompression of the stream and saves us from computing optical flows. Additional computational economy comes from having one motion vector each 16/spl times/16 sub-image; this makes the algorithms faster than working with dense optical flows. Experimental results reported at the end of this paper show that MPEG motion compensation vectors are suitable for this kind of applications.", "authors": ["Edoardo Ardizzone", "M. La Cascia", "A. Avanzato", "A. Bruna"], "n_citation": 81, "references": ["17f01f85-4909-41b7-bafd-88939c01894a", "56d6466f-28bc-429c-a969-9b9609398481", "80d21afa-532b-4951-897f-b0ba62208999", "8a6c00f8-7ab6-4aca-8ccc-42c57bb56e6c", "aef49ce6-051c-4146-8237-485d14a9b6ff", "fe646421-b223-4daa-9465-bab32de4a402"], "title": "Video indexing using MPEG motion compensation vectors", "venue": "international conference on multimedia computing and systems", "year": 1999, "id": "a5b7c48e-1287-4b2e-b2f1-1ba8243e1c8f"}
{"abstract": "Numerous systems have been designed which use virtualization to subdivide the ample resources of a modern computer. Some require specialized hardware, or cannot support commodity operating systems. Some target 100% binary compatibility at the expense of performance. Others sacrifice security or functionality for speed. Few offer resource isolation or performance guarantees; most provide only best-effort provisioning, risking denial of service.This paper presents Xen, an x86 virtual machine monitor which allows multiple commodity operating systems to share conventional hardware in a safe and resource managed fashion, but without sacrificing either performance or functionality. This is achieved by providing an idealized virtual machine abstraction to which operating systems such as Linux, BSD and Windows XP, can be  ported  with minimal effort.Our design is targeted at hosting up to 100 virtual machine instances simultaneously on a modern server. The virtualization approach taken by Xen is extremely efficient: we allow operating systems such as Linux and Windows XP to be hosted simultaneously for a negligible performance overhead --- at most a few percent compared with the unvirtualized case. We considerably outperform competing commercial and freely available solutions in a range of microbenchmarks and system-wide tests.", "authors": ["Paul Barham", "Boris Dragovic", "Keir Fraser", "Steven Hand", "Timothy L. Harris", "Alex Ho", "Rolf Neugebauer", "Ian Pratt", "Andrew Warfield"], "n_citation": 8547, "references": ["115ce5c8-8c08-46b1-a100-f6aaa68f20d5", "17d502ec-9d95-412a-b1d4-004fc5d8ab04", "207aecbb-81f9-48c2-b8be-21119bcceafc", "2c9ebc3d-713f-42d8-a867-0ff2d24644d3", "37c3f144-3bb2-4df7-a05d-d482dbca0398", "53f82d8c-22d7-43e4-be03-fe0cdd7b8abc", "553db688-bb98-4ed0-a2a4-42f1e5678559", "569b777f-eb40-4fa8-9567-c5844c8c3522", "6993119b-feb4-4f91-b2d8-5fe12bcdfa84", "70177cf6-e1e7-4624-b371-75b49a1b837f", "79df819e-bae3-4d67-bee8-baa3fc148d82", "84cdb716-319a-430a-b8e1-90e4848aa187", "9dddf29d-dcfe-4a5c-85cc-6a7b6b2d91b4", "b5b9d83b-c85b-4418-8d01-4d00ef8a091f", "b5ba979f-ba02-4ba4-975d-8687812f4b70", "c7bf74ee-739c-45c6-9713-6a0eeb08e76d", "d693ff4a-02ea-43a1-bc66-c64970f275a9", "da8e4122-1d7b-449c-b52d-0a43c32fc6e7", "dfcd55ef-26c0-41c9-8681-9af2a2afd43b", "e49e1d41-99eb-41f7-971b-d9c2544198ed", "e883ae1e-0c54-4fcb-9c38-4165bb0fcc7a", "e96dc7d8-19a8-4495-861e-bfc3963361a7", "f483eabe-4858-4d94-88bc-82df43f32a81", "f4d35f6d-e961-4f7e-bd18-fda32093cfd0", "f67bf40c-fdad-4215-942b-b23b2a017115", "fd5b4339-0328-41fc-90b7-12d5f093072c"], "title": "Xen and the art of virtualization", "venue": "symposium on operating systems principles", "year": 2003, "id": "78991392-db9c-45a4-86a2-b4ce93ab0ec0"}
{"abstract": "We attempt a new variant of the scheduling problem by investigating the scalability of the schedule length with the required number of processors, by performing scheduling partially at compile time and partially at run time. Assuming infinite number of processors, the compile time schedule is found using a new concept of the threshold of a task that quantifies a trade-off between the schedule-length and the degree of parallelism. The schedule is found to minimize either the schedule length or the number of required processors and it satisfies: A feasibility condition which guarantees that the schedule delay of a task from its earliest start time is below the threshold, and an optimality condition which uses a merit function to decide the best task-processor match for a set of tasks competing for a given processor. At run time, the tasks are merged producing a schedule for a smaller number of available processors. This allows the program to be scaled down to the processors actually available at run time. Usefulness of this scheduling heuristic has been demonstrated by incorporating the scheduler in the compiler backend for targeting Sisal (Streams and Iterations in a Single Assignment Language) on iPSC/860. >", "authors": ["Santosh Pande", "Dharma P. Agrawal", "Jon Mauney"], "n_citation": 69, "references": ["0489f1fb-f8a7-40bd-9054-15552e0b2a18", "08aa16ba-91cb-4326-a284-77954ca3885d", "0ac2b75d-db2d-4d2b-ba4a-6e4aa3d0c6b0", "0ddc9254-4feb-40f3-a4f5-820c2cf452ec", "3295d02a-ee89-4593-9689-4f21f47c226c", "428170ac-353f-41b8-8976-54ac5684ea11", "6c44c923-d8a2-4aab-aef0-1d4be6181d14", "9de372ee-78ba-4084-9f81-0c044ab632c7", "a4f5c1cd-c5d3-457b-ab57-be407c5bc9c2", "b5d16866-bbcd-4317-b638-370478da5a63", "bd9e8c9e-f983-4dd8-92f4-904061c4a00b", "c4ebbdbc-97ba-45a7-8e56-1eb9436e4d52", "ca6e1bb0-892e-4e61-8d47-bcf42b020e1e", "d0a3abdc-a7a0-4909-9284-aaf9e71a0586", "ddcd967f-b1df-4b59-8b6b-bc58b74036a0", "ec5cea52-381b-4263-ac39-5f59db9b0f91", "f9b1a16f-4f65-4362-ba45-06a31931972d"], "title": "A scalable scheduling scheme for functional parallelism on distributed memory multiprocessor systems", "venue": "IEEE Transactions on Parallel and Distributed Systems", "year": 1995, "id": "ce8ec15c-e6dc-4a2c-8899-729bc43d14c5"}
{"abstract": "This paper presents LOCO, a graphical, interactive environment to experiment with code obfuscation and deobfuscation transformations, which can be applied automatically, semi-automatically and by hand. LOCO is an extension of the multi-platform visualization tool LANCET, combined with an obfuscation infrastructure in the underlying link-time program rewriter DIABLO. By use of LOCO, a developer can easily navigate through the control flow graph of a program and do fine-grained obfuscation, test new obfuscation transformations, test the robustness of existing transformations or improve existing transformations.", "authors": ["Matias Madou", "Ludo Van Put", "Koen De Bosschere"], "n_citation": 51, "references": ["1f645369-8fe7-4987-9a50-9ab67a086d12", "6852b20f-61c6-4d44-9c73-95af7f483f1f", "812f7c12-a745-4bf8-b29b-e851eff99eba", "b1bbb93a-17d3-458f-a97f-36f76ffb653f", "b304c838-dff1-4fb4-a7c8-43ce62f1ca46", "ec83d2a6-b348-4e77-ae5c-ae58b43d8330"], "title": "LOCO: an interactive code (De)obfuscation tool", "venue": "partial evaluation and semantic-based program manipulation", "year": 2006, "id": "c08dac56-fa72-4ac3-a140-abb91142c842"}
{"abstract": "Computer systems are becoming extremely complex. Complexity stems from the large number and heterogeneity of a system's hardware and software components, from the multi-layered architecture used in the system's design, and from the unpredictable nature of the workloads, especially in Web-based systems. Because of these reasons, performance management of complex systems is difficult and expensive when carried out by human beings. A new approach, called self-managing computer systems, is to build into the systems the mechanisms required to self-adjust configuration parameters so that the Quality of Service requirements of the system are constantly met. In this paper, we describe an approach in which analytic performance models are combined with combinatorial search techniques to de sign controllers that run periodically (e.g., every few minutes) to determine the best possible configuration for the system given its workload. We first illustrate and motivate the ideas using a simulated multithreaded server. Then, we provide experimental results , obtained by using the techniques described here, to an actual Web server subject to a workload generated by SURGE.", "authors": ["D. Menasce", "Mohamed N. Bennani"], "n_citation": 101, "references": ["05248914-6606-4de6-9a1d-e9170a332a8f", "1ea412cf-ceb9-46fe-90f4-c8f7c1676ee1", "3cc7701f-78c8-4282-b4a1-6927b35d675d", "80230489-ae23-4e11-96d5-c7e6196f719d"], "title": "ON THE USE OF PERFORMANCE MODELS TO DESIGN SELF-MANAGING COMPUTER SYSTEMS", "venue": "", "year": 2003, "id": "2c07a57b-ffb0-43b3-9965-ea6e3539daff"}
{"abstract": "This paper presents a new neural network approach to real-time pattern recognition on a given set of binary (or bipolar) sample patterns. The perceptive neuron of a binary pattern is defined and constructed as a binary neuron with a neighborhood perceptive field. Letting its hidden units be the respective perceptive neurons of the patterns, a three-layer forward neural network is constructed to recognize these patterns with minimum error probability in a noisy environment. The theoretical and simulation analyses show that the network is effective for pattern recognition and can be under strict real-time constraints.", "authors": ["Jinwen Ma"], "n_citation": 9, "references": ["0149ab3e-59fb-4dee-88c9-1568a42d32c9", "289a6524-04db-47f7-871c-6a782751a25a", "49137163-715f-41eb-b971-be037ef192bb", "7f6a97bf-c66d-4afb-91b5-24a4ec13c6fe"], "title": "A neural network approach to real-time pattern recognition", "venue": "International Journal of Pattern Recognition and Artificial Intelligence", "year": 2001, "id": "46d762c3-4653-48ba-82ed-c1588e6a7335"}
{"abstract": "Cost effective systems use specialization to optimize factors such as power consumption, processing throughput, flexibility or combinations thereof. Reconfigurable systems obtain this specialization at run-time. System reconfiguration has a vertical, a horizontal and a time dimension. We organize this design space as the reconfiguration hierarchy, and discuss the design methods that deal with it. Finally, we survey existing commercial platforms that support reconfiguration and situate them in the reconfiguration jungle.", "authors": ["Patrick Schaumont", "Ingrid Verbauwhede", "Kurt Keutzer", "Majid Sarrafzadeh"], "n_citation": 242, "references": ["167e4a72-34b5-4341-ac1d-7ffd42648a98", "269a3c84-1164-42c8-b4c7-d23641058533", "58b20538-0cdb-48e1-88c6-1d68654acf44", "67362358-73b1-417f-9f9c-25e206f752ab", "75796717-2244-43de-be81-983aecbe623c", "83affcb1-9e2f-4e54-a344-7b3dd95ad92e", "ab70d868-1333-416e-8f4a-5c462bbf3aa3"], "title": "A quick safari through the reconfiguration jungle", "venue": "design automation conference", "year": 2001, "id": "43391bc9-f3bb-438a-9928-71af87b45b8b"}
{"abstract": "The asymptotic stabilisation problem of a class of large-scale interconnected systems is considered, where the non-linear interconnections between subsystems satisfy quadratic constraints that are functions of the whole system's state vector. A decentralised combined observer-controller compensator is proposed and analysed, where the subsystems\u2019 state vectors are estimated using local sliding mode observers. The closed-loop system driven by the proposed decentralised compensator is guaranteed to be asymptotically stable subject to two conditions that are easily verifiable. Simulation results illustrate the effectiveness of the proposed decentralised combined observer-controller compensator.", "authors": ["Karanjit Kalsi", "Jianming Lian", "Stanislaw H. Zak"], "n_citation": 18, "references": ["044c095e-c785-4064-bf00-c189e893608b", "21362933-c3aa-444a-bd55-5e0037e7e071", "5399cf60-5812-4843-987e-3166519489aa", "8a9d2def-b381-4556-954a-3378a710b8b4", "af5d94c7-3313-4429-937e-9fb26965433f", "dc94b43c-34f4-411a-a973-46b36e35b775", "ff60c975-60de-4fe6-8bf3-9689338cd470"], "title": "On decentralised control of non-linear interconnected systems", "venue": "International Journal of Control", "year": 2009, "id": "c34bd04f-4ee9-4803-9713-ef1fa0f1ca9b"}
{"abstract": "The goal of this research was the creation of an adaptation mechanism for the delivery of three-dimensional content. The adaptation of content, for various network and terminal capabilities \u2013 as well as for different user preferences, is a key feature that needs to be investigated. Current state-of-the art research of the adaptation shows promising results for specific tasks and limited types of content, but is still not well-suited for massive heterogeneous environments. In this research, we present a method for transmitting adapted three-dimensional content to multiple target devices. This paper presents some theoretical and practical methods for adapting three-dimensional content, which includes shapes and animation. We also discuss practical details of the integration of our methods into MPEG-21 and MPEG-4 architectures.", "authors": ["Hyung Seok Kim", "Chris Joslin", "Thomas Di Giacomo", "Stephane Garchery", "Nadia Magnenat-Thalmann"], "n_citation": 50, "references": ["0075805b-ae9a-4e41-883d-61850aaed472", "096afad5-27e6-45ae-9e3d-655d0c677d94", "1d42c285-4fd6-4f55-9189-7c04d67b87ff", "2d73c88c-076e-49a9-918f-33fe2ef80723", "55f51a98-e912-4327-800e-c58c7c11cd16", "759cccfd-ddd9-44ff-b6b1-249ecd22bbe0", "7cea37f4-5fa3-44b5-a673-c9016ad3f691", "7d3d0508-b3a4-45a4-b49d-5e026fc0f273", "8ad46028-68f9-40dd-b310-4e8757b2efa9", "9728abc5-3066-4eae-914f-0e4c59567ec6", "a499d84e-7102-4dce-9222-965ca2244441", "ad106012-b65a-4488-afdb-1bfb2a24235c", "b57fee7d-9b2d-4898-b6a6-b7aac3b234bd", "b87cce6a-7915-4dcd-b387-d13bf9fd626d", "c9287e41-e1cd-4b62-8c5c-57cbc4a91adf", "d6a5c712-e8e5-425d-bac6-07d07b89d4d9", "d81f78c2-cdd3-43f1-af66-4eeef71b491b", "fb06da0d-1e32-4565-a21b-0d25e60ff037"], "title": "Device-based decision-making for adaptation of three-dimensional content", "venue": "The Visual Computer", "year": 2006, "id": "2b790cfc-9334-4c1d-9ada-8bb78c77b84d"}
{"abstract": "Various relevance feedback algorithms have been proposed in recent years in the area of content-based image retrieval. This paper gives a brief review and analysis on existing techniques-from early heuristic-based feature weighting schemes to recently proposed optimal learning algorithms. In addition, the kernel-based biased discriminant analysis (KBDA) is proposed to fit the unique nature of relevance feedback as a biased classification problem. As a novel variant of traditional discriminant analysis, the proposed algorithm provides a trade-off between discriminant transform and regression. The kernel form is derived to deal with non-linearity in an elegant way. Experimental results indicate that significant improvement in retrieval performance is achieved by the new scheme.", "authors": ["Thomas S. Huang", "Xiang Sean Zhou"], "n_citation": 113, "references": ["0e2a0680-d99c-4ece-927b-dabfb28b3bb2", "10c713eb-0b9b-4911-9f41-0d1373569b52", "11c22d16-f2c8-4c90-b220-56a9922b97ee", "13b91eb0-0857-4556-b32a-0f85a1cf43f6", "1c3f63fb-91e9-4147-99b3-2dffdde20341", "2430d105-9797-43da-ae3f-85eb05580219", "2d9d8d55-0c15-473b-a3c5-d0becc375775", "33da0355-a2af-4185-8234-02e054eb7fdc", "6e4ecc92-bf51-4a12-a2df-15f0da3d8e14", "77975ed0-05d3-40bc-b179-41e734271c4d", "7e7d82ae-865f-46eb-9a38-ad180c1d1d60", "f2281d46-788e-4c45-a594-81634febabb6", "fdd18096-827d-414b-b512-fd1d4ef3bfc4"], "title": "Image retrieval with relevance feedback: from heuristic weight adjustment to optimal learning methods", "venue": "international conference on image processing", "year": 2001, "id": "039c15b6-12ff-46f8-b41f-badd8446673e"}
{"abstract": "Today, planning and control of logistic processes on automobile terminals are generally executed by centralised logistics systems, which cannot cope with high requirements for flexible order processing due to increasing dynamics and complexity. The main business processes on automobile terminals \u2013 notification of vehicles by automobile manufacturer, transport to automobile terminal, storage and technical treatment as well as delivery to automobile dealer \u2013 are planned and controlled by centralised application software systems. In the context of this article, an innovative approach to autonomous control in automobile logistics is investigated, considering as example the logistic order processing of an idealised automobile terminal of the company E.H. Harms Automobile\u2010Logistics. Within a simulation study, evidence of the existing application potential of autonomous control in the field of vehicle storage management is provided. Thereupon the technical feasibility of an autonomously controlled storage manage...", "authors": ["Felix B\u00f6se", "Jakub Piotrowski", "Bernd Scholz-Reiter"], "n_citation": 17, "references": ["02a30d20-6a14-47b0-bf0f-c7d836bd4423"], "title": "Autonomously controlled storage management in vehicle logistics \u2013 applications of RFID and mobile computing systems", "venue": "International Journal of Rf Technologies: Research and Applications", "year": 2009, "id": "7111aa22-2620-4d05-90fe-510e43c05a22"}
{"abstract": "A multiple observation-based scheme (MObS) is described for robust facial recognition, and a novel object recognition method called kernel mutual subspace method (KMS) is proposed. The mutual sub-space method (MSM) proposed by (Maeda, et al., 1999) is a powerful method for recognizing facial images. However, its recognition accuracy is degraded when the data distribution has a nonlinear structure. To overcome this shortcoming we apply kernel principal component analysis (kPCP) to MSM. This paper describes theoretical aspects of the proposed method and presents the results of facial image recognition experiments.", "authors": ["Hitoshi Sakano", "Naoki Mukawa"], "n_citation": 25, "references": ["061dcb4c-d98f-40a9-9c4a-aecb23fa078a", "94898e1d-1e50-41ab-9dcc-2c2e030cddd0", "bdac313e-152a-4d75-a707-d3e752ce45ea"], "title": "Kernel mutual subspace method for robust facial image recognition", "venue": "", "year": 2000, "id": "356f2b3d-cda2-40e0-ba51-d6a44f5e9f24"}
{"abstract": "This paper describes the design and development of a multimodal biometric personal recognition system based on features extracted from a set of 14 geometrical parameters of the hand, the palmprint, four digitprints, and four fingerprints. The features are extracted from a single high-resolution gray-scale image of the palmar surface of the hand using the linear discriminant analysis (LDA) appearance-based feature-extraction approach. The information contained in the extracted features is combined at the matching-score level. The resolutions of the palmprint, digitprint and fingerprint sub-images, the similarity/dissimilarity measures, the matching-score normalization technique, and the fusion rule at the matching-score level, which optimize the system performance, were determined experimentally. The biometric system, when using a system configuration with optimum parameters, showed an average equal error rate (EER) of 0.0005%, which makes it sufficiently accurate for use in high-security biometric systems.", "authors": ["Tadej Savi\u010d", "Nikola Pavesic"], "n_citation": 85, "references": ["13fba283-e80f-4b24-9331-644e08fe0491", "2d31d7a2-01f5-44dd-aaa0-56343850e876", "3e26cbdc-4a20-438e-aac1-1bcb2205991d", "4043767f-122d-4f34-b81f-01c810d17e28", "4f3b5bd2-1178-43be-99e0-e81c286847f9", "56f4b72a-ec39-47ac-8220-899296e7fb18", "62cc2e88-0884-4676-84e2-0daa40f0baaa", "64db32a5-037f-4c5c-aae5-38291a787dff", "69190718-b4c0-4175-b16f-22abfc8086c3", "71e42825-650f-4dbe-af93-1a05b71d70f9", "73c914f7-5e0d-4df6-aec5-81577485b160", "83379aab-3703-4e5f-bd8d-ac7dc825a908", "8347a760-0f29-430a-a5c5-b80e65604ec9", "88654e63-a2b0-485c-9a07-e55c1fe6bc98", "929cd67f-68df-4047-9e7c-d866d5c685c5", "9719aeff-873c-4f6e-ae18-8f68137b58ac", "976c4962-f8c9-40f1-8888-777f5199861d", "9f5c6e98-d176-400e-87be-929eef0f5999", "baba2d75-97fb-4bcd-8423-56a1f650960f", "bd80a129-9187-40ce-84ae-ee7a5acb9155", "c2e043e0-7dd1-428e-8d99-106c5c625ff4", "d130ecec-e5cf-4f59-b4f8-1cbda4b0c307", "e06ca75a-32c6-40bf-91cd-9b65c6c066d9", "e8e7660e-8286-4c63-a9ee-4edface45f74", "ead2e28a-f551-4765-a7aa-5f311fb0536a", "f6aaebd3-6bdf-40d9-be12-5eac6dea4846", "fbac2138-ab49-41ab-9f6e-3748de9415ff", "fd1f5c0f-44c8-4943-bc3a-e4785cd700d5"], "title": "Personal recognition based on an image of the palmar surface of the hand", "venue": "Pattern Recognition", "year": 2007, "id": "c29584ae-ae54-45c1-9f6f-5ae3540455f1"}
{"abstract": "In this article, we look at the elliptic curve cryptography, which is believed to be one of the most promising candidates for the next generation cryptographic tool. The following issues are addressed here; 1. Discrete Logarithm Problem in finite fields 2. Elliptic Curve Discrete Logs 3. Implementation of ECDLP Cryptographic Schemes 4. Attacks on EC Cryptosystems 5. Minimum Requirement for Secure EC Cryptosystems 6. Standardization and Commercialization of EC Cryptosystems 7. Construction of Elliptic Curves", "authors": ["Kiyomichi Araki", "Takakazu Satoh", "Shinji Miura"], "n_citation": 42, "references": ["0067011d-0ba8-4987-9aa3-cc4f5fa4f83a", "094d6f2e-cd3c-47bf-96f1-98986aff5c50", "2c33bdb1-6f8e-4453-8e10-5153056ae70f", "3476d9f9-f276-434d-a09c-ccfca9208d1a", "3a899883-bfbc-49c4-b937-40b9c86cdcd5", "47a2f4f8-f9cd-482c-9b7b-176844dba1ba", "4dff0b06-dc4d-45e9-addc-4f706ef583be", "636420e7-f4cd-4b97-b9a3-fe0afd48e8d5", "78dc8056-3145-49fa-991e-885747aba24f", "7b2119f4-2ad7-4c7f-bdc7-2de6e3da0dd0", "7db5ea9a-dfc0-4581-a055-31495342e746", "a046c626-5cb3-482e-8726-d6b3c7c86cd9", "a103a538-5bde-44af-a77f-ded179220c1e", "ca394e6a-59e0-466c-a66a-d976555db689", "dc0d7299-7de4-4edb-ae27-bb073092260a", "f8b6466a-d65e-4144-8920-883e6046936f"], "title": "Overview of Elliptic Curve Cryptography", "venue": "public key cryptography", "year": 1998, "id": "c35b3520-4350-44b2-89bf-b4bd10e4b1ce"}
{"abstract": "Two approaches for achieving correctness of code are verification and synthesis from specification. Evidently, it is easier to check a given program for correctness (although not a trivial task by itself) than to generate algorithmically correct-by-construction code. However, formal verification may give quite limited information about how to correct the code. Genetic programming repeatedly generates mutations of code, and then selects the mutations that remain for the next stage based on a fitness function, which assists in converging into a correct program. We use a model checking procedure to provide the fitness value in every stage. As an example, we generate algorithms for mutual exclusion, using this combination of genetic programming and model checking. The main challenge is to select a fitness function that will allow constructing correct solutions with minimal effort. We present our considerations behind the selection of a fitness function based not only on the classical outcome of model checking, i.e., the existence of an error trace, but on the complete graph constructed during the model checking process.", "authors": ["Gal Katz", "Doron A. Peled"], "n_citation": 52, "references": ["0edf262f-0ccc-43da-ba2a-a14caa3c247f", "32797d89-028d-42ca-aa08-2187d9739fe8", "3491feb2-bf31-4fde-b199-b652007cd999", "65ad0318-7dff-41c1-a3af-a63fae38e28c", "79378db1-ba0a-4f17-b51c-ade43c21f917", "79b15e00-42fe-418c-89dc-65ae58844cf9", "7c55abc5-ede0-42b7-a77a-427654b36d66", "805b3cee-8203-4281-963f-b9d27c0fc00e", "837d4855-cc93-42ff-a841-cd6e2a3b1dce", "877fd32f-56eb-4dac-a62f-df6a3694858e", "8a30efe1-0c47-47d8-b9bc-52e58d6028b6", "9849d9c4-a97f-452f-882c-42a8c6cab0b5", "c00bbb49-6e29-4103-8883-55acd23c248b", "c061069f-29d1-46d4-9974-dede8d5461f9", "c6a59dbf-4c05-4be2-b06a-689821149321", "eb0fccc5-4903-4c48-92b7-186dc2d8645d", "fa115597-6101-4fee-aa8c-f2501397c738"], "title": "Model checking-based genetic programming with an application to mutual exclusion", "venue": "tools and algorithms for construction and analysis of systems", "year": 2008, "id": "d22c3e71-e9b0-4503-a793-5b6c61db2e74"}
{"abstract": "Control Theory and feedback control in particular have been steadily gaining momentum in software engineering for adaptive systems. Feedback controllers work by continuously measuring system outputs, comparing them with reference targets and adjusting control inputs if there is a mismatch. In Control Theory, quantifying the effects of control input on measured output is a process known as system identification. This process usually relies either on detailed and complex system models or on system observation. In this paper, we adopt a Requirements Engineering perspective and ideas from Qualitative Reasoning to propose a language and a systematic system identification method for adaptive software systems that can be applied at the requirements level, with the system not yet developed and its behavior not completely known.", "authors": ["V\u00edtor Est\u00eav\u00e3o Silva Souza", "Alexei Lapouchnian", "John Mylopoulos"], "n_citation": 50, "references": ["003a6a94-09b7-402f-91b7-8c3397e9883c", "096b5064-32d1-4d48-bdba-41e964e76717", "2be9287d-1eef-45b8-b7f5-d92cf62339a6", "4c540dd6-8061-461a-889d-bb9c46e9b210", "50052f19-89a3-4ceb-95af-0f251f710ab7", "50ba4c9b-aeec-485e-8d97-dbaf42759fad", "6d0747e3-8892-4e07-9a75-3466f03e33cb", "798b658f-8135-4b71-ac3f-7bde32d53dff", "a9a7fd07-ef71-4b3c-8fcf-d7fe114d2148", "d9c3e39f-6d27-47a7-b4ae-76b5bcae8dc6", "e12b1987-5f4e-4356-8f48-71d58eef4aac", "fac86b5d-de78-4185-9f40-b8309796f067"], "title": "System identification for adaptive software systems: a requirements engineering perspective", "venue": "international conference on conceptual modeling", "year": 2011, "id": "f2bcc11e-4130-4362-a265-2ec46b4de3a9"}
{"abstract": "This paper describes our methodological and technological approach for collaborative ontology development in inter-organizational settings. It is based on the formalization of the collaborative ontology development process by means of an explicit editorial workflow, which coordinates proposals for changes among ontology editors in a flexible manner. This approach is supported by new models, methods and strategies for ontology change management in distributed environments: we propose a new form of ontology change representation, organized in layers so as to provide as much independence as possible from the underlying ontology languages, together with methods and strategies for their manipulation, version management, capture, storage and maintenance, some of which are based on existing proposals in the state of the art. Moreover, we propose a set of change propagation strategies that allow keeping distributed copies of the same ontology synchronized. Finally, we illustrate and evaluate our approach with a test case in the fishery domain from the United Nations Food and Agriculture Organisation (FAO). The preliminary results obtained from our evaluation suggest positive indication on the practical value and usability of the work here presented.", "authors": ["Ra\u00fal Palma", "Oscar Corcho", "Asunci\u00f3n G\u00f3mez-P\u00e9rez", "Peter Haase"], "n_citation": 50, "references": ["049e323c-653c-40e0-ab7d-a362d4ff7428", "235a27ec-7a05-4278-a9ca-e27a281792db", "27a12cd8-ed60-4509-9d1d-12ffa0a1959f", "4d1afdb6-88fe-427f-924a-9b64c99d61b6", "51cb9fc1-3a32-445c-b47b-d548f9972c25", "5de0d7f6-b6fd-43da-a67d-6377b43fe00e", "6268a798-5c59-4f9c-a320-a76046bc5089", "6ea2aa1a-b30e-4488-9a60-e80cac3be2e8", "7101be81-c857-4eb5-addb-7ea92d7151c8", "7323f25e-0d4e-4b12-a5ba-bc7fe7c24014", "87b9ba13-4adc-4f06-a086-1fc69dbfbe4b", "9a07cb48-11e8-464d-841f-59dff01455da", "9c7c0b14-75e2-4ff0-a01e-751799aafda8", "9ffba8c1-d965-4ac0-a539-676de8d200cb", "a18f52e2-ebd2-46f7-9f73-f45b4bfde8fd", "a70c548c-6a10-4756-b4be-e026e391f60c", "c2222caa-fa8c-42a7-816e-764532e67e17", "cb344c73-c1a3-4148-9e21-3132fb8823d6", "e3ca3686-b725-4f9e-b82d-4e7006c40fc4", "e488571e-3e58-4159-a0b7-e21e51b4235a", "f4819734-d6ca-44ce-adda-d3ec7b1cdb4b", "f60f44f3-8f9c-420d-9f76-79d7bfeccd2f"], "title": "A holistic approach to collaborative ontology development based on change management", "venue": "Journal of Web Semantics", "year": 2011, "id": "be61480b-470a-491b-a24e-61b623d2353d"}
{"abstract": "We propose a new framework for providing robust location detection in emergency response systems, based on the theory of identifying codes. The key idea of this approach is to allow sensor coverage areas to overlap in such a way that each resolvable position is covered by a unique set of sensors. In this setting, determining a sensor-placement with a minimum number of sensors is equivalent to constructing an optimal identifying code, an NP-complete problem in general. We thus propose and analyze a new polynomial-time algorithm for generating irreducible codes for arbitrary topologies. We also generalize the concept of identifying codes to incorporate robustness properties that are critically needed in emergency networks and provide a polynomial-time algorithm to compute irreducible robust identifying codes. Through analysis and simulation, we show that our approach typically requires significantly fewer sensors than existing proximity-based schemes. Alternatively, for a fixed number of sensors, our scheme can provide robustness in the face of sensor failures or physical damage to the system.", "authors": ["Saikat Ray", "Rachanee Ungrangsi", "De Pellegrini", "Ari Trachtenberg", "David Starobinski"], "n_citation": 156, "references": ["1027598e-b6bd-4218-94e4-849b6c502a99", "1045e1f2-be8b-4f6a-988d-87e5067c35ce", "1209baa9-10f6-4bf3-af97-e93bdc4977b3", "2a6bd7f0-1e71-45ef-ba47-66760ae38582", "310fcebe-c94f-4af6-8547-879ed732778d", "3939cb96-d8c8-4ec4-8102-bbce2976aeee", "47d3ff04-5c1c-427a-be1a-5666f34d28ad", "4ac80067-bbea-4eaf-8b7a-89c97db7ecfe", "4f5530bf-de86-4f1d-a55f-24202a7aa691", "7d42815c-daac-4c27-a9a3-39bd29536fed", "816ea88f-9788-487e-a83d-fc027806a635", "98c6e82c-4f64-4753-9c39-3760aca70577", "a8d141a3-31a8-40ee-81b7-6273e4343b9c", "aaecae73-d725-46ef-bb0a-4da94bb8380b", "b297de2d-8197-4cec-90b8-15a0ffe1efa4", "f8a9df79-9be7-4333-a71c-327040f67fcd", "fd51d78a-e2f5-46b6-b041-4dae9aebdc76"], "title": "Robust location detection in emergency sensor networks", "venue": "international conference on computer communications", "year": 2003, "id": "dac8c2b1-665f-43bd-8e18-412b600b4868"}
{"abstract": "Shaping by successive approximations is an important animal training technique in which behavior is gradually adjusted in response to strategically timed reinforcements. We describe a computational model of this shaping process and its implementation on a mobile robot. Innate behaviors in our model are sequences of actions and enabling conditions, and shaping is a behavior editing process realized by multiple editing mechanisms. The model replicates some fundamental phenomena associated with instrumental learning in animals, and allows an RWI B21 robot to learn several distinct tasks derived from the same innate behavior.", "authors": ["Lisa M. Saksida", "Scott Raymond", "David S. Touretzky"], "n_citation": 118, "references": ["171b55f1-c116-4bd7-9893-3acf9022a7d9", "24440c0f-649b-4498-893d-330f86bd98fb", "288106a6-f48d-44c2-98fb-bd4c257d6ff5", "33f371a4-afd3-48c2-a683-3b223de892f7", "43cb1b16-7f97-479b-89d3-360bb8411bae", "49fa2442-e13c-4e7b-bde4-ab65e0b5185c", "5e152bf0-9d37-466d-9da8-83e760da43d6", "7e5c26f0-dc3f-429d-89df-3e4de5fde7e8", "996c7ee1-b8de-4dc7-8ec4-6f403f00d3bc", "bccfcf8e-60c1-4deb-a691-687c278b0f9e", "c56a99d6-baed-4ef2-b85d-b506aa5164bf"], "title": "Shaping robot behavior using principles from instrumental conditioning", "venue": "Robotics and Autonomous Systems", "year": 1997, "id": "19b93878-e5a0-4574-8e8a-687211949d2e"}
{"abstract": "Energy efficient communications in ad hoc and sensor wireless networks is a very important topic. We study the problem of creating spanning trees of low cost, where low cost can be viewed in terms of global or local energy efficiency. We refer to the algorithms and techniques presented in the literature, and we show an extension to them, called TDPC (time division path changing), which takes into account both global and local efficiency. We show that these techniques can be applied to existing algorithms, improving the performance, and addressing both needs. We show how it is possible, in general, to cut a trade-off between the two contrasting requests of global and local energy efficiency, by using TDPC with a particular class of algorithms.", "authors": ["Leonardo Badia", "Michele Zorzi"], "n_citation": 8, "references": ["0af670c7-9d5e-4919-b252-8aac6c08a3a5", "1bec0dfe-7bf6-467e-be96-46bc98d24633", "38f54b84-5272-43df-8cde-a3e755b17dee", "90b80d6a-d4e1-445a-a42e-cf37ccc650b7"], "title": "On the construction of broadcast and multicast trees in wireless networks - global vs. local energy efficiency", "venue": "global communications conference", "year": 2002, "id": "c8d9e9df-10c6-40d1-8fc2-7e42c98b8d4a"}
{"abstract": "In this paper, we employ probabilistic neural network (PNN) with image and data processing techniques to implement a general purpose automated leaf recognition for plant classification. 12 leaf features are extracted and orthogonalized into 5 principal variables which consist the input vector of the PNN. The PNN is trained by 1800 leaves to classify 32 kinds of plants with an accuracy greater than 90%. Compared with other approaches, our algorithm is an accurate artificial intelligence approach which is fast in execution and easy in implementation.", "authors": ["Stephen Gang Wu", "Forrest Sheng Bao", "Eric You Xu", "Yu-Xuan Wang", "Yi-Fan Chang", "Qiao-Liang Xiang"], "n_citation": 478, "references": ["01570ac6-ab0a-4e78-a145-d65ff4e4ec22", "4367b81f-4209-45cc-97c5-98614918e031", "69ec922e-1be6-4fa7-a0a4-a718bb568e6e", "85767da7-113e-4a20-94bc-de6bd7427e54", "a9741d1b-831a-4b1c-8fb4-1f43b6d2f1de", "d2c0a5e9-8a4f-426d-96ab-bffa70536fb3", "da991e89-8e1c-414e-9383-bb92815eb933", "db10cf87-b55b-4e49-8940-bc30860a2536", "dc083709-61e4-4314-a238-169c19e67ac1", "e08cf3bc-6e9b-4e43-9001-f25980ac9999", "e2d2a141-b8d4-4aaf-9f0f-ae08de9bfd20"], "title": "A Leaf Recognition Algorithm for Plant Classification Using Probabilistic Neural Network", "venue": "international symposium on signal processing and information technology", "year": 2007, "id": "0a7fc092-be7b-4b39-b2d3-a54b2f9ac0cf"}
{"authors": ["Vladimir Vujovic", "Mirjana Maksimovic"], "n_citation": 13, "references": [], "title": "Raspberry Pi as a Wireless Sensor node: Performances and constraints", "venue": "international convention on information and communication technology, electronics and microelectronics", "year": 2014, "id": "f7403bde-9ffc-4441-b9ee-06199360b1da"}
{"abstract": "Robot motion planning in a dynamic cluttered workspace requires the capability of dealing with obstacles and deadlock situations.#R##N##R##N#The paper analyzes situations where the robot is considered with its shape and size and it can only perceive the space through its local sensors. The robot explores the space using a planner based on an artificial potential field and incrementally learns a fast way to escape or prevent deadlock situations using a combination of sensor perceptions, field information and planner experience. The knowledge acquired is a high-level network useful for avoiding deadlock areas consisting of local minimum nodes, backtracking nodes and subgoal nodes.", "authors": ["Luca Maria Gambardella", "Cristina Versino"], "n_citation": 17, "references": ["1684c753-2f10-4bd9-8c2e-e5fc7643bd58", "21847d7f-e860-49c2-8f76-b53162c4d5ef"], "title": "Robot motion planning integrating planning strategies and learning methods", "venue": "", "year": 1994, "id": "a9b0c589-e649-4cf1-b804-595dd0e3bf2e"}
{"abstract": "This paper describes an agile development methodology which combines agile principles with organizational patterns and adapts them to build embedded real-time systems focusing on the system's constraints. The hardware/software partitioning and platform-based design are used in the proposed methodology to support the embedded system designer meet the system's constraints in an iterative and incremental way and to reduce substantially the design time and cost of the product. To discuss the strengths and weakness of this methodology, a case study involving a pulse oximeter is also presented", "authors": ["Lucas C. Cordeiro", "Raimundo S. Barreto", "Rafael Barcelos", "N Meuse Oliveira", "Vicente Ferreira de Lucena", "Paulo Romero Martins Maciel"], "n_citation": 14, "references": ["1000db79-802a-4f1a-87ea-e0305d513f07", "2d53c010-bc5c-4228-89d8-75d1327c101d", "35e7f83b-6649-4354-b6bf-4de0b8d0b75e", "4eccdbde-5f63-41b9-b566-f090dc87edbd", "5da75678-4d67-41bd-9afe-8efc5ef3b04e", "695c7b36-d06a-473d-a109-84738cb66d07", "6ade6c60-1b5b-4f83-a51f-1be7482a0f04", "f0ff2792-7305-40e7-95ac-c530e5e6ec84"], "title": "Agile Development Methodology for Embedded Systems: A Platform-Based Design Approach", "venue": "engineering of computer based systems", "year": 2007, "id": "b1299143-97a0-4f4d-99a2-7fde84789d59"}
{"authors": ["Peter McIlroy", "Keith Bostic", "M. Douglas McIlroy"], "n_citation": 110, "references": ["8345448c-5110-41c1-a395-01602a37c9c3", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "cb3cec59-ff10-4070-bda4-b440614d59b7", "d5f07bd6-3dee-43b7-abdb-f1d18457961d"], "title": "Engineering Radix Sort", "venue": "Computing Systems", "year": 1993, "id": "cf55627a-ebcf-413a-bd33-6c0ad8dae7d0"}
{"abstract": "We develop a theory of local errors for the explicit and implicit tau-leaping methods for simulating stochastic chemical systems, and we prove that these methods are first-order consistent. Our theory provides local error formulae that could serve as the basis for future stepsize control techniques. We prove that, for the special case of systems with linear propensity functions, both tau-leaping methods are first-order convergent in all moments. We provide a stiff stability analysis of the mean of both leaping methods, and we confirm that the implicit method is unconditionally stable in the mean for stable systems. Finally, we give some theoretical and numerical examples to illustrate these results.", "authors": ["Muruhan Rathinam", "Linda R. Petzold", "Yang Cao", "Daniel T. Gillespie"], "n_citation": 105, "references": ["ea38e4ed-3d3f-4fa0-b318-674b81a8b84d"], "title": "Consistency and Stability of Tau-Leaping Schemes for Chemical Reaction Systems", "venue": "Multiscale Modeling & Simulation", "year": 2005, "id": "9272e6f3-b929-490c-829c-a3aac542adba"}
{"abstract": "Hard real-time code is special purpose code whose worst-case performance (worst-case execution time WCET) needs to be good and easy to predict. Despite these specific demands on the temporal properties of hard real-time code, real-time programmers often use the same algorithms and programming techniques that have proven effective for nonreal-time applications. This paper explains the different temporal requirements imposed on real-time resp. nonreal-time code, and outlines why traditional (nonreal-time) programming tends to produce code that (a) has a high WCET and (b) is hard to analyze for its WCET. Based on these observations, the paper proposes an unconventional programming strategy that avoids the shortcoming of traditional coding and yields code that is well suited for hard real-time system, i.e., its WCET is short and predictable. The evaluation of a number of examples demonstrates the advantages of the proposed programming strategy on WCET and its predictability.", "authors": ["Peter P. Puschner"], "n_citation": 34, "references": ["26b6178f-b143-4e9d-813f-16a9fb9e4e58", "8ac43b49-8495-41a5-af31-7b05d677dccb", "ddd106ad-211a-4b29-81c4-518996311511"], "title": "Algorithms for dependable hard real-time systems", "venue": "", "year": 2003, "id": "4149ea96-db28-4c2d-bc8e-e8ba47d27c6f"}
{"abstract": "Purpose #R##N#Breast cancer computer-aided diagnosis (CADx) may utilize image descriptors, demographics, clinical observations, or a combination. CADx performance was compared for several image features, clinical descriptors (e.g. age and radiologist\u2019s observations), and combinations of both kinds of data. A novel descriptor invariant to rotation, histograms of gradient divergence (HGD), was developed to deal with round-shaped objects, such as masses. HGD was compared with conventional CADx features.", "authors": ["Daniel C. Moura", "Miguel Angel Guevara L\u00f3pez"], "n_citation": 50, "references": ["0b0abd55-db39-46f0-8410-a9c8c505a9f0", "2ebfebc7-a20e-4e23-9386-4eb9e089ed32", "3064feac-fbea-4b0a-a109-7707d92c8831", "3615ef39-127c-4f22-bb91-ecdf6f11368d", "4289bfe3-7305-41e5-a19d-8f0dd37e9892", "46c20996-8baf-472e-b5c2-d0b3495b1218", "4b5c3e88-f26e-4ac6-8869-70854cf85313", "6d79a4f8-359e-4956-bac7-8ce8451692e7", "7eb8fe29-385f-49e0-b4fa-cd106d2cf763", "8026f56a-a93e-4933-8ead-c9aa9e3f0498", "92508c4c-4262-4984-a3bc-edd8d214c7ce", "9cef868f-eb6d-4189-acd1-43eac87cf81e", "9dfd81c6-3dea-4e56-bbc9-80377e397979", "a96068ba-91ce-4e44-a5d6-f97cb8c6b66f", "aa767a83-de19-4421-bfb4-f63808992758", "ab1d2422-9a3a-47b3-a0e6-cbebb0e1fadc", "b45e1e7b-24e3-490d-bf5b-043e19a48599", "b944f77f-113b-4a02-ae5e-d4a124b8fd5b", "bda4a970-1fb8-42c2-a099-4820b603e86a", "be8c5b6e-5687-4aa4-aaaa-f038ce822d8f", "db7dad29-24b4-4607-b3a3-62265d39d39a", "dd83785a-dd19-41e3-9b25-ebabbd48d336", "e3557e8d-a1e2-4bc7-a705-1e0e3a7574e3", "ed18f400-9013-4abb-8ea1-0a203d1519c6", "ee4f1758-28f1-49f9-a313-acaccb334af0", "fac468df-8f40-47e3-8877-b036594bdb9e"], "title": "An evaluation of image descriptors combined with clinical data for breast cancer diagnosis", "venue": "computer assisted radiology and surgery", "year": 2013, "id": "37aaa3a0-30e6-4803-ae8f-29970ae9baa1"}
{"abstract": "Treemaps, a visualization method for large hierarchical data spaces, are used to augment the capabilities of the Analytic Hierarchy Process (AHP) for decision-making. Two direct manipulation tools, presented metaphorically as a \u201cpump\u201d and a \u201chook,\u201d were developed and applied to the treemap to support AHP sensitivity analysis. Users can change the importance of criteria dynamically on the two-dimensional treemap and immediately see the impact on the outcome of the decision. This fluid process dramatically speeds up exploration and provides a better understanding of the relative impact of the component criteria. A usability study with six subjects using a prototype AHP application showed that treemap representation was acceptable from a visualization and data operation standpoint.", "authors": ["Toshiyuki Asahi", "David Turo", "Ben Shneiderman"], "n_citation": 102, "references": ["24b4ca75-f7fb-4001-b473-f21b60f5a932", "344e9c70-c89f-4ac4-9636-554f2f01f6ef", "575571ca-5d86-40b4-8ab9-9cde3be2e3ab", "584752ce-83d3-4462-8a79-1a214912dc97"], "title": "Using Treemaps to Visualize the Analytic Hierarchy Process", "venue": "Information Systems Research", "year": 1995, "id": "bd5c3777-8e80-4631-bc7f-93f2cbf3a5b6"}
{"abstract": "Defect causal analysis offers a simple, low-cost method for systematically improving the quality of software produced by a team, project, or organization. DCA takes advantage of one of the most widely available types of quality information, the software problem report. This information drives a team-based technique for defect causal analysis. The analysis leads to process changes that help prevent defects and ensure their early detection. The paper discusses the three principles that drive the DCA approach. It considers the impact of DCA on an organization.", "authors": ["David N. Card"], "n_citation": 127, "references": ["4beaea9e-8e68-4642-84ac-7ea6933b7b27", "c00925c9-2b51-4297-b957-ad13446ed00a", "cf216dbc-d892-4904-bd9a-cf8a50086805", "d4c3a0a8-80f6-4450-b678-639692543e25"], "title": "Learning from our mistakes with defect causal analysis", "venue": "IEEE Software", "year": 1998, "id": "9f379ea4-5abb-4fa6-b6b2-125e2a575fc9"}
{"abstract": "A large amount of biological knowledge today is only available from full-text research papers. Since neither manual database curators nor users can keep up with the rapidly expanding volume of scientific literature, natural language processing approaches are becoming increasingly important for bioinformatic projects.#R##N##R##N#In this paper, we go beyond simply extracting information from full-text articles by describing an architecture that supports targeted access to information from biological databases using the results derived from text mining of research papers, thereby integrating information from both sources within a biological application.#R##N##R##N#The described architecture is currently being used to extract information about protein mutations from full-text research papers. Text mining results drive the retrieval of sequence information from protein databases and the employment of algorithmic sequence analysis tools, which facilitate further data access from protein structure databases. Complex mapping of NLP derived text annotations to protein structures allows the rendering, with 3D structure visualization, of information not available in databases of mutation annotations.", "authors": ["Ren\u00e9 Witte", "Christopher J. O. Baker"], "n_citation": 50, "references": ["05f55bea-b625-49dd-841b-de634dc57ef9", "2616451f-9c95-4137-8868-459a58df74e5", "5b264ef5-d326-4056-b2ed-b898c1fbb4ce", "a1922c85-3cae-4ca7-ac47-3b5e6ad20a9c", "b549827d-c9c4-4ee3-9ea2-46c4e46d94a0", "bdfb185d-9023-4e26-a891-f252d11c6bf9", "c0ca7970-9cd1-4421-b9a8-0d97950f92ba"], "title": "Combining biological databases and text mining to support new bioinformatics applications", "venue": "applications of natural language to data bases", "year": 2005, "id": "c1c932cc-a1cc-4c3f-86f9-148f894b1d0b"}
{"abstract": "In many database applications, one of the common queries is to find approximate matches to a given query item from a collection of data items. For example, given an image database, one may want to retrieve all images that are similar to a given query image. Distance based index structures are proposed for applications where the data domain is high dimensional, or the distance function used to compute distances between data objects is non-Euclidean. In this paper, we introduce a distance based index structure called multi-vantage point (mvp) tree for similarity queries on high-dimensional metric spaces. The mvp-tree uses more than one vantage point to partition the space into spherical cuts at each level. It also utilizes the pre-computed (at construction time) distances between the data points and the vantage points. We have done experiments to compare mvp-trees with vp-trees which have a similar partitioning strategy, but use only one vantage point at each level, and do not make use of the pre-computed distances. Empirical studies show that mvp-tree outperforms the vp-tree 20% to 80% for varying query ranges and different distance distributions.", "authors": ["Tolga Bozkaya", "Z. Meral Ozsoyoglu"], "n_citation": 503, "references": ["07c804bf-b60d-4b5d-b004-8f4652e7d81b", "17f01f85-4909-41b7-bafd-88939c01894a", "24e6ebc0-f597-4ca2-9df9-aa8117b94207", "2663d978-9596-4c7c-bf06-14f80ecf46a3", "3af0f523-03d1-4112-97da-ffea22691a22", "3c281c4e-8302-4c37-96d7-1e615167c5f5", "6c5e1d10-bd51-4ac6-83f8-b74efec751b2", "783e5a24-8505-4817-9566-36b1a478a6be", "938d4320-d40b-4c63-a899-d7a03df35964", "a0304326-321c-49c0-843e-6ad5ea9f5815", "d6ffd0e7-61aa-4dea-9fe0-4345e2382e96"], "title": "Distance-based indexing for high-dimensional metric spaces", "venue": "international conference on management of data", "year": 1997, "id": "105edb54-d48b-4470-a4dc-528270ee4c4a"}
{"abstract": "A biologically-based multistage neural network is presented which produces color constant responses to a variety of color stimuli. The network takes advantage of several mechanisms in the human visual system, including retinal adaptation, spectral opponency, and spectrally-specific long-range inhibition. This last stage is a novel mechanism based on cells which have been described in cortical area V4. All stages include nonlinear response functions. The model emulates human performance in several psychophysical paradigms designed to test color constancy and color induction. We measured the amount of constancy achieved with both natural and artificial simulated illuminants, using homogeneous grey backgrounds and more complex backgrounds, such as Mondrians. On average, the model performs as well or better than the average human color constancy performance under similar conditions. The network simulation also displays color induction and assimilation behavior consistent with human perceptual data. >", "authors": ["Susan M. Courtney", "Leif H. Finkel", "Gershon Buchsbaum"], "n_citation": 50, "references": ["65f8bd7f-5cfe-4de1-822d-c7a0ccb758ac", "88fe493e-f143-402c-8553-c0d6b2449f02", "ae38e6d6-2bae-484c-b529-03646bf976bc"], "title": "A multistage neural network for color constancy and color induction", "venue": "IEEE Transactions on Neural Networks", "year": 1995, "id": "9e4283f0-f1d9-43d8-a3f2-ab1f37015e69"}
{"authors": ["S\u00e9bastien Konieczny", "Ram\u00f3n Pino P\u00e9rez"], "n_citation": 47, "title": "On the Frontier between Arbitration and Majority.", "venue": "principles of knowledge representation and reasoning", "year": 2002, "id": "7ff75bb6-a70d-40b3-a9cb-52868de08cee"}
{"authors": ["C. J. van Rijsbergen"], "n_citation": 28, "title": "An algorithm for information structuring and retrieval", "venue": "The Computer Journal", "year": 1971, "id": "bb77684b-66b6-4f6d-b30c-115e2bcf82cb"}
{"abstract": "Constraints are a powerful general paradigm for representing knowledge in intelligent systems. The standard constraint satisfaction paradigm involves variables over a discrete value domain and constraints which restrict the solutions to allowed value combinations. This standard paradigm is inapplicable to problems which are either:#R##N##R##N#(a) mixed, involving both numeric and discrete variables, or#R##N##R##N#(b) conditional,1 containing variables whose existence depends on the values chosen for other variables, or#R##N##R##N#(c) both, conditional and mixed.#R##N##R##N#We present a general formalism which handles both exceptions in an integral search framework. We solve conditional problems by analyzing dependencies between constraints that enable us to directly compute all possible configurations of the CSP rather than discovering them during search. For mixed problems, we present an enumeration scheme that integrates numeric variables with discrete ones in a single search process. Both techniques take advantage of enhanced propagation rule for numeric variables that results in tighter labelings than the algorithms commonly used. From real world examples in configuration and design, we identify several types of mixed constraints, i.e. constraints defined over numeric and discrete variables, and propose new propagation rules in order to take advantage of these constraints during problem solving.", "authors": ["Esther Gelle", "Boi Faltings"], "n_citation": 89, "references": ["06bee4ac-7900-4247-988b-fd9c5feba6af", "0e2b7c65-3e1e-4f62-8815-ee71a8519c36", "2fb3bd66-88e0-4769-b0ae-3fbdc59cbbef", "39f662c4-2733-4f70-95bc-6c561d91f166", "6231277b-cc88-41a4-aecc-8293138d433a", "6ad4875c-1a85-45bd-bc55-ee17afecd3ce", "74cbb8cc-dfb4-4c35-92e1-d194787c57cf", "84f6729f-393a-472e-8aab-2fda338d5748", "8c6d0269-4df0-46de-a5e7-8e223986e44d", "8e8a1e63-a43e-4957-b22c-443bab037a67", "995b150c-6522-4960-a45b-6c5cb8bb3299", "a60b346f-9f08-4775-a599-6790898f6c8d", "ac39dba5-04ee-4ac3-9cc0-75bab50ad629", "bb1daa61-5802-4330-9f05-b77edb8b9d09", "c97bb5ae-bed8-4472-82d4-b132d625b491", "cc307149-72cf-4a35-bcc3-ae45faba38d2", "d16f89db-04bc-40ce-8bcc-ab5c19255de4", "eefe66e0-3602-43fe-b2ec-89c691e58a1e", "f3f31842-d5bc-4ab0-a6f3-b4ca35095917"], "title": "Solving Mixed and Conditional Constraint Satisfaction Problems", "venue": "Constraints - An International Journal", "year": 2003, "id": "97f88369-901d-4199-9a54-6615edf70fd0"}
{"abstract": "In this paper we present the new logic programming language DALI, aimed at defining agents and agent systems. A main design objective for DALI has been that of introducing in a declarative fashion all the essential features, while keeping the language as close as possible to the syntax and semantics of the plain Horn--clause language. Special atoms and rules have been introduced, for representing: external events, to which the agent is able to respond (reactivity); actions (reactivity and proactivity); internal events (previous conclusions which can trigger further activity); past and present events (to be aware of what has happened). An extended resolution is provided, so that a DALI agent is able to answer queries like in the plain Horn--clause language, but is also able to cope with the different kinds of events, and exhibit a (rational) reactive and proactive behaviour.", "authors": ["Stefania Costantini"], "n_citation": 32, "references": ["06e64e99-3717-4646-89e7-941a787fba79", "13308683-9151-4288-97c9-50fbf379a100", "232a8052-ce89-4d07-b392-ce610857e2fe", "3a3050b3-f861-4b1d-baeb-37b3b6a916b3", "51cb282f-23f0-46e0-8ee2-524d50aeb4a6", "5fa570a4-684e-42cd-957b-8c2fddaea7e7", "6d2b1776-1cb6-44c8-8f4b-114202b7d763", "7565eb7f-f8ff-4cbe-9a11-3556366298ec", "febfed39-9cc9-4a47-8047-286706cf5e0d"], "title": "Towards Active Logic Programming", "venue": "arXiv: Artificial Intelligence", "year": 2014, "id": "f4d914ef-305d-4049-b260-bc153aafa8b1"}
{"abstract": "This paper concerns the introduction of an iterator into the refinement calculus. The construct is based on concepts from functional programming, and the work gives an interesting example of cross-fertilisation between the functional and imperative programming worlds. Specifically, the iterator construct it..ti uses the idea of a catamorphism -- the unique homomorphism from an initial algebra. The datatype for which the iterator is to be defined is considered as an initial algebra of an appropriate functor. The it..ti construct is formally defined as a recursive procedure, and it is shown that, if the value to be obtained by an iteration can be expressed as a catamorphism, then the it..ti construct provides a very natural implementation. Examples are given to show typical uses of the new construct.", "authors": ["Steve King", "Carroll Morgan"], "n_citation": 2, "references": ["2ca54b2a-e117-4316-ae94-498c3de35d58", "33bb3d3b-cf44-481b-a6a7-23c7cc2dd219", "35c8c06c-2ad0-46b4-9e92-2d684f3abd94", "3fb0faac-d13d-43c1-bfc9-9dff1b07c660", "4e9842f6-367d-499c-a00f-1a22f61d1caa", "5cef570a-cfa2-462e-820e-05682b0c91f3", "7ed765ec-8ae6-45bf-a90b-bc420900d2f2", "9086a437-bdde-48ba-963b-e9e6991d46f5", "91fa8ca4-6800-4a6b-a229-fe7388a46a61", "970ee1cb-8750-4c8e-8e08-d3a236d843c5", "c711a3aa-9c7d-4b1e-b65c-4ba7d3190e6e", "e5fc0866-ad17-405c-9312-106d67bf5ae2", "f0bc77f3-834c-47d8-bf08-e98a46e6ab3e"], "title": "An iterator construct for the refinement calculus", "venue": "formal methods", "year": 2000, "id": "d01cc77d-1166-480e-8d44-6cfd53fb1ce8"}
{"abstract": "In this paper we consider how energy efficiency aspects can be added to Openstack. With the objective of devising an energy efficient resource manager for Openstack, we first analyze resource and energy utilization on our cloud resources. We observe that there is a large fixed cost associated with server usage patterns and powering down servers is necessary to achieve energy savings. Following this we consider migration mechanisms which are necessary to perform load consolidation: we find that hybrid live migration has the necessary robustness to be part of a sophisticated load management solution. Finally we discuss ongoing work on realizing a load manager for Openstack based on these observations.", "authors": ["Vojtech Cima", "Bruno Grazioli", "Se\u00e1n Murphy", "Thomas Michael Bohnert"], "n_citation": 1, "references": ["0011d1fc-f7c1-4bcd-af19-5cc4b130153e", "03aad60f-40af-4ea0-a9ce-b19f66020b3c", "4176c232-fa9d-4540-a778-d2fe285cd2ae", "eb428b4f-c49c-430d-a079-e04ef031cddd"], "title": "Adding energy efficiency to Openstack", "venue": "", "year": 2015, "id": "5c850d63-fce5-406e-b900-e9e4e6e28ee4"}
{"abstract": "Temporal Petri nets are Petri nets in which certain restrictions on the firings of transitions are represented by formulas containing temporal operators. The use of temporal Petri nets for formal specification and verification of the alternating bit protocol is discussed. The temporal Petri net which models the protocol is analyzed formally using the existing theory of omega -regular expressions and Buchi-automata. >", "authors": ["Ichiro Suzuki"], "n_citation": 63, "references": ["239df21d-c413-40b2-8aad-772afacaa33e", "2bb4d065-418c-43ea-808d-cce74899d639", "41c2b0a3-9a16-46d0-b201-adfeff668c0b", "68488374-d54a-4e50-b198-3e85eda36762", "86718b68-beb2-4201-8bce-845a80302bd2", "9c00b540-465c-4559-ad30-09c09cbea903", "a963d780-e980-4e8f-ac94-83943241ede0", "c875dc71-072e-43bb-af97-298f46c6e2d6", "e1161405-6718-4983-8717-1354ecac5401", "e699fb63-c9b6-450e-bbf4-ec1aaee95def", "ed8dc42b-c472-4fcc-9d0a-55f3043446dc"], "title": "Formal analysis of the alternating bit protocol by temporal Petri nets", "venue": "IEEE Transactions on Software Engineering", "year": 1990, "id": "9f3cea46-627e-40a2-8b2c-912b7457eec0"}
{"abstract": "In the software engineering field, reuse is considered the key for achieving quality, reducing costs and increasing productivity. Such expectations motivate the proposition of generic, reusable solutions for the development of applications in various domains. In this paper, we address some initial considerations on the potentials of object-oriented reuse technology, particularly frameworks, in the computer-supported cooperative learning (CSCL) domain. The paper discusses the important aspects of such technology, the difficulties for defining expected functionality for CSCL applications, and describes some of the existing customizable solutions for the CSCL domain. Two of them, namely TOP and Habanero, are analyzed in more detail.", "authors": ["Karin Becker", "Ana P. T. Bacelo Blois"], "n_citation": 7, "references": ["0a112c4e-29b1-44b1-affd-01328fc70f0d", "8ec7b584-8c6d-4fa3-8fe2-40e303180f55", "9f7c7efc-4ce1-4ce9-8db5-f9c3553d8eef", "ad700f66-a46c-4669-84a4-eb9aa13923c2", "c24988eb-1786-4e97-96cf-9660531da324", "cf73b979-2fa8-4fdb-b772-46d3173278f2", "e3d3dd16-8d48-4570-8046-336d9efe35f8"], "title": "Considerations on the application of object-oriented reuse technology to the computer-supported cooperative learning domain", "venue": "", "year": 2001, "id": "b8f6c70f-9c0a-46c2-b20e-7bf3ab1b8a68"}
{"abstract": "Pseudo-code written in natural language can aid the comprehension of source code in unfamiliar programming languages. However, the great majority of source code has no corresponding pseudo-code, because pseudo-code is redundant and laborious to create. If pseudo-code could be generated automatically and instantly from given source code, we could allow for on-demand production of pseudo-code without human effort. In this paper, we propose a method to automatically generate pseudo-code from source code, specifically adopting the statistical machine translation (SMT) framework. SMT, which was originally designed to translate between two natural languages, allows us to automatically learn the relationship between source code/pseudo-code pairs, making it possible to create a pseudo-code generator with less human effort. In experiments, we generated English or Japanese pseudo-code from Python statements using SMT, and find that the generated pseudo-code is largely accurate, and aids code understanding.", "authors": ["Yusuke Oda", "Hiroyuki Fudaba", "Graham Neubig", "Hideaki Hata", "Sakriani Sakti", "Tomoki Toda", "Satoshi Nakamura"], "n_citation": 32, "references": ["06ba8c41-6f82-4722-b0af-4260612387c8", "096a89c0-096e-4ede-8149-8afe4810e28b", "1268112c-a3a5-411d-9469-c9937aed533e", "1846e33e-cb41-46f4-904d-9bbed8abf5fc", "19108e2f-ac11-4bc6-9ef9-0bc9cc9ace76", "259c2a82-15f9-4709-bb22-458fa038d5e6", "2da5f9dd-3b9a-40f5-99cf-2f44a9219666", "3c22868d-d6da-4e8d-8325-3683605a4293", "3c3dc25e-5189-4eb2-99f8-c36150af4021", "4eaf5bba-9100-4330-a7d8-91d527cc3c9d", "5443ee2f-a083-4829-bfd3-b92e50b6d78e", "6180adcc-0954-4951-8807-64b649dcb5ce", "6b462d8d-e218-4614-88ef-d5c58227e227", "751e1f20-9f17-448b-8d01-00afa01839ba", "7df69d77-1858-48c8-a658-c978de6ae049", "7e551e83-e81d-4113-98b8-01a680e73bc3", "8da8f929-f124-470b-ae62-0ebb499ba10c", "92f5bfa2-3877-40f8-a894-d3c5f4f8254e", "9735980d-18cd-475d-8605-23b493d4e406", "99063540-5350-4d69-b140-c6c2b34ceb34", "c1c634fa-13aa-4e6e-8273-f1365b43b246", "c2f21ae4-81c9-4dc6-95f0-661f8b6a55e6", "d4faa0de-0cb0-4c04-a8d4-6534092489c3", "d63aa78b-6056-49da-b04a-afd8ba945d3c", "e52d3690-0e47-4d82-a383-49bb4bb28c32", "e5f98b05-e091-480d-aae4-721644485c8d", "e94efccd-b842-40ac-bc53-c71216ea8ea6", "ea201f9b-6ae7-4d19-b761-8d959814b969", "ede81ef9-f018-4fe8-a37b-4a22858f2c5a"], "title": "Learning to Generate Pseudo-Code from Source Code Using Statistical Machine Translation (T)", "venue": "automated software engineering", "year": 2015, "id": "32066f8a-411d-4839-95a2-5e58f8e8f174"}
{"abstract": "In this paper we address the problem of multi-objective attribute selection in data mining. We propose a multi-objective genetic algorithm (GA) based on the wrapper approach to discover the best subset of attributes for a given classification algorithm, namely C4.5, a well-known decision-tree algorithm. The two objectives to be minimized are the error rate and the size of the tree produced by C4.5. The proposed GA is a multi-objective method in the sense that it discovers a set of non-dominated solutions (attribute subsets), according to the concept of Pareto dominance.", "authors": ["Gisele L. Pappa", "Alex Alves Freitas", "Celso A. A. Kaestner"], "n_citation": 49, "references": ["599bcd08-2ee6-4fbb-84d4-a701868acb93", "62549bc2-e0b3-46e8-8d32-390dded105d5", "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "6fe0a71c-4f95-4a54-8ef6-3d9a4be559a4", "9b80e173-2d0d-4e2d-8cd0-0fcfe230fd81"], "title": "Attribute Selection with a Multi-objective Genetic Algorithm", "venue": "brazilian symposium on artificial intelligence", "year": 2002, "id": "438a4c63-677a-48fe-97ad-d155f89ba944"}
{"abstract": "Fairground: Thrill Laboratory was a series of live events that augmented the experience of amusement rides. A wearable telemetry system captured video, audio, heart-rate and acceleration data, streaming them live to spectator interfaces and a watching audience. In this paper, we present a study of this event, which draws on video recordings and post-event interviews, and which highlights the experiences of riders, spectators and ride operators. Our study shows how the telemetry system transformed riders into performers, spectators into an audience, and how the role of ride operator began to include aspects of orchestration, with the relationship between all three roles also transformed. Critically, the introduction of a telemetry system seems to have had the potential to re-connect riders/performers back to operators/orchestrators and spectators/audience, re-introducing a closer relationship that used to be available with smaller rides. Introducing telemetry to a real-world situation also creates significant complexity, which we illustrate by focussing on a moment of perceived crisis.", "authors": ["Holger Schn\u00e4delbach", "Stefan Rennick Egglestone", "Stuart Reeves", "Steve Benford", "Brendan Walker", "Michael Wright"], "n_citation": 69, "references": ["167f6fe9-5d82-4ea5-acf0-27cfabf32036", "28b6bbab-2131-4259-83c0-8201ef763f17", "39d1f0e5-0fe0-4cd6-819e-5609a73d7631", "58064cfa-b7be-4ed0-8eab-bf1b4ab35bbb", "7c2e91df-6ae8-4338-8149-218d4452751e", "8dfccfbb-73f0-4dd0-9247-9ad3045ed751", "d55be88e-c7cf-4bf4-93d5-99bbee40bfac", "fd301a66-c05e-4b6b-b48a-92bee94cf3e2"], "title": "Performing thrill: designing telemetry systems and spectator interfaces for amusement rides", "venue": "human factors in computing systems", "year": 2008, "id": "e620e212-bf4f-4fb0-9182-fdfb92317edd"}
{"abstract": "A new approach of reliable image and video transmission over noisy channels is proposed. For subband decomposed image and video, combined source coding and channel modulation design can achieve high compression efficiency and preferable quality. Further performance gain is obtained by multiresolution modulation as well as a bit remapping scheme that assigns efficient mapping from each source codeword to channel modulation points. We show that the combined source coding and modulation design outperforms conventional approaches, which design source coding and modulation separately. A simple channel distortion approximation is derived by applying a bit-remapping scheme, which allows the power allocation to be employed to further enhance the performance. Compared to the joint source and channel coding with a binary phase shift keying modulation system and fixed modulation with the one-to-one intelligent mapping system, the proposed system performs better in a middle-range signal-to-noise ratio and low channel bandwidth. The simulation is carried out on additive white Gaussian noise channels.", "authors": ["Haitao Zheng", "K.J.R. Liu"], "n_citation": 33, "references": ["0b578f69-c39b-406b-a73b-b321bbecf507", "0d7a4be0-8cb4-42be-972d-3f072f288449", "122039c4-2605-46c7-8a77-f831b352b790", "3027eafe-243e-44d3-b27c-d8391c0d9686", "359bfefd-c7d6-4f92-a392-0164a70facdc", "37708b6d-80cd-4d60-bc32-9255c830032a", "41ee7ee4-7f98-456a-bf3c-cd9c32c4f98b", "4abe3d2b-433d-4f49-8c6d-87755a437154", "7a0dd21d-8732-4db0-8473-9ee90dcd2f9f", "938b98e9-7c7e-4d9e-9d26-53f5f9c44c25", "a2e1ddb4-e0b8-42b8-ae39-4c15e8d65f27", "b8af4d40-3f7c-4432-8f60-de4dbaa7c701", "cfb21f03-9839-4785-8335-df1984bfdd4b", "d919ead1-c1be-407c-b256-a99d8180225d", "e850b2ab-a70b-4068-915e-7ec67f91ca6c"], "title": "The subband modulation: a joint power and rate allocation framework for subband image and video transmission", "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "year": 1999, "id": "23f7bb98-14de-4c15-8019-47acbb2221e5"}
{"abstract": "Digital watermarking is an emerging research area for copyright protection of electronic documents and media, which is one of the most important problems to be solved in the cyberspace society. A statistic approach for embedding and extracting a digital watermark on an image is proposed. This approach is based on the realization that a stego-image after watermark attacks should preserve the characteristics of the stego-image if the stego-image after attacks retains its commercial values. In other words, the appearance of the image after attacks is still clearly visible and similar to the original image. This kind of preservation can be reflected as the variances of color levels of pixels both in stego-without-attacks- and stego-with-attacks-images are most likely the same. The embedded digital watermark by this approach seems robust after several attacks are performed on the stego-image.", "authors": ["Pei-Min Chen"], "n_citation": 11, "references": ["1bcb66df-8d4f-4c8c-b1a9-27ebcf683847", "45abd8c1-38ec-44e4-bd25-2e467ef30e6e", "9d04ddd4-5265-452c-8cc2-d8ba82a8bea4", "a22f0114-5c79-41b8-9fbe-f467a074592b", "a8cf2d7f-a3e9-40cb-96b1-f49b1c6403d6", "b5bc85f7-6555-42ae-8697-67a1ab3cfca6", "c4703cf0-1bb7-4694-b294-26f320310d96", "d23ae5f9-2910-4c70-82c1-94667142ae0d", "d4e86eda-1bb0-4e9a-8aec-163bd3b02305", "f9c799fc-c3ba-41f1-9dab-d1b7525bb5eb"], "title": "A robust digital watermarking based on a statistic approach", "venue": "", "year": 2000, "id": "f0074c66-983e-4efb-a8b9-38e62c812920"}
{"abstract": "Uninfluenced social systems often exhibit suboptimal performance; a common mitigation technique is to charge agents specially-designed taxes, influencing the agents' choices and thereby bringing aggregate social behavior closer to optimal. In general, the efficiency guaranteed by a particular taxation methodology is limited by the quality of information available to the tax-designer. If the tax-designer possesses a perfect characterization of the system, it is often straightforward to design taxes which perfectly optimize the behavior of the agent population. In this paper, we investigate situations in which the tax-designer lacks such a perfect characterization and must design taxes that are robust to a variety of model imperfections. Specifically, we study the application of taxes to a network-routing game, and we assume that the tax-designer knows neither the network topology nor the tax-sensitivities and demands of the agents. Nonetheless, we show that it is possible to design taxes that guarantee that network flows are arbitrarily close to optimal flows, despite the fact that agents' tax-sensitivities are unknown to us. We term these taxes \u201cuniversal,\u201d since they enforce optimal behavior in any routing game without a priori knowledge of the specific game parameters. In general, these taxes may be very high; accordingly, for affine-cost parallel-network routing games, we explicitly derive the optimal bounded tolls and the best-possible efficiency guarantee as a function of a toll upper-bound.", "authors": ["Philip N. Brown", "Jason R. Marden"], "n_citation": 8, "references": ["07871fe9-13c6-478e-bfed-2cb521d8a411", "0cfd7d6d-0a54-4f00-ac15-3207222bf3d4", "33e5b7f8-f8e4-4be4-98b0-2d62bfe9fa13", "534029ee-d93f-4652-97f6-f6ef4e9f43b5", "5deaddec-33d4-456f-b3fb-d9f0af46e699", "b55b81c2-3494-4e9c-b624-cf8ca57163cf", "ddcf1eff-07dc-48d4-b8c8-1c7eab1dfab2", "ef07e08c-2606-4773-bd0c-b403b6b4924a"], "title": "Optimal mechanisms for robust coordination in congestion games", "venue": "conference on decision and control", "year": 2015, "id": "0b6c3baf-d6af-4a78-867f-57ee6ccafde4"}
{"authors": ["David Scott Warren", "Saumya K. Debray"], "n_citation": 64, "references": ["1db06cc5-71d7-4060-ac11-2e7c10ba9925", "3018b561-5d3e-4adf-82d8-672890f7e521", "729d25fb-50de-4363-8a39-2326e703de82", "a0804928-eada-46c9-9bbf-389b26a6cc66"], "title": "Detection and optimization of functional computations in Prolog", "venue": "international conference on logic programming", "year": 1986, "id": "642a2e1c-1313-467a-9fd5-ee9a223979c9"}
{"abstract": "Workloads drive architecture design and will change in the next two decades. For high-performance, general-purpose processors, there is a consensus that multimedia will continue to grow in importance. The authors predict these processors will incorporate more media processing capabilities, eventually bringing about the demise of specialized media processors, except perhaps, in embedded applications. These enhanced general-purpose processor capabilities will arise from multimedia applications that require real-time response, continuous-media data types and significant fine-grained data parallelism.", "authors": ["Keith Diefendorff", "Pradeep Dubey"], "n_citation": 297, "title": "How multimedia workloads will change processor design", "venue": "IEEE Computer", "year": 1997, "id": "9ca8cf5a-e2ce-434c-bfa6-6fc7c1c90765"}
{"abstract": "Since smartphones have stored diverse sensitive privacy information, including credit card and so on, a great deal of malware are desired to tamper them. As one of the most prevalent platforms, Android contains sensitive resources that can only be accessed via corresponding APIs, and the APIs can be invoked only when user has authorized permissions in the Android permission model. However, a novel threat called privilege escalation attack may bypass this watchdog. It's presented as that an application with less permissions can access sensitive resources through public interfaces of a more privileged application, which is especially useful for malware to hide sensitive functions by dispersing them into multiple programs. We explore privilege-escalation malware evolution techniques on samples from Android Malware Genome Project. And they have showed great effectiveness against a set of powerful antivirus tools provided by VirusTotal. The detection ratios present different and distinguished reduction, compared to an average 61% detection ratio before transformation. In order to conquer this threat model, we have developed a tool called DroidAlarm to conduct a full-spectrum analysis for identifying potential capability leaks and present concrete capability leak paths by static analysis on Android applications. And we can still alarm all these cases by exposing capability leak paths in them.", "authors": ["Yibing Zhongyang", "Zhi Xin", "Bing Mao", "Li Xie"], "n_citation": 50, "references": ["2f96468d-190c-4d80-92f6-c64eeea9040a", "47b04fc1-5f76-4454-b744-db2709840a5f", "5190b376-7923-445f-a891-d1bac46fd35d", "60f32cb8-b61a-464b-a20a-b98f14e20aab", "6c5d5bb4-52ed-45da-bceb-71525b70fafc", "96bfd4e8-10d3-45dc-a305-c1632beb27cb", "c140fcc3-ae8f-499b-be4e-1b40bf5e933a", "dd12844b-dffa-4f60-a08d-11db76365714", "fc2384c8-1124-48ac-b4e9-fcb5715d3f45"], "title": "DroidAlarm: an all-sided static analysis tool for Android privilege-escalation malware", "venue": "computer and communications security", "year": 2013, "id": "7fca5ad8-5435-4b7d-bb78-b43b62c0e1ed"}
{"abstract": "3D BINARY IMAGES. Basics. Features of 3D Components. Operations on 3D Binary Images. 3D GREY LEVEL IMAGES. Images Enhancement. Geometric Transformations of Voxel Images. Surface Segmentation. Region Segmentation. MODELLING AND REGISTRATION OF OBJECTS. Surface Tiling. Surface Reconstruction. Registration. Appendix. References. Index.", "authors": ["Gabriele Lohmann"], "n_citation": 267, "title": "Volumetric Image Analysis", "venue": "", "year": 1998, "id": "3f4d2eaf-5b31-4b03-a3ce-31d82afcd8cc"}
{"abstract": "We discuss the interpretation of read and write frames in model-oriented specification taking the B's generalised substitutions as the vehicle for the presentation. In particular, we focus on the interpretation of read frames, the semantics of which have not been considered by previous authors. We gives several examples of the relevance of read frames and show that a substitution admits a read respecting implementation if and only if a certain bisimulation condition is satisfied. We use this to motivate a richer semantic model for substitutions which interprets read and write constraints directly in the denotation of a substitution. This semantics yields some non-interference results between substitutions which cannot be given at this level without the use of read and write frames.", "authors": ["Juan Bicarregui"], "n_citation": 50, "references": ["0d995f1f-d3ea-4c1b-b0cc-3fa301ec010e", "15d338d2-1dd3-4637-b964-34a9b88d9c1d", "3023929a-c93e-49c5-b03f-7fb0414d94df", "3fb0faac-d13d-43c1-bfc9-9dff1b07c660", "5bc86a22-af3f-47b6-9baa-c9035a0c1c3d", "ded2f7d7-c4fd-4ccc-8de1-e0e3b0fd9e63", "e711d562-4777-4e97-b42e-af0e4cf63393"], "title": "Do Not Read This", "venue": "formal methods", "year": 2002, "id": "1b52a948-9a08-44ce-9998-956721155b44"}
{"abstract": "A central challenge in the runtime management of computing environments is the necessity to keep these environments continuously optimized. In this paper we introduce a new paradigm, which focuses on self-optimization according to high-level business objectives such as maximizing revenues. It replaces the more traditional optimizations that are based upon IT measures such as resource availability. A general, autonomous process is defined to enable such optimizations, and a set of technologies and methodologies is introduced to support the implementation of such a process. The paper concludes with two types of validation tests carried out on an eCommerce site, that demonstrate the value and applicability of this approach.", "authors": ["Sarel Aiber", "Dagan Gilat", "Ariel Landau", "Natalia Razinkov", "Aviad Sela", "Segev Wasserkrug"], "n_citation": 88, "references": ["01748082-154c-41ba-9a54-b0ffa26c2191", "1ea412cf-ceb9-46fe-90f4-c8f7c1676ee1", "64893998-af0e-4a21-844d-7bb2bbc0ea6a", "80cc7370-aaf8-419d-8c5f-46a0000e5f49", "b0148304-9034-45e9-94e8-daca44de29d3", "b82c9947-e49a-4bb4-b747-d5c115e74a0a"], "title": "Autonomic self-optimization according to business objectives", "venue": "international conference on autonomic computing", "year": 2004, "id": "78693c03-a574-4915-a489-7e60d3b827cc"}
{"abstract": "A set equations in the quantities  a i  ( p ), where  i  = 1, 2, \u00b7 \u00b7 \u00b7,  m  and  p  ranges over a set  R  of lattice points in  n -space, is called a  system of uniform recurrence equations  if the following property holds: If  p  and  q  are in  R  and  w  is an integer  n -vector, then  a i  ( p ) depends directly on  a j  ( p  -  w ) if and only if  a i  ( q ) depends directly on  a j  ( q  -  w ). Finite-difference approximations to systems of partial differential equations typically lead to such recurrence equations. The structure of such a system is specified by a  dependence graph G  having  m  vertices, in which the directed edges are labeled with integer  n -vectors. For certain choices of the set  R , necessary and sufficient conditions on  G  are given for the existence of a schedule to compute all the quantities  a i  ( p ) explicitly from their defining equations. Properties of such schedules, such as the degree to which computation can proceed \u201cin parallel,\u201d are characterized. These characterizations depend on a certain iterative decomposition of a dependence graph into subgraphs. Analogous results concerning implicit schedules are also given.", "authors": ["Richard M. Karp", "Raymond E. Miller", "Shmuel Winograd"], "n_citation": 728, "references": [], "title": "The Organization of Computations for Uniform Recurrence Equations", "venue": "Journal of the ACM", "year": 1967, "id": "4b1f6789-efb1-4695-93e1-b0ef642859f9"}
{"abstract": "The purpose of documentation is to describe software systems and software processes. Consistent, correct and complete documentation of a software system is an important vehicle for the maintainer to gain its understanding, to ease its learning and/or relearning processes, and to make the system more maintainable. Poor system documentation, on the other hand, is the primary reason for quick software system quality degradation and ageing. Proper process documentation records the process, its stages and tasks, executing roles, their decisions and motivations, and the results of each individual process task. It is extremely important for achieving insight and visibility into the processes, important for their meaningful process measurement and thereby pivotal for achieving high process maturity. In this paper, we report on the results of an explorative study in which we have identified a number of rudimentary documentation requirements relevant within corrective maintenance, and found out how they were implemented within eighteen software organizations in Sweden. The goal was to examine the industrial documentation practice within corrective maintenance. Our results show that the documentation within corrective maintenance is still a very neglected issue within the organisations studied. None of our organisations has fully implemented all our documentation requirements.", "authors": ["Mira Kajko-Mattsson"], "n_citation": 53, "references": ["1df189b1-6ede-4e50-a1eb-6c8ace75462b", "3953501e-9af9-41b6-8466-b2c608d856ec", "397522cc-cb26-45fe-9a29-0fd41d9bb4e9", "7342bad3-0814-40fc-912b-e4d037a7e154", "7a9db9d9-46cb-4377-babc-d6fe708f4556", "95a5bfc6-279b-4455-9a04-ace6dc12891d", "a76b3489-ad2d-480c-9045-f1c11f06cfcc", "e143c8b2-d125-4999-bfb5-07d324b134f3", "e528dc62-3859-4e70-9342-2c724a4dddfb"], "title": "A Survey of Documentation Practice within Corrective Maintenance", "venue": "Empirical Software Engineering", "year": 2005, "id": "e36fafb8-55b3-46f4-885b-8096894d2fd2"}
{"abstract": "A general method for planning and orbitally stabilizing periodic motions for impulsive mechanical systems with underactuation one is proposed. For each such trajectory, we suggest a constructive procedure for defining a sufficient number of nontrivial quantities that vanish on the orbit. After that, we prove that these quantities constitute a possible set of transverse coordinates. Finally, we present analytical steps for computing linearization of dynamics of these coordinates along the motion. As a result, for each such planned periodic trajectory, a hybrid transverse linearization for dynamics of the system is computed in closed form. The derived impulsive linear system can be used for stability analysis and for design of exponentially orbitally stabilizing feedback controllers. A geometrical interpretation of the method is given in terms of a novel concept of a moving Poincare section. The technique is illustrated on a devil stick example.", "authors": ["Anton S. Shiriaev", "Leonid B. Freidovich"], "n_citation": 49, "references": ["4fc2d5a1-119a-404b-b4eb-4a6e44860907", "7aabb1a4-ff56-4d28-9df4-5f19fac0fdc3", "7ecb785a-4abe-4198-a7c7-d346d74cc771", "cf379c1f-7c2a-4b42-af46-673a9be1fcb2"], "title": "Transverse Linearization for Impulsive Mechanical Systems With One Passive Link", "venue": "IEEE Transactions on Automatic Control", "year": 2009, "id": "37b45aeb-1557-4079-a14c-63502d0e31a1"}
{"abstract": "This paper presents a problem-space genetic algorithm (PSGA)-based technique for efficient matching and scheduling of an application program that can be represented by a directed acyclic graph, onto a mixed-machine distributed heterogeneous computing (DHC) system. PSGA is an evolutionary technique that combines the search capability of genetic algorithms with a known fast problem-specific heuristic to provide the best-possible solution to a problem in an efficient manner as compared to other probabilistic techniques. The goal of the algorithm is to reduce the overall completion time through proper task matching, task scheduling, and inter-machine data transfer scheduling in an integrated fashion. The algorithm is based on a new evolutionary technique that embeds a known problem-specific fast heuristic into genetic algorithms (GAs). The algorithm is robust in the sense that it explores a large and complex solution space in smaller CPU time and uses less memory space as compared to traditional GAs. Consequently, the proposed technique schedules an application program with a comparable schedule length in a very short CPU time, as compared to GA-based heuristics. The paper includes a performance comparison showing the viability and effectiveness of the proposed technique through comparison with existing GA-based techniques.", "authors": ["Muhammad K. Dhodhi", "Imtiaz Ahmad", "Anwar Yatama", "Ishfaq Ahmad"], "n_citation": 144, "references": ["2e3da10b-cfe9-4ae3-b022-e8f596ae3634", "42352e2e-096e-4846-b5da-c2b041b1013a", "5fff9a52-b624-48fe-bf88-ac96ed74e44b", "61d2dcc6-e3af-4b31-b42c-46d7f054325f", "645482c8-d386-4ff1-84a4-1aaff9848f4e", "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "70a34d8e-9f9c-40b6-8d3a-9c3eba174c13", "8bcf85a5-ca2d-43b9-9185-128fc78cef90", "97ad9a2d-7109-4be2-9bb8-750fdb4e3c14", "9b80e173-2d0d-4e2d-8cd0-0fcfe230fd81", "a32d8f2f-60c1-40a5-b344-106acf67306f", "b27864f4-25c7-423a-8556-594367a8ea83", "b3c0320e-5525-49a7-a308-489ce23cb76c", "b570e9f7-e517-4e71-82cf-461cfe05e3b7", "d4128520-65e4-429b-9ccb-e930c148f12e"], "title": "An integrated technique for task matching and scheduling onto distributed heterogeneous computing systems", "venue": "Journal of Parallel and Distributed Computing", "year": 2002, "id": "506d2a83-95c8-49ba-aca6-5d8139f3415d"}
{"abstract": "We introduce a new context classification and recognition framework for the development and deployment of mobile, context-aware applications. The framework is complemented with an energy calculator that specifically assists mobile developers in estimating the energy footprint of context-aware applications during the development process with the framework. The framework abstracts from the raw context information gathering, allows for sensor fusion, enables the prediction of custom and higher-level contexts, and provides for context sharing. 1. Introduction and Motivation The evolution of mobile devices and the general availability of information sources that describe the situation and environment (i.e., the context) of mobile users offer new opportunities for innovative applications (1). By constantly monitoring the contexts in which mobile users are situated, applications obtain a potential to adapt their behaviour to current contexts more intelligently and without user intervention. However, such mobile context awareness comes at a price: Novel challenges of the mobile environment and specific constraints of mobile devices and their use (e.g., limited battery life, a comparably small screen size, dependence on network infrastructure) can severely impact the acceptance of mobile context-based approaches. In addition, adequate developer support for the realisation of context-aware applications is currently lacking. Consequently, most application developers are on their own when realising the sensing and interpreting of context information, or the sharing of context. With the increasing interest in, and a growing market for, context-aware applications, developers are more and more in charge of carefully designing context-aware applications and they need to be able to competently address issues such as privacy (2), availability, precision of context recognition, or energy requirements. In this contribution, we address the energy-related implications of developers' choices of sensing components, processing algorithms, and granularity or temporal frequency of sensing. We specifically aim at developer energy awareness and present CONTEXTO, an energy-aware framework for offline context classification and recognition on mobile devices. The framework provides a layered, component-based architecture that can easily be extended, modified, or customised. It follows established software engineering patterns to provide high learnability and a low threshold for beginners. Within the framework, the energy requirements for all used components on a specific device are always made transparent, and information about energy requirements can be used early in the design process with the help of the framework's energy calculator, and at runtime.", "authors": ["Maximilian Schirmer", "Sven Bertel", "Jonas Pencke"], "n_citation": 4, "references": ["0acc1345-fdf9-4861-a35b-ec47264d5496", "3981790d-d2e8-4d32-aadb-d58b66502700", "9b6c164f-ba19-47ea-a344-fca0a93101f4", "9bfa45c5-7c26-4007-adcc-bcf1a3c41907", "9fdeed08-1a74-4ca8-ab49-39c8270345b0", "b7a706c5-ba7b-45f5-a10e-e3a68ac91a0b", "e2593748-76d0-41b2-ac6b-1f72abea0652", "f4896738-7b31-420e-9b23-6093f05dd8d5"], "title": "CONTEXTO: Leveraging Energy Awareness in the Development of Context-Aware Applications", "venue": "", "year": 2014, "id": "20fbe127-327a-4258-93e8-3bfcce00076a"}
{"abstract": "In this paper, we present lower and upper bounds for the independence number @a(G) and the clique number @w(G) involving the Laplacian eigenvalues of the graph G.", "authors": ["Mei Lu", "Huiqing Liu", "Feng Tian"], "n_citation": 15, "references": ["1a8887db-49bd-40b4-9935-c64b88f18763", "272cbcde-5144-484d-8084-c1d4acff9363", "2c44b633-654d-4381-9ab0-5127fba45449", "7b75b5c8-7915-4085-9d46-c292b5a9a2b0", "7c7f9ff9-5de1-408f-9d2b-623bd72c956e", "def06266-2d95-4369-bd5b-8814994a040f"], "title": "Laplacian spectral bounds for clique and independence numbers of graphs", "venue": "Journal of Combinatorial Theory", "year": 2007, "id": "81206ef9-a118-4f3d-a978-19ce914c1631"}
{"abstract": "This paper proposes S-MAC, a medium-access control (MAC) protocol designed for wireless sensor networks. Wireless sensor networks use battery-operated computing and sensing devices. A network of these devices will collaborate for a common application such as environmental monitoring. We expect sensor networks to be deployed in an ad hoc fashion, with individual nodes remaining largely inactive for long periods of time, but then becoming suddenly active when something is detected. These characteristics of sensor networks and applications motivate a MAC that is different from traditional wireless MACs such as IEEE 802.11 in almost every way: energy conservation and self-configuration are primary goals, while per-node fairness and latency are less important. S-MAC uses three novel techniques to reduce energy consumption and support self-configuration. To reduce energy consumption in listening to an idle channel, nodes periodically sleep. Neighboring nodes form virtual clusters to auto-synchronize on sleep schedules. Inspired by PAMAS, S-MAC also sets the radio to sleep during transmissions of other nodes. Unlike PAMAS, it only uses in-channel signaling. Finally, S-MAC applies message passing to reduce contention latency for sensor-network applications that require store-and-forward processing as data move through the network. We evaluate our implementation of S-MAC over a sample sensor node, the Mote, developed at University of California, Berkeley. The experiment results show that, on a source node, an 802.11-like MAC consumes 2-6 times more energy than S-MAC for traffic load with messages sent every 1-10 s.", "authors": ["Wei Ye", "John S. Heidemann", "Deborah Estrin"], "n_citation": 6474, "references": ["0b93552e-74e8-483f-82cb-5c04e1cd9232", "1dd8c68d-3b20-4171-9245-3a12c64c2838", "2088d2fd-d0ed-477f-b350-5d342624e91e", "23dd7fc0-1ebd-43ce-ab3e-43896512c209", "330841ef-6d92-4fe7-aebe-c8e7abaf9cd2", "4f60dbc7-9647-4b91-b96f-9f77d07fea7c", "55a6413a-4a9c-4e8d-957b-8c1a4e5d5f0b", "6858fa05-89cf-48b9-ab78-507b868de4bd", "73574f5f-bf4f-44fb-b13f-d5eaa8c96619", "afc06b7c-7fb3-4f88-942b-3076ed77920e"], "title": "An energy-efficient MAC protocol for wireless sensor networks", "venue": "international conference on computer communications", "year": 2002, "id": "85352dec-58be-43db-a428-f3f574ff96ec"}
{"abstract": "We are concerned with functions over words which are computable by means of a rewrite system admitting polynomial interpretation termination proofs. We classify them according to the interpretations of successor symbols. This leads to the definition of three classes, which turn out to be exactly the poly-time, linear exponential-time and doubly linear exponential time computable functions. As a consequence, we also characterize the linear space computable functions.", "authors": ["Guillaume Bonfante", "Adam Cichon", "Jean-Yves Marion", "H\u00e9l\u00e8ne Touzet"], "n_citation": 26, "references": ["3cfc8d40-8a97-4fd1-8d66-33caf713a389", "9e1bdf7e-e23b-4bd3-b7b7-f0e1d7ac9eec", "a8382265-0dc4-44b4-b81b-133bae0b8aba", "b44551bb-04a8-4d31-9aa5-614fef4cb0fa", "be9bd168-a5a8-4c1a-948f-a55eb578acbc", "ce033196-99f8-4d17-a249-3a7f21186ca0", "d7121b6b-f5f6-41cf-aba2-4a7a40e04b97"], "title": "Complexity Classes and Rewrite Systems with Polynomial Interpretation", "venue": "computer science logic", "year": 1998, "id": "7d4b5e60-532b-4436-a85a-71507a04fda4"}
{"abstract": "The increasing popularity of streaming video is a cause for concern for the stability of the Internet because most streaming video content is currently delivered via UDP, without any end-to-end congestion control. Since the Internet relies on end systems implementing transmit rate regulation, there has recently been significant interest in congestion control mechanisms that are both fair to TCP and effective in delivering real-time streams. In this paper we design and implement a protocol that attempts to maximize the quality of real-time MPEG-4 video streams while simultaneously providing basic end-to-end congestion control. While several adaptive protocols have been proposed in the literature [20,27], the unique feature of our protocol, the Video Transport Protocol (VTP), is the use of receiver side bandwidth estimation. We deploy our protocol in a real network testbed and extensively study its behavior under varying link speeds and background traffic profiles using the FreeBSD Dummynet link emulator [23]. Our results show that VTP delivers consistent quality video in moderately congested networks and fairly shares bandwidth with TCP in all but a few extreme cases. We also describe some of the challenges in implementing an adaptive video streaming protocol.", "authors": ["Alex Balk", "Dario Maggiorini", "Mario Gerla", "M. Y. Sanadidi"], "n_citation": 52, "references": ["01a09d2c-f8d3-40e4-bfee-211533b3f526", "0d087923-1007-4029-9f82-b3ad81bda4a4", "11e1f159-b7ca-4b1e-b2e9-b2ddb4000928", "18016b75-0e79-4cad-9195-88d9c2ed7ed8", "18f9f897-6ea7-4487-9bb6-1cdd7d2da882", "3d67a947-6b49-4f9f-b5de-ef9677aa5fe5", "4db5e58f-e242-41e2-990c-d7199bb78619", "6f9e1127-b4f4-4396-a980-19e9ed315ac1", "75bc1967-6f70-4d1c-bc34-0b47cdbcc6e3", "91a61857-3d7e-4856-bd78-4158c93bed57", "ae597de6-1039-46aa-b442-3317e831daa3", "b3cae739-ffac-48c0-b164-11b3088cc22c", "f962e644-0994-4c6b-90f5-d155b6ef7381"], "title": "Adaptive MPEG-4 Video Streaming with Bandwidth Estimation", "venue": "international workshop on quality of service", "year": 2003, "id": "e16b7870-f3db-4212-9930-7735a43c586a"}
{"abstract": "We present a comprehensive strategy for evaluating image retrieval algorithms. Because automated image retrieval is only meaningful in its service to people, performance characterization must be grounded in human evaluation. Thus we have collected a large data set of human evaluations of retrieval results, both for query by image example and query by text. The data is independent of any particular image retrieval algorithm and can be used to evaluate and compare many such algorithms without further data collection. The data and calibration software are available on-line. We develop and validate methods for generating sensible evaluation data, calibrating for disparate evaluators, mapping image retrieval system scores to the human evaluation results, and comparing retrieval systems. We demonstrate the process by providing grounded comparison results for several algorithms.", "authors": ["Nikhil V. Shirahatti", "Kobus Barnard"], "n_citation": 51, "references": ["01eb92a6-cd44-436f-8a37-ac2934fd0694", "077e70f1-ccc3-4c13-9752-3b0a182e0890", "2328abf0-64d8-41a2-b171-40e85f273245", "23bb366a-01a4-4056-9e76-a91d00199c7b", "2abf79b0-be53-4978-a81e-bf05f9d7a638", "4fd91387-fce5-4148-8b26-4f8ac2ccbcd8", "56d6466f-28bc-429c-a969-9b9609398481", "750b0ac1-2ac9-4273-a9c8-baad11e26fcd", "85dfd5b5-72bb-413d-9e78-74369aeb467e", "8bc5f80f-af26-47b4-aa0a-aab3a2e6c503", "c698b0f4-e5d4-46da-80f1-d6d75fea9ded", "cb5e3b2d-a97e-461f-b99e-d4593d0ef2d7", "cc9253f0-d01f-4ac3-b42e-67c303d48125", "d8b8efc0-4de2-47e0-b05b-5959b61090a5", "ec77182b-f881-41b7-a3c1-10cb9a2c65aa"], "title": "Evaluating image retrieval", "venue": "computer vision and pattern recognition", "year": 2005, "id": "b97b802d-651d-478f-99ad-0cb595cf7ca0"}
{"abstract": "Highlights? We have implemented an autonomous overtaking system in a commercial car. ? The system performs the maneuver as humans do, i.e., depending on the leading vehicle. ? Vision system is use to detect obstacles and to determine its length and width. ? Fuzzy logic was used as control technique to design lateral and longitudinal control. ? Real experiments show the ability of the system to manage any overtaking maneuver. There is clear evidence that investment in intelligent transportation system technologies brings major social and economic benefits. Technological advances in the area of automatic systems in particular are becoming vital for the reduction of road deaths. We here describe our approach to automation of one the riskiest autonomous man?uvres involving vehicles - overtaking. The approach is based on a stereo vision system responsible for detecting any preceding vehicle and triggering the autonomous overtaking man?uvre. To this end, a fuzzy-logic based controller was developed to emulate how humans overtake. Its input is information from the vision system and from a positioning-based system consisting of a differential global positioning system (DGPS) and an inertial measurement unit (IMU). Its output is the generation of action on the vehicle's actuators, i.e., the steering wheel and throttle and brake pedals. The system has been incorporated into a commercial Citroen car and tested on the private driving circuit at the facilities of our research center, CAR, with different preceding vehicles - a motorbike, car, and truck - with encouraging results.", "authors": ["Vicente Milan\u00e9s", "David Fern\u00e1ndez Llorca", "Jorge Villagra", "Joshu\u00e9 P\u00e9rez", "Carlos Iglesias Fern\u00e1ndez", "Ignacio Parra", "Carlos Gonz\u00e1lez", "Miguel \u00c1ngel Sotelo"], "n_citation": 60, "references": ["01ef184b-2018-4f78-a572-2b06bb412aed", "10d2ff77-e43a-4fde-ae54-045c9540f46e", "1bcdb764-020e-4570-8bc4-a8b2997cedf8", "1d744593-5126-4c33-89f8-49995f0c6ea8", "23bf7e70-8af7-4022-a3b3-b3b117f0a70b", "3dd49879-8dc7-4094-956a-680a6cedb157", "461dfb33-eb91-45a3-b94a-e7f1cd948271", "57fb791a-e1b5-4e50-ad27-692db32dd459", "5a929b2f-1ec6-4922-81b9-f7d22327ddcc", "6ff709a9-9f08-480d-8784-a972dc42ad2f", "7f27f3f3-6a4c-4edf-bab8-527e369062f6", "86eb8b94-1d20-4b5c-9ca3-daaa856cb5d5", "896b84a3-f37f-4f5d-8544-4da7f2d75154", "934d5512-c9e6-4ed7-8dd9-e3eafb963ced", "945e256f-52ab-49b7-b13d-5bcfcf042682", "9be9d19a-40df-4ef2-b99a-5430cff4a008", "a8f8b016-d684-4d69-949f-97a57bcdeffe", "abd2fa0d-52a4-4688-a07e-96ee8d19265e", "b37e6058-6853-47b6-8386-043f660df44a", "b3f988a9-a7b2-444f-a069-4dda7b45b770", "e0837843-bc4b-4371-acf7-2012bb9f3fdd", "e7d06734-0180-4609-874e-6a2304890b71", "f0176528-49d7-47aa-855e-aaec31e45d5d", "f3730c93-9972-4564-9a70-74c96132cecf", "fdb3f3df-2ea8-4b74-9bbc-efe40b008726"], "title": "Intelligent automatic overtaking system using vision for vehicle detection", "venue": "Expert Systems With Applications", "year": 2012, "id": "cd8c73a7-d74d-4c0d-b071-3b8b0966c5e4"}
{"abstract": "We describe WebASM, a web-based environment that embeds the CoreASM execution engine in a web page. WebASM provides several advantages to specification writers: 1 complex behaviour expressed via ASM can be made visible by using the full power of the web-based presentation layer; 2 ASM specifications can be edited and run interactively via any web browser; 3 the full CoreASM environment is made available via zero-install deployment, thus eliminating a major barrier to the adoption of the language.#R##N##R##N#In this paper, we briefly outline the technicalities of the approach, present an example, and survey possible applications of WebASM.", "authors": ["Simone Zenzaro", "Vincenzo Gervasi", "Jacopo Soldani"], "n_citation": 50, "references": ["14ec3b53-f6b9-4b12-9ac6-dfe712c39428", "5e3019d6-78a7-476d-a914-ae54755d9c57", "723b3efe-6e68-490b-8649-2a33b49de5ac", "7350431c-2637-4d55-99e4-cd26e1e51cc2", "7412ec0a-ffaf-43f4-b1ec-8412866a2ae6", "790d40e1-b24e-478b-b39c-459bf71df735"], "title": "WebASM: An Abstract State Machine Execution Environment for the Web", "venue": "", "year": 2014, "id": "ffacf5c2-1343-468a-a6a6-a0014936bcf8"}
{"abstract": "Current asynchronous voice messaging interfaces, like voicemail, fail to take advantage of our conversational skills. TalkBack restores conversational turn-taking to voicemail retrieval by dividing voice messages into smaller sections based on the most significant silent and filled pauses and pausing after each to record a response. The responses are composed into a reply, alternating with snippets of the original message for context. TalkBack is built into a digital picture frame; the recipient touches a picture of the caller to hear each segment of the message in turn. The minimal interface models synchronous interaction and facilitates asynchronous voice messaging. TalkBack can also present a voice-annotated slide show which it receives over the Internet.", "authors": ["Vidya Lakshmipathy", "Chris Schmandt", "Natalia Marmasse"], "n_citation": 50, "references": ["2f900c08-b325-47ea-9cfb-f65e39ae3547", "39c2d038-802a-46b7-a9af-4d0bd24c001e", "3aab1e46-9e5d-4643-96de-690f6bc92468", "4e96e830-7148-4a45-97bc-fc76f62cb8ea", "4ead1a92-af9f-46b5-8c00-ead89b068813", "7b7ec885-e864-49d6-bc8c-822ea6b0d835", "7c9a047a-d331-4c8b-8861-8afa1aee9d97", "aaac1da3-8e6f-4857-a8b2-febf12795d8e", "c025d7ef-8a13-414d-92ef-31b1143dc2e0", "c7e9b96e-7c0c-483b-9400-56166488d536", "d336a5fc-9362-4082-afac-92b4b47b0cd4", "e47a5dd1-9db3-490a-a097-dccab0792e69"], "title": "TalkBack: a conversational answering machine", "venue": "user interface software and technology", "year": 2003, "id": "36bf638a-a4a6-44b4-b91c-915523a9ccad"}
{"authors": ["G\u00fcnter Halmans", "Klaus Pohl"], "n_citation": 193, "references": ["20732663-8b39-4f72-a043-d991d9bc2c17", "28d20543-118a-4f4b-acd8-90affb56f3d5", "35f24329-18e0-46a7-9bfc-3fc878d4d1ce", "520e52ab-7d17-46ee-aefc-a10b25656205", "6fdd5992-cf59-45d1-bbef-e85c09b8574e", "705879fb-ea91-4699-a0ca-ae9404676c44", "7f4872b0-d490-4ea5-9a08-514a1f7ee324", "9dcea7b6-2db9-4a58-a67e-1a7ae1206e7a", "f3daecd0-d908-4f87-a14d-da7794474ab7"], "title": "Communicating the variability of a software-product family to customers", "venue": "Software and Systems Modeling", "year": 2003, "id": "4a4795e8-5128-4fd3-94ca-9f9080222301"}
{"abstract": "Abstract#R##N##R##N#\u201cWhat being walks sometimes on two feet, sometimes on three, and sometimes on four, and is weakest when it has the most?\u201d \u2014The Sphinx's Riddle#R##N##R##N##R##N##R##N#Pattern recognition is one of the most important functionalities for intelligent behavior and is displayed by both biological and artificial systems. Pattern recognition systems have four major components: data acquisition and collection, feature extraction and representation, similarity detection and pattern classifier design, and performance evaluation. In addition, pattern recognition systems are successful to the extent that they can continuously adapt and learn from examples; the underlying framework for building such systems is predictive learning. The pattern recognition problem is a special case of the more general problem of statistical regression; it seeks an approximating function that minimizes the probability of misclassification. In this framework, data representation requires the specification of a basis set of approximating functions. Classification requires an inductive principle to design and model the classifier and an optimization or learning procedure for classifier parameter estimation. Pattern recognition also involves categorization: making sense of patterns not previously seen. The sections of this paper deal with the categorization and functional approximation problems; the four components of a pattern recognition system; and trends in predictive learning, feature selection using \u201cnatural\u201d bases, and the use of mixtures of experts in classification. \u00a9 2000 John Wiley & Sons, Inc. Int J Imaging Syst Technol 11, 101\u2013116, 2000", "authors": ["Azriel Rosenfeld", "Harry Wechsler"], "n_citation": 4, "references": ["01570ac6-ab0a-4e78-a145-d65ff4e4ec22", "04159164-700d-4aa5-91f5-f8a17bebfc1a", "09d094ac-d876-4abc-be5e-22b776c2816e", "0ddbfee1-8cc2-49f6-be79-59276f496884", "0f115eea-2272-431f-9f21-6d6789b2bbc9", "110280b6-d76e-4ec5-8209-f05e6675055f", "122da3c1-92a0-44a0-b4c3-888a58689239", "13ad2583-bc27-4f65-81c1-a4d2d211cfa7", "180dea34-18e8-411d-932f-94e714651ac7", "193097e1-2f4d-4430-b379-16efe5fea9b8", "1a642cf3-caad-4cc2-ae3d-82f46013a0be", "1bfa187e-2966-4a8f-ad71-f62a12204971", "1e7292e7-867e-40e1-951b-d4b021521572", "20fb61d7-108f-4045-a45f-1c7db93c3476", "3704f939-09a2-4e9f-b851-1261bcd310df", "383a35cc-9b62-41ba-b07d-99b7a7d46199", "40f728c0-55b3-423b-aff5-a9b3ff27b7d5", "417d1684-e1ae-4fc4-8505-74db0d282011", "41f3b8a9-2d80-4fc6-ab7d-1753b5e4eb9c", "43ebfc6a-57cb-438f-bafa-37d31ea89f62", "4a29b56b-b74e-4945-9017-61a7ab844fd9", "4ccd0131-897c-40dd-aae6-2e5f6b269fa4", "56f4b72a-ec39-47ac-8220-899296e7fb18", "580cb16b-97bf-43ed-8850-85b5918bdb83", "5b38ce2f-9c78-4d6e-850e-c398a8813b67", "5eb1916a-bbf2-4413-b5ba-589c62877ac0", "5ffac6f9-2456-42cf-830c-9049ce37c899", "62549bc2-e0b3-46e8-8d32-390dded105d5", "6c68311c-2745-446f-9c09-df4632392a78", "6c8cffb5-1552-434d-8941-d5fa38cfdfec", "74cf0cba-4174-4b0b-9525-52799e206829", "7ccbdf09-a84e-4ad2-ab20-cb28b6c41155", "7d738632-dc5d-4ec9-a4cd-1d1a74d33166", "85114f9d-70a8-4940-83aa-af504b75acf8", "94898e1d-1e50-41ab-9dcc-2c2e030cddd0", "99f2c01b-6d49-4a93-8723-155698197ed6", "9e984177-249e-4c39-9bad-016ae47aa135", "a62dcfd2-1687-4ba3-8722-8b718ea333c0", "b2f30765-3243-48f6-82c2-0e337c86e993", "b69213be-0c61-4874-9787-a38282c30a7a", "b889d6ec-330d-406f-87b6-ea34804fadfd", "b88e82ed-5123-4d1c-86a1-2e7c6f8aff90", "b8a2354a-b78c-436d-9aa0-5270d88cf418", "bb3c38fa-c2b0-4d4f-8c9d-ca1884343474", "becc43bc-a7b6-46e1-817e-553c84a4a6dd", "c6fb731b-cccf-44f4-bfa8-59e89609ac31", "cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a", "d9752a5a-1603-45cc-9a21-7997750d429f", "da4534a6-897c-4431-89ef-cd326bfaf9a8", "fc443443-416f-4fd5-ba46-17a06046711d"], "title": "Pattern recognition: Historical perspective and future directions", "venue": "International Journal of Imaging Systems and Technology", "year": 2000, "id": "8872f550-f835-4734-9071-ed8f0fa48de6"}
{"abstract": "We propose two approximate dynamic programming (ADP)-based strategies for control of nonlinear processes using input-output data. In the first strategy, which we term 'J-learning,' one builds an empirical nonlinear model using closed-loop test data and performs dynamic programming with it to derive an improved control policy. In the second strategy, called 'Q-learning,' one tries to learn an improved control policy in a model-less manner. Compared to the conventional model predictive control approach, the new approach offers some practical advantages in using nonlinear empirical models for process control. Besides the potential reduction in the on-line computational burden, it offers a convenient way to control the degree of model extrapolation in the calculation of optimal control moves. One major difficulty associated with using an empirical model within the multi-step predictive control setting is that the model can be excessively extrapolated into regions of the state space where identification data were scarce or nonexistent, leading to performances far worse than predicted by the model. Within the proposed ADP-based strategies, this problem is handled by imposing a penalty term designed on the basis of local data distribution. A CSTR example is provided to illustrate the proposed approaches.", "authors": ["Jong Min Lee", "Jay H. Lee"], "n_citation": 54, "references": ["586d996e-fd91-48d2-b74c-6a7d07eece7b", "948a791e-a967-4cda-97b9-09f9c00eacfc", "9a2ad1c6-9e8e-4b4d-8143-303ab5b52970", "d1a9fdce-08fc-4598-ae4a-bd17b51ab281", "e0f3a738-4ab2-40d1-ba44-506d81c1d230"], "title": "Approximate dynamic programming-based approaches for input-output data-driven control of nonlinear processes", "venue": "Automatica", "year": 2005, "id": "3fab9c20-938c-4ae6-bfe9-c9e0df81deb2"}
{"abstract": "Background#R##N#In computer supported outbreak detection, a statistical method is applied to a collection of cases to detect any excess cases for a particular disease. Whether a detected aberration is a true outbreak is decided by a human expert. We present a technical framework designed and implemented at the Swedish Institute for Infectious Disease Control for computer supported outbreak detection, where a database of case reports for a large number of infectious diseases can be processed using one or more statistical methods selected by the user.", "authors": ["Baki Cakici", "Kenneth Hebing", "Maria Gr\u00fcnewald", "Paul Saretok", "Anette Hulth"], "n_citation": 50, "references": ["a9badd5c-96bc-43a1-83d7-b4bf827a170a"], "title": "CASE: a framework for computer supported outbreak detection", "venue": "BMC Medical Informatics and Decision Making", "year": 2010, "id": "3844c192-af8a-4d52-bbc5-f796864aec46"}
{"abstract": "SMT solvers have been recently applied to bounded model checking and satisfiability checking of metric temporal logic. In this paper we consider SOLOIST, an extension of metric temporal logic with aggregate temporal modalities; it has been defined based on a field study on the use of specification patterns in the context of the provisioning of service-based applications. We apply bounded satisfiability checking to perform trace checking of service execution traces against requirements expressed in SOLOIST. In particular, we focus on sparse traces, i.e., traces in which the number of time instants when events occur is very low with respect to the length of the trace.#R##N##R##N#The main contribution of this paper is an encoding of SOLOIST formulae into formulae of the theory of quantifier-free integer difference logic with uninterpreted function and predicate symbols. This encoding paves the way for efficient checking of SOLOIST formulae over sparse traces using an SMT-based verification toolkit. We report on the evaluation of the proposed encoding, commenting on its scalability and its effectiveness.", "authors": ["Marcello M. Bersani", "Domenico Bianculli", "Carlo Ghezzi", "Sr\u0111an Krsti\u0107", "Pierluigi San Pietro"], "n_citation": 11, "references": ["10821664-44d0-4f07-8237-3755b532819c", "1bc61e03-4ec0-44c6-9b7c-ae6655af606d", "2994bb2e-46fd-4a31-9c25-137f8953ca38", "2beb4188-07cf-4911-b501-cb345cc7fdf4", "3e29953b-4812-4068-8c5c-2cf542efdcdd", "61a686bb-20a0-4b7f-81aa-4ebc2d1f2c6a", "6519f146-d16f-4912-8d95-3a67c1ae8625", "8af637b6-fa68-48b0-ad9f-20987c42f903", "95aabe5c-03bf-410b-b22e-d67393437c0c", "a0c4c4ae-1340-42ca-8335-74bdb4606e45", "aaca8314-7026-4f8f-a061-f306f6fe18a2", "bb85ffed-8e22-4dea-8f20-22e7f28ea6a2", "cd40aeb4-b64a-4903-9729-43a03d875538", "d6cdba48-3cbf-4f54-936f-5f118917205f", "da1bc862-c6fb-4fc3-b25b-541444bc8c35", "dad5c1f0-246f-4c20-a30b-bfffef8fe9e2", "e6e40cc6-ede1-4057-bd6d-af394f54a0cc", "efc4b1c6-227c-482f-bfae-3d44d8dba146", "f6da83dc-8b6a-46ba-a4e2-c27bdb0d6db5"], "title": "SMT-Based Checking of SOLOIST over Sparse Traces", "venue": "fundamental approaches to software engineering", "year": 2014, "id": "27e1ec92-1aff-44a0-ba15-ab2010370ecf"}
{"abstract": "Abstract#R##N##R##N#This study sought to investigate the effects of cognitive style (field dependent and field independent) and on-line database search experience (novice and experienced) on the World Wide Web (WWW) search performance of undergraduate college students (n = 48). It also attempted to find user factors that could be used to predict search efficiency. Search performance, the dependent variable, was defined in two ways: (1) time required for retrieving a relevant information item, and (2) the number of nodes traversed for retrieving a relevant information item. The search tasks required were carried out on a University Web site, and included a factual task and a topical search task of interest to the participant. Results indicated that while cognitive style (FD/FI) significantly influenced the search performance of novice searchers, the influence was greatly reduced in those searchers who had on-line database search experience. Based on the findings, suggestions for possible changes to the design of the current Web interface and to user training programs are provided.", "authors": ["Ruth A. Palmquist", "Kyung-Sun Kim"], "n_citation": 180, "references": ["0122dc00-0388-47b7-8691-ca5888ae9423", "026902ad-d47e-404e-bae9-e70c555af295", "21e6c5b4-b587-4735-9c73-f50f6e9996e6", "4cb8bb49-7b38-4ed8-8fe7-f23ff60ec65e", "ab63b761-a778-4681-bd78-ae83ed3c1500", "b2ee3556-b44a-4591-8ed1-f6b9b996b035", "c5beb52a-55f7-40bc-9e23-85d66b13883a", "d4e6e88f-bbe5-44ee-9e39-127356c7cf84", "d6a2a92d-9316-48d3-af1b-3f21060f2192", "e28bbb8e-5a39-4848-a280-e1087367045f", "e2d90968-4d37-49c8-8c4d-92dcf8e3cb96"], "title": "Cognitive style and on-line database search experience as predictors of web search performance", "venue": "Journal of The American Society for Information Science", "year": 2000, "id": "cca36401-e149-4169-aac6-181859689426"}
{"authors": ["Thomas R\u00f6mke", "Markus R\u00f6ttger", "Ulf-Peter Schroeder", "Jens Simon"], "n_citation": 50, "references": ["332c651b-afab-45af-a2ae-898b11b7dca3", "45e04958-5bcb-4cfa-8879-4f0e6bb396e3", "775e46e3-4bce-494c-ab35-de7d9e59d678", "8e228ea6-e23b-4223-93f1-c72dd5a94688", "b6fe0f69-0a25-4e1e-a7c9-37fbb97c7b66", "b75673cc-76df-4929-8f20-bde355243385"], "title": "On Efficient Embeddings of Grids into Grids in PARIX", "venue": "european conference on parallel processing", "year": 1995, "id": "59a6c5e5-1926-4b1c-b7bd-5ef3ea2ee92d"}
{"abstract": "Interactive storytelling is a privileged application of intelligent visual actor technology. The authors introduce their character-based interactive storytelling prototype that uses hierarchical task network planning techniques, which support story generation and any-time user intervention.", "authors": ["Marc Cavazza", "Fred Charles", "Steven J. Mead"], "n_citation": 382, "references": ["08fd8dc1-e47b-4a33-806a-344030dac5c4", "1d33b519-5dbe-4470-97b2-3ebf959be3e8", "1da448e1-3ecc-4f61-a6b2-64274ec08f4c", "3e6077bf-740e-4578-9822-b6176d7912f3", "62b3e692-e44e-40d7-9a60-0428f590879d", "79194f62-caa7-4a61-a4ac-81420202b02f", "7aabcd90-2f3e-4140-ac9b-6c40bcb56b94", "823ae640-7c92-458c-b8c4-25b93ba24300", "ad08b6d7-9313-42ea-b879-b46d1733f18e", "e94b2b3c-1b04-43fb-97fe-283c9f56c647", "ea2538d7-6952-4542-aa58-016668d41959", "f9afb789-541f-4d97-b968-6fd8ed370ffa"], "title": "Character-based interactive storytelling", "venue": "IEEE Intelligent Systems", "year": 2002, "id": "4d5582fa-ebfb-474a-aa46-14a1b5d85367"}
{"abstract": "We consider the optimal guidance of an ensemble of independent, structurally identical, finite-dimensional stochastic linear systems with variation in system parameters between initial and target states of interest by applying a common control function without the use of feedback. Our exploration of such ensemble control systems is motivated by practical control design problems in which variation in system parameters and stochastic effects must be compensated for when state feedback is unavailable, such as in pulse design for nuclear magnetic resonance spectroscopy and imaging. In this paper, we extend the notion of ensemble control to stochastic linear systems with additive noise and jumps, which we model using white Gaussian noise and Poisson counters, respectively, and investigate the optimal steering problem. In our main result, we prove that the minimum norm solution to a Fredholm integral equation of the first kind provides the optimal control that simultaneously minimizes the mean square error (MSE) and the error in the mean of the terminal state. The optimal controls are generated numerically for several example ensemble control problems, and Monte Carlo simulations are used to illustrate their performance. This work has immediate applications to the control of dynamical systems with parameter dispersion or uncertainty that are subject to additive noise, which are of interest in quantum control, neuroscience, and sensorless robotic manipulation.", "authors": ["Ji Qi", "Anatoly Zlotnik", "Jr-Shin Li"], "n_citation": 7, "references": ["3e53114e-b8ee-4b80-b5c5-f28e747aa4a2", "54bc0217-6a6c-46db-bc25-f6d8b72d1a2b", "96bc57d2-a67e-4b74-8041-618d61ecbfc4", "9c223b2c-0fd7-48c5-8057-9b41b1cccdad", "a9ebd30d-45fd-485b-b947-92478ee0a034", "ad733674-5d03-464b-b487-55fb337150c1", "b2af16e9-0ac0-48f2-9ddc-8295ed8cec4e", "c7f5b788-0401-402d-af2a-8623f9696294"], "title": "Optimal ensemble control of stochastic time-varying linear systems", "venue": "Systems & Control Letters", "year": 2013, "id": "82b55358-4ebf-4103-8069-720dd4de056c"}
{"abstract": "Web browsers' access control policies have evolved piecemeal in an ad-hoc fashion with the introduction of new browser features. This has resulted in numerous incoherencies. In this paper, we analyze three major access control flaws in today's browsers: (1) principal labeling is different for different resources, raising problems when resources interplay, (2) runtime changes to principal identities are handled inconsistently, and (3)browsers mismanage resources belonging to the user principal. We show that such mishandling of principals leads to many access control incoherencies, presenting hurdles for web developers to construct secure web applications. A unique contribution of this paper is to identify the compatibility cost of removing these unsafe browser features. To do this, we have built WebAnalyzer, a crawler-based framework for measuring real-world usage of browser features, and used it to study the top 100,000 popular web sites ranked by Alexa. Our methodology and results serve as a guideline for browser designers to balance security and backward compatibility.", "authors": ["Kapil Singh", "Alexander Moshchuk", "Helen J. Wang", "Wenke Lee"], "n_citation": 75, "references": ["0012ea0d-8d41-4246-87d2-160896ae97d1", "16ec3f70-e1d3-47e0-9bbc-384bb0a5fc81", "5af5cda1-0aa1-4ef3-a011-3174915bf3f4", "5de997ea-e7a7-4cf8-bd0e-eb88c7cd72cc", "67053621-2a31-4710-8071-12c9430d6a21", "717d675a-0595-4c1f-ba3c-ff4f010aca09", "7d3ad5e5-f72e-4670-9e3e-4abda6124c52", "84e20618-449b-402c-99f9-e70a7998756c", "aa394e83-0daf-4701-872c-633c12b0af7b"], "title": "On the Incoherencies in Web Browser Access Control Policies", "venue": "ieee symposium on security and privacy", "year": 2010, "id": "78e5611e-9ba0-4dd8-91e4-c1f8b5b62ba2"}
{"abstract": "Numerous methodological issues arise when studying teams that span multiple boundaries. The main purpose of this paper is to raise awareness about the challenges of conducting field research on teams in global firms. Based on field research across multiple firms (software development, product development, financial services, and high technology), we outline five types of boundaries that we encountered in our field research (geographical, functional, temporal, identity, and organizational)and discuss methodological issues in distinguishing the effects of one boundary where multiple boundaries exist. We suggest that it is important to: (1) appropriately measure the boundary of interest to the study, (2) assess and control for other influential boundaries within and across teams, and (3)distinguish the effects of each boundary on each team outcome of interest. Only through careful attention to methodology can we properly assess the effects of team boundaries and appreciate their research and practical implications for designing and using information systems to support collaborative work.", "authors": ["J. Alberto Espinosa", "Jonathon N. Cummings", "Jeanne M. Wilson", "Brandi M. Pearce"], "n_citation": 268, "references": ["1fe75223-2d42-450a-bf5e-94fb65e8f411", "76b7bab5-8066-42c7-bfdd-f1087a866eb7", "8eaa9d14-71ff-4cf1-8038-abd9b62f4c6e", "97e50bd4-0fda-4d8e-84d2-3b282643b9e4", "cecbf5fd-148a-4de9-ae11-b3be17a004d1", "d2738c3d-028f-4b84-9aaa-dd8f764e5909", "fa426261-b4df-46f9-850e-000fe1a5ce6a"], "title": "Team Boundary Issues Across Multiple Global Firms", "venue": "Journal of Management Information Systems", "year": 2003, "id": "5fff445e-ea84-45de-831b-ab77a11f5e3c"}
{"authors": ["Thiago Alexandre Salgueiro Pardo", "Lucia Helena Machado Rino"], "n_citation": 11, "references": ["449e8cb2-9084-4974-8321-cb4477d7b31c", "71ecd1d2-c656-489d-95a6-503e31e3e05f", "89a494d6-1f57-4070-8d02-492a1fab41cf", "b42a4834-ae3c-4ae1-bc6b-352428aa8e24", "bdbad5dd-09aa-4d45-ad54-6e52c933e591", "f0a5e86a-36b0-4c47-b085-0d35f15e9e8e"], "title": "A summary planner based on a three-level discourse model.", "venue": "", "year": 2001, "id": "8d3d6521-3279-4568-b5ba-baba9dbe3d8c"}
{"abstract": "This work introduces the use of LBP like texture descriptors for efficient multispectral face recognition. LBP has been widely used in visible spectrum face recognition. This work extend its use to non visible spectrums (active and passive infrared spectrums). Local Binary Pattern (LBP) and Local Ternary Pattern (LTP) descriptors are used. Also a simple differential LTP descriptor (DLT) is introduced. The proposed texture space is less sensitive to noise, illumination change and facial expressions. These characteristics make it a good candidate for efficient multispectral face recognition. Linear and non linear dimensionality reduction techniques are introduced and used for performance evaluation of multispectral face recognition in the texture space. The obtained results show that the use of the proposed texture descriptors permit to achieve high recognition rates in multispectral face recognition.", "authors": ["Abdelhakim Bendada", "Moulay A. Akhloufi"], "n_citation": 50, "references": ["057d00b0-184e-437b-9367-7a5972318efd", "40ea9b15-e3ff-4e65-b8b7-dd8b8e564931", "4958f18d-ba76-495d-8165-2e8717b49d51", "65a715a4-70ee-48e2-a0a2-331e1099b394", "66e2a36d-36f0-468a-80af-2b39eecf6d74", "708d540a-0197-4436-a59e-7bf32048395a", "767319b3-1d27-402f-b411-7a158ad19ae5", "9270a9b5-940a-4394-814f-433c6440f286", "e3a5cec9-7e82-4c14-86ab-0d95a92712a7", "eb85c0bc-14c5-4b13-b34f-4da288b1a2fb", "f270ea0c-5524-4b11-86da-b37f70aa7f6f"], "title": "Multispectral Face Recognition in Texture Space", "venue": "canadian conference on computer and robot vision", "year": 2010, "id": "e0c20442-c087-4be9-8339-df2ce028b3dc"}
{"abstract": "In this paper a finite-buffer discrete-time approach is presented in order to analyze the performance of a multiplexer loaded by N multimedia sources. For this purpose the emission process of each multimedia source is defined as the superposition of heterogeneous correlated emission processes, each of which models one monomedia source as a Switched Batch Bernoulli Process (SBBP). In order to model the intermedia relationships, the Markov chain underlying each SBBP consists of a 2-state process, where the transition probabilities are functions of the states of the other monomedia sources. Correlation functions are derived for each monomedia source as well as for the multimedia source as a whole. The proposed analytical model is used to calculate the loss probability and the delay jitter pdf for each media in an ATM multimedia multiplexer structure. The effectiveness of the proposed paradigm is shown by means of various examples in a case study.", "authors": ["A. La Corte", "A. Lombardo", "Giovanni Schembra"], "n_citation": 22, "references": ["0773923d-b7b5-424b-9e57-3e811deda84d", "26e8c9cd-c083-423a-9a76-24cf6e47f4ef", "2de1b9ec-8dc4-4960-89cb-0102129287a3", "338720e8-e250-4157-8682-d3c3123ed184", "345a254b-d05a-4a41-bccc-ee4a2104e1d2", "524c420d-a3f0-4e36-9805-3e16a4e127d8", "56904468-b807-4f2b-87c8-c145b59bfdd7", "6bf1a8a9-9c8f-4015-92ff-060daa7be309", "7ac8c2ef-dab3-4c74-aee9-c5881e1e6dc2", "8c2b6b2d-0779-4406-bc4a-c77b9f781b78", "91701de1-1d0b-4c09-97c4-13c174447de1", "97c2fbc5-3e37-466a-bb4f-664f6860306b", "9daef521-e415-40ba-8e04-a762f5be7018", "a65559af-1bdd-4fac-81f3-0082bb992f00", "b09795f0-bc50-4307-bec8-36af890df09a", "b5e0118c-2aa8-462e-86b5-f7da233aa14e", "bfac75ce-8ef1-431b-bce2-a09dd04e049a", "c4ce8a36-07d8-47bc-8f68-15bb62c7f1b1", "d33811f1-a26c-4dab-aea9-eb1d91827af6", "da744ef8-4f2d-4b9e-9c52-5d773145aa6a", "e7c9c534-9b11-422a-91c6-d7061d489dae", "e977fe06-34a0-4bc7-baa8-2ab386b962e8", "eafe1e8f-9519-484c-aa94-b324f1379de4", "f16c64fd-0aa0-4d66-a331-59d18cb13f28", "f20ae0ff-dba6-402d-9844-1d70717e5a6f"], "title": "An analytical paradigm to calculate multiplexer performance in an ATM multimedia environment", "venue": "Computer Networks and Isdn Systems", "year": 1997, "id": "6189adef-cc11-407f-b51f-ef57f2fb2339"}
{"abstract": "This paper presents a new affine invariant image transform called multiscale autoconvolution (MSA). The proposed transform is based on a probabilistic interpretation of the image function. The method is directly applicable to isolated objects and does not require extraction of boundaries or interest points, and the computational load is significantly reduced using the fast Fourier transform. The transform values can be used as descriptors for affine invariant pattern classification and, in this article, we illustrate their performance in various object classification tasks. As shown by a comparison with other affine invariant techniques, the new method appears to be suitable for problems where image distortions can be approximated with affine transformations.", "authors": ["Esa Rahtu", "Mikko Salo", "Janne Heikkil\u00e4"], "n_citation": 111, "references": ["019a5ad3-5d2f-4514-92a8-d5a0280d5ac9", "0dcbb0fe-91fb-463d-9e81-8bfc2b5c85a8", "0ffce42e-5fbd-43da-9788-925373b802d4", "1e3fb1da-43bb-41db-8995-0356cc6bb543", "219f4729-a9bc-42d3-bca4-2ae088e5f475", "54d73706-bc47-411b-82c9-2cb8f81f449e", "54d7b7d3-3645-480d-9e4c-ef368df46d7f", "6e903032-d4ef-4bed-ba62-f75d4483cf9d", "792acff6-facf-40c9-98d7-312ce2485ad3", "7f1159c8-1673-40a0-9c0e-d79836c2dbff", "91c573c8-3107-4b0b-8771-de1c60fa29d5", "94bf0a68-cdf1-42f3-9d7b-3e05e0b34c8e", "b2d10062-0eeb-408b-81ee-e33518aef2b7", "c4200bf7-2b67-473a-8e91-544b9463bfe0", "d5f8e154-e8c9-45e8-a3a0-fd705f00ced4", "d83892c7-481b-4514-8cce-a8ae6bae5638", "ef1c9957-c4a8-47bc-aa59-e09c9a4b8a6d", "fc9a9147-14f6-4637-9b91-38480bc9647b"], "title": "Affine invariant pattern recognition using multiscale autoconvolution", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2005, "id": "eea7fee1-9404-4c41-9d38-6fc520b2a453"}
{"abstract": "The Bayesian committee machine (BCM) is a novel approach to combining estimators that were trained on different data sets. Although the BCM can be applied to the combination of any kind of estimators, the main foci are gaussian process regression and related systems such as regularization networks and smoothing splines for which the degrees of freedom increase with the number of training data. Somewhat surprisingly, we find that the performance of the BCM improves if several test points are queried at the same time and is optimal if the number of test points is at least as large as the degrees of freedom of the estimator. The BCM also provides a new solution for on-line learning with potential applications to data mining. We apply the BCM to systems with fixed basis functions and discuss its relationship to gaussian process regression. Finally, we show how the ideas behind the BCM can be applied in a non-Bayesian setting to extend the input-dependent combination of estimators.", "authors": ["Volker Tresp"], "n_citation": 258, "references": ["0fdc885f-d42c-4f9a-9b14-2cc7a97c8492", "5206bed9-d48d-44ab-b0cd-4731dfe5679c", "549f0527-0f13-4447-9dc0-ca699e2dc219", "6389dc89-bcea-4d9d-b72e-ec786c0cc9ab", "927bf1e6-e7c9-4f84-b8fc-d14227b3c9eb", "97048a44-a841-4e49-ad9d-4a322ceb5db6", "ac926330-234d-4698-ac11-4927fea380b9", "b2f30765-3243-48f6-82c2-0e337c86e993", "c3381be7-98e5-4267-b5a3-4e895ce9828d", "cb4fbf1c-02e4-4ca9-995d-29f5282fdb4a", "d35e56ae-bf83-452a-b14b-dc7df8104056", "dcd6762a-ff44-46aa-ab12-6b951955199c", "f5852fc4-396e-4e1e-b434-d32c7b8046fb"], "title": "A Bayesian Committee Machine", "venue": "Neural Computation", "year": 2000, "id": "130d329c-60d3-4dcd-9618-43a3b25b630e"}
{"abstract": "Hashing is a primary, yet under appreciated, tool in digital forensic investigations. Recent R&D has demonstrated that, with clever design, we can construct robust fingerprinting and similarity hashes that can significantly speed up an investigation.", "authors": ["Vassil Roussev"], "n_citation": 55, "references": ["0209c39e-1602-4ed0-965c-ce1ac295578f", "1152cec5-0e0e-4ac3-a3d0-57bd86bb63cd", "346a6fbd-115d-40ef-9015-2f06f2d86257", "502bcc3c-d14b-4edb-8ca2-a2ec0925c41a", "55f4933e-56af-4807-b466-0ec19261d023", "6fdb51a7-14cd-4f95-ab3c-67e2addf2a09", "96ee3315-5abc-41fc-a126-b4b704577400", "b1f771a9-3739-446d-adc3-600bd9bb7c8b", "be23df9d-eee9-4db4-8e88-55c3b9dd0481", "c410c3ae-4c9d-42be-b348-6981fecd5467", "f228c79d-1fbb-4a25-9041-f9de6a443843"], "title": "Hashing and Data Fingerprinting in Digital Forensics", "venue": "ieee symposium on security and privacy", "year": 2009, "id": "b2a728a7-647c-4512-b405-febda5ab343a"}
{"abstract": "We propose a new frequency-based replacement algorithm for managing caches used for disk blocks by a file system, database management system, or disk control unit, which we refer to here as data caches. Previously, LRU replacement has usually been used for such caches. We describe a replacement algorithm based on the concept of maintaining reference counts in which locality has been \u201cfactored out\u201d. In this algorithm replacement choices are made using a combination of reference frequency and block age. Simulation results based on traces of file system and I/O activity from actual systems show that this algorithm can offer up to 34% performance improvement over LRU replacement, where the improvement is expressed as the fraction of the performance gain achieved between LRU replacement and the theoretically optimal policy in which the reference string must be known in advance. Furthermore, the implementation complexity and efficiency of this algorithm is comparable to one using LRU replacement.", "authors": ["John T. Robinson", "Murthy V. Devarakonda"], "n_citation": 475, "references": ["07194702-1044-48fa-8e3d-e95631650f36", "0ee5c447-1765-4dc5-a37c-5821d5591c27", "7a8f7ed0-3dee-4292-9951-3d01b8644d57", "c39ae428-0302-4794-9f94-3d6aaf32c5df", "e3875ea4-0f95-4f09-89f0-1d1fce54254e"], "title": "Data cache management using frequency-based replacement", "venue": "measurement and modeling of computer systems", "year": 1990, "id": "15f978e0-6e7f-4167-a2e0-cc89ef3555cf"}
{"abstract": "We perform a novel analysis of the fitness landscape of the job-shop scheduling problem (JSP). In contrast to other well-known combinatorial optimization problems, we show that the landscape of the JSP is non-regular, in that the connectivity of solutions is variable. As a consequence, we argue that random walks performed on such a landscape will be biased. We conjecture that such a bias should affect both random walks and local search algorithms, and may provide a partial explanation for the remarkable success of the latter in solving the JSP.", "authors": ["Christian Bierwirth", "Dirk C. Mattfeld", "Jean-Paul Watson"], "n_citation": 50, "references": ["0a4eb31b-9227-471b-bc5e-924f9e77ffd2", "69fc30d0-3f4f-4a84-9dc3-2017669eba2f", "6cf27cbd-408a-454f-8dfa-f5987e040360", "7d58aa33-4b77-431f-90ca-ed824ecbde3b", "94df3482-e3e2-4c0b-94d8-ed5814eee0c4", "d5d4aebd-99ce-4d42-86e9-c2b2b8f2f516", "db90576c-7e2f-4af3-b959-a2352378c062", "e4435fdf-7060-4919-a237-3457896943fe"], "title": "Landscape Regularity and Random Walks for the Job-Shop Scheduling Problem", "venue": "", "year": 2004, "id": "df8a4230-ecaa-45bb-97fc-dce05016e5e8"}
{"authors": ["Klaus Bergner", "Andreas Rausch", "Marc Sihling", "Alexander Vilbig", "Manfred Broy"], "n_citation": 50, "title": "A Formal Model for Componentware.", "venue": "", "year": 1999, "id": "ac697818-202c-4783-ada0-3aa5cc44a838"}
{"authors": ["Bernhard Selk", "Sebastian Kloeckner", "Bettina Bazijanec", "Antonia Albani"], "n_citation": 6, "references": ["bd30cbb4-d594-434a-8d3a-9bbf4372c73e", "d891c129-7303-4826-a428-0cdc0efd4c23", "d8d75f85-3435-4858-8aa4-172fa4980478"], "title": "Experience Report: Appropriateness of the BCI-Method for Identifying Business Components in large-scale Information Systems.", "venue": "", "year": 2005, "id": "1356aefe-f0c5-47ba-a2bf-ab11ac29cea9"}
{"abstract": "We present Build Analyzer, a tool that helps developers optimize the build performance of huge systems written in C. Due to complex C header dependencies, even small code changes can cause extremely long rebuilds, which are problematic when code is shared and modified by teams of hundreds of individuals. Build Analyzer supports several use cases. For developers, it provides an estimate of the build impact and distribution caused by a given change. For architects, it shows why a build is costly, how its cost is spread over the entire code base, which headers cause build bottlenecks, and suggests ways to refactor these to reduce the cost. We demonstrate Build Analyzer with a use-case on a real industry code base.", "authors": ["Alexandru Telea", "Sl Lucian Voinea"], "n_citation": 16, "references": ["d7d56d4a-fa0c-45c5-9dea-f8adca7590c4"], "title": "A Tool for Optimizing the Build Performance of Large Software Code Bases", "venue": "conference on software maintenance and reengineering", "year": 2008, "id": "37341ec2-1b55-4072-b931-075e1a7e5cc9"}
{"abstract": "Kernel-based learning (e.g., Support Vector Machines) has been successfully applied to many hard problems in Natural Language Processing (NLP). In NLP, although feature combinations are crucial to improving performance, they are heuristically selected. Kernel methods change this situation. The merit of the kernel methods is that effective feature combination is implicitly expanded without loss of generality and increasing the computational costs. Kernel-based text analysis shows an excellent performance in terms in accuracy; however, these methods are usually too slow to apply to large-scale text analysis. In this paper, we extend a Basket Mining algorithm to convert a kernel-based classifier into a simple and fast linear classifier. Experimental results on English BaseNP Chunking, Japanese Word Segmentation and Japanese Dependency Parsing show that our new classifiers are about 30 to 300 times faster than the standard kernel-based classifiers.", "authors": ["Taku Kudo", "Yuji Matsumoto"], "n_citation": 239, "references": ["01f15552-88f8-48ca-a75a-663822a6199a", "07814736-04a6-4d6c-8f1a-51aa6a11e647", "0d5941b6-15b6-4ec1-a44d-f1c991bd04c4", "31726c35-1136-41ed-89f5-197c77ecdb87", "31f54397-343f-4b98-b19e-7600734ed2d1", "5bc0d70d-0260-42e4-853b-4a576e86b807", "6b3483b2-504d-454e-8f03-e58ad4c7f4b0", "826060b2-d590-4b04-a62f-612157dd65b3", "c960c558-c94b-4449-93af-c0f07e89c010", "ce9c7430-fe27-4552-8f3e-fe5591e3918c", "f324d36a-1c7e-4c43-86c5-b4bc5a423cfa"], "title": "Fast Methods for Kernel-Based Text Analysis", "venue": "meeting of the association for computational linguistics", "year": 2003, "id": "d679839f-afdc-42f8-8aa9-92bf8892ceca"}
{"authors": ["Eugene Asarin", "Oded Maler", "Amir Pnueli"], "n_citation": 308, "references": ["02de5106-8acc-4ca6-9861-4805210ab776", "2383e70b-0513-4e40-9719-a4c3eb46589c", "56ab7838-a49b-4f3e-a084-7f8a435d710b", "5edb99f2-cc75-468e-9ca0-28ce7a1e709d", "66290726-8f4d-4596-a0ac-9ae00bed0c6f", "756b4570-813b-486f-b38a-b55b050065e7", "7d6d7735-2002-4067-a26f-5cf93aa590f1", "a4799c38-84d0-4b52-84d6-18e493af3a3c", "d7f2c945-b293-46f9-95dd-f30e82d1dfda"], "title": "Symbolic Controller Synthesis for Discrete and Timed Systems", "venue": "", "year": 1995, "id": "b0ff8fdc-0845-4fc7-8016-43a62bc6f969"}
{"authors": ["Stefano Nolfi", "Domenico Parisi"], "n_citation": 76, "references": ["1ec48329-d0b2-4771-b62a-c6b549aaebf3", "37d07d0c-efc9-40f2-b27b-db5c720df893", "8786acf1-989d-4cf5-9064-cc0c0c3688cc"], "title": "Evolving Artificial Neural Networks that Develop in Time", "venue": "european conference on artificial life", "year": 1995, "id": "93d8cc19-7b54-4c7f-935a-4053994fb49a"}
{"abstract": "A new application of fuzzy systems to the processing of materials is presented. The relationships between temperature, time, and the impact strength of an austempered ductile iron (ADI) part are adaptively modeled. Four fuzzy and neuro fuzzy approaches have been used to build predictive models. These are: a fuzzy based model, a backpropagation based neuro fuzzy model, a clustering based model, and a clustering backpropagation based neuro fuzzy model. The clustering approach, using the subclustering method, yielded the best predictive results when all models had been given the same input-output training data. The backpropagation based neuro fuzzy approach suffers from the lack of a higher number of input-output data training sets. All preliminary results obtained suggest the adequacy of the fuzzy based and neuro fuzzy based modeling techniques to tackle those types of problems in the material processing areas.", "authors": ["Labib Arafeh", "Harpreet Singh", "Susil K. Putatunda"], "n_citation": 61, "references": ["163cd454-0b6d-406b-a3f4-bb374eb43489", "4524b811-d9fd-4aaf-8f4c-7503c61284a7", "542806b8-6c5b-4e07-b0b7-b4c727ba2361", "6bfa8795-f0d8-4f20-afe9-ad842c2fa6fc", "91cfc696-3038-4461-8ed3-940e42592a8e", "96c210e3-f75b-4e15-b3fa-c9ee755e4cc2", "b4882f7a-edfb-4bbf-90ed-8855da33d830", "c9cd95ef-9a83-47be-904d-756e80c904fd", "d47dcf6c-1abb-4bc8-90d8-3972307f8722", "e18e45a8-a057-4e81-a4dc-61e326c465f8"], "title": "A neuro fuzzy logic approach to material processing", "venue": "systems man and cybernetics", "year": 1999, "id": "d37b212b-9fa0-41d7-a935-c605652429f7"}
{"abstract": "We present the discrete beeping communication model, which assumes nodes have minimal knowledge about their environment and severely limited communication capabilities. Specifically, nodes have no information regarding the local or global structure of the network, do not have access to synchronized clocks and are woken up by an adversary. Moreover, instead on communicating through messages they rely solely on carrier sensing to exchange information. This model is interesting from a practical point of view, because it is possible to implement it (or emulate it) even in extremely restricted radio network environments. From a theory point of view, it shows that complex problems (such as vertex coloring) can be solved efficiently even without strong assumptions on properties of the communication model.#R##N##R##N#We study the problem of interval coloring, a variant of vertex coloring specially suited for the studied beeping model. Given a set of resources, the goal of interval coloring is to assign every node a large contiguous fraction of the resources, such that neighboring nodes have disjoint resources. A k-interval coloring is one where every node gets at least a 1/k fraction of the resources.#R##N##R##N#To highlight the importance of the discreteness of the model, we contrast it against a continuous variant described in [17]. We present an O(1) time algorithm that with probability 1 produces a O(\u0394)-interval coloring. This improves an O(log n) time algorithm with the same guarantees presented in [17], and accentuates the unrealistic assumptions of the continuous model. Under the more realistic discrete model, we present a Las Vegas algorithm that solves O(\u0394)- interval coloring in O(log n) time with high probability and describe how to adapt the algorithm for dynamic networks where nodes may join or leave. For constant degree graphs we prove a lower bound of \u03a9(log n) on the time required to solve interval coloring for this model against randomized algorithms. This lower bound implies that our algorithm is asymptotically optimal for constant degree graphs.", "authors": ["Alejandro Cornejo", "Fabian Kuhn"], "n_citation": 65, "references": ["1baf90c8-5c75-4e5d-99f1-378571ef5a71", "1ef02bd5-77d2-4b29-b461-c3ac6fc27d77", "334cd1d6-c5b7-459f-b591-cef794fb11f8", "3f2264f9-7bbb-4912-9ee6-88b1f58e484f", "42504d0c-f584-4880-afa9-05732e871b54", "42959a3f-56db-4350-a4ba-99464c1e7d21", "4420efd6-6edd-48ae-9618-e3d2c1acda85", "4e5fce5b-5f47-42bd-9ec9-f88657846dee", "50aa95f1-73f1-4ffd-a6d2-dfb61e1c8d64", "54bf3be5-8a3f-40d0-8531-052430d6c2c1", "58a9275a-9240-4399-a846-687c44912217", "5dcf9da4-b7f9-42b8-a7db-6def51cddb6d", "6b99cfd7-b208-4b73-9899-16fab7ed546e", "7bdedace-5879-4d10-967d-89d7f8d06ede", "7ee6ef68-bef0-451a-8383-a56e543baf5b", "9e2f1dc9-3e72-4456-a67c-8161ca6cc04e", "b12cd4a9-90c8-41d7-94a1-d9e80a546e3a", "c8defedf-4eae-47a9-842a-b920b15503b4", "ced03f3a-fa4b-42d6-9c25-b87b62f57339", "e0713d4b-ae7a-43e9-bd25-ff113c843a8d", "f552752d-9526-4802-8af6-ada95be31a4d", "f833b903-da8a-4e2a-8103-1373013ab926"], "title": "Deploying wireless networks with beeps", "venue": "international symposium on distributed computing", "year": 2010, "id": "16832cf9-de66-497a-9255-e65590480e34"}
{"abstract": "Disjunctive Logic Programming (DLP) under the answer set semantics, often referred to as Answer Set Programming (ASP), is a powerful formalism for knowledge representation and reasoning (KRR). The latest years witness an increasing effort for embedding functions in the context of ASP. Nevertheless, at present no ASP system allows for a reasonably unrestricted use of function terms. Functions are either required not to be recursive or subject to severe syntactic limitations, if allowed at all in ASP systems.#R##N##R##N#In this work we formally define the new class of finitely-ground programs, allowing for a powerful (possibly recursive) use of function terms in the full ASP language with disjunction and negation. We demonstrate that finitely-ground programs have nice computational properties: (i) both brave and cautious reasoning are decidable, and (ii) answer sets of finitely-ground programs are computable. Moreover, the language is highly expressive, as any computable function can be encoded by a finitely-ground program. Due to the high expressiveness, membership in the class of finitely-ground program is clearly not decidable (we prove that it is semi-decidable). We single out also a subset of finitely-ground programs, called finite-domain programs, which are effectively recognizable, while keeping computability of both reasoning and answer set computation.#R##N##R##N#We implement all results in DLP, further extending the language in order to support list and set terms, along with a rich library of built-in functions for their manipulation. The resulting ASP system is very powerful: any computable function can be encoded in a rich and fully declarative KRR language, ensuring termination on every finitely-ground program. In addition, termination is \"a priori\" guaranteed if the user asks for the finite-domain check.", "authors": ["Francesco Calimeri", "Susanna Cozza", "Giovambattista Ianni", "Nicola Leone"], "n_citation": 110, "references": ["03e325ff-4652-48bb-8d39-82b05679e337", "12667a29-14c4-453f-9e61-31478ed9046b", "185f7384-2349-4b98-9c48-c366b846689a", "201a07dd-9666-43bf-b3e2-7120d9f3e7fe", "3eb8201d-cd66-4705-9675-4ce354cc01da", "58c12637-335e-4f0e-bb51-e7cb05cd6d79", "5c50a384-c52c-4389-bee4-fc0b4cee9c7b", "66ca966c-16bc-4bbc-9e13-c97afeea8724", "6d7f2581-37f1-4f5b-b637-f4b0e655f783", "80d207b6-318d-41ef-82be-9d472493a516", "8d6430dc-a8ca-40ed-bead-a523aa31850c", "ab08d49f-9282-447c-a09b-4bb84cd9d1a0", "c83c616b-fa8f-4dc8-9afc-9b7f02c00c0c", "cf7a2bdf-2a81-4303-92f9-f93f02da52b1", "db658327-1f48-4f80-8f7d-09d88096f297", "e22908da-10e5-49ec-93ed-2d7b1e1e8da3", "e27b158d-018a-4753-955a-41921a159224"], "title": "Computable Functions in ASP: Theory and Implementation", "venue": "international conference on logic programming", "year": 2008, "id": "08cf4cec-baa2-4e6f-8937-b3e3c30e34bc"}
{"abstract": "Recent contributions have extended the applicability of Koopman operator theory from dynamical systems to control. Stability theory got reformulated in terms of spectral properties of the Koopman operator [1], providing a nice link between the way we treat linear systems and nonlinear systems and opening the door for the use of classical linear e.g. pole placement theory in the fully nonlinear setting. New concepts such as isostables proved useful in the context of optimal control. Here, using Kato Decomposition we develop Koopman expansion for general LTI systems. We also interpret stable and unstable subspaces in terms of zero level sets of Koopman eigenfunctions. We then utilize conjugacy properties of Koopman eigenfunctions to extend these results to globally stable systems. In conclusion, we discuss how the classical Hamilton-Jacobi-Bellman setting for optimal control can be reformulated in operator-theoretic terms and point the applicability of spectral operator theory in max-plus algebra to it. Geometric theories such as differential positivity have been also related to spectral theories of the Koopman operator [2], in cases when the attractor is a fixed point or a limit cycle, pointing the way to the more general case of quasiperiodic and chaotic attractors.", "authors": ["Igor Mezic"], "n_citation": 11, "references": ["3e5ebd1e-ed2c-42a2-8fcf-ad90ffe45505", "b0cbad15-7652-4d5e-a804-e9caaa0ad2f7"], "title": "On applications of the spectral theory of the Koopman operator in dynamical systems and control theory", "venue": "conference on decision and control", "year": 2015, "id": "51e86eda-8780-4357-a52a-ceb8d9ab064d"}
{"abstract": "Explore a novel feature extraction method.Find whether the proposed features have high dominant power.Proposed features gave an accuracy of 97.6% as compared to Color-Shape-Texture. The purpose of this article was to explore a new feature extraction method for classifying paddy seeds using a feature extraction algorithm to achieve the Horizontal-Vertical and Front-Rear angles. The method used fusion of angle features for classification, which were then compared to features such as seed color, shape, and texture. Experiments show that the proposed features work better in classifying paddy seeds in comparison with some of the standard features, and that the proposed features have an excellent discriminating property for seeds. The discriminating power of these features was assessed using the neural network architectures for the unique identification of seeds of four Paddy (Rice) grains: viz. Karjat-6(K6), Karjat-2(K2), Ratnagiri-4(R4) and Ratnagiri-24(R24). The classification accuracies of Color-Shape-Texture obtained was 95.2% while the proposed method gave an accuracy of 97.6%.", "authors": ["Archana Chaugule", "Suresh N. Mali"], "n_citation": 4, "references": ["69ec922e-1be6-4fa7-a0a4-a718bb568e6e", "a46b93ed-9b8b-4216-bafb-548d46fe3842", "abc1a719-f4bb-44f6-baa3-61f26ccd1044"], "title": "Identification of paddy varieties based on novel seed angle features", "venue": "Computers and Electronics in Agriculture", "year": 2016, "id": "83b28631-8616-4191-9828-d90aebbd880d"}
{"abstract": "The restriction of access is a mechanism by which organisations protect their information assets. Requirements models use actor definitions to describe users and to specify their access policies. Actors normally represent roles that users adopt, while roles can represent different things, such as a position in an organisation or the assignment of a task. Current requirements modelling approaches do not provide a systematic way of defining roles for incorporation into access policies. We address this issue by proposing a framework that facilitates the derivation of role definitions from their wider organisational context. We illustrate how our framework can be used to extend a formal version of i* - to define and verify access policies definitions -and demonstrate its applicability via a case study.", "authors": ["Robert Crook", "Darrel C. Ince", "Bashar Nuseibeh"], "n_citation": 50, "references": ["02426ca1-b6f8-4880-912c-a0b841bbf4c9", "05390dca-2d36-447e-bb9f-c982f817febd", "16c671c4-3a06-4f95-b5dc-c41f678ea1f2", "211a7e14-de48-40f1-b622-b36fa6f47cf8", "309de70c-a850-4b0a-830b-a05739ea66d9", "4908fbde-754b-446b-977b-b2ae65467634", "538b88a6-6c00-441e-842d-5fae1a738d50", "6127bf40-6d09-4e4b-9d74-a3aa6e79c60a", "6247ecd7-5edc-4281-a00a-f49d8df6163f", "69220232-821f-4e21-8d99-3decfb2f9da6", "6fd6a5b6-8e13-4ec7-bcb0-36148ae886b2", "74b585d2-c254-432a-ad03-4711db8ec8fe", "79fc0389-d85c-4ff1-a5eb-ee4ef3111b83", "7ca134e9-b06e-484d-b617-85723ad97dd7", "83299865-262b-44ee-8b3c-8c4f57aa9ada", "bdf0cfed-01b6-4c77-8c9d-dd6905fc3955", "c02f856d-fbb7-44c3-a9ba-dbefe25fe1ef", "c279a6c2-7cfb-409d-a371-eb27005db766", "da0d129a-feab-4700-8104-d3165622e938", "e59cac72-57b1-4b83-9ff7-287bf10fdf28", "ecfb2022-e18c-4e5e-8733-d8bc6f4c8fc9", "f13f0531-6f50-4118-8136-1afc725fcd41", "f1bd881c-d581-445b-babd-404be218439f", "fcd6572e-d91e-4c89-ae17-a65fc0365be1", "fe32e866-8180-40dc-b499-446d54983456"], "title": "On modelling access policies: relating roles to their organisational context", "venue": "Requirements Engineering", "year": 2005, "id": "87ba75b1-0d98-4705-a3f8-48c557f309b6"}
{"abstract": "To prevent an electric power system losing synchronism under a large sudden fault and to achieve voltage regulation are major objectives in power system design. This paper applies the Riccati equation approach, together with the direct feedback linearization (DFL) technique, to design robust nonlinear controllers for transient stability enhancement and voltage regulation of power systems under a symmetrical three-phase short circuit fault. A DFL excitation controller and a DFL coordinated controller (excitation and fast valving controller) are proposed. The simulation results show that a power system can keep transiently stable, even when a large sudden fault occurs at the generator terminal. The robust nonlinear DFL controllers proposed here can greatly improve transient stability and achieve voltage regulation.", "authors": ["Youyi Wang", "David J. Hill"], "n_citation": 101, "references": ["f752a344-f357-440d-810b-b87fa70c09c2"], "title": "Robust nonlinear coordinated control of power systems", "venue": "Automatica", "year": 1996, "id": "c5e928d5-1caf-4465-ac37-6ff3662a2f91"}
{"abstract": "In this technical note, we give a geometrical framework for the design of observers on finite-dimensional Lie groups for systems which possess some specific symmetries. The design and the error (between true and estimated state) equation are explicit and intrinsic. We consider also a particular case: left-invariant systems on Lie groups with right equivariant output. The theory yields a class of observers such that the error equation is autonomous. The observers converge locally around any trajectory, and the global behavior is independent from the trajectory, which is reminiscent of the linear stationary case.", "authors": ["Silv\u00e8re Bonnabel", "Philippe Martin", "Pierre Rouchon"], "n_citation": 140, "references": ["3c3a5b5c-a61b-4970-9cf3-6427efb404df", "456e3ef9-ee0c-4d5a-be78-3724b9e15ce3", "59d8f17b-4019-4a3c-9cbd-7f0f25c44952", "64743278-7332-4232-ba2d-b67d9405cb73", "6ddb8f3e-b5ae-422e-b398-5dcf4bdbd6b9", "88958dd7-1a7f-4886-8735-b7641816a81d", "a187739f-c652-46e1-8398-7b65553d92a5"], "title": "Non-Linear Symmetry-Preserving Observers on Lie Groups", "venue": "IEEE Transactions on Automatic Control", "year": 2009, "id": "f79005b4-6f21-4099-a394-94902e53a6c5"}
{"abstract": "In this paper, we present an efficient failure recovery scheme for mobile applications based on movement-based checkpointing and logging. Current approaches take checkpoints periodically without regard to the mobility rate of the user. Our movement-based checkpointing scheme takes a checkpoint only after a threshold of mobility handoffs has been exceeded. The optimal threshold is governed by the failure rate, log arrival rate, and the mobility rate of the application and the mobile host. This allows the tuning of the checkpointing rate on a per application and per mobile host basis. We identify the optimal movement threshold which will minimize the recovery cost per failure as a function of the mobile node's mobility rate, failure rate and log arrival rate. We also calculate the recoverability, i.e., the probability that the recovery can be done by a specified recovery time, and discuss the applicability of the approach.", "authors": ["Sapna E. George", "Ing-Ray Chen", "Ying Jin"], "n_citation": 52, "references": ["11f52fe3-4eca-4818-9bcf-9e24cdc76fb5", "124f3621-387d-4005-9735-3a6c5f594197", "357d4b44-8dec-4c0d-bcb6-ccddeb0f4a2c", "53a5edd7-07cc-4cc2-9766-80757b9e3f01", "53e6e46a-07e7-4acf-86f3-036259741b75", "5cc8457a-4f55-4154-9ce1-fd5082c017d4", "643a3b5d-03b9-4cac-9e9f-abb52eb48693", "788fcd34-fc21-40df-b62f-b0159f2f93fb", "b909a6d0-1b32-44a1-a197-78644cc04bad", "c29d7d9b-4f0b-4afd-ad70-c0c0f27998bb", "e3256f35-624e-41b9-b231-622721fff033"], "title": "Movement-based checkpointing and logging for recovery in mobile computing systems", "venue": "data engineering for wireless and mobile access", "year": 2006, "id": "44e9e253-0795-4eb4-8b2e-93aacf092258"}
{"authors": ["Job Zwiers"], "n_citation": 50, "references": ["0de8a07f-7011-4134-b726-78afb8b6536d", "81ad8d98-8e9c-492c-9f0e-dc4b1e6d3d8b", "9a0eaf85-af7b-44cf-9bd4-e18c884bb490", "9ba64329-fb53-4018-8afd-c292f9f8860d"], "title": "Layering and Action Refinement for Timed Systems", "venue": "", "year": 1991, "id": "0a5e58c4-2bcc-43a2-9b7c-8fff450fc4b4"}
{"abstract": "The Interactive Multimedia Intelligent Tutoring System (IMITS) is designed to assist electrical engineering undergraduate students taking their first circuits courses. The IMITS system places the student in a real-life engineering scenario in which the student is a newly hired engineer within the fictional IMITS Corporation and given \"real-life\" problems to solve, corresponding to course material. The office has file cabinets, bookshelves, a printer, and a personal computer. The personal computer allows the student to receive televideo messages, receive \"e-mail\", and send \"e-mail\" reports to senior engineers. A feature of IMITS is that the student decides which actions to take and may validate analyses and designs using a virtual laboratory incorporated with the software. A brief historical perspective of intelligent tutoring systems is presented, followed by an explanation of their architecture. Next, a detailed discription of the intelligent tutoring system IMITS is given. Then the results of usability and effectiveness evaluations of the software are given", "authors": ["Brian P. Butz", "Michael Duarte", "Susan M. Miller"], "n_citation": 63, "references": ["443aff6d-32ba-41e2-b651-35801aab802b", "78ec75a6-7992-4497-8e40-cb5cd72ab734"], "title": "An intelligent tutoring system for circuit analysis", "venue": "IEEE Transactions on Education", "year": 2006, "id": "0b038a2f-10ee-4b7b-ac91-7c6b90bf85d0"}
{"authors": ["Benjamin C. Pierce", "David N. Turner"], "n_citation": 597, "title": "Pict: a programming language based on the Pi-Calculus", "venue": "", "year": 2000, "id": "684f80ac-4d7d-46eb-9d1b-2599bae23de6"}
{"abstract": "Several recent studies indicate that many industrial applications exhibit poor quality in the design of exception-handling. To improve the quality of error-handling, we need to understand the problems and obstacles that developers face when designing and implementing exception-handling. In this paper, we present our research on understanding the viewpoint of developers-novices and experts-toward exception-handling. First, we conducted a study with novice developers in industry. The study results reveal that novices tend to ignore exceptions because of the complex nature of exception-handling. Then, we conducted a second study with experts in industry to understand their perspective on exception-handling. The study results show that, for experts, exception-handling is a crucial part in the development process. Experts also confirm the novices' approach of ignoring exception-handling and provide insights as to why novices do so. After analyzing the study data, we identified factors that influence experts' strategy selection process for handling exceptions and then built a model that represents a strategy selection process experts use to handle exceptions. Our model is based on interacting modules and fault scope. We conclude with some recommendations to help novices improve their understanding of exception-handling.", "authors": ["Hina Shah", "Carsten G\u00f6rg", "Mary Jean Harrold"], "n_citation": 45, "references": ["17cad5cf-eeef-440f-8e49-9a202747fe7f", "339e1da8-4dbe-48d1-bbcd-17b26c383b0a", "853a1f3b-9bfc-41d0-850c-de7764a6cc79", "8bd4161d-4ac7-42a9-abe5-f0bb38719581", "9d0b5a9b-6854-48b1-aa7b-1909dd981629", "b4b62316-e30f-482a-abc0-d1a6eaa250cd", "b6dba649-3614-4073-8ca4-0f84b73ca1bf", "cacf17ba-3601-4db2-baf6-1aac1ea14b46", "cc7e13d8-953b-4e94-8c41-5bf397aab61c", "d09f7451-5342-4b5a-aac6-01c4449ed097", "f4bb8093-dd97-457b-88a7-8c18d017bcf9"], "title": "Understanding Exception Handling: Viewpoints of Novices and Experts", "venue": "IEEE Transactions on Software Engineering", "year": 2010, "id": "7a7abec8-ce04-4786-9f1c-3b24ab58270b"}
{"authors": ["Marcin Jurdzinski", "Jeremy Sproston", "Fran\u00e7ois Laroussinie"], "n_citation": 74, "references": ["10e8157e-963a-44e8-b4f6-f2cf054da376", "2383e70b-0513-4e40-9719-a4c3eb46589c", "56581228-ef84-4f6b-b0df-44c2ddd976f5", "74391027-89df-4e55-aa3b-8862aa020d45", "7a663fd9-67bf-44c0-8fe6-f574675ae736", "7d0aacf2-c65e-4bec-a38e-2177b8fec842", "7d72a9b2-5330-4388-8243-ea3e567379a7", "84f69ceb-6599-4f6a-980f-c4331ddbefc4", "8f14b017-09cd-47a2-b947-4b5daf308fde", "9a7e8549-bc5a-4fac-bba9-c4951f655a31", "a0168090-d78a-4692-ad70-d081f9803fdf", "aab8c482-f4bd-4e7b-b92a-63c2d002f55b", "c00bbb49-6e29-4103-8883-55acd23c248b", "cda7f5b9-2ebc-45d4-ba8e-c06535133100", "d50d5956-1fc0-42b3-99f3-0bcdd7050df3", "daf3eb53-6ac8-43f2-8009-01986e701499", "e82ac6ce-36e8-43d3-8539-7055847e420f", "f1029115-54b8-42a1-a30c-9e76a2fcc3c7", "f1e47811-8ef7-4bf8-b505-7c595b57d49f", "f34427d2-a7f4-4ef0-ae58-831da6037aed"], "title": "Model Checking Probabilistic Timed Automata with One or Two Clocks", "venue": "Logical Methods in Computer Science", "year": 2008, "id": "b657d260-6e42-4a12-810e-50d964525770"}
{"abstract": "Virtually all mail sorting machines currently used in China only recognize post code and ignore the useful destination address information on the envelopes. This paper discusses how to efficiently utilize such important information on handwritten Chinese envelopes in order to improve the sorting performance. For this purpose, two particular problems are addressed, respectively. One is the location of destination address block (DAB) on the envelope, and a new bottom-up location method is described in detail. The other is the interpretation of handwritten Chinese destination address strings. We present our effort on using as many geometric constraints as possible in the string segmentation. Then a novel address interpretation algorithm with global optimization is proposed. It combines the segmentation, recognition and address context information by the best-path search. The effectiveness of the proposed algorithms is fully demonstrated by our experiments on real envelopes.", "authors": ["Junliang Xue", "Xiaoqing Ding", "Changsong Liu", "Rui Zhang", "Weiwei Qian"], "n_citation": 14, "references": ["0c96a3dc-3a9e-4171-bde8-8247eeaa2f38", "3a6fffa8-3105-44d6-941d-9b45983c1155", "75409195-2c67-4e4a-afb7-7c7d474f10f7", "7f889ebe-c2c0-4020-b52a-422f5b9930ac", "8e2e4199-4744-4984-bc96-fc9dd886eca9", "b8cb542b-721a-4334-9674-373fd36ecd34", "c481b1d2-e3a4-4d99-9457-1fa8c91f0dac", "d4770a36-44ad-43e1-8d5a-a5c454f75f2d", "ee4a89ea-72ac-4064-aefb-92bc7d482493"], "title": "Location and interpretation of destination addresses on handwritten Chinese envelopes", "venue": "Pattern Recognition Letters", "year": 2001, "id": "b12b2a61-134b-45ee-b49f-855b8aaff74a"}
{"abstract": "Many animals, including insects, successfully engage in visual homing. We describe a system that allows a mobile robot to home. Specifically, we propose a simple, yet robust, homing scheme that only relies upon the observation of the bearings of visible landmarks. However, this can easily be extended to include other visual cues. The homing algorithm allows a mobile robot to home incrementally by moving in such a way as to gradually reduce the discrepancy between the current view and the view obtained from the home position. Both simulation and mobile robot experiments are used to demonstrate the feasibility of the approach.", "authors": ["K. Weber", "Svetha Venkatesh", "Mandyam V. Srinivasan"], "n_citation": 86, "references": ["5c87d0aa-ca65-48f9-88f6-3a31866d6794", "696df56b-c1f9-4fb4-9f66-73e944ae9061", "6f686bb9-4eff-42d1-a847-05c112ed229f", "c31942bd-f81d-4d49-b88d-609e7b70c123", "ca97a07a-d25b-4c07-b5e8-3e05e5621d22"], "title": "Insect-inspired robotic homing", "venue": "Adaptive Behavior", "year": 1999, "id": "88e324cb-3391-47f8-b57e-45a09e9abc98"}
{"abstract": "We establish, for the first time, an explicit and simple lower bound on the nonlinearity Nf of a Boolean function f of n variables satisfying the avalanche criterion of degree p, namely, Nf \u2265 2n-1 - 2n-1-1/2p. We also show that the lower bound is tight, and identify all the functions whose nonlinearity attains the lower bound. As a further contribution of this paper, we prove that except for very few cases, the sum of the degree of avalanche and the order of correlation immunity of a Boolean function of n variables is atmost n-2. These new results further highlight the significance of the fact that while avalanche property is in harmony with nonlinearity, it goes against correlation immunity.", "authors": ["Yuliang Zheng", "Xian-Mo Zhang"], "n_citation": 37, "references": ["0269ee73-7848-4b20-a4b2-c0740e0f35b0", "208d44d6-ed91-49e5-8630-e701e89e5290", "2ee5babb-09aa-4b24-8db1-f75c233ae13d", "40c18b28-01be-4b94-8731-b67b60a9ea55", "42707a85-1846-4586-b02c-eb6591c1fa67", "48015aaf-bd21-4422-9604-8aa834b93cc6", "4c4f2a98-5049-4ce1-badb-3fe641c72b85", "55728d5b-3120-4c7e-8d14-691c0ae7e36d", "8c84fd79-ebc7-4b81-b6e7-37c4fdae15b0", "ac1c6c13-b310-42e7-9545-60c047fe68a4", "b1525009-6488-41ab-9829-fb08c1c534eb", "d383d3e8-6d16-4aa0-9083-30fb1dcd0e1a", "d9e8f3a9-397f-4c28-8c60-a653a596ab2d", "e7e33543-1793-4290-a514-9df9465ceffa"], "title": "On Relationships among Avalanche, Nonlinearity, and Correlation Immunity", "venue": "international conference on the theory and application of cryptology and information security", "year": 2000, "id": "b4cca6e1-dccf-4193-b458-b0dd51ea449e"}
{"abstract": "In this paper, a novel methodology called a reference model approach to stability analysis of neural networks is proposed. The core of the new approach is to study a neural network model with reference to other related models, so that different modeling approaches can be combinatively used and powerfully cross-fertilized. Focused on two representative neural network modeling approaches (the neuron state modeling approach and the local field modeling approach), we establish a rigorous theoretical basis on the feasibility and efficiency of the reference model approach. The new approach has been used to develop a series of new, generic stability theories for various neural network models. These results have been applied to several typical neural network systems including the Hopfield-type neural networks, the recurrent back-propagation neural networks, the BSB-type neural networks, the bound-constraints optimization neural networks, and the cellular neural networks. The results obtained unify, sharpen or generalize most of the existing stability assertions, and illustrate the feasibility and power of the new method.", "authors": ["Hong Qiao", "Jigen Peng", "Zongben Xu", "Bo Zhang"], "n_citation": 141, "references": ["0279a70f-c4ff-4f71-9b97-84946daea54a", "04530f26-3d0d-418d-956f-d30fd85be7b6", "15280758-1065-495f-a329-b8a3725d7380", "24310d4d-1a07-4a1a-8ded-8639111c81af", "2d3d7e62-fba5-4b26-8592-89da7e1839a5", "67c1586a-1c19-4609-8f2e-ec9d4ba115be", "6d45741c-a175-4ea1-a3d3-e75a978cd387", "79941139-d1a1-4e8f-85bd-034d2e76ac65", "8a13c341-5a03-4ad5-af3e-4136474c43c2", "92217906-f5bf-498d-94a7-d6e69d882585", "93a4f430-01d6-4526-a223-cb3c0d185cbb", "9a63bffd-6cad-4966-807a-1b8ff0c0b30d", "bf5205ea-ff18-458b-b0fe-3cd7265584db", "c4fc3454-10b3-4624-ac11-2e1c68db0f3b", "c795a00d-8c02-41af-a718-136dceb95b67", "eb21e188-e153-478c-a8a3-3c7f35eed5ed", "ecef8a12-8973-4ab9-8978-ce8c95c68262", "ed62a1ff-afa4-41ac-8292-c66ac583f00b", "f12827ab-7d9c-4136-868d-94a0a1e1463c", "ffaefcb4-fea4-480d-bbc1-cf57a8ece2ce"], "title": "A reference model approach to stability analysis of neural networks", "venue": "systems man and cybernetics", "year": 2003, "id": "01ed893f-57d3-4dec-8079-612417960d10"}
{"abstract": "A noise map facilitates monitoring of environmental noise pollution in urban areas. It can raise citizen awareness of noise pollution levels, and aid in the development of mitigation strategies to cope with the adverse effects. However, state-of-the-art techniques for rendering noise maps in urban areas are expensive and rarely updated (months or even years), as they rely on population and traffic models rather than on real data. Participatory urban sensing can be leveraged to create an open and inexpensive platform for rendering up-to-date noise maps.   In this paper, we present the design, implementation and performance evaluation of an  end-to-end  participatory urban noise mapping system called Ear-Phone. Ear-Phone, for the first time, leverages  Compressive Sensing  to address the fundamental problem of recovering the noise map from incomplete and random samples obtained by crowdsourcing data collection. Ear-Phone, implemented on Nokia N95 and HP iPAQ mobile devices, also addresses the challenge of collecting accurate noise pollution readings at a mobile device. Extensive simulations and outdoor experiments demonstrate that Ear-Phone is a feasible platform to assess noise pollution, incurring reasonable system resource consumption at mobile devices and providing high reconstruction accuracy of the noise map.", "authors": ["Rajib Rana", "Chun Tung Chou", "Salil S. Kanhere", "Nirupama Bulusu", "Wen Hu"], "n_citation": 471, "references": ["0944af6a-037f-4ac8-9f75-4270555e69bd", "6de0570a-e000-43d6-85ef-72e6f62f975a", "70907f21-e75b-4d6f-9486-ca873a35ac2b", "7c280097-d629-4bd4-b706-178f7a75d421", "91630dc8-a45c-4be6-9909-6f0d1dbac27e", "9f4b09e2-2f7d-4ec3-97ac-b7cefd74cbbf", "ad963c42-1e69-4da7-a185-b7b23af46656"], "title": "Ear-phone: an end-to-end participatory urban noise mapping system", "venue": "information processing in sensor networks", "year": 2010, "id": "69fae176-953c-499a-889e-6a82539f4160"}
{"abstract": "The authors analyze the error behavior for the discrete-time extended Kalman filter for general nonlinear systems in a stochastic framework. In particular, it is shown that the estimation error remains bounded if the system satisfies the nonlinear observability rank condition and the initial estimation error as well as the disturbing noise terms are small enough. This result is verified by numerical simulations for an example system.", "authors": ["Konrad Reif", "Stefan G\u00fcnther", "Edwin Engin Yaz", "Rolf Unbehauen"], "n_citation": 558, "references": ["5ddb8f58-1abc-4d5b-b045-72cbb50f3c0b", "9e667d8a-ebf3-4705-ad53-6de482b5c01f", "c023333e-e3dc-4d55-b6ea-f3f194cbcbc6", "e741d2a6-ae97-4890-a38a-9e92214ae5e7", "f742d90c-c39b-4d5b-9b1c-76fba28dcbb3"], "title": "Stochastic stability of the discrete-time extended Kalman filter", "venue": "IEEE Transactions on Automatic Control", "year": 1999, "id": "1239dd82-6b31-4e8d-a59d-4d9fab15df7d"}
{"abstract": "This paper describes a new search technique for large vocabulary speech recognition based on a stack decoder. Considerable memory savings are achieved with the combination of a tree based lexicon and a new search technique. The search proceeds time-first, that is partial path hypotheses are extended into the future in the inner loop and a tree walk over the lexicon is performed as an outer loop. Partial word hypotheses are grouped based on language model state. The stack maintains information about groups of hypotheses and whole groups are extended by one word to form new stack entries. An implementation is described of a one-pass decoder employing a 65000 word lexicon and a disk-based trigram language model. Real time operation is achieved with a small search error, a search space of about 5 Mbyte and a total memory usage of about 35 Mbyte.", "authors": ["Tony Robinson", "James Christie"], "n_citation": 40, "references": ["4516e177-3699-4837-b61c-963c961b37ff", "e86f50f8-a4ca-4fbb-9d9a-db464ce88532"], "title": "Time-first search for large vocabulary speech recognition", "venue": "international conference on acoustics speech and signal processing", "year": 1998, "id": "96610fb2-30cc-4081-97b5-499bf8357782"}
{"authors": ["William E. Richardson"], "n_citation": 50, "references": ["78b07ec1-4762-42fe-ad1e-6b6e97efed15", "b7e0e25e-5d30-49ac-adeb-d1da77823cad", "baac40a6-08e6-4d89-bea3-ba66d3d70a68"], "title": "Undergraduate Software Engineering Education", "venue": "computer science and software engineering", "year": 1988, "id": "1528660e-46b3-4d75-9e56-8ba8551f3393"}
{"abstract": "This paper deals with the problem of estimating the state of a discrete-time linear stochastic dynamical system on the basis of data collected from multiple sensors subject to a limitation on the communication rate from the sensors. More specifically, the attention is devoted to a centralized sensor network consisting of: (1) multiple remote nodes which collect measurements of the given system, compute state estimates at the full measurement rate and transmit data (either raw measurements or estimates) at a reduced communication rate; (2) a fusion node that, based on received data, provides an estimate of the system state at the full rate. Local data-driven transmission strategies are considered and issues related to the stability and performance of such strategies are investigated. Simulation results confirm the effectiveness of the proposed strategies.", "authors": ["Giorgio Battistelli", "Alessio Benavoli", "Luigi Chisci"], "n_citation": 20, "references": ["0aef08a4-9fb6-41df-a465-94dd331e7825", "18c7c422-75bb-4181-ab26-dc16c519c41f", "3c24e98a-ef68-4e47-bb92-09ec0991ea0a", "3c7e1ef1-fa85-4b0f-8c18-d31d0a59bf30", "4062d776-ae5e-441c-aa27-a31dd7293f82", "746c76b2-95de-4ace-9568-88f093a6242b", "8e82abb9-c538-495b-9c75-78221d4251d8", "a4e07d15-98b8-4fc6-9d47-72530fb8c0f9", "ac2e8959-4c7b-4787-931a-34dfa0196b94", "bf40f657-d004-4b64-8fd8-25b5971a1dc4", "e50f36ee-c4d5-4bd8-8983-b6e844b610c1"], "title": "Brief paper: Data-driven communication for state estimation with sensor networks", "venue": "Automatica", "year": 2012, "id": "fc64da1d-68fe-4ffb-9834-7a1c228c4e6f"}
{"abstract": "Judging by the wealth of problems reported in the literature, information systems (IS) and general managers are not sure how to manage the introduction of new information technology. One step toward providing sound management guidelines is to improve understanding of the social forces which affect the introduction and diffusion process within organizations. This research takes a step toward that goal by examining the validity of innovation diffusion theory within the context of end-user computing. The research involved a field study and historical analysis of the diffusion of spreadsheet software in organizations. To assist in controlling exogenous factors, only finance and accounting departments were studied. Over 500 professionals in 24 business units from 18 large businesses in manufacturing and services participated in the research. Findings supported hypotheses that earlier adopters of spreadsheet software were younger, more highly educated, more attuned to mass media, more involved in interpersonal communication, and more likely to be opinion leaders. Also supported was the hypothesized sigmoidal distribution of adoption over time. Application of the theory was not supported in all areas, however, suggesting that information technology diffusion is different from other diffusion phenomena. Contrary to theory, interpersonal channels of communication were dominant in all phases of adoption decision making. And contrary to their hypothesized role as change agent, IS departments played a minor role in the diffusion process. This was consistent with the observed user-led nature of the phenomenon. Implications for research and practice are discussed.", "authors": ["James C. Brancheau", "James C. Wetherbe"], "n_citation": 514, "references": ["1df5245f-77c8-484a-811b-5cae5a8b54ac", "9967cd2b-0616-49e6-85f9-21b972d2580d", "af0b55cd-692f-4be2-943c-1aa64ad46f18", "cafaf04b-b64d-46d2-9485-b0d09995a9e4", "f48d5699-3965-4b84-a609-569c9f529ad6"], "title": "The Adoption of Spreadsheet Software: Testing Innovation Diffusion Theory in the Context of End-User Computing", "venue": "Information Systems Research", "year": 1990, "id": "fe2cf63c-b3ba-4580-a7b3-9995d9610c67"}
{"abstract": "The Real-time Specification for Java (RTSJ) introduced a range of language features for explicit memory management. While the RTSJ gives programmers fine control over memory use and allows linear allocation and constant-time deallocation, the RTSJ relies upon dynamic runtime checks for safety, making it unsuitable for safety critical applications. We introduce ScopeJ, a statically-typed, multi-threaded, object calculus in which scopes are first class constructs. Scopes reify allocation contexts and provide a safe alternative to automatic memory management. Safety follows from the use of an ownership type system that enforces a topology on run-time patterns of references. ScopeJ's type system is novel in that ownership annotations are implicit. This substantially reduces the burden for developers and increases the likelihood of adoption. The notion of implicit ownership is particularly appealing when combined with pluggable type systems, as one can apply different type constraints to different components of an application depending on the requirements without changing the source language. In related work we have demonstrated the usefulness of our approach in the context of highly-responsive systems and stream processing.", "authors": ["Tian Zhao", "Jason Baker", "James J. Hunt", "James Noble", "Jan Vitek"], "n_citation": 22, "references": ["01fb4d45-bde3-4833-a007-4d8bbf4c3c64", "06ffefee-1eff-4644-8d0f-3d2c6563888f", "222fb0b5-a142-4d1d-8a74-d187b98dfc4c", "23d00708-410e-4049-9573-57702ab606ff", "2d5242fb-346e-48e9-b0a8-9ef6c87d94a6", "31726ce5-02f6-4a0f-8f0e-b1b3348600e0", "33efbbca-dcb2-48f6-a5cb-60917579fc6c", "42c4f67e-2639-42bf-ad14-9d2867978a6c", "452d0fc2-2096-49e4-9a00-4a3047a42b86", "4c87740f-1202-4306-84d8-c32013fe2383", "60c12e13-ae2b-42ad-bbc7-c7aae2f50a10", "616e8f92-c909-4870-a119-c0a6a3f22a09", "62bae75e-3a11-4917-b1ad-d47822f51ac5", "6f8ca083-ca18-4f86-ac05-a5a31942bbaf", "820e69ed-8333-4150-8fa2-7c550fa8cf8a", "89aa0933-6475-48fe-b965-73639eeca5a6", "8f555660-fcec-41c5-ae92-ad9d2b8e1666", "a34cef51-7a4c-49c9-b1a4-54b20f965c00", "a7440d6d-380f-450b-9c1a-adb360fafae5", "a7a1829b-8176-4b0d-9825-414d3fe20838", "a850da0e-b279-47ed-8248-a493ff9a5c1d", "abb48f4a-0e25-4701-996c-379e36bba24a", "bdb2e932-7f60-4b02-8812-45f6bc516a54", "bf9cecbb-daea-4cda-b521-e78ed8413382", "c61d7b91-9a98-441f-a926-f2edf261854e", "c814fa31-8dfc-4705-86aa-165565df04c4", "cb764a4a-e976-4d65-84a8-2dc58c37ca43", "d5053d6b-db0d-4f87-945d-52a523bea54b", "d8cae251-39e4-43d2-b41a-fb64646de19f", "db9f2ad1-b152-4413-80ef-182b89f2db0c", "dc8996da-7eb2-4f75-9728-9e835634b6f7", "e00183e2-2c19-4135-81e0-c506b3660be6", "ec19ff7d-4be4-4670-8908-1d49de7967c6", "f041c8dc-53c6-4747-a61a-6f3b3af82d3b", "f10cfb56-1737-4597-87cf-75f35143a3e5"], "title": "Implicit ownership types for memory management", "venue": "Science of Computer Programming", "year": 2008, "id": "5e3bfbf0-d016-4f2b-8bae-62bb2242902b"}
{"abstract": "Factor graphs and Gibbs sampling are a popular combination for Bayesian statistical methods that are used to solve diverse problems including insurance risk models, pricing models, and information extraction. Given a fixed sampling method and a fixed amount of time, an implementation of a sampler that achieves a higher throughput of samples will achieve a higher quality than a lower-throughput sampler. We study how (and whether) traditional data processing choices about materialization, page layout, and buffer-replacement policy need to be changed to achieve high-throughput Gibbs sampling for factor graphs that are larger than main memory. We find that both new theoretical and new algorithmic techniques are required to understand the tradeoff space for each choice. On both real and synthetic data, we demonstrate that traditional baseline approaches may achieve two orders of magnitude lower throughput than an optimal approach. For a handful of popular tasks across several storage backends, including HBase and traditional unix files, we show that our simple prototype achieves competitive (and sometimes better) throughput compared to specialized state-of-the-art approaches on factor graphs that are larger than main memory.", "authors": ["Ce Zhang", "Christopher R\u00e9"], "n_citation": 50, "references": ["00ba307f-cf25-4833-8896-9c91356e84b1", "03ec40ae-43cc-4570-83aa-c32b70230257", "0c7dccb4-bc9e-47b8-a373-98c8bbc5977f", "0fa7f858-f937-485d-9e24-8096a88c3cc7", "1b3aa05e-701f-4f32-948a-f6e6016e92c2", "240a1e0b-789a-4641-bdac-d6613f108220", "3df6f2ab-b051-4d27-8b58-503a7f256593", "400299f5-6b73-4ea9-b1cc-c4460f8b60c4", "42c64943-cd60-4d01-bf64-5e89d2982a46", "4a30f7fe-0022-4c8b-905b-cbed44b83b38", "4f384e4f-f134-43cd-97d5-ee6813c92bf2", "52981273-36dc-429f-a12d-bada6edee02e", "60ab7033-7d10-44ab-a313-46e138764b34", "719a5559-b6be-48d2-8375-7387992f06f1", "842af4d1-b82a-4dc1-955f-6fdfc099b20d", "8437b22c-59d5-4107-b733-5e99d3045457", "890d9ce0-4ed7-4d09-8b64-eb3e6cdf9ac2", "8aec0b95-75e5-47f2-b385-79f8bafe4e90", "9737bfd4-33d6-4b2a-9ddc-f1d98f1ee096", "9dadc207-0188-422d-ab86-ebce5f016ff9", "a445d289-4be6-4564-b6f2-a71642724f8e", "a960d05e-4c39-4c8e-b559-dbdc17db6194", "ae829318-5d10-461d-9c99-34a95a3f8732", "b9b47583-e1b1-4ddb-a368-a1f8b1c53cda", "c54c0271-a8b0-4c75-999a-414ff6c1cf8a", "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706", "dada53d8-bb7e-4e58-a5d9-41356d46b598", "edaaa4cf-f37a-4011-b1fa-962c44a7e808", "f12b9e42-412e-427e-87cc-223cfd4fe128", "f21c4eee-6217-4cf8-9069-c458779388ec", "faa4d042-0fa9-47fb-8c18-03bfb80df31d", "fc8d6144-11cb-4150-bbbc-1ff48d3fd156", "fd3d707a-c237-4924-b5c3-037e49e1fcb8"], "title": "Towards high-throughput gibbs sampling at scale: a study across storage managers", "venue": "international conference on management of data", "year": 2013, "id": "e4218bc9-fb47-457e-b500-4d921251502d"}
{"abstract": "We motivate a context fusion network (CFN), an infrastructure model that allows context-aware applications to select distributed data sources and compose them with customized data-fusion operators into a directed acyclic information fusion graph. Such a graph represents how an application computes high-level understandings of its execution context from low-level sensory data. Multiple graphs by different applications interconnect with each other to form a global graph. A key advantage of a CFN is reusability, both at code-level and instance-level, facilitated by operator composition. We designed and implemented a distributed CFN system, Solar, which maps the logical operator graph representation onto a set of overlay hosts. In particular, Solar meets the challenges inherent to heterogeneous and volatile ubicomp environments. By abstracting most complexities into the infrastructure, Solar facilitates both the development and deployment of context-aware applications. We present the operator composition model, basic services of the Solar overlay network, and programming support for the developers. We also discuss some applications built with Solar and the lessons we learned from our experience.", "authors": ["Guanling Chen", "Ming Li", "David Kotz"], "n_citation": 148, "references": ["062ebcdd-a13c-479a-a770-ce4d8c4ef261", "0661565a-3f0f-4cec-b7e9-f6c4f1736a0f", "0ba640e8-a0ab-4d39-b13b-c85572a5c57d", "16753166-7737-4a5c-af8e-8f67816bc5bf", "2088d2fd-d0ed-477f-b350-5d342624e91e", "5ad83b9b-6ae3-42ea-9b5f-e2fabe669c74", "6b5a21d8-f5b5-4a78-b394-df792e4a8e3f", "7048a771-b00c-42b7-800b-e8a0108671f3", "7e1a86e0-df71-4c13-bae3-700e97ec26ca", "83cff325-43e0-4161-aedd-01bd59463cc7", "90b95e79-7494-4a92-94bb-930392bf8477", "a5a4cf29-7161-4648-a1f4-8cc95aa725b7", "af4cc774-cab4-4888-9bcf-f29449a58e56", "babbda69-61a0-4231-845c-48d7fd5183aa", "bf35b9a8-959e-40b4-b031-0f1a8f615c79", "c069c256-4bb6-47f4-ab26-ad160161d03d", "c3ffb813-467f-4623-984f-bd4c6ac9adea", "c8a9ae18-703f-4996-91cc-2eabe0735c3b", "dbb9b570-9eff-408b-9e8f-e7f6939cf330", "dc98562f-e69f-4522-9123-8dbab20ffb33", "dd60cb9b-afc4-48b0-a255-72caf89d96ed", "e2593748-76d0-41b2-ac6b-1f72abea0652", "efa04de8-fec3-4c73-8031-5b7990b88e57", "f14df1ed-e3e9-4348-9040-fc06e3411b95", "fa33f31a-5556-4d58-b26e-58437c190bc0"], "title": "Design and implementation of a large-scale context fusion network", "venue": "international conference on mobile and ubiquitous systems networking and services", "year": 2004, "id": "47f85a24-6612-45a2-95ac-15eca4a12075"}
{"authors": ["Jan Chomicki", "Dina Q. Goldin", "Gabriel M. Kuper"], "n_citation": 61, "references": ["02a7486f-4802-4b52-953f-396ce93ee0bd", "2d414d43-bfaa-49a2-9560-6595b0841489", "2f732eb5-eea0-4c7d-91c9-7ab90ff37c8c", "41590882-1008-4a6e-a3fe-2654bc0d0dde", "5f50049e-2c92-456e-8353-70a6e3e7dc88", "6583e0d9-22b9-4994-ae4e-71b16c9143a0", "66a7f48c-5b16-4584-ac3b-7ad946dbb54d", "67a17c2e-6d86-44d7-af9c-af4fdadf8d9f", "6f2ef4f5-89be-4831-8373-a65f378951b1", "764f7d36-f27b-4153-b055-0e83cb2c0445", "7bfbe4ca-728f-48b3-b837-feae3e172598", "b16cb3e5-731a-4c46-a8e9-7bef05e04533", "dd669dd5-d857-4c8e-b20b-d95812303ee4", "fe81edbd-cf3a-47a1-b387-8cd8409f60ce", "ff5eab7f-38e9-4700-b609-0618e279b4a7"], "title": "Variable independence and aggregation closure", "venue": "symposium on principles of database systems", "year": 1996, "id": "6d17ba72-6a2a-46d0-b96b-707b8a313b6d"}
{"authors": ["Jens Knoop", "Bernhard Steffen"], "n_citation": 166, "references": ["3595f070-1e9f-411f-b792-5e76102638fb", "4f52da41-30e5-46a2-9787-1b4ff2eb38ba", "5f51f095-db6f-4ef7-bb7e-9aaeeb59b3b9", "6aec0cf3-52c8-4b68-bc14-0e0c89e7416f", "6f3ce652-49c1-4c17-b5e1-df7c63dcd2f4", "9a4984f9-27d4-47eb-8bc8-0469bf540f94", "a06e2b30-85f3-4dba-bb18-04daa37807a7", "adc3ece1-718a-4667-897e-dc5ea1e89d1e", "f851d832-53ee-4260-8798-b2f53a2a17c9"], "title": "The Interprocedural Coincidence Theorem", "venue": "compiler construction", "year": 1992, "id": "e0c1b56b-6574-4db0-92ed-4a3a337053bd"}
{"abstract": "In this short paper we present the coDB P2P DB system. A network of databases, possibly with different schemas, are interconnected by means of GLAV coordination rules, which are inclusions of conjunctive queries, with possibly existential variables in the head; coordination rules may be cyclic. Each node can be queried in its schema for data, which the node can fetch from its neighbours, if a coordination rule is involved.", "authors": ["Enrico Franconi", "Gabriel M. Kuper", "Andrei Lopatenko", "Ilya Zaihrayeu"], "n_citation": 76, "references": ["13733df6-12a3-4060-99dc-fc64594dd436", "1905a346-c1dd-4ea7-bd87-9b58f3416628", "26d3c037-eca8-47db-a076-ef82224fed70", "322256c3-783e-4cce-9d31-f4a2b3698abe", "38906553-285e-44a3-931d-b16fbb99a297", "482932c4-e755-479e-9523-882e52e17c3e", "5b31ab33-f9e7-467e-8594-0c2d517a6418", "80efd50b-0ac2-422b-8b93-ea57f3350f88", "ac9f7c7a-9e58-4ac9-8cfb-3d9ea886822d", "bcf8abd7-10e4-4e3e-a9db-a1a0583c0568", "ed50c0fa-a423-42d1-bf7a-2c6c3472cd91", "f5ecfcce-e12e-4174-9c50-339dd8d949aa"], "title": "Queries and updates in the coDB peer to peer database system", "venue": "very large data bases", "year": 2004, "id": "0bb389d3-3a6f-43b1-8afc-080b117f0156"}
{"abstract": "State-feedback model predictive control (MPC) of discrete-time linear periodic systems with time-dependent state and input dimensions is considered. The states and inputs are subject to periodically time-dependent, hard, convex, polyhedral constraints. First, periodic controlled and positively invariant sets are characterized, and a method to determine the maximum periodic controlled and positively invariant sets is derived. The proposed periodic controlled invariant sets are then employed in the design of least-restrictive strongly feasible reference-tracking MPC problems. The proposed periodic positively invariant sets are employed in combination with well-known results on optimal unconstrained periodic linear-quadratic regulation (LQR) to yield constrained periodic LQR control laws that are stabilizing and optimal. One motivation for systems with time-dependent dimensions is efficient control law synthesis for discrete-time systems with asynchronous inputs, for which a novel modeling framework resulting in low dimensional models is proposed. The presented methods are applied to a multirate nano-positioning system.", "authors": ["Ravi Gondhalekar", "Colin Neil Jones"], "n_citation": 35, "references": ["09ebf1c0-0f00-4839-bdae-5a0cd51b9dbe", "1dfddb0a-c28f-4852-af75-d6c8f3c971a4", "314320d8-01d5-4085-8cad-a833db4f2dea", "3e7a4b12-6ee4-40aa-944f-f93f854784d8", "5252ee55-b413-498b-bd0f-49ed41abba07", "57e2e0ee-817b-443a-82ee-5a92cffc01b1", "8c90e988-0e76-4a2f-b04c-cbd0780712fa", "b216d48b-eda1-497f-adf0-59ca9d100aed", "bdae38de-9640-40d6-85b7-d5986f4728c8", "c146fe70-b870-4da0-b3b9-0a39eaaa6a38"], "title": "Brief paper: MPC of constrained discrete-time linear periodic systems - A framework for asynchronous control: Strong feasibility, stability and optimality via periodic invariance", "venue": "Automatica", "year": 2011, "id": "8867bab2-d302-43b8-81b7-deaf70f9c1f3"}
{"authors": ["Abraham Bookstein", "Shmuel T. Klein"], "n_citation": 88, "references": ["14793abe-f83c-4126-b77d-cd535d374885", "233bba97-2ca8-480c-95d6-e41269ae73d6", "247d995a-3dc2-4eda-b485-b2771c102a11", "3fe84238-10fb-4cba-a260-f61f75e21d31", "5f2e5fcc-54d7-4a71-840b-8b696f48811c", "6e52c17c-8e8c-4422-a6b2-6a279c434748", "873edd77-8a73-4f10-adf4-0e5f28a3da96", "886340ee-7553-44de-9e7c-c7effa4747f9", "ac316878-26b9-4344-bcf5-8143c2da3113"], "title": "Compression of correlated bit-vectors", "venue": "Information Systems", "year": 1991, "id": "75e00042-ffc7-42da-a2a4-9f2cf68d6a66"}
{"abstract": "Reusing existing library components is essential for reducing the cost of software development and maintenance. When library components evolve to accommodate new feature requests, to fix bugs, or to meet new standards, the clients of software libraries often need to make corresponding changes to correctly use the updated libraries. Existing API usage adaptation techniques support simple adaptation such as replacing the target of calls to a deprecated API, however, cannot handle complex adaptations such as creating a new object to be passed to a different API method, or adding an exception handling logic that surrounds the updated API method calls.   This paper presents LIBSYNC that guides developers in adapting API usage code by learning complex API usage adaptation patterns from other clients that already migrated to a new library version (and also from the API usages within the library's test code). LIBSYNC uses several graph-based techniques (1) to identify changes to API declarations by comparing two library versions, (2) to extract associated API usage skeletons before and after library migration, and (3) to compare the extracted API usage skeletons to recover API usage adaptation patterns. Using the learned adaptation patterns, LIBSYNC recommends the locations and edit operations for adapting API usages. The evaluation of LIBSYNC on real-world software systems shows that it is highly correct and useful with a precision of 100% and a recall of 91%.", "authors": ["Hoan Anh Nguyen", "Tung Thanh Nguyen", "Gary Wilson", "Anh Tuan Nguyen", "Miryung Kim", "Tien N. Nguyen"], "n_citation": 97, "references": ["05bd6a9b-8435-4cdc-86a0-b09f5659a53d", "0a25a3c5-daf8-4525-9846-69d727d29810", "0fc116cc-c1c5-4a24-8a7c-c183158147ab", "195ce5a0-d2b3-4ba8-af03-4c510215525b", "1adef97b-e0d8-4d0c-8a28-526e2b898301", "2ecc2c45-feac-42dc-aa25-07cfd98c22aa", "32ef1e64-2ffa-4476-b76a-c582777e1749", "34b7e270-80d7-46d5-a6f1-e50087a8d045", "388a9305-09f9-4b6e-a41b-5fd60d85f32b", "39977773-fa4b-46ba-a7a6-852ffa291806", "3c20ace8-7ab4-48be-9da0-ada5c87324e3", "4e539632-eacd-44cf-adc1-07255c238cf7", "4fc51346-1bd6-4c60-9b4e-78d2cb037f66", "578677eb-74e6-4f83-9c30-a5426587abc3", "5c3a2552-4dcd-4c8b-8195-be36652419f4", "6b884765-eeff-4697-a8c4-6ef5c9a87347", "7379df7a-d039-49c0-a32a-30b96d09d559", "7883bf2f-dddf-4705-9e39-ce14191f93e1", "795b3c5c-deeb-4281-b4de-d0f1b2d8478d", "7e4eb428-f372-4cb7-a1e9-991905e294b3", "89037109-6f3c-4ba0-b09f-9af808cba24b", "8dc14103-9da9-41b9-830f-96eda413749f", "ab6ea0f5-8a28-4847-bdcf-27ac367ede44", "af42e1dc-b9e1-4894-9d7c-602a4ccacc7f", "b3ef4366-2f14-467b-b784-2a854c8695fe", "b74fae63-605c-4b9b-8017-ce118c4aecc7", "b984854e-bcba-44c4-938b-95e12b82b31f", "ba027ccd-d7f1-40b2-86eb-932fd5ff742b", "c0183ac9-2586-40b4-ad76-cb577472e3b1", "cfba8e0f-e06e-491c-94a8-78013ad8bb30", "d1925fd6-cae1-4335-81df-635aa907a4ad", "d19403c2-6822-42a5-8c11-e54fcfa93770", "e036e1c9-1dd9-4f4c-8ed2-8166f47f43e9", "fab6a5e7-cc06-4858-9dbd-832c2d4751c3", "fcce2c61-51ce-4cca-ae8c-1b004b1482b4", "fd3c49de-62bb-4295-888f-7cfd4d1b4b49", "fec08d3e-46fa-4e15-9728-f7d5e369afec"], "title": "A graph-based approach to API usage adaptation", "venue": "conference on object-oriented programming systems, languages, and applications", "year": 2010, "id": "3010131d-75fd-42d3-8ed2-9afb4f6cfedd"}
{"abstract": "Reuse is not just a technical issue. Hewlett-Packard studied why people sometimes resist reuse and which organizational models appear to encourage reuse more than others. The study found that successful reuse programs must be integrated within the culture of a company's existing organizational structure. One crucial organizational factor is the relationship between producers and consumers of reuse components and services. What are these relationships and how well do they work? To answer this question, I conducted an empirical study of 10 engineering sites at Hewlett-Packard engaged in systematic reuse. From this reuse experience, I identified four models of producer-consumer relationships; evaluated the models in terms of their organizational structures, advantages, and disadvantages; and identified goals for management to enable a successful implementation. The four models are: lone producer, nested producer, pool producer and team producer. Two or more models may occur within a given reuse program. Recommendations to management are based on both current successful practices and interviewees' suggestions. I also include some tentative guidelines on which environments are best suited to each model. >", "authors": ["Danielle Fafchamps"], "n_citation": 79, "references": ["1881977e-6cec-434b-863d-e332fdbaf916", "3dbe9480-7071-46b5-ad7f-278756ff73de"], "title": "Organizational factors and reuse", "venue": "IEEE Software", "year": 1994, "id": "d282fd6c-19f2-43d8-b337-415c0ebaa335"}
{"abstract": "Abstract   We present a simple logic-based formalisation of the behaviours of agents capable of reacting to changes occurring in the external environment. Logic programming is chosen as the specification language of agents, and a quantitative analysis of the behaviours of reactive agents is described.", "authors": ["Antonio Brogi"], "n_citation": 4, "references": ["218317da-31f4-4f4c-a4d7-4e869e42ba85", "22e9e31e-8c9a-4b7d-8ab3-85123ee3740c", "409ad992-eebd-4d97-bf23-a281d26b3986", "51cb282f-23f0-46e0-8ee2-524d50aeb4a6", "6ceff6ac-c76c-4911-85ac-6f065fc86777", "ac2f9102-e02d-4cea-b059-bfc0172288ae", "bc70675e-9948-4f24-9f97-410660dbd99a", "db348c25-fd66-4f91-b676-6d9402cefaa2"], "title": "Probabilistic behaviours of reactive agents", "venue": "Electronic Notes in Theoretical Computer Science", "year": 2001, "id": "c61ac5ed-e0c4-424b-8509-763b6b6dd62d"}
{"authors": ["Hiroshi Kadota", "Katsuyuki Kaneko", "Ichiro Okabayashi", "Tadashi Okamoto", "Tetsuya Mimura", "Yasuhiro Nakakura", "Akiyoshi Wakatani", "Masaitsu Nakajima", "Junji Nishikawa", "Koji Zaiki", "Tatsuo Nogi"], "n_citation": 50, "references": ["73303426-2d4f-4ade-b3da-26d9511afc9d"], "title": "Parallel computer ADENART\u2014its architecture and application", "venue": "international conference on supercomputing", "year": 1991, "id": "9d0f1295-5c31-409f-b271-3a49c5efac19"}
{"abstract": "Visual languages (VLs) play a central role in modelling various sys- tem aspects. Besides standard languages like UML, a variety of domain-specific languages exist which are the more used the more tool support is available for them. Different kinds of generators have been developed which produce visual modelling environments based on VL specifications. To define a VL, declarative as well as constructive approaches are used. The meta modelling approach is a declarative one where classes of symbols and relations are defined and associated to each other. Constraints describe additional language properties. Defining a VL by a graph grammar, the constructive way is followed where graphs describe the abstract syntax of models and graph rules formulate the language grammar. In this paper, we extend algebraic graph grammars by a node type inheritance concept which opens up the possibility to integrate both approaches by identi- fying symbol classes with node types and associations with edge types of some graph class. In this way, declarative as well as constructive elements may be used for language definition and model manipulation. Two concrete approaches, the GENGED and the AToM 3 approach, illustrate how VLs can be defined and mod- els can be manipulated by the techniques described above.", "authors": ["Roswitha Bardohl", "Hartmut Ehrig", "Juan de Lara", "Gabriele Taentzer"], "n_citation": 102, "references": ["07bdfd0b-e23e-49e1-b92c-e09467ec7b6b", "0d261b6a-c94a-4d5e-b44e-eb6ae46581fc", "127579ed-9979-4004-b5e0-ce8a9d792bc8", "198f9886-fc6c-4ec3-a576-afb1f095bc88", "25596ebb-c238-42a4-8733-b51a9b166ada", "4d27e586-5c45-4811-94ff-0b8006ce1a80", "62e3d402-7635-4bbf-af7c-e1f385cfcf96", "8030858d-f5f6-46be-b6bf-a89c9b238f90", "ca3a6df7-bc8d-471c-b081-563a9d75de87", "db89ef2b-7a82-47d3-be7e-9431ef8700c7"], "title": "Integrating Meta-modelling Aspects with Graph Transformation for Efficient Visual Language Definition and Model Manipulation", "venue": "fundamental approaches to software engineering", "year": 2004, "id": "70d97a36-5af6-4671-aeb9-8ec7cd7575f1"}
{"abstract": "A new method to recognize continuous sign language based on hidden Markov model is proposed. According to the dependence of linguistic context, connections between elementary subwords are classified as strong connection and weak connection. The recognition of strong connection is accomplished with the aid of subword trees, which describe the connection of subwords in each sign language word. In weak connection, the main problem is how to extract the best matched subwords and find their end-points with little help of context information. The proposed method improves the summing process of the Viterbi decoding algorithm which is constrained in every individual model, and compares the end score at each frame to find the ending frame of a subword. Experimental results show an accuracy of 70% for continuous sign sentences that comprise no more than 4 subwords.", "authors": ["Quan Yuan", "Wen Geo", "Hongxun Yao", "Chunli Wang"], "n_citation": 17, "references": ["04684b63-05d0-4649-84c7-f6b4d3b060bf", "64eec0c9-2f98-4d93-83d3-24927ce04bf3", "73993e82-42b3-4a68-925a-f106fd5a51e0", "89592258-ae59-4ff5-b00c-b66ff38b2735"], "title": "Recognition of strong and weak connection models in continuous sign language", "venue": "international conference on pattern recognition", "year": 2002, "id": "9926b2b5-a20b-45f7-b4b2-224b4a4d6507"}
{"abstract": "This paper presents a new image interpolation approach based on variational principles. The image interpolation problem is formulated as the constrained minimization of a certain functional. The choice of the functional to be minimized is based on the combination of the restrictions imposed by the mathematical problem and certain considerations related to the physical problem. This paper focuses on the class of nonnegative quadratic functionals whose minimization amounts to 2-D L-generalized splines. The partial differential operators used correspond to certain stochastic partial differential equation (SPDE) image models. Image interpolation is exactly formulated in its discrete form and an extensive analytical treatment of the resulting minimization problem is subsequently presented. The implementation difficulties and computational requirements indicate that such a formulation cannot provide interpolation algorithms of practical value. The derivation of practical interpolation algorithms is based on an alternative formulation of the optimization problem. This new formulation allows the transformation of the original constrained minimization into an equivalent unconstrained one. A number of interpolation algorithms is proposed, based on various noncausal and semicausal SPDE image models. Finally, experimental results are presented, compared and discussed.", "authors": ["Nicolaos B. Karayiannis", "Anastasios N. Venetsanopoulos"], "n_citation": 37, "references": ["270481ae-4c13-4f38-8860-9a3be4006bad", "32f56178-2d7d-492b-bc84-102ca4e7099f", "330712fb-7e48-4874-bc83-cd222af26f23", "936e0ae4-e6e1-4b3b-9d0a-a6bff589fc7b", "93ef73d8-a140-49d1-8b50-f9209d5ead52", "c7e45d01-93dc-4912-a686-9191d1a91e81"], "title": "Image interpolation based on variational principles", "venue": "Signal Processing", "year": 1991, "id": "4eba03cc-4084-41ed-b039-663e3f3167e8"}
{"abstract": "In this paper, we present our networked virtual tennis game that has been developed as a hybrid framework with head-mounted display and fishtank virtual reality systems. The paper reports the findings of a hybrid collaboration task which compared the two systems based on their egocentric and exocentric features. The focus of the study was on the strengths and weaknesses in each system for the given particular task: How do users perform in each system? And how might each system complement the others for teamwork? We report on localization error and correct hit percentage results that were obtained during trials with the two types of systems. These results suggest that head-mounted displays with egocentric features allow more accurate spatial localization and the fishtank displays with exocentric features provide better cues for time synchronization events.", "authors": ["Alp V. Asutay", "Arun P. Indugula", "Christoph W. Borst"], "n_citation": 50, "references": ["07d54343-52d5-4278-9c35-a34451ec1dd0", "1fb3d685-8d9b-4511-8242-eeb9f5b6f1d4", "24a6c479-5644-4cb0-9a95-3d619de2c1fe", "5c42cf7d-f918-4f33-84fd-d8f60d1ab617", "ba82d1f4-5549-4c95-af47-500cee26bda8", "c78b2ac8-bbb8-4587-9293-e5e4c701a0c5", "e116be66-94ba-4da6-9467-6185c3ff296f", "fa2b49b2-3c76-48a1-92ba-c10233bd48b6"], "title": "Virtual tennis: a hybrid distributed virtual reality environment with fishtank vs. HMD", "venue": "", "year": 2005, "id": "3bf52bce-7168-4564-a7f5-d531a39487e8"}
{"abstract": "Multi-agent games are becoming an increasingly prevalent formalism for the study of electronic commerce and auctions. The speed at which transactions can take place and the growing complexity of electronic marketplaces makes the study of computationally simple agents an appealing direction. In this work, we analyze the behavior of agents that incrementally adapt their strategy through gradient ascent on expected payoff, in the simple setting of two-player, two-action, iterated general-sum games, and present a surprising result. We show that either the agents will converge to a Nash equilibrium, or if the strategies themselves do not converge, then their average payoffs will nevertheless converge to the payoffs of a Nash equilibrium.", "authors": ["Satinder P. Singh", "Michael J. Kearns", "Yishay Mansour"], "n_citation": 267, "references": ["efccc198-ee7e-470c-b933-6b2e8e37dcaf", "f96769cc-b034-4960-b890-cfba5c443b3d"], "title": "Nash Convergence of Gradient Dynamics in General-Sum Games", "venue": "uncertainty in artificial intelligence", "year": 2000, "id": "fceead9c-1a82-4ee4-9e12-1a99f990b7c1"}
{"abstract": "A fundamental choice in femtocell deployments is the set of users which are allowed to access each femtocell. Closed access restricts the set to specifically registered users, while open access allows any mobile subscriber to use any femtocell. Which one is preferable depends strongly on the distance between the macrocell base station (MBS) and femtocell. The main results of the this article are lemmas which provide expressions for the signal-to-interference-plus-to-noise ratio (SINR) distribution for various zones within a cell as a function of this MBS-femto distance. The average sum throughput (or any other SINR-based metric) of home users and cellular users under open and closed access can readily be determined from these expressions. We show that unlike in the uplink, the interests of home and cellular users are in conflict, with home users preferring closed access and cellular users preferring open access. The conflict is most pronounced for femtocells near the cell edge, when there are many cellular users and fewer femtocells. To mitigate this conflict, we propose a middle way which we term shared access in which femtocells allocate an adjustable number of time-slots between home and cellular users such that a specified minimum rate for each can be achieved. The optimal such sharing fraction is derived. Analysis shows that shared access achieves at least the overall throughput of open access while also satisfying rate requirements, while closed access fails for cellular users and open access fails for the home user.", "authors": ["Han-Shin Jo", "Ping Xia", "Jeffrey G. Andrews"], "n_citation": 40, "references": ["00d18ef6-0caf-49f5-86ca-4760a8b09902", "16f33bda-4e3d-448f-9fc5-c4aa0729b454", "1d614245-ba9a-4c78-9953-92fff31aa08e", "26c085b3-2b43-4a00-8df2-6edae136f169", "3f3cdc9b-b050-4a02-99ea-fb52ab69caad", "491e9a30-e336-4f28-8055-fb4326c35b98", "52dc957b-fc82-468c-94ce-54c1af3f4721", "54d364a6-fcf1-445d-bcc3-ca58c22f6973", "59c9c4b0-bc67-4d38-b286-e2018eb6b047", "69f23f08-a446-4498-bfca-be367cf8400d", "6cc116fc-0c78-4f07-a063-977fe012c3c7", "7cce8d88-c3c4-46ed-95df-f0577f874db5", "83061c09-85f7-4011-a02b-4db797203d06", "83f603e4-a378-4b2a-9fb5-26910b633e9a", "88a0c275-1fce-4f12-a40b-2472b871811e", "89753425-ace8-4edd-aaa0-2a4012ca7cd6", "8b4385ab-1839-4e1f-8b01-3b1bb3086748", "902856f3-d697-4be3-ac37-80181bf974fb", "a45e9778-ef50-41fc-b477-0bc864ca49a2", "a6057357-3441-4764-a535-4aa7d5b9fc3b", "a7d13553-7283-446c-89a0-5b13f2daa63f", "ac57fe4a-713d-4035-91f1-36ca116dec00", "b2a41538-10b7-4313-a2d4-a3ac924361e4", "b2d2a210-8641-4020-aafd-091cd928af45", "b6f8fc00-3f73-407b-9592-c197f6abc1aa", "b8220a0e-e7ed-4ddb-83fd-5b5ebc778ab5", "c3a7204d-51fc-45c9-9cce-5bcf9e81d566", "c611afd8-59b1-453d-8360-1926bea3fa96", "dada584b-3c77-4419-a999-8083a16a4108", "e03e87c0-54ef-423f-82a9-7f10ca4a00b2", "e3f9b425-1e14-4697-9b41-993c4968fdf0", "ef514450-6fb7-47cf-8b05-5f8ed1f393c8", "ef708533-4801-4a44-974b-5feb7e9da3d0"], "title": "Open, closed, and shared access femtocells in the downlink", "venue": "Eurasip Journal on Wireless Communications and Networking", "year": 2012, "id": "341b25a1-58d2-41c3-9e88-342e088cb194"}
{"authors": ["Werner Damm", "David Harel"], "n_citation": 50, "references": ["0d261b6a-c94a-4d5e-b44e-eb6ae46581fc", "18f08118-9f01-44bf-857f-8ae5e897d4b9", "39c72c08-2556-45fa-9963-aca832fe0f34", "3afb1209-0598-435f-a3e7-e4729eb4ce85", "424e52c7-6984-4ee5-9021-d6df0f1cb96a", "470b418c-efba-43ae-aa55-f4510f7d7b5c", "6ebabae4-1d8e-475b-8e90-72767495c811", "758704b4-8b8e-408b-a1bd-df5b77b11336", "b5fbaa5e-8016-4b7a-8ca0-b9d2359c97fc", "c5929c70-62ac-4ade-a7cd-aa414e60c63f", "dec4dcb2-c6fe-4b99-883d-dcec1f8ece86", "e4b409c7-becb-4919-befb-9d4bc14e1a58"], "title": "LSCs: Breathing Life into Message Sequence Charts", "venue": "formal methods for open object-based distributed systems", "year": 1999, "id": "bde46b2c-2ced-4aea-a1fc-9ce5b7156758"}
{"authors": ["Richard C. Bodner", "Fei Song"], "n_citation": 104, "references": ["1fc2bfe8-dd84-4a17-9f4e-539006b6b29a", "25da05f8-0688-43e3-84f4-3eb498d2bb5c", "366a2502-8abc-4930-9223-40b231f3e5cf", "440e7e85-a031-4e32-9961-3fac421e80bf", "90a7f1a7-6399-4f8e-8abd-843263e9e54c", "abe38dcd-53ce-48b3-8e3d-4702ddd4e4c0", "e75d8e62-a86d-4241-953f-1b315005d920"], "title": "Knowledge-Based Approaches to Query Expansion in Information Retrieval", "venue": "canadian conference on artificial intelligence", "year": 1996, "id": "bd673245-7c9d-4c70-ac67-87292ac24024"}
{"authors": ["Ana Iglesias", "Paloma Mart\u00ednez", "Dolores Cuadra", "Elena Castro", "Fernando Fern\u00e1ndez"], "n_citation": 6, "title": "Learning to Teach Database Design by Trial and Error.", "venue": "international conference on enterprise information systems", "year": 2002, "id": "ec291ba4-790e-41d2-bffb-a03c081b218a"}
{"abstract": "Better orderings of test cases can detect faults in less time with fewer resources, and thus make the debugging process earlier and accelerate software delivery. As a result, test case prioritization has become a hot topic in the research of regression testing. With the popularity of using the JUnit testing framework for developing Java software, researchers also paid attention to techniques for prioritizing JUnit test cases in regression testing of Java software. Typically, most of them are based on coverage information of test cases. However, coverage information may need extra costs to acquire. In this paper, we propose an approach (named Jupta) for prioritizing JUnit test cases in absence of coverage information. Jupta statically analyzes call graphs of JUnit test cases and the software under test to estimate the test ability (TA) of each test case. Furthermore, Jupta provides two prioritization techniques: the total TA based technique (denoted as JuptaT) and the additional TA based technique (denoted as JuptaA). To evaluate Jupta, we performed an experimental study on two open source Java programs, containing 11 versions in total. The experimental results indicate that Jupta is more effective and stable than the untreated orderings and Jupta is approximately as effective and stable as prioritization techniques using coverage information at the method level.", "authors": ["Lingming Zhang", "J.B. Zhou", "Dan Hao", "Lu Zhang", "Hong Mei"], "n_citation": 31, "references": ["0bd7b323-b8a6-4324-a5df-436dcf10804b", "0ed73fc7-0a43-4035-baeb-2ae130c184d5", "0f3a2b1b-7056-4db2-ac09-67f59d45ebce", "188276e0-6a5b-4c7a-a407-28f3978ea36b", "1d79213f-ba17-4cb7-90fb-59132ae38391", "29392886-b35a-429c-a211-e5dbe9f3d0cf", "30521aed-580e-4260-8074-24f470294419", "4849c8ca-d637-4e0c-97eb-f675f9392aa5", "4cb52e3c-7565-497d-8c7a-612bff7adacf", "50ff973a-0fa1-4dde-9d05-3d0737431b69", "58a77f39-fd3c-4379-9f04-5fdac60a736f", "67fdaffd-21ee-439e-b6ac-6142e3386e6d", "85f9970f-0c97-49d3-9872-f07744654998", "98757ab7-2df9-486d-84be-02da3a5b1cbd", "b92bace6-2fe0-4cb5-93c2-c79bb50ad0c7", "c51eb132-a39c-4aee-a440-193d712ae5a5", "d5a730d1-2b10-4434-a00f-a1a99df4c72d", "fae6805c-b379-4d11-972d-76644b22601c"], "title": "Prioritizing JUnit test cases in absence of coverage information", "venue": "international conference on software maintenance", "year": 2009, "id": "86c1046e-96e9-4990-8486-cf3b1f31ca73"}
{"abstract": "Literature tends to discuss software (and system) requirements quality control, which includes validation and verification, as a heterogeneous process using a great variety of relatively independent techniques. Also, process-oriented thinking prevails. In this paper, we attempt to promote the point that this important activity must be studied as a coherent entity. It cannot be seen as a rather mechanical process of checking documents either. Validation, especially, is more an issue of communicating requirements, as constructed by the analysts, back to the stakeholders whose goals those requirements are supposed to meet, and to all those other stakeholders, with whose goals those requirements may conflict. The main problem, therefore, is that of achieving a sufficient level of understanding of the stated requirements by a particular stakeholder, which may be hindered by, for example, lack of technical expertise. In this paper, we develop a unifying framework for requirements quality control. We reorganize the existing knowledge around the issue of communicating requirements to all the different stakeholders, instead of just focusing on some techniques and processes. We hope that this framework could clarify thinking in the area, and make future research a little more focused.", "authors": ["Artem Katasonov", "Markku Sakkinen"], "n_citation": 51, "references": ["02ee9eb9-947b-4f0c-bb9d-7e2da9ad8f25", "0b47ddcd-0538-4522-99d0-ee8028bb8b3a", "14f791d7-393c-438d-9baf-b854b3977144", "382c3ace-4f73-4007-9742-4c729648bbf8", "3b8d8731-2b70-4454-a354-6ed9485098e2", "4a44e7c9-e306-4f02-bc26-d8bb2ee7d76b", "602965f2-9ebd-4dae-9b05-6c4611cd3dc4", "66da3f29-8b45-4dc6-baa4-8e1a05df8807", "69600b36-97cb-4251-aa38-f7b719bb11ad", "69e6b83a-2d17-4d0a-b42d-2929edf79264", "6c3847f8-c495-476d-b69e-35b73e4767ef", "7c12c213-41af-4508-b7b3-a9e9156b41d4", "8002d9fd-ac65-4ae7-b6ab-94c1a442c7c9", "85d58551-ad9d-4915-8abe-f9fe92ad4b75", "8670acc7-c9c3-4f6f-a18a-d675771cd7db", "88a81132-269d-48b6-a35e-28560dd04cea", "98a6ee23-f73e-4b4e-9f44-525a5fc2391a", "a1bc1340-91c9-4e48-9ba4-c8e0956d271e", "a3461c5e-e7a6-44bc-9825-939df1916e56", "b38d0472-3ef2-4aa9-a5d5-b7c89299ab62", "c0ee6e8f-fdfd-4f42-87f7-1500f83ad45f", "c18fe068-1e6e-4058-bbdd-85d52b8a910b", "d6285e34-13fa-4327-b4f9-203181baa8c6", "dffd7b85-86a4-40e5-b6d2-2068b3addbe7", "e29bda91-f98c-4a67-81a0-fe65d85052bd", "eb068874-699c-462f-8082-4bd868b1c362"], "title": "Requirements quality control: a unifying framework", "venue": "Requirements Engineering", "year": 2005, "id": "45789534-4ff5-4da8-a97f-3f795a6e696d"}
{"abstract": "The observation of a class of multi-input multi-output (MIMO) state affine systems with both sampled and delayed output measurements is addressed. These two constraints disturb simultaneously the convergence of the observer. Assuming some persistent excitation conditions to hold, and by using Lyapunov tools adapted to impulsive systems, two classes of global exponential observers are proposed. Some explicit relations between maximum allowable delay and maximum allowable sampling period are given. An extension to some classes of nonlinear systems is also given.", "authors": ["Tarek Ahmed-Ali", "Vincent Van Assche", "Jean-Fran\u00e7ois Massieu", "Philippe Dorleans"], "n_citation": 16, "references": ["138205cc-c460-4dc8-b210-5767eac70fdb", "1fa0720f-05a4-4645-8b9f-187b8ee13311", "5e0e1e1f-439a-40fc-906c-0187b1ef0b01", "5f0edc05-4109-4869-982f-e47ab6550bd8", "78403b7d-7bfc-4462-bbbf-54828ecb6063", "7bda38ba-1a25-4ee7-ae03-e397b24d47a1", "83cec92e-9119-4024-bf52-add0eee9a1a6", "88aef4b7-c673-4499-a56b-fb8af85d9eef", "9ecc9578-8a23-4c07-b911-64812d06fd6b", "a08aa4a8-bbbd-40c1-ac96-09710e08b43b", "ac2e8959-4c7b-4787-931a-34dfa0196b94", "f8a3dd22-e1ea-4b3f-bea2-fefc26148115"], "title": "Continuous-Discrete Observer for State Affine Systems With Sampled and Delayed Measurements", "venue": "IEEE Transactions on Automatic Control", "year": 2013, "id": "08821e1b-492d-44f0-a1b3-0370b027c861"}
{"abstract": "This paper deals with new problems which arise in the application of cryptography to computer communication systems with large numbers of users. Foremost among these is the key distribution problem. We suggest two techniques for dealing with this problem. The first employs current technology and requires subversion of several separate key distribution nodes to compromise the system's security. Its disadvantage is a high overhead for single message connections. The second technique is still in the conceptual phase, but promises to eliminate completely the need for a secure key distribution channel, by making the sender's keying information public. It is also shown how such a public key cryptosystem would allow the development of an authentication system which generates an unforgeable, message dependent digital signature.", "authors": ["Whitfield Diffie", "Martin E. Hellman"], "n_citation": 238, "references": ["74b857f0-0920-455a-9927-84be55db16a0", "c584f452-5069-4f17-ae60-98c790ca006e"], "title": "Multiuser cryptographic techniques", "venue": "", "year": 1976, "id": "4dd32fac-1f39-44ea-bba5-7a54a5766729"}
{"abstract": "The avMlability of large EST (Expressed Sequence Tag) databases has led to a revolution in the way new genes are cloned. Difficulties arise, however, due to high error rates and redundancy of raw EST data. For these reasons, one of the first tasks performed by a scientist investigating any EST of interest is to gather contiguous ESTs and assemble them into a larger virtuai cDNA. The REX (Recursive EST extender) algorithm described in this paper completely automates this process by finding ESTs that can be clustered on the basis of overlapping bases, and then assembhng the contigs into a consensus sequence. By combining the clustering and assembly steps, REX can quickly generate assemblies from EST databases that are frequently updated without having to preprocess the data. A consensus assembly method is used to correct miscalled bases and remove indel errors. A unique feature of this method is that it addresses the issues of splice variants and unspliced cDNA data. Since REX is a fast greedy algorithm, it can address the problem of generating a database of assembled sequences from very large collections of EST data. A procedure is described for creating and maintaining an Assembled Consensus EST database (ACE) that is useful for characterizing the large body of data that exists in EST databases.", "authors": ["David P. Yee", "Darrell C. Conklin"], "n_citation": 50, "references": [], "title": "Automated Clustering and Assembly of Large EST Collections", "venue": "intelligent systems in molecular biology", "year": 1998, "id": "33b5b2ee-3fe2-47fb-aa32-09b96101eacd"}
{"abstract": "Object-oriented database systems (ooDBMSs) are supposed to offer at least the functionality available in commercial relational DBMSs of today. One important consequence of this is that they have to provide a separation of the global (conceptual) database schema from the external schema (\u201csubschema \u201d) of a particular task. Views are a mechanism to realize this data independence. In addition, they also support multiple levels of detail, security and authorization, and interoperability in a heterogeneous environment. In a relational DBMS, views are defined by queries. However, they can not be freely updated. We describe concepts of an object model and query language that are necessary for object view definitions. We show that updating object views is much more feasible than in the case of relational views. The key property of a query language leading to this result is object preserving operator semantics. That is, in contrast to many previous object algebras, query results are sets of existing objects instead of data tuples or new objects. Consequently, we have to solve the classification problem: where to include the view in the type and class lattices.", "authors": ["Marc H. Scholl", "Christian Laasch", "Markus Tresch"], "n_citation": 316, "references": ["0a7e2921-09b4-452c-b384-fa1b74622548", "17d2d5be-1054-4b2d-a901-b4b7cd585a23", "1b548618-58cb-4d62-a8e1-37d595876380", "2836d465-dbb7-43bf-9753-9bf105372479", "2a230c9d-f74c-488b-819c-e9d87396678d", "2a9a8d22-7889-4a1c-988d-30e54b42bb7d", "33ed84ca-4a94-4ce1-82a9-22bfb49a0a96", "43a68f03-dc66-4379-8427-e6e3b0ddd746", "4c57590f-ddc3-4758-a82e-5cae5a39131a", "72151536-469e-4c4a-bd69-f46ad6525a18", "8292e051-b7df-4679-b1a0-079a612537f8", "92807e51-c417-4a05-8c1c-6e4ce88ace11", "92acd5c8-9431-4e20-a111-f59dd3c6fc3f", "93c87afd-4c80-45ff-80f6-a9278403f522", "a42b9442-9033-4908-8a9b-2e76ae05faf0", "a8486514-fe00-41ce-a2df-5ebe50706d6a", "ae83289f-8990-49fb-a842-2839ff03e16b", "b63992f7-e438-4875-bd97-903f0eb76098", "c157db84-adc4-44a4-aff4-cdb5d3255dda", "d0151524-3719-4dcd-8eb3-268397d8e2bd", "d1aa622b-be5e-40ef-9e3e-d33019de59ab", "d55b22d6-2cf2-48c2-ba9c-ae3cf440c3ad", "dd15cccd-4afb-486b-92b7-db079327c548", "eb2d1034-e6aa-478b-a9cb-64753b60ca20", "f4bf1e15-06f5-4d78-8d8f-eff4d57d62d7", "f78340ee-95b1-4326-8084-71840e189802"], "title": "Updatable Views in Object-Oriented Databases", "venue": "", "year": 1991, "id": "39126ab5-3217-4bcf-86ad-03475569af7e"}
{"abstract": "Modal transition systems (MTS) are operational models that distinguish between required and proscribed behaviour of the system to be and behaviour which it is not yet known whether the system should exhibit. MTS, in contrast with traditional behaviour models, support reasoning about the intended system behaviour in the presence of incomplete knowledge. In this paper, we present MTSA a tool that supports the construction, analysis and elaboration of Modal Transition Systems (MTS).", "authors": ["Nicol\u00e1s D'Ippolito", "Dario Fischbein", "Marsha Chechik", "Sebastian Uchitel"], "n_citation": 74, "references": ["4dc40f3c-6018-4b56-9740-dce8c270331b", "7f443156-9806-487f-ba18-abc06f45c4e5", "83364ce0-5713-48c6-9121-fae620b6d07e", "af441cc5-1428-4eed-be6a-aefdd6246676"], "title": "MTSA: The Modal Transition System Analyser", "venue": "automated software engineering", "year": 2008, "id": "dfc66cbb-b353-4b61-8ae8-0762b1031f11"}
{"abstract": "Much computerized support for knowledge workers has consisted of tools to handle low-level functions such as distribution, storage, and retrieval of information. However, the higher level processes of making decisions and taking actions with respect to this information have not been supported to the same degree. This paper describes the ISCREEN prototype system for screening text messages. ISCREEN includes a high-level interface for users to define rules, a component that screens text messages, and a conflict detection component that examines rules for inconsistencies. An explanation component uses text generation to answer user queries about past or potential system actions based on Grice's conversational maxims.", "authors": ["Stephen Pollock"], "n_citation": 97, "references": ["13d5381b-bda2-48af-9fc1-47dfda817a72", "1f4de3aa-5d69-480a-9531-7619810539b0", "8fd9aa19-5b11-48a2-a8dc-4cc75c36d8eb", "d457a8cf-0f5d-4808-83fa-fecd4028b2d5", "d514b0d4-4cee-400c-8ed1-e243b517c361"], "title": "A rule-based message filtering system", "venue": "ACM Transactions on Information Systems", "year": 1988, "id": "6cb3a448-8ffe-4ed9-b8f5-dbf1c529eb70"}
{"abstract": "Due to the W-CDMA radio interface, the area covered by a set of UMTS base stations depends on the signal quality requirements, the power control mechanism as well as on the traffic distribution. In previous work we have proposed discrete optimization models and algorithms for locating base stations in UMTS networks. In this paper we address the general problem of optimizing base station locations as well as their configurations, such as antenna height, tilt, and sector orientation. The proposed model, which can also be used to only optimize the base station configurations, accounts for the power control mechanism typical of W-CDMA and considers the signal-to-interference ratio (SIR) as quality measure. To find good approximate solutions of this NP-hard problem, we develop a Tabu Search algorithm which takes into account traffic coverage and installation costs. Experimental results showing the effect of considering base station configurations in the planning process are reported.", "authors": ["Edoardo Amaldi", "Antonio Capone", "Federico Malucelli"], "n_citation": 50, "references": ["0350848b-2065-4fb3-b50a-be5895e6f517", "1c713565-105c-4311-beb5-35d482c2284a", "207603ac-e64d-4535-bdf1-a37a15ae6394", "49f5e3f9-6b80-4dd1-adf5-ed19d36119a0", "5d19ed18-77a2-4fd2-b361-d7f83b6c6e08", "75316b08-c097-483d-a5c0-66b18920a406", "7a461f7e-6b43-430d-83a0-2a0545944fd4", "f4651f3c-4cf8-43ce-a2c3-e1f160e3db0d"], "title": "Optimizing UMTS radio coverage via base station configuration", "venue": "personal, indoor and mobile radio communications", "year": 2002, "id": "4e1cda12-daea-4571-9955-828e0632cda4"}
{"abstract": "We introduce a new lambda calculus with futures, \u03bb(fut), that models the operational semantics of concurrent statically typed functional programming languages with mixed eager and lazy threads such as Alice ML, a concurrent extension of Standard ML. \u03bb(fut) is a minimalist extension of the call-by-value \u03bb-calculus that is sufficiently expressive to define and combine a variety of standard concurrency abstractions, such as channels, semaphores, and ports. Despite its minimality, the basic machinery of \u03bb(fut) is sufficiently powerful to support explicit recursion and call-by-need evaluation.We present a static type system for \u03bb(fut) and distinguish a fragment of \u03bb(fut) that we prove to be uniformly confluent. This result confirms our intuition that reference cells are the sole source of indeterminism. This fragment assumes the absence of so called handle errors that violate the single assignment assumption of \u03bb(fut)'s handled future-construct.Finally, we present a linear type system for \u03bb(fut) by which to prove the absence of handle errors. Our system is rich enough to type definitions of the above mentioned concurrency abstractions. Consequently, these cannot be corrupted in any (not necessarily linearly) well-typed context.", "authors": ["Joachim Niehren", "Jan Schwinghammer", "Gert Smolka"], "n_citation": 88, "references": ["26f7125f-caab-4729-a1ee-27db0ea17e19", "2bad498c-7790-4291-8341-afc39ca432ec", "2d339384-87c0-4640-b42e-800856da6903", "36d5fa87-ae3f-4944-b1ba-ba7232ca5ec5", "3f6b4f21-b593-49dd-9f81-4affe3176197", "3fd0890e-f8ff-46ef-8c53-c6184d86b2e8", "4af030a7-32b5-4a3d-8c4f-fc5704304376", "5720ec5a-dd1d-4f4a-9fd0-2d71240bc6c3", "5d54bdce-3326-4707-be32-564c756450a6", "684f80ac-4d7d-46eb-9d1b-2599bae23de6", "71139acd-e6ab-4998-808f-bc1fef5e65e1", "722dba61-077c-4483-99cf-6b22df0f5458", "73983a6e-64a2-41b0-8b52-5858f91b7e84", "83a49bfa-6314-4e62-b3a8-ed08323a3e57", "9334482e-c3d0-46c2-a09a-1d47df12471b", "a97daab8-b47b-401f-93ea-f7dab1cfcda7", "ad20d388-2e05-4cba-81b9-019f1f64c388", "ae36b15d-1481-4817-a380-7d5609be79ed", "c089487b-fb38-4ece-a3b6-6685e1478a4c", "c3a859e9-439b-463d-b4b1-71c40f970d56", "db883334-eecc-45e8-a448-7392ac84439b", "fc1d63b9-24c6-4bc8-85a8-ccc2fc7f6a7d"], "title": "A concurrent lambda calculus with futures", "venue": "Theoretical Computer Science", "year": 2006, "id": "20aae579-dab6-4f5c-ab88-72d35d172412"}
{"abstract": "Today\u2019s distributed computing solutions are mostly static in nature and variations in system behavior have to be compiled into the system in advance, because today\u2019s technology does not permit selfconfiguring through dynamic rebinding of components. Self-configuring systems need a design approach based on behavioral specification as well as a middleware layer that can use these specifications to dynamically bind system components at run-time. In this paper, we present a service-oriented programming model and middleware for self-configuring systems. Our approach is based on semantic descriptions of components augmented with contextually dependent non-functional requirements for accomplishing the dynamic binding. For this purpose, we model service inter-dependencies as variability points. The middleware dynamically re-configures system behavior by mapping the variability points to components providing the needed functionality. Along with the middleware design needed for such an approach, we also present our programming model \u2013 called reconfigurable programming \u2013 and show how it can be used to put together self-configuring systems.", "authors": ["Umesh Bellur", "Nanjangud C. Narendra"], "n_citation": 50, "references": ["0c146bf5-26e5-4929-baa6-35ca75f8482e", "15453c5e-cdfb-4003-9295-cda10cc8c38d", "18f194f1-e6ec-410f-a976-a953a72cd002", "1ecea24c-dfd9-45ee-ad3f-2e5032f4658b", "352838dd-9583-402f-be39-52df4810a25f", "4ba594d7-a8da-48ad-9001-85d028b49274", "655472bd-006a-4ab8-9972-c21733d014f0", "69b804d6-f6e4-4dc7-a698-bdf38a7324f4", "75e39d30-370a-49f4-bd4b-cff697fbad9c", "8216dff4-4e91-4c5e-8077-4b7de9ae1d54", "92e7be95-0586-4598-be01-05c38e5bc8ae", "cc6990af-06a6-456c-b8cd-b88505968d36", "e2299cdc-41d2-4f50-8a6a-e2cfe569c7ba", "e99db70a-7ee8-4e14-9b42-9cbe1b3fa9e1", "ef15f996-266c-4323-bf5d-8059e9860156", "f5b9dae5-29f8-444d-b4e1-b2800b9e732b", "ff356bff-aaa7-42d4-811d-1b44c5db4f78"], "title": "Towards a Programming Model and Middleware Architecture for Self-configuring systems", "venue": "communication system software and middleware", "year": 2006, "id": "0f3c90d3-243d-402a-b03e-ce7b0a6ac992"}
{"abstract": "Organizations aim at harnessing predictive insights, using the vast real-time data stores that they have accumulated through the years, using data mining techniques. Health sector, has an extremely large source of digital data - patient-health related data-store, which can be effectively used for predictive analytics. This data, may consists of missing, incorrect and sometimes incomplete values sets that can have a detrimental effect on the decisions that are outcomes of data analytics. Using the PIMA Indians Diabetes dataset, we have proposed an efficient imputation method using a hybrid combination of CART and Genetic Algorithm, as a preprocessing step. The classical neural network model is used for prediction, on the preprocessed dataset. The accuracy achieved by the proposed model far exceeds the existing models, mainly because of the soft computing preprocessing adopted. This approach is simple, easy to understand and implement and practical in its approach.", "authors": ["Veena H. Bhat", "Prasanth G. Rao", "P. Deepa Shenoy", "K. R. Venugopal", "Lalit M. Patnaik"], "n_citation": 50, "references": ["1372a339-b052-478c-a630-c96de8fae6e9", "18f790c2-7467-498f-b685-34fcde3e0e79", "2fc0cfcd-f025-41f6-be2f-76eae12106bb"], "title": "An Efficient Prediction Model for Diabetic Database Using Soft Computing Techniques", "venue": "granular computing", "year": 2009, "id": "682a86d9-e083-4f39-a8b1-a21aa7b3f420"}
{"authors": ["Dennis Tsichritzis", "Stavros Christodoulakis"], "n_citation": 113, "references": ["10a6ec7a-c83f-4a7a-95a5-e86eac914da4", "46ce7e59-f6c4-413d-b6e8-043cacd282b0", "480c74e5-f106-474f-9f80-dbe2f3da3e31", "5c2a9799-166d-4db0-bd4b-7010c1e160cb", "8e04e0b5-3bbd-479c-a975-2a5a97e72ca8", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "b0343204-ca89-4f23-bba1-ea37217cac0a", "d56d959c-44b9-4d73-9c78-c0c7a5f3138e"], "title": "Message files", "venue": "ACM Transactions on Information Systems", "year": 1983, "id": "65f7c5c5-5e33-4103-99a3-0fd294db24a3"}
{"abstract": "The productivity of a software development effort and the quality of the resulting product are determined by the environment in which the software is created. A major driver of the effectiveness of a software production environment is the relationship between the development process and the organizational structure. The work described in this paper studies this relationship.Related work in the study of software development processes includes continuous process improvement, flexible development processes, lean development, and capability maturity. None of these have considered explicitly the importance of the underlying organizational structure to the effectiveness of the process and the quality of the product. However, the effect that an organizational structure can have on the process is of sufficient magnitude to justify considering these two elements together, as equal parts of a single system.This paper describes the OPT approach to improvement of software development environments through improvement of the organizational structure and process. The approach is an iterative improvement method. The steps include modeling the relationship between the organization and the process, measuring various properties of this relationship, and evaluating a set of goals and constraints.", "authors": ["Carolyn B. Seaman"], "n_citation": 50, "references": ["631574d8-94a0-4ce5-81af-c39fe0ebd66a", "68734730-8262-47e2-a8a1-6d67cbdf32f8", "83d54f51-723b-4ab2-9ef7-b844797dacc1", "b2e8a878-c3ae-437a-9c2a-264f478249fd"], "title": "OPT: organization and process together", "venue": "conference of the centre for advanced studies on collaborative research", "year": 1993, "id": "14caa757-5576-4daf-aa26-aa94bc2c1c58"}
{"authors": ["Ramesh Jain"], "n_citation": 50, "title": "Understanding Macroscopic Human Behavior", "venue": "international conference on pattern recognition", "year": 2010, "id": "aa8f5a7a-649a-4583-b5b2-578d6d1034b5"}
{"abstract": "Today, software-intensive systems are increasingly being developed in a globally distributed way. However, besides its benefit, global development also bears a set of risks and problems. One critical factor for successful project management of distributed software development is the allocation of tasks to sites, as this is assumed to have a major influence on the benefits and risks. We introduce a model that aims at improving management processes in globally distributed projects by giving decision support for task allocation that systematically regards multiple criteria. The criteria and causal relationships were identified in a literature study and refined in a qualitative interview study. The model uses existing approaches from distributed systems and statistical modeling. The article gives an overview of the problem and related work, introduces the empirical and theoretical foundations of the model, and shows the use of the model in an example scenario.", "authors": ["Ansgar Lamersdorf", "J\u00fcrgen M\u00fcnch", "H. Dieter Rombach"], "n_citation": 50, "references": ["10d2a727-7ad1-426f-b7a9-12fd16795b5f", "1707f36d-f496-4dfb-a6f4-7db49d5f94d0", "2a0d5376-b235-49ee-afad-aa1112cd71fc", "2e4dd35b-56dd-49e1-b1f3-91d19482f37a", "380fed4f-3dea-47ed-8d29-4eced6bf492e", "3ae01962-269d-4059-b3d1-6c218c10e8fe", "528985e5-7986-48ca-a2be-46a55c24f643", "5a1d1ae4-b359-45d9-8c21-50cbfa5e2a78", "60cbec7e-b1fe-4644-bb43-2bcc38c40bbd", "6468f86d-292d-4055-961c-543fd2e5894a", "64ad49c9-b2cc-43fe-8802-e0cc93faa9d5", "6780c62e-ddf1-418e-83f9-e817624967ad", "6ae1777a-9e80-4cf0-af3a-18393e3dcf65", "780895c7-953e-418f-9e4e-dcfddc0ea124", "89e17d73-c6d8-4ec3-8b8d-cc9a9bd06082", "94b20a6d-bb23-451e-b1ed-ff263950ba18", "97e50bd4-0fda-4d8e-84d2-3b282643b9e4", "9a809ce2-f073-4a98-84be-54d4e68785e3", "bebac889-1186-4eee-a12c-8ab52a66d5d3", "e1f0e461-aa66-475b-b4c8-adbe46e39cb5", "ec4793f5-97eb-4e27-9089-71cd93d2a5b6", "f0055425-1f0a-49e3-b69b-fef9cce3c525", "f1f29672-758c-4597-94bd-42e0344a9ce2", "f22215f6-8ca5-4c18-bca9-6d3c838a9b9c"], "title": "A Decision Model for Supporting Task Allocation Processes in Global Software Development", "venue": "product focused software process improvement", "year": 2013, "id": "08d20598-401a-4c30-9c89-3306e8c2b2c8"}
{"abstract": "In order to reduce mean time to recovery (MTTR) in heterogeneous enterprise environments it should be possible to easily and quickly determine the root cause of a problem detected at a higher level, e.g. through response time violation of a transaction category, and resolve it. Many problem determination applications use a component dependency graph to pinpoint the root cause. However, such graphs are often manually constructed. This paper introduces a simple non-intrusive technique based on mining of existing runtime monitored data, to construct a dynamic dependency graph between the components of an enterprise environment. The graph is traversed to identify nodes that are the cause of response time related problems.", "authors": ["Manish Gupta", "Anindya Neogi", "Manoj K. Agarwal", "Gautam Kar"], "n_citation": 52, "references": ["1dac09a3-05af-4743-98af-a18218e9f713", "55b18b07-f347-499a-84f7-2e80ab0961c3", "6471cc71-c82b-49a6-9f31-76351974fa5f", "86cb005a-ceb6-4a59-b933-5489db6a6f13", "9c59d6eb-4a65-4ef5-948a-ae4ed1fd66cd", "9ff89a6a-32dd-4a4f-9bb6-3753ae4843c8", "b0c1f4cf-b30b-4a55-ad39-76bfbbe11223", "c7d2d82b-3505-40c3-adfb-ad74501d22b4", "ca26cbea-fe59-4b2a-9a7e-174bce708500", "e9fe5cd3-6424-41a9-ad2e-89ae12b69e31", "fc52205e-fd0f-48c3-a398-948cde4aa48d"], "title": "Discovering Dynamic Dependencies in Enterprise Environments for Problem Determination", "venue": "distributed systems operations and management", "year": 2003, "id": "5d426311-bf7e-47d7-9960-eba07ce070ed"}
{"abstract": "This extension of the Lucid language seeks a high-level, real-time software-oriented tool with a formal mathematical semantics in which real time is part of correctness.", "authors": ["A. A. Faustini", "Edgar B. Lewis"], "n_citation": 50, "references": ["72ae5a5c-f19a-4c38-994d-6ced1ff49833", "826de0e9-62c5-49f0-bfce-ffeb70e71e6a", "bd35d311-6161-4640-b616-f42aeeeb3266", "d85c8ce2-8a6b-477a-86b5-affdba88a4dc"], "title": "Toward a Real-Time Dataflow Language", "venue": "IEEE Software", "year": 1986, "id": "1ad01d09-5aa7-471f-b761-a910f54dd007"}
{"abstract": "In this paper, we present some major algorithmic improvements to fast correlation attacks. In previous articles about fast correlations, algorithmics never was the main topic. Instead, the authors of these articles were usually addressing theoretical issues in order to get better attacks. This viewpoint has produced a long sequence of increasingly successful attacks against stream ciphers, which share a main common point: the need to find and evaluate parity-checks for the underlying linear feedback shift register. In the present work, we deliberately take a different point of view and we focus on the search for efficient algorithms for finding and evaluating parity-checks. We show that the simple algorithmic techniques that are usually used to perform these steps can be replaced by algorithms with better asymptotic complexity using more advanced algorithmic techniques. In practice, these new algorithms yield large improvements on the efficiency of fast correlation attacks.", "authors": ["Philippe Chose", "Antoine Joux", "Michel Mitton"], "n_citation": 165, "references": ["28b2a33b-f5ab-42a5-8633-614d7b5e939f", "2ee33c81-bed6-4239-aa21-787fec42e7ee", "5b5f737c-a4b4-4b8c-832f-64a6ae55333d", "626c6a37-6340-4d03-988f-e38f2745445c", "6b87e791-74cd-4f0b-b2ab-4318a23bd8ae", "96adb96c-6d20-4387-a62a-5b6852eec429", "990d56af-1998-4195-8535-bb9739c958d4", "cb5ccfc7-a8c2-42a7-a429-b0eadd9cb401"], "title": "Fast Correlation Attacks: An Algorithmic Point of View", "venue": "theory and application of cryptographic techniques", "year": 2002, "id": "37e6f8f8-8b2e-4e44-b266-a5f0039a4986"}
{"abstract": "Although many color constancy methods exist, they are all based on specific assumptions such as the set of possible light sources, or the spatial and spectral characteristics of images. As a consequence, no algorithm can be considered as universal. However, with the large variety of available methods, the question is how to select the method that induces equivalent classes for different image characteristics. Furthermore, the subsequent question is how to combine the different algorithms in a proper way. To achieve selection and combining of color constancy algorithms, in this paper, natural image statistics are used to identify the most important characteristics of color images. Then, based on these image characteristics, the proper color constancy algorithm (or best combination of algorithms) is selected for a specific image. To capture the image characteristics, the Weibull parameterization (e.g. texture and contrast) is used. Experiments show that, on a large data set of 11,000 images, our approach outperforms current state-of-the-art single algorithms, as well as simple alternatives for combining several algorithms.", "authors": ["Arjan Gijsenij", "Theo Gevers"], "n_citation": 118, "references": ["3bf3194f-9b4e-4bb6-8f4f-0d869a24e19e", "45fbec1c-c97d-45dc-85a7-9341b8e975dc", "49be6175-4ed8-47ef-abe0-c64288b0ca57", "647b6991-2c04-4df2-b839-4c772eda128f", "68cb7b01-d6da-45ab-9c9c-f84e96e77e3c", "6c6d6239-49db-4047-a19a-429fa7bc3cf8", "93378e13-0f38-429d-964b-abf990d6a37d", "ab3afb93-8ca0-4556-ae60-11199dc263c2", "aeafefeb-096f-49d1-bcf0-05fde8330ed1", "bdc38ab9-eafc-4b71-8572-550473759a14", "c1fcaf5b-b9f4-4637-8aac-1f884c464bdd", "c5bbbdd9-16c3-4b2e-866b-b723ad84300b", "ea775cfb-4fba-45ae-be69-710f6059c200", "eba773db-f6b9-4fb3-9112-61cd10e0c754", "ed835ca3-7120-4646-afaf-20c04a57c698"], "title": "Color Constancy using Natural Image Statistics", "venue": "computer vision and pattern recognition", "year": 2007, "id": "aab96f93-10cf-43d2-b235-aa2da741006b"}
{"abstract": "The authors present the original extensions brought to PRIAM to automate both the diagnosis and the rectification of the design errors detected by this tool. PRIAM is an industrial automated formal verifier used to check the functional correctness of digital circuits of up to 20000 transistors. These extensions implement a novel approach to diagnosis based on Boolean equation solving. In particular, no enumeration of the faulty patterns is necessary to find out the incorrect gates in the circuit. The diagnosis system can handle any circuit that can be verified by PRIAM. >", "authors": ["Jean Christophe Madre", "Olivier Coudert", "J. P. Billon"], "n_citation": 126, "references": ["2a73f987-98cc-4d8b-bf27-9d8d0834c57c", "53efaef7-8148-42d8-b653-393ae511ac91", "726a9e26-3cf5-43cc-b96e-89f21f7eb091", "c12db4b0-ace1-42f9-bb55-b857c9e5d0a2", "cf896c76-2940-4af6-bc95-85651004f1ca"], "title": "Automating the diagnosis and the rectification of design errors with PRIAM", "venue": "international conference on computer aided design", "year": 1989, "id": "ff9fa329-0873-4fe8-a269-743e8adfbdd6"}
{"abstract": "We propose a novel method for continuous 3D depth recovery and tracking using calibrated stereo. The method integrates stereo correspondence, surface reconstruction and tracking by using a new single deformable dual mesh optimization, resulting in simplicity, robustness and efficiency. In order to combine stereo correspondence and structure recovery, the method introduces an external energy function defined for a 3D volume based on cross-correlation between the stereo pairs. The internal energy functional of the deformable dual mesh imposes smoothness on the surfaces and it serves as a communication tool between the two meshes. Under the forces produced by the energy terms, the dual mesh deforms to recover and track the 3D surface. The newly introduced dual-mesh model, which is one of the main contributions of this paper, makes the system robust against local minima and yet it is efficient. A coarse-to-fine minimization approach makes the system even more efficient. Tracking is achieved by using the recovered surface as an initial position for the next time frame. Although the system can effectively utilize initial surface positions and disparity data, they are not needed for a successful operation, which makes this system applicable to a wide range of areas. We present the results of a number of experiments on stereo human face and cloud images, which proves that our new method is very effective.", "authors": ["Yusuf Sinan Akgul", "Chandra Kambhamettu"], "n_citation": 19, "references": ["140d3916-f8f7-48c3-b522-cf7d499f7fdb", "1c2cebc6-d763-4814-94a5-0b52ea687f20", "1c63e1d5-b963-455b-829d-e4f3eb63a36a", "29fce575-c4eb-4351-a9b2-79df85bd3f45", "30c86849-5b61-4d37-a7c4-e01c00a2497f", "3f4cc95c-5f47-4031-8671-e23ff4fe2ed2", "54b8ad0d-2246-4650-a09b-5f5b9705e0e6", "54d3b99b-17e0-443f-bd4c-23db90ce9c26", "8d2f3730-636f-4105-a011-62d86b417749", "936e0ae4-e6e1-4b3b-9d0a-a6bff589fc7b", "9f91c3c3-2b1a-470a-bcdf-c5c26d7d7f0b", "b62a32f3-eb04-429f-93ca-f20dadf916a5", "d6f6ce21-4c02-4b9c-b5f0-d0a601dffbbc", "d91cb562-27e8-468a-a114-c019f328f4f4", "e068d506-2794-4b94-9fc8-b1e72f6130d6", "ee13f47b-ab0b-4712-96d8-25b909be0a52"], "title": "Recovery and tracking of continuous 3D surfaces from stereo data using a deformable dual-mesh", "venue": "international conference on computer vision", "year": 1999, "id": "c6c24cd1-806c-457b-a3d1-1565e9d58ad8"}
{"abstract": "The Internet is inherently a multipath network: For an underlying network with only a single path, connecting various nodes would have been debilitatingly fragile. Unfortunately, traditional Internet technologies have been designed around the restrictive assumption of a single working path between a source and a destination. The lack of native multipath support constrains network performance even as the underlying network is richly connected and has redundant multiple paths. Computer networks can exploit the power of multiplicity, through which a diverse collection of paths is resource pooled as a single resource, to unlock the inherent redundancy of the Internet. This opens up a new vista of opportunities, promising increased throughput (through concurrent usage of multiple paths) and increased reliability and fault tolerance (through the use of multiple paths in backup/redundant arrangements). There are many emerging trends in networking that signify that the Internet's future will be multipath, including the use of multipath technology in data center computing; the ready availability of multiple heterogeneous radio interfaces in wireless (such as Wi-Fi and cellular) in wireless devices; ubiquity of mobile devices that are multihomed with heterogeneous access networks; and the development and standardization of multipath transport protocols such as multipath TCP. The aim of this paper is to provide a comprehensive survey of the literature on network-layer multipath solutions. We will present a detailed investigation of two important design issues, namely, the    control plane problem   of how to compute and select the routes and the    data plane problem   of how to split the flow on the computed paths. The main contribution of this paper is a systematic articulation of the main design issues in network-layer multipath routing along with a broad-ranging survey of the vast literature on network-layer multipathing. We also highlight open issues and identify directions for future work.", "authors": ["Junaid Qadir", "Anwaar Ali", "Kok-Lim Alvin Yau", "Arjuna Sathiaseelan", "Jon Crowcroft"], "n_citation": 24, "references": ["00678b22-7e5e-4492-9cbb-d1b6d4baf2c1", "01411551-2965-4d40-ac06-f254762dab8e", "01a3038f-0374-4452-98d8-c496cfa824d7", "038e6896-9a27-41cc-bacb-de3bea520f3b", "051989ad-0e80-411a-a220-84d4a4b18cf3", "0771b8b5-4d9d-47d8-a57a-f89cd145883a", "07baa066-d814-4452-bfc1-3c9a06f1c824", "08655772-647f-43f0-92e8-c44281b39632", "0bba3516-7bcc-45a9-8a5e-2f10ba9d0f78", "0bc075d5-1837-4bfd-b5de-6da958c9aa98", "0c76c9fb-9154-4d30-86db-722eca3db3d2", "0ce4877b-6e18-455c-9ee5-7ca93715a88f", "0ce8149a-808a-426c-9af9-a03bec2d12c1", "0d93a5f7-f838-47bc-89fc-9be43eba0541", "0fdc3c73-63b4-4d6f-8cc1-2e76e28b371d", "10598159-174c-4b89-9f67-3f9f28a9f93c", "11c06db7-bc59-4461-8a4e-e180927afc48", "15b2f2e7-c4a6-4880-93d8-c47438f2e0c3", "1a34752a-1657-4939-a2fc-8b2b4d46f7da", "1ac9f4da-113f-441e-99ba-539882145a8a", "1d763bc7-be7f-441b-93b4-fc02900b4a1c", "1f186c83-ec07-40fe-997e-d0ac5b3d264a", "1f6902f1-311b-4e65-b3a0-8ca193553bd0", "2222f1f9-b357-45ef-8943-ae096e660c5f", "237f98f9-7b96-402f-a214-25aecf7b9e20", "24b3e657-5095-4d99-bd22-f0abac9acb61", "24b96002-9ca7-4d5c-8232-7c6df8c5a3e6", "2529d9fd-834d-4cc3-9f21-d3d1b328d6e6", "295f0392-c8ca-4a1e-a7f4-75afc48effae", "29695034-3d53-42f9-a1e0-f3776f815277", "2a2203ba-10ca-4ae1-8fb9-3bb0cfacdeaf", "2b6f5d2f-532f-4e1c-bc7b-6ea9c243c082", "2b9d01a1-e157-44e4-bb2c-dccb5111fa31", "2ccedcd0-9ca3-4772-bb47-ce0bb70a3346", "2d2a631f-d573-4794-8bc2-66af5b08e551", "2e09ff59-c097-4b47-b72f-5d95f0769a3d", "2eb36bd3-992b-46de-b89d-9166db3d128a", "2f13e79b-4e90-4b9a-986f-8eb95a244cf5", "2f8384d7-81e8-4f75-8864-a3e6df0e9e63", "2fcbdb29-3559-4740-a33f-d6975d74ce21", "30162fb9-f9f3-4626-b77e-8b65f44a3d48", "31592ba2-1b24-44a3-a7d0-d472094a130b", "3168925c-ae2f-4dfe-83f9-22766a1a13e7", "31da3d5a-b369-45c5-ae22-734b121132d7", "335d3ecf-c8b9-42d4-94c0-3fa53a7c6487", "34910918-b72f-407e-a6de-7053bfd64829", "37a95a01-a4de-4b4d-92a4-b6e837ef9f6b", "38219df8-cd6f-4f42-b7e7-1f7028570ae5", "38711d27-db9e-458d-8c00-de910f93ba98", "3e6ee316-39c3-49cf-b4d4-517b6d4724a7", "41b8599d-3e02-43cb-afcb-fc726f3e3829", "41c289a6-3f9b-4546-acd2-ed8cca917963", "420680fb-7b05-4867-b5e2-73d7f721d510", "4395197b-e4e1-4464-a8d9-7750f8761fd7", "44b5edde-4602-433d-8c68-76efb6f75112", "455a1804-9b44-4e4b-86c8-1c19567f7387", "45dc949c-78d4-4e11-8b35-5f29988c55ac", "462e5b5c-9f1d-4e6c-9ab6-fdb0cc839908", "4932fc2a-3313-45bf-9ede-f699908a9b96", "499bb304-22a4-455d-a5a4-4d0aa6e82f34", "49cafff8-eae2-47d7-919d-cf07c08a7e66", "4c433606-8817-4f2c-873f-8c8639546f20", "4efb44de-0f7b-4322-bb1e-0628e51495e5", "52310f0b-e3d3-45ff-b9b3-66c084cc815c", "5347c4dd-9ca7-4d3d-b1b7-b81e9326a5a2", "548c6223-5e03-4503-bc33-48018ea78802", "54be4ce7-2041-4ddb-b06e-ee3cb1494dc8", "54ec4a75-a20d-4348-87a2-af7ddad4c2ce", "555f5e61-598f-4763-b82a-0f43b2d0a6f7", "55703f69-f726-4e6c-b784-5b305c7af0ce", "58c23cad-1260-4989-9e24-5671fffd721c", "59d80c37-dc57-47c7-9d4a-1a2b4a5acdb7", "5a81b18b-334b-4e90-984c-02d97d3bf144", "5bf14bdf-92e7-428c-90f8-a52dcffb650f", "5c810b81-96a7-4f54-8ffe-e4ab32aa1893", "5cf80b4b-d7ef-400b-a41f-421e671a39a3", "5d02484c-5a92-4346-9edd-44467483beff", "5dc3f165-7774-4492-ac72-2e8b5d7f84e1", "5e1bd4f2-aa81-4ee6-bf05-4b9d01da88af", "6177aa78-da80-4f40-99b7-f132e07727cf", "6205cccc-3411-4711-95a3-50f78a6d0383", "6223cc4c-808d-4873-8da9-51782d98de2e", "63e7985e-e27d-4974-96ef-3109cfbfd646", "651dfcfa-6eb3-4f74-988d-5a79b42243a0", "66c7f4cd-e2fb-481e-8884-e58b9da9fa50", "683a2948-2d37-4166-a0e4-546e716b7403", "686b1f97-3cb7-47a6-bbd2-e8ba891dc1b5", "6a869026-6fa6-444c-862e-e16d0b7ca91b", "6b43b988-85dc-471f-bba4-3f00b8ad9e3c", "6b643ff4-a78c-4feb-9cc7-3a97311da63c", "6c07adc3-b2f6-446f-868c-a2edbdb46b58", "6d366137-452f-4733-8c13-a49799814d04", "6d6f1f54-e698-4230-9f91-161f53d51c41", "6eef7b1a-21f0-4526-be20-cb6add438a3e", "6f379d34-0b17-4124-93ea-39e084c736f5", "712cc7ac-25ef-4946-9094-da8abc0cdc98", "731b62a6-bd13-4c13-b4ab-ef032717b015", "75fdc192-b4bc-483e-b423-f053fe1beb18", "77c9d26d-58cf-4635-a16d-416c6330999e", "7a16a9b5-2240-4686-954a-8528a8abb171", "7bf6fbac-e208-44ce-9a72-6c3b99978c2b", "7d6977da-e1b3-41f5-a0f9-8497ab9bd188", "7e2cc588-d9d0-44e1-b0f3-1e5bdabf799e", "80ad3b68-b154-4cc4-9a6c-d76fa97c9355", "8114b065-ecdd-47df-a53e-e5637461409d", "81ac961d-1581-4aa1-8d14-e01b81b1e34b", "8238d21d-773c-4397-9037-3f5d95a3d578", "870592e4-777a-4cc2-8562-c2eeac8a40b7", "881bed16-0a9e-42e3-9128-fe29f654c783", "881d7e4b-0660-420c-be77-c8e835b0c619", "88d43ea7-60bc-406f-9e3e-647c6ba1d21c", "89139188-8e95-4e9d-8a34-8315f195a712", "8b610ac0-2114-4deb-aefa-21de4cac1362", "8e7311b9-87b5-436b-9eaf-da2a39eb5b38", "9124bd30-5760-4718-ac94-c718081616d3", "9150e8b4-6364-411c-a169-cb0d97968345", "92ccb3e8-bf8f-44f8-aa09-df54727fc783", "93a94494-f00f-4b32-ae82-2d402eb1eaa8", "94381e97-bdde-4150-b750-31121fc78997", "94616ff0-3e7e-4630-b60a-50675e06058d", "955f4040-2731-4fa4-9f68-ea850699c19b", "956a6356-ebf7-4b8b-aa9a-b877e5444398", "95a66ba1-5bcd-4dd2-9a07-8a851a4e6873", "965df2ae-7c38-4f44-adf1-6ef8ba327532", "978f8f21-9236-48de-887a-6b0ac7994aed", "97de3761-b7bb-4efe-a332-3eb70bcf649e", "992a4601-7796-4b0c-a386-3e3431154964", "9ad127f3-3f4f-49d3-aa41-f028463f135a", "9ad9fb51-6dc5-4dff-813f-257dd840040b", "9e7f3a14-e586-4bad-aab9-0c36173e441d", "9f6294e0-1a36-4e79-9df5-c0295c75dac0", "a2798489-d347-41ea-9a44-9f77fe7ced22", "a2f6bc97-abdd-4f23-b2d1-7f57fab1429c", "a351db29-012c-4025-91fc-269d72e36068", "a4a9dfdc-7bda-4eaa-8608-759d201d927d", "a535b628-0811-4b0f-bb11-650fc8de6320", "ac21a047-db18-41f2-83c6-faeeca7b01af", "ad7e3c96-35fe-4b48-aa42-9e7fedd78ad7", "afd4c865-5c81-424b-82c3-1dcb6150ea6d", "b0bbbb0d-c0b1-4421-b5d0-f7e1578f0c02", "b0c0cebf-991f-4f49-b4ea-46bd412caba9", "b25c2b94-69d9-4687-af53-931509d716a1", "b30ac711-24c4-4877-95ad-80e3bb38652f", "b5c398fa-67ea-494d-b40d-875e0e7fb72a", "b63703d3-3f63-4bac-9bcd-08d441257967", "b857298c-92c9-4f05-a704-3b9fc6be06e3", "bc112e56-68c7-4680-ac4e-d183cf4fffd2", "bcc152f6-6235-46d9-b21c-749a67315b3a", "bf89ef67-8e64-4e3c-8b11-8f53c8e41936", "bf9d2850-dbca-43f2-90ee-cdd8d0562813", "c052be7c-071a-42b1-95e1-19a591d25c45", "c11379d6-0520-4049-a12f-f2d330571ba9", "c971c07c-212e-4d4f-a119-710a71b71b9d", "cace8766-2a98-4d7f-bdf1-e186b5eb9be5", "cc2c9593-3f1d-43c7-a538-422f0398db1e", "cc2e3d78-8d27-41c8-af81-e46621196d04", "cd297445-cfd4-4756-9362-fd3e297d68a5", "cd3a2472-a904-468b-9c55-be1420758ef3", "ce57478f-ff8f-4335-8481-ded80dfedbfc", "ceb0fa94-3f66-4f2c-a7e2-ccd0474fcba7", "d2b7db5d-bc47-48c7-a173-865fed9bff96", "d360bb88-47b8-4406-a055-9340a540e600", "d363ceb0-e710-4694-8674-432b67a5f890", "d58f78ce-d218-4a27-b922-d7806aa0d8cb", "d7649360-48de-4ca2-8203-e13715e566bc", "d7691a80-8971-4dc4-8f07-b6a6e66d4402", "d8fe5e76-0ddc-43c6-ba84-c31ef5259a89", "e043e646-6af0-4348-ae38-41a24193eba8", "e20db5a0-5870-4bf7-b708-b6f93ec72d1f", "e37924f0-9c45-4139-9f3e-39f67c7c7dc7", "e3fa5058-9d5f-4251-b407-4cb0dfc5c26f", "e4196682-92b8-4b64-852d-c7899d3a0c30", "e49c3eb6-0974-498c-99b1-f38a303dd0f2", "e79eea12-12f6-4cf3-aeca-a47888379eba", "e8e65df2-201f-4925-b41c-8f644064df41", "eaefa0e3-6600-4215-88fe-128c870d0149", "eb5e5b32-a498-4f69-8a7b-73f2adad71cc", "ec0d2f63-f2ce-45f3-81d0-64c9e6f6b96c", "ec25cb49-3e74-41fe-bef0-c7658d0ef911", "ed6c7968-cc9d-4862-b561-5ddb885a7ed7", "ef678be3-7ee9-4317-b84d-34d8e9c86788", "eff8a877-26d6-4ac7-8011-c01c0add2bb4", "f208bf80-558e-4770-9af9-0e92a929bd0a", "f3a0f181-0ab9-434f-95da-06cbab52b50b", "f3cc957f-ca06-4bf0-811e-4a7b076d736b", "f479a6c8-2660-49fe-8544-2ad179835e53", "f5459265-7979-44ca-a42b-8b7a7d19fa99", "f57dd695-f3b4-409e-a93b-371e2dac8f2c", "f7b1452f-7787-4d69-88b0-8f975a75d1a1", "fa308877-7c6e-43a0-8c51-c5b6f5113da2", "fa8e5b67-8cc7-40a3-a5ca-9490a725fdc1", "fcce3ada-91e4-48b4-817b-f6d0349b6fa6", "fdccabef-99ee-43b7-94aa-80eea0eab64b", "fe9232c9-360d-43f0-8854-1e602022b406", "fec6029a-201c-4e4a-8055-33d2a4cabc6c", "fef5d696-e47f-4602-939f-a43ae5093e56"], "title": "Exploiting the Power of Multiplicity: A Holistic Survey of Network-Layer Multipath", "venue": "IEEE Communications Surveys and Tutorials", "year": 2015, "id": "369494d1-afd9-4cb4-a45d-746e4a5db047"}
{"abstract": "The variability in the service level agreements (SLAs) of cloud providers prompted us to ask the question how do the SLAs compare and how should the SLAs be defined for future cloud services. We break down a cloud SLA into easy to understand components and use it to compare SLAs of public cloud providers. Our study indicates that none of the surveyed cloud providers offer any performance guarantees for compute services and leave SLA violation detection to the customer. We then provide guidance on how SLAs should be defined for future cloud services.", "authors": ["Salman Abdul Baset"], "n_citation": 126, "references": ["f897ed31-dde9-47b5-be4c-dbcdee9abccc"], "title": "Cloud SLAs: present and future", "venue": "Operating Systems Review", "year": 2012, "id": "74c9d693-337a-4c1f-9a08-177e4f2954b4"}
{"abstract": "It has been argued that much of human intelligence can be viewed as the process of matching stored patterns. In particular, it is believed that chess masters use a pattern\u2013based knowledge to analyze a position, followed by a pattern\u2013based controlled search to verify or correct the analysis. In this paper, a first\u2013order system, called PAL, that can learn patterns in the form of Horn clauses from simple example descriptions and general purpose knowledge is described. The learning model is based on (i) a constrained least general generalization algorithm to structure the hypothesis space and guide the learning process, and (ii) a pattern\u2013based representation knowledge to constrain the construction of hypothesis. It is shown how PAL can learn chess patterns which are beyond the learning capabilities of current inductive systems. The same pattern\u2013based approach is used to learn qualitative models of simple dynamic systems and counterpoint rules for two\u2013voice musical pieces. Limitations of PAL in particular, and first\u2013order systems in general, are exposed in domains where a large number of background definitions may be required for induction. Conclusions and future research directions are given.", "authors": ["Eduardo F. Morales"], "n_citation": 50, "references": ["14121a9f-3b79-4972-b3c2-c0d08e0bcdd9", "26535595-bf3e-47d4-bb82-1ac89e624919", "34746e29-6e84-44bc-af8c-74e1592d8052", "385540c1-e62f-4a77-9917-01faa254af5a", "4516543e-c8bb-4b21-818e-dad61ff606d0", "5ef17e34-fd82-4fea-9d33-3e0878c85fc1", "a9734cd4-1a64-4249-8657-8a3e8bf090ec", "bd27a259-80aa-43c9-86ae-4b04aa34bfac", "c109bf5a-4d57-469f-b068-8a8fdb6a5df3", "dccc0401-d2df-4cc7-90df-998633ff2b05"], "title": "PAL: A Pattern-Based First-Order Inductive System", "venue": "inductive logic programming", "year": 1997, "id": "fd494525-4a6c-4883-93d6-8dbfb9a0ebf7"}
{"abstract": "We describe a distributed algorithm for solving the rendezvous problem based on consensus protocols. We extend our previous work by considering the case when the evolution of the system is affected by measurement noise. The consensus formulation allows us to derive conditions for convergence of the system towards a ball with a finite radius. We derive an upper bound on the radius of the ball and show how it depends on the magnitude of the noise. We also present examples showing that the bound is tight and can be in fact achieved, but that typically the convergence is much better than the bound suggests.", "authors": ["Carlos H. Caicedo-Nunez", "Milos Zefran"], "n_citation": 9, "references": ["069aa4a5-017b-49e3-ba71-20bcade4d634", "2768199c-b9d6-4001-94d3-e6429c93bc5f", "38d0db45-5041-4bed-9187-a559385f4203", "4a78d773-7703-4de6-9881-2bcef9e336ea", "5a2b7dd5-6bc0-4478-8cc0-28d1ad03cf03", "602e7bea-17a2-492c-8c67-cdd82a30bcb1", "6460eee0-033e-4185-8b7c-dbcb931e1b2c", "860a3efc-800e-4e62-8200-7acf3f8d2b8d", "8c581627-0fe3-46cf-99cf-c5e3c9af272e", "8d2de5b6-3219-40e5-8b49-a2e8d06893ee", "9871f116-5179-4f34-8612-78aa41f13ae7", "b7d6da60-31ce-462f-a89b-d9c28c0e9b14", "d9162547-fd7f-4605-855d-0a3173c4b08e", "d9ca4d11-d43d-4292-9d64-5899028f3c29", "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9"], "title": "Rendezvous under noisy measurements", "venue": "conference on decision and control", "year": 2008, "id": "502ada08-b3c7-44a5-ae7d-c81d6b6fbbb6"}
{"abstract": "A key aspect of variability management in software product families is the explicit representation of the variability. Experiences at several industrial software development companies have shown that a software variability model should do four things: (1) uniformly represent variation points as first-class entities in all abstraction layers (ranging from features to code), (2) allow for the hierarchical organization of the variability, (3) allow for the first-class representation of simple (i.e., one-to-one) and complex (i.e., n-to-m) dependencies, and (4) allow for modeling the relations between dependencies. Existing variability modeling approaches support the first two requirements, but lack support for the latter two. The contribution of this paper is a framework for variability modeling-COVAMOF-that provides support for all four requirements.", "authors": ["Marco Sinnema", "Sybren Deelstra", "Jos Nijhuis", "Jan Bosch"], "n_citation": 303, "references": ["2190e46f-9cd6-4e16-a246-a8105072765a", "28d20543-118a-4f4b-acd8-90affb56f3d5", "3df22f16-7b64-4bc9-9368-3b6df12d1782", "520e52ab-7d17-46ee-aefc-a10b25656205", "576dfe74-f022-4a80-b84d-b0facb1e4064", "64153bc0-0c3a-4c5d-be93-b0f29bafc84f", "70cbeb40-b16f-4131-895d-d55cdc6e1cd3", "746294f6-0356-4684-9b4b-480ad83d0e9a", "7f4872b0-d490-4ea5-9a08-514a1f7ee324", "f3daecd0-d908-4f87-a14d-da7794474ab7"], "title": "COVAMOF: A Framework for Modeling Variability in Software Product Families", "venue": "software product lines", "year": 2004, "id": "cdb12323-f7b7-4010-9a47-22bd39bf3bcf"}
{"abstract": "We show that when a compact set is globally asymptotically stable under the action of a differential inclusion satisfying certain regularity properties, there exists a smooth differential equation rendering the same compact set globally asymptotically stable. The regularity properties assumed in this work stem from the consideration of Krasovskii/Filippov solutions to discontinuous differential equations and the robustness of asymptotic stability under perturbation. In particular, the results in this work show that when a compact set cannot be globally asymptotically stabilized by continuous feedback due to topological obstructions, it cannot be robustly globally asymptotically stabilized by discontinuous feedback either. The results follow from converse Lyapunov theory and parallel what is known for the local stabilization problem.", "authors": ["Christopher G. Mayhew", "Andrew R. Teel"], "n_citation": 18, "references": ["0d46e1f8-f5c9-4da0-972d-614503a4adc5", "20a64340-c9ab-474b-bbe0-0b8c35a06ee5", "28225ca0-1e1f-471f-917d-4db06c1ad91c", "30932642-fd17-4ae9-9a5b-90e67adcfe41", "45cea78d-0878-4d7a-9527-a8d5beb3e6fe", "65db39a6-11a6-4c04-9c4a-b58f5476266d", "722523ab-7af7-4d12-b188-146293a67fce", "925e33ee-e1ab-401b-8c88-1aecbe625c1c", "9783c428-2855-4382-a3e5-944bd21aa1a3", "e585b09d-b6aa-4c09-9ff8-9ad784ec1a1d", "e74e3bd5-6175-4669-9aa7-d82391f8deea"], "title": "On the topological structure of attraction basins for differential inclusions", "venue": "Systems & Control Letters", "year": 2011, "id": "c7df3c6a-5824-4446-b5c1-b9265000dae9"}
{"abstract": "Background: The position of a sentence in a document has been traditionally considered an indicator of the relevance of the sentence, and therefore it is frequently used by automatic summarization systems as an attribute for sentence selection. Sentences close to the beginning of the document are supposed to deal with the main topic and thus are selected for the summary. This criterion has shown to be very effective when summarizing some types of documents, such as news items. However, this property is not likely to be found in other types of documents, such as scientific articles, where other positional criteria may be preferred. The purpose of the present work is to study the utility of different positional strategies for biomedical literature summarization. Results: We have evaluated three different positional strategies: (1) awarding the sentences at the beginning of the document, (2) preferring those at the beginning and end of the document, and (3) weighting the sentences according to the section in which they appear. To this end, we have implemented two summarizers, one based on semantic graphs and the other based on concept frequencies, and evaluated the summaries they produce when combined with each of the positional strategies above using ROUGE metrics. Our results indicate that it is possible to improve the quality of the summaries by weighting the sentences according to the section in which they appear (\u2248 17% improvement in ROUGE-2 for the graph-based summarizer and \u2248 20% for the frequency-based summarizer), and that the sections containing the more salient information are the Methods and Material and the Discussion and Results ones. Conclusions: It has been found that the use of traditional positional criteria that award sentences at the beginning and/or the end of the document are not helpful when summarizing scientific literature. In contrast, a more appropriate strategy is that which weights sentences according to the section in which they appear.", "authors": ["Laura Plaza", "Jorge Carrillo-de-Albornoz"], "n_citation": 50, "references": ["038fe72c-1cf4-4832-a814-4253d1ef8f0d", "08b6dddf-32d4-4364-9abd-0930eb85cc1f", "11951d8c-b678-45dd-9b84-5404bde769d7", "135c7d8b-578a-462d-98d0-0288eec3a9fc", "1e35afc8-a45b-426d-a5c9-d5f7dd2d1b32", "2b2eb3c1-97aa-4641-8c4f-04ea401f6f3e", "321b363b-2fee-45e4-899c-e1f847f5fd69", "3268d2e1-c734-4618-910c-15302ba3e953", "32bd95de-7332-4400-86dc-97f2c6ed6247", "35ebfd73-1465-4aa2-bbdf-f3e7639bdf06", "403f49ae-1898-478f-ba59-8da516211894", "5d4f2004-08df-4e72-ae88-ba2f5f3865c1", "682178fc-2cdd-4d34-ab87-7fe70f7779fd", "743d41f3-717a-4b1f-b211-e502397b371f", "8a620ecc-1ba8-4379-b4b6-a5836fc83f74", "b0f2af35-b51f-411f-9ab8-ce748b2a59af", "b6d15711-df59-4310-af5f-5efe25fb0c87", "bc506a1e-d032-4269-99ba-73848f33e3aa", "c11f3ebc-3624-4bc3-99af-33d8e2a49bf5", "d2e03291-5289-4744-8621-3628979b9cd1", "e5fea480-e629-4561-9d36-96242854195b", "e763895d-e427-42ef-a590-04e35814630d", "ec217317-bfc6-4548-9204-b1134b5a50ba"], "title": "Evaluating the use of different positional strategies for sentence selection in biomedical literature summarization", "venue": "BMC Bioinformatics", "year": 2013, "id": "8b698aa3-b0fb-467c-b480-b074e07d3b32"}
{"abstract": "Abstract   Knowledge engineering for information systems is a long-term, multi-person task that requires tight control and memorization not only of  what  knowledge is acquired but also of  why  and  how  it is acquired. We propose a software process data model as the foundation of a knowledge-based software information system that emphasizes control, support and documentation of design decision-making and tool integration in information systems environments.  The model is developed along two dimensions. Firstly, it defines how to represent and integrate design objects (what), design decisions (why) and design tools (how). Secondly, it exploits the abstraction mechanisms of the extensible hybrid knowledge representation language CML/Telos to manage the evolution not only of particular software projects, but also of the software development environment in which these projects operate. Modular aggregation relates design-in-the-small and design-in-the-large support. Besides motivating and formalizing the model, we describe an operational prototype implementation called  ConceptBase  and report intitial application experiences in the DAIDA ESPRIT project.", "authors": ["Matthias Jarke", "Manfred A. Jeusfeld", "Thomas Rose"], "n_citation": 77, "references": ["0a7e0331-8c7a-42a0-866f-b1426bfb665e", "27955429-2c6d-4b38-849f-fa463dc8f654", "4d6012ab-5d6c-4c64-ae97-1b7565370f12", "4f1c4b4d-94dc-4324-82dc-c3d076d76794", "50689679-8346-48f2-8d70-4dfd29f8b470", "73724859-46fc-40b1-99d7-ea161847bcfe", "7669791b-7045-4040-bf1b-32cb7e7d045d", "87b2974d-1bca-42c8-b8b0-15c92ea5717c", "8cc60b40-a36b-41f7-a9ec-ccc5f3f848ba", "93812939-66d9-4b0b-9137-d08f62dea283", "997e2b1f-327d-4212-a71f-a5936b723772", "9c00b540-465c-4559-ad30-09c09cbea903", "a2333d5c-502d-41af-8e4a-fffc5ed4d374", "a9d193ab-dae8-4876-a0b0-eac4f6134a36", "bb9b07a0-7b53-4c67-81f1-20c049f88249", "bcfa87fb-47c7-43c2-94c4-ffda08ecc9b7", "dad10223-c1b9-413a-9585-32a11674cc7f", "dbe5ae2e-bbc0-4508-8df5-3ec95c784fa8", "e131cc95-8653-48fe-bdbc-b05087b55822", "e6704790-eaad-462d-bd57-12df8e19101f", "ef7ba3ba-003c-453c-9cb1-7ae6e4757d5d"], "title": "A software process data model for knowledge engineering in information systems", "venue": "Information Systems", "year": 1990, "id": "5293a454-36d6-44f7-a0a7-13b1f87b3943"}
{"abstract": "This paper proposes an efficient method for evaluation of deductive queries over constraint databases. The method is based on a combination of the top-down resolution with memoing and the closed form bottom-up evaluation. In this way the top-down evaluation is guaranteed to terminate for all queries for which the bottom-up evaluation terminates. The main advantage of the proposed method is the direct use of the information present in partially instantiated queries without the need for rewriting of the original program. The evaluation algorithm automatically propagates the necessary constraints during the computation. In addition, the top-down evaluation potentially allows the use of compilation techniques, developed for compilers of logic programming languages, which can make the query evaluation very efficient.", "authors": ["David Toman"], "n_citation": 50, "references": ["264298ff-e000-4a51-be7f-fc54d6144562", "2afc2a11-87d7-4357-9d48-f0a6186172b1", "2fd06109-1303-4bb3-b784-53715a07a488", "4d23d7c3-bdc9-4b32-ab16-fb3fefd913c6", "544683d2-16f2-4a50-a4a9-b915b7de6efe", "6583e0d9-22b9-4994-ae4e-71b16c9143a0", "6d73e1cb-ffef-4e1d-b036-9f578449c251", "6f59340f-265f-4622-a64a-9ddde531ed2d", "726a8e8b-1810-4ecd-9816-4f97b54ac876", "aec2f4e9-5e82-4db7-acd4-4813e2b20b62", "b08d9944-1643-400c-9728-c4869ffbb752", "b2eddbc1-021d-41cb-aa50-025eb10ed5c2", "b7d5679f-5edc-4c38-b3d0-944425a7bbe6", "b8ac4c04-09da-4e0b-ac27-79e6094b3d30", "bf65dc93-78f5-4562-8bbf-cced093359a1", "c24278c4-5209-47b5-b2b8-11f0684f1d64", "d0adc46e-d20b-429c-a237-477cbf2d8286", "d36a7f08-2fa4-4447-b20e-ef808d235fd7", "da60708e-45e0-4f72-9f90-f412b8cfdb7a", "ec05eb70-1ca0-4164-a95f-e29dc82d0bfe", "eca97fce-b910-4bf0-80f5-e9c422711d88", "f203d22f-04dd-4fb5-a204-258a7b0cd46c", "f3480f0c-842f-4b11-959f-181d1e08abed"], "title": "Memoing evaluation for constraint extensions of datalog", "venue": "Constraints - An International Journal", "year": 1998, "id": "95872599-11ee-4306-89ea-089d24e96e38"}
{"authors": ["Sung-Shik T. Q. Jongmans", "Farhad Arbab"], "n_citation": 11, "references": ["2e238570-1c06-4956-82bb-3a8513357330", "30d5e5dd-8bdf-4db8-900a-7bacf60c29bf", "5683bed4-81f4-4e95-83ef-57fab6f5b47b", "7cf9ee5e-0334-4a35-a546-fc218e219671", "8136df6e-6bac-484f-a622-06b30c72d9bb", "8e536fdc-a7a3-48f7-8473-5c9be7a18d9b", "8fde3583-8210-40e3-a94d-429ae50bcdab", "9222fbf0-27e7-4373-a280-ae7eb1e4ed89", "93b22478-94f8-4c15-ae03-ed98a856f60c", "cdde72c8-2acf-4207-a7b5-5d0ccac52d76", "fadbc3df-8612-4aa4-8fc9-5efd413cfb02"], "title": "Can High Throughput Atone for High Latency in Compiler-Generated Protocol Code?", "venue": "fundamentals of software engineering", "year": 2015, "id": "16654556-5806-41b9-8508-0b1c24499aab"}
{"abstract": "Transfer learning addresses the problem of how to leverage knowledge acquired in a source domain to improve the accuracy and speed of learning in a related target domain. This paper considers transfer learning with Markov logic networks (MLNs), a powerful formalism for learning in relational domains. We present a complete MLN transfer system that first autonomously maps the predicates in the source MLN to the target domain and then revises the mapped structure to further improve its accuracy. Our results in several real-world domains demonstrate that our approach successfully reduces the amount of time and training data needed to learn an accurate model of a target domain over learning from scratch.", "authors": ["Lilyana Mihalkova", "Tuyen N. Huynh", "Raymond J. Mooney"], "n_citation": 172, "references": ["0a6572fb-3006-4f65-996d-7d6095906c63", "1c152bbb-3f77-4f83-a7d0-2a9b662f93b1", "3a2f5acc-f479-48c3-b355-860726eccdf3", "550c7266-6eed-4135-9f56-07825fb86ed1", "739659a7-5aa8-49de-8cbc-f7d9c3b405e7", "a66b7562-5df3-4143-97b5-a9f746ce90c2", "b7488bd7-0558-43c4-832e-0a1056a23658", "c0c674c6-e0b7-4c5c-b57f-b82be2f62c71", "c33b00d3-e4fd-4c5f-9691-c463d72cf239", "c4054ed9-c5e4-4797-8142-74002e09f49e", "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706", "de201464-47ae-4cc8-bf14-cb40c65ec2ee", "ea1de143-3a1e-466b-8dfb-3d7d7668630c", "ee746464-b6d4-47c6-afbb-8b8e0faa0bcd"], "title": "Mapping and revising Markov logic networks for transfer learning", "venue": "national conference on artificial intelligence", "year": 2007, "id": "830116fb-706d-4cb2-bb01-6d6adf4d67d6"}
{"abstract": "Abstract   Typical multicast protocols are designed to operate with group sizes of up to 50 members. Many of the techniques used do not scale to larger groups very well due to the implosion problem. This paper describes a protocol which has been designed to be scalable to a large degree. The protocol uses negative acknowledgements to increase its reliability, with a saturation method being used when the message is small. This ensures that a message has a high probability of being detected, regardless of the message size. The use of negative acknowledgements is intended to reduce the implosion effect to a minimum. A logical tokenbased ring system is used at the transport level to prevent all of the recipients of a multicast replying at the same time, preventing the client being overrun. Also, this token is used as a failure detector, causing the ring structure to reconfigure around the failure.", "authors": ["Mark G. W. Jones", "S\u00f8ren-Aksel S\u00f8rensen", "Steven R. Wilbur"], "n_citation": 52, "references": ["4064688b-5796-4fb0-9f99-86730a2bf8d3", "4b4c2f4d-3c81-488b-977e-b32c2093ad17", "6602ed73-af56-4856-bbfd-2cc19f159a89", "82df4d2b-e9b2-458a-bf78-5878176d927e", "94da8bf6-ce27-4416-b2ae-238bc372c1c1", "a2fdc63b-cd86-43f0-802e-2eb8a7ddabe6", "a4251a7d-b867-4352-a2f3-497bccc4fc21", "c14654e1-9cdd-43cd-aaf4-bb75a06915a0", "cea4fd65-935e-4d74-b62d-80fa79beae29", "e1c7443f-fbc7-4edc-919b-8f3bd2c1a34c"], "title": "Protocol design for large group multicasting: the message distribution protocol", "venue": "Computer Communications", "year": 1991, "id": "e83dcc20-cd44-4cf5-b9c4-3a6ea532ec0e"}
{"abstract": "Adaptation of Intrusion Detection Systems (IDSs) in the heterogeneous and adversarial network environments is crucial. We design an adaptive IDS that has 10% higher accuracy than the best of four different baseline IDSs. Rather than creating a new \u2018super\u2019 IDS, we combine the outputs of the IDSs by using the online learning framework proposed by Bousquet and Warmuth [1]. The combination framework allows to dynamically determine the best IDSs performed in different segments of a dataset. Moreover, to increase the accuracy and reliability of the intrusion detection results, the fusion between outputs of the four IDSs is taken into account by a new expanded framework. We conduct the experiments on two different datasets for benchmarking Web Application Firewalls: the ECML-PKDD 2007 HTTP dataset and the CISIC HTTP 2010. Experimental results show the high adaptability of the proposed IDS.", "authors": ["Hai Thanh Nguyen", "Katrin Franke"], "n_citation": 50, "references": ["0901005b-5edf-44d9-86cd-9360747ee3ec", "0cb7d82d-88b4-4fa1-a1e3-f03fda40660a", "177dda10-1dae-4ea7-8567-1a49d327afa8", "1f61a4c8-87fa-45d9-bd6b-14c5b815f1bc", "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8", "416c8b20-bd38-4ad5-bedd-09654593735e", "427204e3-eb57-49f7-80c7-84b65e1aad6e", "931e5ce6-77e1-429f-b8a5-d1adff52bed5", "a6f34315-e59f-43fd-8d37-d941779cf8f2", "c0cfab83-403d-4b25-9a61-dbc2b9207531", "c8a617d5-66fb-4f12-bd3d-cf049da09293", "e773b8e6-44d4-49bd-9744-a5ea2b53bb2a", "e93140f8-ff5c-45c0-abd2-57dd471f4ed0"], "title": "Adaptive Intrusion Detection System via online machine learning", "venue": "", "year": 2012, "id": "a7d65c60-7cce-4b3e-8277-22994fa56072"}
{"abstract": "Gaming-simulation is an important pedagogical tool for learning. However, as an educational tool gaming-simulation follows the concept of discovery learning and, therefore, does not necessarily support any direct educational aim. A way to overcome this weakness is to support gaming-simulation with an intelligent tutoring facility. Although it is generally believed that intelligent gaming-simulations have great potential for instruction, little work has been done on the development of an appropriate evaluation method to estimate the efficiency of their intelligent tutoring. The paper presents an introduction to intelligent gaming-simulation. It also proposes an evaluation method for the assessment of the tutoring abilities of intelligent gaming-simulations.", "authors": ["Julika Siemer", "Marios C. Angelides"], "n_citation": 94, "references": ["3c4cadd8-4f5b-484c-a34a-09eeec93e687", "446e341e-3d7a-4700-bf5f-f4919b1989ce", "f52d56ef-4964-4ed0-ab43-e7a10bc36f90"], "title": "Evaluating intelligent tutoring with gaming-simulations", "venue": "winter simulation conference", "year": 1995, "id": "4d0d4e1d-6ac2-498c-ae0a-fa02eb0de77c"}
{"abstract": "To reduce the amount of data transfer in networked systems, measurements are usually taken only when an event occurs rather than at each synchronous sample instant. However, this complicates estimation problems considerably, especially in the situation when no measurement is received anymore. The goal of this paper is therefore to develop a state estimator that can successfully cope with event based measurements and attains an asymptotically bounded error-covariance matrix. To that extent, a general mathematical description of event sampling is proposed. This description is used to set up a state estimator with a hybrid update, i.e., when an event occurs the estimated state is updated using the measurement, while at synchronous instants the update is based on knowledge that the sensor value lies within a bounded subset of the measurement space. Furthermore, to minimize computational complexity of the estimator, the algorithm is implemented using a sum of Gaussians approach. The benefits of this implementation are demonstrated by an illustrative example of state estimation with event sampling.", "authors": ["Joris Sijs", "M Mircea Lazar"], "n_citation": 105, "references": ["0c2c3c8d-c774-4458-8bc3-0649a020c823", "1d24db91-733f-4854-b091-fe485e9cb326", "581dc08a-0370-484c-a3bd-3572af799c43", "9367aa0f-86d0-44ba-a046-28db136aaa3e", "9568b150-94af-41e3-83f5-79b9f1299f21", "f3267c01-b670-4b7a-a3a5-79088c0d90ab"], "title": "Event Based State Estimation With Time Synchronous Updates", "venue": "IEEE Transactions on Automatic Control", "year": 2012, "id": "d38deacf-ea01-467c-a81c-6d90163c2185"}
{"abstract": "The definition of similarity measures is one of the most crucial aspects when developing case-based applications. In particular, when employing similarity measures that contain a lot of specific knowledge about the addressed application domain, modelling similarity measures is a complex and time-consuming task. One common element of the similarity representation are local similarity measures used to compute similarities between the values of single attributes. In this paper an approach to learn local similarity measures by employing an evolution program-- a special form of a genetic algorithm--is presented. The goal of the approach is to learn similarity measures that sufficiently approximate the utility of cases for given problem situations in order to obtain reasonable retrieval results.", "authors": ["Armin Stahl", "Thomas Gabel"], "n_citation": 72, "references": ["227c3759-9108-46ca-b04f-6aae12baf2ec", "5534ae18-9e8c-44f7-adad-e54baa369db7", "676a4898-d87d-40ae-98c7-c74e781f738d", "83a50ecd-cb13-4754-800d-562433b19c5d", "86c1add6-2653-4a52-87bf-0fdc64cb7337", "9b80e173-2d0d-4e2d-8cd0-0fcfe230fd81", "a07c355d-1a19-49c6-9743-f7d97e919ca5", "aecb3d78-0ed0-4916-8d70-7f18136493a2", "eae09b2f-3ae6-4d95-adc4-c61d45bb5801", "f71dd21e-cd1f-4d77-a276-185c432796f1"], "title": "Using evolution programs to learn local similarity measures", "venue": "international conference on case-based reasoning", "year": 2003, "id": "5debc59e-dd00-4915-aa9d-b28b936e48b1"}
{"abstract": "We discuss bribery as a rational behaviour in two player bi-matrix games in game settings, where one player can assign the strategies to the other player. This can be observed as leader (or: Stackelberg) equilibria, where a leader assigns the strategy to herself and to the other player, who follows this lead unless he has an incentive not to. We make the rational assumption that a leader can further incentivise decisions of her follower, by bribing him with a small payoff value, and show that she can improve her gain this way. This results in an asymmetric equilibrium for a strategy profile: the incentive equilibrium. By 'asymmetric equilibrium', we refer to the strategy profile where a leader might benefit from deviation, while her follower does not. We observe that this concept is strong enough to obtain social optimum in the classic example of the prisoners' dilemma. We show that computing such incentive equilibria is no more expensive than computing leader equilibria: as opposed to Nash equilibria, they are both tractable. We evaluated our techniques on a large set of benchmarks (100,000 bi-matrix games) and provide the experimental results for incentive equilibrium.", "authors": ["Anshul Gupta", "Sven Schewe"], "n_citation": 2, "references": ["0f2c44fe-6bde-431b-8c54-7206481ac016", "718af896-9e98-4f50-a9be-5028d6336b59", "9d538d13-7cb5-4d23-b6e7-93c191fa32f1", "b29f7848-1675-44e0-8060-a8f79e92c677", "db5c8841-8b08-4449-9168-ef72f9f11684"], "title": "It Pays to Pay in Bi-Matrix Games: a Rational Explanation for Bribery", "venue": "adaptive agents and multi-agents systems", "year": 2015, "id": "0c4f3ea2-411e-4133-82d9-1d146f0c50f2"}
{"abstract": "We formulate the problem of permuting a matrix to block angular form as the combinatorial minimization of an objective function. We motivate the use of simulated annealing (SA) as an optimization tool. We then introduce a heuristic temperature dependent penalty function in the simulated annealing cost function, to be used instead of the real objective function being minimized. Finally we show that this temperature dependent penalty function version of simulated annealing consistently outperforms the standard simulated annealing approach, producing, with smaller running times, better solutions. We believe that the use of a temperature dependent penalty function may be useful in developing SA algorithms for other combinatorial problems. INFORMS Journal on Computing, ISSN 1091-9856, was published as ORSA Journal on Computing from 1989 to 1995 under ISSN 0899-1499.", "authors": ["Julio Michael Stern"], "n_citation": 50, "title": "Simulated Annealing with a Temperature Dependent Penalty Function", "venue": "Informs Journal on Computing", "year": 1992, "id": "279c35c3-4e1d-4bfb-ade7-0f1a4e11330d"}
{"abstract": "A problem in smart environments is the interaction with a myriad of different devices, in particular the selection which of the devices should be controlled. Typically, different devices require different control tools. In contrast, a generic Point & Click appliance is proposed. To interact with a device in the environment this generic control appliance is pointed at devices for selection providing visual feedback to the user, obtains control information from the device, and allows control with the help of a simple user interface.", "authors": ["Michael Beigl"], "n_citation": 67, "references": ["2b8c4575-897f-40ee-8023-9b4ce82f6fce", "8c414ea6-75cf-4098-bdff-85ca41ae5e04"], "title": "Point & Click - Interaction in Smart Environments", "venue": "ubiquitous computing", "year": 1999, "id": "ecb333c7-cef3-46b8-9ccf-b66b2fd85e01"}
{"abstract": "An automated analysis of all reachable states in a distributed system can be used to trace obscure logical errors that would be very hard to find manually. This type of validation is traditionally performed by the symbolic execution of a finite state machine (FSM) model of the system studied. The application of this method to systems of a practical size, though, is complicated by time and space requirements. If a system is larger, more space is needed to store the state descriptions and more time is needed to compare and analyze these states. This paper shows that if the FSM model is abandoned and replaced by a state vector model significant gains in performance are feasible, for the first time making it possible to perform effective validations of large systems.", "authors": ["Gerard J. Holzmann"], "n_citation": 194, "references": ["294268a7-d280-450b-9bc3-e0d9827f53ec", "493d0cc8-5e24-4aff-a8ac-d17d145078a4", "8f9d1206-5ae0-47ab-be8c-ff9f17735eae", "911d49e6-8db4-4529-af70-5a44f23e781b", "ac78627e-6fce-4633-b2a1-2c11c760ca3c", "ad5f422f-6763-4c74-b273-88ea1af7f518", "d559b371-38db-4957-831f-ab3f05713cf6"], "title": "An improved protocol reachability analysis technique", "venue": "Software - Practice and Experience", "year": 1988, "id": "7683c315-f31d-46e6-b216-9c62cc56746a"}
{"abstract": "The strategic use of deceptive language in managerial financial fraud is investigated with linguistic cues extracted from 202 publicly available financial disclosures. Those crafting fraudulent disclosures use more activation language, words, imagery, pleasantness, group references, and less lexical diversity than non-fraudulent ones. Writers of fraudulent disclosures may write more to appear credible while communicating less in actual content. A parsimonious model with Naive Bayes and C4.5 achieved the highest classification accuracy. Results support the potential use of linguistic analyses by auditors to flag questionable financial disclosures and to assess fraud risk under Statement on Auditing Standards No. 99.", "authors": ["Sean L. Humpherys", "Kevin Moffitt", "Mary B. Burns", "Judee K. Burgoon", "William F. Felix"], "n_citation": 148, "references": ["05e083bc-08f8-4806-abbc-698be72d9d39", "11788c07-c9b8-47c5-bf10-1aa99aee30f6", "234c32e7-159d-4a7b-a5ac-a1a2c7f41b29", "40d86768-80df-44da-9839-b27dc683d05a", "4b035e63-dab7-4ddf-88e1-7a93269ec4bb", "62549bc2-e0b3-46e8-8d32-390dded105d5", "95216d98-ea14-405a-9d56-0d142b055198", "c1e288b2-dae6-4d16-af60-46476e382bbc", "d6843442-d876-4d13-a0b2-a26f1f60da48", "e0b44b7e-6964-4e7a-994f-ebebff854a35", "e8b14864-1cb6-4aea-882c-2cced55313e5", "ec9799d5-9bbc-47f9-aa3e-34ba7502251b", "f2c8a468-8b66-460d-a1e4-7a5ef5ed3543", "f405e756-0ffe-4382-b67d-b434b937a108", "fde1a431-09f2-4ae9-9816-f82a6228d057"], "title": "Identification of fraudulent financial statements using linguistic credibility analysis", "venue": "decision support systems", "year": 2011, "id": "d166c1e9-de8e-4685-a3c0-6f76dd310a0f"}
{"abstract": "This paper summarized experiences of practical software development exercise in PBL style activities from organizer perspective. The object of this PBL is nurturing advanced knowledge as advanced information and communication technology (ICT) engineers. A main pillar of this report is trace the 5-year history of three sub environments such as development, development support and teaching support environment which are badly need to hold our software development PBL, from problem and its solutions viewpoint.", "authors": ["Naoki Fukuyasu", "Sachio Saiki", "Hiroshi Igaki", "Yuki Manabe"], "n_citation": 4, "references": ["aa45546d-8fa2-401a-ac2b-0108bbeb1bc1"], "title": "Experimental Report of the Exercise Environment for Software Development PBL", "venue": "software engineering, artificial intelligence, networking and parallel/distributed computing", "year": 2012, "id": "e00c6585-f288-46d4-9a9f-efb36d64ea02"}
{"abstract": "Objectives: During the last decade, evidence-based medicine has given rise to an increasing number of medical practice guidelines and protocols. However, the work done on developing and distributing protocols outweighs the efforts on guaranteeing their quality. Indeed, anomalies like ambiguity and incompleteness are frequent in medical protocols. Recent efforts have tried to address the problem of protocol improvement, but they are not sufficient since they rely on informal processes and notations. Our objective is to improve the quality of medical protocols. Approach: The solution we suggest to the problem of quality improvement of protocols consists in the utilisation of formal methods. It requires the definition of an adequate protocol representation language, the development of techniques for the formal analysis of protocols described in that language and, more importantly, the evaluation of the feasibility of the approach based on the formalisation and verification of real-life medical protocols. For the first two aspects we rely on earlier work from the fields of knowledge representation and formal methods. The third aspect, i.e. the evaluation of the use of formal methods in the quality improvement of protocols, constitutes our main objective. The steps with which we have carried out this evaluation are the following: (1) take two real-life reference protocols which cover a wide variety of protocol characteristics; (2) formalise these reference protocols; (3) check the formalisation for the verification of interesting protocol properties; and (4) determine how many errors can be uncovered in this way. Results: Our main results are: a consolidated formal language to model medical practice protocols; two protocols, each both modelled and formalised; a list of properties that medical protocols should satisfy; verification proofs for these protocols and properties; and perspectives of the potentials of this approach. Our results have been evaluated by a panel of medical experts, who judged that the problems we detected in the protocols with the help of formal methods were serious and should be avoided. Conclusions: We have succeeded in demonstrating the feasibility of formal methods for improving medical protocols.", "authors": ["Annette ten Teije", "Mar Marcos", "Michael Balser", "Joyce van Croonenborg", "Christoph Duelli", "Frank van Harmelen", "Peter J. F. Lucas", "Silvia Miksch", "Wolfgang Reif", "Kitty Rosenbrand", "Andreas Seyfang"], "n_citation": 118, "references": ["02a156bf-d9e8-4d94-8368-d265435d5002", "15afbd51-7e6f-4cad-9cc7-eb485a1465e8", "2a49b773-1e5f-423a-9555-b5c27e5ed22d", "49b77cdd-4171-4716-ba68-61c61aab8868", "50375a3d-76cf-464a-9e7b-88c60f26e844", "594e1c23-9d78-49e7-a3fb-407ab718b302", "95f3511c-e695-4b49-95e1-83983c4f006e", "9bd1c3eb-9ba4-453c-a662-46fe847c22ad", "a591e0f3-473e-4787-b6a3-905b8831cc87", "b45835f0-065e-4cdf-9c0b-1247da374161", "b6737175-b463-4590-a05b-0dd3a0a0335c", "badc312f-209c-44c4-9161-c7611e47e5f3", "c40bffa2-02cc-4e6f-8484-40a6132b608f", "d3c99906-64b9-44c7-a13c-97a50dbd12b5"], "title": "Improving medical protocols by formal methods", "venue": "Artificial Intelligence in Medicine", "year": 2006, "id": "7e488194-0eab-49e6-9b3f-198d5dd3b0fb"}
{"abstract": "A technique is presented that allows (1) computing the best approximation of a given family using linear combinations of a small number of basis functions; and (2) describing all finite-dimensional families, i.e. the families of filters for which a finite-dimensional representation is possible with no error. The technique is general and can be applied to generating filters in arbitrary dimensions. Experimental results that demonstrate the applicability of the technique to generating multi-orientation multiscale 2-D edge-detection kernels are presented. The implementation issues are also discussed. >", "authors": ["Pietro Perona"], "n_citation": 96, "references": ["0d8e7cf4-513f-4642-9fe5-349821428d35", "1a040e34-192c-48da-89c4-a89f05cc6f9b", "1aab6663-cc0a-425c-83b4-2ac5d8b5e052", "25b0c9f9-0c8a-4f2a-b075-90d339b6faa3", "33f413a3-d1b1-4080-a09b-4491a830bcfe", "36800655-b2ff-4eb7-9070-c6be304c4baa", "4967f485-afb7-4886-ab15-995d3a9e9d09", "4b230d75-936c-4a3f-9c1c-725bfd52ac51", "5b255d3a-5639-41cf-886b-8377bea8193f", "6cd1fccd-865f-4d54-b037-d622dbcfaf00", "7e7899a6-9d9f-4a1b-a6bd-ac5be828658c", "a4bdd408-986b-4257-98e5-b524cdcf310f", "a6719925-a6ec-491b-8a60-0fda5e0a0e8c", "d61e46ec-1332-4e40-a442-9e036507775a", "f3c16c78-af2a-4f51-8498-5067490b3a6b", "fc443443-416f-4fd5-ba46-17a06046711d"], "title": "Deformable kernels for early vision", "venue": "computer vision and pattern recognition", "year": 1991, "id": "3609b9c3-1aa0-4611-ab48-892a4a4d983d"}
{"abstract": "The smallest known biological organisms are, by far, the viruses. One of the unique adaptations that many viruses have aquired is the compression of the genes in their genomes. In this paper we study a formalized model of gene compression in viruses. Specifically, we define a set of constraints that describe viral gene compression strategies and investigate the properties of these constraints from the point of view of genomes as languages. We pay special attention to the finite case (representing real viral genomes) and describe a metric for measuring the level of compression in a real viral genome. An efficient algorithm for establishing this metric is given along with applications to real genomes including automated classification of viruses and prediction of horizontal gene transfer between host and virus.", "authors": ["Mark Daley", "Ian McQuillan"], "n_citation": 4, "references": ["12016e41-3186-4869-9caa-e459059b0456", "332084ee-29ab-411e-9d8b-0dc9e977c5a9", "678e38ed-adec-46b5-a030-90b705cce67a", "75432120-d662-4ebb-b6c9-32a0e204c11b", "e12b2a8d-6755-472c-83e6-ba62463934aa"], "title": "Viral gene compression: complexity and verification", "venue": "", "year": 2004, "id": "d41e0023-a5cd-4517-a314-036df3f03816"}
{"abstract": "A layered model of structured overlays has been proposed and it enabled development of a routing layer independently of higher-level services such as DHT and multicast. The routing layer has to include other part than a routing algorithm, which is essential for routing. It is routing process, which is common to various routing algorithms and can be decoupled from a routing algorithm. We demonstrated the decomposition by implementing an overlay construction toolkit Overlay Weaver. It facilitates implementation of routing algorithms and we could multiple well-known algorithms just in hundreds of lines of code with the toolkit. The decomposition also enables multiple implementations of the common routing process. Two implementations the toolkit provides perform iterative and recursive routing, respectively. Additionally, to our knowledge, the toolkit is the first feasibility proof of the layered model by supporting multiple algorithms and the higher-level services. Such modular design contributes to our goal, which is facilitation of rapid development of realistic routing algorithms and their application. We demonstrates that Overlay Weaver supports the goal by conducting large-scale tests and comparisons of algorithms on a single computer. The resulting algorithm implementations work on a real TCP/IP network as it is.", "authors": ["Kazuyuki Shudo", "Yoshio Tanaka", "Satoshi Sekiguchi"], "n_citation": 168, "references": ["1b0edd4c-486e-4ca7-84ae-1a7defa0a3aa", "1cd16e64-d0ff-4a1a-82d2-fcb45cebe213", "4c36f482-1f7d-4a6c-a6f9-2e0a5b7056a4", "4ef0e696-ed0d-4801-a5f7-ae03e59f4d13", "563b773a-023c-4b82-8016-694125b36594", "5d145698-700b-486f-86fb-13221c494363", "8ca9ca44-f8cd-4ca6-9f80-a0a4c112add2", "a8b1be24-c00f-4316-bc27-03d290ef19fc", "b5361b54-8bf8-4a9c-adab-97a0d08ad455", "c287e3bf-52f0-420f-bcd4-aa096c4be55a", "d5fb639a-89b7-4dbf-bce9-f4669854f455", "f14df1ed-e3e9-4348-9040-fc06e3411b95"], "title": "Overlay Weaver: An overlay construction toolkit", "venue": "Computer Communications", "year": 2008, "id": "25f103e4-2c84-4b53-a377-90ff33d452c6"}
{"authors": ["Bruno Monsuez"], "n_citation": 8, "references": ["039eca46-bad8-43c5-9361-764b4ecedcbb", "4b8d5647-b891-4bd0-b974-010bb0a27d6f", "635e2014-6579-4acf-9737-49593bc74701", "9642b45e-0c38-4c12-9ebf-45645e21fa4f", "9a4984f9-27d4-47eb-8bc8-0469bf540f94", "e435c51c-247b-4386-8238-0f4d5d754eca", "e520970c-da39-4a0f-b406-598c4958024d", "ed6c39a4-113a-4a27-829e-ee1c0808b8e8"], "title": "System F and Abstract Interpretation", "venue": "static analysis symposium", "year": 1995, "id": "b8f42da0-2c65-4f4e-a9af-df024c439bae"}
{"abstract": "As technological devices become more present in education, more researchers and educators are looking into different aspects of technology enhanced learning. Most recently, focus in technology enhanced learning is put on use of mobile devices i.e. mobile learning or m-learning. Mobile learning promotes concept of anytime anywhere learning which is important for students who frequently change places of learning and need access to the learning material as they move from one place to another. Such concept of learning is possible because more and more students have some type of a mobile device and mobile devices are mostly cheap, portable and flexible, have no start-up time, and require virtually no maintenance. While the mobile technology seems to be very attractive to students and usable in the learning process, there are also problems which burden further development of mobile learning or at least they are not helping its development: technological problems and obsolesce, lack of digital content made for use on mobile devices, lack of training of proper use of mobile devices in the learning process etc. Most of these and similar problems could be overcome if universities put more effort in adoption of mobile technologies among students and teaching staff.", "authors": ["Radovan Vrana"], "n_citation": 8, "references": ["2c394935-6459-48c4-ac6c-cb19a4ec1421", "2da16191-39f4-44b9-9209-ba635079783b", "337ab929-8ca1-42d1-8f07-ebee02a11ff8", "595b5ac4-4647-4bc5-b524-0b5087e42627", "63dbf281-4e8a-459d-be91-02bc7f4880e6", "dc61d458-8bb3-4ea6-9e88-93fe4554e1b1"], "title": "The developments in mobile learning and its application in the higher education including libraries", "venue": "international convention on information and communication technology electronics and microelectronics", "year": 2015, "id": "3b953035-b978-43ec-80b5-3c5ae397d64b"}
{"abstract": "Abstract#R##N##R##N#This paper examines a common design for a lexical analyser and its supporting modules. An implementation of the design was tuned to produce the best possible performance. In effect, many of the optimizations that one would expect of a production-quality compiler were carried out by hand. After measuring the cost of tokenizing two large programs with this version, the code was \u2018detuned\u2019 to remove specific optimizations and the measurements were repeated. In all cases, the basic algorithm was unchanged, so that the difference in cost is an indication of the effectiveness of the optimization. Comparisons were also made with a tool-generated lexical analyser for the same task. On the basis of the measurements, several specific design and optimization strategies are recommended. These recommendations are also valid for software other than lexical analysers.", "authors": ["William M. Waite"], "n_citation": 50, "references": ["0e99cc9a-805e-4070-923c-42954e012b9a", "54931be4-e926-46c6-9863-273ad8473d96", "79e46d07-465c-49d9-88de-6d508102015a", "bb54aa96-2cb1-4d59-9879-ee7848acc64b"], "title": "The cost of lexical analysis", "venue": "Software - Practice and Experience", "year": 1986, "id": "a3699b73-afc3-424b-b2eb-0375404de567"}
{"abstract": "Our study analyzes the security and privacy properties of an implantable cardioverter defibrillator (ICD). Introduced to the U.S. market in 2003, this model of ICD includes pacemaker technology and is designed to communicate wirelessly with a nearby external programmer in the 175 kHz frequency range. After partially reverse-engineering the ICD's communications protocol with an oscilloscope and a software radio, we implemented several software radio-based attacks that could compromise patient safety and patient privacy. Motivated by our desire to improve patient safety, and mindful of conventional trade-offs between security and power consumption for resource-constrained devices, we introduce three new zero-power defenses based on RF power harvesting. Two of these defenses are human-centric, bringing patients into the loop with respect to the security and privacy of their implantable medical devices (IMDs). Our contributions provide a scientific baseline for understanding the potential security and privacy risks of current and future IMDs, and introduce human-perceptible and zero-power mitigation techniques that address those risks. To the best of our knowledge, this paper is the first in our community to use general-purpose software radios to analyze and attack previously unknown radio communications protocols.", "authors": ["Daniel Halperin", "Thomas S. Heydt-Benjamin", "Benjamin Ransford", "Shane S. Clark", "Benessa Defend", "Will Morgan", "Kevin Fu", "Tadayoshi Kohno", "William H. Maisel"], "n_citation": 578, "references": ["021e2e04-3de1-440c-aeb3-5f5c907988e8", "0b868c0b-2b01-4732-abfb-06a8773783cb", "1067759f-2494-49db-a9b2-a529d429a942", "2791a7a5-ac7d-4b66-91fc-96dbafccbd7e", "28fa59f0-eca3-4c79-a2e8-2a60a9180b1c", "2f4736ce-ab9d-4fec-afc9-07e2292bd672", "3f170d4f-0ac1-47b8-9f16-44f1e3ab6793", "471b1d1f-c254-4ff5-a09e-3c2bff85d09d", "559fe4de-feb8-468c-91c3-84630c050710", "5a9cb89c-1bc1-437b-a734-bf1b2d3557d4", "69c141f2-09f7-46a8-a32e-d4ffccfc2df1", "75d65c88-da83-4528-9926-c6804842bae9", "8828d2f5-0b50-4715-863d-66c787fc40e0", "f7e81952-53a7-4e95-9da6-740cfcf27ced"], "title": "Pacemakers and Implantable Cardiac Defibrillators: Software Radio Attacks and Zero-Power Defenses", "venue": "ieee symposium on security and privacy", "year": 2008, "id": "9fcde8cf-0902-4814-8ebf-37b9e0fd85ad"}
{"abstract": "Besides a large set of malware categories such as worms and Trojan horses, Advanced Persistent Threat (APT) is another more sophisticated attack entity emerging in the cyber threats environment. In this paper we propose a model of the APT detection problem as well as a methodology to implement it on a generic organization network. From our knowledge, the proposed method is the first to address the problem of modeling an APT and to provide a possible detection framework.", "authors": ["Paul Giura", "Wei Wang"], "n_citation": 42, "references": ["1bea854d-3b0d-4f07-bcc5-a07c775b934a", "3f5d18f7-6039-42ba-9a26-85104f486cde"], "title": "A Context-Based Detection Framework for Advanced Persistent Threats", "venue": "", "year": 2012, "id": "07ee327d-4b4b-42e6-b3fd-e3d955365f02"}
{"abstract": "We present a semantic model for knowledge with the following properties: (1) Knowledge is necessarily correct, (2) agents are logically omniscient, i.e., they know all the consequences of their knowledge, and (3) agents are positively introspective, i.e., they are aware of their knowledge, but not negatively introspective, i.e., they may not be aware of their ignorance. We argue that this is the appropriate model for implicit knowledge. We investigate the properties of the model, and use it to formalize the notion of circumscribed knowledge.", "authors": ["Moshe Y. Vardi"], "n_citation": 34, "references": ["76076e32-17ea-492c-9824-e133b6853059", "82fc56b4-354a-49bd-ae40-fd985a7d4497", "b14e6a89-9b85-4869-a087-9d70acd19c96", "c7a3e3c8-1f58-4c6b-9bba-ba9ad85dff65", "f18e363f-7509-4396-8653-a0e0d4204f80", "f7c6a142-4bc4-43d8-8991-b9ad3677ecc8"], "title": "A model-theoretic analysis of monotonic knowledge", "venue": "international joint conference on artificial intelligence", "year": 1985, "id": "578a7964-9ede-41e3-8757-dff5092f0fe7"}
{"abstract": "A team performance model provided an organizing framework for studying multi-cultural distributed learning teams. Structural equation modeling was used to test for relationships among individual, cultural and attitudes about collaborative work factors and team performance. The paper describes this model and its theoretical basis and reports on results from two pilot projects involving 152 students from the US, Panama, UK, and Turkey. While the model shows satisfactory fit, the results suggest that other factors may also influence how well students work together on global software projects. Future research, followed by model development, should incorporate these factors to capture the complexity of the educational and training environments.", "authors": ["Kathleen M. Swigger", "Ferda Nur Aplaslan", "Victor Lopez", "Robert P. Brazile", "Geroge Dafoulas", "Fatma Cemile Serce"], "n_citation": 50, "references": ["2f2654e6-ba8a-4e61-8a51-c51c0042206d", "328ac34c-26e0-4c2f-bb4f-e474d14911c5", "5780eca9-1cf3-4126-9087-4701ace2c415", "6a83b9e7-5dc3-493d-b9a6-99fb12630788", "6e7590b9-074f-4734-b7fe-cbd67ef83541", "74c5a2c0-fc24-4ad7-8167-5c71a73101f2", "9f1e484b-0cb3-4201-903c-69ded3a145c4", "a3f56fda-15e6-4ff5-85c5-8e2f3f40c18c", "cf97384f-f0d8-42a3-a9d5-02e2efb50eb6", "e41c93b8-75b8-48b5-a5ad-5c2833f7cd0d", "ea604508-9874-4c13-8190-b7b5201f8559", "ee7ee300-8f33-44e7-9ac9-2aad8031f599"], "title": "Structural factors that affect global software development learning team performance", "venue": "", "year": 2009, "id": "947ba7b9-4a98-4c3a-9e96-92d676ac0b1c"}
{"abstract": "We define a class of diagrams that represent abstractions of--possibly infinite-state--reactive systems described by specifications written in temporal logic. Our diagrams are intended as the basis for the verification of both safety and liveness properties of such systems. Non-temporal proof obligations establish the correspondence between the original specification and the diagram, whereas model checking can be used to verify properties over finite-state abstractions. We describe the use of abstract interpretation techniques to generate proof diagrams from a given specification and user-defined predicates that represent sets of states.", "authors": ["Dominique Cansell", "Dominique M\u00e9ry", "Stephan Merz"], "n_citation": 50, "references": ["12b4acbf-a124-4e03-bc5e-21cd6dbd7464", "18427a97-5bc3-4afe-9a96-769ea0982a65", "229ae5f9-b5b9-4f63-ae80-4e9f190a16ba", "2376c562-2d9e-4768-931b-7e467d885d14", "3023929a-c93e-49c5-b03f-7fb0414d94df", "31ba104f-9f79-4a2e-88ae-a0685728f8ea", "35c48ff7-9be2-4924-b178-75fda2abfaba", "6527f747-563e-4e5f-b9a1-44ea23adbf26", "6f6be8e6-abe7-4a7e-a9e2-ebabfb7eb675", "814db3f7-9e89-4943-8486-cbd569afd0eb", "860e01c7-adb6-461e-b0d3-81a51191a1bf", "889d28a8-9e43-4b14-9817-9443a69cbe26", "8ca31a79-cc09-4cef-b784-b73feed2199f", "9412e1a5-127d-450b-954f-8507eaada3d6", "9c67cfcf-d2ad-4c84-af82-6cb0fa785fd1", "c19b56b1-433d-43fc-aaa4-1892624b09ff", "d02e1976-4f84-455a-9b9d-fda2df5b259f", "ecbaeced-0a5e-435a-9a34-c7d0a25412a4", "ed28d1f9-71c3-4f71-8518-27fae869f6a7"], "title": "Predicate Diagrams for the Verification of Reactive Systems", "venue": "integrated formal methods", "year": 2000, "id": "f290ef1a-d296-48a9-ad3c-87789c52fe1f"}
{"abstract": "Improving productivity of practitioners through effective knowledge management and delivering high quality service in Application Management Services (AMS) domain, are key focus areas for all IT services organizations. One source of historical knowledge in AMS is the large amount of resolved problem ticket data which are often confidential, immensely valuable, but majority of it is of very bad quality. In this paper, we present a knowledge management tool that detects the quality of information present in problem tickets and enables effective knowledge search in tickets by prioritizing quality data in the search ranking. The tool facilitates leveraging of knowledge across different AMS accounts, while preserving data privacy, by masking client confidential information. It also extracts several relevant entities contained in the noisy unstructured text entered in the tickets and presents them to the users. We present several experimental evaluations and a pilot study conducted with an AMS account which show that our tool is effective and leads to substantial improvement in productivity of the practitioners.", "authors": ["Debapriyo Majumdar", "Rose Catherine", "Shajith Ikbal", "Karthik Visweswariah"], "n_citation": 50, "references": ["296919c6-c5b6-4a49-baac-ae6c111b2ff2", "321cb20e-b1da-4c79-96be-409e7c9bbb68", "336863f4-7074-4457-9e3b-2c5cb399fe07", "519087b9-ce8a-455f-a5ca-c8de3087ba4d", "6187110d-0de8-435f-845a-cd0270aa7bc8", "8cfd5c55-a5bd-493d-a23c-491239007e23", "9402965d-aa0d-47a8-a6f0-5dbdf4d5d70d", "9c3eabd3-3573-41b9-b1f1-de39a6e585a9", "ae782312-917f-417e-9440-53c3ed8599f9", "af930219-44f3-4c90-967c-c4c53cd54ce4", "b06392f5-f254-48d4-93b7-a3c2931c01a5", "cfbfc72d-ace6-4b3c-9960-da8128b2a0e9", "ec115dba-62a8-45da-8df7-b41d4bf7cc9e", "ec9b9999-8b4f-441d-af6d-418b9bafb127"], "title": "Privacy protected knowledge management in services with emphasis on quality data", "venue": "conference on information and knowledge management", "year": 2011, "id": "bb3a1c8b-e9e6-4445-ac04-d7f27ccfbeb4"}
{"abstract": "A self-stabilizing system is a system such that it autonomously converges to a legitimate system state, regardless of the initial system state. The local mutual exclusion problem is the problem of guaranteeing that no two processes neighboring each other execute their critical sections at a time. The process identifiers are said to be chromatic if no two processes neighboring each other have the same identifiers. Under the assumption that the process identifiers are chromatic, this paper proposes two self-stabilizing local mutual exclusion algorithms; one assumes a tree as the topology of communication network and requires 3 states per process, while the other which works on any communication network, requires n + 1 states per process, where n is the number of processes in the system. We also show that the process identifiers being chromatic is close to necessary for a system to have a self-stabilizing local mutual exclusion algorithm. We adopt the shared memory model for communication and the unfair distributed daemon for process scheduling.", "authors": ["Hirotsugu Kakugawa", "Masafumi Yamashita"], "n_citation": 50, "references": ["0b51ede8-1daf-41a6-93f1-96af5b037f62", "136c4780-2f25-4068-90a5-aed6afaf2890", "324fd565-acdf-4e67-9bc6-b39a6061e875", "33de8856-0b19-450b-b18c-c38288e941ec", "377b7e70-6787-4cb4-8059-7ccfc8bee1ae", "43cdc5a0-cefc-403e-9949-59f653aee0db", "59055d1c-3328-4241-abc1-a3066c08d1c9", "832e4aad-b714-494e-b719-eee203abd5fe", "9d61e126-27cd-41f7-b41f-c37c98cca20e", "9fd50a0b-7a42-4827-9cbe-59378c0627b6", "d2ab4e80-e9b0-4f10-a29e-3f14eafde254"], "title": "Self-stabilizing local mutual exclusion on networks in which process identifiers are not distinct", "venue": "symposium on reliable distributed systems", "year": 2002, "id": "ddef3b2a-06b5-4183-a737-9f58817b9216"}
{"abstract": "Agent-based application development must face the issues related to the interactions among agents. In fact, their sociality allows decomposing large applications into collaborating agents, while open environments, such as the Internet, require agents belonging to different applications to compete to gain resources. In the BRAIN framework, interactions among agents are fruitfully modeled and implemented on the basis of roles. This approach achieves several advantages, from separation of concerns between the algorithmic issues and the interaction issues, to the reuse of solutions and experiences in different applications. In this paper we propose a mechanism to enable Java agents to dynamically assume roles at runtime. Our approach is based on the modification of the bytecode of Java agents, in order to implement an appropriate interface and to add the related methods. An application example and the comparison with other approaches show the effectiveness of our approach.", "authors": ["Giacomo Cabri", "Luca Ferrari", "Letizia Leonardi"], "n_citation": 38, "references": ["1a70170c-e012-4ac5-a774-0247fe3f4b5b", "323f6994-34e2-4852-98f0-13036fae4f06", "3a32d085-0fa6-4867-8c36-d89465a8b507", "43a1ebbf-dcb1-4d52-bde3-9dedc4b69950", "6a0424eb-5ed7-4eef-8dea-bae780912ba0", "98822fec-f3b1-4a17-92e3-1fcc9e83a5aa"], "title": "Enabling mobile agents to dynamically assume roles", "venue": "acm symposium on applied computing", "year": 2003, "id": "55858202-dda9-479b-9a10-2d9e8ed02b3a"}
{"abstract": "In this paper, we present a suboptimal and analytical solution to the trajectory generation of mobile robots operating in a dynamic environment with moving obstacles. The proposed solution explicitly addresses both the robot kinodynamic constraints and the geometric constraints due to obstacles while ensuring the suboptimal performance to a combined performance metric. In particular, the proposed design is based on a family of parameterized trajectories, which provides a unified way to embed the kinodynamic constraints, geometric constraints, and performance index into a set of parameterized constraint equations. To that end, the suboptimal solution to the constrained optimization problem can be analytically obtained. The solvability conditions to the constraint equations are explicitly established, and the proposed solution enhances the methodologies of real-time path planning for mobile robots with kinodynamic constraints. Both the simulation and experiment results verify the effectiveness of the proposed method.", "authors": ["Jun Peng", "Wenhao Luo", "Weirong Liu", "Wentao Yu", "Jing Wang"], "n_citation": 9, "references": ["054d13c6-bcf8-4c7a-a6d0-aa9b5c5e3d13", "0e732551-ed47-4035-8293-f168844e2b7a", "0fd4bd2d-560e-4337-9cca-812805034c73", "10abf4d5-f755-4190-be36-b98c2d77ba5d", "38c98479-76d3-48e9-899a-ee65188760d0", "3a33bfa6-ec22-448c-bad2-0acd1c6b2724", "42e2a897-2271-48b2-a09b-5e043c4d6328", "4773f1f0-89a2-4cd1-849a-6f2925f0cccb", "4bb271f5-733e-4d34-af24-fdc5ea732545", "5396dec2-beba-4a1b-829f-5769dfa91ccf", "541c8559-6ee9-43df-a541-c489993d2248", "5ad5a989-d840-4343-ab09-094956a1dbaa", "6383b843-4f43-41cc-a80c-c4f5cae37bb0", "743e337d-dfda-478b-8944-b3dbb888e02b", "7f66c795-3881-48db-8ec4-1f3f7c1f7f27", "8caddb88-2869-43c2-a256-ab907d6b4bac", "94a7718f-252e-4fbf-bf0b-ad232892d30d", "9ba42fd5-5a71-4b57-8bd0-3aa7b28cf488", "9d0a8f45-233a-48a6-8ac9-670e99fa473e", "b160a5aa-ea97-40b7-a848-55e06675377a", "b7a1e2b6-9c1a-4870-b273-f8fff6c6baaf", "c5571a17-ce09-4db8-b163-23526965df18", "c7bdaccf-caf8-4a6b-8284-f7cee97a9b59", "ca136702-f5c2-4fe2-a4c8-74ee7bd2c8fb", "d122fecb-0de6-4949-91d2-622b685c7c60", "de1ce8a0-bbd9-4edf-a337-30c4d4fcfd76", "df2fbb26-fd13-404d-8d06-30125d763f77", "e08ebfd7-35ce-4124-979f-7cd990d88e53", "e25250b4-14ea-4e5c-b596-40eb78ad36a7", "f15eb577-68ba-4d2e-9322-951f3663ebf9", "f2b937eb-4f85-49a3-af07-d59e5fa1772c", "f30ee4a6-44e5-4d8e-afa1-aacc586aa544"], "title": "A suboptimal and analytical solution to mobile robot trajectory generation amidst moving obstacles", "venue": "Autonomous Robots", "year": 2015, "id": "c82bf49c-8fc2-4119-b131-d37b8d0424e8"}
{"abstract": "In subspace identification methods, the system matrices are usually estimated by least squares, based on estimated Kalman filter state sequences and the observed inputs and outputs. For a finite number of data points, the estimated system matrix is not guaranteed to be stable, even when the true linear system is known to be stable. In this paper, stability is imposed by using regularization. The regularization term used here is the trace of a matrix which involves the dynamical system matrix and a positive (semi) definite weighting matrix. The amount of regularization can be determined from a generalized eigenvalue problem. The data augmentation method of Chui and Maciejowski (1996) is obtained by using specific choices for the weighting matrix in the regularization term.", "authors": ["T. Van Gestel", "J.A.K. Suykens", "P. Van Dooren", "B. De Moor"], "n_citation": 86, "references": ["1459f91e-91c3-4b4e-8322-c4409c8692f5", "948a791e-a967-4cda-97b9-09f9c00eacfc", "ab268563-2131-4d93-b1d7-ba81e10f7b9c", "fa49498a-b557-4a7a-8b88-710d97ef322d"], "title": "Identification of stable models in subspace identification by using regularization", "venue": "IEEE Transactions on Automatic Control", "year": 2001, "id": "20342deb-7b97-4e10-a0a8-8790cbbec1dd"}
{"abstract": "Smart cities have become a reality around the world. They rely on wireless communication technologies, and they have provided many benefits to society, such as monitoring road traffic in real-time, giving continuous healthcare assistance to residents and managing the environment. This article revisits key interoperability questions in heterogeneous wireless networks for smart cities, and outlines a simple, modular architecture to deal with these complex issues. The architecture is composed by sensing, access network, Internet/cloud and application layers. Different features provided by the architecture, such as interoperability among technologies, low cost, reliability and security, have been evaluated through experiments and simulations under different scenarios. The QoS support and the seamless connectivity between pairs of heterogeneous technologies are proposed through a policy-based management (PBM) framework and MIH (Media Independent Handover). Moreover, an 802.11 mesh backbone composed of different types of mesh routers has been deployed for interconnecting the sensors and actuators to the Internet. Key results from experiments in the backbone are examined. They compare: (i) the performance of a single-path routing protocol (OLSR) with a multipath one (MP-OLSR); (ii) the monitoring delays from the proposed low cost sunspot/mesh and arduino/mesh gateways; and (iii) the authentication mechanisms employed. Significant results from simulations allow the analysis of the reliability on vehicular/mesh networks under jamming attacks by applying the OLSR and MP-OLSR routing protocols. Finally, this article provides an overview of open research questions.", "authors": ["Edson Avelar", "Lorena Marques", "Diego dos Passos", "Ricardo Macedo", "Kelvin Lopes Dias", "Michele Nogueira"], "n_citation": 16, "references": ["1713b1be-aeb9-46dd-bc26-fb91929375f4", "3c006851-7099-408b-9151-9381e62f9232", "5a0af513-37ae-4e61-90d3-2f2dd3832d27", "78d57cdc-1d89-421b-b676-a425911bd6b9", "7ba87567-f971-4a12-91e7-c4052f6cbe4c", "98cdf078-b19f-4e84-b98b-92b29513aea7", "a705ba1f-de64-4289-87c1-74656f257e99", "b562bf98-9a5e-43b1-b3f3-4224275295f9", "c8931e1a-2eac-417d-ac70-9db96c0d23ed", "d7b9440d-01cd-4eb1-bb46-a2f7008d6522", "dc9a3b71-8925-4e32-b0ef-ee8dd8ff1016", "e7f7192e-6e37-4bd3-b84d-72b2175c1a32"], "title": "Interoperability issues on heterogeneous wireless communication for smart cities", "venue": "Computer Communications", "year": 2015, "id": "2d102fec-6eaf-4f15-9b47-bd321d614bad"}
{"abstract": "Programs written for GPUs often contain correctness errors such as races, deadlocks, or may compute the wrong result. Existing debugging tools often miss these errors because of their limited input-space and execution-space exploration. Existing tools based on conservative static analysis or conservative modeling of SIMD concurrency generate false alarms resulting in wasted bug-hunting. They also often do not target performance bugs (non-coalesced memory accesses, memory bank conflicts, and divergent warps). We provide a new framework called GKLEE that can analyze C++ GPU programs, locating the aforesaid correctness and performance bugs. For these programs, GKLEE can also automatically generate tests that provide high coverage. These tests serve as concrete witnesses for every reported bug. They can also be used for downstream debugging, for example to test the kernel on the actual hardware. We describe the architecture of GKLEE, its symbolic virtual machine model, and describe previously unknown bugs and performance issues that it detected on commercial SDK kernels. We describe GKLEE's test-case reduction heuristics, and the resulting scalability improvement for a given coverage target.", "authors": ["Guodong Li", "Peng Li", "Geoffrey Sawaya", "Ganesh Gopalakrishnan", "Indradeep Ghosh", "Sreeranga P. Rajan"], "n_citation": 94, "references": ["33c32b5c-ee15-4346-a135-e67478b93b11", "3bbea262-f8ec-416b-b065-5fcbbeaa86e4", "4737d508-2cee-4877-aeb6-531a26fb5cba", "48eef517-5370-4176-a42c-9e5c0bd7d729", "4a0d2b54-7662-46f6-923b-b1f5839eadc7", "4b8fdc3f-148a-4f4b-a45f-7cc11ba7a2cb", "4e9bb45b-db66-4370-a86b-e718b3ae4bdb", "6c51278a-7dcf-4d23-9b40-c91d0d4619ac", "71c47dd0-a7ff-4b97-a640-1186dd9ac968", "9353512f-fdd2-4d0c-b237-86798657d977", "a6e2c70d-0585-4f13-8f28-45831696af3e", "ad42beba-7e29-4168-8b9a-523bd7ff1f2c", "f28cee2f-5391-45ed-8d1a-125feb7b02dd", "f9a8f31f-dae4-4556-ac2e-f53a91992e5d"], "title": "GKLEE: concolic verification and test generation for GPUs", "venue": "acm sigplan symposium on principles and practice of parallel programming", "year": 2012, "id": "dbe6b071-f42f-4231-acc4-afdb36c56f3d"}
{"abstract": "When several applications are co-scheduled to run on a system with multiple shared LLCs, there is opportunity to improve system performance. This opportunity can be exploited by the hardware, software, or a combination of both hardware and software. The software, i.e., an operating system or hypervisor, can improve system performance by co-scheduling jobs on LLCs to minimize shared cache contention. The hardware can improve system throughput through better replacement policies by allocating more cache resources to applications that benefit from the cache and less to those applications that do not. This study presents a detailed analysis on the interactions between intelligent scheduling and smart cache replacement policies. We find that smart cache replacement reduces the burden on software to provide intelligent scheduling decisions. However, under smart cache replacement, there is still room to improve performance from better application co-scheduling. We find that co-scheduling decisions are a function of the underlying LLC replacement policy. We propose Cache Replacement and Utility-aware Scheduling (CRUISE)-a hardware/software co-designed approach for shared cache management. For 4-core and 8-core CMPs, we find that CRUISE approaches the performance of an ideal job co-scheduling policy under different LLC replacement policies.", "authors": ["Aamer Jaleel", "Hashem Hashemi Najaf-abadi", "Samantika Subramaniam", "C Simon Steely", "Joel S. Emer"], "n_citation": 75, "references": ["07beac95-06c8-4578-bc5a-571b5f9dc9d3", "08f93e66-54ba-4cd1-9224-730024fe01b0", "0ee52d92-42d1-484e-8087-1b2f68bb0e6d", "11317b62-c333-4ae2-8faa-fa5d1322bf76", "20d28824-b9e3-4ab2-a7e4-9b3c4ac9a5f4", "214ecd41-08ba-47dc-95a4-34865686f5f9", "361c3a64-526a-406b-8d96-aff900ac6b77", "4a9b1e34-dd25-47ca-931b-801cb5447816", "53c4e067-cfe1-4600-8aa0-6930e61ee1e5", "5a7fcc5f-7614-41ce-9f3d-5e64185edfd1", "5bc4eaba-3dbd-4725-b41c-ad6819e5f7ea", "5ffa6899-57db-4179-a41b-b5d3f4c7ca9a", "7239ebbd-4b5d-4aac-80ff-ce1d64c7bad9", "72d330ab-f081-423d-8736-b8c4a983e3b2", "8012e407-ad3c-4319-b550-50a73533b17b", "824bdcf9-0415-4d86-b93f-3789fd2d053c", "83d171e6-d6bf-4b2e-8b14-1c0eb8b069ab", "a0cfbea4-310b-4762-a451-6b8b58391e4e", "a4b592d3-91d5-4451-a00f-741eb0c6d2f4", "a9afc4a6-3209-4bb7-af95-8240471af883", "b219795c-bc95-4c9e-9407-c0cc79bbae2a", "b63d9b77-f545-45d7-b0e6-c70a53953534", "b9a9d962-dbcc-4776-af6d-25f7d2b313d6", "bc766aff-a67c-4e04-aaa3-a4392fd73cb8", "c2dc4b00-fb1f-4c3e-b9f4-addd7ca807b3", "c7967aba-9e39-4f16-bc70-90f11c61a3ea", "d8f965a8-74d7-4fcd-8567-1d3b37c25f6b", "da43feb2-93cd-44f7-a7e8-a74dffab0c65", "e796ecf5-3ebc-4ec1-8be5-8aefa589ba6d", "ed0ac60f-0239-4610-a34b-b6933d5d2d9d"], "title": "CRUISE: cache replacement and utility-aware scheduling", "venue": "architectural support for programming languages and operating systems", "year": 2012, "id": "01141621-161a-410a-84d8-640b109fecdb"}
{"abstract": "Let n be an odd integer. Take a random number a from a uniform distribution on the set $\\{1, 2,\\cdots, n -1\\}$. If a and n are relatively prime, compute the residue $\\varepsilon \\equiv a^{(n - 1)/2}(\\bmod n)$, where $ - 1 \\leqq \\varepsilon   1$ or $\\varepsilon \\ne \\delta $ decide that n is composite. Obviously, if n is prime, the decision made will be correct. We will show below, that for composite n the probability of an incorrect decision is $\\leqq 1 / 2$. The number of multiprecision operations needed for the whole procedure is $< 6\\log _2 n$. m-fold repetition using independent random numbers yields a Monte-Carlo test for primality with error probabilities 0 (if n is prime) and $< 2^{-m}$(if n is composite) and with multiprecision arithmetic cost $< 6m\\log _2 n$.", "authors": ["Robert M. Solovay", "Volker Strassen"], "n_citation": 646, "title": "A Fast Monte-Carlo Test for Primality", "venue": "SIAM Journal on Computing", "year": 1977, "id": "011d7883-14a9-438c-98af-df7374058a85"}
{"abstract": "Product design review is one of the typical scenarios of collaborative product development. We developed a Web-based prototype framework for supporting collaborative tele-product design review on the Internet. It provides a suite of tools to establish and manage the new product design review process. The paper discusses the issues related to the development and implementation of Web applications in prototype implication. The typical 3-tier architecture is explained to show how the CyberReview components work together to achieve the intended functionality. VRML EAI and Java Applet-Servlet pair technology was included to support the implication.", "authors": ["George Q. Huang", "Kai-Ling Mak", "Jy Shen", "J. Q. Yan"], "n_citation": 50, "references": ["f55d0070-336b-496b-9fbd-893e370e78d6"], "title": "Web-based product design review: implementation perspective", "venue": "computer supported cooperative work in design", "year": 2001, "id": "7b43b910-a7d6-41d2-a578-d3380435f9b9"}
{"abstract": "In the years since 1969, the study of computer systems has assumed a role nearly equal in importance to \"theory of computation\" and \"programming\" in computer science curricula. In contrast, computer systems was regarded as recently as 1965 as being inferior in importance to these two more traditional areas of study. This is a significant change in attitude. The harbingers of the change appear in ACM's Curriculum 68, and the speed of its development is demonstrated in the report of Task Force VIII of the COSINE (Computer Science in Electrical Engineering) committee of the Commission on Education of the National Academy of Engineering, entitled \"An Undergraduate Course on Operating Systems Principles.\"", "authors": ["Peter J. Denning"], "n_citation": 50, "references": ["12b22eb8-81ed-458e-8ba1-0889e3531626", "44d4e356-f0d6-4455-becd-12ccea0d04e3", "507f5bb5-796f-4eac-a447-224dcbbae973", "88264db1-55f4-4db2-9746-56ff6c176e6a", "93705fd6-781e-493f-ada5-6b657281182c", "d6e42fea-970e-4833-bb4c-1687ced46433", "da0ee408-11e7-4b2b-8cae-f062ef46d0ca", "ebbbd463-9d05-411b-8c8a-d195896469ec", "fa0b4274-c58c-464c-9e29-dc87e62b414f"], "title": "Operating systems principles and undergraduate computer science curricula", "venue": "", "year": 1972, "id": "b253ba16-2a82-485d-bb93-1562e5b49f01"}
{"abstract": "With the advent of new, low-cost 3D sensing hardware such as the Kinect, and continued efforts in advanced point cloud processing, 3D perception gains more and more importance in robotics, as well as other fields. In this paper we present one of our most recent initiatives in the areas of point cloud perception: PCL (Point Cloud Library - http://pointclouds.org). PCL presents an advanced and extensive approach to the subject of 3D perception, and it's meant to provide support for all the common 3D building blocks that applications need. The library contains state-of-the art algorithms for: filtering, feature estimation, surface reconstruction, registration, model fitting and segmentation. PCL is supported by an international community of robotics and perception researchers. We provide a brief walkthrough of PCL including its algorithmic capabilities and implementation strategies.", "authors": ["Radu Bogdan Rusu", "Steve B. Cousins"], "n_citation": 2410, "references": ["4147dff4-b781-4cdc-8ea7-4c8bb49b1d60", "66bd7646-e537-4733-8313-2d101136ade0", "7c0d483a-ab6e-473f-9904-4a717bf7ce08", "d3b1d34a-eaf1-4272-a9de-0c07d09fd99d", "d9ae2f3c-0f6a-4ff3-87f2-0a02300a7db1", "ebfca554-7a3c-4597-954b-07336a2e3030"], "title": "3D is here: Point Cloud Library (PCL)", "venue": "international conference on robotics and automation", "year": 2011, "id": "bf2388db-f4a7-4300-a222-338b3d419613"}
{"abstract": "A computer program is described that is capable of learning multiple concepts and their structural descriptions from observations of examples. It decomposes this conceptual clustering problem into two modules. The first module is concerned with forming a generalization from a pair of examples by extracting their common structure and calculating an information measure for each structural description. The second module, which is the subject of this paper, incrementally incorporates these generalizations into a hierarchy of concepts. This second module operates without reference to any underlying representation language and utilizes only the information measure provided by the first module, while employing a branch and bound procedure to search the hierarchy for concepts from which to form new clusters. This ability to search the hierarchy is used as the basis of a hill climbing strategy which has as its goal the avoidance of local peaks so as to reduce the sensitivity of the program to the order in which the observations are encountered.", "authors": ["Arthur J. Nevins"], "n_citation": 50, "references": ["10d1429b-2469-4165-bc90-62b23c5621f6", "171007d3-32d5-4177-b78a-84a4752aa130", "54d4fa52-1ff2-4bad-860f-a014766a673d", "7288ab5c-4638-4285-9c64-65896e680cf5", "76f221bf-6a1c-449f-b365-e6d5a2feff67", "7ef1ce39-67af-4dae-bab2-dacca7168a84", "8225a69d-2fa5-4196-836d-a1a407343077", "842315df-b707-445d-ab87-5804bbabadce", "8f9b43a0-1ead-4809-bca2-fcd02cd879c4", "bea7a43c-c6ad-4876-9a9b-f12704074aa8", "c9d7e50e-26d6-41f1-aa09-f49fc546af36", "cb9c1034-a9b3-4191-9d34-052ab2d82389", "cf9e147b-c9cb-46cd-80b5-e004a55e356f", "d4d4286f-609d-42cb-a3a5-47f057ff4a7e"], "title": "A Branch and Bound Incremental Conceptual Clusterer", "venue": "Machine Learning", "year": 1995, "id": "0f9ecc62-8c0b-49a6-a8c9-223bcec3cc21"}
{"abstract": "1 Introduction to SQL-92 2 Getting Started with SQL-92 3 Basic Table Creation and Data Manipulation 4 Basic Data Definition Language (DDL) 5 Values, Basic Functions, and Expressions 6 Advanced Value Expressions: CASE, CAST, and Row Value Expressions 7 Predicates 8 Working with Multiple Tables: The Relational Operators 9 Advanced SQL Query Expressions 10 Constraints, Assertions, and Referential Integrity 11 Accessing SQL from the Real World 12 Cursors 13 Privileges, Users, and Security 14 Transaction Management 15 Connections and Remote Database Access 16 DYNAMIC SQL 17 Diagnostics and Error Management 18 Internationalization Aspects of SQL-92 19 Information Schema 20 A Look to the Future A Designing SQL-92 Databases B A Complete SQL-92 Example C The SQL-92 Annexes: Differences, Implementation-Defined and Implementation-Dependent Features, Deprecated Features, and Leveling D Relevant Standards Bodies E Status Codes F The SQL Standardization Process G The Complete SQL-92 Language", "authors": ["Jim Melton", "Alan R. Simon"], "n_citation": 478, "title": "Understanding the new SQL: a complete guide", "venue": "", "year": 1993, "id": "9505b840-176e-488a-bbfc-e488442e45e8"}
{"abstract": "Minimum-norm control laws for hybrid dynamical systems are proposed. Hybrid systems are given by differential equations capturing the continuous dynamics or flows, and by difference equations capturing the discrete dynamics or jumps. The proposed control laws are defined as the pointwise minimum norm selection from the set of inputs guaranteeing a decrease of a control Lyapunov function. The cases of individual and common inputs during flows and jumps, as well as when inputs enter through one of the system dynamics, are considered. Examples illustrate the results.", "authors": ["Ricardo G. Sanfelice"], "n_citation": 2, "references": ["17afbebf-a1ac-448f-b163-e963f5b14265", "49e3eeb7-9f3e-40c4-89c5-ca76cd8fac3e", "64e8ca5a-9c99-4d89-9099-645c981ec409", "9727fdf7-b879-4bfd-ab43-f17d6e13b4b0"], "title": "Pointwise minimum norm control laws for hybrid systems", "venue": "conference on decision and control", "year": 2013, "id": "b9ec3d15-61c5-4bec-8e2f-de2f66fd3ab9"}
{"authors": ["Kouichi Itoh", "Tetsuya Izu", "Masahiko Takenaka"], "n_citation": 28, "references": ["01d0b8a2-cd17-4455-a3fb-46ac6d221686", "033ebb72-0119-4cc9-89b8-f011c55ddd79", "0650e057-590b-4e80-9e07-1198cfbc32a4", "1ee05b30-e1fe-48c8-8dbb-d6a4cb40b52a", "20a7c4f6-c544-4072-abaf-d8d11a9cfd7f", "54da8c72-271a-43c0-953c-3c934feb3a05", "552a0af8-f7ce-45dc-93a8-9e5e196e6eb8", "59c06aea-b5a8-4cba-9c58-7601b7c0be49", "630eb0f2-48ef-40c9-905b-a937b178948e", "64463ebf-427f-4eaf-81b6-107aef94d558", "65d9b4ab-ea74-4101-afae-6898690e901a", "6d1d6b6d-908a-4a6a-bfc1-d2f6ddc1107d", "76718777-acb5-4fb6-bb41-9fa1a35c75d5", "785200d9-0b9c-44cc-85a5-341cf7afcbca", "885a1895-bd72-48da-9eca-89aeaea03100", "8c17bb77-acd1-4d0e-82a3-47e453ee50c2", "a58f21b0-93de-4a83-a4b5-78df7e27a993", "a9b73d0b-4189-4851-9ff9-ae3078044f6b", "b1cb4bf6-388e-4ca6-a78e-15f2d2d8c69d", "b2146048-0c66-4dc9-b9de-cb386c3140ab", "c5920c8a-ace1-48a2-bf68-67f3c6d41512", "c714fe77-7438-4917-8d45-b61b09ecfca8", "dce32b6a-544c-4cb6-8940-feb6bc325b35", "ef3aa116-f725-40bd-88a1-36a050426ae8", "f2d4e89e-e973-4259-94ec-a3beac9c42c3", "f4decfe0-e455-48ee-a649-b974e061386a"], "title": "Efficient Countermeasures Against Power Analysis for Elliptic Curve Cryptosystems", "venue": "smart card research and advanced application conference", "year": 2004, "id": "3da07f27-9c7d-4cf3-99aa-3b62d5e1c5e3"}
{"abstract": "Recent work on mid-level visual representations aims to capture information at the level of complexity higher than typical \"visual words\", but lower than full-blown semantic objects. Several approaches [5,6,12,23] have been proposed to discover mid-level visual elements, that are both 1) representative, i.e., frequently occurring within a visual dataset, and 2) visually discriminative. However, the current approaches are rather ad hoc and difficult to analyze and evaluate. In this work, we pose visual element discovery as discriminative mode seeking, drawing connections to the the well-known and well-studied mean-shift algorithm [2, 1, 4, 8]. Given a weakly-labeled image collection, our method discovers visually-coherent patch clusters that are maximally discriminative with respect to the labels. One advantage of our formulation is that it requires only a single pass through the data. We also propose the Purity-Coverage plot as a principled way of experimentally analyzing and evaluating different visual discovery approaches, and compare our method against prior work on the Paris Street View dataset of [5]. We also evaluate our method on the task of scene classification, demonstrating state-of-the-art performance on the MIT Scene-67 dataset.", "authors": ["Carl Doersch", "Abhinav Gupta", "Alexei A. Efros"], "n_citation": 206, "references": ["08106dfa-c3d7-47d4-a784-4c4d6736b50a", "0d25593e-6f5c-4c13-9714-1b7c0bea1492", "133a3ea8-d872-49bb-be06-6aa9cd84a614", "2868fc0e-e80c-435b-b9a1-a8bf7a9628ee", "359929be-eb5b-43e6-b815-85ff151f99c4", "37c5104a-63b7-4864-bd6c-c3f09da44f54", "3cf43ae0-4f85-460e-b141-368027c853d3", "440e15b8-57ee-4ad8-850d-ac0c9a16ddb7", "50f87fcb-dade-4c29-b919-8ab0214dcb71", "6ff80af3-a02c-44f1-8a1c-64bad28a1927", "78a7e13c-0840-4954-8e16-60ccfb410442", "7c3f444f-8c22-4780-aeac-01b711ecb77a", "88514745-f903-4187-8267-f1d24743461a", "9272fb14-2dab-4c5c-b2b1-0a72662d6a7b", "aaf4caeb-f428-4ac1-bfe1-67854b87d5f9", "b19bafa8-1ea3-4f23-b861-ffc43b0915ca", "b29cb808-1f59-40e9-8afa-26a3701b6284", "bb978087-d01a-4aa3-a8e5-500cf7a863a0", "d4096c82-a4ad-41c8-a3c6-4aa2924dfcbb", "db807124-0169-4fdf-83b7-3157739d2c07", "e2f7a74a-8430-4463-94ce-fe85dfd309f9", "e5f5cacc-f6da-458e-b8cb-bcfbd753e611", "eadac557-e7f8-43f5-9b59-f89376a15699", "efac2ac3-7d5c-4ffe-ab1e-91b38beb116a", "f592195b-ced2-408d-a5c0-86a57aba9947"], "title": "Mid-level Visual Element Discovery as Discriminative Mode Seeking", "venue": "neural information processing systems", "year": 2013, "id": "42df4133-3d89-43bf-a44b-a6cb57281151"}
{"authors": ["Howard Foster", "Sebastian Uchitel", "Jeff Magee", "Jeff Kramer"], "n_citation": 50, "references": ["016741e1-ac0e-4ebc-bdc9-66e0a98319f2", "3023929a-c93e-49c5-b03f-7fb0414d94df", "357c20e7-3c6f-439a-8123-eac44a6f15ca", "35f43c7b-a3ed-4dec-b519-0137daf11936", "3afb1209-0598-435f-a3e7-e4729eb4ce85", "4e2d669f-c76a-4ba0-a804-138dcbb73d0f", "4f3e7b6d-39a0-4524-b88e-f7f2b189c1a3", "5bb50329-29c2-45aa-80cd-b6c0b22aab37", "65503256-2b72-4968-b90f-3784ff3cba37", "6d24f8ff-0f85-4474-b955-e60c0bdf6775", "91bd5bed-21b6-4344-a446-917b483f5827", "a81d0708-bf4a-43da-ae46-6449059ebd2d", "ac88da07-ade7-40cb-9e6c-b6667525c09a", "c412a8dd-bd51-4772-8ada-61c3f3fd96fb", "d2bac31c-df3e-465c-916f-7d2961b68acf", "d47c7ca7-d286-4967-a9ad-475da9e23908", "dcee2770-50ff-4823-9df8-e877ce3d7ab2", "e38bfd6d-5357-4f1c-95fd-62d7e725a858", "ec01733d-273e-498a-95d6-f90a8af2ca85"], "title": "WS-Engineer: A Model-Based Approach to Engineering Web Service Compositions and Choreography", "venue": "", "year": 2007, "id": "1ff66569-3c6c-4f34-8b68-d9e8162a9261"}
{"abstract": "The first international worst-case execution time (WCET) Tool Challenge in 2006 used benchmark programs to evaluate academic and commercial WCET tools. It aimed to study the state-of-the-art in WCET analysis. The WCET Tool Challenge comprised two parallel evaluation approaches: an internal evaluation by the respective tool developers and an external test by a neutral person of an independent institute. The latter was conducted by the author of this paper. Focusing on the external test, we describe the rules, benchmarks, participants and discuss the obtained results.", "authors": ["Lili Tan"], "n_citation": 11, "references": ["0a14a4e0-62ce-49f7-8864-738e957728d7", "0d261b6a-c94a-4d5e-b44e-eb6ae46581fc", "373c470a-32a1-43df-b2cd-94e35c428df5", "b10d7317-f68a-4b03-b302-53fdaf4ed970", "da980a7a-fdbf-479b-beda-bf7b2040e22a", "f092cad5-bc21-4aa5-b2b5-691473ac3a76"], "title": "The worst-case execution time tool challenge 2006", "venue": "International Journal on Software Tools for Technology Transfer", "year": 2009, "id": "e0d86f20-61db-4e64-8161-4a84a6e7777a"}
{"abstract": "Abstract   The Distributed Interactive Virtual Environment (DIVE) is an experimental software platform for the development of multi-user virtual reality applications. DIVE uses active replication and reliable multicast protocols to distribute data between participants. The distribution model enables a large number of users and applications to participate and interact in the same virtual environment. The DIVE platform offers a wide range of interaction support and user-related abstractions to ease the task of application and user interface construction.", "authors": ["Christer Carlsson", "Olof Hagsand"], "n_citation": 412, "references": ["3c6b31ea-3427-44ea-b4e0-e6f8ef5fea5d", "6016c104-5e77-48aa-ad48-399de21c1a38", "74b6960d-a672-4a11-a26f-0b9d7e9f2daa", "82f84675-3b8f-4c57-9399-10aaaa572f1c", "b7b5854e-5167-41eb-864e-9f7d9e1d2330", "c2ae4793-a514-442c-907f-63a84b425d62"], "title": "DIVE\u2014A platform for multi-user virtual environments", "venue": "Computers & Graphics", "year": 1993, "id": "7ec18d7e-2139-4c8f-9304-aed5932ad115"}
{"abstract": "This paper gives an algorithm for approximately solving the  post office problem:  given  n  points (called sites) in  d  dimensions, build a data structure so that, given a query point  q , a closest site to  q  can be found quickly. The algorithm is also given a relative error bound e, and depends on a ratio r, which is no more than the ratio of the distance between the farthest pair of sites to the distance between the closest pair of sites. The algorithm builds a data structure of size  O ( n e) O (1/e) ( d \u22121)/2  in time  O ( n  2 e) O (1/e) ( d \u22121) . Here e=log(r/e). With this data structure, a site is returned whose distance to a query point  q  is within 1+e of the distance of the closest site. A query needs  O (log n ) O (1/e) ( d \u22121)/2  time, with high probability.", "authors": ["Kenneth L. Clarkson"], "n_citation": 148, "references": ["43dfd110-6a4d-4463-838a-dad26db1b846", "c9893d06-344b-4b96-9954-753535b00fad", "d057a535-fa3e-4636-b4c8-6a291f96eda9", "d20995f6-529c-41c6-b75e-a169b005fb5c", "f6272ea9-0360-47ed-90a5-651ea958143f"], "title": "An algorithm for approximate closest-point queries", "venue": "symposium on computational geometry", "year": 1994, "id": "0d41d9b5-6e7d-476e-a484-36758a6b209a"}
{"abstract": "Automated testing is a basic principle of agile development. Its benefits include early defect detection, defect causelocalization and removal of fear to apply changes to the code. Therefore, maintaining high quality test code is essential. This study introduces a model that assesses test code quality by combining source code metrics that reflect three main aspects of test codequality: completeness, effectiveness and maintainability. The model is inspired by the Software Quality Model of the SoftwareImprovement Group which aggregates source code metrics into quality ratings based on benchmarking. To validate the model we assess the relation between test code quality, as measured by the model, and issue handling performance. An experiment isconducted in which the test code quality model is applied to   $18$       open source systems. The test quality ratings are tested for correlation with issue handling indicators, which are obtained by mining issue repositories. In particular, we study the (1) defect resolution speed, (2) throughput and (3) productivity issue handling metrics. The results reveal a significant positive correlation between test code quality and two out of the three issue handling metrics (throughput and productivity), indicating that good test code quality positively influences issue handling performance.", "authors": ["Dimitrios Athanasiou", "Ariadi Nugroho", "Joost Visser", "Andy Zaidman"], "n_citation": 50, "references": ["02e0342a-33d3-4d3f-9f1d-b14081edbc39", "0668ea90-57e5-4a05-a43a-da2462bf48cd", "0a99b6f9-6c46-47c6-885f-fb1b5ad7b2b8", "0d89ee51-90ff-4653-a547-adfd849d18d4", "0de91a59-b37f-4008-b201-0d168f5645b8", "1a03cbae-26e0-4147-ac0c-e74673c36943", "2508abc5-1f38-45c5-87bf-433de5f5f1e4", "26bc9805-cb9e-407b-8042-68eebcd550e0", "29f65137-2260-42a9-81ba-eb86e67a1f79", "2ac5fedd-db52-4207-ac12-b527da60b604", "2b47a5ec-fd51-4b53-bd29-f6fc5e44da8a", "2c823ddd-6ada-446d-a663-65344771b83b", "40c9504d-c08a-4707-99ec-8d31558f9674", "432a90a4-e9dd-40b6-9f77-d3cc4ca0a75a", "43d82eca-9eb6-4ae5-b477-a2f4ea8ef26e", "5681cff6-8e8c-4878-b0bd-0eb5cb0ebf5e", "568fb62a-1f49-4200-bb65-5a0eece0b137", "56941878-4354-4039-8b03-b8aa8cbfa6f6", "57071747-069e-453f-b3e1-b16b417581ee", "5c1a7ec2-ce9c-4ac8-8273-4b3eba8e4eab", "616c4fd3-cf16-44ae-9d73-d8e1001f8ed9", "6abfc566-b718-4d0e-b276-821f5475f22f", "6bf538bc-5dca-4775-96b9-cecff31ec59b", "6e8ea39b-5d8f-43e5-9663-84abb1b52da6", "73c12deb-b8b6-41b8-b958-d45095ca23ca", "78a6d91d-2b98-4464-8bea-cd034e8c7d74", "7a640e67-7f6e-49f1-86b3-47ec320d63f7", "86372cae-0ca9-4a9f-923d-cdb230bf303e", "86d0bfad-a86f-4860-91c0-ccb96c6a5353", "8b1775b0-c210-4bfc-848f-b2ccf8f4536e", "8b18321c-06eb-421d-8fd6-b2382b0fbbad", "92413a18-b836-40a7-883e-ded812136caf", "93fa4edd-05c1-462f-a504-16f9bec72933", "991b6118-6066-439e-8ed5-ad896391511b", "9f3bdcc5-658d-4865-b856-f00b14c3460e", "9f919569-bb11-498d-a0b0-fd1ffda2918f", "a09b9bc5-a653-46c7-9f2b-d4509b4449f3", "a7122806-c66c-49e6-8876-70093d70f605", "aa53709a-972b-47be-a10f-b76259fc3978", "b4ddf96f-8c01-47ca-8664-1e12868f8a03", "b88049d0-381b-4689-a17c-21a58977ac1e", "baeb44c4-9b29-4ab8-ba05-4c560ba8bc1c", "bd7fe127-d827-4f7c-8828-4561c84515cf", "c12407f2-5a9f-4a93-b4e1-6553e6636586", "c312f9e8-ffbc-4f30-bb5a-a772720d7afc", "c3b7a3c1-6bcd-4148-91e5-2e3e17f43e8a", "c5559d8a-f8cb-4110-aa89-6a01a2abc0b5", "c5ec1c87-2aa7-4178-a048-53a43de44145", "ce1de14a-719d-41ca-9569-b882ce817195", "d8ab6b10-bed8-4f5d-8a4c-21a3432797a9", "e36897c3-bea2-4149-a731-5847236a3d06", "e714ec1b-74da-4c78-800f-ab38ed52d811", "e7c5501b-6ba7-48f7-be99-c1b61ec11dcc", "e92e9a2b-c023-4d02-a70d-5353237662ad", "ea43fe6a-3222-43a6-8e22-1a98257f573b", "ec81362d-c57a-4049-a835-adf80c4a01fd", "ee872429-10c8-4860-b7c8-423079049cf0", "eeb92931-e69e-4c3d-a65f-097354e047ad", "f184f0cf-3e46-4f76-a554-dd6a63673984", "ff6a0cc6-c9ba-4974-9df0-8361f5731872"], "title": "Test Code Quality and Its Relation to Issue Handling Performance", "venue": "IEEE Transactions on Software Engineering", "year": 2014, "id": "7ec19c65-1c13-4d4a-a69d-a60c2ce8833a"}
{"abstract": "Fluid (or Hybrid) Petri Nets are Petri net based models with two classes of places: discrete places that carry a natural number of distinct objects (tokens), and fluid places that hold a positive amount of fluid, represented by a real number. With respect to previous formulations, the FSPN model presented in this paper, is augmented with a new primitive, called flush-out arc. A flush-out arc connects a fluid place to a timed transition, and has the effect of instantaneously emptying the fluid place when the transition fires. The paper discusses the modeling power of the augmented formalism, and shows how the dynamics of the underlying stochastic process can be analytically described by a set of integro-differential equations. A procedure is presented to automatically derive the solution equations from the model specifications. The whole methodology is illustrated by means of various examples.", "authors": ["Marco Gribaudo", "Matteo Sereno", "Andr\u00e1s Horv\u00e1th", "Andrea Bobbio"], "n_citation": 85, "references": ["09bc1c5f-57b5-4d79-9e88-d26c8c9b2e74", "1a0e2158-1a5e-4e2a-b20b-559d0c8f0cc4", "2d1b3485-4b45-4f2f-882e-6c6239c3ae70", "46317cf2-44ba-403e-897c-3f262da727d9", "67ad9463-c0f9-4bd1-a557-6d6802e1dad6", "8a5b4b75-59da-4c83-8b9b-376dfb1e68f2", "8c10362d-3a33-471b-90d4-8c169941913e", "9bd5df94-121e-47aa-a422-024ba4cc38ac", "a9012627-587b-4a58-9416-2052c33d779c", "de0bd8a5-545b-4aca-a35e-4bb41173313b", "f2ecdffa-bbd5-49bf-8bf6-94f8547c282f", "f7c1f809-5ae5-463f-8494-b223672e5520", "f97d8220-0d23-4ddf-b797-11f2e8c294c9"], "title": "Fluid Stochastic Petri Nets Augmented with Flush-out Arcs: Modelling and Analysis", "venue": "Discrete Event Dynamic Systems", "year": 2001, "id": "92544613-b7b9-4260-84da-fdf958dc19fb"}
{"abstract": "In this paper, we present the current state of the art in semantic data modeling of multimedia data. Semantic conceptualization can be performed at several levels of information granularity, leading to multilevel indexing and searching mechanisms. Various models at different levels of granularity are compared. At the finest level of granularity, multimedia data can be indexed based on image contents, such as identification of objects and faces. At a coarser level of granularity, indexing of multimedia data can be focused on events and episodes, which are higher level abstractions. In light of the above, we also examine modeling and indexing techniques of multimedia documents.", "authors": ["Wasfi G. Al-Khatib", "Young Francis Day", "Arif Ghafoor", "P.B. Berra"], "n_citation": 183, "references": ["0eff354a-8c19-40ad-be5f-4448d20a3281", "10aa4f6a-b791-443c-978a-455b3d25f3fa", "16088d1a-5061-4460-a562-239f2c64854a", "16fb90c7-64db-4630-81a8-1cbe11b50f63", "22b99f97-1bfb-4a70-9ea8-d105ce6a5366", "2607488c-ba7a-4806-92db-7440d0b4207e", "2b822a89-8a9f-463f-b736-db516c507991", "2e6b9a4f-9944-4e36-bf90-fd352b630e17", "35851b05-42fe-4396-8cdb-8e46868f4dbd", "4d65c147-3ff3-4c80-82ad-760057fd2310", "4df3ab4c-0c6c-447e-9d33-06aa4e319497", "538e222e-2927-4960-9b50-fb4ce97f1238", "53febd2f-cda9-43d5-a576-a2c3367883ad", "5af538d7-841b-403f-8289-cdffe6561a9f", "695f2717-c814-440c-82bd-67f5b2828f37", "7183f8c0-8675-4378-9b04-d5d772f41819", "71bbf2ac-bbe2-4c4b-8695-20e007b18be3", "7ac8c2ef-dab3-4c74-aee9-c5881e1e6dc2", "8d1babb8-e4f4-4377-8b7f-77afbe7167be", "9a6cc355-4198-4d9d-beb3-7debff92fdc1", "ab344689-80f8-4f1d-b8a7-d9ff7f128396", "abb162c8-4fae-43e7-afd7-316bbf4f1a1b", "acb5e5d9-490c-4122-b701-558ba4f6335e", "c3204ece-e787-43d6-979a-cea6ddf8a1bc", "da58bca6-8693-4c55-a41b-f0406fba2540", "db4c7467-7212-4532-b880-a0a8e0994553", "dbe5ae2e-bbc0-4508-8df5-3ec95c784fa8", "e5e7d1e9-e0b3-43ba-ad9d-a951dc71b75c", "f484f56b-640f-4f4a-a9cf-05f9adcafe8d", "f6d1cca6-37cb-4277-a6dd-8535f264b8a1"], "title": "Semantic modeling and knowledge representation in multimedia databases", "venue": "IEEE Transactions on Knowledge and Data Engineering", "year": 1999, "id": "ab1d23eb-cc12-44dd-976c-14cf9d8c448c"}
{"abstract": "We describe a robust accurate domain-independent approach to statistical parsing incorporated into the new release of the ANLT toolkit, and publicly available as a research tool. The system has been used to parse many well known corpora in order to produce data for lexical acquisition efforts; it has also been used as a component in an open-domain question answering project. The performance of the system is competitive with that of statistical parsers using highly lexicalised parse selection models. However, we plan to extend the system to improve parse coverage, depth and accuracy.", "authors": ["Ted Briscoe", "John Carroll"], "n_citation": 333, "references": ["01394e48-603f-432f-980c-463d0521ff99", "0a9be626-7224-444a-8ff0-06c2bd427647", "140adedf-806c-49e9-8b11-b9468b9b392c", "2268d22d-76da-41f3-aac6-54f83b3a012c", "4decb722-b620-48d5-8d7d-cf6045b1bbbe", "5538b634-04f3-4d09-bb4e-90055817e3b1", "58d8ff4d-a21d-4df6-8cea-402df7362b41", "5dbdba8b-3e98-4712-aa8c-0c0945b44dd0", "61794f79-473a-4c03-85e5-bf78a1acf6fa", "6d986416-3e63-41bd-89e4-3668e30e0e5a", "7187ef7e-a9ed-4daf-8b18-4a3b5637ea29", "7555bee6-4a5e-4c98-8d8d-8ed7c5df0ad2", "8e1f4895-8737-4c18-8712-9ba4c349e2d9", "9422a03c-f845-44c9-b998-e7cbedb822f6", "bf3ca99c-d07d-4277-bb3d-07768e15014e", "d7ce1ca2-678b-4ae6-ab52-20c8646e8158", "dd52b6eb-7d36-446e-9213-71c454d2f7a0", "dd8cb5dd-69c2-4e13-a4ca-75728344fd4b", "f3930c8d-ae71-4b65-9f1b-fd37f9996991", "fa512d50-e535-4feb-91d0-42b071e08a4f"], "title": "Robust accurate statistical annotation of general text", "venue": "language resources and evaluation", "year": 2002, "id": "54b4e4f0-f85d-4de0-bbb1-5cf18d4b3d1b"}
{"abstract": "Abstract   This paper presents a novel approach to usability evaluation with children called  peer tutoring . Peer tutoring means that children teach other children to use the software that is evaluated. The basic philosophy behind this is to view software as a part of child's play, so that the teaching process is analogous to explaining the rules of a game such as hide and seek. If the software is easy to teach and learn, it is more likely that the amount of users increases in a social setting such as a school. The peer tutoring approach provides information about teachability and learnability of software and it also promotes communication in the test situation, compared to a test person communicating with an adult instructor. The approach has been applied to the development of a perceptually interactive user interface in QuiQui's Giant Bounce, a physically and vocally interactive computer game for 4\u20139 year old children. The results and experiences of using peer tutoring are promising and it has proved to be effective in detecting usability flaws and in improving the design of the game.", "authors": ["Johanna H\u00f6ysniemi", "Perttu H\u00e4m\u00e4l\u00e4inen", "Laura Turkki"], "n_citation": 129, "references": ["20e74357-ce0e-44a4-bbcd-b5a3b8447920", "25f9118e-d4dc-4512-b3ed-e29275aa6f63", "2d158983-02e8-4ae0-a635-37b2bd835a35", "2fd8012e-dddc-4cfa-afac-4660e0f534b5", "43627616-4a32-48a7-b27c-a52fa0672fd5", "51a794b0-be09-4a06-90ac-86a94b88bf96", "59bf775e-35ad-4dd2-857d-559fb6c358e2", "6fe3f0a4-930a-4643-91de-8a4417863efe", "72fd76f2-c2b3-418a-9fba-8de1209becfc", "a7505708-7b11-46fa-b82a-2ad2166678cf", "b8d97ff5-e730-4aee-b514-43ed8fbd9cb9", "f08a755a-f174-4041-bec0-ac43bbe31072", "f0df7273-4a4d-4b0b-bb37-558c4d9d000c"], "title": "Using peer tutoring in evaluating the usability of a physically interactive computer game with children", "venue": "Interacting with Computers", "year": 2003, "id": "df4583d7-2c61-441d-aa56-c568bc5c46b7"}
{"abstract": "Data mining is the process of extracting desirable knowledge or interesting patterns from existing databases for specific purposes. Most conventional data-mining algorithms identify the relationships among transactions using binary values. Transactions with quantitative values are however commonly seen in real-world applications. We proposed a fuzzy mining algorithm by which each attribute used only the linguistic term with the maximum cardinality int he mining process. The number of items was thus the same as that of the original attributes, making the processing time reduced. The fuzzy association rules derived in this way are not complete. This paper thus modifies it and proposes a new fuzzy data-mining algorithm for extrating interesting knowledge from transactions stored as quantitative values. The proposed algorithm can derive a more complete set of rules but with more computation time than the method proposed. Trade-off thus exists between the computation time and the completeness of rules. Choosing an appropriate learning method thus depends on the requirement of the application domains.", "authors": ["Tzung-Pei Hong", "Chan-Sheng Kuo", "Sheng-Chai Chi"], "n_citation": 133, "references": ["1012cd0d-9eaf-423b-875e-f82f94628434", "229d50ee-2d1d-459c-8c75-75a1d962da6f", "29be7e13-baac-4700-8230-8700499ffa9d", "744ca414-e477-4df0-96ce-312e4a371141", "83759260-9385-4a77-b108-45aaf008ce1e", "86dafb65-1d2e-42d9-8982-4d520b6da774", "b6d163d8-c566-4c81-bf94-6d4d004888ba", "dcd9d334-ec87-46cf-98ae-22d940b98a27"], "title": "TRADE-OFF BETWEEN COMPUTATION TIME AND NUMBER OF RULES FOR FUZZY MINING FROM QUANTITATIVE DATA", "venue": "International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems", "year": 2001, "id": "e27142ce-e4fb-43ca-8db8-bb40271432a9"}
{"abstract": "Simultaneous editing is a new method for automating repetitive text editing. After describing a set of regions to edit (the records), the user can edit any one record and see equivalent edits applied simultaneously to all other records. The essence of simultaneous editing is generalizing the user\u2019s selection in one record to equivalent selections in the other records. We describe a generalization method that is fast (suitable for interactive use), domain-specific (capable of using high-level knowledge such as Java and HTML syntax), and under user control (generalizations can be corrected or overridden). Simultaneous editing is useful for source code editing, HTML editing, and scripting, as well as many other applications.", "authors": ["Robert C. Miller", "Brad A. Myers"], "n_citation": 93, "references": ["33834a31-132a-409b-b646-c8918a85afb0", "8751db49-ccfc-4ec3-bd03-e60bf70dc136", "b2a6b391-2bf8-497a-aaf2-eaf2c4f71fa9", "b6e41731-3aff-4311-b7fe-1f41d68e1b07", "cfbb051b-53e5-4fe9-8cc9-37a5410e481b"], "title": "Interactive Simultaneous Editing of Multiple Text Regions", "venue": "usenix technical conference", "year": 2001, "id": "57e75b32-24ac-42ae-9c80-d18a59adc719"}
{"authors": ["Paul Gustafson", "Peter Carbonetto", "Natalie J. Thompson", "Nando de Freitas"], "n_citation": 31, "title": "Bayesian Feature Weighting for Unsupervised Learning\u201a with Application to Object Recognition", "venue": "", "year": 2003, "id": "3eedd25b-65cf-40f9-943e-163b36e53050"}
{"abstract": ".de Zusammenfassung Durch die Zun ahme von E-Commerce-Anwen\u00ad dungen verstiirkt sich die Bed eutung der verteilten Datenverarbeitung von Datenquellen im Internet. Viele Firmen schli eBen sich zu virtuellen Unternehmen zusa mme n od er griinden gemeinsam virtuelle Marktplatze. Dabei erschwere n st andige Veranderungen der verfiigbar en Ressourcen (z. B. Datenquellen) und ein permanent fiuktuierender Teiln ehmerkreis das Auffinden relevanter Informationen. In dies er Arbeit priisentier en wir die Met ad at env erwaltung MDV , deren PublishjSubscribe-Mechanismus die Dynamik im Bereich E-Commerce adressiert . Ein Backbone mit we\u00ad nigen offentlichen MDV s iibernimmt di e Registrierung und Verteilung von Met adaten im RDF-Format . Lokale MDVs a bonniere n Metadaten von einem Backbone. Wir zeigen anhand des offenen , verteilten Anfrageb e\u00ad arbe it ungssy ste ms ObjectGlobe, wie die MDV das Auffinden wichtiger Ressourcen fiir die Anfrageb earbeitung a uf Internet-Dat enquellen errnog\u00ad licht . Eine weit er e zent ra le Herausforderung in der Entwicklung unter\u00ad nehmensiiber gr eifender Dat env erarbeitungsanwendungen ist Sicherheit, insbesondere Au then t ifizierung und Autor isierung. Aus diesem Grund gehe n wir niiher a u f den Einsatz der MDV zur Sp eicherung von Sicher\u00ad heitsinforma tionen in ObjectGlobe ein .", "authors": ["Markus Keidl", "A. Kreutz", "Alfons Kemper", "Donald Kossmann"], "n_citation": 7, "references": ["0625e224-dfa3-4135-9393-af066b8e605a", "074b01bc-a31f-4838-b783-d698b393cd57", "0fd6d6d1-6155-4b67-93c2-4cae66d09091", "1d0ef800-3b44-43c9-bdd8-126e8d50cef8", "31c5e39a-3f24-4d20-bf8c-3d00036baf95", "4ad90b1a-094e-46c0-941f-b35856bd6109", "7b0c4405-cf77-44f8-a88f-69dfa759750c", "9d75e18d-862f-4fd8-b576-b08bfa35dacc", "b98cf7e9-2976-4bf6-8400-8acedd43ed06", "c9b8f3bf-babd-427a-8723-68b7e4526dd4", "d10f840c-1003-48b5-8aec-3ecc0957c658", "e95d26ca-43e5-4d9f-b30d-73bc4bdc81a4", "ecfb2022-e18c-4e5e-8733-d8bc6f4c8fc9"], "title": "Verteilte Metadatenverwaltung f\u00fcr die Anfragebearbeitung auf Internet-Datenquellen", "venue": "", "year": 2001, "id": "bb7252cf-213c-41b2-bb81-8923ebd65bc8"}
{"abstract": "In this paper, we propose a new framework for discriminating the initial maneuver of a lane-crossing event from a driver correction event, which is the primary reason for false warnings of lane departure prediction systems (LDPSs). The proposed algorithm validates the beginning episode of the trajectory of driving signals, i.e., whether it will cause a lane-crossing event, by employing driver behavior models of the directional sequence of piecewise lateral slopes (DSPLS) representing lane-crossing and driver correction events. The framework utilizes only common driving signals and allows the adaptation scheme of driver behavior models to better represent individual driving characteristics. The experimental evaluation shows that the proposed DSPLS framework has a detection error with as low as a 17% equal error rate. Furthermore, the proposed algorithm reduces the false-warning rate of the original lane departure prediction system with less tradeoff for the correct prediction.", "authors": ["Pongtep Angkititrakul", "Ryuta Terashima", "Toshihiro Wakita"], "n_citation": 52, "references": ["099155a9-d3e9-47a4-9fec-d79fa2d52684", "260e59fe-b38c-4731-9c05-8634e8e80e26", "2d3a942e-50a8-44eb-a59a-78622e3a2cc5", "323289ed-7acf-4663-bf89-2e8e3dacc6c7", "4ecc7fcd-cc81-4450-a007-8edc62dedba3", "91908efa-2d60-4af9-bea1-261b638ed0e8", "95817a6a-fcc4-475b-81b7-b3714a1c1472", "95c6635e-6828-468b-883a-d4f4723e5a9c", "97cf7f10-646e-48d0-b408-c7339aa514fc", "9be321b0-71e1-4e53-ba99-34209f7db514", "a95e4733-c574-4c2f-a4ad-b582da2ef270", "adb92636-6d67-478a-a3fe-109a98b988e7", "b8f175cb-ffaa-4bd4-ac12-1ae137340f77", "bbd62b80-c145-45e8-b17b-dde109fe29d9", "c7e3b27e-e74e-4aea-b4ee-0e5dc75eb35f", "d35e2e75-c60d-48cf-b240-a0909fbecea2"], "title": "On the Use of Stochastic Driver Behavior Model in Lane Departure Warning", "venue": "IEEE Transactions on Intelligent Transportation Systems", "year": 2011, "id": "eb68c19c-0a19-4a3a-86b2-9fed9c1cf955"}
{"abstract": "In this paper we present three different parallelizations of a discrete radiosity method achieved on a cluster of workstations. This radiosity method has lower complexity when compared with most of the radiosity algorithms and is based on the discretization of surfaces into voxels and not into patches. The first two parallelizations distribute the tasks. They present good performance in time but they did not distribute the data. The third parallelization distributes voxels and required the transmission of small part of the voxels between machines. It improved time while distributing data.", "authors": ["Rita Zrour", "Pierre Y. Chatelier", "Fabien Feschet", "R\u00e9my Malgouyres"], "n_citation": 50, "references": ["053de278-7882-41c1-8a90-62ba72e384eb", "0be74a38-2022-447c-89ca-543d6df35f92", "1cd46e48-e347-4092-b43f-d41d5e9154a2", "7d01ab56-645c-4ab3-8577-5a7d81b05354", "8db16d04-38d6-4d8d-bef4-1e8dd123fcd2", "949f642f-2daa-4ce5-b465-1d54f7b7da81", "c073775d-a6d2-4c71-869c-8779a30d610f", "c4f637c9-a21a-4cee-9712-e857bdfc5d7d", "d1dac6b9-4eac-4fad-91cf-6d7b124368e5", "d2ea1b2e-7e9d-4603-b2ea-40b4bda4b620"], "title": "Parallelization of a discrete radiosity method", "venue": "european conference on parallel processing", "year": 2006, "id": "aa0580d5-7a77-43a3-bd5f-c49e24671740"}
{"abstract": "In this work we present the average-case analysis of orthogonal range search for several multidimensional data structures. We first consider random relaxed K-d trees as a prototypical example. Later we extend these results to many different multidimensional data structures. We show that the performance of range searches is related to the performance of a variant of partial matches using a mixture of geometric and combinatorial arguments. This reduction simplifies the analysis and allows us to give exact upper and lower bounds for the performance of range searches (Theorems 3 and 4) and a useful characterization of the cost of range search as a sum of the costs of partial match-like operations (Theorem 5). Using these results, we can get very precise asymptotic estimates for the expected cost of range searches (Theorem 6).", "authors": ["Amalia Duch", "Conrado Mart\u00ednez"], "n_citation": 17, "references": ["0b567f00-224b-48a9-82b0-bd673fcede60", "32277bbc-6113-46cb-84a1-23068d587972", "3eb5c91f-ada8-4e36-9490-836e512ffcbf", "6361a09f-8d20-42b4-be0f-e8784afeb9c2", "c643d4e5-d26c-46e6-918d-39f458449d0f", "c860072e-01c0-425e-8855-7f921bff76ed", "ccdb0ced-7f29-4daa-a0a1-c92849284024", "d6ffd0e7-61aa-4dea-9fe0-4345e2382e96", "e97d9c05-854e-4bd6-9301-11affc0d103f", "f47f5c50-60af-4c30-941c-93be9b2204c5", "f9952fb8-ab4a-4d98-92d6-e35b6dcbcbd0", "fd027907-4303-44c8-820b-e9fa65397f24"], "title": "On the average performance of orthogonal range search in multidimensional data structures", "venue": "Journal of Algorithms", "year": 2002, "id": "3a26f3a1-d27f-48f2-8a5d-9d9a44f916f0"}
{"abstract": "Abstract The evaluation of digital watermarks is an active and important research area. From the vari ety there are different types of attacks like geometric attacks, lossy compression, security or protocol attacks [1, 2] available to evaluate the robustness of digital watermarks. Furthermore, different att ack strategies like single attacks or profile attacks are known to improve the evaluation process [3]. If for example, the robustness of a watermarking algorithm is evaluated, then the signal of the audio content and the embedded watermark is m odified with the goal to remove or weaken the watermark information. In this paper, the focus is set on audio signals. We introduce the evaluation process of an existing benchmark service, the Audio Watermark Evaluation Testbed (Audio WET) [4] by evaluating five different audio watermarking algorithms, which work in time, frequency and wavelet domain. Therefore, we introduce basic, extended and application profiles which improve the evaluation of watermarking algorithms to provide comparability. Whereas the basic profiles measure single properties on a watermarking algorithm, the extended and application profiles reflect real world application scenarios. Furthermore a test scenario and test environment for the evaluation of five audio watermarking algorithms by using basic profiles is described and discussed. The test results of the first evaluation by using basic profiles are introduced and a comparison of the evaluated watermarking algorithms using different parameter sets for embedding function is provided.", "authors": ["Andreas Lang", "J. R. Dittmann"], "n_citation": 5, "references": ["1e325bfb-62c0-4d9b-95bc-cd476d1c8257", "2f496bc9-1f4c-47ce-b5d0-aca4b6219995", "c7f3f5ed-855a-498f-aeb2-dbd450cc7561"], "title": "Profiles for evaluation: the usage of audio WET", "venue": "Proceedings of SPIE", "year": 2006, "id": "e0db7974-2e9b-420d-a65b-058ebb18694a"}
{"abstract": "We present a labeling scheme for rooted trees which allows to compute, from the label of v alone, unique identifiers for the ancestors of v that are at distance at most d from v. For any constant d our labeling scheme produce labels of length log n+O(\u221alog n), and for d \u2208 O(\u221alog n) the labels are still of length O(log n).#R##N##R##N#In particular, given the labels of two nodes u and v we can determine from the labels alone whether u is the parent of v or vice versa, whether u and v are siblings, and whether u and v are at distance at most d from each other.#R##N##R##N#The need for such labeling scheme arises in several application areas, including in particular communication networks and search engines for large collections ofWeb XML files. In the latter application XML files are viewed as trees, and typical queries ask for XML files containing a particular set of nodes with specific ancestor, parent, or sibling relationships among them.", "authors": ["Haim Kaplan", "Tova Milo"], "n_citation": 70, "references": ["02f9e191-0430-4a7c-a8bd-20674738bee3", "297191d6-0fc3-46e8-92ab-5f4962003ad3", "341eb951-02f0-47c7-97c4-4ba40aae95de", "53092382-633d-41c4-a063-cd843ae28120", "6ece887c-ce5f-4b03-a3f0-a6296671dd16", "b7278be9-3ac5-43c1-9710-da623e38ee1e", "e6626bfc-378f-41db-bbbe-df14c0770f9b"], "title": "Short and Simple Labels for Small Distances and Other Functions", "venue": "workshop on algorithms and data structures", "year": 2001, "id": "a07f94d8-fd26-4fa1-ba42-1c76a2b0dd1b"}
{"abstract": "Although personalized search has been proposed for many years and many personalization strategies have been investigated, it is still unclear whether personalization is consistently effective on different queries for different users, and under different search contexts. In this paper, we study this problem and get some preliminary conclusions. We present a large-scale evaluation framework for personalized search based on query logs, and then evaluate five personalized search strategies (including two click-based and three profile-based ones) using 12-day MSN query logs. By analyzing the results, we reveal that personalized search has significant improvement over common web search on some queries but it also has little effect on other queries (e.g., queries with small click entropy). It even harms search accuracy under some situations. Furthermore, we show that straightforward click-based personalization strategies perform consistently and considerably well, while profile-based ones are unstable in our experiments. We also reveal that both long-term and short-term contexts are very important in improving search performance for profile-based personalized search strategies.", "authors": ["Zhicheng Dou", "Ruihua Song", "Ji-Rong Wen"], "n_citation": 572, "references": ["014b7429-189f-4d55-8aed-df212bd82152", "0761dd7a-2983-49ed-99ba-55d01ad52742", "22ae4c6a-4c16-43ec-ae0d-4e2762c6cdee", "259c8ddc-fc48-4b79-a0c8-f5a13bbcf09d", "29fb9c66-9b0d-4d19-9297-f92df3988440", "2a856c55-fea1-4160-a7dc-3a48c7321d75", "2f04623f-f234-4cf5-9c86-de1e2be5fc10", "312e54ca-e7e9-4129-99f4-36f3aeff827e", "34a40c3f-e512-4c57-8e5b-af9a6f2b0036", "43f16e4e-aa6e-4450-99bc-c8e55298747f", "4b628fe0-96a7-4a8d-8c4e-bee8a46086d9", "5af127f2-7627-4c89-963e-409ccd9c6ec1", "610134d0-26c5-440c-be9b-b47ac3b41070", "697f9b0b-fe81-4335-860b-136776e5ab00", "737e87f3-c930-4fca-8ae6-d0be2555de06", "741dc00a-69f2-469b-abf3-11c3f19c2fbd", "743afdd4-6987-4e7a-a7df-bcb43eb0240e", "9b3419fe-ba66-406c-a9ad-5135ffa7cc76", "ab36ec67-b622-48c9-b154-ce4581781ea6", "ac1ab239-16c3-4402-9e40-83cae17ad497", "ae518197-3b2b-41c5-9b30-84d0cadf1081", "c0116ed9-3fb8-42b7-83f3-e67143d5b82b", "c3cca647-b51c-45d0-b523-5a44cd0ace95", "c5282ccf-4d83-402b-bde2-5d3e00337911", "c5583ade-f07d-4e6c-a0d4-a0729e529bc0", "c9b9ff4f-2582-4364-b126-a4b558411512", "ccc5cb4e-4af9-44b4-b510-d87bea1e4500", "d5e1f58a-5619-4dd6-ac76-324506f37d5a", "e5c9b457-32f7-4909-88c3-539e97557ac3", "e93831d6-717e-418b-9afb-db3804bc17c6", "ea52709e-6802-4224-8216-8eb725f90137", "f978a89a-6f27-48e4-aa6f-0cbe195b838e"], "title": "A large-scale evaluation and analysis of personalized search strategies", "venue": "international world wide web conferences", "year": 2007, "id": "f40931e0-7dd7-4035-bb6f-4750e1c76451"}
{"authors": ["Joseph A. Goguen"], "n_citation": 274, "references": ["24c12596-3d27-420c-998c-3ab430bc394d", "3a268c6f-4213-4113-b4bd-f6cc9034c7a2", "72c8e748-f123-46c0-965d-1bd57ae0c8c7", "73a233ee-3f8b-4d46-8a2e-5cd720e5fb9a", "94f48c48-bd47-489b-a176-632b82593a24", "bcab66ff-5729-458d-8820-7dd6ed8e9153", "e5bf88c2-91b2-4ef3-874e-8845c9152dcc"], "title": "A categorical manifesto", "venue": "Mathematical Structures in Computer Science", "year": 1991, "id": "b104d082-cf69-46a9-bbe2-59067c240016"}
{"abstract": "Interoperability and cross-fertilization of multiple hypermedia domains are relatively new concerns to the open hypermedia and structural computing community. Recent work in this area has explored integrated data models and component-based structural service architectures. This paper focuses on the user interface aspects relating to client applications of the structural services. It presents an integrative design of a graphical hypermedia user interface for hypermedia-based process-centric enterprise models. An enterprise model covers various important perspectives of an enterprise (such as processes, information, organization, and systems). In this paper, examples are given to show that these perspectives are presented better using a mixture of hypermedia structures found in several hypermedia domains. The visualization and interaction design for such hypermedia-based enterprise models integrates many features found in navigational, spatial, taxonomic, workflow and cooperative hypertext domains. A use case is provided to show that client applications based on this design allow users to see and interact with an enterprise model from multiple perspectives. In addition, some' initial user experience is also reported.", "authors": ["Weigang Wang"], "n_citation": 5, "references": ["04910e72-303b-4ed8-b5ae-8b7f60591c0e", "13ca496a-e8a1-4c1b-95c4-f3b3b6107a13", "27be9338-5b09-4f43-848a-78fe3413d6c0", "31958eff-1a44-40b7-a9a5-39cdda4aa5c4", "380d01ef-e062-4eb4-9552-6167ccf2c7cf", "3e4eb726-17d4-4b9f-95da-244f54881529", "48321285-699a-40a4-9eb7-9c8108f8b428", "4d9fbf2f-9130-4572-a417-e7fa91b364b4", "6a0ea688-514a-4217-ab63-5b1984f56a92", "6d62e242-31be-4b7a-b796-55610a44eb83", "6dc7c781-b2c6-4fa8-b766-2e56143bf1c5", "720a176c-a787-490e-9401-2981765775ef", "72c824e8-eb09-438b-8ba2-0439ec3ec4d2", "a87dea65-5533-493b-acd5-1dd25b50bf43", "adeac47f-3f0d-485b-aaf4-3b02a7493446", "c2c45cb9-4037-4f46-bf92-1f8cbe9bced9", "e967808f-e129-4e48-8493-703eabb65515"], "title": "Visualizing and interacting with hypermedia-based process-centric enterprise models", "venue": "Journal of Network and Computer Applications", "year": 2003, "id": "4b8e1c57-1c1e-449f-b1eb-71a337dc7fd9"}
{"abstract": "Abstract   By explicit evaluation of the linear programming bound for the case  q =2,  d =3 (after adding one inequality when  n =0 (mod4)), we prove that   A[n, 3]\u2a7d2     n\u22122   [  1  4  n+1]  . In particular the binary Hamming code is shown to remain optimal when it is shortened one, two or three times. Furthermore some general relations between solutions of the LP problem are derived.", "authors": ["Marc R. Best", "Ae Andries Brouwer"], "n_citation": 50, "references": [], "title": "The triply shortened binary Hamming code is optimal", "venue": "Discrete Mathematics", "year": 1977, "id": "58d3b763-508a-45ba-b35d-37abaeee94a3"}
{"abstract": "This article describes an implementation of the optical flow estimation method introduced by Zach, Pock and Bischof in 2007. This method is based on the minimization of a functional containing a data term using the L 1 norm and a regularization term using the total variation of the flow. The main feature of this formulation is that it allows discontinuities in the flow field, while being more robust to noise than the classical approach by Horn and Schunck. The algorithm is an efficient numerical scheme, which solves a relaxed version of the problem by alternate minimization. Source Code A C implementation of this algorithm is provided. The source code and an online demo are accessible at the web page of this article 1 .", "authors": ["Javier Sanchez", "Enric Meinhardt-Llopis", "Gabriele Facciolo"], "n_citation": 50, "references": ["1d7adf37-d57f-4f8b-b25a-c5d288d554d7", "4a32fff6-9a42-4a01-aefc-05e70b59da9a", "63194705-0835-478d-bdca-102daa5da56d", "c4ab9d06-4e79-459c-b641-677b17471592"], "title": "TV-L1 Optical Flow Estimation", "venue": "", "year": 2012, "id": "3f4efc6c-28fd-4b75-8e4d-b9e6cd0903be"}
{"abstract": "In \"Single-Value domains\", each agent has the same private value for all desired outcomes. We formalize this notion and give new examples for such domains. including a \"SAT domain\" and a \"single-value combinatorial auctions\" domain. We study two informational models: where the set of desired outcomes is public information (the \"known\" case). and where it is private information (the \"unknown\" case). Under the \"known\" assumption, we present several truthful approximation mechanisms. Additionally, we suggest a general technique to convert any bitonic approximation algorithm for an unweighted domain (where agent values are either zero or one) to a truthful mechanism, with only a small approximation loss. In contrast, we show that even positive results from the \"unknown single minded combinatorial auctions\" literature fail to extend to the \"unknown\" single-value case. We give a characterization of truthfulness in this case, demonstrating that the difference is subtle and surprising.", "authors": ["Moshe Babaioff", "Ron Lavi", "Elan Pavlov"], "n_citation": 51, "references": ["3309a19a-99b4-40a0-94a9-02caba0e7bc0", "3934991d-4fb8-4304-86e2-4c3c5e917b14", "39a244b5-ddd5-47dd-b9db-9135f158a41f", "660cb5c6-16ad-4561-98de-faaef9d345d0", "9f4a4c1c-3835-4bff-8a2f-e48b1edf6c23", "a8e9c0d8-c253-453d-855e-e19b72a87b69"], "title": "Mechanism design for single-value domains", "venue": "national conference on artificial intelligence", "year": 2005, "id": "29ef9bfe-32bd-4eae-97b4-64944564abc4"}
{"abstract": "Sequential access pattern mining discovers interesting and frequent user access patterns from web logs. Most of the previous studies have adopted Apriori-like sequential pattern mining techniques, which faced the problem on requiring expensive multiple scans of databases. More recent algorithms that are based on the Web Access Pattern tree (or WAP-tree) can achieve an order of magnitude faster than traditional Apriori-like sequential pattern mining techniques. However, the use of conditional search strategies in WAP-tree based mining algorithms requires re-construction of large numbers of intermediate conditional WAP-trees during mining process, which is also very costly. In this paper, we propose an efficient sequential access pattern mining algorithm, known as CSB-mine (Conditional Sequence Base mining algorithm). The proposed CSB-mine algorithm is based directly on the conditional sequence bases of each frequent event which eliminates the need for constructing WAP-trees. This can improve the efficiency of the mining process significantly compared with WAP-tree based mining algorithms, especially when the support threshold becomes smaller and the size of database gets larger. In this paper, the proposed CSB-mine algorithm and its performance will be discussed. In addition, we will also discuss a sequential access-based web recommender system that has incorporated the CSB-mine algorithm for web recommendations.", "authors": ["Baoyao Zhou", "Siu Cheung Hui", "Alvis Cheuk M. Fong"], "n_citation": 42, "references": ["0fd6d6d1-6155-4b67-93c2-4cae66d09091", "33610064-749d-4b38-91cc-1d8151dfb19a", "34b7e270-80d7-46d5-a6f1-e50087a8d045", "40b1014f-f0a2-4222-aabb-8d5e1c4431ce", "44e91111-b413-4143-85a9-81872a97fa9d", "5733466c-82bc-442b-a6ce-93918493ae70", "5f02e7c1-95dd-4c9b-b977-2f8bf079c296", "718562ef-10d7-43a7-b958-cdcdca367151", "b2576f0d-c649-4e66-9a6d-54b50151d602", "c2584c6c-d396-4724-97fb-f040d47b4751", "c4710c73-497d-44f0-ae10-64613eca18d4", "d1c93534-82a5-41fa-a5fa-9d18f5c2577f", "d6cec9a8-f1bc-4541-b7a7-0350b4055334", "df338255-a225-4c0e-931d-4a011d141184"], "title": "Efficient sequential access pattern mining for web recommendations", "venue": "International Journal of Knowledge-based and Intelligent Engineering Systems", "year": 2006, "id": "4a26988a-f791-45f6-a0bb-56f01cbf222e"}
{"abstract": "A procedure is described for augmenting a Simple LR(k) parser with new states which enable the extended parser to continue parsing the input after an error is detected. Examples of the error recovery technique are given.", "authors": ["Frederick C. Druseikis", "G. David Ripley"], "n_citation": 50, "references": ["1bfa8811-7ed4-4bb5-a6fd-41a35b4f9021", "29342bcc-2777-4fdf-9d21-75e0c117b302"], "title": "Error recovery for Simple LR(k) parsers", "venue": "", "year": 1976, "id": "4d199a4e-2b40-41af-a570-1f2e2f669ab3"}
{"abstract": "Machine learning research often has a large experimental component. While the experimental methodology employed in machine learning has improved much over the years, repeatability of experiments and generalizability of results remain a concern. In this paper we propose a methodology based on the use of  experiment databases . Experiment databases facilitate large-scale experimentation, guarantee repeatability of experiments, improve reusability of experiments, help explicitating the conditions under which certain results are valid, and support quick hypothesis testing as well as hypothesis generation. We show that they have the potential to significantly increase the ease with which new results in machine learning can be obtained and correctly interpreted.", "authors": ["Hendrik Blockeel", "Joaquin Vanschoren"], "n_citation": 58, "references": ["21cdcb44-d3f8-4d0b-8e14-9ce4d8942bfd", "58c2b316-016e-4d7a-a1c6-8b3963445070", "7a10be82-6113-4f60-9e37-f35f2d9423c5", "7b613c31-1174-4d22-8cf7-1807d85fa9c3", "9c01a502-04f3-4adb-9bde-f06253818cb9", "aa767a83-de19-4421-bfb4-f63808992758", "c3b30d12-3e05-407e-95b0-383feecde86c", "e28939c6-e43e-489b-8877-d09a758503a6"], "title": "Experiment Databases: Towards an Improved Experimental Methodology in Machine Learning", "venue": "european conference on principles of data mining and knowledge discovery", "year": 2007, "id": "e8500673-6ac8-4d59-b4a0-63c92fa13d6b"}
{"abstract": "Roles are an essential concept within agent-oriented software engineering (AOSE). Role definitions in current AOSE methodologies are usually claimed to be for use at the requirements level. However, in most methodologies, they are too low level, specifying too much detail. We present a \"higher level\" role specification. The role specification method described works together with other agent specification/analysis methods that we and others have developed. However, we believe that role specification may also be used with nonagent-based systems, and provide a useful abstraction for specifying the requirements of any software system.", "authors": ["Kevin Chan", "Leon Sterling"], "n_citation": 50, "references": ["365ac4aa-5611-41ad-8018-6dba33f27ada", "48ebc275-044a-4251-b997-0784f188dbce", "8fdfb278-ca93-4b7d-819e-afa21b2878b3", "af758934-597a-401d-9801-bfd60aeabe80", "bff54864-b50e-4ed1-b44d-e45c74526cee", "c0d2b44d-14d3-4047-842e-8aa5f66d4554", "c85c4f66-7765-4a23-b9ea-7498c94f3c29", "e995ade1-741a-44cc-862e-f5e4054350a4", "ea10c05b-0fe7-40f8-b153-5459ef11c01b", "f235421f-598c-4e38-baf7-4024dfe4d762"], "title": "Specifying roles within agent-oriented software engineering", "venue": "asia-pacific software engineering conference", "year": 2003, "id": "959092b4-0b8d-4550-a38c-ad43c4b1c6d8"}
{"abstract": "There is a hidden intrigue in the title. CT is one of the most abstract mathematical disciplines, sometimes nicknamed \u201dabstract nonsense\u201d. MDE is a recent trend in software development, industrially supported by standards, tools, and the status of a new \u201dsilver bullet\u201d. Surprisingly, categorical patterns turn out to be directly applicable to mathematical modeling of structures appearing in everyday MDE practice. Model merging, transformation, synchronization, and other important model management scenarios can be seen as executions of categorical specifications. Moreover, the paper aims to elucidate a claim that relationships between CT and MDE are more complex and richer than is normally assumed for \u201dapplied mathematics\u201d. CT provides a toolbox of design patterns and structural principles of real practical value for MDE. We will present examples of how an elementary categorical arrangement of a model management scenario reveals deficiencies in the architecture of modern tools automating the scenario.", "authors": ["Zinovy Diskin", "T. S. E. Maibaum"], "n_citation": 39, "references": ["0389efad-957c-4a33-9cdb-4f22a1f13c53", "051c0195-a265-4e2a-9213-bdd97db17875", "058ac5d9-c0cb-4a7c-9f33-524b5ac13e28", "0622471f-c669-4c7f-8527-80586fbc4373", "0a4e2903-2512-4f0f-b5cd-3772a49a0e44", "0a9e0dd6-8586-4d46-84df-44cadc30a136", "0d052a50-0681-461e-9296-623794a860d3", "0d9553a7-7db0-498e-9b5a-8b06a532a780", "0e17d529-7c63-4bd1-94fb-78805b5cb614", "1229de83-3602-4f69-beed-45f9b304d1e4", "12af8261-42f7-4ae8-9144-2f308c0555a8", "17207521-bada-4a78-aee9-a463b27f5d0e", "1adec6e0-1298-4dd1-a499-51f2f9500590", "1da8d19d-36ba-4ace-9f77-6062bd718f2a", "23d7b228-c096-4f22-820d-5dec6e661b3d", "2503995b-45a2-42d3-a2ce-e108e1e696a1", "26eccc76-4668-4356-8b1e-2c18dadbc937", "2cfe1585-2736-46db-8b3a-a3b010943680", "2d3b1b03-84a1-43fe-b3c8-d4163b9b4275", "2eb44518-fbce-49de-bfef-c5b60379a85d", "36e3709c-3437-4e12-8432-981b934e8e76", "42d4cdda-3738-49d5-aff9-ff7ebc4229c0", "47afea37-b584-4dc5-b605-0702e037e492", "47e1e888-1625-4d54-aa33-610f6ef2f6f2", "47f394f9-1c7a-4a85-a18a-631caa5709e5", "4807db9a-c4e4-4d53-8ffd-62ce1921b009", "4d723c9d-ac75-413f-bf81-540f3cac9a74", "50e940fb-9fc3-479f-b0bd-bd83f503dd36", "51e1b471-eaa3-40f3-b99d-45e59cb29887", "52098cac-898f-474e-bf3c-7f6ab07480f1", "55fd81ff-fef2-44c9-8cec-d95fccdad41f", "5d8d840a-2fba-4018-8ac3-fd5cb706560a", "5e64b2cd-4f7c-4a90-ae23-82e0ff087935", "6142a41e-a0cf-4d6b-9151-3a108dfe1f3f", "6255c378-0fd5-41a0-b690-459bc6ac9b1e", "6282ec7f-fab9-41fc-a813-c3c0dc69818e", "64e399f1-a83d-41e1-af8f-f9c74f6476c2", "6d33c7d2-9ad1-48d3-8017-bd3a59aa9e01", "6fa0203b-090f-450e-a0cd-f551f0e7790b", "702d7dac-7c19-4027-81dc-99f5f3f3fe05", "73466761-0327-43a0-ab11-832979a644b4", "7360f316-3fd9-40f5-92a2-e5b38914c0d9", "748e5f25-f758-4440-a197-de3f0a23616a", "77cb94b9-050f-443b-a3c4-6e84700d8ce9", "784d5154-818d-441a-a060-2bc47dc8ddba", "7ae83c41-f2f8-4179-acd5-12251cc72950", "86718b68-beb2-4201-8bce-845a80302bd2", "89cfb73b-93e8-4407-8000-3b12333e27c8", "963e13a0-44ac-4d07-b9d1-53532adb9214", "9a4d631a-b9b9-488f-a97e-97b100508c41", "9b1b0df3-0a07-4247-b4f5-d1607f309bed", "9da077ac-e3b4-4edd-899b-d6be9c079aa6", "a6ca3a71-d011-42fc-8af0-9af8aabffa62", "b0ea027d-3363-4212-9377-920db0d6b232", "b104d082-cf69-46a9-bbe2-59067c240016", "b234164b-fb52-4389-abee-64d95db5aa75", "c0a71885-6a60-4a21-925c-f711e2f17bf3", "c0d2d959-bdf1-4f80-8972-91e713244a3c", "c3c80a8c-2d0b-4fa9-ba94-b13502120c50", "c9923d06-e955-4f98-9d4e-a85a8ec1565b", "cb801d2f-f207-4785-b791-9c39a4656210", "cbfa3276-c22a-4fbf-ab23-a3b9a8bed8cc", "d5be731f-04af-4167-84b5-1d6d3cf9d0b0", "d654b82c-e698-4736-a77f-5b2d4cb39397", "d765a244-d23f-4c6b-b67c-67260dd002ae", "db5a361d-f705-4f43-8a6f-0013e5fdff3c", "e091ebd6-a426-4601-b08e-66d9a66db7f3", "e181053b-2580-403e-9860-419cba40bf7f", "e298ffe9-16b8-465a-92ef-ff427472a8a2", "e3f337df-0403-47a4-831e-8098ffeb6919", "e4ba5cca-9b3c-47e6-87de-e8c863d3e7d4", "ea60d01d-f97c-413c-852c-d1159f945516", "f2b2ec2c-34d7-43ed-94fa-660fe4a5e710", "f2ec3a54-c745-4c15-bf31-0f2aee0aca32", "f382e1ad-da97-4839-a805-660700b6bca8"], "title": "Category Theory and Model-Driven Engineering: From Formal Semantics to Design Patterns and Beyond", "venue": "Electronic Proceedings in Theoretical Computer Science", "year": 2012, "id": "3097f749-2366-4184-80df-7fd79c730cae"}
{"abstract": "Hard problem of cartographic pattern recognition in fine scale 1 maps, using information that comes from coarse scale 2 maps, is considered. The maps are raster-scanned color maps of different thematic, representing the same terri- tory in coarse and fine scale respectively. A solution called Coarse-to-Fine Scale Method is proposed. This method is defined in terms of means: coarse scale maps and their information; concepts: image associated function, carto- graphic knowledge domain and cartographic pattern; and tools: a set of cluster- ing criteria of the Logical Combinatorial Pattern Recognition.", "authors": ["Efr\u00e9n Gonz\u00e1lez-G\u00f3mez", "Serguei Levachkine"], "n_citation": 1, "references": ["5ddfb0e1-b96a-4024-a6f8-1ee6dc5f31ab", "91a1a54d-e935-4c09-9933-70a548b9e05a", "b3f8270d-50bc-41ea-acee-950368f56763", "b6d5cb55-1e02-4202-b2cc-93f4e27fbbda", "ea853bd5-5844-4804-af13-5754dc6dff44"], "title": "Color Cartographic Pattern Recognition Using the Coarse to Fine Scale Method", "venue": "iberoamerican congress on pattern recognition", "year": 2004, "id": "89acc7e9-5269-4b87-b9c8-e6c9e5e321c4"}
{"abstract": "The choice of how to represent the search space for a genetic algorithm (GA) is critical to the GA's performance. Representations are usually engineered by hand and fixed for the duration of the GA run. Here a new method is described in which the degrees of freedom of the representation-i.e. the genes-are increased incrementally. The phenotypic effects of the new genes are randomly drawn from a space of different functional effects. Only those genes that initially increase fitness are kept. The genotype-phenotype map that results from this selection during the construction of the genome allows better adaptation. This effect is illustrated with the NK landscape model. The resulting genotype-phenotype maps are much less epistatic than unselected maps would be, having extremely low values of \"K\"-the number of fitness components affected by each gene. Moreover, these maps are exquisitely tuned to the specifics of the epistatic fitness function, creating adaptive landscapes that are much smoother than generic NK landscapes with the same genotype-phenotype maps, with fitness peaks many standard deviations higher. Thus a caveat should be made when making arguments about the applicability of generic properties of complex systems to evolved systems. This method may help to solve the problem of choice of representations in genetic algorithms. >", "authors": ["Lee Altenberg"], "n_citation": 129, "references": ["58810840-1a9c-4e06-9553-80406ebb9f7a", "c061069f-29d1-46d4-9974-dede8d5461f9"], "title": "Evolving better representations through selective genome growth", "venue": "world congress on computational intelligence", "year": 1994, "id": "8f039fa6-d4db-4f79-8463-6c196f907125"}
{"abstract": "Over the next few years the amount of biometric data being at the disposal of various agencies and#R##N#authentication service providers is expected to grow significantly. Such quantities of data require not #R##N#only enormous amounts of storage but unprecedented processing power as well. To be able to face this #R##N#future challenges more and more people are looking towards cloud computing, which can address these #R##N#challenges quite effectively with its seemingly unlimited storage capacity, rapid data distribution and #R##N#parallel processing capabilities. Since the available literature on how to implement cloud-based #R##N#biometric services is extremely scarce, this paper capitalizes on the most important challenges #R##N#encountered during the development work on biometric services, presents the most important standards #R##N#and recommendations pertaining to biometric services in the cloud and ultimately, elaborates on the #R##N#potential value of cloud-based biometric solutions by presenting a few existing (commercial) examples. #R##N#In the final part of the paper, a case study on fingerprint recognition in the cloud and its integration into #R##N#the e-learning environment Moodle is presented.", "authors": ["Peter Peer", "Jernej Bule", "Jerneja Gros", "Vitomir \u0160truc"], "n_citation": 29, "references": ["200572d5-5f99-433b-8205-a1222e2fcc29", "976c4962-f8c9-40f1-8888-777f5199861d", "d8be7d6f-c5e2-4b52-a1e8-171918fe7ebc", "db764b43-aecf-4f1b-bf0b-0b123f6b8ed4", "f41bf5a5-2960-4b2a-b680-d49e24f06bd0"], "title": "Building Cloud-based Biometric Services", "venue": "Informatica (lithuanian Academy of Sciences)", "year": 2013, "id": "2f044e21-b6c8-4078-a0e6-636934d483ac"}
{"abstract": "In pattern recognition-based myoelectric control, high accuracy for multiple discriminated motions is presented in most of related literature. However, there is a gap between the classification accuracy and the usability of practical applications of myoelectric control, especially the effect of long-term usage. This paper proposes and investigates the behavior of fifty time-domain and frequency-domain features to classify ten upper limb motions using electromyographic data recorded during 21days. The most stable single feature and multiple feature sets are presented with the optimum configuration of myoelectric control, i.e. data segmentation and classifier. The result shows that sample entropy (SampEn) outperforms other features when compared using linear discriminant analysis (LDA), a robust classifier. The averaged test classification accuracy is 93.37%, when trained in only initial first day. It brings only 2.45% decrease compared with retraining schemes. Increasing number of features to four, which consists of SampEn, the fourth order cepstrum coefficients, root mean square and waveform length, increase the classification accuracy to 98.87%. The proposed techniques achieve to maintain the high accuracy without the retraining scheme. Additionally, this continuous classification allows the real-time operation.", "authors": ["Angkoon Phinyomark", "Franck Quaine", "Sylvie Charbonnier", "Christine Serviere", "Franck Tarpin-Bernard", "Yann Laurillau"], "n_citation": 133, "references": ["14631f89-c6e3-47f3-b5e7-c3c5132db7d6", "23657201-5d44-4623-a6ac-459afb35f7e8", "24807b7e-d4cc-4f11-b959-1c7c8cfbb7f4", "48a96620-f239-42ef-a1ef-980c2a32d234", "59cf0437-68e5-4504-bec5-0ab2a9207101", "5dfd069c-3b7d-4ef2-9fa3-026e39f933fc", "5e879828-dd38-405e-8956-5cf42f926716", "708df101-0196-4e1c-a95c-dd7ac9a80b46", "818c2293-11e9-4d5e-8c44-3c23c099a807", "90c5a508-1db4-43eb-865b-194e0bae07a8", "9ac51f44-a0c5-4058-9b51-db0772ada067", "9d403884-89b8-4360-92b6-7652599aae3f", "aef6cee4-d396-41a1-9b93-d90fb6e818ec", "c909cf77-dfd9-4d29-959c-05383d6e0459", "cda8cdcb-e97e-48a5-afa3-7b7ec51480ba", "e3d5aca0-1a6a-445b-9887-4620a8c522bd", "ed963718-72f1-4577-9937-6d9064765126", "f6bd8b64-684d-429a-aab5-8ff3a2c23cd6"], "title": "EMG feature evaluation for improving myoelectric pattern recognition robustness", "venue": "Expert Systems With Applications", "year": 2013, "id": "4e272948-e527-44e2-934f-5f7aef875d75"}
{"abstract": "The paper studies asynchronous consensus problems of continuous-time multi-agent systems with discontinuous information transmission. The proposed consensus control strategy is implemented based on the state information of each agent's neighbors at some discrete times. The asynchrony means that each agent's update times, at which the agent adjusts its dynamics, are independent of others'. Furthermore, it is assumed that the communication topology among agents is time-dependent and the information transmission is with bounded time-varying delays. If the union of the communication topology across any time interval with some given length contains a spanning tree, the consensus problem is shown to be solvable. The analysis tool developed in this paper is based on nonnegative matrix theory and graph theory. The main contribution of this paper is to provide a valid distributed consensus algorithm that overcomes the difficulties caused by unreliable communication channels, such as intermittent information transmission, switching communication topology, and time-varying communication delays, and therefore has its obvious practical applications. Simulation examples are provided to demonstrate the effectiveness of the theoretical results.", "authors": ["Feng Xiao", "Long Wang"], "n_citation": 487, "references": ["0bf829c3-d555-4745-b1a5-7c5ce8acbff6", "223edc15-f2f7-4796-8b91-9fab63eda279", "2768199c-b9d6-4001-94d3-e6429c93bc5f", "36f4d1ef-6c87-412f-98a5-9475f5a1f888", "423548af-857e-4063-88b5-14cd2d7f2155", "6460eee0-033e-4185-8b7c-dbcb931e1b2c", "7ad963e0-1a49-40d7-afe0-47b47f89880a", "aca928ab-a742-4ff7-bf7c-7ee7f5df4866", "b6a0562d-91b9-4b65-a395-0e705e24f3ba", "d9162547-fd7f-4605-855d-0a3173c4b08e", "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9"], "title": "Asynchronous Consensus in Continuous-Time Multi-Agent Systems With Switching Topology and Time-Varying Delays", "venue": "IEEE Transactions on Automatic Control", "year": 2008, "id": "fc2c4e17-8a50-4705-a2d7-1c855a752f0e"}
{"abstract": "Humans perceive the three-dimensional structure of the world with apparent ease. However, despite all of the recent advances in computer vision research, the dream of having a computer interpret an image at the same level as a two-year old remains elusive. Why is computer vision such a challenging problem and what is the current state of the art? Computer Vision: Algorithms and Applications explores the variety of techniques commonly used to analyze and interpret images. It also describes challenging real-world applications where vision is being successfully used, both for specialized applications such as medical imaging, and for fun, consumer-level tasks such as image editing and stitching, which students can apply to their own personal photos and videos. More than just a source of recipes, this exceptionally authoritative and comprehensive textbook/reference also takes a scientific approach to basic vision problems, formulating physical models of the imaging process before inverting them to produce descriptions of a scene. These problems are also analyzed using statistical models and solved using rigorous engineering techniques Topics and features: structured to support active curricula and project-oriented courses, with tips in the Introduction for using the book in a variety of customized courses; presents exercises at the end of each chapter with a heavy emphasis on testing algorithms and containing numerous suggestions for small mid-term projects; provides additional material and more detailed mathematical topics in the Appendices, which cover linear algebra, numerical techniques, and Bayesian estimation theory; suggests additional reading at the end of each chapter, including the latest research in each sub-field, in addition to a full Bibliography at the end of the book; supplies supplementary course material for students at the associated website, http://szeliski.org/Book/. Suitable for an upper-level undergraduate or graduate-level course in computer science or engineering, this textbook focuses on basic techniques that work under real-world conditions and encourages students to push their creative boundaries. Its design and exposition also make it eminently suitable as a unique reference to the fundamental techniques and current research literature in computer vision.", "authors": ["Richard Szeliski"], "n_citation": 1653, "title": "Computer Vision: Algorithms and Applications", "venue": "", "year": 2010, "id": "62c533ff-6236-4fed-bdec-1d1d6c94cb6a"}
{"abstract": "As the complexity of scientific software increases, scientists are often expected to be experts in their own domain as well as in the construction and maintenance of their software. To support this paradigm, numerous specialized approaches have emerged. Leveraging the underlying expertise and motivational factors that drive scientific software development practices, the authors are developing a hybrid scientific software process improvement framework (SciSPIF) to allow scientific software developers to \"self-drive\"' their SE process improvement activities according to their own goals. Here, the authors report on the strategy for designing and building SciSPIF and provide preliminary insights.", "authors": ["Erika S. Mesh", "Gabbie Burns", "J. Scott Hawker"], "n_citation": 2, "references": ["33255c00-5d30-459b-91a3-88d2f0345690", "3edc4848-fe90-4c25-a893-0e25664f3d69", "4d28c150-e237-4c89-ab33-4ee65fa53f2d", "b1f04006-fcf3-47a4-b757-786fba18c709", "ba6307b9-b273-4554-976c-831857a0318f", "c03c27ec-6235-47f0-9cf2-90cac90dbc2f", "fddea136-d7d9-4892-9d15-cc0c0253599d"], "title": "Leveraging Expertise to Support Scientific Software Process Improvement Decisions", "venue": "Computing in Science and Engineering", "year": 2014, "id": "3f4515a8-8422-4e71-a424-6a45745c67f6"}
{"abstract": "Incremental search techniques find optimal solutions to series of similar search tasks much faster than is possible by solving each search task from scratch. While researchers have developed incremental versions of uninformed search methods, we develop an incremental version of A*. The first search of Lifelong Planning A* is the same as that of A* but all subsequent searches are much faster because it reuses those parts of the previous search tree that are identical to the new search tree. We then present experimental results that demonstrate the advantages of Lifelong Planning A* for simple route planning tasks.", "authors": ["Sven Koenig", "M. Likhachev"], "n_citation": 146, "references": ["80532a94-f2fc-4dcf-af88-af38ed8279f7", "83359201-f6d5-4572-97df-c06380267aa1", "a5342bea-6da4-4b1a-9836-fd5fb03c2e50", "f14570d7-ad74-4f59-8c5e-1c7238ecffe1"], "title": "Incremental A", "venue": "neural information processing systems", "year": 2002, "id": "f5a6f0dd-ddb3-47c7-bcd9-9414f9f02541"}
{"abstract": "In this paper, we provide optimal solutions to two different (but related) input/output design problems involving large-scale linear dynamical systems, where the cost associated to each directly actuated/measured state variable can take different values, but is independent of the input/output performing the task. Under these conditions, we first aim to determine and characterize the input/output placement that incurs in the minimum cost while ensuring that the resulting placement achieves structural controllability/observability. Further, we address a constrained variant of the above problem, in which we seek to determine the minimum cost placement configuration, among all possible input/output placement configurations that ensures structural controllability/observability, with the lowest number of directly actuated/measured state variables. We develop new graph-theoretical characterizations of cost-constrained input selections for structural controllability and properties that enable us to address both problems by reduction to a weighted maximum matching problem - efficiently addressed by algorithms with polynomial time complexity (in the number of state variables). Finally, we illustrate the obtained results with an example.", "authors": ["Sergio Daniel Pequito", "Soummya Kar", "A. Pedro Aguiar"], "n_citation": 24, "references": ["0fbeb53c-5c63-4a64-8402-daa9b2773a45", "1dd916f1-ca84-45a9-98a7-cbf6d5ae8016", "25318f53-39d5-44d4-95f0-6acd5c30436b", "2eb3431d-6022-4dc9-8fa6-91409849844c", "35d95733-5a55-41ae-9930-bbf6f1aadeb0", "36a74005-5a3f-4b2e-bcc1-6adb03c4097b", "377b7a7d-48fd-4bfe-8685-49ca5fabe5cc", "4e68a479-4765-41b9-8e9f-a880e22f3f89", "6fd65800-dc1a-4654-90ee-33b94f1a6269", "716f80a8-b7d9-4419-b356-e40a92ac49ab", "8a166388-ddcc-4528-ae5c-59799fafd957", "9480262d-fc03-41ac-a3df-b02175b47129", "a264da96-a8dc-42ee-baf8-19011a67f1d1", "a773cf45-61ee-48cd-9939-4a9056dc04fb", "ab4b0193-dbb1-4cc6-b006-539e27e09a2b", "b203638c-e182-40fe-b293-94bdfcfdb08a", "e196915a-c493-42e6-be09-a623d65c88d3"], "title": "Minimum cost input/output design for large-scale linear structural systems", "venue": "Automatica", "year": 2016, "id": "0bb37b2f-6dc4-4c54-b535-54d5d9739bea"}
{"abstract": "This current work describes human push recovery data classification using features that are obtained from intrinsic mode functions by performing empirical mode decomposition on different leg joint angles (hip, knee and ankle). Joint angle data were calculated for both open-eyes and closed-eyes subjects. Four kinds of pushes were applied (small, medium, moderately high, high) during the experiment to analyze the recovery mechanism. The classification was performed based on these different kinds of the pushes using deep neural network (DNN), and 89.28 % overall accuracy was achieved. The first classifier was based on artificial neural network on feed-forward back-propagation neural network (FF-BPNN), and second one was based on DNN. The proposed DNN-based classifier has been applied and evaluated on four types of pushes, i.e., small, medium, moderately high, high. The classification accuracy with a success of 88.4 % has been obtained using fivefold cross-validation approach. The analysis of variance has also been conducted to show the statistical significance of results. The corresponding strategies (hip, knee, and ankle) can be utilized once the categories of pushes (small, medium, moderately high, high) were identified accordingly push recovery (Semwal et al. in International conference on control, automation, robotics and embedded systems (CARE), pp 1\u20136, 2013).", "authors": ["Vijay Bhaskar Semwal", "Kaushik Mondal", "Gora Chand Nandi"], "n_citation": 50, "references": ["16da9026-1f1b-43f0-92ab-5876d4110f54", "27b5295a-23fb-4f2e-b5e2-f056f12e5390", "28aa9a88-0708-4d67-acf4-8e400395686b", "45fe5f58-080d-4448-8393-a1c72df664c9", "7d79abf4-f760-42ca-b072-a37accb3b6af", "83bf6d79-2f03-48e4-a45d-615bc511efdc", "aa3328ef-272c-4269-9bb0-d198cbf56410", "ba60b423-bec6-4880-b36d-98779ded02d4", "c2810be9-e330-49ad-b911-b6aeeba58ec9", "d0a71d40-80dd-41b4-8d66-c1e65c749054", "d1d3bff8-4c31-4647-883e-4db4289e69ea", "d4099142-84e1-46ed-8f2e-9dbcfce55965", "dc155453-85ea-4aa2-8ab6-60266f997ad8", "e88c6ad6-450f-433c-bdf6-e7d5db2a25ab", "eca31b93-100a-46aa-a188-a2c6057b6116", "fa4f9ed6-f523-42cb-a464-b6b4cbd0ad38"], "title": "Robust and accurate feature selection for humanoid push recovery and classification: deep learning approach", "venue": "Neural Computing and Applications", "year": 2017, "id": "006c8b43-4a31-43d1-8a6c-eccf3913daff"}
{"abstract": "Whilst there is a general consensus that quantitative approaches are an important part of successful software project management, there has been relatively little research into many of the obstacles to data collection and analysis in the real world. One feature that characterises many of the data sets we deal with is missing or highly questionable values. Naturally this problem is not unique to software engineering, so we explore the application of two existing data imputation techniques that have been used to good effect elsewhere. In order to assess the potential value of imputation we use two industrial data sets. Both are quite problematic from an effort modelling perspective because they contain few cases, have a significant number of missing values and the projects are quite heterogeneous. We examine the quality of fit of effort models derived by stepwise regression on the raw data and data sets with values imputed by various techniques is compared. In both data sets we find that k-nearest neighbour (k-NN) and sample mean imputation (SMI) significantly improve the model fit, with k-NN giving the best results. These results are consistent with other recently published results, consequently we conclude that imputation can assist empirical software engineering.", "authors": ["Michelle Cartwright", "Martin J. Shepperd", "Qinbao Song"], "n_citation": 104, "references": ["044074e8-31cb-44b6-ab74-fa21c93dd14b", "2304ef09-d937-4f6b-a9e6-97d17ffac734", "77705cb6-95f2-4be0-a7bc-f0a90b0efdc0", "892a3214-15b3-420c-9a99-18b5f5d263b2", "b32e042c-85cd-4c2c-a31c-02e1848fa5b5", "c6405cf3-e135-409f-9cd4-58673e3b210d", "ca51e37b-1a26-4bc9-a028-068621d7408f", "cebfe1ef-526c-4d16-8372-c93c0fdd486a", "d4c3a0a8-80f6-4450-b678-639692543e25", "eeac839a-ee02-48f9-92b2-4113d754a98d"], "title": "Dealing with missing software project data", "venue": "ieee international software metrics symposium", "year": 2003, "id": "00a1f915-36e1-4d24-86fe-3ecd38eb6d55"}
{"abstract": "We are witnessing in recent years growing interest for location-dependent information services among mobile users. We examine the issue of processing location-dependent queries in a mobile broadcast environment. Different from a traditional environment, mobile users are concerned with not only access latencies but also power conservation. The planar point location algorithms and conventional spatial index structures are shown inefficient. We propose a new index data structure, called D-tree, for querying location-dependent data in mobile broadcast environments. The basic idea is to index data regions based on the divisions between them. We describe how to construct the binary D-tree index, how to process location-dependent queries based on this index structure, and how to page the D-tree to fit the packet capacity. The performance of the D-tree is evaluated using both synthetic and real datasets. Experimental results show that the proposed D-tree provides a much better overall performance than the well-known existing schemes such as the R*-tree.", "authors": ["Jianliang Xu", "Baihua Zheng", "Wang-Chien Lee", "Dik Lun Lee"], "n_citation": 103, "references": ["24e2beb6-4741-48ad-87fa-27c108ab2ffd", "251873cd-50ca-4bba-a9cf-94bc5406c95e", "2e4e507b-bf78-45ae-889f-27a3d7296ae4", "407e8a80-2670-42db-a118-2d1f9865dd5b", "455bb334-d50a-45f7-bc2d-3e7ec5bc50c8", "56dd2d9f-64c6-47f1-8892-418d86d1d54e", "59f2f674-f88d-46a5-b0fd-1c78a41827e8", "6867a27b-4b3c-4bfc-8dd1-286630cb69cd", "73c955ac-0d9f-42a3-a466-46a5817490ee", "783e5a24-8505-4817-9566-36b1a478a6be", "94ec23c9-d905-4c71-b6c3-e1104ceb52af", "9e86db6a-39ad-41c8-98f5-a5ac7c71fc17", "af6334ce-672a-4bd9-88b8-9f1563c9b44d", "b3309a71-62bd-4c1b-93d0-a7fad54b9ddf", "c0ec3d71-8f25-4b4c-848e-4cb2efe478a6", "ca48d368-6b71-41bd-8dcc-f08cb8db9be2", "cb82c09b-8994-4d34-9eb2-1a2e8872b14f", "e9a91f9a-8bb9-405a-a709-46d6f0decd2a"], "title": "Energy efficient index for querying location-dependent data in mobile broadcast environments", "venue": "international conference on data engineering", "year": 2003, "id": "56b6a3b3-f56e-4520-a5c0-83d9d33f0531"}
{"authors": ["Deepak Kapur", "Mahadevan Subramaniam"], "n_citation": 50, "references": ["1465ad4c-6c36-4114-9cdd-b0e0f8d6d6d6", "25225c97-7811-418b-8773-79312eb3cfc7", "27793f54-901a-4313-a603-a6d8f53abb3c", "31a42c9c-c389-4feb-a3a0-8f0e73c99f75", "741eed20-a87c-4112-8cd4-5c1e0417e5cd", "b5fbaa5e-8016-4b7a-8ca0-b9d2359c97fc", "fff80810-7120-4b7f-bc04-e4736dd5312c"], "title": "Mechanically Verifying a Family of Multiplier Circuits", "venue": "computer aided verification", "year": 1996, "id": "8dd732ab-0f1b-48af-a06f-1d492e19c2ae"}
{"abstract": "MicroArchitectural Attacks (MA), which can be considered as a special form of Side-Channel Analysis, exploit microarchitectural functionalities of processor implementations and can compromise the security of computational environments even in the presence of sophisticated protection mechanisms like virtualization and sandboxing. This newly evolving research area has attracted significant interest due to the broad application range and the potentials of these attacks. Cache Analysis and Branch Prediction Analysis were the only types of MA that had been known publicly. In this paper, we introduce Instruction Cache (I-Cache) as yet another source of MA and present our experimental results which clearly prove the practicality and danger of I-Cache Attacks.", "authors": ["Onur Aciicmez"], "n_citation": 186, "references": ["033ebb72-0119-4cc9-89b8-f011c55ddd79", "0b240904-2d93-4b12-9f52-df9b9adde53b", "11b80a6b-08d6-4ea5-aeb7-6db83cb0b9bf", "286322b3-fc17-4ebe-94f1-9c1a8d5e0588", "3be36bec-3e52-4958-a4df-ea5034a0e027", "44bba5ca-6654-4163-92da-bced0de97c78", "50a9e0e2-6c6c-499d-948e-8de0a0166a98", "5c92e865-55ed-489e-9009-7fbeb7c27dd1", "65ecbc11-e6de-4c76-93a6-05175c684ed4", "76dab463-bb32-4626-9a90-7c50958af0ef", "7a2f9f0e-005e-45e9-93f6-1609283889cf", "96ff09f7-e819-4de9-aaf8-9eac2f5fa751", "9d8ed38b-fd86-4ff2-9dc5-0106cb3c025b", "b68fc787-7817-421e-8e66-8a98ab9db1ad", "c5920c8a-ace1-48a2-bf68-67f3c6d41512", "d57f7e7f-c204-4d12-9581-a0b05d4fde8a", "e0360d10-d04c-4950-87f0-cea3f3d7b115", "f92d6fa2-1e15-4161-907b-42dfbbb226e5"], "title": "Yet another MicroArchitectural Attack:: exploiting I-Cache", "venue": "computer and communications security", "year": 2007, "id": "aa2680c5-1f9e-4e29-81a1-fe2bd1e0153f"}
{"abstract": "A survey of research in the area of vision sensor planning is presented. The problem can be summarized as follows: given information about the environment as well as information about the task that the vision system is to accomplish, develop strategies to automatically determine sensor parameter values that achieve this task with a certain degree of satisfaction. With such strategies, sensor parameters values can be selected and can be purposefully changed in order to effectively perform the task at hand. The focus here is on vision sensor planning for the task of robustly detecting object features. For this task, camera and illumination parameters such as position, orientation, and optical settings are determined so that object features are, for example, visible, in focus, within the sensor field of view, magnified as required, and imaged with sufficient contrast. References to, and a brief description of, representative sensing strategies for the tasks of object recognition and scene reconstruction are also presented. For these tasks, sensor configurations are sought that will prove most useful when trying to identify an object or reconstruct a scene. >", "authors": ["Konstantinos A. Tarabanis", "Peter K. Allen", "Roger Y. Tsai"], "n_citation": 519, "references": ["02439fda-afba-4721-8ead-8494ee4d2dac", "04840022-504b-4526-ad5d-06dd8737fe99", "0e97d4ea-beb2-4caa-b672-8e210908b85b", "1e988d65-85f4-4e70-bd47-3f87535c9824", "2e78bb7d-7223-41ec-9a9f-10cf8f7d964a", "318a112e-0a86-4729-8605-200e06a2d6bd", "373108d3-72aa-4475-a66c-60d1a83e6d4f", "39536116-298e-4111-a0cc-de46bbc96632", "3a7e40fe-02c9-4546-a452-9bb3e171f845", "4092914e-5c52-4a0b-9beb-fec9fe2263d5", "40fc1eaa-a23b-44a8-b284-476e26aa1d83", "4de173db-2806-48f5-a18d-f25a5865a7c8", "5571a5c6-91e2-4a3e-abb3-6ee1919b89cf", "68a64d13-3253-40cd-bc37-140aa9ea457e", "85a07920-73ee-401c-98dd-b983b9ad2624", "8ba23141-4cf6-4e76-a007-b86de9e15687", "8bb86ec9-f05b-4d8a-b2d3-e235a6f3562b", "c8db0d39-d1b3-4772-8aa6-3fb5477f9b88", "cfabe781-2723-49a6-9854-56d8e5aa0179", "d4908fda-92e1-4514-b482-574493a25cde", "da477527-493c-438f-b880-c78d95b5f4a8", "de298324-d01e-4b89-8d7d-dc25c39b08d6", "e20b8828-51d7-44e0-a4d0-60cf8630c516", "e73d7d6e-e0ee-490d-8c6d-562b65abc212", "f11a2e44-7843-4f83-afd3-762c67aa5ec2", "ff4ee980-9544-4fa9-8964-0c880ecabdfb"], "title": "A survey of sensor planning in computer vision", "venue": "international conference on robotics and automation", "year": 1995, "id": "565e9ee0-f11e-4b21-a306-249c59b1443f"}
{"abstract": "The current paper establishes empirical patterns associated with mobile internet use on smartphones and explores user differences in these behaviors. We apply a naturalistic and longitudinal logs-based approach to collect real usage data from 24 iPhone users in the wild. These data are used to describe smartphone usage and analyze revisitation patterns of web browsers, native applications, and physical locations where phones are used. Among our findings are that web page revisitation through browsers occurred very infrequently (approximately 25% of URLs are revisited by each user), bookmarks were used sparingly, physical traversing patterns mirrored virtual (internet) traversing patterns and users systematically differed in their web use. We characterize these differences and suggest ways to support users with enhanced design of smartphone technologies and content.", "authors": ["Chad C. Tossell", "Philip Kortum", "Ahmad Rahmati", "Clayton Shepard", "Lin Zhong"], "n_citation": 62, "references": ["16415964-e87a-4493-b3f4-b9dd0bfc0c55", "259ff48c-d0b9-4fd4-8275-8169c6152224", "26a00e46-63c3-40e9-96a7-7b5b22d65990", "35e1e676-2ea9-4aa5-b1f6-5372f444f1f7", "390b83f3-72db-4218-8932-9bcf5798e7e8", "3d43b5ed-4a21-4bad-bdaf-8e7df6b1657a", "55e1fda9-ef4e-4c36-899e-46ee99881479", "65552bb8-aa1f-41e4-8ba0-97774a5599b8", "65edada7-9844-459b-983e-00fe60990c39", "6ebc51a4-9df3-47f2-9228-cbdf41710cb2", "74850126-397d-4efa-b998-321db2ca480f", "861ca8c4-4c2c-4970-be7e-7bf54cd610ed", "91f7ace6-d19e-4091-9b84-18971b8e120a", "a491bbe2-645e-484d-9ead-0cfacaeb14e5", "bd9522f5-5922-47fa-bee1-e0df6e7ff4c6", "be854767-d7c4-4749-bf75-c458684e68ee", "bf653bc2-6027-4cc7-8239-73990e675dd8", "bfd7e012-b018-47e6-ba7c-11ba7d74f2f7", "d1c59573-feea-4c8f-a5c7-be3892eddfd1", "d904cb5f-0951-4731-902b-86af051ef83c", "d98b9510-3ef5-4fff-baa2-4a2482b06a4d", "e820b0cc-4d2e-4040-a0e8-17120ff05186", "f79c2b16-952b-410c-abd2-cc69171ac5d6", "fda46298-d98a-4eb2-85f9-31106108949e"], "title": "Characterizing web use on smartphones", "venue": "human factors in computing systems", "year": 2012, "id": "eb6e4603-50dd-469c-aca2-c0021603be5a"}
{"abstract": "A method for handprinted Chinese character recognition based on Gabor filters is proposed. The Gabor approach to character recognition is intuitively appealing because it is inspired by a multi-channel filtering theory for processing visual information in the early stages of the human visual system. The performance of a character recognition system using Gabor features is demonstrated on the ETL-8 character set. Mental results show that the Gabor features yielded an error rate of 2.4% versus the error rate of 4.4% obtained by using a popular feature extraction method.", "authors": ["Yoshihiko Hamamoto", "Shunji Uchimura", "K. Masamizu", "Shingo Tomita"], "n_citation": 50, "references": ["75409195-2c67-4e4a-afb7-7c7d474f10f7", "8747f12d-32f3-4156-a0b9-ad8d8c8df8f5", "a7118e96-8f8c-4294-9abb-e12647db7127", "a79a9499-b4f5-4480-a7dc-6b4ea58aeed5"], "title": "Recognition of handprinted Chinese characters using Gabor features", "venue": "international conference on document analysis and recognition", "year": 1995, "id": "bb868904-f761-44ed-bd7a-2dae9bad1a69"}
{"abstract": "It has been argued that a single two-dimensional visualization plot may not be sufficient to capture all of the interesting aspects of complex data sets and, therefore, a hierarchical visualization system is desirable. In this paper, we extend an existing locally linear hierarchical visualization system PhiVis in several directions: 1) We allow for nonlinear projection manifolds. The basic building block is the Generative Topographic Mapping (GTM). 2) We introduce a general formulation of hierarchical probabilistic models consisting of local probabilistic models organized in a hierarchical tree. General training equations are derived, regardless of the position of the model in the tree. 3) Using tools from differential geometry, we derive expressions for local directional curvatures of the projection manifold. Like PhiVis, our system is statistically principled and is built interactively in a top-down fashion using the EM algorithm. It enables the user to interactively highlight those data in the ancestor visualization plots which are captured by a child model. We also incorporate into our system a hierarchical, locally selective representation of magnification factors and directional curvatures of the projection manifolds. Such information is important for further refinement of the hierarchical visualization plot, as well as for controlling the amount of regularization imposed on the local models. We demonstrate the principle of the approach on a toy data set and apply our system to two more complex 12- and 18-dimensional data sets.", "authors": ["Peter Tino", "Ian T. Nabney"], "n_citation": 95, "references": ["06d5ee43-254e-4c7c-a401-b6bc29b08579", "2834deb1-eaf2-40c8-899c-fdf2d28e556f", "63b2fa29-6e20-4ec5-bc55-842b8a395208", "6fb0d722-095f-41a9-b66a-6477232c6d8d", "8bcff77d-deb6-4b49-91ea-77b04b6a9a44", "d777639d-ff12-444d-ab9a-4fc796f2428e", "f2aadfc2-cda0-4dea-b786-29b578bfae0f"], "title": "Hierarchical GTM: constructing localized nonlinear projection manifolds in a principled way", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2002, "id": "d1aaf019-7395-4415-920d-30bea7a9b16e"}
{"abstract": "In many applications it is important that one view a scene at different levels of detail. A prime example is flight simulation. A high level of detail is needed when flying low, whereas a low level of detail suffices when flying high. More precisely, one would like to visualize the part of the scene that is close at a high level of detail and the part that is far away at a low level of detail. We propose a hierarchy of detail levels for a polyhedral terrain (or, triangulated irregular network) that given a viewpoint, makes it possible to select the appropriate level of detail for each part of the terrain in such a way that the parts still fit together. The main advantage of our structure is that it uses the Delaunay triangulation at each level, so that triangles with very small angles are avoided. This is the first method that uses the Delaunay triangulation and still allows one to combine different levels into a single representation.", "authors": ["Mark de Berg", "Katrin Dobrindt"], "n_citation": 181, "references": ["071cc614-4958-4e74-bbf6-a7dd3bbc77a7", "52a6d643-24cc-41bb-9db9-c24bb44c71ae", "6867a27b-4b3c-4bfc-8dd1-286630cb69cd", "6baf2e5a-cd0f-4f7d-bc91-57e53a4d3b9b", "77a0e258-b43b-4387-8d4d-160e241fd9ac", "7b2b888c-113e-4386-9b84-01cb3b33b7d9", "816a534f-a386-46a0-b8b7-224d9af9c515", "897b9415-6b97-4084-8539-267eebb62f4b", "a1a3d6ef-6cd7-4b03-a5cc-69d82b6d0809", "b87cce6a-7915-4dcd-b387-d13bf9fd626d", "ec8bd69b-d79e-4dd1-a90c-897c029b959f"], "title": "On levels of detail in terrains", "venue": "Graphical Models \\/graphical Models and Image Processing \\/computer Vision, Graphics, and Image Processing", "year": 1998, "id": "b5ac99eb-3a92-4ddf-9ed5-49cf745dda2c"}
{"abstract": "This article surveys research in service advertising, discovery, and selection for mobile ad hoc networks and related issues. We include a categorization of service discovery architectures for MANETs and their modes of operation, presenting their merits and drawbacks. We pay particular attention to cross-layer service discovery - a special class of efficient service discovery approaches for MANETs. We also present security issues and discuss service description options, service selection mechanisms, and service-state maintenance techniques. We conclude with a summary, an outlook, and directions for future research in this area.", "authors": ["Christopher N. Ververidis", "George C. Polyzos"], "n_citation": 217, "references": ["00e7238c-7976-4af5-9681-996c024e7922", "04ffb449-db45-4f47-9cae-68a27ae4b69e", "06682dc8-411e-44f5-9b47-47bff3be8b8a", "0e88fbef-c1fa-471f-a90b-b2bc66080d8b", "10a295f6-a0a8-4a1f-8026-1431ed928727", "16ab020e-2cf1-4fac-9124-7775dad0363b", "208febea-9043-46f4-9832-5bdadb9a33cd", "2678a59b-c866-495e-ba60-1ec9ff29538b", "292f5f81-3fc1-41a9-a3f0-c1b0d8830d99", "31c5e39a-3f24-4d20-bf8c-3d00036baf95", "3f8ee2c4-791d-4b0c-b24d-6df9e236da2f", "414ab875-9c0f-4894-8adc-e10ee3b793b1", "417944f6-0536-4ea2-bb15-ffdcba0ed958", "4f568c06-561e-437a-8b7e-30a2a3454341", "4ff81ed2-2216-4823-8f38-66041903ea9d", "53157586-703c-4a06-bfcb-2a2c4bee6afb", "5c44a064-244a-444e-b542-8bc1b5985f5d", "5e881321-9ba5-4f3d-aa3e-0fe806afc4f4", "67869bc3-0611-4bf0-8cb0-3221049fca4e", "7039fc91-96e5-4c0b-ad72-76c9376f4960", "7105c1a5-0bd4-4480-a7f0-44bd0f6294c1", "71bb416d-2884-485c-af39-ca374d4ee831", "729a8856-5346-4a8c-a334-d532cb0875ca", "731cbf94-0f49-42a0-ac14-451f6722cfda", "75eb545d-94f7-4aad-95bd-4f6ce33362e0", "797d8c71-05d5-4b74-a7f8-bd61071a318b", "7de2e342-c090-4fdc-9692-d385a5307f43", "804a4810-d809-4882-adcc-a3a8c758f163", "86f0ca47-c9e0-48a5-9339-0c0d332f6e7b", "8b57dc8b-a9e7-4063-839b-9bc8f6eed5ea", "8dff4f6a-14ab-4324-b5de-e97c05cff6cc", "920b8888-5886-456e-989c-236ea788f58c", "93b426e4-7a39-4fad-b71a-dbfe5b945960", "9a0e8578-1933-4f6d-9e43-d49022b982ad", "9cba9aa4-4ab0-42c9-a9fd-21cfdbb6a9ef", "9f14c92d-0df4-4c81-9ff7-37cc75459ce7", "a1f744f9-ed0a-483c-bbc1-3b58fed5ba41", "a7340a61-dea5-4557-a6e4-eff19addd694", "a811f0af-8898-45e1-b2cd-a62d35270573", "abac0ca3-d5e8-4f0d-a504-f96aec907d70", "acb44055-ea55-4215-ad9a-45741a4b47c9", "cb5bf146-91f2-497c-b781-98383e19a07c", "cc8dd09a-eabc-4c1e-8fd9-4989c101a84c", "cfd2f0a7-a89b-4637-a541-1e8ee462f38d", "d678af60-448c-49bc-8f91-b875e225f2e9", "d6d83e24-475a-4252-836a-1d7a69951593", "d8c5ea4a-4a3c-4e95-9bce-1c9f83bd05db", "e14391ba-ac9e-4ebe-bcc8-505a8699966d", "ea0f7452-5c18-43bf-b636-adcc023d2537", "ea8bcb28-4114-4d64-bbe0-f7fb5139f1e1", "f51eac1f-4e3d-41c7-a512-f184be5abb26", "fd682858-0e73-4534-9248-c0789bbd9f6e", "feb60c5b-dd6a-4f46-b09a-3958ae512cae", "ff23d007-59af-4284-bab4-da2a1c186be4"], "title": "Service discovery for mobile Ad Hoc networks: a survey of issues and techniques", "venue": "IEEE Communications Surveys and Tutorials", "year": 2008, "id": "a77d5efa-ee60-4341-8d1f-9ee67c03936c"}
{"abstract": "The Internet and World Wide Web are milestones in the history of information sharing. Scientists are increasingly relying on them to support their research. Knowledge is the basis of realizing intelligent services. The knowledge grid is a mechanism that can synthesize knowledge from data through mining and reference methods and enable search engines to make references, answer questions, and draw conclusions from masses of data. The knowledge grid infrastructure supports e-science through a set of relevant application services and semantic resources. We have developed a semantic-link-making tool for users to conveniently describe their understandings of provided resources and background knowledge.", "authors": ["Hai Zhuge"], "n_citation": 252, "references": ["355fdb56-5d3c-4138-9ed2-43b059a709b6", "379bf81f-a7f9-40da-9664-f30243187950", "457b9cd7-24eb-4bb8-9e5c-5bd1026212ce", "46b3cacc-57d1-4b81-a5b9-c65cab7479df", "5555a92a-d6e6-499a-8b22-b2d22db5228f", "84feff37-05d1-426c-8744-1fa7358ee272", "a912f8e7-5084-4742-887b-d871c6a42b8c", "d75374da-a292-44e4-9a8c-36896f73ed9c"], "title": "China's e-science knowledge grid environment", "venue": "IEEE Intelligent Systems", "year": 2004, "id": "7beee8a6-39ad-4bb2-91fd-4c50b8580387"}
{"authors": ["Masahide Nakamura", "Yoshiaki Kakuda", "Tohru Kikuno"], "n_citation": 30, "title": "Feature Interaction Detection Using Permutation Symmetry.", "venue": "", "year": 1998, "id": "97bd449e-8ff9-4ce4-a08b-1259926ee93d"}
{"abstract": "We consider abstract second order evolution equations with unbounded feedback with time-varying delay. Existence results are obtained under some realistic assumptions. We prove the exponential decay under some conditions by introducing an abstract Lyapunov functional. Our abstract framework is applied to the wave, to the beam, and to the plate equations with boundary delays.", "authors": ["Emilia Fridman", "Serge Nicaise", "Julie Valein"], "n_citation": 32, "references": ["931efef1-ce5a-4fcb-8afc-acd2ced2afc2", "b8b5223a-95dd-4f0e-ae68-26e95adfc186", "bf9d57ad-605e-46a3-80cf-49c530021f09", "dfc1156f-2b7b-4c42-8ebc-fc47b099fa50", "f2cd9b39-ee8e-4402-9166-e9b3d69a7a84"], "title": "Stabilization of Second Order Evolution Equations with Unbounded Feedback with Time-Dependent Delay", "venue": "Siam Journal on Control and Optimization", "year": 2010, "id": "42573628-d0b2-4f71-94b3-8c8d5d9096cc"}
{"abstract": "The adoption of Model-Driven Development (MDD) is increasing and it is widely recognized as an important approach for building software systems. In addition to traditional development process models, an MDD process requires the selection of metamodels and mapping rules for the generation of the transformation chain which produces models and application code. In this context, software process tasks should be performed in a specific sequence, with the correct input artifacts to produce the output ones. However, existing support tools and transformation engines for MDD do not have a process-centered focus that addresses different kinds of software process activities, such as application modeling and testing to guide the developers. Furthermore, they do not enable process modeling nor the (semi) automated execution of activities during process enactment. The MoDErNE (Model Driven Process-Centered Software Engineering Environment) uses process-centered software engineering environment concepts to improve MDD process specification and enactment by using a metamodeling foundation. In MoDErNE, a software process model may be enacted several times in different software projects. This paper details the MoDErNE environment, its approach and architecture and also the case studies through which the tool was evaluated.", "authors": ["Rita Suzana Pitangueira Maciel", "Ramon Ara\u00fajo Gomes", "Ana Patr\u00edcia Fontes Magalh\u00e3es", "Bruno Carreiro da Silva", "Jo\u00e3o Queiroz"], "n_citation": 11, "references": ["00830c2e-3967-4cb0-9e92-c5dd017b2e32", "01005ecc-8aa5-41d4-94b1-d09c7a0826bc", "1541a17a-a32b-4a61-920d-9e03d82eae10", "18f0ef88-3acd-4c8d-abab-7a1048743b52", "219ed13b-491d-472c-8bb7-2682b718b99e", "2727f9a8-d23f-44e4-8157-f64f08fe6825", "2d98756c-b5f1-462e-a80e-1136abf03f6e", "33adbda5-d78d-449a-8c99-d2b571a791ff", "37853925-5943-45c5-8e12-3e3b3cadc5d0", "6a8c8eef-4a36-4d9f-acd1-8412d3c9cc4b", "6c67c7fa-a306-4228-ba1d-8182b00dec72", "6cbb3e30-016a-4a13-a180-3e3639697ac2", "7146da00-9058-477c-bba2-396b2af6a985", "84cde65d-23a5-4ab7-8443-f38fc2914b77", "8feac316-5028-4c3d-99d7-a6ffa192d5e1", "b9e35c65-0672-4c48-9787-4f5cacb83f7f", "be9613df-fb64-4317-ae19-c5225bc9f507", "c8a1e9cb-bb23-4ef8-a1c9-295aa263089b", "da0eca5c-971c-4040-99b8-a7d76dd31f83", "dd03989c-1f09-4a42-9f91-44ef08c56038", "e804d3bb-f5c4-4272-90d5-a872f147e01c", "e84ef380-5fd9-4dcc-b3ad-bc199528ff28", "f0c3a0bc-beb4-4ae9-99bb-327fe0cf8b3a"], "title": "Supporting model-driven development using a process-centered software engineering environment", "venue": "automated software engineering", "year": 2013, "id": "3be79082-eff8-476b-a523-f0c7e6a5993d"}
{"abstract": "The advent of solid-state fingerprint sensors presents a fresh challenge to traditional fingerprint matching algorithms. These sensors provide a small contact area (/spl ap/0.6\"/spl times/0.6\") for the fingertip and, therefore, sense only a limited portion of the fingerprint. Thus multiple impressions of the same fingerprint may have only a small region of overlap. Minutiae-based matching algorithms, which consider ridge activity only in the vicinity of minutiae points, are not likely to perform well on these images due to the insufficient number of corresponding points in the input and template images. We present a hybrid matching algorithm that uses both minutiae (point) information and texture (region) information for matching the fingerprints. Results obtained on the MSU-VERIDICOM database shows that a combination of the texture-based and minutiae-based matching scores leads to a substantial improvement in the overall matching performance.", "authors": ["Anil K. Jain", "Arun Ross", "Salil Prabhakar"], "n_citation": 379, "references": ["2d31d7a2-01f5-44dd-aaa0-56343850e876"], "title": "Fingerprint matching using minutiae and texture features", "venue": "international conference on image processing", "year": 2001, "id": "f12a32b8-aeab-48c2-8300-1dfd395fda17"}
{"abstract": "Region-based memory management is an alternative to standard tracing garbage collection that makes operation such as memory deallocation explicit but verifiably safe. In this article, we present a new compiler intermediate language, called the Capability Language (CL), that supports region-based memory management and enjoys a provably safe type systems. Unlike previous region-based type system, region lifetimes need not be lexically scoped, and yet the language may be checked for safety without complex analyses. Therefore, our type system may be deployed in settings such as extensible operating systems where both the performance and safety of untrusted code is important. The central novelty of the language is the use of static capabilities to specify the permissibility of various  operations, such as memory access and deallocation. In order to ensure capabilities are relinquished properly, the type system tracks aliasing information using a form of bounded quantification. Moreover, unlike previous work on region-based type systems, the proof of soundness of our type system is relatively simple, employing only standard syntactic techniques. In order to show how our language may be used in practice, we show how to translate a variant of Tofte and Talpin's high-level type-and-effects system for region-based memory management into our language. When combined with known region inference algorithms, this translation provides a way to compile source-level languages to CL.", "authors": ["David Walker", "Karl Crary", "J. Gregory Morrisett"], "n_citation": 132, "references": ["0ded7f08-d0c1-4698-bee1-862a8c676440", "1bf17d1d-52cd-48da-858b-8c9c210b5864", "21d3fc3b-da3e-4b5a-9d72-ac72a15df43b", "23c82e3b-76e3-401a-835b-7b7cc9e708c0", "28b15182-9b07-41ad-b38f-dcf0a7ba85ca", "30ccc8ec-434d-496e-ab40-d669add4041c", "37ec6a09-fd51-494b-b834-080f8ffa8f1d", "396e3eed-ed52-4ca3-9c0d-651015417c9c", "41385c93-631e-468a-a90c-ff4a4ff693f8", "4578b3fa-109f-4b3e-b28f-4adec13403d6", "5268dd27-cea9-4f6e-8d1b-24bff534d700", "53a00e4f-8e46-46a9-b81a-403373d20620", "5fe30513-bd87-4848-8294-4e6e55aab4f8", "68710711-e569-4b5f-a2df-7dbea65d97d3", "7d843c13-cc97-449f-a3ba-05046e7ffa6e", "82aa9af7-36ca-4954-bb20-ab26ee946551", "9076bd34-4562-4817-96bd-0154eb2f047c", "9469dba9-4205-4782-a3d3-b83b86658620", "a59257db-95e5-4bd8-9010-61dd1864c875", "aa44dd48-8e1b-4c0e-b79e-95e3bf683345", "aad2e003-c65c-48d6-9810-f8b6da772f4c", "afef5e47-6b27-47db-96a6-543f1cfba92a", "b4ad266b-6c3e-433d-9820-dbd80307b608", "b826aeb6-49f6-42a8-878b-4b45d69c9fbb", "ccaf455f-7b99-4080-9619-a729e74889b3", "d2778f5c-8986-4f52-b91b-4ec0d23c394c", "d4d2007d-86ad-4de2-ac70-79e070085b51", "d554fbc9-86ff-498c-b2f5-25a41e46488e", "d778f216-81b6-4ced-a2b6-3b1c4fac146b", "d9b4d99b-0f73-4525-aa55-4ac40260f533", "dc0db1bd-ae69-4975-a9d9-3335f994d4c6", "dfbf0164-0416-4728-ad22-37422110ba24", "dfe956b4-b304-497f-8db3-40b2b990282e", "e22b15b4-cf13-46c1-b5b3-f611c8ebfa1b", "e883ae1e-0c54-4fcb-9c38-4165bb0fcc7a", "f10cfb56-1737-4597-87cf-75f35143a3e5", "f80319f9-a53f-46cc-b195-45e605d9c109"], "title": "Typed memory management via static capabilities", "venue": "ACM Transactions on Programming Languages and Systems", "year": 2000, "id": "cea252a9-5f89-40ec-a4c9-9313fc2d2dd5"}
{"abstract": "This article introduces an approach to measures of information granules based on rough set theory. Informally, an information granule is a representation of a multiset (or bag) of real-world objects that are somehow indistinguishable, or similar, or which cause the same functionality. Examples of measures of information granules based on the rough set theory are inclusion, closeness, size, and enclosure. All of these measures are based on rough inclusion. This paper is limited to a consideration of measures of inclusion based on a straightforward extension of classical rough membership functions and closeness based on measurement of separation of equivalence classes in a partition of the universe containing information granules. Measurement of sensor-based information granules has been motivated by recent studies of sensor signals. A sensor signal is a non-empty, finite set of sample sensor signal values temporally ordered. Classification of sensor signals requires measurements of sample signal values over subintervals of time. This article introduces a rough set approach to measuring information granule inclusion and closeness.", "authors": ["James F. Peters", "Zdzis\u0142aw Pawlak", "Andrzej Skowron"], "n_citation": 44, "references": ["0e7f4fcc-b79e-476b-9b7f-1e3265c94090", "390e5133-7a73-4175-abf6-50d2eb6acdf3", "55448f6f-b5b2-4b60-899f-e79341002a80", "66b473fd-99ff-4726-8d3b-3d361c946af0", "90737ab2-d02a-4f11-ad55-05369c3582ab", "937b0abc-f798-4c4a-8fdb-241cef55c716", "c54e20e0-e96a-4de1-8786-63453765b2bf", "ce56fba7-9c45-4273-8e96-bf0bdb3b6268", "e6981920-5615-460a-9f86-d025d3043916", "e7f0e361-9abf-4e1d-9d1f-a7ea20f472a4", "fcc98e9a-934e-4465-9474-af2e81fe3c30"], "title": "A rough set approach to measuring information granules", "venue": "computer software and applications conference", "year": 2002, "id": "da0e5641-1ee5-4420-8d41-2e771d65b410"}
{"abstract": "This paper studies five strategies for storing XML documents including one that leaves documents in the file system, three that use a relational database system, and one that uses an object manager. We implement and evaluate each approach using a number of XQuery queries. A number of interesting insights are gained from these experiments and a summary of the advantages and disadvantages of the approaches is presented.", "authors": ["Feng Tian", "David J. DeWitt", "Jian-Jun Chen", "Chun Zhang"], "n_citation": 247, "references": ["10f7eccc-b21d-4efe-838e-26a817cb150b", "29781bdd-2b53-428c-a7bb-60b2f1805ea1", "3233c7ed-afa3-41e1-877f-2af847d7c8d9", "6edb1438-3585-42da-b220-9ff15fc6a5da", "6f87cc34-22a9-48ca-ab02-1caaea9af8d6", "7aa62859-da2b-412b-b566-c01493aa3e9d", "afa5b89a-b6aa-4682-ac8d-5fd3be29114a", "d0345a49-3916-4287-bc8d-3cd7c21f4038", "d3ee0aa5-26b3-48fc-abe4-318063c65532", "e8951ad4-317c-4303-b015-f77771072168", "ef78330f-d706-48b4-a37d-4a971ab0c1d5", "f6d201d7-21d2-4e38-aa36-fc6de92f160c"], "title": "The design and performance evaluation of alternative XML storage strategies", "venue": "international conference on management of data", "year": 2002, "id": "29a9c138-f05e-42c6-8267-f31417675bb8"}
{"abstract": "Web applications are becoming an essential part of our everyday lives. Many of our activities are dependent on the functionality and security of these applications. As the scale of these applications grows, injection vulnerabilities such as SQL injection are major security challenges for developers today. This paper presents the technique of automatic query sanitization to automatically remove SQL injection vulnerabilities in code. In our technique, a combination of static analysis and program transformation are used to automatically instrument web applications with sanitization code. We have implemented this technique in a tool named ASSIST (Automatic and Static SQL Injection Sanitization Tool) for protecting Java-based web applications. Our experimental evaluation showed that our technique is effective against SQL injection vulnerabilities and has a low overhead.", "authors": ["Raymond Mui", "Phyllis G. Frankl"], "n_citation": 3, "references": ["261a0c04-9996-461b-a136-1d5d8938fffa", "3317d1f5-f673-4847-874a-74861a51294f", "350e165f-d7e9-4e99-8165-a299569d1255", "3f29f1e1-ebc2-4e3a-aad5-e0db58e6057a", "41b2496f-a96c-41c4-b80f-c953132919b7", "46b21104-e2dc-44ac-bce0-f3cb3bf2e38a", "4ccaffc7-de60-438b-83f4-f201a9a21d6f", "5691525e-0309-49a3-9955-6f409375c9d8", "57ec1c8f-e742-4e18-906c-f11d942000da", "63570c22-0a71-4f6d-9c18-bb338e7686c9", "6c68e6ec-2f4d-48ba-a8ab-a64a94da97d8", "819da3e8-bebd-4a36-8991-b51fb011ae43", "8bd2338b-05e6-4755-b224-38aedb86a278", "a3e42847-046f-4464-b329-0568c5a64046", "b083304d-bd9e-40aa-bf50-26a1a7786f09", "cb4c9d52-4670-4de1-b43f-f8ecc202a2b6", "dc93b5f8-777c-40f1-bc3b-5b74d8b99ae7", "de869aee-9206-4d68-9dc0-2cfaf6f4fb36", "ea7f79aa-7225-490c-9b43-5297092903c5"], "title": "Preventing SQL Injection through Automatic Query Sanitization with ASSIST", "venue": "Electronic Proceedings in Theoretical Computer Science", "year": 2010, "id": "f738bcd3-5bc3-435f-8645-565d12e623d6"}
{"authors": ["David Harel", "Amir Pnueli", "Jeanette P. Schmidt", "Rivi Sherman"], "n_citation": 17, "title": "On the Formal Semantics of Statecharts (Extended Abstract)", "venue": "logic in computer science", "year": 1987, "id": "1526d8aa-9219-4b72-a225-7aa64fc11461"}
{"abstract": "We describe a wayfinding system for blind and visually impaired persons that uses a camera phone to determine the user's location with respect to color markers, posted at locations of interest (such as offices), which are automatically detected by the phone. The color marker signs are specially designed to be detected in real time in cluttered environments using computer vision software running on the phone; a novel segmentation algorithm quickly locates the borders of the color marker in each image, which allows the system to calculate how far the marker is from the phone. We present a model of how the user's scanning strategy (i.e. how he/she pans the phone left and right to find color markers) affects the system's ability to detect color markers given the limitations imposed by motion blur, which is always a possibility whenever a camera is in motion. Finally, we describe experiments with our system tested by blind and visually impaired volunteers, demonstrating their ability to reliably use the system to find locations designated by color markers in a variety of indoor and outdoor environments, and elucidating which search strategies were most effective for users.", "authors": ["James M. Coughlan", "Roberto Manduchi"], "n_citation": 59, "references": ["034cfc64-a7a0-4ff8-ac98-17966db4448a", "0607a76d-2dce-4753-bfbc-64ca86c20b0c", "0a5c6445-baf8-4a6a-ba53-a09f3f6af5a3", "0c426d02-bf9f-43b8-83f5-f0c9a8a6a9b0", "1930b4fe-eb53-40ad-9f12-a8a4d510918a", "35bced31-180d-4388-974d-cb5b7f1cb81e", "37a25570-cca2-4268-9485-0c442ecd0237", "56588675-66c1-4761-91ad-f006432e1dce", "636eb285-7d99-4d7e-8f94-a3705638ba9b", "699368fa-17ae-499d-9715-75ee98d678bf", "85472a1b-71d3-4725-962e-a158c185dd2c", "9b83ebc1-acac-4a7b-a68f-cb910b6bea6a", "d3b9f6b8-ff92-49d2-b26b-8f207ae1aefd", "ed3549a2-9b34-4767-81bd-bbd0bb5d4c84", "fec144f2-a2e3-4d2a-a741-d92e59bea803", "fff00346-fad5-4ab2-bc1a-2998cf8414d3"], "title": "FUNCTIONAL ASSESSMENT OF A CAMERA PHONE-BASED WAYFINDING SYSTEM OPERATED BY BLIND AND VISUALLY IMPAIRED USERS", "venue": "International Journal on Artificial Intelligence Tools", "year": 2009, "id": "4fa3d771-b6ae-4649-98ff-e87834c6bb7f"}
{"abstract": "The generation of a 3D CAD model from a set of unstructured points of an unknown 3D object is an important problem of a reverse engineering process that can occur several times within a complete design process chain. Efficient 3D scanning technologies, such as laser range scanning systems become more and more sophisticated. Therefore the representation of 3D objects as a large set of digitized, unstructured point data became a common technique that builds the first step of a reverse engineering process. The main interest of this paper is to explain the further steps of the reverse engineering process, the filtering, clustering and segmentation of the point data and the final surface reconstruction out of point segmentations. This paper is concerned with structuring of point data as a pre-processing before the actual surface reconstruction and with the final surface reconstruction based on a variational design approach considering boundary conditions. First, the focus is set to an algorithm to reduce the data of large point sets. Subsequent a new method for curvature approximation, based on a Delaunay triangulation of the points, is described. By means of curvature discontinuities the points are grouped to represent separate surfaces of the model. After that variational design methods considering boundary conditions to generate the final surfaces from the group of points tangent to earlier created surfaces will be explained.", "authors": ["Hans Hagen", "Siegfried Heinz", "Michael Thesing", "Thomas Schreiber"], "n_citation": 50, "references": ["b4ced62f-8f07-40f5-b7b5-0cf95c76ea7c", "de7a27d9-2d29-4860-9e73-d93095e27cd4", "fbf9aee0-7362-4662-becb-e63b232bcded"], "title": "SIMULATION BASED MODELLING", "venue": "International Journal of Shape Modeling", "year": 1998, "id": "f69df867-c589-4af1-a3a0-cbeb2d316a5d"}
{"abstract": "Ant colony algorithms are a class of metaheuristics which are inspired from the behavior of real ants. The original idea consisted in simulating the stigmergic communication, therefore these algorithms are considered as a form of adaptive memory programming. A new formalization is proposed for the design of ant colony algorithms, introducing the biological notions of heterarchy and communication channels. We are interested in the way ant colonies handle the information. According to these issues, a heterarchical algorithm called \"Continuous Interacting Ant Colony\" (CIAC) is designed for the optimization of multiminima continuous functions. CIAC uses two communication channels showing the properties of trail and direct communications. CIAC presents interesting emergent properties as it was shown through some analytical test functions.", "authors": ["Johann Dr\u00e9o", "Patrick Siarry"], "n_citation": 198, "references": ["3d0fa0ea-c769-4f69-a278-060da7222cc9", "471ee6f8-45f8-4a08-abb8-74ffa7fc76b2", "4bc7f5ec-cd57-4ad0-9524-4c8b48a4ec8c", "675525e3-866a-4414-b4f6-4a77bfcc4054", "749978b7-ab2f-42e2-a96a-ab6950117020", "89880efb-e88b-4892-a295-0f8dd24c23e5", "9a7247d7-a53f-4dfb-b10b-0d005411b9a2", "ceeedf74-d74a-4d09-8f44-2fab5922459f", "e4b468aa-2b23-4229-8872-f9286464a19f"], "title": "Continuous interacting ant colony algorithm based on dense heterarchy", "venue": "Future Generation Computer Systems", "year": 2004, "id": "68c07db4-30f3-4241-a7ff-b755b6e99f6a"}
{"abstract": "In this paper a method is proposed for locating horizontal, uniform-colored text in video frames. It was observed that when a row of pixels across such a text region is clustered in perceptually uniform L*a*b* color space, the pixels of one of these clusters would belong to the text strokes. These pixels would appeal as a line of short streaks on the row since a typical text region has many vertical and diagonal strokes. The proposed method examines every third row of the the image and checks whether this row passes through a horizontal text region. For a given row R, the pixels of R are hierarchically clustered in L*a*b* space and each cluster is tested whether similar-colored pixels in R's vicinity are possibly part of a text region. Candidate text blocks are marked by heuristics using information about the cluster's line of shell streaks. The detected text blocks are fused with the text regions. The method was tested on key frames of several video sequences and was able to locate a wide variety of text.", "authors": ["Vladimir Y. Mariano", "Rangachar Kasturi"], "n_citation": 116, "references": ["0236a0e6-0bc9-44d6-af14-9fe30e797bc8", "4967f7dd-4787-4ac3-9520-6e8c76e5fa5b", "54bb1a06-55c2-4782-b7f4-23c244ac6fa3", "60ae83a8-c764-411f-a49d-87950fc7f59b", "66f900bd-8503-4490-bc8a-ecb53ab616c0", "99c0bb7b-8c56-4931-bb08-2988387c3cd4"], "title": "Locating uniform-colored text in video frames", "venue": "international conference on pattern recognition", "year": 2000, "id": "29690834-e63a-4021-9339-98a976ef7827"}
{"abstract": "Applications require the composition of resources to execute in a grid computing environment. The grid service providers (GSPs), the owners of the computational resources, must form virtual organizations (VOs) to be able to provide the composite resource. We consider grids as self-organizing systems composed of autonomous, self-interested GSPs that will organize themselves into VOs with every GSP having the objective of maximizing its profit. Using game theory, we formulate the resource composition among GSPs as a coalition formation problem and propose a framework to model and solve it. Using this framework, we propose a resource management system that supports the VO formation among GSPs in a grid computing system. Copyright \u00a9 2008 John Wiley & Sons, Ltd.", "authors": ["Thomas E. Carroll", "Daniel Grosu"], "n_citation": 30, "references": ["0df5662c-f2f5-4abe-a6f2-ca2d8feabb80", "14dba817-d309-49de-92e4-ab07d89a2342", "178658bb-4903-4c05-9283-d00a53e9b842", "1879b8c4-1633-40ac-a4f2-5c4680a085cb", "1d547c2f-2014-4d32-aebd-c8a32a5bede1", "1e573014-c071-423d-9f79-0e8e20d60331", "2c300f15-cdba-4938-b196-f17e792a4393", "2f9706c1-bb27-46e4-a75f-d352298a7b69", "34458101-945a-4755-ac08-378082250203", "40e179cf-6346-4eee-8267-9c70b2298cf7", "493fd722-ed06-4a05-a44d-0fd76cfcacbd", "5aaa9bda-2c35-4eaa-a804-b54a15662ada", "5d53c6f5-5160-4345-a58b-9426d8ce39a9", "73a705c9-2561-4927-90eb-f7928a0e7fb7", "7cc0e762-2e36-4548-aabd-c0f2495263c5", "8f18db81-b778-40e6-a891-695556dda50e", "a79a8af4-9c49-4e19-808b-159601aeecbf", "a8a04d10-0b1e-431e-85c2-92029cf12bbc", "a8f1fc9a-aff6-4b47-b956-eebbce871383", "ac36f63f-798b-42f3-b546-e42ca52fd118", "ba20e06b-0b7e-4455-828a-cc4dbbac177d", "bdf73ff6-cab8-4722-bb21-cd6eb39a0bea", "c2f67467-3138-4d37-a743-10340dc3ea44", "ce98dec1-6cc2-44ad-a511-63130f48144e", "d1a911fc-ff2a-4f43-8878-2266a1ddbf6b", "d547f1cd-f8bc-44f3-916f-2feb4195ed66", "f36a8af1-70e0-4999-a83b-61bbfc982759", "f4d5fd52-2e17-4a80-871a-b37d29f7de94", "f63d3a8d-5fbc-4ffa-a9cb-5d288709a007", "f64f9442-fdbb-4516-ab4b-6b258b5d1448"], "title": "Formation of virtual organizations in grids: a game-theoretic approach", "venue": "Concurrency and Computation: Practice and Experience", "year": 2010, "id": "5df27c19-e4c5-451a-93d0-ee982ed4b692"}
{"abstract": "This paper describes jMetal, an object-oriented Java-based framework aimed at the development, experimentation, and study of metaheuristics for solving multi-objective optimization problems. jMetal includes a number of classic and modern state-of-the-art optimizers, a wide set of benchmark problems, and a set of well-known quality indicators to assess the performance of the algorithms. The framework also provides support to carry out full experimental studies, which can be configured and executed by using jMetal's graphical interface. Other features include the automatic generation of statistical information of the obtained results, and taking advantage of the current availability of multi-core processors to speed-up the running time of the experiments. In this work, we include two case studies to illustrate the use of jMetal in both solving a problem with a metaheuristic and designing and performing an experimental study.", "authors": ["Juan Jos\u00e9 Durillo", "Antonio J. Nebro"], "n_citation": 543, "references": ["05e92963-11be-4e9a-b4b6-b4b7aca59d4b", "1c210c0f-f07a-4fb4-93d6-4e053ef1b33e", "23dc6e53-9579-4198-bb00-dedfd3e6071b", "4e0ec5cc-3523-44cc-9c8e-1616c2c42a82", "4fb54171-f2d0-428a-a826-43a7a5d0d9a8", "516632de-65d2-4342-b358-3c154de44776", "5f17f6ee-c355-4045-a50e-f850d16c6d2e", "5ff9f99a-a731-4dd6-b011-f517d96c477c", "65d5ccdc-7022-45b0-adf9-0385273b1283", "67b87e9e-53b4-47e2-b025-76f9aa4ac2a7", "6cc8c9bb-0b17-401e-bc56-a5a17851ee7b", "80003792-b1c6-4847-834b-19a1de13bb12", "8666d3c4-737c-48ef-b1bd-a65206527ba9", "9136eff9-442d-4221-a12f-e2b1ff808472", "9ed7f67d-071f-4468-a376-e96ff52c71dd", "a17a4d03-e986-4243-8f75-fee72331f096", "a9ba46f3-66be-4f83-a506-eccb93fbdd15", "b13ca83a-21cb-459d-8e16-ee29b631f156", "b5bdaccd-d49b-4be6-82d3-c1cfce8b8d2b", "b7fc7c62-b922-4f8d-abd6-a14239e6fbbd", "c8640b3d-1916-488f-b7f6-6ba7257ffe40", "cb890ff0-2b26-4afb-8635-ac7bfe30cefa", "cec0b0d5-1bdc-4c06-974e-2bde755bb417", "cfb4099e-1848-48dd-b38a-63a59b5c7c9e", "d23dbc85-2a9c-4fcd-8efe-33b8c4cf9f2c", "d745a597-7a3f-4307-90a8-e5ef006d9fe8", "e21e99df-9cc9-4ba8-b21f-c40f94581480", "fae230b4-8ee6-45eb-ba9f-9861be9c1cd5", "faf9b9e7-a6e4-4124-a9f4-3b719ee465ac", "fc6bd7c6-6849-4a38-bea4-5a647032ee0e"], "title": "jMetal: A Java framework for multi-objective optimization", "venue": "Advances in Engineering Software", "year": 2011, "id": "485ac84a-abf3-4f57-895a-41ff8782476d"}
{"abstract": "Software system documentation is almost always expressed informally, in natural language and free text. Examples include requirement specifications, design documents, user manual pages, system development journals, error logs and related maintenance reports. We propose an approach to establish and maintain traceability links between the source code and free-text documents. A premise of our work is that programmers use meaningful names for program's items, such as functions, variables, types, classes and methods. We believe that the application domain knowledge that programmers process when writing the code is often captured by the mnemonics for identifiers; therefore, the analysis of these mnemonics can help to associate high-level concepts with program concepts, and vice versa. In this paper, the approach is applied to software written in an object-oriented (OO) language, namely C++, to trace classes to manual sections.", "authors": ["Giuliano Antoniol", "Gerardo Canfora", "A. De Lucia", "Ettore Merlo"], "n_citation": 63, "references": ["1ed69bc1-4c53-4085-af2e-0c7f189fcfaa", "27e5463b-3434-4db1-8194-3954a4fe47a5", "33825089-9ef5-42d3-9858-e918e33ef35c", "34a38a33-f26b-49ad-8589-7755f174e7ed", "38d28e05-02cb-4df2-809e-fbf5f6cfd900", "3b6770f9-09e3-4c0d-b2e9-ef7ada3f0878", "3c3ce1cf-8c7a-444c-82d8-b428963784e6", "4aafeefd-c5fb-4baf-8fac-0acde02f070c", "52e819e5-3725-4e5f-b397-738ffb367a9d", "53cfa569-cb85-4302-8b9e-7f62ed11933c", "54b9d4ca-0de5-44ae-87bf-ec741c5ce708", "5aa08010-8153-4d31-bb7c-cfd190bf3ffa", "65e9d883-cc87-4505-ab64-99a181371d6f", "7dace715-2430-48c2-9eca-f8729f128a08", "93928962-ce82-4490-b203-d829a9313b27", "9428951d-0b21-4947-8710-45b5ce73de79", "b75c0b61-7d06-4587-be47-10ca339751c8", "d5020036-d0b6-4542-960f-d55bc33a30ad", "dbda5440-1d8d-4c18-b2cf-bbc1bd385537", "e1cfb778-f574-40a4-a00c-5f7655102451", "e7165054-f2e3-47d8-83af-bdc7f720057b"], "title": "Recovering code to documentation links in OO systems", "venue": "working conference on reverse engineering", "year": 1999, "id": "b014ee14-69b1-434d-8d42-204ee437e768"}
{"abstract": "Given some integrity constraints over a distributed database, we consider the problem of incrementally checking global consistency in response to updates made to the base relations but without accessing all these base relations. In many application areas such as collaborative design, mobile computing and enterprise information systems, total data availability cannot be assumed. Even if all the base data is available, some of it may incur such a high cost that its use should only be considered as a last resort. Without looking at all the relations that participate in the constraint, how can one meaningfully check a constraint for violation? When the constraint is known to be satisfied prior to the update, the state of the relations that are available (aka local) can in principle be used to infer something about the relations that are not available (aka remote). This observation is the basis for the existence of tests that guarantee that global consistency is preserved under a given update, without looking at all the base data. In order to make consistency maintenance practical, the challenge is to find those tests that are most general (we call Complete Local Tests) and that are efficient to generate and execute. This paper addresses the problem of finding efficient complete local tests for an important class of constraints that are very common in practice: constraints expressible as conjunctive queries with negated subgoals. For constraints where the predicates for the remote relations do not occur more than once, we present complete local tests under insertions and deletions to the local relations. These tests can be expressed as safe, nonrecursive Datalog \u00ac queries against the local relations. These results also apply to other constraints with negation that are not conjunctive.", "authors": ["Nam Huyn"], "n_citation": 50, "references": ["097f0990-d133-4998-b517-805529ac8010", "2f456e5b-5ee1-4aa8-9391-e1291bd4dec7", "48ea2f5d-4926-45d6-be03-2ba1257e0237", "b04c4a51-6a70-42e0-8ce3-c4692f342c6a", "b3e9295b-0c05-4128-a8ef-0296f6d8c2d7", "da492321-8f70-42ba-ac56-45336d136f79"], "title": "Maintaining global integrity constraints in distributed databases", "venue": "Constraints - An International Journal", "year": 1998, "id": "9ed0c084-8ac9-41e0-b250-61fb64df373f"}
{"abstract": "Fast routing lookups are crucial for the forwarding performance of IP routers. Longest prefix match makes routing lookups difficult. This paper proposes a method to partition a routing table. The method can divide all prefixes in a routing table into several prefix sets where prefixes don't overlap. Based on the method, this paper also presents a common parallel lookup framework(PRLF) that reduces longest prefix matching in all the prefixes to only prefix matching in several prefix sets. The framework can effectively simplify the design of lookup algorithms and improve lookup performance. The framework is suitable for most lookup algorithms. For simple binary search algorithm, the framework can reach log 2 2N/B lookup complexity (where N is prefix number in a routing table and B is an integer bigger than 4). Also, the framework can scale to IPv6 easily.", "authors": ["Zhiyong Liang", "Ke Xu", "Jianping Wu"], "n_citation": 50, "references": ["0a50a0a9-439e-43c0-aaa3-561fce1cd16f", "56fad217-58da-4f8a-8898-dc293ebc2002", "6f3cb7b2-d813-466e-8907-ed9a4761b403", "8aecb3cd-988c-437f-9286-3db1feff44b6", "9d966424-58e9-4501-9fd1-9f3c8bc967a1", "ae941637-b658-4a15-be8d-f32109e5f510"], "title": "A Scalable Parallel Lookup Framework Avoiding Longest Prefix Match", "venue": "international conference on information networking", "year": 2004, "id": "eeb4dcb3-415e-49ad-b53c-26cb890cd281"}
{"abstract": "This paper represents a Particle Swarm Optimization (PSO) algorithm, for grid job scheduling. PSO is a population-based search algorithm based on the simula- tion of the social behavior of bird flocking and fish schooling. Particles fly in problem search space to find optimal or near-optimal solutions. In this paper we used a PSO ap- proach for grid job scheduling. The scheduler aims at minimizing makespan and flow- time simultaneously. Experimental studies show that the proposed novel approach is more efficient than the PSO approach reported in the literature.", "authors": ["Hesam Izakian", "Behrouz Tork Ladani", "Kamran Zamanifar", "Ajith Abraham"], "n_citation": 74, "references": ["125c9fb0-67f8-4ed8-a4ae-ae4d2efc2ded", "46aea81a-b9bc-47b6-a5e1-be8f8e795f22", "4cbbce9b-bbc3-46ea-86b8-76eabee9b862", "82836326-5b69-4135-b2fc-d1c5745148e7", "a112175d-a5bd-4ae4-8fd2-0eb4b3a89a22", "bd297839-add8-42ab-8e12-83514f0d128f", "bf6dfdca-328f-4b17-b658-78959121290d", "c2f67467-3138-4d37-a743-10340dc3ea44", "c754e4e7-d674-4d9a-b1e7-10b829f2583f", "d73b204f-a1b7-4d42-9d09-3454ca71e7b9", "e96d59f1-7075-4b91-9cb3-8938829a7e42"], "title": "A Novel Particle Swarm Optimization Approach for Grid Job Scheduling", "venue": "international conference on information systems", "year": 2009, "id": "f502bd24-b4f7-4fa4-8a5b-8c0db5ed5495"}
{"abstract": "The paper reports on research concerned with learners' uses of mobile technologies based on an international survey that targeted students registered in selected master's and doctoral programmes in Australia, Hong Kong, Portugal, Sweden, and the United Kingdom. The survey findings were enriched by local knowledge, as the authors administered questionnaires in their own countries. The research gives an account of uses of handheld devices by students from departments of education, educational technology, engineering, and information technology in the domains of learning, work, social interaction and entertainment. The paper illuminates learners' choices in the midst of evolving social practices, and challenges the common preconception that mobile devices are not suitable for academic study. In today's global education marketplace, educators must know the technology habits and expectations of their students, including those from other countries. Knowing about students' previous practices and the techno-cultural setting they come from can help institutions determine what mobile applications are most appropriate to support learning.", "authors": ["Agnes Kukulska-Hulme", "Ana Am\u00e9lia Amorim Carvalho", "David M. Kennedy", "John Pettit", "Linda Bradley", "Anthony Herrington", "Aisha Walker"], "n_citation": 77, "references": ["01d3f80e-481a-4d6f-8771-d8e27c669569", "85d4f337-a03f-45dd-bc3f-caa4a3a2d12a", "ce66548b-9860-43ec-8e9b-3f14ca7bfa01", "f1a718a2-e170-4cef-a84e-a19f82c8f387"], "title": "Mature Students Using Mobile Devices in Life and Learning", "venue": "International Journal of Mobile and Blended Learning", "year": 2011, "id": "f9da919a-0fb0-4945-967b-bff49d56e7c9"}
{"authors": ["Henning Dierks"], "n_citation": 110, "references": [], "title": "PLC-Automata: A New Class of Implementable Real-Time Automata", "venue": "algebraic methodology and software technology", "year": 1997, "id": "96c9c655-4849-4fa8-bb8c-c0da659a634e"}
{"abstract": "NASA/JPL's Mars exploration rovers acquire their attitude upon command and autonomously propagate their attitude and position. The rovers use accelerometers and images of the sun to acquire attitude, autonomously searching the sky for the sun with an articulated camera. To propagate the attitude and position the rovers use either accelerometer and gyro readings or gyro readings and wheel odometry, depending on the nature of the movement Earth-based operators have commanded. Where necessary, visual odometry is performed on images to fine tune the position updates, particularly in high slip environments. The capability also exists for visual odometry attitude updates. This paper describes the techniques used by the rovers to acquire and maintain attitude and position knowledge, the accuracy which is obtainable, and lessons learned after more than one year in operation.", "authors": ["Khaled S. Ali", "Charles A. Vanelli", "Jeffrey J. Biesiadecki", "Mark W. Maimone", "Yang Cheng", "A.M. San Martin", "James W. Alexander"], "n_citation": 89, "references": ["3287734b-d7f9-409e-b759-f15755626a1c", "65e3edbd-5e38-4e08-96c2-5c3936405447"], "title": "Attitude and position estimation on the Mars exploration rovers", "venue": "systems, man and cybernetics", "year": 2005, "id": "3626cb34-c075-4601-a8f5-a0723cfb10bb"}
{"abstract": "Terminal sliding-mode (TSM) control (TSMC) is known for its high gain property nearby the vicinity of the equilibrium while retaining reasonably low gain elsewhere. This is desirable in digital implementation where the limited sampling frequency may incur chattering if the controller gain is overly high. In this paper, we integrate a linear switching surface with a terminal switching surface. The switching surface can be designed according to the precision requirement, and for the first time, real-time implementation of TSM is carried out. The analysis and experimental investigation show that the TSMC design outperforms the linear sliding-mode control.", "authors": ["Khalid Abidi", "Jian-Xin Xu", "Jin-Hua She"], "n_citation": 54, "references": ["08c78d4e-8b1c-4f67-bdc6-6033da06c27f", "26230d0b-fa29-4f38-b345-62f0ec843cea", "3986e6b5-5a21-407d-90f0-263a4da39b55", "40f9a850-ff92-4f76-8aeb-c89d7fb74f90", "4dea69fb-b7e1-4f9d-abca-f1c4d4432882", "5f415b27-64c8-47a5-95cf-7fad70683444", "a0df2d2a-1d96-40a3-bc43-161ec33eb76c", "c39ff2b3-6a53-49b7-bc55-0c5a7cca2185", "ebb6436f-f2c9-4f4c-ab82-7be500e47609"], "title": "A Discrete-Time Terminal Sliding-Mode Control Approach Applied to a Motion Control Problem", "venue": "IEEE Transactions on Industrial Electronics", "year": 2009, "id": "30036d8b-3f4c-40e9-a23a-8d114ae8a4e5"}
{"authors": ["W. Kevin Wilkinson", "Marie-Anne Neimat"], "n_citation": 85, "references": ["071567c1-6198-4cce-a8b8-7abeb129c3c3", "22914df1-2a1f-492a-862f-e8d2c4139b89", "3248234c-4da7-40d1-826c-37243b08ac3d", "5db4a470-6f3e-4512-a763-959395b932ab", "670c2a3e-5e72-44fb-acdf-73efdaca2acb", "9c45cf69-2577-4982-a362-64a3ec3df9db", "bfc29e94-bfd4-4ad0-ab8a-2dd6755d42a5", "c1d237d0-29d6-43e0-82c4-639178604f46", "d1203728-03b5-462a-b08d-06e7b3a9a00a"], "title": "Maintaining Consistency of Client-Cached Data", "venue": "very large data bases", "year": 1990, "id": "d5f3df05-86dd-4634-9c92-a3a0b142aa64"}
{"abstract": "This paper proposes a novel approach to constructing a hierarchical representation of visual input that aims to enable recognition and detection of a large number of object categories. Inspired by the principles of efficient indexing (bottom-up,), robust matching (top-down,), and ideas of compositionality, our approach learns a hierarchy of spatially flexible compositions, i.e. parts, in an unsupervised, statistics-driven manner. Starting with simple, frequent features, we learn the statistically most significant compositions (parts composed of parts), which consequently define the next layer. Parts are learned sequentially, layer after layer, optimally adjusting to the visual data. Lower layers are learned in a category-independent way to obtain complex, yet sharable visual building blocks, which is a crucial step towards a scalable representation. Higher layers of the hierarchy, on the other hand, are constructed by using specific categories, achieving a category representation with a small number of highly generalizable parts that gained their structural flexibility through composition within the hierarchy. Built in this way, new categories can be efficiently and continuously added to the system by adding a small number of parts only in the higher layers. The approach is demonstrated on a large collection of images and a variety of object categories. Detection results confirm the effectiveness and robustness of the learned parts.", "authors": ["Sanja Fidler", "Ales Leonardis"], "n_citation": 223, "references": ["20f52431-62f1-4670-ba81-d19ef3c04204", "3843d2db-d96f-47be-8ece-fa9c1e87d1bc", "3871db29-4ce5-4ab0-a1fa-4bb93d04e88d", "613841ae-c925-4aee-9c2e-8675213e4bbf", "7d48df04-8ba0-4f2a-8422-adc65405094c", "a899908d-d5d1-4616-a6f9-3a9f4dfc5460", "b2286f1f-27f8-441b-9a79-5695e21f30eb", "ba38b975-adf1-4985-ac18-f62989940055", "c17b4778-a9d9-4213-8967-c5e8ed708ea0", "c38cebd1-1503-4321-ab02-28712487b9d3", "ccb2e49a-c329-49c3-ae97-46637bb02220", "e05a6676-6e91-466e-b705-19e19b66e5a2", "e7005d3a-7bbb-46f1-a84b-50d110ddee6e", "f1bd37c4-d033-4cd1-af44-4df9f11c71e4"], "title": "Towards Scalable Representations of Object Categories: Learning a Hierarchy of Parts", "venue": "computer vision and pattern recognition", "year": 2007, "id": "a7621af4-d387-4134-912b-33c00ec0db32"}
{"abstract": "A new studio system for the production of three-dimensional (3-D) content is introduced. The system combines the ability to capture dynamic scenes, based on a multicamera system in a chroma-key environment, with a view-dependent projection for actor feedback. The system allows the generation and rendering of 3-D models in preview quality for on-set visualization in real time and in high quality for postproduction applications in an offline phase. The shape reconstruction is based on the computation of the visual hull. The view-dependent projection component allows actors to be immersed into a virtual scene and to interact with virtual components. The functional modules of the system were implemented in a highly distributed system using standard, inexpensive IT components. Therefore, the system is quite scalable and can be fitted into most studio environments. For the integration of the system components, a middleware architecture was developed.", "authors": ["Oliver Grau", "Tim Pullen", "Graham Thomas"], "n_citation": 87, "references": ["24170bb8-5094-46c4-a2e2-2d13475a3d04", "318a112e-0a86-4729-8605-200e06a2d6bd", "33f65f88-38e9-443b-a32b-e36abe1d121c", "60985c9a-ca14-4324-882d-95cedabefdeb", "8b83360d-e0b4-4e14-a275-0d75a243c30c", "9afd7e3d-4320-4ba6-ab20-2c6cf099d997", "9c426c05-ad28-40d9-9a0b-01a470484681", "9cb15c77-d815-4d11-92cd-1631697d8d97", "a258304b-f9ba-42d1-aba1-389ab47b869d", "c0ba5d0d-89e3-4274-be9f-e59ad601f0e5", "e33854dd-49a1-43e5-ae91-01c16c09a19c"], "title": "A combined studio production system for 3-D capturing of live action and immersive actor feedback", "venue": "IEEE Transactions on Circuits and Systems for Video Technology", "year": 2004, "id": "b4154a3d-4d0b-4ce4-853e-d82b7b9446cf"}
{"abstract": "There are several aspects involved in supporting human cooperative work by computers. One of them concerns team awareness to avoid unnecessary effort or even chaos. Notification services provide suited information about other team members and team relevant events. Traditionally, such services are realized by a central or distributed approach but exhibit shortcomings with respect to filtering policies and mobility of notified participants. A third alternative consists in applying mobile software agents. In this case, each participant is represented by one immobile and a number of mobile agents. The immobile agent manages all events that are caused by its user. Mobile agents are responsible to observe events being caused by other team members. They communicate either remotely or locally with managers of their partners. Advantages and disadvantages of all possible mechanisms are discussed.", "authors": ["Cora Burger"], "n_citation": 7, "references": ["2e29a1cc-fcdf-4843-9828-51074a85e551", "36cac293-ee33-4c1a-a9c7-0787a7c37bb0", "3ea45d97-ef88-4f03-b5ad-16fe9f2f5e1e", "4884ee9a-dd5f-4204-ad73-11a3f2af2285", "5c12901d-1da5-43b1-bbcc-8fd9fe83fe4d", "69a61375-719c-4e1d-8d37-4d1908a46c97", "b75c31b4-53d4-4f73-a4ea-734e7ee023e3", "d6e944ff-550c-44a6-b069-61704fd8f5c5", "fd51d78a-e2f5-46b6-b041-4dae9aebdc76"], "title": "Team awareness with mobile agents in mobile environments", "venue": "international conference on computer communications and networks", "year": 1998, "id": "b8cb3475-78fa-47bb-8eb6-560b2d6f98fb"}
{"abstract": "Developers often use replication and caching mechanisms to enhance Web application performance. The authors present a qualitative and quantitative analysis of state-of-the art replication and caching techniques used to host Web applications. Their analysis shows that selecting the best mechanism depends heavily on data workload and requires a careful review of the application's characteristics. They also propose a technique for Web practitioners to compare different mechanisms' performance on their own", "authors": ["Swaminathan Sivasubramanian", "Guillaume Pierre", "M. van Steen", "Gustavo Alonso"], "n_citation": 168, "references": ["07c5f2e6-f53b-4615-8f9b-9c9ee5becdc6", "54c22819-253a-45cb-ad5f-1dcf9f8233e3", "571719c8-ba29-4808-8990-a64222bd9289", "923a0bd0-fe84-4767-825c-2a5059847e0a", "9c0df26f-4b87-4447-9c0c-f472d111d2fc", "a04e128a-1e8b-4387-ba23-872b5f1856e2", "f2d34fe5-9158-4b3b-8909-d10fb755e668"], "title": "Analysis of Caching and Replication Strategies for Web Applications", "venue": "IEEE Internet Computing", "year": 2007, "id": "45b11890-5b98-4551-bdd6-db9a4d646626"}
{"abstract": "This report compares the performance of different computer systems in solving dense systems of linear equations. The comparison involves approximately a hundred computers, ranging from a CRAY Y-MP to scientific workstations such as the Apollo and Sun to IBM PCs.", "authors": ["Jack Dongarra"], "n_citation": 966, "references": ["30577785-43de-4a11-b5f8-d460cd2944ec", "473def2e-0f6b-4076-9b68-7ea40eafcf42", "be50e11a-eb55-4b2e-857b-40766b8a9754"], "title": "Performance of various computers using standard linear equations software", "venue": "ACM Sigarch Computer Architecture News", "year": 1990, "id": "df26516f-9978-454d-ae2d-ae0ff4df4a20"}
{"abstract": "An approach is presented for planning sensing strategies dynamically on the basis of the system's current best information about the world. The approach is for the system to propose a sensing operation automatically and then to determine the maximum ambiguity which might remain in the world description if that sensing operation were applied. The system then applies that sensing operation which minimizes this ambiguity. To do this, the system formulates object hypotheses and assesses its relative belief in those hypotheses to predict what features might be observed by a proposed sensing operation. Furthermore, since the number of sensing operations available to the system can be arbitrarily large, equivalent sensing operations are grouped together using a data structure that is based on the aspect graph. In order to measure the ambiguity in a set of hypotheses, the authors apply the concept of entropy from information theory. This allows them to determine the ambiguity in a hypothesis set in terms of the number of hypotheses and the system's distribution of belief among those hypotheses. >", "authors": ["Seth Hutchinson", "Robert L. Cromwell", "Avinash C. Kak"], "n_citation": 240, "references": ["02439fda-afba-4721-8ead-8494ee4d2dac", "0e97d4ea-beb2-4caa-b672-8e210908b85b", "105abed2-da9d-41b5-85c5-76fa050b050b", "2975e2bd-522d-4656-bdf4-dc3d48dd6ac2", "39536116-298e-4111-a0cc-de46bbc96632", "3a7e40fe-02c9-4546-a452-9bb3e171f845", "46f3db05-4252-4eb6-90c9-89510bc478eb", "5571a5c6-91e2-4a3e-abb3-6ee1919b89cf", "771f7972-410a-4a26-8399-1ed88893e8f1", "b147bf91-c249-4240-885a-b2ae4077383a", "cb6f553c-e118-4375-af4e-834d1929cbca", "f29b01a5-db9b-4817-a306-65e2b343b492", "f95863d0-cb40-43a6-9e15-2eb0be33efc7", "ff194947-12f2-43a6-8734-59d12a809ee4"], "title": "Planning sensing strategies in a robot work cell with multi-sensor capabilities", "venue": "international conference on robotics and automation", "year": 1988, "id": "ff4ee980-9544-4fa9-8964-0c880ecabdfb"}
{"abstract": "Face-to-face collaboration of small groups is one of the most common forms of group work, yet group-aware computer support for this type of collaboration is limited. My research examines the effectiveness of Single Display Groupware (SDG), computer systems that support face-to-face collaboration around a single computer display. Together with the help of a group of elementary school children, I will design and build a prototype SDG system called Sushi that is an authoring tool for interactive multimedia stories.", "authors": ["Jason Edward Stewart"], "n_citation": 51, "references": ["03654385-d6b8-469c-8478-3db32b5e2f60", "16bacc74-0f92-41fa-a048-feb87b8f849b", "2bcef527-5dfd-417d-8702-927fe91f9226", "2c4141e9-f672-41c5-8e70-6451d3781e68", "2fd8012e-dddc-4cfa-afac-4660e0f534b5", "397aa984-d831-47e3-9913-c894434754fe", "4dbc854e-bf76-4875-b80e-4b78d8e86b02", "5fab7aac-4a4b-44e4-b91b-aa01a4a3db35", "6920f293-bb7e-48a9-9da2-3c1e04110c5c", "945f0b08-9113-453c-bba0-366b4b579365", "959ceb33-4297-418a-925f-51b2682e7d3a", "abd81793-c353-4d6d-9c20-4f0ac0928149", "c0237746-e729-4f3d-84fb-c04f5e31d295", "c326607a-aada-4a8d-9bfe-337448220c13", "ec621434-ace7-47f0-ad22-7c9ca1c8af95", "f08a755a-f174-4041-bec0-ac43bbe31072", "f6888287-69c4-4cbe-896d-7eb63901ef67", "f7911798-787d-4f07-9cef-f652c99ec49e"], "title": "Single display groupware", "venue": "human factors in computing systems", "year": 1997, "id": "965c691d-c927-4030-a41c-02234e73c4e9"}
{"abstract": "Encoding of sensory events in internal states of the brain requires that this information can be decoded by other neural structures. The encoding of sensory events can involve both the spatial organization of neuronal activity and its temporal dynamics. Here we investigate the issue of decoding in the context of a recently proposed encoding scheme: the temporal population code. In this code, the geometric properties of visual stimuli become encoded into the temporal response characteristics of the summed activities of a population of cortical neurons. For its decoding, we evaluate a model based on the structure and dynamics of cortical microcircuits that is proposed for computations on continuous temporal streams: the liquid state machine. Employing the original proposal of the decoding network results in a moderate performance. Our analysis shows that the temporal mixing of subsequent stimuli results in a joint representation that compromises their classification. To overcome this problem, we investigate a number of initialization strategies. Whereas we observe that a deterministically initialized network results in the best performance, we find that in case the network is never reset, that is, it continuously processes the sequence of stimuli, the classification performance is greatly hampered by the mixing of information from past and present stimuli. We conclude that this problem of the mixing of temporally segregated information is not specific to this particular decoding model but relates to a general problem that any circuit that processes continuous streams of temporal information needs to solve. Furthermore, as both the encoding and decoding components of our network have been independently proposed as models of the cerebral cortex, our results suggest that the brain could solve the problem of temporal mixing by applying reset signals at stimulus onset, leading to a temporal segmentation of a continuous input stream.", "authors": ["Kn\u00fcsel P", "Reto Wyss", "Peter K\u00f6nig", "Paul F. M. J. Verschure"], "n_citation": 25, "references": ["1955d2b2-f190-4129-b95f-7da445b4c868", "666d36f9-3465-491e-b55e-7d8aa5f0358a", "78b9bee0-6db6-4fb4-9c1f-4a86e549f742", "eb90e4bd-76bb-48fd-94f5-5208e896127a"], "title": "Decoding a Temporal Population Code", "venue": "Neural Computation", "year": 2004, "id": "a2bc29a3-043d-4011-8626-ecf6466b39ee"}
{"abstract": "Programmers who need high performance currently rely on low-level, architecture-specific programming models (e.g. OpenMP for CMPs, CUDA for GPUs, MPI for clusters). Performance optimization with these frameworks usually requires expertise in the specific programming model and a deep understanding of the target architecture. Domain-specific languages (DSLs) are a promising alternative, allowing compilers to map problem-specific abstractions directly to low-level architecture-specific programming models. However, developing DSLs is difficult, and using multiple DSLs together in a single application is even harder because existing compiled solutions do not compose together. In this paper, we present four new performance-oriented DSLs developed with Delite, an extensible DSL compilation framework. We demonstrate new techniques to compose compiled DSLs embedded in a common backend together in a single program and show that generic optimizations can be applied across the different DSL sections. Our new DSLs are implemented with a small number of reusable components (less than 9 parallel operators total) and still achieve performance up to 125x better than library implementations and at worst within 30% of optimized stand-alone DSLs. The DSLs retain good performance when composed together, and applying cross-DSL optimizations results in up to an additional 1.82x improvement.", "authors": ["Arvind K. Sujeeth", "Tiark Rompf", "Kevin J. Brown", "HyoukJoong Lee", "Hassan Chafi", "Victoria Popic", "Michael Wu", "Aleksandar Prokopec", "Vojin Jovanovic", "Martin Odersky", "Kunle Olukotun"], "n_citation": 56, "references": ["066b0e85-69db-4244-ac9d-c0503350907a", "14d79116-53b0-48ba-ab2f-fec59555cfaf", "1773716d-17f6-4ac3-9adf-69ee5ef23c78", "1a1fdf30-825a-42f8-991f-80bceaf62489", "1d2af9d2-4474-4145-b282-e626790506d4", "1f0f36c9-27a5-4426-b222-0237640c1b76", "1f4501e1-d1e0-43a4-9158-34e45045067f", "3454d34f-86a8-4d26-a22f-8f04d4bbcd73", "36f339f1-3e52-4417-b4d8-a349c33f8127", "3f1f6984-bf71-459a-9979-1f5e828a7a41", "4f736331-4663-4b8b-8317-c04c59b32a25", "579448c6-b1da-44c0-8242-7beccb8c2ae3", "7183aef1-9742-49a7-bd4b-8b9f2ea194a3", "72d4e713-0cea-4982-b6d0-564f0a8cdeec", "736f9f95-b782-4db5-ad4f-19a50e896056", "792f50fb-081c-4715-b47f-37ca51b5d1d2", "8400b70c-377d-49eb-96f2-bc2d64168fe1", "8a0a53d8-bf21-486a-b3a6-39883a17443e", "8e160dc7-81c3-446a-a744-2d0fa13bc615", "98fb878a-5b81-4634-90e8-116446f28cfb", "a5dcd817-7530-4521-900f-d6d89097fe58", "ac103c8b-c10f-41f7-8f98-66353749800a", "af84a339-e8dc-4f08-887d-36b9bb0cedad", "b3302aa8-0f32-4b21-9af8-6a4af294679c", "c253eb20-915a-414b-b729-e6f1eb097536", "c62993d4-9372-4a20-a6b9-8bb19f7c18a6", "df846d34-d0b6-412c-8819-614db70fd850", "e4a4c696-46dc-4bec-9a11-13646dbc1bbd", "ebe94155-82b0-4840-a8ff-e59e289729f6", "f29a110e-2fe4-47e7-9dcc-0487eb2f77d9", "fdce467b-dff6-440c-9fa7-f52cfc891b39"], "title": "Composition and reuse with compiled domain-specific languages", "venue": "european conference on object oriented programming", "year": 2013, "id": "08d0644b-ce65-43b3-a771-6a35df9fb221"}
{"abstract": "A large class of problems can be formulated in terms of the assignment of labels to objects. Frequently, processes are needed which reduce ambiguity and noise, and select the best label among several possible choices. Relaxation labeling processes are just such a class of algorithms. They are based on the parallel use of local constraints between labels. This paper develops a theory to characterize the goal of relaxation labeling. The theory is founded on a definition of con-sistency in labelings, extending the notion of constraint satisfaction. In certain restricted circumstances, an explicit functional exists that can be maximized to guide the search for consistent labelings. This functional is used to derive a new relaxation labeling operator. When the restrictions are not satisfied, the theory relies on variational cal-culus. It is shown that the problem of finding consistent labelings is equivalent to solving a variational inequality. A procedure nearly identical to the relaxation operator derived under restricted circum-stances serves in the more general setting. Further, a local convergence result is established for this operator. The standard relaxation labeling formulas are shown to approximate our new operator, which leads us to conjecture that successful applications of the standard methods are explainable by the theory developed here. Observations about con-vergence and generalizations to higher order compatibility relations are described.", "authors": ["Robert A. Hummel", "Steven W. Zucker"], "n_citation": 1163, "references": ["0308792c-3154-41d0-9bf1-cf57e12b7d69", "1f47e848-ab80-41af-88b1-b58dae33ea77", "1f8891b4-b770-40a1-b726-f1d2cdd31287", "350a9213-8466-47e4-84a0-51b1adffc774", "42fdf4a1-59ec-4566-9239-6795fb9f862c", "946b8b4b-424e-422b-b2c1-d9d9640adf19", "e245ea86-6538-482e-820f-beadc4c4a520"], "title": "On the Foundations of Relaxation Labeling Processes", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 1983, "id": "28baa713-3f4f-421b-b140-e1e46b0e7012"}
{"abstract": "This paper argues for the usefulness of an application-cooperative interactive management system for wireless sensor networks and presents SNMS, a sensor network management system. SNMS is designed to be simple and have minimal impact on memory and network traffic, while remaining open and flexible. The system is evaluated in light of issues derived from real deployment experiences.", "authors": ["Gilman Tolle", "David E. Culler"], "n_citation": 492, "references": ["105314df-68a1-40e0-b793-af225567b50c", "612910b7-24f8-4f67-9d3d-a2814b7c15f8", "6bfdf9a3-6cd9-43d8-9785-0073dbe96f1b", "84b58288-c05b-46a0-b77d-fff1ac822ffd", "914c264e-b59c-4239-b101-7fab6add57d8", "afc06b7c-7fb3-4f88-942b-3076ed77920e", "b5b8132d-0a8c-4e6c-999f-839f0cef48b7", "ed4ea231-d9c5-44fc-9a21-40feb7c136da", "ee4d57a4-27c5-4378-9ef1-28720f2318c6", "efa04de8-fec3-4c73-8031-5b7990b88e57", "f682f022-3c5c-4638-a9d4-5b08bfa136a1", "fd15feef-f60a-40af-a780-a67e4f70bace"], "title": "Design of an application-cooperative management system for wireless sensor networks", "venue": "international conference on embedded wireless systems and networks", "year": 2005, "id": "f7d60003-9448-488e-8845-70f07508cf1a"}
{"abstract": "We describe a method for automatically synthesizing deaf signing animations from a high-level description of signs in terms of the HamNoSys transcription system. Lifelike movement is achieved by combining a simple control model of hand movement with inverse kinematic calculations for placement of the arms. The realism can be further enhanced by mixing the synthesized animation with motion capture data for the spine and neck, to add natural \"ambient motion\".", "authors": ["Richard Kennaway"], "n_citation": 100, "references": ["02f9e191-0430-4a7c-a8bd-20674738bee3", "1f0a6822-fa95-4681-93b9-e5641f119932", "49e6ecd2-3176-48c3-ab54-3ce46e152d4f", "4f25d34f-dc8e-4387-9f83-e0436849b7fa", "63249ecf-be12-4e7b-9ef2-0dd0d972058d", "908bf7e0-38de-4294-9ce9-35c15c48826b", "d1a3de6d-89b7-40ee-97ce-504c035781d0", "dd922e78-a78e-4a59-830f-ab74aacbae1a"], "title": "Synthetic Animation of Deaf Signing Gestures", "venue": "", "year": 2001, "id": "c79d87a5-1122-4c7d-bc86-17c5f3e237b7"}
{"abstract": "We present the concept of an  access control space  and investigate how it may be useful in managing access control policies. An access control space represents the permission assignment state of a subject or role. For example, the set of permissions explicitly assigned to a role defines its  specified  subspace, and the set of constraints precluding assignment to that role defines its  prohibited  subspace. In analyzing these subspaces, we identify two problems: (1) often a significant portion of an access control space has unknown assignment semantics, which indicates that the policy is underspecified; and (2) often high-level assignments and constraints that are easily understood result in conflicts, where resolution often leads to significantly more complex specifications. We have developed a prototype system, called Gokyo, that computes access control spaces. Gokyo identifies the unknown subspace to assist system administrators in developing more complete policy specifications. Also, Gokyo identifies conflicting subspaces and enables system administrators to resolve conflicts in a variety of ways in order to preserve the simplicity of constraint specification. We demonstrate Gokyo by analyzing a Web server policy example and examine its utility by applying it to the SELinux example policy. Even for the extensive SELinux example policy, we find that only eight additional expressions are necessary to resolve Apache administrator policy conflicts.", "authors": ["Trent Jaeger", "Xiaolan Zhang", "Antony Edwards"], "n_citation": 110, "references": ["04a33e22-977a-4628-b551-cf393e9ee758", "0d257a35-02cc-4081-94cd-06ba3fbfac51", "1620c8dc-5869-44f2-8110-9b866e7c970c", "28e08f01-e281-405f-bec4-cc891d7bbdb0", "2d8f1f8b-b4db-4cd9-9e8b-8b68ac98ec5e", "38bc7275-da8e-429a-baf6-26bd1165a0c9", "3983b045-6073-46ef-a3b3-8d77fe85d46f", "4751a2d7-735d-4d9c-82e6-b40f8f1d757b", "4899f9ae-466f-4038-8e4b-9f345d85752b", "571284e1-95aa-4839-a746-bbefcef6ac16", "59bfcccb-d987-43ef-b12d-cccb6393188a", "64a90f66-255b-4d02-aa1d-8eb3989f98f5", "6f703076-9875-4352-ad71-bca5490ec3ae", "6f9b2f83-73a1-48de-a26b-87c90e6557c8", "851ff45b-d8f3-4765-9ade-064dc0a3514d", "888ed26f-f060-465d-915e-0a0c2d96bb6d", "a102d95f-9fc2-4d52-be1d-53e5dd984c5c", "a4383572-c3ad-4d79-a3e3-250a814e6cf1", "b3210810-7355-473e-b2e9-77916cf5ad86", "bf9adae0-fb12-4b24-916d-6f515fd8612a", "c57b52c3-8d6b-477e-92b4-3659e14ea546", "d96038fe-ae6a-432c-bfe7-dc5c730496c4", "e415f628-05cc-4195-bdb7-6b53ff8d0540", "ecfb2022-e18c-4e5e-8733-d8bc6f4c8fc9", "f92c47d0-5e22-4d95-b51f-2fcffc226004"], "title": "Policy management using access control spaces", "venue": "ACM Transactions on Information and System Security", "year": 2003, "id": "850619bf-fb6f-4900-a24d-5553d0b8b945"}
{"abstract": "This paper describes a theoretical framework for the design of controllers to satisfy probabilistic safety specifications for partially observable discrete time stochastic hybrid systems. We formulate the problem as a partial information stochastic optimal control problem, in which the objective is to maximize the probability that the state trajectory remains within a given safe set in the hybrid state space, using observations of the history of inputs and outputs. It is shown that this optimal control problem, which has a multiplicative payoff structure, is equivalent to a terminal payoff problem when the state space is augmented with a binary random variable capturing the safety of past state evolution. This allows us to derive a sufficient statistic for the probabilistic safety problem as a set of Bayesian filtering equations updating a conditional distribution on the augmented state space, as well as an abstract dynamic programming algorithm for computing the maximal probability of safety and an optimal control policy.", "authors": ["Jerry Ding", "Alessandro Abate", "Claire J. Tomlin"], "n_citation": 15, "references": ["3949f595-2b19-4d0c-993e-bd24ee798194", "42c35207-7ec5-4640-8cb1-5345c9d44162", "61851c6e-ffa6-40ce-bfa8-358131c4b193", "83e8d2b6-76f2-40c2-acbd-eec39d5d2e6e", "84f69ceb-6599-4f6a-980f-c4331ddbefc4", "adcb03d3-28a6-4bb2-a78d-f86e6dbbf6d7", "b3a771df-f4f3-40b8-aec0-cf2fe216ce13", "ce333d94-39ab-4fb4-b743-3cbe78f4ba3b", "e35d097f-6d71-4306-8bd4-628a7d1bf4b0", "eb09e3ca-2b79-4324-b338-09aaeba4c25e", "eb58cb15-7c4e-45f1-bce0-e05c00fbc10a"], "title": "Optimal control of partially observable discrete time stochastic hybrid systems for safety specifications", "venue": "american control conference", "year": 2013, "id": "c5353bd2-ce2f-40cb-995d-a109347b01cb"}
{"authors": ["Marc Olano", "Trey Greer"], "n_citation": 104, "references": ["13541f80-ed55-41e1-b46f-49a55dd7818a", "20cd0454-1860-4117-ab8f-d4c225dbcc1b", "4f636bc5-15d6-48bc-85b9-899428d32e57", "b6fdf03f-3ccb-41cb-a7aa-a5d6c10fecb5"], "title": "Triangle scan conversion using 2D homogeneous coordinates", "venue": "international conference on computer graphics and interactive techniques", "year": 1997, "id": "d2070485-9180-4487-bbd6-61e41e62a7cd"}
{"abstract": "A test generation procedure to detect multiple state-table faults in finite-state machines is proposed. The importance of multiple state-table faults and their advantages as test generation objectives to avoid the need for checking experiments are considered. The proposed procedure is based on a new method for implicit enumeration of large numbers of multiple faults by using incompletely specified faulty machines. Experimental results are presented to demonstrate the effectiveness of implicit fault enumeration in detecting large numbers of multiple faults and in guaranteeing detection of all the faults or all the faults up to a specific multiplicity.", "authors": ["Irith Pomeranz", "Sudhakar M. Reddy"], "n_citation": 50, "references": ["64359f6c-cb70-4d43-8409-a3ff0879c75d", "a271c351-25f7-4a4a-b511-41a2a4e0ab14", "da8e9255-f38d-4a8b-bf3d-c8003b92f2ec", "f6841011-edfd-42e8-af5a-09e5de4722c6", "feb5b573-b935-453f-a2f5-455266a877de"], "title": "Test generation for multiple state-table faults in finite-state machines", "venue": "IEEE Transactions on Computers", "year": 1997, "id": "d8218dab-167b-4967-b54d-4e49d926d0ef"}
{"abstract": "We propose anew rectification method for aligning epipolar lines of a pair of stereo images taken under any camera geometry. It effectively remaps both images onto the surface of a cylinder instead of a plane, which is used in common rectification methods. For a large set of camera motions, remapping to a plane has the drawback of creating rectified images that are potentially infinitely large and presents a loss of pixel information along epipolar lines. In contrast, cylindrical rectification guarantees that the rectified images are bounded for all possible camera motions and minimizes the loss of pixel information along epipolar line. The processes (e.g., stereo matching, etc.) subsequently applied to the rectified images are thus more accurate and general since they can accommodate any camera geometry.", "authors": ["S\u00e9bastien Roy", "Jean Meunier", "Ingemar J. Cox"], "n_citation": 110, "references": ["1da58fd4-be97-47e5-a94f-3b8a75a39160", "214a9f8e-1f8c-4322-83f7-fdd2bcd2988c", "900c927f-8e6e-4290-8eac-63fef682460d", "a748e0f4-ee6f-41ad-a2a5-1a5a6751086d", "ca825df2-5439-465d-93c4-7437d89bfcb5", "e5acb96b-d9ae-4902-9015-4f758a001199"], "title": "Cylindrical rectification to minimize epipolar distortion", "venue": "computer vision and pattern recognition", "year": 1997, "id": "f92629a2-c934-495d-8736-b7c3c537b57a"}
{"abstract": "In this paper, a set of shape features which was based on the special characteristics of Chinese signatures was proposed for off-line Chinese signature verification. Another set of high-pressure features was also developed to extract timing and dynamic information indirectly from the signature image. A database of 100 genuine signatures and 50 simple forgeries was used to investigate the effectiveness of these two sets. Though shape features and high-pressure features had an error rate of 6.5% and 20.0% respectively, the collective use of these two sets reduced the error rate of simple forgery verification to 2.5%. It was concluded that combined use of static and dynamic information is an effective way for off-line Chinese signature verification.", "authors": ["Jun Lin", "Jie-Gu Li"], "n_citation": 18, "references": ["1e5d2ca6-310d-4737-ad55-391ade728821", "3240b442-238d-4265-b951-6ec9a11b45f0", "bf562618-9161-457f-8941-ca9c71652b69", "e3a4895f-6f51-467f-a523-f973331111fe"], "title": "Off-line Chinese signature verification", "venue": "international conference on image processing", "year": 1996, "id": "660ef572-a142-475a-85bf-95fcba09e542"}
{"abstract": "We describe three semantic text similarity systems developed for the *SEM 2013 STS shared task and the results of the corresponding three runs. All of them shared a word similarity feature that combined LSA word similarity and WordNet knowledge. The first, which achieved the best mean score of the 89 submitted runs, used a simple term alignment algorithm augmented with penalty terms. The other two runs, ranked second and fourth, used support vector regression models to combine larger sets of features.", "authors": ["Lushan Han", "Abhay L. Kashyap", "Tim Finin", "James Mayfield", "Jonathan Weese"], "n_citation": 193, "references": ["21834051-e768-4630-9a01-6aea9930ebfa", "2415a9ee-680c-4091-9072-e7481ea12c7d", "5cff2bc9-b737-470a-9895-8170017cb486", "6056b902-18f6-4914-a91e-cea59e0f947c", "6a06bf57-7ee0-4f3e-8b8f-91d64244b948", "7992b1ff-8ed6-4b18-aac6-bb9ad35b2f65", "7c76e8b1-8c93-485a-9999-da8cf604200a", "8317ef60-e9b8-4680-9160-931bd3009461", "875c72d2-da60-4e5a-91ae-7f5d4c49fb8f", "9e4859ce-16a8-4d7f-ba0d-21fe49950105", "aafffa69-1bc3-4d18-8f3b-296c03a13557", "ac14afe6-de4d-4056-b2ac-0f6e36f369a2", "ad18a17d-a120-448f-9283-749bd5cff122", "af593417-7ff5-4440-ae22-469cff9e0c67", "b39931fd-94fe-46ac-b260-09680447e261", "c1b6b493-01ef-420f-be44-7bacfe34e846", "c92afebe-c430-4bb8-9ef9-6a46981d2008", "cd34e1c4-2cdb-42b6-bb14-ee7cea07f58b", "dbc228a4-d1b4-40d8-8e1f-d221f3ad8b37", "ed8f96b0-dd29-4a5d-8af6-dc1d3ae400a6", "fa512d50-e535-4feb-91d0-42b071e08a4f", "fc8a32b8-87d0-41ce-9b58-368948b270aa"], "title": "UMBC_EBIQUITY-CORE: Semantic Textual Similarity Systems", "venue": "north american chapter of the association for computational linguistics", "year": 2013, "id": "881339b1-2e09-45c5-be74-abc59ff67cc1"}
{"abstract": "This study presents a genetic algorithm (GA) for identifying the exact D-optimal design for multivariate response surface models (called MD-optimal design). The MD-optimal design minimizes the volume of joint confidence regions of model parameters. The covariance between any two responses is assumed to be identical in the two examples of four responses and biresponse problems considered in this study. We have also provided an example of covariance estimation. In order to obtain the initial candidate set, we first obtain a D-optimal design for each response model by using a conventional approach; then, the set of solutions obtained from the individual model is treated as the initial set in the GA. This shows that the MD-optimal designs converge toward the same D-optimal design in a single response linear model; however, the different variance-covariance matrices attain dissimilar objective values. The GA exhibits stable representation in multiple response design problems and performs better than the US algorithm, which is generated only near the MD-optimal design. It is possible for an experimenter to set a high crossover rate except full crossover, and estimate the variance-covariance matrix in the preprocess or set it as an identity matrix in the process of the GA.", "authors": ["Pei-Lan Su", "Yun-Shiow Chen"], "n_citation": 2, "references": ["3f0e32a8-6957-4683-9976-ef2c7e56c161"], "title": "Implementation of a genetic algorithm on MD-optimal designs for multivariate response surface models", "venue": "Expert Systems With Applications", "year": 2012, "id": "51af6863-6f5e-4d30-a4f1-5ff3794059a7"}
{"abstract": "The application of dyadic wavelet decomposition in the context of time delay estimation is investigated. We consider a model in which the source signal is deterministic and the received sensor outputs are corrupted by additive noises. Wavelet denoising is exploited to provide an effective solution for the problem. Denoising is first applied to preprocess the received signals from two spatially separated sensors with an attempt to remove the contamination, and the peak of their cross correlation function is then located from which the time delay between the two signals can be derived. A novel wavelet shrinkage/thresholding technique for denoising is introduced, and the performance of the algorithm is analyzed rigorously. It is proved that the proposed method achieves global convergence with a high probability. Simulation results also corroborate that the technique is efficient and performs significantly better than both the generalized cross correlator (GCC) and the direct cross correlator (CC).", "authors": ["Pak-Chung Ching", "Hing-Cheung So", "Shi-Quan Wu"], "n_citation": 126, "references": ["fc50466c-e162-4a71-bf91-de43a4abd2e5"], "title": "On wavelet denoising and its applications to time delay estimation", "venue": "IEEE Transactions on Signal Processing", "year": 1999, "id": "3c3b99e7-eeb8-4a3d-a514-0363c2338381"}
{"abstract": "Smart grid is a visionary user-centric system that will elevate the conventional power grid system to one which functions more cooperatively, responsively, and economically. Dynamic demand side management is one of the key issues that enable the implementation of smart grid. In this paper, we use the framework of dynamic games to model the distribution demand side management. The market price is characterized as the dynamic state using a sticky price model. A two-layer optimization framework is established. At the lower level, for each player (such as one household), different appliances are scheduled for energy consumption. At the upper level, the dynamic game is used to capture the interaction among different players in their demand responses through the market price. We analyze the N-person nonzero-sum stochastic differential game and characterize its feedback Nash equilibrium. A special case of homogeneous users is investigated in detail and we provide a closed-form solution for the optimal demand response. From the simulation results, we demonstrate the use of demand response strategy from the game-theoretic framework and study the behavior of market price and demand responses to different parameters.", "authors": ["Quanyan Zhu", "Zhu Han", "Tamer Basar"], "n_citation": 52, "references": ["1099c8b1-196f-40a7-aef9-b7fe70a1ccaf", "28da0af7-cd46-46fa-970d-c2a9bea11c5b", "5df050fc-f26a-4a8c-9e07-8c0cecd77efe", "caa7486b-f987-49c9-924b-84c2462f66c8"], "title": "A differential game approach to distributed demand side management in smart grid", "venue": "international conference on communications", "year": 2012, "id": "976289e2-77ae-401b-8703-51b20168f871"}
{"abstract": "We consider the problem of computing the minimum-cost tree spanning at least k vertices in an undirected graph. Garg [10] gave two approximation algorithms for this problem. We show that Garg's algorithms can be explained simply with ideas introduced by Jain and Vazirani for the metric uncapacitated facility location and k-median problems [15], in particular via a Lagrangean relaxation technique together with the primal-dual method for approximation algorithms. We also derive a constant-factor approximation algorithm for the k-Steiner tree problem using these ideas, and point out the common features of these problems that allow them to be solved with similar techniques.", "authors": ["Fabi\u00e1n A. Chudak", "Tim Roughgarden", "David P. Williamson"], "n_citation": 86, "references": ["066d363b-4627-4ad8-a06b-f934fd3d037d", "18b26b3f-f34f-417f-a070-a2322b39f22c", "38e5341a-b776-4de4-b243-4175898dcff5", "443238c5-a2a5-4d2e-a09e-4a32aabb06b2", "536255d1-6c26-447f-931d-d92c69d18823", "6110673e-9017-4f8a-9db0-d759808ea84f", "7bd576b4-5791-4756-b00d-76bfadb5c78f", "9d6cfd2c-4a22-4ee0-a15d-ddb042a06a96", "cfb4e2cb-db3b-4961-bb23-5e3fdd0eba33", "fec44afc-ba10-4d57-a898-4208e83890eb"], "title": "Approximate k-MSTs and k-Steiner Trees via the Primal-Dual Method and Lagrangean Relaxation", "venue": "integer programming and combinatorial optimization", "year": 2001, "id": "6b8b1f2a-9eb5-4c65-9203-7ebec5988a43"}
{"abstract": "Examining the effectiveness of control in networked systems is a thriving research area. Autonomous systems that can be intermittently influenced (controlled) by external agents find applications ranging from machine calibration to satellite control. We refer to this class of networks as semi-autonomous. If the semi-autonomous agents' interaction dynamics are consensus-based, we dub this subclass as semi-autonomous consensus, which is the focus of the paper. Within such a subclass, we consider the dynamics of networked agents in the context of performance (friendly influence) and security (unfriendly influence). Our approach to appraise a semi-autonomous consensus network is to expose the network to fundamental test signals, namely white noise and an impulse, and use the resultant system response to quantify network performance and security. Traditionally, input-output properties are varied by altering the dynamics of the network agents. We instead adopt topological methods for this task, designing five protocols for tree graphs that rewire the network topology, leaving the network agents' dynamics untouched. In pursuit of this objective, four adaptive protocols are introduced to either increase or decrease the mean tracking and variance damping measures, respectively. Finally, a proposed fifth hybrid protocol is shown to have a guaranteed performance for both measures using a game-theoretic formalism.", "authors": ["Airlie Chapman", "Mehran Mesbahi"], "n_citation": 50, "references": ["00547759-0499-41f2-ae1f-5bc14bf384f9", "223edc15-f2f7-4796-8b91-9fab63eda279", "272df332-e1fc-404a-90b7-fd12c98ab553", "423548af-857e-4063-88b5-14cd2d7f2155", "597b26a2-15eb-431b-b1a4-0ee6f6849b5a", "5b3b98ab-0ec9-48da-99b3-5ceb8f343b8a", "71217121-7b8b-47c3-8786-3dcff9831fb8", "7919577c-d132-4d4b-83c5-a25868fdb648", "90105a97-56d3-44c1-831b-ddc4a0c73605", "cf8eb4ea-3f59-4447-a6b1-f7c0f2d0fc53", "d9162547-fd7f-4605-855d-0a3173c4b08e", "e0424506-3106-4687-91bf-7fe0f1fdc802", "e76049b0-ff8f-4d01-a407-3ab4f3b16384", "ea1d5c21-fba6-4fae-9fdc-ee7679ee46c9", "f09dc854-1d96-45e7-b939-a963e31b919d"], "title": "Semi-Autonomous Consensus: Network Measures and Adaptive Trees", "venue": "IEEE Transactions on Automatic Control", "year": 2013, "id": "4a4d87dd-8505-47c8-b7ff-966acc650679"}
{"abstract": "Brajnik et alia describe their view of an effective retrieval interface, one which coaches the searcher using stored knowledge not only of database structure, but of strategic situations which are likely to occur, such as repeating failed tactics in a low return search, or failing to try relevance feedback techniques. The emphasis is on the system suggesting search strategy improvements by relating them to an analysis of work entered so far and selecting and ranking those found relevant. FIRE is an interface utilizing these techniques. It allows the user to assign documents to useful, topical and trash folders, maintains thesauri files automatically searchable on query terms, and it builds, using user entries and a rule system, a picture of the retrieval situation from which it generates suggestions.", "authors": ["Giorgio Brajnik", "Stefano Mizzaro", "Carlo Tasso"], "n_citation": 78, "references": ["0122dc00-0388-47b7-8691-ca5888ae9423", "0895c22d-37c5-4c8f-9202-a32ebd2cb0c0", "2f319337-f636-4f83-8139-c867deda44c9", "35cdfdca-95e5-4162-b72a-bd5155f53228", "3b5f4cd7-760b-4da0-9d63-413ee7cdbba8", "4b3ae99d-ffe1-4e70-9e20-e8b70ba716e2", "5113a38d-e69e-4a2a-8d3e-a89782e075ea", "669fb415-bbef-4d0b-b3aa-567ffc9a840f", "6baeb50c-1637-491d-b3d9-fa908f8acf96", "70a46c18-161f-439c-9e39-3533005ef873", "7c4dfd37-fa37-4a43-a3e1-898b98e0b48d", "81ed10be-b192-4035-ad1e-5f77ecb2b751", "88d82a29-49ad-4e20-b777-9b748b4108c2", "8b7d96e3-f148-4101-a116-6e1543e529aa", "a429071b-e8a0-488c-abf4-81cb72a0860e", "b9f52d99-5541-46bd-9214-297aad44401f", "ba7b5f35-9201-49dc-b8d0-6a0986f52a29", "c5beb52a-55f7-40bc-9e23-85d66b13883a", "c87c59bb-6f65-45ab-a210-bb1cb2d0f623", "cc57d3a1-2780-4467-a80c-a3e2028989e8", "df20a5c7-0039-426e-8b5b-ad03f801a4b0", "e196f006-7308-43fb-ae78-e7c9a85e5026", "e28bbb8e-5a39-4848-a280-e1087367045f", "f1e32ad2-0eb0-4c9f-a271-1f3589bfd372", "f43b032d-6b86-4bc5-b9a3-e7365d8adda0"], "title": "Strategic help in user interfaces for information retrieval", "venue": "Journal of the Association for Information Science and Technology", "year": 2002, "id": "889dca11-2d64-4f09-a596-40b80fc0604b"}
{"abstract": "Various ways of vocal sound production are being actively studied. We are constructing a phonetic machine with a vocal chord and a vocal tract based on mechatronics technology. Mechanical construction of a human vocal system is considered to generate natural voice so that it can be advantageously applied to singing voice production. In voice generation, analysis and mechanical realization of the behaviors of the vocal chords and vocal tract are required. Furthermore, the fluid mechanical system is less stable, thus making control more difficult. Several motors are employed to manipulate the mechanical vocal system. Mappings between motor positions and the produced vocal sounds are automatically established in the learning phase. In the singing performance, the system is able to sing while vocal pitches and phonemes are adaptively controlled by an auditory feedback process. This paper presents the latest mechanisms of our mechanical vocal system together with adaptive tuning algorithms of the physical mech...", "authors": ["Hideyuki Sawada", "Shuji Hashimoto"], "n_citation": 4, "title": "Mechanical construction of a human vocal system for singing voice production", "venue": "Advanced Robotics", "year": 1998, "id": "881172ef-097d-491d-8004-1913b7f69e12"}
{"abstract": "Abstract#R##N##R##N#The algorithm proposed by Chang and lyengar to perfectly balance binary search trees has been modified to not only balance but also thread binary search trees. Threads are constructed in the same sequence as normal pointers during the balancing process. No extra workspace is necessary, and the running time is also linear for the modified algorithm. Such produced tree structure has minimal average path length for fast information retrieval, and threads to facilitate more flexible and efficient traversing schemes. Maintenance and manipulation of the data structure are discussed and relevant algorithms given.", "authors": ["S. Sitharama Iyengar", "Hsi Chang"], "n_citation": 50, "references": ["04c5195d-f5c6-4b10-ab13-80cc4c308749", "4a705f98-43b7-4e64-b18e-2fc5920305ac"], "title": "Efficient algorithms to create and maintain balanced and threaded binary search trees", "venue": "Software - Practice and Experience", "year": 1985, "id": "aab7c933-e866-4028-a79f-e11aeb1c2b0f"}
{"abstract": "This note describes a robust sensor bias fault diagnosis architecture for dynamic systems represented by a class of nonlinear discrete-time models. The nonlinearity in the system nominal model is assumed to be a function of inputs and outputs only. Specifically, this note uses adaptive techniques to estimate an unknown sensor bias in the presence of modeling uncertainties. A simulation example is presented to illustrate the methodology. The robustness, sensitivity and stability properties of the bias fault diagnosis architecture are rigorously analyzed.", "authors": ["Arun T. Vemuri"], "n_citation": 17, "references": ["05b3f309-98f7-4cbc-bc3e-b2f66514db94", "33ac9f00-70b8-4fdf-b134-44f7a87338e1", "5bec017b-1fbe-411c-8daf-ab8cffc6f6fb", "90b35567-d92b-409a-a18a-732634dfc797", "c7d56952-6310-4ddb-b410-ed9a7675323a"], "title": "Sensor bias fault diagnosis in a class of nonlinear systems", "venue": "IEEE Transactions on Automatic Control", "year": 2001, "id": "db23ff30-b035-440c-8636-2d02103b4e80"}
{"abstract": "The Layered Cross Product (LCP) of layered graphs is introduced. It is shown that several well-known networks are LCPs of simple layered graphs, such as trees. We believe that this new tool will make the construction of new networks easier, and it will simplify the study of the properties of known and new networks.", "authors": ["Shimon Even", "Ami Litman"], "n_citation": 50, "title": "Layered Cross product : A technique to construct interconnection networks", "venue": "Networks", "year": 1997, "id": "f1492f3d-95fe-4e4a-ae0b-fb0873d6eeb0"}
{"authors": ["Aaron F. Bobick"], "n_citation": 14, "references": ["015d4134-1053-4e9f-99b6-143a3e91e0ea", "0f1eaa0c-eee7-4acc-af94-73d15916c178", "349c69b2-6558-4013-984a-56e7c2287526", "3a2de5e2-6d2c-4d7a-9e21-61c483c022fe", "5fa50960-2eb1-4fe0-b07a-ad2f88bc9bdc", "748763b2-b9d4-41cf-9d00-8763a7902da9", "eebe49e1-42f0-43b8-b5ec-cfaaaf3b90e1"], "title": "Video Annotation: Computers Watching Video", "venue": "asian conference on computer vision", "year": 1995, "id": "5385588d-662b-418c-9d6b-a9284624a041"}
{"abstract": "A score function induced by a generative model of the data can provide a feature vector of a fixed dimension for each data sample. Data samples themselves may be of differing lengths (e.g., speech segments, or other sequence data), but as a score function is based on the properties of the data generation process, it produces a fixed-length vector in a highly informative space, typically referred to as a \"score space\". Discriminative classifiers have been shown to achieve higher performance in appropriately chosen score spaces than is achievable by either the corresponding generative likelihood-based classifiers, or the discriminative classifiers using standard feature extractors. In this paper, we present a novel score space that exploits the free energy associated with a generative model. The resulting free energy score space (FESS) takes into account latent structure of the data at various levels, and can be trivially shown to lead to classification performance that at least matches the performance of the free energy classifier based on the same generative model, and the same factorization of the posterior. We also show that in several typical vision and computational biology applications the classifiers optimized in FESS outperform the corresponding pure generative approaches, as well as a number of previous approaches to combining discriminating and generative models.", "authors": ["Alessandro Perina", "Marco Cristani", "Umberto Castellani", "Vittorio Murino", "Nebojsa Jojic"], "n_citation": 31, "references": ["21a8e8fd-0172-4e9a-8474-7024eb0bf979", "25a3bd8d-4173-4122-a2ee-6e4b64a0426f", "7084c198-9747-42de-bb40-f9e3264a898b", "7afddacc-670d-4c2f-9de7-b2c37a63a0c9", "83657aeb-eb85-4d1c-9ec3-a398002bd57a", "9508bdd9-7288-455a-80f8-d0f22fa66d54", "959519d3-eacf-4349-9a2f-bb2b3e7a8041", "9b93d2e7-e2cd-4750-b86a-4d8dbc4b9f80", "ab3afb93-8ca0-4556-ae60-11199dc263c2", "bab23171-e277-45f3-8253-0e8dbb62081e", "c2b9beb2-7ce9-42d7-bfc3-060ab60b5139", "e0ac4812-7729-4a2d-8a1f-74b1b7c8eb5d", "e30006aa-a666-4d31-a6e5-9464797811a6", "ec8c9e00-d026-4d33-b102-ffd5389234cd", "fb244d98-60f6-40f8-8c42-a233dfa5843f"], "title": "Free energy score space", "venue": "neural information processing systems", "year": 2009, "id": "2689fc01-7819-4f37-9497-335c17ccfcdc"}
{"abstract": "The Java Remote Method Invocation (JRMI) specification simplifies the development of distributed Java applications, but provides little support to guarantee reliable, highly-available operation. The Aroma System is middleware that transparently enhances the JRMI model with the mechanisms required for consistent replication of client and server objects. By exploiting novel interception mechanisms, the Aroma System is activated at runtime, with minimal modification to the application and to the JRMI infrastructure. The Aroma System adapts the JRMI model for group communication, and exploits an underlying reliable, totally-ordered multicast protocol to provide strong replica consistency. We describe the architecture of the Aroma System, and discuss the mechanisms required to achieve transparent replication of Java RMI objects and to enforce strong replica consistency.", "authors": ["Nitya Narasimhan", "Louise E. Moser", "P. M. Melliar-Smith"], "n_citation": 50, "references": ["5f3c50f5-e87a-4143-915f-6373cb9527fa", "6f82f76d-a9a8-47cb-a0d9-129e4fb63073", "6f942029-dd91-4f6f-b2cd-e15f1ffd9eab", "9277c882-84b3-4ade-ad7f-29bb4e1c291f", "b24f49f2-7001-4fca-a44e-c0a4acd0322e", "b5635a67-86ea-4fb1-93ba-c9b198344628", "d555053e-b655-4b7d-b735-bfef5dec1a3c", "daa6f698-4df7-4054-bd87-75616d68acc0", "e63ebe15-8e20-4055-8ac1-b017fd87fa0a"], "title": "Transparent consistent replication of Java RMI objects", "venue": "", "year": 2000, "id": "99239f13-2163-485d-8372-e102d2867975"}
{"abstract": "REACH is an active object system intended to control heterogeneous systems, possibly under timing constraints. When dealing with open systems in which the controlled system may execute irreversible actions, many notions of active databases must be revised and adapted to this situation. In this paper we draw the system boundaries between controlling and controlled system, present a rule system that includes events and actions both in the controlled and the controlling systems and analyze the effects of this open environment on the rule structure. We identify two new coupling modes, sequential causally dependent and exclusive causally dependent, which are necessary for handling irreversible actions in external systems and contingency plans, respectively.", "authors": ["Holger Branding", "Alejandro P. Buchmann", "Thomas Kudrass", "J\u00fcrgen Zimmermann"], "n_citation": 161, "references": ["3ad2284d-686f-43aa-8813-90d918f29596", "5a3d25d4-7f7f-4578-bcc7-cac7e5478785", "8ec39a3a-4902-4250-b80e-e19cd8d5d36a", "a0d19909-90a1-4d94-9973-6edf30dd045f", "a3338113-ab1a-44bb-82de-dea086907ca2", "c643e668-9dcf-4f28-9e98-2f4e91256595", "d3822649-b90d-4633-aefb-07759b601e68", "f486c9c3-c035-43ed-8e9d-be2763d13f4e"], "title": "Rules in an Open System: The REACH Rule System", "venue": "", "year": 1994, "id": "69ba2a6a-5f6e-48d0-8414-c6563ec8f668"}
{"abstract": "MetLife processes over 260,000 life insurance applications a year. Underwriting of these applications is labor intensive. Automation is difficult because the applications include many free-form text fields. MetLife's intelligent text analyzer (MITA) uses the information-extraction technique of natural language processing to structure the extensive textual fields on a life insurance application. Knowledge engineering, with the help of underwriters as domain experts, was performed to elicit significant concepts for both medical and occupational textual fields. A corpus of 20,000 life insurance applications provided the syntactical and semantic patterns in which these underwriting concepts occur. These patterns, in conjunction with the concepts, formed the frameworks for information extraction. Extension of the information-extraction work developed by Wendy Lehnert was used to populate these frameworks with classes obtained from the systematized nomenclature of human and veterinary medicine and the Dictionary of Occupational Titles ontologies. These structured frameworks can then be analyzed by conventional knowledge-based systems. MITA is currently processing 20,000 life insurance applications a month. Eighty-nine percent of the textual fields processed by MITA exceed the established confidence-level threshold and are potentially available for further analysis by domain-specific analyzers.", "authors": ["Barry Glasgow", "Alan Mandell", "Dan Binney", "Lila Ghemri", "David Fisher"], "n_citation": 34, "references": ["0e1d46f1-0879-486b-a349-17cab36b8034", "100d9f16-5fc5-468b-be7b-2fadaf9bcd02", "2db70d24-c7f0-4c82-b677-97e5dc3bb1a7", "caf151be-3267-440f-bf02-f190803c5873", "e3728333-e884-414c-839d-781e5dbc399c", "f5ddea41-cbba-4120-b373-5ab5ba266a9b"], "title": "MITA: An Information-Extraction Approach to the Analysis of Free-Form Text in Life Insurance Applications", "venue": "Ai Magazine", "year": 1998, "id": "fb6d3fab-5f89-4c28-8a61-1501453f0e29"}
{"abstract": "This paper attempts to address the question of why certain dataflow analysis problems can be solved efficiently, but not others. We focus on flow-sensitive analyses, and give a simple and general result that shows that analyses that require the use of  relational attributes  for precision must be PSPACE-hard in general. We then show that if the language constructs are slightly strengthened to allow a computation to maintain a very limited summary of what happens along an execution path, inter-procedural analyses become EXPTIME-hard. We discuss applications of our results to a variety of analyses discussed in the literature. Our work elucidates the reasons behind the complexity results given by a number of authors, improves on a number of such complexity results, and exposes conceptual commonalities underlying such results that are not readily apparent otherwise.", "authors": ["Robert Muth", "Saumya K. Debray"], "n_citation": 47, "references": ["072aea53-e281-47f7-8203-e7259fcf54f7", "156e6fea-8358-47eb-a929-8a00bff82c30", "66d779cf-d6bc-4d55-8865-8e946a7645b4", "6c6c19c6-fc6b-415a-8203-064eac60082b", "8316afe2-55f1-48f1-b308-a159e2b2856f", "a7f3ac80-bd0b-482d-a05c-1feeb7f6cec5"], "title": "On the complexity of flow-sensitive dataflow analyses", "venue": "symposium on principles of programming languages", "year": 2000, "id": "6c930934-4e92-453c-8c10-69b59617d066"}
{"abstract": "Abstract   This paper reports on experiments where techniques of supervised machine learning are applied to the problem of planning. The input to the learning algorithm is composed of a description of a planning domain, planning problems in this domain, and solutions for them. The output is an efficient algorithm\u2014a strategy\u2014for solving problems in that domain. We test the strategy on an independent set of planning problems from the same domain, so that success is measured by its ability to solve complete problems. A system, L2A ct , has been developed in order to perform these experiments.  We have experimented with the blocks world domain and the logistics transportation domain, using strategies in the form of a generalisation of decision lists. The condition of a rule in the decision list is an existentially quantified first order expression, and each such rule indicates which action to take when the condition is satisfied. The learning algorithm is a variant of Rivest's (1987) algorithm, improved with several techniques that reduce its time complexity. The experiments demonstrate that the approach is feasible, and generalisation is achieved so that unseen problems can be solved by the learned strategies. Moreover, the learned strategies are efficient, the solutions found by them are competitive with those of known heuristics for the domains, and transfer from small planning problems in the examples to larger ones in the test set is exhibited.", "authors": ["Roni Khardon"], "n_citation": 136, "title": "Learning action strategies for planning domains", "venue": "Artificial Intelligence", "year": 1999, "id": "077f3cc9-120a-4530-acec-ff0f6f5c10a7"}
{"abstract": "We describe an enhanced method for the selection of optimal sensor actions in a probabilistic state estimation framework. We apply this to the selection of optimal focal lengths for cameras with a variable motor zoom in a real-time visual object tracking task. The optimal camera action is determined by the expected state estimate entropy for each candidate action. Varying action costs are taken into account by predicting the entropy several steps into the future. Our contribution is the use of the sequential Kalman filter to deal transparently with a variable number of cameras, potential object loss in a subset of the cameras, and to reduce the calculation time through independent optimization.", "authors": ["Benjamin Deutsch", "Heinrich Niemann", "Joachim Denzler"], "n_citation": 8, "references": ["81e538eb-7aa6-49c1-9a8d-b9c4cd6d92be", "9526ded7-0d11-4e18-8c1f-fdb2640fbdea", "a3dfca63-dba5-4eee-a70d-ef1992b36af5", "c86ab37a-6baa-47fb-a885-bfbb7f23d973", "f7c58a26-9f29-4fe7-8ded-5fc938844c40"], "title": "Multi-step active object tracking with entropy based optimal actions using the sequential Kalman filter", "venue": "international conference on image processing", "year": 2005, "id": "26884546-f366-4c71-b567-e3220f416854"}
{"abstract": "One of the ways in which we cope with large and complex systems is to abstract away some of the detail, considering them at an architectural level as compositions of interacting components. To this end, the variously termed Coordination, Configuration and Architectural Description Languages (ADL) facilitate description, comprehension and reasoning at that level, providing a clean separation between individual component behaviour and their interaction in a software architecture. However, in the search to provide sufficient detail for reasoning, analysis or construction, many approaches are in danger of obscuring the essential structural aspect of the architecture, thereby losing the benefit of abstraction. In this paper we argue for the use of a concise and simple language explicitly designed for describing architectural structures. This can be used to provide the skeleton upon which to add the particular details of concern when necessary. Systems described in this way have an explicit and exposed skeleton which, being shared, helps to maintain consistency between the various elaborated views. To illustrate our approach, we use the Darwin architectural description language and the Tracta approach for compositional reachability analysis.", "authors": ["Jeff Kramer", "Jeff Magee"], "n_citation": 61, "references": ["04469f17-57b9-48dd-a425-65356088d02d", "0468472d-d16a-4521-b0e0-008e92fef477", "049e4529-6016-4ae3-bc63-7f5f4a9bd25f", "13d7c232-f241-408e-ac3a-a7224b001fc0", "1412ff23-1344-4034-87ac-344cc850f0b3", "173b2b20-25de-42ad-ac41-96ffdbea21cb", "19d9019b-b010-479d-ac25-26d7e45eca6b", "29f7e7d4-2771-4096-a72a-de82d7e16e73", "33f9ebe7-a105-4290-aed5-988484ccd0db", "3a30887f-011a-401a-a8c5-3523218ca2ad", "533369e5-45c8-4c36-865f-e47fa1b769e7", "5ae29b96-5968-4f0a-9f68-8e7b2c334289", "5f8169e2-4816-43be-96ee-0fd1ecbfb9dd", "6321c4eb-6305-4883-b93f-dd45be3002ac", "85c1de96-97f5-478f-aa27-3c8581595c15", "91b5fdfc-9d65-4e06-9408-a7256e4dda37", "a13a126e-37f7-4fad-8cfe-a3184320d64a", "a805e282-4223-476c-812a-232d57a33af1", "a8840afa-a1ab-49f3-990e-e86a398da051", "ba0ffed5-3044-4547-a891-3891007c44de", "df241eaf-9a61-4e85-a32e-3b4533f2beb6", "f794bd44-aadf-4e34-83db-9c7e8b8cac7c"], "title": "Exposing the Skeleton in the Coordination Closet", "venue": "international conference on coordination models and languages", "year": 1997, "id": "e152904f-8684-4297-b569-b216b73b1f22"}
{"abstract": "We propose a new class of algorithms for linear cost network flow problems with and without gains. These algorithms are based on iterative improvement of a dual cost and operate in a manner that is reminiscent of coordinate ascent and Gauss-Seidel relaxation methods. We compare our coded implementations of these methods with mature state-of-the-art primal simplex and primal-dual codes, and find them to be several times faster on standard benchmark problems, and faster by an order of magnitude on large, randomly generated problems. Our experiments indicate that the speedup factor increases with problem dimension.", "authors": ["Dimitri P. Bertsekas", "Paul Tseng"], "n_citation": 200, "references": ["0f9ee8d9-103c-4453-bc6f-3b2928aa13fa", "2964d87a-4cad-4d21-a1ea-b11fb6edad08", "2ea61f92-2574-4b14-962c-c2536c367b2b", "493996e3-261e-4aa4-aa41-4ec925d4ce22", "4cf6905b-af4c-47ee-9a9f-458482c71096", "4ee81980-49d4-4e1b-b650-1a1b77892940", "5e28bc4b-8564-4190-b0df-aa97c7a33c67", "8edd40b7-76b6-4ed7-9dac-e383ac1cf31c", "9392bd21-5283-444c-853b-92a010015c34", "939a116e-f1f6-446d-8423-44c958475da9", "af3dcf0c-6e6f-4190-a9d6-9a9d2551e378", "b6e98aa1-c44f-425a-ab30-742f68213468", "c7635acb-6dce-49da-b719-122ef065dbac", "d770a73f-ab6f-4be0-976f-5b10f30b8ed9"], "title": "Relaxation methods for minimum cost ordinary and generalized network flow problems", "venue": "Operations Research", "year": 1988, "id": "020f4a6f-8940-4740-b104-a613037286d8"}
{"abstract": "Many business documents are represented in XML. However XML only describes the structure of data, not its meaning. The meaning of data is required for advanced automated processing, as is envisaged in the \"Semantic Web\". Ontologies are often used to describe the meaning of data items. Many ontology languages, however, depend on the RDF data model and cannot describe XML data directly. This paper presents a procedure that can be used to turn XML documents into RDF statements via an RDF schema specification. This allows semantic annotation of XML documents via external RDF schema ontologies. This procedure makes the data in XML documents available for the Semantic Web.", "authors": ["Michel C. A. Klein"], "n_citation": 121, "references": [], "title": "Interpreting XML documents via an RDF schema ontology", "venue": "database and expert systems applications", "year": 2002, "id": "0acfbfc7-c94f-4a94-b3a8-c7cdba4a2db4"}
{"abstract": "We analyze a dynamic oligopoly model with strategic sellers and buyers/consumers over a finite horizon. Each seller has private information described by a finite-state Markov process; the Markov processes describing the sellers' information are mutually independent. At the beginning of each time/stage t the sellers simultaneously post the prices for their good; subsequently, consumers make their buying decisions; finally, after the buyers' decisions are made, a public signal, indicating the buyers' consumption experience from each seller's good becomes available and the whole process moves to stage t + 1. The sellers' prices, the buyers' decisions and the signal indicating the buyers' consumption experience are common knowledge among buyers and sellers. This dynamic oligopoly model arises in online shopping and dynamic spectrum sharing markets. The model gives rise to a stochastic dynamic game with asymmetric information. Using ideas from the common information approach (developed in [1] for decentralized decision-making), we prove the existence of common information based equilibria. We obtain a sequential decomposition of the game and we provide a backward induction algorithm to determine common information-based equilibria that are perfect Bayesian equilibria. We illustrate our results with an example.", "authors": ["Yi Ouyang", "Hamidreza Tavafoghi", "Demosthenis Teneketzis"], "n_citation": 4, "references": ["049095de-b40e-45b4-af95-1c9ac7bb7dcc", "32aff2ca-a754-4e98-949e-e5c09a1cc7a1", "370c42de-0ba1-49a2-b434-8e833ac30e8f", "514e0d40-7d4b-4f14-bb23-19db5a7f28ce", "5e3ab49a-9a2d-41d6-aebd-3120b1ab681d", "7886aefb-b213-470c-a234-5ead92292654", "a39be072-eb19-44ba-bc23-e89cf0a5a4ff", "adff270d-9a52-4307-aa7f-f1162437e80a", "af37ad1d-e89d-4e8e-bcea-6a8a8e48c444", "b4b91b6f-e09e-464d-9c3f-51ad772ae370", "d4aa0ca3-6514-4b0a-97e2-3e0beb7fcf7a", "de405be2-f3be-43b2-a365-ed5400ec9cf2", "eb075e36-08bf-4d66-8f0b-cc7e210b5d84", "f4992f60-efa9-421e-b155-9b4902fc616f"], "title": "Dynamic oligopoly games with private Markovian dynamics", "venue": "conference on decision and control", "year": 2015, "id": "fb6bdc1f-f34b-4b35-9cdb-1aca9a4c102b"}
{"abstract": "We give a tight analysis of the greedy algorithm introduced by Krumke and Wirth for the minimum label spanning tree problem. The algorithm is shown to be a (ln(n - 1) + 1)-approximation for any graph with n nodes (n < 1), which improves the known performance guarantee 2 ln n + 1.", "authors": ["Yingyu Wan", "Guoliang Chert", "Yinlong Xu"], "n_citation": 75, "references": ["a18e4afc-2829-4bcf-8f22-7b99658ba79f", "a4212fe4-f769-42d4-a8c6-e543540818db", "ffcaad21-0688-435d-8bb0-aa8a9b253430"], "title": "A note on the minimum label spanning tree", "venue": "Information Processing Letters", "year": 2002, "id": "4283029b-b2fa-423e-9fb4-197f18cba8a9"}
{"abstract": "In this paper we discuss a pilot user study that compares the use of two integrated development environments (IDEs), Eclipse and Gild, by novice programmers. Gild is a perspective for Eclipse that is intended to be more suitable for first-year students who are learning how to program in Java. This study focuses on qualitative and quantitative measures; the quantitative measures include: efficiency, effectiveness, satisfaction and understanding. Two statistically significant results are obtained from the satisfaction measure, in particular: the frustration level and the overall level of satisfaction. The mean differences for the remaining measures indicate that Gild was more suitable for novices than Eclipse. Qualitative analysis yields suggestions for improvement for both interfaces and also identifies areas of success.", "authors": ["Peter C. Rigby", "Suzanne Thompson"], "n_citation": 50, "references": ["8063f79c-5aa9-4fd0-8ec4-cd80d98e0c8e", "db5b857a-ea3a-4e5c-9341-f2c09fd757ea", "efe14e54-6495-4094-b841-7c5dba19b058"], "title": "Study of novice programmers using Eclipse and Gild", "venue": "eclipse technology exchange", "year": 2005, "id": "f4a8fc41-117f-4c4d-9da5-29cc9df3504b"}
{"abstract": "Currently, Grid research as well as distributed database research deals with data replication but both tackle the problem from different points of view. The aim of this paper is to outline both approaches and try to find commonalities between the two worlds in order to have a most efficient Data Grid that manages data stored in objectoriented databases. Our target object-oriented database management system is Objectivity/DB which is currently the database of choice in some existing High Energy Physics (HEP) experiments as well as in next generation experiments at CERN. The characteristics of Data Grids are described, especially within the High Energy Physics community, and needs for Data Grids are defined. The Globus toolkit is the Grid middle-ware on which we base our discussions on Grid research.", "authors": ["Heinz Stockinger"], "n_citation": 103, "references": ["1b213d72-3d78-479d-aeb7-d1b4d537800d", "76633948-1f65-47aa-bab2-60595021524a", "8b2a9481-1053-456d-b6bb-2ee9c1d22bcf", "90bcd3ab-d6b7-4917-b78d-3a6eab7e965a", "9db9578a-6f45-4630-a7ac-854a93cd5c55", "dd382532-9071-45aa-a6a6-382216d650d0"], "title": "Distributed Database Management Systems and the Data Grid", "venue": "", "year": 2001, "id": "63a48403-f47e-4e6a-ab34-d2ad8f00d3f2"}
{"abstract": "We introduce FunArray, a parametric segmentation abstract domain functor for the fully automatic and scalable analysis of array content properties. The functor enables a natural, painless and efficient lifting of existing abstract domains for scalar variables to the analysis of uniform compound data-structures such as arrays and collections. The analysis automatically and semantically divides arrays into consecutive non-overlapping possibly empty segments. Segments are delimited by sets of bound expressions and abstracted uniformly. All symbolic expressions appearing in a bound set are equal in the concrete. The FunArray can be naturally combined via reduced product with any existing analysis for scalar variables. The analysis is presented as a general framework parameterized by the choices of bound expressions, segment abstractions and the reduction operator. Once the functor has been instantiated with fixed parameters, the analysis is fully automatic.   We first prototyped FunArray in Arrayal to adjust and experiment with the abstractions and the algorithms to obtain the appropriate precision/ratio cost. Then we implemented it into Clousot, an abstract interpretation-based static contract checker for .NET. We empirically validated the precision and the performance of the analysis by running it on the main libraries of .NET and on its own code. We were able to infer thousands of non-trivial invariants and verify the implementation with a modest overhead (circa 1%). To the best of our knowledge this is the first analysis of this kind applied to such a large code base, and proven to scale.", "authors": ["Patrick Cousot", "Radhia Cousot", "Francesco Logozzo"], "n_citation": 113, "references": ["05187588-ada5-47d3-ab0d-a282be6fc447", "10adca6a-9f7a-44d4-bf6b-13c71d22ad21", "14a64143-c18e-41d3-b7ce-84d01602c3ab", "220412a4-8df9-493d-8325-9d3b062f2c72", "3911f07d-fbf5-48b5-85f1-129a1e0306ea", "3aa1d28c-6df3-4952-8da5-ab63bf0bbbc1", "4a4fcd3f-4cee-421c-bbe4-54f03c717d08", "565299c0-b315-4894-8198-6062ceb35f81", "5ac30865-1aba-4279-9430-6ba57c7a8892", "5f51f095-db6f-4ef7-bb7e-9aaeeb59b3b9", "635e2014-6579-4acf-9737-49593bc74701", "64868f34-1514-4d46-92ee-6122f7a6e7fc", "67770ebc-ee75-421d-95db-1952cafc5c05", "7016df95-d3b6-48bd-8cfb-62abdae9ff39", "7152c6eb-2452-494a-852d-2d438712085b", "7a595a89-6208-4e2e-8ac2-ca5664732700", "838d99b5-5b05-41a8-adc7-a597195fefad", "8cf429c1-7217-44a3-80b6-a2031bf9ca30", "970ee1cb-8750-4c8e-8e08-d3a236d843c5", "9a4984f9-27d4-47eb-8bc8-0469bf540f94", "a03c4210-1b18-4cfa-9017-c87a31597c18", "a4ee080c-bd84-4085-9958-5a4b2fb41bd4", "ab336aa6-bfb4-48a4-bf02-cd79ca826581", "b707baf4-29ee-410b-b9de-2ee7cc52ec71", "bc6341c2-ab97-4a7b-942e-3cbe0411386f", "c55ce9f8-b50e-4ecd-9c00-df8a8ee2ae93", "d426f13b-9d17-4e5b-ad92-e19d9e3f99a5", "f4270e7e-3819-424b-9ae1-93539fd8901e", "f5b9fcbf-a8b9-4be9-9d18-6bd6f2e5d303", "f6034171-845f-47d5-b260-e91dfacd8dea"], "title": "A parametric segmentation functor for fully automatic and scalable array content analysis", "venue": "symposium on principles of programming languages", "year": 2011, "id": "2a3ab5c5-284d-404d-b9cb-2f0a899eb76f"}
{"abstract": "Models for deterministic continuous-time nonlinear systems typically take the form of ordinary differential equations. To utilize these models in practice invariably requires discretization. In this paper, we show how an approximate sampled-data model can be obtained for deterministic nonlinear systems such that the local truncation error between the output of this model and the true system is of order /spl Delta//sup r+1/, where /spl Delta/ is the sampling period and r is the system relative degree. The resulting model includes extra zero dynamics which have no counterpart in the underlying continuous-time system. The ideas presented here generalize well-known results for the linear case. We also explore the implications of these results in nonlinear system identification.", "authors": ["Juan I. Yuz", "Graham C. Goodwin"], "n_citation": 101, "references": ["37f2aaf2-14cf-476c-ba4e-c4a4800f9dce", "8a308a6c-253c-49e6-8fa3-a90ab4ed4bbc", "967a144f-60bd-49b7-ac2f-9d2001dc48dd", "a7582d8c-2c44-4aa8-8027-7a144c234dbd", "bc81fe9f-533b-4010-a4eb-1f95b7382794"], "title": "On sampled-data models for nonlinear systems", "venue": "IEEE Transactions on Automatic Control", "year": 2005, "id": "65b5792a-1158-4559-a19f-96ba1df257c0"}
{"abstract": "We present control methods for an autonomous four-rotor helicopter, called a quadrotor, using visual feedback as the primary sensor. The vision system uses aground camera to estimate the pose (position and orientation) of the helicopter. Two methods of control are studied - one using a series of mode-based, feedback linearizing controllers, and the other using a backstepping-like control law. Various simulations of the model demonstrate the implementation of feedback linearization and the backstepping controllers. Finally,. we present initial flight experiments. where the helicopter is restricted to vertical and yaw motions.", "authors": ["Erdinc Altug", "James P. Ostrowski", "Robert E. Mahony"], "n_citation": 587, "references": ["e016fc9f-139b-4568-b5c5-c315b45a274d"], "title": "Control of a quadrotor helicopter using visual feedback", "venue": "international conference on robotics and automation", "year": 2002, "id": "bcac4659-3dc4-4d8e-9254-440ac1ea27a7"}
{"abstract": "This paper proposes a novel multifractal traffic model, and an associated parameter fitting procedure, based on stochastic L-systems, which were introduced by biologist A. Lindenmayer (1968) as a method to model plant growth. We provide a detailed comparison with a related multifractal model based on conservative cascades. Our results, that include applying the fitting procedure to real observed data with multifractal scaling behavior, show that L-system based models can achieve excellent fitting performance in terms of first and second order statistics and queuing behavior.", "authors": ["Paulo Salvador", "Ant\u00f3nio Nogueira", "Rui Valadas"], "n_citation": 4, "references": ["2222f1f9-b357-45ef-8943-ae096e660c5f", "5c62ace1-7b17-4a08-b944-f9757065f3bc", "5ca9f573-14f9-4b7e-91e4-979d54447977", "6734208b-3be3-4d23-b684-7c35f8e6f107", "ab48f870-29a1-4db2-aa9d-6d44a7137916", "c87f8eba-8226-46b8-8e28-f21044936c6c", "f42e671e-7a91-499d-a7ba-05a9c276f622"], "title": "Modeling multifractal traffic with stochastic L-systems", "venue": "global communications conference", "year": 2002, "id": "02f8f5d3-4dcf-46fc-a8f7-d68a15e2d70b"}
{"abstract": "There is a class of packet processing applications that inspect packets deeper than the protocol headers to analyze content. For instance, network security applications must drop packets containing certain malicious Internet worms or computer viruses carried in a packet payload. Content forwarding applications look at the hypertext transport protocol headers and distribute the requests among the servers for load balancing. Packet inspection applications, when deployed at router ports, must operate at wire speeds. With networking speeds doubling every year, it is becoming increasingly difficult for software-based packet monitors to keep up with the line rates. We describe a hardware-based technique using Bloom filters, which can detect strings in streaming data without degrading network throughput. A Bloom filter is a data structure that stores a set of signatures compactly by computing multiple hash functions on each member of the set. This technique queries a database of strings to check for the membership of a particular string. The answer to this query can be false positive but never a false negative. An important property of this data structure is that the computation time involved in performing the query is independent of the number of strings in the database provided the memory used by the data structure scales linearly with the number of strings stored in it. Furthermore, the amount of storage required by the Bloom filter for each string is independent of its length.", "authors": ["Sarang Dharmapurikar", "Praveen Krishnamurthy", "Todd S. Sproull", "John W. Lockwood"], "n_citation": 569, "references": ["6401f9f6-145b-4e8a-b693-a3b58b54d5f8", "a7771804-31d8-4cce-8210-38096589bdfc", "b380878d-e9de-48cf-b630-682f368840c7", "bfef2e4a-c40b-4103-a25f-b71f755d4dd9", "e93140f8-ff5c-45c0-abd2-57dd471f4ed0"], "title": "Deep packet inspection using parallel bloom filters", "venue": "international symposium on microarchitecture", "year": 2004, "id": "47572265-8712-4dc6-a67b-441164423abe"}
{"abstract": "Usually formal methods adopt the traditional waterfall model of system design. New design methodologies, such as Open Distributed Processing and Object Oriented Design, allow for incremental and partial specification. In order to support such design methods, the issues of consistency between specifications and composition of (partial) specification become vital. This paper presents a general framework for dealing with partial specification, which is instantiated for the specification language LOTOS. Necessary and sufficient conditions for consistency to hold between LOTOS specifications are given, and an operational semantics for composition is proposed. Keywords: LOTOS, formal methods, consistency, composition, incremetal specification, refinement.", "authors": ["Maarten Steen", "Howard Bowman", "John Derrick"], "n_citation": 32, "references": ["255de218-d62f-4fca-b5e0-9b7492efa0be", "560a6ef5-c239-4f4b-826b-b2d88b8094f5"], "title": "Composition of LOTOS specifications", "venue": "", "year": 1995, "id": "460a5054-b853-48fa-8ed6-11bf896745a6"}
{"authors": ["Daniel N. Osherson", "Scott Weinstein"], "n_citation": 55, "references": ["3affdf45-39d4-4894-b95a-34575b18607c", "61bd766a-21c0-4a26-8293-70a05e1081f0"], "title": "Identification in the limit of first order structures", "venue": "Journal of Philosophical Logic", "year": 1986, "id": "73f1208a-0f38-4f25-9ee9-26cac78368b3"}
{"abstract": "From time to time a movement arises that promises to save the world, or at least to make it vastly better. The extraordinary achievements of digital computing make it a locus of such movements today. Yet we should be wary; when movements fail they provoke backlash that rejects the more limited gains that they might have afforded. Today \"computational thinking\" has a considerable following, and I would like to discuss some problems with its discourse. It is too often presented in terms that could be interpreted as arrogant or that are overstated. Its descriptions too often lack appropriate examples, and perhaps as a result, it gets misunderstood in casual writing.", "authors": ["David Hemmendinger"], "n_citation": 14, "references": ["6a21b18f-e47a-4c17-b438-4831dcf163c6", "9daac2f0-482a-493c-801b-b64756cc7989", "e4da4a76-0fcf-4510-a27e-073714963e9c"], "title": "A plea for modesty", "venue": "", "year": 2010, "id": "792adbfb-21fd-4660-8493-f5b4441cef0f"}
{"authors": ["Pavel Brazdil", "Jo\u00e3o Gama", "Bob Henery"], "n_citation": 175, "references": ["43e502f4-87f2-4672-9217-823cf6c56e56", "62549bc2-e0b3-46e8-8d32-390dded105d5", "76f3c558-4e06-4f2e-99af-a5172fab5cc4", "d82d7b47-ed52-49e4-9b6a-4c6ce39ec6be"], "title": "Characterizing the applicability of classification algorithms using meta-level learning", "venue": "", "year": 1994, "id": "4b0df874-c029-4993-9c36-50e795192cfb"}
{"abstract": "It is shown that a digital arc S is the digitization of a straight line segment if and only if it has the \"chord property:\" the line segment joining any two points of S lies everywhere within distance 1 of S. This result is used to derive several regularity properties of digitizations of straight line segments.", "authors": ["Azriel Rosenfeld"], "n_citation": 397, "references": ["1ba1b82a-698b-4cdb-985f-3bf57296db57", "3e7dc60a-f732-4915-b09b-29708a5b593b", "3fab6b4f-4a77-44c4-85e1-07585ba89e4d", "5aae80e6-ab8c-463a-81a8-bc4f4bf993c7", "acfcabe3-eda6-4b9d-93c3-d58e23179ec0", "fa6febd2-897d-4324-905a-6e31c012c47e"], "title": "Digital Straight Line Segments", "venue": "IEEE Transactions on Computers", "year": 1974, "id": "dfd8f3c4-fab3-4b7c-90a9-1978f11be189"}
{"abstract": "The design and development of distributed software is a complex task. This was not different in OurGrid, a project whose objective was to develop a free-to-join grid. After two years of development, it was necessary to redesign OurGrid in order to cope with the integration problems that emerged. This paper reports our experience in using Aspect-Oriented Programming (AOP) in the process of redesigning the OurGrid middleware. The essential direction of our approach was to get the project (and the software) back in shape. We discuss how the lack of separation of concerns created difficulties in the project design and development and how AOP has been introduced to overcome these problems. In particular, we present the event-based pattern designed to better isolate the middleware concerns and the threads. Besides, we also present the aspects designed for managing the threads and for aiding the testing of multithreaded code. We also highlight the lessons learned in the process of regaining control of the software.", "authors": ["Ayla Dantas", "Walfredo Cirne", "Katia Barbosa Saikoski"], "n_citation": 50, "references": ["02037b99-a48a-4a46-9516-9e038b52f4dc", "1dc17a99-d952-48fe-83b5-3ca7e629478f", "28aed1df-e34a-42b2-85eb-83eff115ce1f", "2a32af98-d20f-446d-b749-d4ad9e72d0a3", "41318979-3d2d-464e-85e4-372bdd6430c5", "4c3ea816-85d9-4903-b52e-77af36ed9640", "4df004e1-b013-4da9-8157-0999add3a12b", "7043f825-5afb-4f56-847b-7babafe45a1d", "744b179c-68d6-4e58-8e0b-aec60b3964f5", "892ce023-e197-4f8c-8d6b-39a5842db1fb", "8b57a3d5-2a29-4cd8-9a8b-ab04ea2fbcf2", "8f18db81-b778-40e6-a891-695556dda50e", "a0fb7233-1626-41cf-bbdf-1d41127c0af3", "af5f248a-b6d9-41f8-9d18-914b921f3fe4", "aff8c6fa-8362-415d-abe8-e65c6562ed91", "b5e0d4f5-e2c4-4246-b2ce-50f65d53e767", "bd676d52-5982-4b66-80a3-35038127a8ce", "c7d8ebe4-dfc4-4122-bf06-8f3214f2ab59", "c8b5a8d7-98b6-49cd-8ae7-3dd91ba2ce11", "c9e7f588-1ef4-4b5e-9bab-a7e106d701ce", "e84cebd7-a220-4e70-b72f-22d17f88c3e0"], "title": "Using AOP to bring a project back in shape: The OurGrid case", "venue": "Journal of the Brazilian Computer Society", "year": 2005, "id": "ae3bb6c9-d922-4b35-916a-da7f0db4b311"}
{"authors": ["Alptekin Erkollar", "Birgit Oberer"], "n_citation": 2, "references": ["57978ded-87ae-4d8d-a30d-cca89a69792b", "98014293-861d-4134-be7f-63f1c18746cd", "a2caf930-704d-496b-b8d2-3747ac58ac37"], "title": "Anytime. Everywhere. Mobile Learning in Higher Education: Creating a GIS Course", "venue": "", "year": 2012, "id": "19a72f60-c697-4bc5-a3e4-d9c2f7561d10"}
{"abstract": "Sensitivity analysis plays an important role in model development, calibration, uncertainty analysis, scenario analysis, and, hence, decision making. With the availability of different sensitivity analysis techniques, selecting an appropriate technique, monitoring the convergence and estimating the uncertainty of the sensitivity indices are very crucial for environmental modelling, especially for distributed models due to their high non-linearity, non-monotonicity, highly correlated parameters, and intensive computational requirements. It would be useful to identify whether some techniques outperform others with respect to computational requirements, reliability, and other criteria. This paper proposes two methods to monitor the convergence and estimate the uncertainty of sensitivity analysis techniques. One is based on the central limit theorem and the other on the bootstrap technique. These two methods are implemented to assess five different sensitivity analysis techniques applied to an environmental model. These techniques are: the Sobol' method, the Morris method, Linear Regression (LR), Regionalized Sensitivity Analysis (RSA), and non-parametric smoothing. The results show that: (i) the Sobol' method is very robust in quantifying sensitivities and ranking parameters despite a large number of model evaluations; (ii) the Morris method is efficient to rank out unimportant parameters at a medium cost; (iii) the non-parametric smoothing is reliable and robust in quantifying the main effects and low-order interactions while requiring a small number of model evaluations; finally (iv) the other two techniques, that is, LR and RSA, should be used with care.", "authors": ["Jing Yang"], "n_citation": 82, "references": ["071bfb27-409a-45e5-951c-42b1c380a887", "4780b204-6e92-4639-a634-e85658a01bf0", "5a3d8bdd-70fa-477e-84b6-ed28b7a54e12", "66053859-1e2b-44a2-be45-13f5fb239449", "663ee381-6b4d-4340-bc8d-d6d704e9cab0", "9a131715-8dc5-4c1e-ba6f-86ef920b6e8a", "9e8251d3-bc8b-487b-b7c8-5b55b811e8e9", "a4d48359-b884-422b-bb6d-d0959f551fee", "ba361dc8-0f29-4e2e-bb23-abc472fb757b", "da08093c-3a97-4acb-96e2-a350061d055c", "edcb413e-0605-432e-a6ff-703d3dab8721", "f43dbc7b-018d-49b1-8eda-dd520b80aa81"], "title": "Convergence and uncertainty analyses in Monte-Carlo based sensitivity analysis", "venue": "Environmental Modelling and Software", "year": 2011, "id": "969b79d4-bb5b-4b59-a591-dc356164e407"}
{"abstract": "The stochastic optimal controller design for the nonlinear networked control system (NNCS) with uncertain system dynamics is a challenging problem due to the presence of both system nonlinearities and communication network imperfections, such as random delays and packet losses, which are not unknown a priori. In the recent literature, neuro dynamic programming (NDP) techniques, based on value and policy iterations, have been widely reported to solve the optimal control of general affine nonlinear systems. However, for realtime control, value and policy iterations-based methodology are not suitable and time-based NDP techniques are preferred. In addition, output feedback-based controller designs are preferred for implementation. Therefore, in this paper, a novel NNCS representation incorporating the system uncertainties and network imperfections is introduced first by using input and output measurements for facilitating output feedback. Then, an online neural network (NN) identifier is introduced to estimate the control coefficient matrix, which is subsequently utilized for the controller design. Subsequently, the critic and action NNs are employed along with the NN identifier to determine the forward-in-time, time-based stochastic optimal control of NNCS without using value and policy iterations. Here, the value function and control inputs are updated once a sampling instant. By using novel NN weight update laws, Lyapunov theory is used to show that all the closed-loop signals and NN weights are uniformly ultimately bounded in the mean while the approximated control input converges close to its target value with time. Simulation results are included to show the effectiveness of the proposed scheme.", "authors": ["Hao Xu", "Sarangapani Jagannathan"], "n_citation": 51, "references": ["08298542-c6c8-4956-902a-b3c68716950a", "3ccc0fae-57b9-4971-8371-b3391eb7858e", "538b2394-acac-40f0-bcf2-006e8dc0916a", "5c5da16c-d3b5-4820-a16f-20e12b933d6b", "68ce5329-1129-4d2d-ae4c-dfbf80ee0e1f", "8712a494-25bc-4526-b8a2-3108e3306748", "8a827bd8-50f9-44a7-af8f-bfac4ae665ec", "a5280b4e-b528-4fbf-be74-9ec81596d873", "b8646e81-6aca-432d-9f3b-8801398c05f8"], "title": "Stochastic Optimal Controller Design for Uncertain Nonlinear Networked Control System via Neuro Dynamic Programming", "venue": "IEEE Transactions on Neural Networks", "year": 2013, "id": "2dd4089a-471c-4684-a0df-65ecc2782f85"}
{"abstract": "Space-time block codes (STBCs) from orthogonal designs proposed by Alamouti, and Tarokh-Jafarkhani-Calderbank have attracted considerable attention lately due to their fast maximum-likelihood (ML) decoding and full diversity. However, the maximum symbol transmission rate of an STBC from complex orthogonal designs for complex signals is only 3/4 for three and four transmit antennas, and it is difficult to construct complex orthogonal designs with rate higher than 1/2 for more than four transmit antennas. Recently, Jafarkhani, Tirkkonen-Boariu-Hottinen, and Papadias-Foschini proposed STBCs from quasi-orthogonal designs, where the orthogonality is relaxed to provide higher symbol transmission rates. With the quasi-orthogonal structure, the quasi-orthogonal STBCs still have a fast ML decoding, but do not have the full diversity. The performance of these codes is better than that of the codes from orthogonal designs at low signal-to-noise ratio (SNR), but worse at high SNR. This is due to the fact that the slope of the performance curve depends on the diversity. It is desired to have the quasi-orthogonal STBCs with full diversity to ensure good performance at high SNR. In this paper, we achieve this goal by properly choosing the signal constellations. Specifically, we propose that half of the symbols in a quasi-orthogonal design are chosen from a signal constellation set A and the other half of them are chosen from a rotated constellation e/sup j/spl phi// A. The resulting STBCs can guarantee both full diversity and fast ML decoding. Moreover, we obtain the optimum selections of the rotation angles /spl phi/ for some commonly used signal constellations. Simulation results show that the proposed codes outperform the codes from orthogonal designs at both low and high SNRs.", "authors": ["Weifeng Su", "Xiang-Gen Xia"], "n_citation": 593, "references": ["102c3fe9-23ee-4521-bed0-f102d3ac23dd", "18d9f900-d2f5-416d-98d8-0cb7a2ca0727", "1da458f4-2375-4da1-96ab-bf824835ae62", "1dfa434a-de30-475a-8125-4c8604c9d168", "2659531e-eb9d-4dd5-b46f-10f66a4819c6", "324c0cc6-829c-4b4f-8ef4-5f2d9b34bf58", "3251e2ff-5a08-4d5c-98d9-52e1ea447d24", "334d62da-9162-4f2f-bcf5-718213dc8dbe", "3894525d-0d2d-404f-8087-a3223ccd4f9e", "3beb8139-9ef5-4e9f-9d1a-417740f4704a", "4eec044b-7d46-4ebd-b387-4adca987ad43", "748a2ab3-8b5f-4d0a-9e2d-af685089843a", "75d804f1-0505-47bf-b7a7-ddbf473c0638", "85bd9cc6-e41a-4fd4-8f3b-e776329efc4b", "8e293977-78f3-4045-b8ed-13660543902b", "9827d620-908e-4b6b-9e74-eac161e32d39", "aef8a0bd-4a41-44a5-9033-e11bc8648096", "b69ec93b-f678-472d-942e-e5fec4b751d6", "b8b95e2e-7a6e-4688-9788-5e5b350f4275", "ba3106c1-82a8-44bf-9e59-ce9b1a0da898", "cab91964-4e8d-4211-8d32-455cfd690b60", "d0f8886d-cf41-4887-a49b-ea009540de2f", "f6c8d847-401c-4b92-8732-6b3daa96618c", "faae1996-07e7-424a-86dc-3d570769a95a", "ff6761b7-9d0a-4784-a9c5-fd6c0a2a2ad1"], "title": "Signal constellations for quasi-orthogonal space-time block codes with full diversity", "venue": "IEEE Transactions on Information Theory", "year": 2004, "id": "30e3f8b0-6911-4176-bc78-7bc097a853af"}
{"abstract": "Previous work has found that (a) when software is developed collaboratively, concurrent accesses to related pieces of code are made, and (b) when these accesses are coordinated asynchronously through a version control system, they result in in- creased defects because of conflicting concurrent changes. Previous findings also show that distance collaboration aggravates software-development problems and radical co- location reduces them. These results motivate a semi-synchronous distributed computer- supported model that allows programmers creating code asynchronously to synchro- nously collaborate with each other to detect and resolve potentially conflicting tasks be- fore they have completed the tasks. We describe, illustrate, and evaluate a new model designed to meet these requirements. Our results show that the model can catch con- flicts at editing time that would be expensive to manage at later times.", "authors": ["Prasun Dewan", "Rajesh Hegde"], "n_citation": 108, "references": ["19a6a302-a0b4-4440-8e58-b7bbe2e71898", "2ff7cc88-e6ff-4099-9e6d-5ec86d927a12", "3695a095-0fab-4141-bdc4-2d24cb097352", "54d1c433-8229-4d9f-ad99-89b4ce3000fd", "5f5a1715-d7b0-4659-947a-afec905e30bc", "61184aa4-cf1d-4aac-8a8a-4892c3033a76", "6f2cc448-5ad0-4883-9203-df3f2626e0b1", "7d57c7e1-6355-4d2a-aef2-ebdc200ad727", "831a050c-7e7e-46ed-a9dc-baabacdff05f", "92315972-39b7-4a93-9269-5b3bd52b8cb6", "9f141f8a-d30b-4151-964b-c29aa5fefb0a", "aad6ef8f-2da9-4811-86bd-9698851a844b", "b9bdee88-c0d1-487b-ba5f-a2b3a4b82985", "c2f414b5-f64a-45fb-92c1-2ecaa527d59d", "cecbf5fd-148a-4de9-ae11-b3be17a004d1", "dea6e9fa-8b45-4a45-ba70-483b73dbaaa9", "f757a5e2-6487-4b8d-9a43-416aa0ba81e8", "fbd0e911-36d2-45e9-a1d4-a1bfa2e88f90"], "title": "Semi-synchronous conflict detection and resolution in asynchronous software development", "venue": "european conference on computer supported cooperative work", "year": 2007, "id": "65d1ad8e-f19e-4563-8cac-cf7bb9633d84"}
{"abstract": "In recent years, more and more researchers have been involved in research on both agent technology and data mining. A clear disciplinary effort has been acti- vated toward removing the boundary between them, that is the interaction and inte- gration between agent technology and data mining. We refer this to agent mining as a new area. The marriage of agents and data mining is driven by challenges faced by both communities, and the need of developing more advanced intelligence, informa- tion processing and systems. This chapter presents an overall picture of agent mining from the perspective of positioning it as an emerging area. We summarize the main driving forces, complementary essence, disciplinary framework, applications, case studies, and trends and directions, as well as brief observation on agent-driven data mining, data mining-driven agents, and mutual issues in agent mining. Arguably, we draw the following conclusions: (1) agent mining emerges as a new area in the scientific family, (2) both agent technology and data mining can greatly benefit from agent mining, (3) it is very promising to result in additional advancement in intel- ligent information processing and systems. However, as a new open area, there are many issues waiting for research and development from theoretical, technological and practical perspectives.", "authors": ["Longbing Cao"], "n_citation": 50, "references": ["05ae3084-e01d-4afd-bdc3-d391dac51a50", "11f8c219-c092-43b4-9cf8-cb2bd05e9055", "12c2f824-00d9-4f22-b9ba-a18d0f9880c7", "1d139842-6a70-4045-804f-7531362396c1", "3bd28380-fc3b-416b-9a37-ccf02b4829d8", "52c2b80c-79e8-4f32-8d5f-680405e0d409", "56a6103d-45f0-472e-b44e-a83ba8411f62", "605d96bd-03a5-4c0f-aa5c-1c5014699d73", "75592d24-605b-42bc-a040-10d764c67e11", "762181b1-c92d-409b-ae79-b8cc7f124b43", "77357841-776b-4184-a609-93cd7fd9d3fc", "7e85890e-78df-4462-8795-bd39a251fce6", "8c7a6f06-eed4-440d-bf32-c26bd6fd1401", "ba17b645-afbf-4fa8-9986-d44faf0c9911", "bf9c7d2a-4fe0-43db-936e-0ebe3456c7c2", "c555cbf1-13fb-4a59-bf05-8c5546e92be8", "cb7f34e5-6603-42da-b0e3-035630fca599", "db3c9df4-1304-4780-b29c-4adad665fd72", "dfd77165-057b-4333-862d-7e9ca08b3868", "ef1aa54f-dee8-4082-ba03-7c7b3c151e1a", "f8564918-fa13-4317-b712-8621e2d7ad98", "f8fef5f1-407c-4a97-a851-422d8a2953ac"], "title": "Introduction to Agent Mining Interaction and Integration", "venue": "", "year": 2009, "id": "c490b341-7653-48a3-9f8d-24ad8ad2bf4a"}
{"abstract": "Scheduling analysis in real-time systems require an off-line feasibility (schedulability) test to guarantee the response time of critical tasks. There are fast and efficient tests for static schedulers. However, when a dynamic scheduler is required, the available tests are not as feast and efficient as static ones. In this paper, two different characterizations of feasible task sets are presented. These characterizations lead to an new feasibility algorithm. The proposed algorithm has an worst-case exponential complexity, but experimental results indicated that it runs on pseudo-polynomial time for a very large percentage of task sets. The algorithm also provides a sufficient condition for feasible asynchronous task sets. One of the main contributions of this work is the theoretical approach used to obtain the new feasibility test. The results of a large number of simulations, as well as, the theoretical demonstrations point out the improvements reached over previous tests.", "authors": ["Ismael Ripoll", "Alfons Crespo", "Aloysius K. Mok"], "n_citation": 184, "references": ["1040cc98-4c40-4081-8eb8-c5a75897c098", "533ace90-fd57-4a85-bd79-1ac608fb639a", "86347feb-607b-4852-8001-87595a663b89", "8a1a043c-28c9-4575-8e8d-afeee28a0069", "9a0d9ce5-5d3c-498f-8151-0e8d28b9f95d", "a558c905-8585-4610-8ddf-243e2cb2648e", "c3302d0a-4a20-4cac-ab6a-5306eadcd538", "d7eb74d3-04a3-476b-8e3d-563f6729ca3b", "eedd9e22-f588-4f83-8f98-6f1f049b99dc"], "title": "Improvement in feasibility testing for real-time tasks", "venue": "Real-time Systems", "year": 1996, "id": "2d411fb6-7cb2-420f-b019-7e23bcb10c68"}
{"authors": ["Bernhard Steffen", "Tiziana Margaria"], "n_citation": 4, "title": "Method engineering for real-life concurrent systems", "venue": "ACM Computing Surveys", "year": 1996, "id": "19fa6c29-bf14-4c13-85c2-c3195b8d47e6"}
{"abstract": "In this paper, tabu search for SAT is investigated from an experimental point of view. To this end, TSAT, a basic tabu search algonthm for SAT, is introduced and compared With Selman et al. Random Walk Strategy GSAT procedure, in short RWS-GSAT. TSAT does not involve the additional stochastic process of RWS-GSAT. This should facilitate the understanding of why simple local search methods for SAT work. It is shown that the length of the tabu list plays a critical role in the performance of the algorithm. Moreover surprising properties about the (experimental) optimal length of the tabu list are exhibited, raising interesting issues about the nature of hard random SAT problems.", "authors": ["Bertrand Mazure", "Lakhdar Sais", "\u00c9ric Gr\u00e9goire"], "n_citation": 202, "references": ["1e4e8925-3328-4af5-be88-56eef2f6aa8f", "288dce14-855c-4502-a7d2-cbc4dee2a31e", "365a72f8-0909-4c37-a154-470caa5d1dd3", "45147d7b-255d-45e0-85c6-5646b1f039c7", "66e25c15-7854-4c64-afee-209d2413ce8b", "72bc81b3-b0b9-48d0-8471-0db3a399360a", "7c12a367-1741-4aab-b8a9-952f86e61538", "8d09527f-b5ad-4902-ba34-5583f6759d3b", "c0a69970-4b14-492a-adcc-6928988a9f2a", "cf7f48dd-fc88-4f47-8f8e-f7b24e5de011"], "title": "Tabu search for SAT", "venue": "national conference on artificial intelligence", "year": 1997, "id": "5b025b8e-fdd7-4d96-a0b1-bd37ae973bce"}
{"abstract": "Previous work on tracking source locations has focused on tracking lines through multiple revisions of software. In this paper, we explore a new technique for tracking statements, rather than lines, across multiple revisions of Java source code. We show that our statement-tracking technique achieves comparable accuracy for source code than the most accurate line-tracking techniques, while also safely handling all non-executable formatting changes, such as breaking a single statement across many lines, adding or removing whitespace, moving brackets, or re-ordering methods. Finally, we compare the performance of three of the current state-of-the-art techniques for tracking lines across revisions on a series of benchmarks, and discuss the strengths and weaknesses of each technique.", "authors": ["Jaime Spacco", "Chadd C. Williams"], "n_citation": 4, "references": ["1adef97b-e0d8-4d0c-8a28-526e2b898301", "2c850a6b-215d-4eaf-9dc2-d2e8e7e06766", "2f3c4b2d-e85e-440e-8f3b-4323a0296719", "3c20ace8-7ab4-48be-9da0-ada5c87324e3", "47ac94fe-2cc9-48e6-9d53-c7cc20d7857d", "6b884765-eeff-4697-a8c4-6ef5c9a87347", "6f353434-5bcb-4067-b854-d66315c1fb42", "7e3ecc68-1e92-4e48-91bd-3ad58ef2469a", "840eb898-ae9e-4c86-868b-bdb83cb995b8", "86877346-2923-4ad6-b986-430a48970504", "963e92f8-3e64-4927-a980-97273419aaff", "abfb2630-3955-470b-b354-fe3d230ba3e3", "c0183ac9-2586-40b4-ad76-cb577472e3b1", "c9d3e4ee-3cec-4e26-bb2c-4346516af435"], "title": "Lightweight Techniques for Tracking Unique Program Statements", "venue": "source code analysis and manipulation", "year": 2009, "id": "135a73d7-4f18-444e-84d3-fc1fafbfe83f"}
{"abstract": "We discuss the Hegselmann-Krause model for opinion dynamics in discrete-time for a symmetric confidence bound. We construct an adjoint dynamics and use it to define a Lyapunov comparison function that decreases along the trajectory of the opinion dynamics. Using the Lyapunov comparison function, we develop a novel upper bound on the convergence time of the dynamics.", "authors": ["Behrouz Touri", "Angelia Nedic"], "n_citation": 50, "references": ["0d59a602-6e38-49c2-a73f-fd5d4c855869", "3a6c777a-aefc-4d72-bc91-54b2ef5a7c7d", "6460eee0-033e-4185-8b7c-dbcb931e1b2c"], "title": "Discrete-time opinion dynamics", "venue": "", "year": 2011, "id": "423eaadb-e6d9-4cc2-a503-aa0bb72d70d7"}
{"abstract": "We propose new antichain-based algorithms for checking universality and inclusion of nondeterministic tree automata (NTA). We have implemented these algorithms in a prototype tool and our experiments show that they provide a significant improvement over the traditional determinisation-based approaches. We use our antichain-based inclusion checking algorithm to build an abstract regular tree model checking framework based entirely on NTA. We show the significantly improved efficiency of this framework through a series of experiments with verifying various programs over dynamic linked tree-shaped data structures.", "authors": ["Ahmed Bouajjani", "Peter Habermehl", "Luk\u00e1\u0161 Hol\u00edk", "Tayssir Touili", "Tom\u00e1\u0161 Vojnar"], "n_citation": 44, "references": ["17affb65-1514-45d7-9fa2-67441f547f56", "17c5d23c-bc07-4a3e-8c4c-a81bf245848c", "53ae5230-eb46-4c88-ae96-84e11756e1ad", "554c5476-5088-4e02-9d31-c79a35b06f67", "5ea22c55-9931-4738-9525-3ba509d4b37e", "9849d9c4-a97f-452f-882c-42a8c6cab0b5", "fe9441a7-bb8d-46d1-8742-f0effb217dbe"], "title": "Antichain-Based Universality and Inclusion Testing over Nondeterministic Finite Tree Automata", "venue": "", "year": 2008, "id": "f2e18f3f-93d8-4073-b128-b9a913164ba7"}
{"abstract": "Traditional discrete-event simulations employ an inherently sequential algorithm. In practice, simulations of large systems are limited by this sequentiality, because only a modest number of events can be simulated. Distributed discrete-event simulation (carried out on a network of processors with asynchronous message-communicating capabilities) is proposed as an alternative; it may provide better performance by partitioning the simulation among the component processors. The basic distributed simulation scheme, which uses time encoding, is described. Its major shortcoming is a possibility of deadlock. Several techniques for deadlock avoidance and deadlock detection are suggested. The focus of this work is on the theory of distributed discrete-event simulation.", "authors": ["Jayadev Misra"], "n_citation": 1259, "references": ["0e9361ef-fad3-4f5c-b576-5c751cc938eb", "10dd8ddf-0bb3-405b-9461-4f424318c988", "13b0b505-2ba4-490e-a14d-ab58d5715137", "517f5545-8cad-48c4-8ef4-921bb2d6b042", "67acefc2-b722-4b94-a034-8f4ffdbc0f99", "832acb23-caba-4e3a-99ea-34345fff1fe4", "bad973cb-6f4b-46e3-a017-d2e3f7fb2156", "d27a6ec2-bde4-4155-862e-2e4dc992ea9e", "d9214fae-410d-428d-be93-df0830818e79", "f4ea1c5a-917a-4632-b2bf-7c5a074534b5", "f6b8341a-0222-4ed4-a326-29d7d9edad08"], "title": "Distributed discrete-event simulation", "venue": "ACM Computing Surveys", "year": 1986, "id": "4dca7d73-a3c4-4add-936e-ad2eca2ef718"}
{"abstract": "This paper argues that semantic information encoded in natural language identifiers is a largely neglected resource for program analysis. First we show that words in Java class names relate to class properties, expressed using the recently developed micro patterns language. We analyse a large corpus of Java programs to create a database that links common class name words with micro patterns. Finally we report on prototype tools integrated with the Eclipse development environment. These tools use the database to inform programmers of particular problems or optimization opportunities in their code.", "authors": ["Jeremy Singer", "Chris C. Kirkham"], "n_citation": 50, "references": ["15ce814d-8d79-4141-95dc-80282d967898", "2f320d85-20ce-47d2-b707-7e06f79a8ddc", "ae1424e5-731f-42ae-8582-c1e7feae9660", "b87a4fe7-505c-4b97-8568-570b158f3373", "c9c52265-06ef-460d-8e58-58e52e1258b4", "e07369ee-f5be-46a6-94d3-664c5966dedf", "e2e8ebf0-3981-4496-9d96-6637e61292d0", "f740dcab-868e-4ce0-af53-8be55e800346"], "title": "Exploiting the Correspondence between Micro Patterns and Class Names", "venue": "source code analysis and manipulation", "year": 2008, "id": "9cb11b9c-ea85-4b18-9b4c-c9d3a784aceb"}
{"abstract": "In wireless ad-hoc networks, network partitioning occurs when the mobile nodes move with diverse patterns and cause the network to separate into completely disconnected portions. Network partitioning is a wide-scale topology change that can cause sudden and severe disruptions to ongoing network routing and upper layer applications. Its occurrence can be attributed to the aggregate group motion exhibited in the movements of the mobile nodes. By exploiting the group mobility pattern, we can predict the future network partitioning, and thus minimize the amount of disruption. We propose a new characterization of group mobility, based on existing group mobility models, which provides parameters that are sufficient for network partition prediction. We then demonstrate how partition prediction can be made using the mobility model parameters and illustrate the applicability of the prediction information. Furthermore, we use a simple but effective data clustering algorithm that, given the velocities of the mobile nodes in an ad-hoc network, can accurately determine the mobility groups and estimate the characteristic parameters of each group.", "authors": ["Karen H. Wang", "Baochun Li"], "n_citation": 259, "references": ["b2acda61-f787-4f76-8dca-88fc3ef801be"], "title": "Group mobility and partition prediction in wireless ad-hoc networks", "venue": "international conference on communications", "year": 2002, "id": "6af149b3-575c-47e6-a433-36d67fb3020a"}
{"abstract": "It has been recently shown (e.g., Hornik, Stinchcombe & White, 1989, 1990) that sufficiently complex multilayer feedforward networks are capable of representing arbitrarily accurate approximations to arbitrary mappings. We show here that these approximations are learnable by proving the consistency of a class of connectionist nonparametric regression estimators for arbitrary (square integrable) regression functions. The consistency property ensures that as network \u201cexperience\u201d accumulates (as indexed by the size of the training set), the probability of network approximation error exceeding any specified level tends to zero. A key feature of the demonstration of consistency is the proper control of the growth of network complexity as a function of network experience. We give specific growth rates for network complexity compatible with consistency. We also consider automatic and semi-automatic data-driven methods for determining network complexity in applications, based on minimization of a cross-validated average squared error measure of network performance. We recommend cross-validated average squared error as a generally applicable criterion for comparing relative performance of differing network architectures and configurations.", "authors": ["Halbert White"], "n_citation": 520, "references": ["0fff9597-d6b0-4400-91fc-67e77efc51e0", "1a642cf3-caad-4cc2-ae3d-82f46013a0be", "6dfd5bec-b651-4dfb-915d-a284335b47ea", "7b75127a-9fc0-4fa3-85dd-1e9744d3addb", "8d7bb750-adbb-4a71-813f-09fdfab8f7d0", "9c968227-9170-48da-b937-46b451271ab4"], "title": "Connectionist nonparametric regression: multilayer feedforward networks can learn arbitrary mappings", "venue": "Neural Networks", "year": 1990, "id": "2c9f10eb-229d-45cc-84ef-46844deb28ef"}
{"abstract": "DNA self-assembly is an emerging technology with potential as a future replacement of conventional lithographic fabrication. A key challenge is the specification of appropriate DNA sequences that are optimal according to specified metrics and satisfy various design rules. To meet this challenge we developed a thermodynamics-based design automation tool to evaluate the vast DNA sequence space (2.8k base pairs) and select appropriate sequences. We use this tool to design DNA nanostructures that were previously impossible with existing text distance based tools. We also show that for nanoscale structures our approach produces superior results compared to existing tools.", "authors": ["Constantin Pistol", "Alvin R. Lebeck", "Chris Dwyer"], "n_citation": 50, "references": ["192594cb-3456-4576-933f-58877703a727", "cc1ac4d3-7ab1-480d-9f93-b1ebb7629b54"], "title": "Design automation for DNA self-assembled nanostructures", "venue": "design automation conference", "year": 2006, "id": "c7b511e2-0dfc-4a1c-9289-8287cc98b1ed"}
{"authors": ["Eric Chien", "Liam O'Murchu", "Nicolas Falliere"], "n_citation": 29, "title": "W32.Duqu: The Precursor to the Next Stuxnet.", "venue": "", "year": 2012, "id": "a9abb8ee-5440-4d66-acdb-f70a9bc30b25"}
{"abstract": "Different types of decentralized clustering problems have been studied so far for networks and multi-agent systems. In this paper we introduce a new type of a decentralized clustering problem for networks. The so called Decentralized Packet Clustering (DPC) problem is to find for packets that are sent around in a network a clustering. This clustering has to be done by the routers using only few computational power and only a small amount of memory. No direct information transfer between the routers is allowed. We investigate the behavior of new a type of decentralized k-means algorithm \u2014 called DPClust \u2014 for solving the DPC problem. DPClust has some similarities with ant based clustering algorithms. We investigate the behavior of DPClust for different clustering problems and for networks that consist of several subnetworks. The amount of packet exchange between these subnetworks is limited. Networks with different connection topologies for the subnetworks are considered. A dynamic situation where the packet exchange rates between the subnetworks varies over time is also investigated. The proposed DPC problem leads to interesting research problems for network clustering.", "authors": ["Daniel Merkle", "Martin Middendorf", "Alexander Scheidler"], "n_citation": 50, "references": ["418e2f38-1ccd-4874-be4e-df74d4e83ebb", "7551713b-74b5-4f81-9e75-8fd0505d8899", "7a1025ca-cb91-4502-8842-eb019baa3d66", "8ad736b8-ce50-4345-b338-9f58cc7b077f", "b34f5afa-69e0-4f04-96c3-958a9ca5231c", "b606ec42-daad-4e2a-ac15-b6d63eded286", "e100dd96-1ad2-4305-94d2-f0cf637d4f72", "e78546a1-9506-43b8-bf27-d065afe67731", "f771cc6a-f097-48ad-bd40-06940e805ada", "fd9c79e0-2819-46df-bfb3-d79bccc3c097"], "title": "DECENTRALIZED PACKET CLUSTERING IN ROUTER-BASED NETWORKS", "venue": "International Journal of Foundations of Computer Science", "year": 2005, "id": "da4a3608-2f44-4b10-938f-9929ebd47fe4"}
{"abstract": "The nilpotent minima are important t-norms in fuzzy logic and fuzzy reasoning. Two interesting formal systems--nilpotent minimum logic NM and L*-based on nilpotent minima have been proposed and have been intensively studied. In this paper, their equivalence is pointed out. Moreover, coincidence of two related algebraic structures--NM- and R0-algebras--is also proved. In addition, we give an equivalent form of involutive monoidal t-norm-based logic IMTL.", "authors": ["Daowu Pei"], "n_citation": 117, "references": ["2691a264-e579-46d6-8d9c-4346e2b6b228", "6377c301-f0dc-4157-989d-01672fd87755", "6b8a932d-3ad5-4aaa-a39a-dbdc5d08c843", "7880479f-d765-4925-b4dc-30d9aa6af285", "c6a30262-e87a-4289-857c-3a1348115f2b", "d3d3c523-6e6e-4d77-94ea-ccb92d2ba127", "eabae987-2b37-44f8-89a4-633792da2bb2", "eb8821f0-35a9-4bd3-a5d3-427e946ef54c", "f2a20815-2d92-421b-92a0-4b375df2379b", "fe5d1365-69e9-47ed-8bfd-ce0cbdb173db"], "title": "On equivalent forms of fuzzy logic systems NM and IMTL", "venue": "Fuzzy Sets and Systems", "year": 2003, "id": "d853b3de-ed34-47e6-b79e-3e986b5482f8"}
{"abstract": "Mobile agents show promise as a new distributed programming paradigm in which locality plays a central role\u2014programs that are able to move closer to their data can overcome limitations of connectivity, latency or bandwidth. Mobility also enables distributed systems to evolve; for instance, the deployment of a new service over a network can be programmed as part of the service itself. Of course, moving programs introduces new challenges. One of these is related to program structure: How much of a computation should be moved? Where are the boundaries between mobile and immobile entities drawn? A second challenge is to provide security guarantees: How can the actions of mobile agent be controlled? And what kinds of security properties can we realistically expect to enforce? We answer these questions within the framework of the JavaSeal mobile agent system kernel. JavaSeal provides several abstractions for constructing agent systems in Java. Our basic building block is the seal which is a nested encapsulated computation fragment with sharply delineated boundaries. Strands are sequential threads of computation bound to a seal. Capsules transfer passive seals and objects over communication channels; Traffic over channels is regulated by portals. We argue that these abstractions are sufficient to program secure mobile agent systems. An electronic commerce application built over our kernel is used as a demonstrator.", "authors": ["Ciar\u00e1n Bryce", "Jan Vitek"], "n_citation": 52, "references": ["02cd77ef-1cbd-4f5c-93cf-1285bade333c", "0840666a-3d83-495f-bd0b-3bd2ca498a75", "0bd76c78-eb33-4b30-ae81-931c5b6ea796", "179434e5-9d43-42d1-998b-9efd62e718c7", "2e20e9ca-eeb2-4617-be53-f7510c2a0f77", "2eac91a5-a624-4e2d-85ed-82f5bcefb8b8", "3df02e7b-67df-4f8e-9031-5cf7d7f54a69", "43196235-dd57-466a-846a-68b383622e5b", "5206874c-79d4-4562-9c08-632a861f2eb6", "5268dd27-cea9-4f6e-8d1b-24bff534d700", "6598ec8c-3c4a-41b7-9dea-a92bb5cf9c9e", "77dfbd8b-46b6-468e-9e76-96d5c5c68be0", "7aa26b9a-131a-43a8-b0ca-16a744a951ee", "936951f9-b247-4fae-940c-0a40830dd4fd", "94fbc0ff-4485-4899-a1ea-e317bbdc07e3", "9866e6c4-9757-421d-8cf4-3bf03d3899cf", "9dd43ce4-4187-475c-b9d9-da171d2b98b9", "a556fb4a-058a-4074-a8c8-a55d19d46203", "a62492f1-22aa-488b-ae60-c446ea66d574", "a850da0e-b279-47ed-8248-a493ff9a5c1d", "a87ba873-8b3b-430f-8c6a-2d509006dd16", "b377453a-8422-495a-848d-ea180b93c6b2", "b3c18cc2-96d1-45a8-95c1-b50b0eb78980", "b62a2f03-8c81-42a8-92e6-79a6994780d3", "b6d7b91d-4be0-43a1-8d34-55ef817607cd", "b75c31b4-53d4-4f73-a4ea-734e7ee023e3", "c4397a1e-67a7-4e57-b486-aa5db444ccd2", "c8fb41aa-d974-4e42-bbfa-65e429dfdc33", "d0b15cdd-9842-4716-b267-5834aaa5d722", "d17bfb6c-db5f-4b4f-905d-da9a7bb96aca", "e883ae1e-0c54-4fcb-9c38-4165bb0fcc7a", "e8d42c24-fa43-4482-a10e-ee9069c04845", "ec904f67-c883-4f11-a0a8-881354b4b3d7", "fe9d2177-5770-40ec-acd2-2fc1ce394947", "ff4862a5-d73a-423c-9699-6dfbd13491c4"], "title": "The JavaSeal Mobile Agent Kernel", "venue": "Autonomous Agents and Multi-Agent Systems", "year": 2001, "id": "64963f03-cb83-4258-a8e9-1ec4cc554694"}
{"abstract": "Abstract   The ISO standard for the Standard Generalized Markup Language (SGML) provides a syntactic meta-language for the definition of textual markup systems. In the standard, the right-hand sides of productions are based on regular expressions, although only regular expressions that denote words unambiguously, in the sense of the ISO standard, are allowed. In general, a word that is denoted by a regular expression is witnessed by a sequence of occurrences of symbols in the regular expression that match the word. In an unambiguous regular expression as defined by Book et al. (1971, IEEE Trans. Comput.  C-20 (2), 149\u2013153), each word has at most one witness. But the SGML standard also requires that a witness be computed incrementally from the word with a one-symbol lookahead; we call such regular expressions 1- unambiguous . A regular language is a 1- unambiguous language if it is denoted by some 1-unambiguous regular expression. We give a Kleene theorem for 1-unambiguous languages and characterize 1-unambiguous regular languages in terms of structural properties of the minimal deterministic automata that recognize them. As a result we are able to prove the decidability of whether a given regular expression denotes a 1-unambiguous language; if it does, then we can construct an equivalent 1-unambiguous regular expression in worst-case optimal time.", "authors": ["Anne Br\u00fcggemann-Klein", "Derick Wood"], "n_citation": 193, "references": ["1c33e680-5e19-4056-a735-16fb8383b5bf", "29ea3c4e-a8e5-4439-8eba-ec2248c370de", "3ebb73d1-a0a8-42a1-a389-5e58d49f40ac", "70e19a57-78b6-4c5e-bce8-d1ceb1244bdf", "7f1f9851-635c-4497-98eb-dfaad96b63a2", "8cedce27-0d0c-470b-9b25-00c678b27d9e", "cb083b29-7db2-4c9c-8a25-a68ac524377e", "cc09df23-31da-40fb-8aa3-e67b9d7fc7a2", "efe24564-a47d-4d2d-8050-7745ad1c3ea3", "f6ebba67-a362-44a2-ba0e-7513bf55d243", "fab7c251-cc94-492a-b1ad-92b63579688f"], "title": "One-unambiguous regular languages", "venue": "Information & Computation", "year": 1998, "id": "b6dbcbb1-60f1-426a-9a38-2ecb44b37f1d"}
{"abstract": "We present a new method for determining the pose of a human head from its 2D image. It does not use any artificial markers put on a face. The basic idea is to use a generic model of a human head, which accounts for variation in shape and facial expression. Particularly, a set of 3D curves are used to model the contours of eyes, lips and eyebrows. A technique called iterative closest curve matching (ICC) is proposed, which aims at recovering the pose by iteratively minimizing the distances between the projected model curves and their closest image curves. Because curves contain richer information (such as curvature and length) than points, ICC is both more robust and more efficient than the well-known iterative closest point matching techniques (ICP). Furthermore, the image can be taken by a camera with unknown internal parameters, which can be recovered by our technique thanks to the 3D model. Preliminary experiments show that the proposed technique is promising and that an accurate pose estimate can be obtained from just one image with a generic head model.", "authors": ["Ikuko Shimizu", "Zhengyou Zhang", "Shigeru Akamatsu", "Koichiro Deguchi"], "n_citation": 52, "references": ["4b222616-1498-4af3-98d5-695f25e8d513", "5dcd5949-faa9-4af3-8c6f-b285dd3b6566", "700061b6-54a5-4f50-a1ef-1d8de3015c43", "a7a01782-8e14-4dd6-9336-60718abbfc0b", "b72ef385-f390-497c-812d-85d77963045c", "b962c49e-2d68-448b-9317-c0e860d1f7c7", "c97a48bf-396c-4c73-af34-feab9f4039d5", "cd90e104-f991-4cce-92d8-70c719e84ebe"], "title": "Head pose determination from one image using a generic model", "venue": "ieee international conference on automatic face and gesture recognition", "year": 1998, "id": "eede97e6-1365-4fe4-91fe-8a1fa9608eca"}
{"abstract": "Automatic dialogue systems used, for instance, in call centers, should be able to determine in a critical phase of the dialogue-indicated by the customers vocal expression of anger/irritation-when it is better to pass over to a human operator. At a first glance, this does not seem to be a complicated task: It is reported in the literature that emotions can be told apart quite reliably on the basis of prosodic features. However, these results are achieved most of the time in a laboratory setting, with experienced speakers (actors), and with elicited, controlled speech. We compare classification results obtained with the same feature set for elicited speech and for a Wizard-of-Oz scenario, where users believe that they are really communicating with an automatic dialogue system. It turns out that the closer we get to a realistic scenario, the less reliable is prosody as an indicator of the speakers' emotional state. As a consequence, we propose to change the target such that we cease looking for traces of particular emotions in the users' speech, but instead look for indicators of TROUBLE IN COMMUNICATION. For this reason, we propose the module Monitoring of User State [especially of] Emotion (MOUSE) in which a prosodic classifier is combined with other knowledge sources, such as conversationally peculiar linguistic behavior, for example, the use of repetitions. For this module, preliminary experimental results are reported showing a more adequate modelling of TROUBLE IN COMMUNICATION.", "authors": ["Anton Batliner", "Kerstin Fischer", "Richard Huber", "J\u00f6rg Spilker", "Elmar N\u00f6th"], "n_citation": 338, "references": ["1965efb1-86d8-417d-aac2-ac6129bb5f02", "1b60a0a6-2a94-4b3b-ad4f-a7d0cccb0935", "5dc4f436-1d49-48f4-8abc-23dc2e45c5e7", "65e86989-133b-48c0-b3b4-aaf7c26fc0fe", "7ade5141-b0aa-4e60-8640-c31d19f1ee9c", "8936051b-0834-4282-9c28-83001a367674", "a16588b8-c8ed-48c0-b769-ee2d6dd83b07", "a5c8b23e-fa6f-4400-a669-ce321f36f2e0", "ba22b930-51ac-4011-86cd-2d88c369a148", "df9f0905-7f65-4455-86c0-3a9a31bb5d65", "f105e516-20b9-4bbb-97db-68ed4b396d31"], "title": "How to find trouble in communication", "venue": "Speech Communication", "year": 2003, "id": "61b166bc-9e4b-4796-9c51-1877bdb3c2ba"}
{"abstract": "The Sdv Research Platform (Sdvrp) is a new academic release of Static Driver Verifier (Sdv) and the Slam software model checker that contains: (1) a parameterized version of Sdv that allows one to write custom API rules for APIs independent of device drivers; (2) thousands of Boolean programs generated by Sdv in the course of verifying Windows device drivers, including the functional and performance results (of the Bebop model checker) and test scripts to allow comparison against other Boolean program model checkers; (3) a new version of the Slam analysis engine, called Slam2, that is much more robust and performant.", "authors": ["Thomas Ball", "Ella Bounimova", "Vladimir Levin", "R. Kumar", "Jakob Lichtenberg"], "n_citation": 24, "references": ["0278bce3-e509-4ae6-b130-87a283a4b819", "28248831-d840-4a54-9fab-fe549977fe00", "6e08b0da-944e-41ef-b5a7-a8dccba7c58e", "76d4cc9f-d3ad-43dd-a05c-f05eff3d1b18", "9849d9c4-a97f-452f-882c-42a8c6cab0b5"], "title": "The static driver verifier research platform", "venue": "computer aided verification", "year": 2010, "id": "17771b0e-84ce-48cb-9952-ce39a61f7de0"}
{"abstract": "A goal in cloud computing is to allocate (and thus pay for) only those cloud resources that are truly needed. To date, cloud practitioners have pursued schedule-based (e.g., time-of-day) and rule-based mechanisms to attempt to automate this matching between computing requirements and computing resources. However, most of these \"auto-scaling\" mechanisms only support simple resource utilization indicators and do not specifically consider both user performance requirements and budget concerns. In this paper, we present an approach whereby the basic computing elements are virtual machines (VMs) of various sizes/costs, jobs are specified as workflows, users specify performance requirements by assigning (soft) deadlines to jobs, and the goal is to ensure all jobs are finished within their deadlines at minimum financial cost. We accomplish our goal by dynamically allocating/deallocating VMs and scheduling tasks on the most cost-efficient instances. We evaluate our approach in four representative cloud workload patterns and show cost savings from 9.8% to 40.4% compared to other approaches.", "authors": ["Ming Mao", "Marty Humphrey"], "n_citation": 375, "references": ["020918b3-f5dc-4cf9-841d-0364fc2d3534", "09b234e9-fa30-4ae5-af4d-585dfece4e47", "0ac21966-ba17-4df5-8806-1d6e5a9d7743", "117d7c05-35c9-4745-bd6c-c745c35ec7eb", "15778a8c-2361-49fa-b073-c5aae4516d99", "15c42461-71da-4e24-909d-87b6f3d7c9f4", "19296370-ad2d-4df5-8d3a-4e977cf7cd59", "280c8c41-c544-449c-9373-950e790fd52e", "2e8ccebb-931c-439f-acea-17362da9b8e4", "3cad0f8f-b3dd-4f7d-9ca5-22849a61cda2", "454f02e2-d285-4063-ad5d-88fdcdc3abf9", "56eb93ed-44c1-48d1-9e87-84737d3ebddf", "691ee99d-6bea-4544-b708-bb3fe6f2067c", "739f6084-0fc6-418c-bfc5-ed7c7416cf87", "76bbc144-3a33-4589-a7bb-53714f60378a", "8a1913c1-ed4c-431e-afe6-7319abef4376", "af1d95e7-3e21-4945-b809-1f74835c2958", "b0926839-0938-4ae1-83fe-0aa6b2bf365f", "b25773c3-7488-4bd1-ada6-fcb0f7303c09", "bc2cbff0-ba2b-40e7-bcb4-38fafbbed8ea", "c72494c9-50b8-466b-8190-32ffb6be348f", "c957d0b1-4649-4ee8-ab41-e55727972151", "c9db4760-1b18-4fef-8fd3-9991879ea0e0", "e0fe76c0-ebb3-4922-8a02-b0886bf989ed", "e3432705-4df5-4fe2-92e4-4630926c2a96", "e556d501-f8b0-4499-865a-cc900e7390f8"], "title": "Auto-scaling to minimize cost and meet application deadlines in cloud workflows", "venue": "ieee international conference on high performance computing data and analytics", "year": 2011, "id": "c1c91baf-9f3b-4ccc-b9c6-75702e437223"}
{"abstract": "This paper introduces to the finite-state calculus a family of directed replace operators. In contrast to the simple replace expression, UPPER \u2190 LOWER, defined in Karttunen (1995), the new directed version, UPPER @\u2190 LOWER, yields an unambiguous transducer if the lower language consists of a single string. It transduces the input string from left to right, making only the longest possible replacement at each point.A new type of replacement expression, UPPER @\u2190 PREFIX ... SUFFIX, yields a transducer that inserts text around strings that are instances of UPPER. The symbol ... denotes the matching part of the input which itself remains unchanged. PREFIX and SUFFIX are regular expressions describing the insertions.Expressions of the type UPPER @\u2190 PREFIX ... SUFFIX may be used to compose a deterministic parser for a \"local grammar\" in the sense of Gross (1989). Other useful applications of directed replacement include tokenization and filtering of text streams.", "authors": ["Lauri Karttunen"], "n_citation": 87, "references": ["0af5a383-a5b1-4fce-96b1-ae14468441c8", "332084ee-29ab-411e-9d8b-0dc9e977c5a9", "4258fc2b-f252-431b-8ac2-e223ebc99a8e", "4c2d5f31-06c7-4d9e-85fa-f2cd5a6ae14f", "5588e3a3-4aa6-431f-b13f-8f7b5b6a0e45", "68688894-30c1-458c-8fe8-9d1192607fe2", "9ecd8750-5a92-4eba-b5e1-cf37641da0f7", "ee43f26f-d6cb-4522-a55f-126a188708bd", "faae4a02-9154-4a5b-b5d9-a544326b92bd"], "title": "Directed Replacement", "venue": "meeting of the association for computational linguistics", "year": 1996, "id": "ce3e5dba-3f08-4183-accb-480cdbd17756"}
{"abstract": "Despite preceding related publications, works dealing with the resolution of software engineering problems by search techniques has especially risen since 2001. By its first decade, the Search Based Software Engineering (SBSE) approach has been successfully employed in several software engineering contexts, using various optimization techniques. Aside the relevance of such applications, knowledge regarding the publication patterns on the field plays an important role to its understanding and identity. Such information may also shed light into SBSE trends and future. This paper presents the first bibliometric analysis to SBSE publications. The study covered 740 publications of the SBSE community from 2001 through 2010. The performed bibliometric analysis concerned mainly in four categories: Publication, Sources, Authorship, and Collaboration. Additionally, estimates for the next years of several publication metrics are given. The study also analyzed the applicability of bibliometric laws in SBSE, such as Bradfords and Lotka.", "authors": ["Fabricio Gomes de Freitas", "Jerffeson Teixeira de Souza"], "n_citation": 50, "references": ["24662ae5-792d-467b-a7ff-500f40e486fd", "2b043649-06b7-4479-abd5-a7d10435472a", "2b82dcc0-2982-424b-9824-0f6a769f0065", "4056eb66-b7f6-49c0-b945-3a8ad61f300e", "4cd2d294-fb69-421e-900f-7d13a15b714f", "53577a95-d855-41b3-9ac2-6287b4f0262b", "5e067cd9-7028-45e8-8e5c-3d21cb29cb45", "6e83a740-817b-4627-b54a-3e81c6386aec", "7f4a790a-a76a-4a4b-9195-65d2dfd05f70", "854e0980-b768-4017-bb93-fce21ce4cfe6", "972042aa-6b41-4667-9dbf-9227620948ec", "a8b24485-451e-44a3-9d66-c2f79f1d4193", "b5d953ff-caf9-4766-87b0-933707726dd9", "c6174c0a-9adb-4853-bb01-b108fc43c9a7", "c7b3516b-8144-4976-8b21-fe34afeed42d", "e631fc24-d799-4379-8da8-25a2f5dd684f", "e6e7be15-ec67-4845-890d-63e6a15ad0a4", "f9c9c246-31c6-43a1-a48f-20d82bb2634c"], "title": "Ten years of search based software engineering: a bibliometric analysis", "venue": "symposium on search based software engineering", "year": 2011, "id": "e749644a-ac57-4d07-99e0-6735a7991252"}
{"abstract": "The transformation of large, off-the-shelf Java applications to support complex new functionality essentially requires generation of an entirely new application that retains the execution semantics of the original. We describe such a whole-program modification in the context of RuggedJ, a dynamic transparent Java distribution system. We discuss the proxy-based object model that allows remote Java objects to be referenced in the same way as those residing on the current virtual machine, the optimizations that allow us to bypass proxies in the case of purely local or remote object, and the mechanisms needed to guarantee that static data remain unique in a distributed system. We then detail some of the more interesting features involved when implementing this object model in rewritten bytecode, including transformations required within method bodies and coordination between bytecode and the run-time system that distributes an application across the network.", "authors": ["Phil McGachey", "Antony L. Hosking", "J. Eliot B. Moss"], "n_citation": 50, "references": ["1b496b2e-55f9-4c6e-bfc4-363b17aea80f", "3e948b31-d8e6-494d-aa0e-9b21b12cb575", "422ff465-83a5-4c12-b72d-d508f57c51d0", "7cc94bd9-f7bf-464e-93aa-8df102b63634", "8fc5be04-7776-4a6a-81d4-9a9ce0e1e8d6", "93e0cf75-f97e-45f6-96b1-28f648460ca0", "9dcec517-2ba5-4a35-a527-fe52b9298715", "bbbdcca6-61b0-41bf-bd5a-24e3a33690ad", "cb6d0d02-942b-4119-a0c4-a2a7e0e27630", "d1173c24-2942-42c0-97c8-96b0a1bcedb6", "d7a0e8a5-b2f9-4105-b5a8-da00f488f315"], "title": "Pervasive Load-Time Transformation for Transparently Distributed Java", "venue": "Electronic Notes in Theoretical Computer Science", "year": 2009, "id": "e3bededa-1c77-4b9c-b58f-14cb1fe88217"}
{"authors": ["J\u00fcrgen Menden", "Georg Stellner"], "n_citation": 50, "references": ["021ae941-78c4-4004-bc8c-01ebf484049e", "22487eb6-a70b-4262-8539-9a637d978616", "765a5f62-24d9-4ae0-a6d9-79c143d6d5eb", "77d2ea65-9174-464d-a871-60b33377035c", "7b6b22a3-1a7a-49dc-943f-533ab347ac4c", "83f5624b-031a-4104-8e39-26e5b214cc02", "8d9b552a-b047-4f2d-8ca8-4307cebe389d", "9553fde5-7523-4944-abb2-ce12a6d02afc", "c568d647-969b-4c02-b0b5-3e1b25499a8b", "da7d4b59-210a-4bb3-b9b4-a41bd045f150", "fcc366e1-ddca-43df-ae8e-0b068926dc2f", "fd2c1d27-30e7-4004-a891-81062e14089f"], "title": "Proving Properties of PVM Applications - A Case Study with CoCheck", "venue": "", "year": 1996, "id": "e77770eb-4963-4bd0-ad2c-454b8aa00821"}
{"abstract": "Software reliability and error handling are concepts that any programmer knows and deals with on a daily basis. Even so, studies suggest that the current approach to exception handling raises fundamental incompatibilities with object-oriented concepts, being a major cause for the lack of quality on error handling code. In this paper, we propose an exception handling model that makes the runtime environment responsible for automatically dealing with abnormal situations. The platform provides a number of benign recovery actions that are able to deal automatically with most common exception types. Whenever an exception is raised, and a benign recovery method can be found, code is re-executed from a clean transactional state. In this approach try blocks not only represent a nesting level where a fault can occur but also a block that can be re-executed transactionally as a clean slate. For validating the approach two case studies were performed. One involved providing automatic exception handling for Glassfish's Java Messaging System implementation and the other for the Hipergate CRM application. Both showed that increased robustness is possible while freeing the programmer from manually writing extensive error-handling code.", "authors": ["Bruno Cabral", "Paulo Marques"], "n_citation": 24, "references": ["0326e00a-9499-4d42-8feb-66be5f139ea6", "0399968c-12e3-4548-b07c-0b9eba53c985", "071b05d5-e139-404b-aa98-5c682526cfb9", "08de31d5-74cd-4196-b2e4-3a089ed2968a", "122b7592-cd35-4299-840a-da69ab15d565", "12b81c42-879a-428a-bb69-aef58524dfd8", "1300a62a-a336-4466-8f69-d21c9ee10f84", "14866b14-9a5a-414e-8113-a0d0fd092fb0", "17cad5cf-eeef-440f-8e49-9a202747fe7f", "182cd2f4-253a-45ed-b4b9-e7f2affbb70d", "1989b23c-3190-460f-92b6-6982c861a346", "1c02701a-a6b8-4de8-9dc4-e231c608e70a", "258948ff-cbfd-4704-a2f9-3adb293494a0", "26f7125f-caab-4729-a1ee-27db0ea17e19", "27ebbd21-68be-43a9-8d3a-e27b25da9b6e", "2a0380d0-5659-4dfd-8ea9-fcfdecc7de53", "2cf9ab57-251a-4737-a4b0-5ecd2979a895", "2ec1c324-a431-45f3-a3ef-947f55b44e6e", "3340c31e-266b-4780-945d-5468bf5d9543", "339e1da8-4dbe-48d1-bbcd-17b26c383b0a", "3648c33e-28a6-45ca-b755-4f21cf5ab939", "37b80aef-fa63-4f46-a82f-e0c2899a89d3", "3db5726d-d633-4a39-a53a-c68ee033bae9", "3fff331e-2ec4-49b5-922d-6e33c9bd3b08", "43047bed-6608-4811-b391-f80995a0c7ca", "4484f54d-ea17-47ae-823c-31f2fd735da8", "47d0e8d9-79e9-4584-bffb-35937bcd29d3", "48078471-5597-465b-b15b-100472326027", "50c2b39b-21c3-41ba-9894-c8d952291868", "5903dbda-c749-41fd-90b6-03d59fada05a", "59705501-0cbe-46af-b65f-e05e55ad0934", "5a729f4f-7f52-496f-bb29-2644be2e96b4", "6870fa31-f0c1-453e-99ea-98101f2f23cd", "690e99b1-52db-44cd-b6ce-38008d4dc761", "76a5ba90-d174-459f-b373-3a493b57218c", "7d858c10-2f60-4a71-b51c-be58827083d8", "89d8394e-e94c-41e7-8745-74a961f49374", "8b25659c-2447-4cc8-af3c-736f6bb7ba7f", "8bd4161d-4ac7-42a9-abe5-f0bb38719581", "91b77ae6-7e38-4da8-ad9b-6d7a0e4537d6", "92ef257c-ce16-4121-8348-335036a45952", "93e0cf75-f97e-45f6-96b1-28f648460ca0", "94400faa-d60f-442c-8bbe-11cb44d8c55b", "9aa677ee-4e3c-4d8f-8f28-97b58d0c549c", "9d0b5a9b-6854-48b1-aa7b-1909dd981629", "9d8031b0-ffe3-4761-a9f3-a8ca3d6b4e2a", "9e2e64b3-69ff-4500-a343-b1dd66aef7d4", "9eb6d806-630a-43d4-b35a-5dbae451b4a1", "a361da76-4e62-47a6-9ad7-7b5b20f1e9d9", "a4896655-d74e-4be3-a45c-c04178ccb172", "b4b62316-e30f-482a-abc0-d1a6eaa250cd", "b6dba649-3614-4073-8ca4-0f84b73ca1bf", "bc3a0f8d-e09b-4214-a24b-f7fe8ecad8c9", "c168594c-6256-4e81-927c-c2ee48c93715", "c9daf25c-1900-4b85-be48-b81755c6486f", "cacf17ba-3601-4db2-baf6-1aac1ea14b46", "cc7e13d8-953b-4e94-8c41-5bf397aab61c", "ce021460-e274-410e-b525-2947d470812a", "d09f7451-5342-4b5a-aac6-01c4449ed097", "e176f645-79c2-4346-8964-828eb5a4017c", "e2285510-fd4d-4b40-89ca-627a9ce7b76c", "eddb5444-7214-4283-be37-98d0b53785e3", "efa1c9d5-e6e0-4e20-b971-e62ec1e6776c", "f08a1ef2-a6ca-4057-bd31-a71b10e6630b", "f23003f8-31ac-48fa-bd75-71aaa801767e", "f380833e-d323-460c-9f7b-cea34c70748d", "f9a69bbd-5d5a-4efd-b658-24c0789a9cf6"], "title": "A transactional model for automatic exception handling", "venue": "Computer Languages, Systems & Structures", "year": 2011, "id": "031449a8-25af-4b44-9eab-9cef191555c6"}
{"abstract": "A phishing attack exploits both the enormous scale of the web and the fact that users are often enormously confused about what they can trust. Scale allows the phisher to get many responses to his attack, even though the probability of any given user responding is low (it costs the phisher no more to send a million emails than to send one). The enormous confusion about trust allows the phisher make a copy of a bank web-site look as trustworthy to the victim as the original. Previous approaches to this problem have tried to solve the problem by preventing useful information leaking to the phisher; for example by alerting the user to suspicious or low reputation sites. Generally this is done at the client (typically in a browser plugin or add-on).#R##N##R##N#We propose a scheme that in several respects is a radical departure from previous approaches. First, we make no attempt to prevent information leakage. Rather, we try to detect and then rescue users from the consequences of bad trust decisions. Second, we harness scale against the attacker instead of trying to solve the problem at each client. Thus our scheme increases in efficacy with the scale of deployment: it offers very little protection if a small fraction of users participate, but makes phishing almost impossible as the deployment increases. Finally, we make clear that small trials of our system would prove little. The scale requirements of Password Rescue make it suitable for large deployment or not at all. HotSec seems like the best forum for such ideas.", "authors": ["Dinei A. F. Flor\u00eancio", "Cormac Herley"], "n_citation": 44, "references": ["7931f530-7f0c-454d-a30b-5f3fcd870c7e", "93174b24-8b12-4ef5-94fa-b9a8e35087eb", "955557ca-e966-4078-a1ad-88139f6cd7dd", "fdf8208f-a593-4764-a9c0-ae0f31526c7d"], "title": "Password rescue: a new approach to phishing prevention", "venue": "", "year": 2006, "id": "33b087a3-f386-4ca2-949b-b5d31ed8a811"}
{"abstract": "A direct combinatorial argument is given to bound the convergence rate of Markov chains in terms of their conductance (these are statements of the nature 'random walks on expanders converge fast'). In addition to showing that the linear algebra in previous arguments for such results on time-reversible Markov chains was unnecessary, the direct analysis applies to general irreversible Markov chains. >", "authors": ["Milena Mihail"], "n_citation": 214, "references": ["89564659-6116-4e34-9d2d-ca7c104c58d0"], "title": "Conductance and convergence of Markov chains-a combinatorial treatment of expanders", "venue": "foundations of computer science", "year": 1989, "id": "96e5f883-4912-4128-9075-d78d047ec9b8"}
{"abstract": "Recent theories of agency (sees to it that) of Nuel Belnap and Michael Perloff are examined, particularly in the context of an early proposal of the author.", "authors": ["Brian F. Chellas"], "n_citation": 107, "references": [], "title": "Time and modality in the logic of agency", "venue": "Studia Logica", "year": 1992, "id": "8bb87335-92e3-43a5-af39-70434e2a3dd5"}
{"abstract": "Anecdotal evidence from several sources, primarily in industry, indicates that two programmers working collaboratively on the same design, algorithm, code, or test perform substantially better than the two would working alone. In this technique, often called \"pair programming\" or \"collaborative programming\", one person is the \"driver\" and has control of the pencil/mouse/keyboard and is writing the design or code. The other person continuously and actively observes the work of the driver-watching for defects, thinking of alternatives, looking up resources, and considering strategic implications of the work at hand. A course in Web programming was taught at the University of Utah in Summer Semester 1999. In this course, the students worked in pairs, continuously collaborating on all programming assignments. Using the technique, the students applied a positive form of \"pair-pressure\" on each other, which proved beneficial to the quality of their work products. The students also benefited from \"pair-learning\", which allowed them to learn new languages faster and better than they had experienced with solitary learning. \"Pair-learning\" also reduced the workload of the teaching because the students no longer relied primarily on them for technical support and advise.", "authors": ["Laurie Williams", "Robert R. Kessler"], "n_citation": 137, "references": ["54d1c433-8229-4d9f-ad99-89b4ce3000fd", "a65c12e6-e0a8-428f-8d15-e694f5afd37d", "c6045537-5b41-4de6-8ae4-6754bf8f92af"], "title": "The effects of \"pair-pressure\" and \"pair-learning\" on software engineering education", "venue": "", "year": 2000, "id": "e57a0817-6539-4aa6-98cd-0bd0b98df765"}
{"abstract": "To perform service composition, mismatches are challenging obstacles due to the decentralization and independent development of services. Mediation, as a promising solution, attracts most attentions. And pattern based mediation proposed a modularly constructive thoughtway: basic mediator patterns were created and sufficient for advanced mediators against all possible mismatches. The pattern structure is illustrated in this paper. And construction rules for each pattern are presented. Executable codes such as BPEL codes can be automatically generated from these rules. As a systematic engineering solution, its feasibility is validated through a case study in the end.", "authors": ["Feng Jiang", "Yushun Fan", "Xun Zhang"], "n_citation": 50, "references": ["0f0996fa-8ca4-4bf1-b7af-8206fdaf09b2", "1735f072-f54a-4cc2-b4ec-bebd4e204e63", "1ec36184-857a-4ac1-ad01-01ff209db531", "2674d03b-2d28-4dd2-acaa-695690592425", "3807875c-9e83-4b28-a225-1b239a57965d", "628aabc8-cd49-49ec-83f0-ceb6743de657", "8f94b3c4-bdd0-40a9-af0a-6081f76ba325", "8fb7152e-946b-474e-b2c0-4fa2301a7fa7", "9001032c-19b6-432e-9a2d-a2e2f25c3c1f", "b25f5ebd-cb42-488d-96fd-33e01f05d92b", "b87ecc8b-bdd0-45d7-9cda-c2ec1ce92cd0", "cec1c96f-74a2-49df-a101-9adc3d455f43", "d796ac7a-1b2a-4525-9240-31edaa4cfba1", "ea89ced8-e205-4c33-9855-6fe150bdc158", "efd2c9ee-acbb-4664-bf12-068277870447", "f5fa30fb-8a91-464e-99a6-1c0c3e5b76a3"], "title": "Rule-Based Automatic Generation of Mediator Patterns for Service Composition Mismatches", "venue": "grid and pervasive computing", "year": 2008, "id": "35797c58-7d88-4fb0-aaa1-f6ff5a3bb255"}
{"abstract": "We introduce the notion of certificate-based encryption. In this model, a certificate - or, more generally, a signature - acts not only as a certificate but also as a decryption key. To decrypt a message, a keyholder needs both its secret key and an up-to-date certificate from its CA (or a signature from an authorizer). Certificate-based encryption combines the best aspects of identity-based encryption (implicit certification) and public key encryption (no escrow). We demonstrate how certificate-based encryption can be used to construct an efficient PKI requiring less infrastructure than previous proposals, including Micali's Novomodo, Naor-Nissim and Aiello-Lodha-Ostrovsky.", "authors": ["Craig Gentry"], "n_citation": 259, "references": ["062d5c6a-6725-4603-b49c-fb92c4bd0f5a", "35ce170e-c80a-4b55-b37d-468146ac2192", "3d933ed4-75b8-4631-a7a6-6eb5043122d8", "666e1ca7-8c79-43b1-8b57-6c5714301481", "7c46f437-772e-47bd-8c0a-8dd14ac08f17", "99a82f5b-aa75-418c-bb46-3774a3e1199f", "b10fd24d-6a42-4821-9517-da6d1e14b17b", "d0c5e67f-06a7-4435-a8c4-664e84b7a1e2", "ed804c0f-dad5-4ce5-9da3-f69da43f137a"], "title": "Certificate-based encryption and the certificate revocation problem", "venue": "theory and application of cryptographic techniques", "year": 2003, "id": "7b8a0060-89c5-4e58-9c97-56cfd32088f0"}
{"abstract": "This paper proposes a novel algorithm for image feature extraction, namely, the two-dimensional locality preserving projections (2DLPP), which directly extracts the proper features from image matrices based on locality preserving criterion. Experimental results on the PolyU palmprint database show the effectiveness of the proposed algorithm.", "authors": ["Dewen Hu", "Guiyu Feng", "Zongtan Zhou"], "n_citation": 87, "references": ["17373dba-934f-4ae0-bb50-8cc00dd7c19f", "3e26cbdc-4a20-438e-aac1-1bcb2205991d", "494b497b-836b-445a-8bcb-095600835d89", "71f18014-a35d-4b1c-a52c-05ea2a5cd8fd", "d258aff3-95e4-4435-8248-a9f90f1806a2"], "title": "Discussion: Comment on: Two-dimensional locality preserving projections (2DLPP) with its application to palmprint recognition", "venue": "Pattern Recognition", "year": 2008, "id": "09958c14-cfe0-438a-89de-c83fb11a3a64"}
{"abstract": "Abstract   Given a graph  G  and a family  H  of hypomatchable subgraphs of  G , we introduce the notion of a  hypomatching  of  G  relative to  H  as a collection of node disjoint edges and subgraphs, where the subgraphs all belong to  H . Examples include matchings ( H  =  O ), fractional matchings ( H  contains all the hypomatchable subgraphs of  G ), and edge-and-triangle packings ( H  is the set of 3-cliques of  G ). We show that many of the classical theorems about maximum cardinality matchings can be extended to hypomatchings which cover the maximum number of nodes in a graph.", "authors": ["G\u00e9rard Cornu\u00e9jols", "David Hartvigsen"], "n_citation": 52, "references": ["457b1a8a-7297-42a1-a716-2188d0dfd7f9", "ab0b9d1e-65e2-4737-8d1a-a376bf157075"], "title": "An extension of matching theory", "venue": "Journal of Combinatorial Theory", "year": 1986, "id": "ed91a481-6aa0-4d2f-9ba0-77b42ed36ce0"}
{"authors": ["James F. Smith", "Robert D. Rhyne"], "n_citation": 11, "title": "A Resource Manager for Distributed Resources: Fuzzy Decision Trees and Genetic Optimization.", "venue": "", "year": 1999, "id": "2dcad845-f55c-419a-8363-2a0e9d7db531"}
{"authors": ["Annelie Heuser", "Michael Zohner"], "n_citation": 11, "title": "Intelligent Machine Homicide - Breaking Cryptographic Devices Using Support Vector Machines.", "venue": "", "year": 2012, "id": "ad94194b-f1a5-46ed-95d7-42f1bc09c10b"}
{"abstract": "A scalable approach to trust negotiation is required in digital library (DL) environments that have large and dynamic user populations. In this paper we introduce Trust-Serv, a model-driven trust negotiation framework for Web services, and show how it can be used to effectively handle trust negotiation in DLs. The framework employs a model for trust negotiation based on state machines, extended with security abstractions. High-level specifications expressed with the state-machine-based model are then translated into formats suitable for automating the trust negotiation process. The proposed framework also supports negotiation policy lifecycle management, an important trait in the dynamic environments that characterize DLs. In particular, we present a set of policy change operations that enable the dynamic evolution of negotiation policies without disrupting ongoing negotiations. The proposed approach has been implemented as a container-centric mechanism that is transparent to the DL and to the developers of DL Web services, simplifying DL development and management as well as enabling scalable deployments.", "authors": ["Halvard Skogsrud", "Boualem Benatallah", "Fabio Casati"], "n_citation": 18, "references": ["02f9e191-0430-4a7c-a8bd-20674738bee3", "0a4221de-0195-4c9f-9ead-1dd975107818", "1c1a6077-6452-4898-add9-3ae3144eec52", "244c546c-bec5-47c2-9ebd-0456b8fa035f", "34c8da5d-9993-4c3c-9915-79b45f192aea", "374b8142-c97b-43d8-afdc-194c2c68c35a", "3ba8cb0c-13b9-473f-b22f-6e7dc7ec2d7e", "3d964a49-45e0-47dd-8b63-d7f39a112c8d", "4d1392ed-345a-4e91-bff2-b9b9876b7d59", "5d11f3e7-7af2-4ee9-ba02-121fe3b4b2b8", "82c52588-d0fb-4d45-8e42-460c4114e1c6", "861e097a-2b02-4e68-966c-5fb4058863f0", "8c09ba42-5c63-4937-9822-848ea8f2e49c", "91bd5bed-21b6-4344-a446-917b483f5827", "923fb0b7-fa34-4ad2-8fd4-e3dac99607e7", "ae1823a4-40e0-4a1f-bb45-019e955ad8b4", "bc796683-8a0c-4a34-888f-cb32d2bc88cd", "bd6de100-9148-4899-ae64-0c61f42ac938", "c57b52c3-8d6b-477e-92b4-3659e14ea546", "c669b6f9-6f52-42ae-a80d-633403b738ba", "cd0e1f40-5d5d-405b-a2c9-41cb52cb555d", "dc8e7396-6c6c-4b42-acbe-c006f740bf3d", "e41b7e75-d2ee-4155-983b-1152a7a3a8c4", "fbf428ef-2fd2-4563-801a-6024bb5ef012"], "title": "A trust negotiation system for digital library Web services", "venue": "International Journal on Digital Libraries", "year": 2004, "id": "b618bf0f-200d-43f2-acd4-7ccb0596695f"}
{"abstract": "Since energy is a valuable resource in Wireless Sensor Networks (WSNs), it is important to continuously monitor the status of this valuable network resource after network deployment. The information about energy status can be used to early notify both sensor nodes and Network Deployers of resource depletion in some parts of the network. It can also be used to perform energy-efficient routing in WSNs. In this paper, we propose a scheme for monitoring residual energy distributions at different parts of the network through a mechanism called Energy Centric scale (ECscale). ECscale is then used to perform optimal as well as approximate Energy-Centric Routing (ECR) in WSNs with the objective of maximizing the network lifetime. The proposed algorithms make use of a fixed virtual wireless backbone that is built on top of the physical topology. Simulation results show that our scheme is scalable and can provide many folds of energy savings when compared to conventional routing schemes.", "authors": ["Jamal N. Al-Karaki", "Ghada A. Al-Mashaqbeh"], "n_citation": 16, "references": ["23dd7fc0-1ebd-43ce-ab3e-43896512c209", "30ac1757-80f7-4b9e-bb10-639a76916d66", "52da1a09-9acd-495d-b885-850b3508f87c", "7b57a3f4-44a2-4fe3-9959-f25255669534", "9a464b30-5030-49d5-a833-fab5eb3a72d4", "c1885030-870c-4fcb-8573-31faa93c7b25", "d3a6b91d-9fad-4438-82e2-ac405428cae2", "f3267c01-b670-4b7a-a3a5-79088c0d90ab"], "title": "Energy-centric routing in wireless sensor networks", "venue": "Microprocessors and Microsystems", "year": 2007, "id": "ada12316-6e33-4a91-b490-68d1ef117cfa"}
{"abstract": "We present a new class of low-bandwidth denial of service attacks that exploit algorithmic deficiencies in many common applications' data structures. Frequently used data structures have \"average-case\" expected running time that's far more efficient than the worst case. For example, both binary trees and hash tables can degenerate to linked lists with carefully chosen input. We show how an attacker can effectively compute such input, and we demonstrate attacks against the hash table implementations in two versions of Perl, the Squid web proxy, and the Bro intrusion detection system. Using bandwidth less than a typical dialup modem, we can bring a dedicated Bro server to its knees; after six minutes of carefully chosen packets, our Bro server was dropping as much as 71% of its traffic and consuming all of its CPU. We show how modern universal hashing techniques can yield performance comparable to commonplace hash functions while being provably secure against these attacks.", "authors": ["Scott A. Crosby", "Dan S. Wallach"], "n_citation": 341, "references": ["0e330fe2-8720-4b8d-9128-92c28d3eaea7", "5daf6f84-0d4a-445a-b173-8d2a55a98438", "70a4fa95-e960-4c72-8db0-557d7defa300", "73062e15-33c4-4258-8815-47a35c352994", "8ed0c977-c4e4-4183-8ec3-b2fc7bea41cf", "a59be9de-2672-4f92-8ff6-636b3afbce68", "abf003a2-6485-41f0-a111-88b80412d539", "c3f655c3-2163-4b08-9243-96a0baaf5720", "ea1c24ee-716a-47b5-bf9b-76fcbca6ea16", "eef82e0a-f422-4921-a712-082ab5e23c51", "f1059e66-3d21-4fdf-8783-dbb719236d9f"], "title": "Denial of service via algorithmic complexity attacks", "venue": "usenix security symposium", "year": 2003, "id": "a5d10b53-84d3-4a02-9ced-13d6d239e729"}
{"abstract": "This paper aims to provide the reader with a review of the main technologies explored in the literature to solve the indoor localization issue. Furthermore, some systems that use these enabling technologies in real-world scenarios are presented and discussed. This could deliver a better understanding of the state-of-the-art and motivate new research efforts in this promising field. Finally, focusing on one of the major challenges in the indoor localization field, i.e., the indoor animal tracking, existing indoor tracking systems have been reviewed and compared by analyzing advantages and drawbacks.", "authors": ["Luca Mainetti", "Luigi Patrono", "Ilaria Sergi"], "n_citation": 64, "references": ["0596fca0-b2f2-4232-bff1-8699230e19cf", "09b15f07-7672-47fb-88a5-5cad3dcaf475", "0cdc4df5-78e2-4461-83a2-e1fbf7427b9a", "1204ba55-e61e-40e5-82c0-76c897da1c5d", "22b3af8b-814c-4957-8d3b-6413884de12d", "304cf765-8dad-4ece-9b44-1c7d04e736c2", "307a241c-33ad-4413-a510-c33f3e7bd69c", "342aabc6-b3ea-4a2c-a039-a2ec0055b588", "358c90a2-8a7c-4426-b978-cb766763960e", "360bdf99-68db-4982-aa01-6aa93d17c460", "396d4d11-5ef3-4f72-910b-8b4514f4156e", "3acfa153-a4e2-4fb5-a83f-4f3328e05c24", "41f98d83-57f8-4762-9e33-c49a67088b86", "4754c8c9-73cb-4a7e-819a-3fb59580cedb", "52756146-73c7-4e99-99bf-ab1a220dcbbf", "5b2c9d00-2b4c-4714-9d32-66146238d632", "6277eee3-059d-4615-a3a2-011fb15f9895", "69609e75-fe12-4f7a-9f1b-2a71690863ce", "6d02b71a-c789-45c4-b65e-b2fc2ddc9a70", "768cbcbc-f0c0-4a4a-ae3b-b36896a826b2", "768f5dbf-3dbc-471b-9085-bbbc6f930229", "776626ae-e595-48b5-a5db-a07865b09d34", "7f16005c-abec-4195-9197-5d83a7df0eaf", "8432df06-1fce-4537-81d3-c207e4cfc75b", "872fb0bc-d5d6-4fc0-93bd-d7faa590efa1", "92a2b8da-f73a-4528-b056-72247f18c226", "aa7175c1-204f-4ff1-82cb-f15d847c42ed", "b2f92a1c-de40-4fe7-bcfc-08839770834b", "c663f45c-e405-4f6d-a0dd-1749b1f5f334", "cacf5026-64bc-42d7-9bac-cbfe7ac7dde6", "ce13ccae-65e8-4d40-b262-8589e67f1dac", "d130a098-3bfb-4802-9699-62914b67d41c", "d30b47bb-1e27-4504-a5cd-ccf859ead2c7", "f3e684b0-0cf1-4b41-b5be-18a4afcbf068", "feac1967-1a88-4efc-88b8-93b249c1e072", "ff4edc5b-a005-4d74-bbdf-bb6659fc76b8"], "title": "A survey on indoor positioning systems", "venue": "", "year": 2014, "id": "8a297597-b8b7-4259-a4d7-f3a8b27ee0f0"}
{"abstract": "Fundamental logical concepts the propositional calculus proof systems for the propositional calculus the predicate calculus proof systems for the predicate calculus first-order theories modal and temporal logics.", "authors": ["Antony Galton"], "n_citation": 58, "title": "Logic for information technology", "venue": "", "year": 1990, "id": "8073fcbc-97c4-4c42-9698-5d4217b35caa"}
{"abstract": "In this paper, a general class of recurrent neural networks with time-varying delays is studied. Some novel and sufficient conditions are given to guarantee the global exponential stability of the equilibrium point and the existence of periodic solutions for such delayed neural networks. Comparing with some previous literature, in which the time-varying delays were assumed to be differentiable and their derivatives were simultaneously required to be not greater than 1, the restrictions on the time-varying delays are removed. Therefore, our results obtained here improve and extend some previously related results. Finally, two numerical examples are provided to illustrate our theorems.", "authors": ["He Huang", "Daniel W. C. Ho", "Jinde Cao"], "n_citation": 88, "references": ["1d963557-b184-4000-9ba3-6d8b91b54b12", "30317d10-9453-4f05-b16f-db7ff141fdcd", "38d20ba0-db8e-47db-ab6b-f2898683a0a1", "4967e8e2-929a-4bd6-bc8b-c4ea94f30f1f", "54142e16-afb0-4f1a-92fe-3f1050157c16", "69cfdfe5-25cc-43ff-b160-3b0808f30069", "7dc6ac69-4c1d-4cd1-9951-14c74c5e40cb", "bf5205ea-ff18-458b-b0fe-3cd7265584db", "cd6052a9-3bf5-4826-bb66-a8fcdf03924b", "f789780c-d292-4a07-b10a-244b11d71f19"], "title": "Analysis of global exponential stability and periodic solutions of neural networks with time-varying delays", "venue": "Neural Networks", "year": 2005, "id": "b2431411-83c8-4191-b676-d4f11d71c2f2"}
{"abstract": "We propose new hybrid methods for automated segmentation of radiological patient data and the Visible Human data. In this paper, we integrate boundary-based and region-based segmentation methods which amplifies the strength but reduces the weakness of both approaches. The novelty comes from combining a boundary-based method, the deformable model-based segmentation with region-based segmentation methods, the fuzzy connectedness and Voronoi Diagram-based segmentation, to develop hybrid methods that yield high precision, accuracy and efficiency. This work is a part of a NLM funded effort to provide a fully implemented and tested Visible Human Project Segmentation and Registration Toolkit (Insight).", "authors": ["Celina Imielinska", "Dimitris N. Metaxas", "Jayaram K. Udupa", "Yinpeng Jin", "Ting Chen"], "n_citation": 44, "references": ["088d00cf-ed12-4552-8958-8b550401f355", "1c63e1d5-b963-455b-829d-e4f3eb63a36a", "3c2d21e3-faa3-4e79-b7a2-8388e69da4b4", "3f4cc95c-5f47-4031-8671-e23ff4fe2ed2", "510eec1d-f82c-4b19-b116-b8fd4c66531a", "682fd165-b453-4224-a148-0352b91f7845", "6c341eb6-f901-4353-b5ff-8da4ce990d11", "784b6b67-b84b-48d5-942c-fb4960289de0", "802c5b49-ccf8-4c37-a3df-e8a9e12a06cb", "c146fe70-b870-4da0-b3b9-0a39eaaa6a38", "e3aeaf52-fad2-4b78-b0b4-70686978e1b3", "fad46bfb-eda4-467b-ac7b-c6826561e1f7"], "title": "Hybrid Segmentation of Anatomical Data", "venue": "medical image computing and computer-assisted intervention", "year": 2001, "id": "90d2cb7a-d3f1-44da-914c-60efdd894486"}
{"authors": ["Spiros Lalis", "Beverly A. Sanders"], "n_citation": 50, "references": ["49a67b87-0c91-4b32-907f-6fba3d8ddc52", "5f04688c-f150-44d5-9314-333715bbbf0e", "a674e299-14d9-4a24-acde-164579ed98e8", "ba7b5a23-3686-4ac1-b7d1-3e6600057648", "fbcad938-9d40-4bd7-b7c5-2cf040dc0bec"], "title": "Adding Concurrency to the Oberon System", "venue": "", "year": 1994, "id": "7abae1d0-60be-488f-ac2a-6d8d8e773a5f"}
{"abstract": "Based on closed kinematic chains, parallel robots obtain favorable dynamic properties as well as high stiffness. Hence, their application can significantly enlarge the productivity of automated production processes. A control concept for tapping the high potential concerning low cycle times and high path-tracking accuracy is presented. The proposed approach adapts autonomously to changing dynamic parameters as varying payload. The autonomous behavior is achieved by combining an adaptive control approach with an adaptive, time-optimal trajectory planning concept and an online-trajectory adaption mechanism. Extensive experimental results prove the performance of the proposed approach. Note to Practitioners -Many applications in the field of production automation (material handling, assembly, etc.) require high operating speeds and accelerations. During the past years, parallel robots proved to be an efficient and suitable supplement to serial robots. Unfortunately, the promising possibilities of parallel robots often cannot yield profit because their dynamic potential is still not fully exploited. The payload/robot mass ratio of parallel structures is even higher compared to serial robots, where the influence of the payload on the impedance of the robot is negligible. By use of direct drives the influence of a variable payload cannot be ignored. A modified adaptive control concept, which adapts autonomously to changing dynamic parameters-as varying payload due to diversity of assembly processes-guarantees high tracking accuracy and therefore better process quality as well as accurate estimates of changing dynamic parameters and therefore better process quality. In addition the productivity of the process can be enlarged, if the full drive power can be used at each point on the path. Thus, a new adaptive time-optimal trajectory planning algorithm is used to exploit the dynamic potential of the direct drives and consequently to shorten the cycle times. The aim of time-optimal trajectory planning, as it is commonly understood, is the determination of the maximum velocity profile along a given path that complies with all given dynamic and kinematic robot constraints like limited drive forces/torques, limited path and/or drive velocities and limited path jerk. Combining the adaptive control scheme and the adaptive, time-optimal trajectory planning algorithm with an online trajectory adaption mechanism, a control concept is realized, which autonomously adapts to changing dynamic robot behavior. Using this new approach, the advantages of parallel robots-as well as serial robots with direct drives-can better be utilized. This is a necessary prerequisite for a larger extension of PKMs for industrial applications.", "authors": ["Ingo T. Pietsch", "Mathias Krefft", "Oliver Becker", "Carlos Cezar Bier", "J\u00fcrgen Hesselbach"], "n_citation": 53, "references": ["076a598e-e610-44b5-a264-478d9a96a2ed", "1f2626cc-d742-44f1-b0e8-65fad990dd4b", "532b27fb-f9c5-4723-86e7-d27c17753431", "6871674d-db6e-4571-b7ac-3e2952ce63fb", "6c2a95ed-0366-4028-b993-53e7c9215480", "6f47b50b-c366-4c9c-84cc-f9bc5fec53a4", "856b3e79-70b1-4496-b1e9-88dab0bddadd", "a9aca3cf-39df-4f9b-8775-14d79f5b7217", "b96b06cf-5a64-4a05-a852-569fa9a2ddfb", "bda9b95f-ad86-4cfe-a5fc-47a404f18849", "c84f5d5e-b3c4-4fe2-8a72-e52ee61e0d10", "cd239b16-9554-4dab-b19a-8cfc47466136", "e6aafbdc-eeb0-4b7b-a5d5-3653d0d3ac19"], "title": "How to reach the dynamic limits of parallel robots? An autonomous control approach", "venue": "IEEE Transactions on Automation Science and Engineering", "year": 2005, "id": "e4be2a31-62aa-4e34-a570-4bb7986851b6"}
{"authors": ["Nicholas C. Romano", "Jerry Fjermestad"], "n_citation": 190, "references": ["0684630b-dfc0-45b1-a0cd-281310bb160f", "0f1a0f90-ead9-4609-a621-f5380ec95cf7", "134d9866-c63d-4015-bbd1-6382c976976b", "14459d24-9847-42df-ab45-ca29886cc135", "1610f07d-48f6-4527-be62-4e8307b3a5b9", "16a1c769-9150-48ca-b5ac-311a33bd772c", "16fa3919-142f-40f8-9aaa-fbacf48872b1", "18e318d0-caaa-48d4-ac9d-858687c70bf8", "3574464c-8f60-4e44-a5cf-5db92d4ca019", "3703ab6c-d56b-4d69-9ae6-110f88a2453d", "3787310e-ef4a-469f-b018-95d34c24a9c3", "381d50c7-656f-4ec8-85e4-8b90dffbb7d6", "3afd0f1e-ef1b-4e92-bfc7-f93ac8e335b0", "3cc9058d-f153-44c9-97a7-c75bcc621724", "405801cc-7dd8-47e5-bdbf-c722cdf02bfa", "43a5b033-c354-46ba-800b-decf1ed737a3", "4cc2a82d-0ed7-4c48-88ab-ce71f748b5a7", "4d7a4118-fe44-41c6-b111-69ab3982533b", "4f5c8195-9491-48fa-b5fb-7deee880f549", "4f98bb78-3721-4b8b-8048-ff610fa22f31", "50dfc853-2c66-412b-afb3-13446a007aac", "533c108b-ec97-48d0-8a58-6cfe0c1d7493", "584a231e-565e-4594-9bc6-8260a4796d59", "587677c0-8ae8-4edf-979d-229f42ec75e1", "5e11033c-d85d-4455-bf5d-69f64d3efdf4", "5f338f33-a8ab-4af9-8995-ef5ce90eb3a3", "62808594-9e28-4c8c-8eb5-5c0b45b5f73f", "64305aad-2e79-470d-9d59-0dbb722fa3d1", "6f0a7f17-b909-42dc-8140-69fe46f1eed0", "6f23e07c-338a-48fc-89d9-a8ff5af2c9c8", "7df42e91-8a37-4a8d-a50e-d0e71765c3a4", "7effcd14-1b17-4e93-b07b-bed961ac1f68", "959aa57b-bd5e-46ea-a6b5-aad0fc099bda", "9868bb26-c0d0-47eb-ab4c-40cabfc3c1ca", "9a24c7c3-77ea-479a-b9a3-93848a0d3e27", "9b824cbb-a206-4aee-a062-ac2337084e39", "9d912297-e52f-4ab6-add4-633e0f263933", "9e0324ec-48ce-4d2b-8f3b-ec9205d94a4f", "a1fa8a87-dcad-42f5-a765-095967dd932e", "a5ed7a1a-c049-4d3d-97dd-393915b80278", "a61eedea-1cc0-4e57-9fe5-6f6b4e5846f7", "abd00fe7-6375-48bf-a5ed-30f878b25c00", "b16f389f-4d6c-4a52-ba1c-1c86a38a228f", "b97c62a1-8d95-4ada-a438-a1a9b78f7c68", "c11841c9-10e5-448a-94e6-050ac9d78c84", "c276ecc2-8c24-4a7d-b825-918d6b99b0d3", "c517f47d-e19a-4792-b8c6-7c7ae5e589eb", "c8b5d4d7-f4a4-40ea-9355-20f7779bb782", "c97f3a7e-6b29-4b6a-87b5-5f1ba3631c21", "cde0d149-5dec-4283-b181-ac192918eebb", "d06762d9-ea72-41d0-8b1b-30d787d890d1", "d082d1bb-160e-4d26-b12d-86412db6312a", "d0affe26-1b29-4a0a-968a-82ccdcb333b4", "d0e0fdad-04b2-49d2-a4f4-d026e785d597", "d169eecc-adbe-4278-b9e6-106aa543b0f7", "d2012855-7b29-408b-98ee-2f41383feb26", "d6000950-aaae-4c5a-8057-6fe4c147eeb3", "df4bbccc-151a-4e2e-a62a-c25e6db9e6ee", "e0bbe65d-9e70-48ef-a9ff-37bf70eb429a", "e0e5fc51-b78d-462d-810f-591af0b78e98", "e50411ef-4ffd-4253-a8a4-3308ee41612b", "e56598ba-3d5a-4413-ba28-e92afd3a7b49", "ed9d76c0-ea1b-4d8d-a521-06cd725a767a", "f397a784-2d9a-401d-a6ff-f4631ed695aa", "f6f80307-185c-4818-bf6e-46bd9b0427ea"], "title": "Electronic Commerce Customer Relationship Management: A Research Agenda", "venue": "International Journal of Information Technology and Management", "year": 2003, "id": "d7363ce2-91a3-4828-ba02-432f03bd8bae"}
{"abstract": "Understanding sequence data, and the ability to utilize this hidden knowledge, creates a significant impact on many aspects of our society. Examples of sequence data include DNA, protein, customer purchase history, web surfing history, and more. Sequence Data Mining provides balanced coverage of the existing results on sequence data mining, as well as pattern types and associated pattern mining methods. While there are several books on data mining and sequence data analysis, currently there are no books that balance both of these topics. This professional volume fills in the gap, allowing readers to access state-of-the-art results in one place. Sequence Data Mining is designed for professionals working in bioinformatics, genomics, web services, and financial data analysis. This book is also suitable for advanced-level students in computer science and bioengineering. Forward by ProfessorJiawei Han,University of Illinois at Urbana-Champaign.", "authors": ["Guozhu Dong"], "n_citation": 211, "title": "Sequence Data Mining", "venue": "", "year": 2009, "id": "3143d091-d8bc-4a16-956a-7dd84d475dd7"}
{"abstract": "Mori (1970) proposed a hypothetical graph describing a nonlinear relation between a character's degree of human likeness and the emotional response of the human perceiver. However, the index construction of these variables could result in their strong correlation, thus preventing rated characters from being plotted accurately. Phase 1 of this study tested the indices of the Godspeed questionnaire as measures of humanlike characters. The results indicate significant and strong correlations among the relevant indices (Bartneck, Kulic, Croft, & Zoghbi, 2009). Phase 2 of this study developed alternative indices with nonsignificant correlations (p>.05) between the proposed y-axis eeriness and x-axis perceived humanness (r=.02). The new humanness and eeriness indices facilitate plotting relations among rated characters of varying human likeness.", "authors": ["Chin-Chang Ho", "Karl F. MacDorman"], "n_citation": 143, "references": ["02773ffb-e452-448b-8ce5-6bf362f73fbf", "14f6b755-e627-4850-9b43-51b477810b3d", "3b2171ba-494c-40dd-9d83-bfa953a5bf32", "45e75346-62b2-4c61-8647-94eaabb1126f", "5804470d-5e3d-4e61-a49e-7bebb513d0c7", "6a5c0132-8df7-4966-b213-19c253313666", "85deb474-fa2b-498f-ad26-1ddf557eef58", "8c473ba8-bffe-4186-b47a-9fa216aa17be", "92fd3a51-b0fd-4f42-bdff-1a8c3d445d1d", "932a4e1b-32d5-4505-8e2a-ae3e60118862", "d2613c37-aa0b-4e1d-b15e-6838107badb2", "ffcaf602-01e0-427d-a913-794af6891da4"], "title": "Revisiting the uncanny valley theory: Developing and validating an alternative to the Godspeed indices", "venue": "Computers in Human Behavior", "year": 2010, "id": "6b6a2144-8303-4231-9d1d-13d4ba2eba7b"}
{"abstract": "We present PLANet: an active network architecture and implementation. In addition to a standard suite of Internet-like services, PLANet has two key programmability features: (1) all packets contain programs; and (2) router functionality may be extended dynamically. Packet programs are written in our special purpose programming language PLAN, the Packet Language for Active Networks, while dynamic router extensions are written in OCaml, a dialect of ML. Currently, PLANet routers run as byte-code-interpreted Linux user-space applications, and support Ethernet and IP as link layers. PLANet achieves respectable performance on standard networking operations: on 300 MHz Pentium-II's attached to 100 Mbps Ethernet, PLANet can route 48 Mbps and switch over 5000 packets per second. We demonstrate the utility of PLANet's activeness by showing experimentally how it can nontrivially improve application and aggregate network performance in congested conditions.", "authors": ["Michael Hicks", "Jonathan T. Moore", "D.S. Alexander", "Carl A. Gunter", "Scott M. Nettles"], "n_citation": 160, "references": ["10d5afc8-1acb-4f3a-ae47-f32137b09e6d", "179434e5-9d43-42d1-998b-9efd62e718c7", "7172ba56-f3d2-4c77-a734-51ee4a915ae8", "88083036-842b-4045-9404-038481b6debf", "98e953e7-de43-4669-8d19-f294d27861bf", "98f5e5de-e7d2-4d72-b64f-0860f79d0dba", "a91d1321-2b89-4a28-a3dd-19f59538bac4", "c8fb41aa-d974-4e42-bbfa-65e429dfdc33", "c92ab2ef-2d59-4edc-9a41-6ba6fb7c926e"], "title": "PLANet: an active internetwork", "venue": "international conference on computer communications", "year": 1999, "id": "8489a8ac-264c-49cb-b843-994d7e8ed0cc"}
{"abstract": "Abstract   Systems of uniform recurrence equations were proposed by  Karp et al. (1967)  as a means to derive automatically programs for parallel architectures. Since then, extensions of this formalism were used by many authors, in particular, in the fields of systolic array synthesis. The  computability  of a system of recurrence equations is, therefore, of primary importance, and is considered as the first point to be examined when trying to implement an algorithm. This paper investigates the computability of recurrence equations. We first recall the results established by  Karp et al. (1967)  on the computability of systems of uniform recurrence equations, by  Rao (1985)  on regular iterative arrays, and  Joinnault's (1987)  undecidability result on the computability of conditional systems of uniform recurrence equations with nonbounded domain. Then we consider systems of parameterized affine recurrence equations, that is to say, systems of recurrence equations whose domains depend linearly on a size parameter, and establish that the computability of such system is also undecidable.", "authors": ["Yannick Saouter", "Patrice Quinton"], "n_citation": 54, "references": ["4b1f6789-efb1-4695-93e1-b0ef642859f9", "a662a4e7-415e-417e-8a8f-fe085d7e487f", "faf706d9-40d7-48a2-ba4c-8d37bbcd3a2d"], "title": "Computability of recurrence equations", "venue": "Theoretical Computer Science", "year": 1993, "id": "b4f550f8-39d3-4bc1-90aa-d2ec527ebe53"}
{"abstract": "This article shows how CGLF, CGIF, KIF, Formalized-English and Frame-CG can be used in a panorama of knowledge representation cases. It highlights various inadequacies of CGLF and CGIF, advantages provided by high-level expressive notations, and the KIF translations provide a logical interpretation. Knowledge providers may see this document as a guide for knowledge representation. Developers may see it as a list of cases to take into account for their notations and inferences engines.", "authors": ["Philippe Martin"], "n_citation": 61, "references": ["077af785-1969-4e25-a296-ea0b5d600688", "d3190f3b-ea8b-4a44-83f1-d17f7080df4e", "f91d7672-153b-4aca-b9d6-02f2b7177ffa"], "title": "Knowledge representation in CGLF, CGIF, KIF, Frame-CG and formalized-english", "venue": "international conference on conceptual structures", "year": 2002, "id": "1277c195-24c7-4159-ae1c-b34039fb71b3"}
{"abstract": "A comparison is made of the space requirements of pointer and a number of pointer-less implementations of multidimensional quadtree-based file structures. The database is assumed to be static. In order to make the comparison realistic, considerations such as computer byte sizes are taken into account, and fields are constrained to start on bit and byte boundaries where appropriate. In many practical cases, the pointer quadtree requires less space than the pointer-less quadtree. This effect is more pronounced for octrees and data of higher dimension. Empirical data from a cartographic batabase are used to support the analysis.", "authors": ["Hanan Samet", "Robert E. Webber"], "n_citation": 23, "references": ["0ee738c7-9e13-4ef6-b6a0-d496e9c3fd51", "299dbd68-c2de-4be9-b069-9219123ce5ec", "31209076-11f3-4328-8e87-d12a59d62dfa", "36121bc5-3ebc-485a-9890-92df89716d59", "39bde15f-75f7-4b8e-8732-a08be99b5665", "3baf9dae-8781-4b18-b6f1-a62ebbccac9a", "3dc33be3-0fbf-4765-a1cd-67fda306675d", "5384be17-46f4-412b-9c95-834d90d83297", "56a41f3c-7b53-43c4-a7f9-dfdcdb51de7c", "5c35f8cc-235c-43a6-b7dc-bb63b2a1539e", "673085d3-6f42-469b-96e1-c8c05e9cae07", "727b043e-1946-4ef8-95a1-0e2af4a31686", "73c771d8-7836-47f9-b20a-ba257f541903", "84bfb85f-bf92-497d-a552-34fdde6f26a9", "8a5d3fc6-5fc7-42d5-b7ae-0ee888e2bf00", "95f0b594-323f-4dc1-b6a5-00170dc32df4", "a8c76816-3583-47e8-98e1-18db34cb5b67", "a9166903-efe2-4810-a20f-15b84cd742db", "bc6afbe4-4d0a-4373-a2a1-d082515a1409", "c247baf0-3ed9-4599-90d6-bf87088ed3f2", "c3e49e95-9eb0-4c45-8a4e-7fc6c0ac83fe", "c835ce44-b334-450f-9340-af2f31f1550f", "d6ffd0e7-61aa-4dea-9fe0-4345e2382e96", "d91067ab-3fe2-4953-ac92-9ba52b235280", "e97d9c05-854e-4bd6-9301-11affc0d103f", "ef5e7eea-beff-4fc5-8bcf-c359914ef278", "f283c49a-f137-49d1-9516-01d20f2e6d8a", "f7f7cc3e-2458-40fb-940c-47d0b0625de4"], "title": "A comparison of the space requirements of multi-dimensional quadtree-based file structures", "venue": "The Visual Computer", "year": 1989, "id": "d8f62751-e8c1-474c-a1ad-64a95f034389"}
{"abstract": "Despite improvements in network interfaces and software messaging layers, software communication overhead still dominates the hardware routing cost in most systems. In this study, we identify the sources of this overhead by analyzing software costs of typical communication protocols built atop the active messages layer on the CM-5. We show that up to 50\u201370% of the software messaging costs are a direct consequence of the gap between specific network features such as arbitrary delivery order, finite buffering, and limited fault-handling, and the user communication requirements of in-order delivery, end-to-end flow control, and reliable transmission. However, virtually all of these costs can be eliminated if routing networks provide higher-level services such as in-order delivery, end-to-end flow control, and packet-level fault-tolerance. We conclude that significant cost reductions require changing the constraints on messaging layers: we propose designing networks and network interfaces which simplify or replace software for implementing user communication requirements.", "authors": ["Vijay Karamcheti", "Andrew A. Chien"], "n_citation": 120, "references": ["1e51da39-6e06-4c67-bc59-bb8074240d47", "24f49c9f-c1f9-4d3d-b9bb-1873588c944b", "31a8adb7-ac53-45dd-a077-4f7044de491f", "33ce592c-6ff1-46aa-94a1-7618f4c11ae5", "3d9e52bb-b80b-4647-ae2a-69bee3491f23", "5131054c-2a54-4e33-9285-2fd76d4df543", "73739568-56c1-4153-a32c-3961d4edb81f", "7ce14ed8-8158-45c1-86b0-76596643e187", "8c755958-b404-40b0-8a56-83ffb52c1d45", "9b8f4bcb-144e-4d0d-bd85-7fbc546e3200", "a4437695-8351-4d57-9663-560d8f7e3e5d", "c67c9508-e4b3-41ea-9e3c-8b9c0a5bd211"], "title": "Software overhead in messaging layers: where does the time go?", "venue": "architectural support for programming languages and operating systems", "year": 1994, "id": "59e4be91-1b84-4f62-97d0-6027945cc6f4"}
{"abstract": "We present a framework for performance prediction of distributed and mobile systems. We rely on process calculi and their structural operational semantics. The dynamic behaviour is described through transition systems whose transitions are labelled by encodings of their proofs that we then map into stochastic processes. We enhance related works by allowing general continuous distributions resorting to a notion of enabling between transitions. We also discuss how the number of resources available affects the overall model. Finally, we introduce a notion of bisimulation that takes stochastic information into account and prove it to be a congruence. When only exponential distributions are of interest our equivalence induces a lumpable partition on the underlying Markov process.", "authors": ["Corrado Priami"], "n_citation": 18, "references": ["09bc1c5f-57b5-4d79-9e88-d26c8c9b2e74", "1153fc31-d831-4eb2-8816-4423e60d89f5", "11d43d08-d930-4f95-ae8f-30ad403a3ece", "23163bd2-37f1-46f1-bde9-1a3636f87822", "3023929a-c93e-49c5-b03f-7fb0414d94df", "32c07bd4-52c7-4427-81a2-7dcdf2221452", "35617fe9-74d0-4ed1-80e6-2fde4876f074", "447bbd79-393a-4fb7-9bcb-e515f27d065b", "48404ae7-16ba-45e2-8997-e818a3a35959", "4b8d5647-b891-4bd0-b974-010bb0a27d6f", "53657d83-b1e4-40a2-84b6-de826c581015", "5ddd90bc-0702-41fd-8d6c-aa8a3ee09211", "6282ec7f-fab9-41fc-a813-c3c0dc69818e", "6480d5ac-a3a2-4084-9b36-8474c822ae19", "684f80ac-4d7d-46eb-9d1b-2599bae23de6", "6f1736c4-f00c-4169-8c11-9054dbbd461a", "6f45828a-82d4-4306-bc4f-f7fb31d4298e", "6fa0203b-090f-450e-a0cd-f551f0e7790b", "7e265bf9-4b1c-4bbe-8cf1-f3030ba51aee", "85b69cb4-228e-4b86-be0d-61c302d011dc", "89963e9c-71c9-48ee-94a5-89f639ccd76b", "92c421fd-bfa2-4600-86e8-734b5931a34b", "9801a8a7-90c9-4f54-abea-35bfaa48ecb7", "98c37b30-e2e1-4a5c-b64d-6fde36d32110", "a5791150-d736-4684-99b2-b4e04d74db8b", "a64dcd95-1a13-49dd-bb21-e9caa21229d4", "aafb864e-c2c1-4028-883e-aaa19d5d6973", "c6ec44bf-6c1b-436d-82ee-0d5e0e8af224", "c9b96f21-5796-4b7d-9d49-14812c0764b6", "ce6379b4-ea5c-4b8b-9ad2-510261b14611", "d51767f0-885a-43fa-b19f-a493cd846f02", "d618a444-a871-46db-9f99-13141aba2e4d", "ddf60a93-c9dd-4e23-996c-90a3426150f4"], "title": "Language-based Performance Prediction for Distributed and Mobile Systems", "venue": "Information & Computation", "year": 2002, "id": "6904f5f9-2711-4966-8985-7d2a38f1c877"}
{"abstract": "We present a theory of timed interfaces, which is capable of specifying both the timing of the inputs a component expects from the environment, and the timing of the outputs it can produce. Two timed interfaces are compatible if there is a way to use them together such that their timing expectations are met. Our theory provides algorithms for checking the compatibility between two interfaces and for deriving the composite interface; the theory can thus be viewed as a type system for real-time interaction. Technically, a timed interface is encoded as a timed game between two players, representing the inputs and outputs of the component. The algorithms for compatibility checking and interface composition are thus derived from algorithms for solving timed games.", "authors": ["Luca de Alfaro", "Thomas A. Henzinger", "Mari\u00eblle Stoelinga"], "n_citation": 219, "references": ["15453c5e-cdfb-4003-9295-cda10cc8c38d", "16869ef2-6c02-4516-890a-4f86862ff8ed", "1ef11eb3-f65a-4d8b-b003-031feb751838", "65ca2646-5e2f-4568-bdb0-d2d8ca73d47b", "75a3c4f1-94e8-44f6-9b8a-174635779f54", "92d67e53-a8e0-4b0c-bc5a-7bcc1c6f6271", "932af7de-7b95-421e-9c2e-9b55d84d556e", "9d197342-cf24-4cd9-859e-1c2ca1d22ab7", "ae0756d4-ab12-48f2-baee-5ba8d65c38a7", "e1238dd4-16e1-47ea-aa4b-bc8c48a48436", "efa90775-95e2-43d5-bed6-f4588fc0a03a", "f297f98e-92ff-456a-af7d-25ef3057957d", "f93087c8-ae61-4507-bc30-7f29a96ac1dc"], "title": "Timed Interfaces", "venue": "embedded software", "year": 2002, "id": "b71ee39c-1e27-4293-b5a2-8acc91d9f7c0"}
{"abstract": "An integrated environment for requirements engineering that supports participatory development activities is described. The environment helps ensure quality by supporting and encouraging group participation and interaction. The computer-supported cooperative-work environment supports the development and analysis of system-and-software-level requirements for large, complex applications. It encompasses and coordinates all aspects of requirements development, from conceptual inspiration, through planning, to specific project details. Case studies of groups using this environment show it can support requirements engineering for groups of users determining system-level requirements for large, complex systems. >", "authors": ["J.D. Palmer", "N.A. Fields"], "n_citation": 50, "references": ["9cf88142-29d6-49df-8b06-6b8462252de1"], "title": "An integrated environment for requirements engineering", "venue": "IEEE Software", "year": 1992, "id": "17bbde4e-4037-45ce-a0d0-147218769b02"}
{"abstract": "This paper evaluates a number of methods for authentication and passwording. It first discusses the role of authentication as a component in an overall approach to information system security. It then classifies the various approaches to authentication into two categories: natural properties and artificial measures. Among the artificial measures, password is most common. The paper provides a quantitative measure for password robustness and 'lasting' power. It discusses encryption possibilities and provides a comparative evaluation of various password methods. The paper concludes by providing some guidelines for evaluating authentication methods.", "authors": ["Niv Ahituv", "Yeheskel Lapid", "Seev Neumann"], "n_citation": 12, "references": ["3fb43b00-905c-4a08-934d-198ea4eb66c3", "6928e652-bddd-4f05-8bc9-c9f0174aec32", "d61fd9c3-fd2b-4c89-9baa-477a271ea68f"], "title": "Verifying the authentication of an information system user", "venue": "Computers & Security", "year": 1987, "id": "1a83f13a-dd28-49f1-ad04-9fc92ed44b3d"}
{"abstract": "This paper describes a general framework for automatic termination analysis of logic programs, where we understand by \u201ctermination\u201d the finiteness of the LD-tree constructed for the program and a given query. A general property of mappings from a certain subset of the branches of an infinite LD-tree into a finite set is proved. From this result several termination theorems are derived, by using different finite sets. The first two are formulated for the predicate dependency and atom dependency graphs. Then a general result for the case of the query-mapping pairs relevant to a program is proved (cf. [29, 21]). The correctness of the TermiLog system described in [22] follows from it. In this system it is not possible to prove termination for programs involving arithmetic predicates, since the usual order for the integers is not well-founded. A new method, which can be easily incorporated in TermiLog or similar systems, is presented, which makes it possible to prove termination for programs involving arithmetic predicates. It is based on combining a finite abstraction of the integers with the technique of the query-mapping pairs, and is essentially capable of dividing a termination proof into several cases, such that a simple termination function suffices for each case. Finally several possible extensions are outlined.", "authors": ["Nachum Dershowitz", "Naomi Lindenstrauss", "Yehoshua Sagiv", "Alexander Serebrenik"], "n_citation": 84, "references": ["009589d7-98d4-43fe-b7f2-be8cca868248", "1f24007d-08ff-4c6b-ae3a-12451d6a65b3", "1fdfbd1c-28c7-445d-9144-3bbd8a843f3b", "58c12637-335e-4f0e-bb51-e7cb05cd6d79", "5d9b9bdd-450e-43fc-b313-2608614c202a", "643a9613-fe47-406f-ad22-dbb42cc2f8ab", "66e22125-bbae-407e-8f00-ccf450bff9c4", "69fd07ac-6c29-4d16-ab8c-2bfcda5d1910", "7043c65b-1f94-478c-9c0b-bd34c20351de", "8efc6cd8-545f-4cf0-b25a-b6f83840c1a8", "9d023f9c-79d7-437e-b4f8-84ffc4fcee40", "a1f2721a-2c77-44c8-bb41-08eaacb9910e", "b2c8fe81-0c47-4498-85b8-a3245c64f2dc", "c24278c4-5209-47b5-b2b8-11f0684f1d64", "cf4fc14a-87a7-4338-b5bd-d3d1a4888095", "cf932d26-3ea5-42ef-bea4-2168dafd8961", "e54b994e-9293-4b1e-82d1-771b0fc76035", "ea2bf352-164a-4e52-b342-a98bc3f65cc9", "f8f85a41-d27f-4c31-861b-2642dcbfd40d"], "title": "A General Framework for Automatic Termination Analysis of Logic Programs", "venue": "Applicable Algebra in Engineering, Communication and Computing", "year": 2001, "id": "35c186be-44d5-47eb-b536-9938a93308ba"}
{"abstract": "The water distribution system (WDS) is composed by several elements, where flow control is one of the most important components needed in order to provide a satisfactory level of service. In order to advene an adequate level of water in the distribution tanks, we need to dynamically control the flow. Here, we propose a replicator dynamics approach in order to control tanks, by allocating in them the maximum uniform volume. The feedback interconnected systems reach an asymptotically stable equilibrium point for this approach. The stability analysis uses some passivity concepts and classic Lyapunov theory for a closed-loop system that combines the replicator dynamics (controller), and the WDS (process). We show the operation under different scenarios via simulations.", "authors": ["Eduardo Ramirez-Llanos", "Nicanor Quijano"], "n_citation": 2, "references": ["107a6f4e-a167-4b1a-9d71-8461daa4408b", "6310471d-f344-4a68-b937-7a9f9ec1b919", "c1758e88-3261-4600-988c-bd217a037396"], "title": "Analysis and control for the water distribution problem", "venue": "conference on decision and control", "year": 2010, "id": "3562da43-3b69-4ce0-b8a8-03187c313f02"}
{"abstract": "We present an integer linear program based algorithm and a K shortest path based heuristic algorithm for solving the routing and wavelength assignment problem in all optical networks with limited wavelength conversion. These algorithms are executed on a random mesh National Science Foundation Network (NSFNET). Their performances are compared.", "authors": ["M. D. Swaminathan", "Kumar N. Sivarajan"], "n_citation": 50, "references": ["568921fb-af83-459f-bee7-0d0b2f8b8bfe", "74ed25ec-082c-4a33-8da3-8ca2853d08cb", "80e4e32f-d624-4887-8d0d-2a7bcb91bc1e", "e8e9e4d3-89a2-42cb-b22c-8a0a2374b634"], "title": "Practical routing and wavelength assignment algorithms for all optical networks with limited wavelength conversion", "venue": "international conference on communications", "year": 2002, "id": "7c3ae2a1-1f54-4c0c-be0c-e3b5e4067111"}
{"abstract": "Privacy definitions provide ways for trading-off the privacy of individuals in a statistical database for the utility of downstream analysis of the data. In this paper, we present  Blowfish , a class of privacy definitions inspired by the Pufferfish framework, that provides a rich interface for this trade-off. In particular, we allow data publishers to extend differential privacy using a   policy , which specifies (a)  secrets , or information that must be kept secret, and (b)  constraints  that may be known about the data. While the secret specification allows increased utility by lessening protection for certain individual properties, the constraint specification provides added protection against an adversary who knows correlations in the data (arising from constraints). We formalize policies and present novel algorithms that can handle general specifications of sensitive information and certain count constraints. We show that there are reasonable policies under which our privacy mechanisms for k-means clustering, histograms and range queries introduce significantly lesser noise than their differentially private counterparts. We quantify the privacy-utility trade-offs for various policies analytically and empirically on real datasets.", "authors": ["Xi He", "Ashwin Machanavajjhala", "Bolin Ding"], "n_citation": 50, "references": ["0c3fa627-3215-4dd1-9f76-9a14c9bb8e0a", "1b062c55-1cb2-48e6-a809-97258bb308be", "23c0fb40-5d1f-4160-95fc-2e94a6f2d270", "389cd6d0-c6c4-4d44-8a76-63caf0d202f9", "5919a4d4-b4fc-4d8d-9b4d-d4b3255259f3", "5b26d855-551c-47cc-be7b-0bb83b54efd7", "5b7626f0-9946-44b8-99d1-4b06e36c6973", "5e11a4d6-8096-49bc-a3fd-35a9e0d62adc", "700672fd-23a3-4ac5-bbd5-9c6139a36507", "70f4dcf0-2784-4627-899c-1463988a3f52", "86e22e52-fcf7-4c67-bc2f-4cd688169d41", "acfb77cd-46c1-4998-96e0-324b53fd410c", "b132bbac-799b-4cec-8ec1-eec195be3a13", "b4123537-75d5-420f-ac0e-e69f16da1ae1", "b658b650-290f-46d9-b052-c3995b3bb24a", "b9badc17-895e-40e2-adc1-e34ad9ca2f5f", "c85a6eda-12fb-43f5-98cd-dcc0ab83b13d", "e387fa3e-6700-4a20-a5bb-3d8eaaa900bc"], "title": "Blowfish privacy: tuning privacy-utility trade-offs using policies", "venue": "international conference on management of data", "year": 2014, "id": "81fa38a7-59da-42da-883e-5a06cd8b793d"}
{"abstract": "Core Grid technologies are rapidly maturing, but there remains a shortage of real Grid applications. One important reason is the lack of a simple and high-level application programming toolkit, bridging the gap between existing Grid middleware and application-level needs. The Grid Application Toolkit (GAT), as currently developed by the EC-funded project GridLab, provides this missing functionality. As seen from the application, the GAT provides a unified simple programming interface to the Grid infrastructure, tailored to the needs of Grid application programmers and users. A uniform programming interface will be needed for application developers to create a new generation of \"Grid-aware\" applications. The GAT implementation handles both the complexity and the variety of existing Grid middleware services via so-called adaptors. Complementing existing Grid middleware, GridLab also provides high-level services to implement the GAT functionality. We present the GridLab software architecture, consisting of the GAT, environment-specific adaptors, and GridLab services. We elaborate the concepts underlying the GAT and outline the corresponding application programming interface. We present the functionality of GridLab's high-level services and demonstrate how a dynamic Grid application can easily benefit from the GAT. All GridLab software is open source and can be downloaded from the project Web site.", "authors": ["Gabrielle Allen", "K. Davis", "Tom Goodale", "Andrei Hutanu", "Hartmut Kaiser", "Thilo Kielmann", "Andre Merzky", "R.V. van Nieuwpoort", "A. Reinefeld", "Florian Schintke", "T. Schott", "Edward Seidel", "Brygg Ullmer"], "n_citation": 187, "references": ["17b994e8-a1f6-4c9d-9360-30c599b582e9", "21885a44-c51c-4ba7-9d09-509c5517d33b", "319ee4cf-6eea-4134-9d8b-4ae1f739f33d", "35702210-fe5d-431f-9e02-91b9f3773c85", "36c05ec1-7f89-44d4-a180-49820c36e4a0", "379bf81f-a7f9-40da-9664-f30243187950", "4b07c7e5-9f09-495f-bbe5-01b7a8f289ac", "4e082c61-952f-4f86-819f-229e1e12ebd6", "5d421362-ba23-44bf-91b5-cc9334ffe8d3", "7e71272f-fc7a-4435-83d3-c097b56e7489", "80adbd88-3e4d-43e5-9c90-57bd2891fc77", "9553fde5-7523-4944-abb2-ce12a6d02afc", "aedd0f93-21be-4e3e-8307-5760eb20ecb1", "c8311815-4163-4e5c-8a25-c4a3205cb6d9", "f117be69-4ff9-42ad-b240-dea26333e27d"], "title": "The Grid Application Toolkit: Toward Generic and Easy Application Programming Interfaces for the Grid", "venue": "Proceedings of the IEEE", "year": 2005, "id": "9aba3413-36c9-4fa0-a3ed-4c2d2de7c83a"}
{"abstract": "Recently modern non-Euclidean structure and motion estimation methods have been incorporated into augmented reality scene tracking and virtual object registration. We present a study of how the choice of projective, affine or Euclidean scene viewing geometry and similarity, affine or homography based object registration affects how accurately a virtual object can be overlaid in scene video from varying viewpoints. We found that projective and affine methods gave accurate overlay to a few pixels, while Euclidean geometry obtained by auto calibrating the camera was not as accurate and gave about 7 pixel overlay error.", "authors": ["Dana Cobzas", "Martin Jagersand"], "n_citation": 8, "references": ["59bca9b6-5a65-46a0-937e-01c3d52b7a56", "61d46e5d-553e-476f-8440-938224c32d8e", "6638640f-dac6-4abf-bdac-427600d48b40", "7b3e2564-07d0-4a24-a7af-5dd8c4f6003d", "8ffc9710-39d5-44ba-9edd-8c66b8002603", "905461e4-643b-4da0-a669-f52318b9e126", "9cf8a10b-cbad-486a-900e-d2bcfb64438f", "af0fcbf4-a30e-4fb3-980a-7c2e68fd5240", "d1641753-2e4c-403c-8661-38934c93e950", "ef80496a-0106-484c-abf8-c848b7427321", "f6779f97-9495-4387-b68c-e5fd5cf3462f"], "title": "A comparison of viewing geometries for augmented reality", "venue": "scandinavian conference on image analysis", "year": 2003, "id": "b956251a-a8c7-4748-8f1c-74da34a2deb3"}
{"abstract": "In a large-scale space, structure is at a significantly larger scale than the observations available at an instant. To learn the structure of a large-scale space from observations, the observer must build a cognitive map of the environment by integrating observations over an extended period of time, inferring spatial structure from perceptions and the effects of actions. The cognitive map representation of large-scale space must account for a mapping, or learning structure from observations, and navigation, or creating and executing a plan to travel from one place to another. Approaches to date tend to be fragile either because they don't build maps; or because they assume nonlocal observations, such as those available in preexisting maps or global coordinate systems, including active landmark beacons and geo-locating satellites. We propose that robust navigation and mapping systems for large-scale space can be developed by adhering to a natural, four-level semantic hierarchy of descriptions for representation, planning, and execution of plans in large-scale space. The four levels are sensorimotor interaction, procedural behaviors, topological mapping, and metric mapping. Effective systems represent the environment, relative to sensors, at all four levels and formulate robust system behavior by moving flexibly between representational levels at run time. We demonstrate our claims in three implemented models: Tour, the Qualnav system simulator, and the NX robot.", "authors": ["Benjamin Kuipers"], "n_citation": 419, "title": "Navigation and mapping in large-scale space", "venue": "Ai Magazine", "year": 1988, "id": "ae6cd4c2-6f6b-49bb-baa8-232b394b171f"}
{"authors": ["Robin Milner"], "n_citation": 110, "references": ["1112fb69-3c57-474e-8249-b9e9d4fee557", "130de3ed-7534-4e47-86f3-de89c7d2d897", "be7fa144-980d-4531-bb25-de47709b68ca"], "title": "Flowgraphs and Flow Algebras", "venue": "Journal of the ACM", "year": 1979, "id": "756844a5-0145-4529-b1e8-63e0cf1f4bc5"}
{"abstract": "The development of a syntactic textual entailment system that compares the dependency relations in both the text and the hypothesis has been reported. The Stanford Dependency Parser has been run on the 2-way RTE-3 development set and the dependency relations obtained for a text and hypothesis pair has been compared. Some of the important comparisons are: subject-subject comparison, subject-verb comparison, object-verb comparison and cross subject-verb comparison. Corresponding verbs are further compared using the WordNet. Each of the matches is assigned some weight learnt from the development corpus. A threshold has been set on the fraction of matching hypothesis relations based on the development set. The threshold score has been applied on the RTE-4 gold standard test set using the same methods of dependency parsing followed by comparisons. Evaluation scores obtained on the test set show 54.75% precision and 53% recall for YES decisions and 54.45% precision and 56.2% recall for NO decisions.", "authors": ["Partha Pakray", "Alexander F. Gelbukh", "Sivaji Bandyopadhyay"], "n_citation": 9, "references": ["06ba8c41-6f82-4722-b0af-4260612387c8", "28ec179b-6167-40a6-a95c-7cf67600a951", "484d1994-e9da-477d-9be2-1f1e154cd919", "66c3e6a6-94ab-4315-b795-9bd71d02506c"], "title": "A syntactic textual entailment system based on dependency parser", "venue": "international conference on computational linguistics", "year": 2010, "id": "143535ef-760d-4deb-b8dc-0bcd37741575"}
{"abstract": "The Grid's vision, of sharing diverse resources in a flexible, coordinated and secure manner through dynamic formation and disbanding of virtual communities, strongly depends on metadata. Currently, Grid metadata is generated and used in an ad hoc fashion, much of it buried in the Grid middleware's code libraries and database schemas. This ad hoc expression and use of metadata causes chronic dependency on human intervention during the operation of Grid machinery, leading to systems which are brittle when faced with frequent syntactic changes in resource coordination and sharing protocols. The Semantic Grid is an extension of the Grid in which rich resource metadata is exposed and handled explicitly, and shared and managed via Grid protocols. The layering of an explicit semantic infrastructure over the Grid Infrastructure potentially leads to increased interoperability and greater flexibility. In recent years, several projects have embraced the Semantic Grid vision. However, the Semantic Grid lacks a Reference Architecture or any kind of systematic framework for designing Semantic Grid components or applications. The Open Grid Service Architecture (OGSA) aims to define a core set of capabilities and behaviours for Grid systems. We propose a Reference Architecture that extends OGSA to support the explicit handling of semantics, and defines the associated knowledge services to support a spectrum of service capabilities. Guided by a set of design principles, Semantic-OGSA (S-OGSA) defines a model, the capabilities and the mechanisms for the Semantic Grid. We conclude by highlighting the commonalities and differences that the proposed architecture has with respect to other Grid frameworks.", "authors": ["Oscar Corcho", "Pinar Alper", "Ioannis Kotsiopoulos", "Paolo Missier", "Sean Bechhofer", "Carole Goble"], "n_citation": 137, "references": ["10d9432c-e962-4bd7-b653-7c56fbcf85de", "379bf81f-a7f9-40da-9664-f30243187950", "3b02244d-9185-4d68-a812-3ccf16a3b93f", "52597083-287b-4ef5-b5bf-0eb8d1bb0aae", "56b05bc7-1cbb-4b6e-9b74-1bf8236aa4f7", "7beee8a6-39ad-4bb2-91fd-4c50b8580387", "8d09d372-993c-48d5-918d-d646c979b2fe", "cd842614-1072-4f3a-9a1b-85a8e3034eaa", "ee946288-8d86-4d4a-b2e1-dbd1571aa1ff"], "title": "An overview of S-OGSA: A Reference Semantic Grid Architecture", "venue": "Journal of Web Semantics", "year": 2006, "id": "c3bb0be5-5598-4a78-939f-94c3ff2231b2"}
{"abstract": "Methods to display realistic clouds are proposed. To display realistic images, a precise shading model is required: two components should be considered. One is multiple scattering due to particles in clouds, and the other factor to be considered is sky light. For the former, the calculation of cloud intensities has been assumed to be complex due to strong forward scattering. However, this paper proposes an efficient calculation method using these scattering characteristics in a positive way. The latter is a very significant factor when sky light is rather stronger than direct sunlight, such as at sunset/sunrise, even though sky light has been ignored in previous methods. This paper describes an efficient calculation method for light scattering due to clouds taking into account both multiple scattering and sky light, and the modeling of clouds. CR Categories and Subject Descriptors:", "authors": ["Tomoyuki Nishita", "Yoshinori Dobashi", "Eihachiro Nakamae"], "n_citation": 269, "references": ["07e6ea14-64f9-4835-9a02-a608650fe580", "10482dd3-4642-4193-842f-85f3b70fcf65", "2c01eefe-8b3b-408e-be76-a176ecbe4fdc", "5ee7a58a-fad4-4d5f-83be-998d07734e67", "7459a5f6-fab5-497f-a3a9-451c0a78eb78", "794095cf-df7a-441b-bfce-e03b52245eaf", "81026b0e-a27c-4d87-bed6-c24f6389c525", "a074457f-ea16-49ec-bf14-bd9c65110e07", "af89096b-b3f3-4bd7-8509-73b8fa06b973", "c1d52e7d-ff96-4ecd-b329-1255af370945", "c2a1c711-22a4-4847-8795-609e064060f6", "c7a440fd-5918-4b4c-883d-c0c27429948b", "da983d15-0b0a-4a81-8a0c-e087be1125da", "e8c402f1-4ee8-442d-a634-d19430340fe6", "ffeeeb06-9bd7-4c0d-bf4e-cd91c0924a28"], "title": "Display of clouds taking into account multiple anisotropic scattering and sky light", "venue": "international conference on computer graphics and interactive techniques", "year": 1996, "id": "2b81ed4d-2df5-49c6-a241-8530c0f3bf21"}
{"abstract": "The REALISM animation system encapsulates behavioural control mechanisms within the objects in a scene, offering a single interface to both modelling and animation. Libraries of actors allow creative skills to be focused on scene development and not individual object control. The progress of an animation sequence is defined by a controlling script. Individual object behaviour is defined by rules and constraints, themselves dynamic entities that can modify their own behaviour during the animation. Each element controls its own destiny which is guided but not dictated by the script. To reduce the communication overhead caused by the inter-object dialogue necessary for collision detection, a two stage process is implemented. This consists of a bounding volume check as the first stage, and objects communicating to resolve collisions as the second stage. The algorithm ensures that the workload is distributed evenly throughout the objects, guaranteeing a maximum limit to the workload per object. >", "authors": ["Ian J. Palmer", "Richard L. Grimsdale"], "n_citation": 50, "references": ["259017f1-3f1f-438f-bd92-eb264d7ed402", "5999ccaa-aa2f-42eb-84fc-97d63227e4ad", "5d938778-733a-4dce-9805-7c55ce268338", "82e8e75f-5cae-4b1a-9f3d-79ea2555f9fe", "90cdf053-16bd-49f0-83d2-c055fc562bd7", "f002a00c-c4a0-487e-ada7-cfc65692b6ce", "f09f9db4-25a8-4964-8fb1-60a066598709"], "title": "REALISM: reusable elements for animation using local integrated simulation models", "venue": "", "year": 1994, "id": "8b0c4e42-999d-4567-9cd5-4930d18ab2e2"}
{"authors": ["Catriel Beeri"], "n_citation": 53, "references": ["0b6d242d-73a1-40e2-913e-b2df42337912", "15fe90ce-45ae-48f3-a57b-a499ea57052b", "1de1d0ab-2892-4bbf-9039-286b2ea807e1", "2d414d43-bfaa-49a2-9560-6595b0841489", "30cdf3c6-464a-4d66-812e-f9a50a2fc3b0", "38791ff6-513b-4bf8-b17e-df7ee2b66040", "43c03d43-c171-48c7-bc94-75d5324a90f1", "4ca749f6-e785-4bae-8020-d00757000d5f", "4d72ac5c-0b93-4fb0-9d39-bd23feb91fa0", "515cadca-a173-4ecd-b0d4-b67c26a2a844", "51e2b28e-9843-4d1d-9f6f-f1b1d7eb56c1", "545700fc-1579-4e59-a277-32b00bb4d53f", "5c089439-08c0-44bc-b5bb-e2b834f18aba", "6097fdc7-d124-47d9-a6ac-4366c4505800", "6be12c99-50af-4cfb-9fb2-98104c46486c", "7b9c2caa-ce30-4b47-9105-840ce086dafe", "84a1ae73-8bff-46b4-a10a-71652ab28b70", "90ed385b-f9fa-469f-9c7d-b473cb78707b", "9b9b09fa-d65d-4c3d-950c-82c28798df79", "b4d3eace-3201-48a3-8395-408616b884f8", "d274ab9e-b47c-456f-9493-b8935f64400f", "d3822649-b90d-4633-aefb-07759b601e68", "dc08b803-60be-4afe-bc0a-d5a1d726d436", "df205695-3e42-450b-b16a-24cd98bf0090", "e3ba6428-74ba-41c2-9bd7-148a2c6308a8", "e3d42787-46cd-4342-ae81-079a850267d0", "e77ab374-1156-458e-acc8-af73e69e5d06", "fbf9cf1c-1733-4493-a720-ca8607ad3082", "ff5eab7f-38e9-4700-b609-0618e279b4a7"], "title": "Data Models and Languages for Databases", "venue": "international conference on database theory", "year": 1988, "id": "72b8da5e-7012-4c07-b87b-f92721676c4b"}
{"abstract": "A key problem in diagrammatic reasoning is understanding how people reason about qualitative relationships in diagrams. We claim that progress in diagrammatic reasoning is slowed by two problems: (1) researchers tend to start from scratch, creating new spatial reasoners for each new problem area, and (2) constraints from human visual processing are rarely considered. To address these problems, we created GeoRep, a spatial reasoning engine that generates qualitative spatial descriptions from line drawings. GeoRep has been successfully used in several research projects, including cognitive simulation studies of human vision. In this paper, we outline GeoRep\u2019s architecture, explain the domainindependent and domain-specific aspects of its processing, and motivate the representations it produces. We then survey how GeoRep has been used in three different projects \u2010a model of symmetry, a model of understanding juxtaposition diagrams of physical situations, and a system for reasoning about military courses of action.", "authors": ["Ronald W. Ferguson", "Kenneth D. Forbus"], "n_citation": 70, "references": ["2e6b9a4f-9944-4e36-bf90-fd352b630e17", "324d16a2-c273-4744-8f45-bd903eab9897", "78dd7c1a-bc00-4993-bd41-8e5da9a7fe5b", "d2c84270-b7a1-4eeb-8555-a5a447a3280b", "dbe5ae2e-bbc0-4508-8df5-3ec95c784fa8", "f8290e0d-727b-4405-ae8c-2e8e4c71347e"], "title": "GeoRep: A Flexible Tool for Spatial Representation of Line Drawings", "venue": "national conference on artificial intelligence", "year": 2000, "id": "26ba48bf-372e-45c7-b1f6-59748c5fa3a6"}
{"abstract": "Often, qualitative values have an ordering, such as (very-short, short, medium-height, tall) or a hierarchical level, such as (The-World, Europe, Spain, Madrid), which are used by people to interpret mistakes and approximations among these values. Confusing Paris with Madrid yields an error smaller than confusing Paris with Australia, or Paris with Abraham Lincoln. And the \"difference\" between very cold and cold is smaller than that between very cold and warm. Methods are provided to measure such confusion, and to answer approximate queries in an \"intuitive\" manner. Examples are given. Hierarchies are a simpler version of ontologies, albeit very useful. Queries have a blend of errors by order and errors by hierarchy level, such as \"what is the error in confusing very cold with tall?\" or \"give me all people who are somewhat like (John (plays baseball) (travels-by water-vehicle) (lives-in North-America)).\" Thus, retrieval of approximate objects is possible, as illustrated here.", "authors": ["Adolfo Guzm\u00e1n-Arenas", "Serguei Levachkine"], "n_citation": 50, "references": [], "title": "Graduated Errors in Approximate Queries Using Hierarchies and Ordered Sets", "venue": "mexican international conference on artificial intelligence", "year": 2004, "id": "85ddd962-c37a-424d-8290-c2651df17b64"}
{"abstract": "A support vector machine (SVM) with the auto-correlation of a compactly supported wavelet as a kernel is proposed in this paper. The authors prove that this kernel is an admissible support vector kernel. The main advantage of the auto-correlation of a compactly supported wavelet is that it satisfies the translation invariance property, which is very important for its use in signal processing. Also, we can choose a better wavelet by selecting from different wavelet families for our auto-correlation wavelet kernel. This is because for different applications we should choose wavelet filters selectively for the autocorrelation kernel. We should not always select the same wavelet filters independent of the application, as we demonstrate. Experiments on signal regression and pattern recognition show that this kernel is a feasible kernel for practical applications.", "authors": ["Guangyi Chen", "Gregory Dudek"], "n_citation": 18, "references": ["06e57e72-6753-4be2-8a60-8f9030b0472e", "281281cd-8ef7-4f6b-bd5d-dbdc69b264ad", "46fd3ceb-5061-4348-800b-1165d8eff55f", "4a577eda-741c-4bac-87d6-477ca2b794d5", "50dd56db-151d-4d62-8576-65f0ef6f381b", "549f0527-0f13-4447-9dc0-ca699e2dc219", "7ccbdf09-a84e-4ad2-ab20-cb28b6c41155", "9836613c-d506-47ca-be5c-9b126f250ddc", "98ff032e-274c-44b1-80b6-0448a597b7d2", "c179f115-9bc7-48c0-b420-fa2bf8769b6e", "d56289f6-f687-41be-a820-a5bb4c249686"], "title": "Auto-correlation wavelet support vector machine", "venue": "Image and Vision Computing", "year": 2009, "id": "a8c99f00-bee6-46b5-9e44-3a694c981053"}
{"abstract": "We show how to continuously map a texture onto a 3D triangle mesh when some of the mesh vertices are constrained to have given (u,v) coordinates. This problem arises frequently in interactive texture mapping applications and, to the best of our knowledge, a complete and efficient solution is not available. Our techniques always guarantee a solution by introducing extra (Steiner) vertices in the triangulation if needed. We show how to apply our methods to texture mapping in multi-resolution scenarios and image warping and morphing.", "authors": ["Ilya Eckstein", "Vitaly Surazhsky", "Craig Gotsman"], "n_citation": 58, "references": ["18cc56a1-b545-4ab3-b61a-dfa5cbf57210", "352924a1-d9a9-48de-bf81-08a2a29f3a6b", "41bf2474-f226-46c1-8016-9d133f601d18", "6df2e4aa-ad51-4489-a67f-ef952dcb038c", "7050f0fb-7af2-49aa-86e1-b4115342ee85", "74686071-4ae5-41de-8327-0ec948b6dd31", "83414b2a-ff37-44e1-909d-c7db3c1a4187", "abff3bd4-b671-448f-8c1a-22c1c1da461f", "b82a8561-a636-4ec4-9ba4-fe7451739049", "c55938d4-d283-4d82-8649-75a5ffd28d67", "d81f78c2-cdd3-43f1-af66-4eeef71b491b", "dff823b8-6efa-4ef4-b1f1-21f237f81a79"], "title": "Texture Mapping with Hard Constraints", "venue": "Computer Graphics Forum", "year": 2001, "id": "0a2c918b-0122-48f8-85ce-61ea12b643b9"}
{"abstract": "As processors continue to exploit more instruction-level parallelism, a greater demand is placed on reducing the effects of memory access latency. In this paper, we introduce a novel modification of the processor pipeline called memory renaming. Memory renaming applies register access techniques to load instructions, reducing the effect of delays caused by the need to calculate effective addresses for the load and all preceding stores before the data can be fetched. Memory renaming allows the processor to speculatively fetch values when the producer of the data can be reliably determined without the need for an effective address. This work extends previous studies of data value and dependence speculation. When memory renaming is added to the processor pipeline, renaming can be applied to 30% to 50% of all memory references, translating to an overall improvement in execution time of up to 41%. Furthermore, this improvement is seen across all memory segments-including the heap segment, which has often been difficult to manage efficiently.", "authors": ["Gary S. Tyson", "Todd M. Austin"], "n_citation": 168, "references": ["00191767-c48b-4da4-b976-1bdf39dbde6c", "00f223e1-6505-4561-929b-580e3b48d465", "2099a564-1840-4e7c-a89b-75d4736600b3", "50bf95a2-b96d-49ec-828e-a46abe0e1057", "5e03fa4e-0898-4b8c-b1ed-2ba7ab0cb27f", "b2d3b3b4-6721-4180-8c39-90b1365eb959"], "title": "Improving the accuracy and performance of memory communication through renaming", "venue": "international symposium on microarchitecture", "year": 1997, "id": "35e5bef2-e21b-4850-8667-dbbcdfec8fa5"}
{"abstract": "We present an algorithm for the c-approximate nearest neighbor problem in a d-dimensional Euclidean space, achieving query time of O\\left( {dn^{1/c^2 + o(1)} } \\right) and space O\\left( {dn + n^{1 + 1/c^2 + o(1)} } \\right). This almost matches the lower bound for hashing-based algorithm recently obtained in [27]. We also obtain a space-efficient version of the algorithm, which uses dn+n log^{O(1)} n space, with a query time of dn^{O(1/c^2 )}. Finally, we discuss practical variants of the algorithms that utilize fast bounded-distance decoders for the Leech Lattice.", "authors": ["Alexandr Andoni", "Piotr Indyk"], "n_citation": 533, "references": ["0f094852-0668-4dfe-92cc-ae5659ffc1d9", "15ea05e5-6f54-4572-973b-a7ec37f5bd26", "180227c0-b93a-4b0b-8194-7b5ce2c01e1f", "1cd8a7cf-6612-4ad0-991b-f5850aa76755", "1fb75a9d-a142-41aa-bd2f-a5968925d721", "29f196b0-3df4-43c9-bf33-6411f5adf879", "2aa0b062-5069-4b28-8020-5e5325e77acd", "2cde7156-9b73-4ffd-804b-2089b7b98d51", "2e0c0709-138c-461c-af4f-64037b7feee4", "42ccceff-8186-4fb1-a8a6-27468fa828ce", "53feaa4d-2c39-437e-b381-313e3bde12c0", "5437c0a0-8f20-49c3-86e5-9d860f3e4f04", "58525691-f447-4300-8a8a-a94af1edbde8", "5fec7ec9-a6ad-4793-89a7-f834305b4e4f", "80aca55b-1c67-4260-a3a0-e203fd8d49ec", "84475cb3-1451-4d84-ad16-3c96240bb5e1", "89022b09-5732-4493-9e2d-2046059dd2e5", "8b5a4802-dab0-4d29-8398-e3c91f0edfe8", "90ef9074-bd72-4b31-b9c0-0c20e3e7eb2e", "9a33ddde-c275-4997-b037-0b48648bb1f7", "adf6fdf9-01a0-4051-9d99-965f4a5baa4d", "b11f895d-0f55-486d-8d4a-dbd18bf9ba1f", "bad4cb64-90b5-4c8d-b1bf-0241bca6d850", "bc46277f-2a3c-466e-a646-1a5394ace50d", "bd99cee2-3297-4155-af82-426ab28c1e11", "be23df9d-eee9-4db4-8e88-55c3b9dd0481", "c315a8f1-cfad-488b-aaf3-b805f67d4a3c", "d177d36d-4ab6-4ac8-8dc0-e24581b1ed84", "d970a76b-2c8d-49ef-92e4-b94f43e334df", "dda32e99-40c9-4d5f-8982-51e4b1dca885", "ddaddf72-e527-455d-8a1b-67553b867fb2", "e4195865-096f-42ce-9d05-502eddea54b3", "e97d9c05-854e-4bd6-9301-11affc0d103f", "f6272ea9-0360-47ed-90a5-651ea958143f"], "title": "Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions", "venue": "foundations of computer science", "year": 2006, "id": "a51fa2f9-2e1f-4070-9a5d-3951da3287c0"}
{"abstract": "It is difficult to interact with computer displays that are across the room, which can be important in meetings and when controlling computerized devices. A popular approach is to use laser pointers tracked by a camera, but interaction techniques using laser pointers tend to be imprecise, error-prone, and slow. Therefore, we have developed a new interaction style, where the laser pointer (or other pointing technique such pointing with a finger or even eye tracking) indicates the region of interest, and then the item there is copied (\"snarfed\") to the user's handheld device, such as a Palm or PocketPC handheld. If the content changes on the PC, the handheld?s copy will be updated as well. Interactions can be performed on the handheld using familiar direct manipulation techniques, and then the modified version is sent back to the PC. The content often must be reformatted to fit the properties of the handheld to facilitate natural interaction.", "authors": ["Brad A. Myers", "Choon Hong Peck", "Jeffrey Nichols", "Dave Kong", "Robert C. Miller"], "n_citation": 69, "references": ["169baf44-e66a-4163-bc12-062ab6516f30", "26d16ee1-5c2e-4445-8674-452598562770", "2bcef527-5dfd-417d-8702-927fe91f9226", "2f9d18e9-b489-49da-b283-2f8df57cafe1", "3d53c9de-1dec-4b78-a23d-d76c08f1e349", "420558d3-ae91-423d-b411-86eb7fbb3f65", "49177332-af00-4c4f-a9be-0b88165877a4", "55cc1a34-3be0-474f-9f00-8c53a1e67918", "b880f998-7f7f-49f9-8203-6789eed349fa", "e9ad62a7-612c-4581-ac73-8b008c5f797a", "f7911798-787d-4f07-9cef-f652c99ec49e"], "title": "Interacting at a Distance Using Semantic Snarfing", "venue": "ubiquitous computing", "year": 2001, "id": "94631d47-cfc5-4d49-8208-9d70e23f9785"}
{"abstract": "Abstract : Some recent advances in intrusion detection are based on detecting anomalies in program behavior, as characterized by the sequence of kernel calls the program makes. Specifically, traces of kernel calls are collected during a training period. The substrings of fixed length N (for some N) of those traces are called N-grams. The set of N-grams occurring during normal execution has been found to discriminate effectively between normal behavior of a program and the behavior of the program under attack. The N-gram characterization, while effective, requires the user to choose a suitable value for N. This paper presents an alternative characterization, as a finite state machine whose states represent predictive sequences of different lengths. An algorithm is presented to construct the finite state machine from training data, based on traditional string-processing data structures but employing some novel techniques.", "authors": ["Carla Marceau"], "n_citation": 149, "references": ["0c68a0b9-1ec4-455a-83c2-a38a2fcf7903", "33834a31-132a-409b-b646-c8918a85afb0", "5d3f3da9-66ad-4533-9cb0-24dd040581ce", "6ce2a644-1c2e-45cb-8453-2c702e9fb06e", "71dfe3af-6e1c-4ae8-b263-0dbaf3874c35", "b183a338-50d9-4195-b2d1-78243b3de3e8", "ca0c5501-5851-4f69-9f86-41deefcdbc8f", "d3e02530-7dca-4e01-8789-3490b8f1ca4f"], "title": "Characterizing the behavior of a program using multiple-length N-grams", "venue": "new security paradigms workshop", "year": 2001, "id": "cf74c67b-da47-4319-bc0a-9c9059797fb9"}
{"abstract": "As more health data becomes available, information extraction aims to make an impact on the workflows of hospitals and care centers. One of the targeted areas is the management of pathology reports, which are employed for cancer diagnosis and staging. In this work we integrate text mining tools in the workflow of the Royal Melbourne Hospital, to extract information from pathology reports with minimal expert intervention. Our framework relies on coarse-grained annotation (at document level), making it highly portable. Our evaluation shows that the kind of language used in these reports makes it feasible to extract information with high precision and recall, by means of state-of-the-art classification methods, and feature engineering.", "authors": ["David Martinez", "Yue Li"], "n_citation": 16, "references": ["10f9f125-909e-4671-b9b0-b89b76ae6ac9", "1208e677-5c30-46fb-b056-501eaa235f73", "93c54718-a2a9-4dfd-8c97-1a733d8e8a3a", "a6a56bcc-7671-46e6-a425-4a556539a7f6", "dadde174-3fc7-4c7d-8326-04e675eb2a41"], "title": "Information extraction from pathology reports in a hospital setting", "venue": "conference on information and knowledge management", "year": 2011, "id": "febc9cf6-e07d-4efd-aa6f-84c9feb97ab0"}
{"abstract": "For distributed applications to take full advantage of cloud computing systems, we need middleware systems that allow developers to build elasticity management components right into the applications. This paper describes the design and implementation of ElasticRMI, a middleware system that (1) enables application developers to dynam- ically change the number of (server) objects available to handle remote method invocations with respect to the application's workload, without requiring major changes to clients (invokers) of remote methods, (2) en- ables flexible elastic scaling by allowing developers to use a combination of resource utilization metrics and fine-grained application-specific in- formation like the properties of internal data structures to drive scaling decisions, (3) provides a high-level programming framework that handles elasticity at the level of classes and objects, masking low-level platform specific tasks (like provisioning VM images) from the developer, and (4) increases the portability of ElasticRMI applications across different pri- vate data centers/IaaS clouds through Apache Mesos (5).", "authors": ["Keerti Jayaram"], "n_citation": 50, "references": ["22dc34f7-bd6a-4f3f-822c-6fe8d6d2bf43", "2bb0a29d-ea18-4424-9821-0f09fabafd45", "35b81f6b-16e1-4dc7-a4a7-81e2f6962a2a", "38310602-ea23-471c-9937-3b0bb9aad658", "66fa41b0-fb74-4f0a-8ca7-b3f0222e60fd", "9230e3b3-a01b-4366-8063-7e3f36c44b69", "bbbdcca6-61b0-41bf-bd5a-24e3a33690ad", "c946121e-ada4-4715-9d77-a148cb280952", "e428d749-c2f1-41da-a00e-ef44850bf4c3"], "title": "Elastic Remote Methods", "venue": "", "year": 2013, "id": "bdc3406c-fae4-4e18-8b2b-5659b021080e"}
{"abstract": "Abstract : Communication, i.e., moving data, between levels of a memory hierarchy or between parallel processors on a network, can greatly dominate the cost of computation, so algorithms that minimize communication can run much faster (and use less energy) than algorithms that do not. Motivated by this, attainable communication lower bounds were established in [12, 13, 4] for a variety of algorithms including matrix computations. The lower bound approach used initially in [13] for Theta(N3) matrix multiplication, and later in [4] for many other linear algebra algorithms, depended on a geometric result by Loomis and Whitney [16]: this result bounded the volume of a 3D set (representing multiply-adds done in the inner loop of the algorithm) using the product of the areas of certain 2D projections of this set (representing the matrix entries available locally, i.e., without communication). Using a recent generalization of Loomis' and Whitney's result, we generalize this lower bound approach to a much larger class of algorithms, that may have arbitrary numbers of loops and arrays with arbitrary dimensions as long as the index expressions are a ne combinations of loop variables. In other words, the algorithm can do arbitrary operations on any number of variables like A(i(sub 1), i(sub 2), i(sub 2) - 2i(sub 1), 3 - 4i(sub 3) + 7i(sub 4), ...). Moreover, the result applies to recursive programs, irregular iteration spaces, sparse matrices, and other data structures as long as the computation can be logically mapped to loops and indexed data structure accesses. We also discuss when optimal algorithms exist that attain the lower bounds; this leads to new asymptotically faster algorithms for several problems.", "authors": ["Michael Christ", "James Demmel", "Nicholas Knight", "T. Scanlon", "Katherine A. Yelick"], "n_citation": 41, "references": ["117babbb-2523-4b3c-9e01-12d35e1b9ae8", "1d510d18-dae8-4c3a-82f9-7ff177102714", "2d405dd5-fbf9-4f45-bf53-d663fa12e5a3", "4643f081-4082-4a87-b9a8-0cc16a566f17", "5b9569d5-62e5-431a-a4a4-be6a03df3778", "73902beb-a66c-4a1e-99a7-5c07b6b9bf33", "9a89f085-a355-4612-9cf3-e173559688bb", "c52c9dc3-78d1-4782-b5f9-d65a545cdc64", "ea3abcf1-cbe5-4531-9606-74b5f8d8b325"], "title": "Communication lower bounds and optimal algorithms for programs that reference arrays -- Part 1", "venue": "arXiv: Classical Analysis and ODEs", "year": 2013, "id": "d2934a63-c187-45e9-b703-2955e6115544"}
{"abstract": "Although modern graphics hardware has strong capability to render millions of triangles within a second, huge scenes are still unable to be rendered in real-time. Lots of parallel and distributed graphics systems are explored to solve this problem. However none of them is built for large-scale graphics applications.We designed AnyGL, a large-scale hybrid distributed graphics system, which consists of four types of logical nodes, Geometry Distributing Node, Geometry Rendering Node, Image Composition Node and Display Node. The first two types of logical nodes are combined to be a sort-first graphics architecture while the others compose images. A new state tracking method based on logical timestamp is also pro-posed for state tracking of large-scale distributed graphics systems. Besides, three classes of compression are employed to reduce the requirement of network bandwidth, including command code compression, geometry compression and image compression. A new extension, global share of textures and display lists, is also implemented in AnyGL to avoid memory explosion in large-scale cluster rendering systems.", "authors": ["Jian Yang", "Jiaoying Shi", "Zhefan Jin", "Hui Zhang"], "n_citation": 50, "references": ["06a382a2-0374-45c2-ad9b-db373091fbf4", "1742be6a-7f66-46ac-9c68-58a82d8d6105", "2d69d0ee-fc6a-42e2-9be5-92ad44083478", "3fde9cbc-651b-4d22-9262-782c3f2bc4a6", "4f636bc5-15d6-48bc-85b9-899428d32e57", "51685519-0af2-422c-9d4d-e5b2d7d1fea0", "8b23e9b9-708e-420a-9fa8-6f58c6cbefaf", "9320c0a0-f4e7-40f9-8db0-e6c4e36705f9", "a71711d5-9990-4de4-85a1-14ebc6160c0e", "b1fa82e3-45a1-467f-948a-4d828f62c891", "b7a998d8-c2f8-42f4-bc6b-1c110806aac1", "db9499d5-de37-49b0-8da9-16c9bf9105ad", "e035e175-271b-44ed-9437-e6c76e763ae2", "e922d9c9-0120-4c46-bac7-a8e5387378d3", "f0c8116b-d0ab-47e3-bad3-f061ca8fedec", "fa335204-afa4-4191-8053-7df37403b317", "fd25e7a7-e333-4f47-873f-3f64f071b699"], "title": "Design and implementation of a large-scale hybrid distributed graphics system", "venue": "eurographics workshop on parallel graphics and visualization", "year": 2002, "id": "cb0e9fc1-32e1-4033-b7f5-18644c0fed8d"}
{"abstract": "With the advancing sophistication of security attacks, protecting open systems is increasingly challenging. Intrusion tolerance should be part of overall in-depth security. This article compares three types of intrusion tolerant system architectures.", "authors": ["Quyen L. Nguyen", "Arun K. Sood"], "n_citation": 50, "references": ["1c4d5171-b122-4192-9772-74f6a92c6911", "1cb78da3-2ce8-46ae-8fe2-54d9839dd973", "4f72ed57-d373-4a6b-8835-f23cf10fb70b", "551d1cbe-4ceb-4e1c-927b-455b91aba571", "570a2b73-3330-485b-b098-c650c4936526", "7f7177fe-1f15-47b4-90c1-3ccc3efdd538", "9d0e1b8f-c467-40e0-aaa9-c2c6f4dab160", "9f9a94e4-9c82-4ed5-b7a3-12811c54af0a", "c32b603c-fd34-4b88-bec2-21dc57d850ba", "fd4cd5fc-8c35-4a85-84ec-82f9a801afab"], "title": "A Comparison of Intrusion-Tolerant System Architectures", "venue": "ieee symposium on security and privacy", "year": 2011, "id": "fc601c45-cbb8-4bc3-add1-3be69f44d779"}
{"authors": ["Stephen Hole", "Duncan McPhee", "Alex Lohfink"], "n_citation": 6, "title": "Mining Spreadsheet Complexity Data to Classify End User Developers.", "venue": "", "year": 2009, "id": "ccebe489-ef26-4fed-94f1-89e32719f534"}
{"abstract": "Defect prediction is a very meaningful topic, particularly at change-level. Change-level defect prediction, which is also referred as just-in-time defect prediction, could not only ensure software quality in the development process, but also make the developers check and fix the defects in time. Nowadays, deep learning is a hot topic in the machine learning literature. Whether deep learning can be used to improve the performance of just-in-time defect prediction is still uninvestigated. In this paper, to bridge this research gap, we propose an approach Deeper which leverages deep learning techniques to predict defect-prone changes. We first build a set of expressive features from a set of initial change features by leveraging a deep belief network algorithm. Next, a machine learning classifier is built on the selected features. To evaluate the performance of our approach, we use datasets from six large open source projects, i.e., Bugzilla, Columba, JDT, Platform, Mozilla, and PostgreSQL, containing a total of 137,417 changes. We compare our approach with the approach proposed by Kamei et al. The experimental results show that on average across the 6 projects, Deeper could discover 32.22% more bugs than Kamei et al's approach (51.04% versus 18.82% on average). In addition, Deeper can achieve F1-scores of 0.22-0.63, which are statistically significantly higher than those of Kamei et al.'s approach on 4 out of the 6 projects.", "authors": ["Xinli Yang", "David Lo", "Xin Xia", "Yun Zhang", "Jianling Sun"], "n_citation": 35, "references": ["11df7d57-bad8-4b0b-8ce8-e26c6d9eb2b0", "12d0dbd4-4dd9-42b7-a321-14270882a619", "1d2aed09-fa6d-4e82-923a-2d5dc495e8f2", "1dcd9254-ecb1-4dd4-a87a-b10703196418", "2068a31e-93c4-497f-ad79-c0ca3bf88ab8", "28d06a39-fdb7-4c5a-9ff8-580ae92b0db9", "2ba41db5-ac76-4805-a904-67ff0361f528", "3ae77959-f332-4322-9ddb-93f1088d095d", "4e0d2792-5f82-4e13-812c-781172f92e40", "53ce6ee3-31f1-48ca-9881-f82209a2f949", "55b0c3cc-fc6d-41d4-9fd1-7c379856c40c", "5a7a4683-c9ae-4a47-8097-4929e006a9ce", "5ae89470-d627-4619-a6d0-c49a182844a5", "657b05e7-9b6f-4214-9be5-9e8aa6e69ff1", "770421aa-8c3e-46f2-ae1f-de1266ee2fcc", "79f86455-68c2-48dd-be7a-bcd009f16f41", "842e96df-fb8b-43ba-8643-4b3714b44dbf", "878389e2-7c11-4021-9be7-c740ef81da89", "8936f6b1-5f4a-43bf-8872-50a8b9e0c9f1", "89f10062-acf1-4171-b882-f3222c3a357e", "9605fd6e-63a8-44fd-b9a7-63e6cddf5a30", "a05b8bcf-789e-4538-8f43-86e6d7bb4285", "a1853113-dd04-44ae-9e76-a0ddfbf49084", "a2298c28-21d4-4bec-bf0f-01e586be093f", "a8d1666c-c249-493d-8f99-806a9403f148", "a95e8cd0-0be7-4a77-aa10-f842193d1f9b", "ab7e74af-c2d1-48bc-827e-32df6027649c", "abed179f-56b3-4cc6-975d-7177f879b97e", "acdc9d28-c847-4614-b133-9a9fe99e7da9", "b8814355-a7a0-4609-a346-e519a3247018", "d2c0bb3b-27f9-4ba0-b5b3-d988a8ec8129", "d696d708-a6fb-49b9-a976-798f858ab380", "d99db833-a31a-4cd4-bee3-c7884687e81c", "d9e4ef07-6d4d-4cf9-8f62-1bc736004bef", "fe68e006-ce24-4ec6-8977-c602a6ef1ac8"], "title": "Deep Learning for Just-in-Time Defect Prediction", "venue": "", "year": 2015, "id": "a6440ff1-5011-4c13-b9d2-1daaee6b3f16"}
{"abstract": "Anytime algorithms offer a tradeoff between solution quality and computation time that has proved useful in solving time-critical problems such as planning and scheduling, belief network evaluation, and information gathering. To exploit this tradeoff, a system must be able to decide when to stop deliberation and act on the currently available solution. This paper analyzes the characteristics of existing techniques for meta-level control of anytime algorithms and develops a new framework for monitoring and control. The new framework handles effectively the uncertainty associated with the algorithm\u2019s performance profile, the uncertainty associated with the domain of operation, and the cost of monitoring progress. The result is an efficient non-myopic solution to the meta-level control problem for anytime algorithms. \uf6d9 2001 Elsevier Science B.V. All rights reserved.", "authors": ["Eric A. Hansen", "Shlomo Zilberstein"], "n_citation": 142, "references": ["02de911e-7f69-4b33-9307-fc08ecba589a", "09ccafac-cb50-4861-bbff-e41181152b25", "0da318aa-c76b-4d3f-b8c2-b6f454ffbaff", "11d0a544-2739-4834-b31f-5fc03647a451", "18843972-ef84-48c2-9d91-b79354d0192c", "1c636635-b408-476f-bbbb-b8c24b52bae8", "3de7b94c-6ad1-49e2-a178-3e993c0e7f71", "4f469e3f-ae61-4c88-bf4c-e2c8aac01f6e", "50675944-207f-4076-b6b8-29e977550a2a", "593f0f5e-7c31-46de-a8d9-e921556af13b", "67c105c8-ff6c-42c0-9c1b-496c8c122ea0", "6dfd8adc-63e4-4963-b693-9508c0480e69", "8a003cdf-fcf1-4f94-adaf-0c1e8004c1a6", "8bb5fc55-b518-41b3-8a2f-df490391c180", "930b21bc-311f-4a40-909b-af88e5161194", "98f32ce5-a223-4ea0-ae5c-eafae780adaf", "9a116e60-b816-413a-a801-b234c3d81a46", "9a6d2245-6faf-438c-b783-b77ddc5050bb", "9c5c5452-549d-4dec-ab02-330c7f13c768", "a18c445e-3ecf-498c-a31b-7e9b98262f0f", "a3693787-db79-42c9-97c0-06d69df5f2f3", "a95ef935-6dfb-42cf-b39c-0f589ee49137", "aeadc7d5-e0c9-4c85-879c-f0043eef443a", "bcd1a06b-e827-4395-ac00-230af8db4cca", "c7d6d3b8-fef4-487f-865d-708b23cfc2ea", "d23ea207-c7e4-4b74-869a-a484872915f7", "defe30a5-6ba2-4b2c-b26c-d64d51f343d8", "e1a6363f-6d29-4ef2-be7d-45b3a69fa9f0", "e81a390b-5a0b-4efd-9ac3-6a5dc7b363cf", "ee4bbc14-80ef-4bb0-9ec8-ce8f7be6d11c"], "title": "Monitoring and control of anytime algorithms: a dynamic programming approach", "venue": "Artificial Intelligence", "year": 2001, "id": "95e1d9ea-cc2c-4f30-84f2-3bcabe09b4fb"}
{"abstract": "We propose a fast and robust method for tracking a user's hand and multiple fingertips; we then demonstrate gesture recognition based on measured fingertip trajectories for augmented desk interface systems. Our tracking method is capable of tracking multiple fingertips in a reliable manner even in a complex background under a dynamically changing lighting condition without any markers. First, based on its geometrical features, the location of each fingertip is located in each input infrared image frame. Then, correspondences of detected fingertips between successive image frames are determined based on a prediction technique. Our gesture recognition system is particularly advantageous for human-computer interaction (HCI) in that users can achieve interactions based on symbolic gestures at the same time that they perform direct manipulation with their own hands and fingers. The effectiveness of our proposed method has been successfully demonstrated via a number of experiments.", "authors": ["Kenji Oka", "Yoichi Sato", "Hideki Koike"], "n_citation": 187, "references": ["0858aa9e-ec11-44af-8c6f-9bb7b26c11da", "1e5f73ab-f049-41bc-89d1-8081818f187d", "43ab6f79-c5f9-4723-8d9c-aab9a96ecaf6", "4eb5af0e-654f-434a-84df-a5e2db569559", "53e11a38-c799-46d1-bf2c-191bc1cb23be", "67cfb6a4-846a-4f7d-9fca-1fc9337663cd", "aa2bb88d-b4f7-4f76-b66e-0dde2ec2b9b6", "e5d8ec50-81db-423a-8a1d-a2b2d7bac2cb", "f498b84a-d0b5-4fed-9061-7beb92fbcd21"], "title": "Real-time tracking of multiple fingertips and gesture recognition for augmented desk interface systems", "venue": "ieee international conference on automatic face and gesture recognition", "year": 2002, "id": "b7835ec1-9390-466b-9862-a155e4b0f37c"}
{"abstract": "While industrial middleware platforms such as CORBA, EJB, or .NET facilitate the development of distributed applications by providing certain infra-structural services required in many distributed systems (such as name services, remote method calls, parameter marshalling, etc.), these industrial platforms fail to support the development of distributed systems with independent components. In particular, their component models do not provide sufficient information for component interoperability checks or automated component adaptation. Especially when considering the personal and institutional separation between component developer and component vendor as one of the prerequisites of an independent component market, finding automatically as many component interoperability errors as possible is crucial. Hence, it is of practical concern that component interfaces not only model the correct way of calling the single methods but also the valid sequences of method calls. Likewise, practice clearly shows that component reuse usually requires component adaptation. This directly shows that only detecting incompatibilities is of limited use, but advocates for techniques of automated component adaptation.In this paper we describe algorithms and tools for specifying and analysing component interfaces in order to check interoperability and to generate adapted component interfaces automatically. Therefore, we introduce the concept of parameterised contracts and a new component interface model.", "authors": ["Ralf H. Reussner"], "n_citation": 56, "references": ["0d261b6a-c94a-4d5e-b44e-eb6ae46581fc", "15453c5e-cdfb-4003-9295-cda10cc8c38d", "16d2d9ba-01bc-499c-9466-f14176c66452", "1735f072-f54a-4cc2-b4ec-bebd4e204e63", "29fb4215-67a2-4edc-9f50-8fdf144480c1", "2bdc36e8-9cf9-408f-9900-aafad36ecd69", "39154096-cc1d-428f-967d-b32baaa209d6", "3b48db0b-0931-48b1-bebe-5ff6ffef1e3d", "3d15988d-d90d-4c7e-ae81-2ca459554aed", "42ea6086-62ba-4bfa-b59c-4e454c848818", "754fdd25-e907-4814-a4e3-a10da1f8f3c0", "8d1688b3-232b-4c48-80f6-d7f5e1b732d8", "9a9402a2-405c-48bd-b06b-82f4fd793546", "ac3d5cbf-62a9-474a-83da-708c9af951ef", "ad9fe868-2c20-49d8-8825-ec4d1d110f48", "c0cfdbcc-3758-4c62-9eac-81b63b9ee6cd", "c86a985c-2896-4e79-a191-4e9a3b7b3a88", "eff9adf0-c70b-42cc-9d6d-47ec62958c23"], "title": "Automatic component protocol adaptation with the CoConut /J tool suite", "venue": "Future Generation Computer Systems", "year": 2003, "id": "c54ea5e8-b0b3-4012-acf3-80be2ccef3cb"}
{"abstract": "The Stanford Microarray Database (SMD) stores raw and normalized data from microarray experiments, and provides web interfaces for researchers to retrieve, analyze and visualize their data. The two immediate goals for SMD are to serve as a storage site for microarray data from ongoing research at Stanford University, and to facilitate the public dissemination of that data once published, or released by the researcher. Of paramount importance is the connection of microarray data with the biological data that pertains to the DNA deposited on the microarray (genes, clones etc.). SMD makes use of many public resources to connect expression information to the relevant biology, including SGD [Ball,C.A., Dolinski,K., Dwight,S.S., Harris,M.A., Issel-Tarver,L., Kasarskis,A., Scafe,C.R., Sherlock,G., Binkley,G., Jin,H. et al. (2000) Nucleic Acids Res., 28, 77\u201380], YPD and WormPD [Costanzo,M.C., Hogan,J.D., Cusick,M.E., Davis,B.P., Fancher,A.M., Hodges,P.E., Kondu,P., Lengieza,C., Lew-Smith,J.E., Lingner,C. et al. (2000) Nucleic Acids Res., 28, 73\u201376], Unigene [Wheeler,D.L., Chappey,C., Lash,A.E., Leipe,D.D., Madden,T.L., Schuler,G.D., Tatusova,T.A. and Rapp,B.A. (2000) Nucleic Acids Res., 28, 10\u201314], dbEST [Boguski,M.S., Lowe,T.M. and Tolstoshev,C.M. (1993) Nature Genet., 4, 332\u2013333] and SWISS-PROT [Bairoch,A. and Apweiler,R. (2000) Nucleic Acids Res., 28, 45\u201348] and can be accessed at http://genome-www.stanford.edu/microarray.", "authors": ["Gavin Sherlock", "Tina Hernandez-Boussard", "Andrew Kasarskis", "Gail Binkley", "John C. Matese", "Selina S. Dwight", "Miroslava Kaloper", "Shuai Weng", "Heng Jin", "Catherine A. Ball", "Michael B. Eisen", "Paul T. Spellman", "Patrick O. Brown", "David Botstein", "J. Michael Cherry"], "n_citation": 544, "references": ["0d8dc04b-7c8d-4c47-9731-f47bcf084c62", "1362085a-5aa8-43c4-afe2-2884d360cf16", "b0ec2286-79de-4abe-b9df-b5e7170a4c36"], "title": "The Stanford Microarray Database", "venue": "Nucleic Acids Research", "year": 2001, "id": "fbf500d5-80ee-4956-9636-6e4bd9e4a746"}
{"abstract": "Evaluation of retrieval performance is a crucial problem in content-based image retrieval (CBIR). Many different methods for measuring the performance of a system have been created and used by researchers. This article discusses the advantages and shortcomings of the performance measures currently used. Problems such as defining a common image database for performance comparisons and a means of getting relevance judgments (or ground truth) for queries are explained. The relationship between CBIR and information retrieval (IR) is made clear, since IR researchers have decades of experience with the evaluation problem. Many of their solutions can be used for CBIR, despite the differences between the fields. Several methods used in text retrieval are explained. Proposals for performance measures and means of developing a standard test suite for CBIR, similar to that used in IR at the annual Text REtrieval Conference (TREC), are presented. (c) Copyright 2001, Elsevier Science, All rights reserved.", "authors": ["Henning M\u00fcller", "Wolfgang Muller", "David Squire", "St\u00e9phane Marchand-Maillet", "Thierry Pun"], "n_citation": 601, "references": ["077e70f1-ccc3-4c13-9752-3b0a182e0890", "1e355d08-af1d-45a1-9b20-9f7ba8c8c9a7", "204e83c6-f9d6-4bbe-8c74-4584f5089fe2", "3122a04e-abb7-4269-ab23-4fba4d2912da", "49d17a56-7f35-46bb-8097-19648e664592", "49e1ef41-0bdd-4f41-b19a-bcd27420f0dd", "61ee16bb-d279-4a22-ab21-463bb86eb01c", "8b61f8c1-e1f2-45dc-98cf-66c2c79814a6", "e5adc7b5-fab7-412b-a348-eee57a6a8b2f"], "title": "Performance evaluation in content-based image retrieval: overview and proposals", "venue": "Pattern Recognition Letters", "year": 2001, "id": "f5d21665-c8d7-4809-9988-45773d529cc5"}
{"abstract": "This paper presents a case study of a machine-aided knowledge discovery process within the general area of drug design. Within drug design, the particular problem of pharmacophore discovery is isolated, and the Inductive Logic Programming (ILP) system progol is applied to the problem of identifying potential pharmacophores for ACE inhibition. The case study reported in this paper supports four general lessons for machine learning and knowledge discovery, as well as more specific lessons for pharmacophore discovery, for Inductive Logic Programming, and for ACE inhibition. The general lessons for machine learning and knowledge discovery are as follows. #R##N##R##N#1. An initial rediscovery step is a useful tool when approaching a new application domain.#R##N##R##N#2. General machine learning heuristics may fail to match the details of an application domain, but it may be possible to successfully apply a heuristic-based algorithm in spite of the mismatch.#R##N##R##N#3. A complete search for all plausible hypotheses can provide useful information to a user, although experimentation may be required to choose between competing hypotheses.#R##N##R##N#4. A declarative knowledge representation facilitates the development and debugging of background knowledge in collaboration with a domain expert, as well as the communication of final results.", "authors": ["Paul W. Finn", "Stephen Muggleton", "David C. Page", "Ashwin Srinivasan"], "n_citation": 155, "references": ["307db816-5b31-4902-b554-29597320719d", "354fa29b-e29d-4d20-b342-3734ead95991", "50e5592d-e449-4b20-b271-6b5a4295ebf7", "64c5f28b-3fb4-4600-9e0b-37f96673f20f", "77e418ff-7124-40e5-a43d-df8357ecfdb6", "95d62e6b-a179-4547-abad-81ac2015348b", "a08362a0-a1ea-4abd-a551-5456bfba9087", "a9734cd4-1a64-4249-8657-8a3e8bf090ec", "bdd72f1c-6df6-4069-bb3a-40a82dfc9065", "fce2dca5-7cf6-4717-817e-df3e6835f6cc"], "title": "Pharmacophore Discovery Using the Inductive Logic Programming System PROGOL", "venue": "Machine Learning", "year": 1998, "id": "6d080b00-1c8a-49d9-bbb6-fe0705f9cb1b"}
{"abstract": "Currently available personal video recorders find and store whole TV programs. Our system, Video Scouting, not only finds and stores programs; it automatically segments and indexes story segments from the programs according to viewers' profiles. The extracted descriptions serve the viewers' content information requests for program segment selection, e.g., play the three minute interview with Hillary Clinton. To achieve this, the system combines information from the audio, visual, and transcript domains in a probabilistic framework based on Bayesian networks. We describe the overall architecture, a system implementation, and discuss some experimental results.", "authors": ["Radu S. Jasinschi", "Nevenka Dimitrova", "Thomas McGee", "Lalitha Agnihotri", "John Zimmerman"], "n_citation": 50, "references": ["23595483-e796-4aa1-ac8e-8eb82cb7611b", "29d76432-9f4f-465e-a51e-013daf097c98", "2f2e9797-fa1e-4090-ae4d-e023977d3b83", "541e494c-a5b5-45b6-868c-56e49f680334", "857795c0-f380-4818-a94a-98ea4dce318b", "9a735cbc-5e09-414a-8453-96b39babc50b", "b8b62b0c-666f-4f2f-9cf5-a6d254c1f6f5", "c7d7ddbb-63e4-47b8-845e-058c14f87ee1", "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706", "db24cbf4-bb4a-40cf-8acb-dbb142640edd", "f7e6e3e3-ed02-4a3e-9bfd-1c40eb29b80f"], "title": "Video scouting: an architecture and system for the integration of multimedia information in personal TV applications", "venue": "international conference on acoustics, speech, and signal processing", "year": 2001, "id": "e889359a-61d1-4ea5-9d49-5dd48346b14f"}
{"abstract": "Ready or not, the digitalization of information has come, and privacy is standing out there, possibly at stake. Although digital privacy is an identified priority in our society, few systematic, effective methodologies exist that deal with privacy threats thoroughly. This paper presents a comprehensive framework to model privacy threats in software-based systems. First, this work provides a systematic methodology to model privacy-specific threats. Analogous to STRIDE, an information flow\u2013oriented model of the system is leveraged to guide the analysis and to provide broad coverage. The methodology instructs the analyst on what issues should be investigated, and where in the model those issues could emerge. This is achieved by (i) defining a list of privacy threat types and (ii) providing the mappings between threat types and the elements in the system model. Second, this work provides an extensive catalog of privacy-specific threat tree patterns that can be used to detail the threat analysis outlined above. Finally, this work provides the means to map the existing privacy-enhancing technologies (PETs) to the identified privacy threats. Therefore, the selection of sound privacy countermeasures is simplified.", "authors": ["Mina Deng", "Kim Wuyts", "Riccardo Scandariato", "Bart Preneel", "Wouter Joosen"], "n_citation": 173, "references": ["018988dd-038e-4c1b-9160-7b661b0ce1a0", "16110fdf-3114-45a5-9445-f91ad9a6a61e", "1dda408f-2203-4793-bfa8-2fab15bce7cf", "1ebfb75a-8a4d-4999-8d19-d4597f50b76e", "2930a0b7-3bf1-4a9a-bec6-ae1b6264d839", "2d3db27a-0b3e-40dc-93cd-5d47d457b39f", "2dca725e-cd2f-4b68-9198-a528781fd7aa", "309de70c-a850-4b0a-830b-a05739ea66d9", "343feed7-8960-4a3d-ba6d-02908dbe4424", "3444112c-0ec1-4b85-b44a-ed0658bfed06", "4958ccd2-12ad-4933-9eb5-5ce255caa3b6", "4e4837d8-3f23-4727-85a0-ebf14e0e39e2", "52ed6f62-9f4b-4838-b4eb-6387b2d389cf", "57b833dd-b964-4ed7-9e33-9ed8a3eb8208", "60623818-25d9-46a9-875d-f2b6d6585faf", "66205b98-2185-49ac-baff-ee3f5aa5cf61", "755c734d-6e65-470d-b9bd-0b4b3422bfe4", "79d7906b-9f42-40f8-98e9-503b11ceb112", "7e38eeca-8c7e-4235-9cf2-6d8ced5d00da", "8116fd9d-cf2b-4bbc-90fa-9847b9071397", "819e971b-4ff6-4d49-a3b4-9f02c476358e", "81c8fa5e-3b06-47e3-a12c-e02e5a298fa1", "8407778d-e0dc-4ba3-a91f-1bc7dac81690", "91161876-afb1-4556-8f32-19b8d447c3d4", "a64594fa-8c15-4d2c-aba2-d42878495f64", "a7656926-7e18-40b8-920b-71109a3357de", "a9063dcd-0aca-4638-bfd9-07736f02fb77", "b3ae400d-e6f1-4020-9d61-85053ee67f38", "b4cddcd7-f788-44b5-96c7-6a854d5c0711", "b68fc787-7817-421e-8e66-8a98ab9db1ad", "ca197e9d-4565-46e9-b55f-e50785747459", "d09a3839-bf14-4c33-b3d1-7097f31403b3", "d3b0635e-5447-435d-9975-a2582d19fc37", "d63dd4ae-4b30-484b-8ffc-88d21839ddad", "da6d70f6-ebcf-494e-bb08-b3c0f1738094", "dcd41f70-c632-4e61-b6f4-da351c5b8612", "e39a8b06-84a8-44d7-b8f9-a95ce7aa8710", "e59cac72-57b1-4b83-9ff7-287bf10fdf28", "eaec322a-ac36-4973-bdcd-d297466b9049", "f0eccc1a-c829-425d-a661-765c3fa2088a", "f54c4191-a196-46e6-bd22-db38ba68e0d3", "fa4a69b9-cdbb-47e7-8868-8f6ef24b23f1"], "title": "A privacy threat analysis framework: supporting the elicitation and fulfillment of privacy requirements", "venue": "Requirements Engineering", "year": 2011, "id": "45fbda21-7eaa-452b-9422-19bcc50f9b73"}
{"abstract": "Data clustering is a popular approach for automatically finding classes, concepts, or groups of patterns. In practice, this discovery process should avoid redundancies with existing knowledge about class structures or groupings, and reveal novel, previously unknown aspects of the data. In order to deal with this problem, we present an extension of the information bottleneck framework, called coordinated conditional information bottleneck, which takes negative relevance information into account by maximizing a conditional mutual information score subject to constraints. Algorithmically, one can apply an alternating optimization scheme that can be used in conjunction with different types of numeric and non-numeric attributes. We present experimental results for applications in text mining and computer vision.", "authors": ["David Gondek", "Thomas Hofmann"], "n_citation": 125, "references": ["045de08a-a1ef-416e-8e6a-9227f402e2a3", "0500ddbe-e274-477b-bb6b-54a7269e4577", "0886e18d-4d6d-489b-81a0-f4cf362a1f22", "15c30ca5-6af6-4acf-b8c5-f2c0e18e6ad8", "42f811cb-51e9-4041-acd4-7e1aae06f40c", "47f728b9-85b0-44c4-ab88-b46eb3b88d4d", "4880e88e-c3c0-48a3-a240-318311335502", "5af5a87e-9360-4dd6-bde1-0aae7d9d1ab0", "8b983be4-398a-4a23-818c-64dd281ab4d8", "9d074996-b71b-4ec9-9be9-2b63d2b62158", "e720ae55-5e05-419c-a587-32cc875001f6", "ee746464-b6d4-47c6-afbb-8b8e0faa0bcd"], "title": "Non-redundant data clustering", "venue": "international conference on data mining", "year": 2004, "id": "143a6919-c595-41fe-b803-a5ed1708b061"}
{"abstract": "Text entry becomes increasingly complex as devices shrink in size. This paper presents the findings of a comparison study of two thumbwheel text entry methods for mobile devices. In the first method, the character set (letters, numbers, punctuation) was implemented as a continuous loop. In the second method, characters were arranged in a two-level menu structure. Thumbwheel methods provide a viable and realistic alternative to keyboard, keypad, stylus, or voice text entry on ultra-small mobile devices.", "authors": ["Peter Tarasewich"], "n_citation": 50, "references": ["00b44e0f-1667-4f55-9497-376ba71149d1", "69ccd939-3f96-4e16-b35d-38430063de5e", "907a8ba8-09a0-48c6-9bda-626d32c70f74"], "title": "Evaluation of thumbwheel text entry methods", "venue": "human factors in computing systems", "year": 2003, "id": "b39cea38-052f-436a-a70a-bed39dcb2252"}
{"abstract": "We consider, in this paper, the problem of knowledge base merging with integrity constraints. We propose a logical characterization of those operators and give a representation theorem in terms of preorders on interpretations. We show the close connection between belief revision and merging operators and we show that our proposal extends the pure merging case (i.e. without integrity constraints) we study in a previous work. Finally we show that Liberatore and Schaerf commutative revision operators can be seen as a special case of merging.", "authors": ["S\u00e9bastien Konieczny", "Ram\u00f3n Pino P\u00e9rez"], "n_citation": 164, "references": ["5535c761-0dc4-4ed4-a58c-b18e5546ca13", "5d1761c0-d046-46fd-a3ee-45919b7d523b", "5d52debd-d39c-424e-949d-0409ac461a96", "78ece605-27ee-4575-b5a6-786ee699a4b9", "82d7ab9b-f6a0-49c7-9ff7-e3e2a42cee14", "8ccc2745-645e-4a4f-9011-dfe5fedfb16f", "aa7543f0-6bd4-451c-9a1b-bac6d06e2048", "b3a6f742-8207-4274-b7d6-cdbefa3e8938", "da2f5ed4-2fa7-43d0-8c47-9d55079789ce"], "title": "Merging with Integrity Constraints", "venue": "european conference on symbolic and quantitative approaches to reasoning and uncertainty", "year": 1999, "id": "19f03043-d536-4801-8b67-b7445175091c"}
{"abstract": "This document describes an industrial application of the B method in smart card applications. In smart card memory, data modification may be interrupted due to a card withdrawal or a power loss. The EEPROM memory may result in an unstable state and the values subsequently read may be erroneous. The transaction mechanism provides a secure means for modifying data located in the EEPROM. As the security in smart card applications is paramount, the use of the B formal method brings high confidence and provides mathematical proof that the design of the transaction mechanism fulfills the security requirements.", "authors": ["Denis Sabatier", "Pierre Lartigue"], "n_citation": 50, "references": ["3b51997d-b242-42da-9398-912a4818d14f"], "title": "The Use of the B Formal Method for the Design and the Validation of the Transaction Mechanism for Smart Card Applications", "venue": "formal methods", "year": 2000, "id": "45b672d9-35ec-42f4-8c96-7e3adbfa13bb"}
{"abstract": "SMIng (next generation structure of management information), an information model for network management, is a prospective structure of management information. When deploying the multi-agent systems to network management environments, we have established a lightweight self-contained knowledge model based on RDF (resource description framework) and its extensions. We also present an implementation prototype to support agent communication and coordination by RDF-based languages.", "authors": ["Jun Shen", "Yun Yang"], "n_citation": 50, "references": ["09612bfc-785a-4524-b05c-280bf91350a9", "855b93cf-8e72-4c02-b449-b7ef97508e2f", "9d4843e6-123f-4718-9019-604a3d2fd120", "d6bc6c9b-8851-432c-8341-69c8c6448010", "d9c7cc6d-0067-4dae-848b-fcbe35b4aec9"], "title": "RDF-based knowledge models for network management", "venue": "integrated network management", "year": 2003, "id": "fed9d094-24ce-4bce-9f4b-017a295cb7f0"}
{"authors": ["S.D. Conte", "Ralph T. Dames"], "n_citation": 50, "references": [], "title": "On an Alternating Direction Method for Solving the Plate Problem with Mixed Boundary Conditions", "venue": "Journal of the ACM", "year": 1960, "id": "9230ff69-cd97-4010-b67e-c05ca81cdf0c"}
{"abstract": "Discrete event simulation is widely used within the networking community for purposes such as demonstrating the validity of network protocols and architectures. Depending on the level of detail modeled within the simulation, the running time and memory requirements can be excessive. The goal of our research is to develop and demonstrate a practical, scalable approach to parallel and distributed simulation that will enable widespread reuse of sequential network simulation models and software. We focus on an approach to parallelization where an existing network simulator is used to build models of subnetworks that are composed to create simulations of larger networks. Changes to the original simulator care minimized, enabling the parallel simulator to easily track enhancements to the sequential version. We describe our lessons learned in applying this approach to the publicly available ns software package (McCanne and Floyd, 1997) and converting it to run in a parallel fashion on a network of workstations. This activity highlights a number of important problems, from the standpoint of how to parallelize an existing serial simulation model and achieving acceptable parallel performance.", "authors": ["George F. Riley", "Richard M. Fujimoto", "Mostafa H. Ammar"], "n_citation": 202, "references": ["0dd1ba3d-19fc-44c4-ab3f-c446ff7ff157", "31ad8e55-4979-4bc6-a432-4536da96a4d4", "47def082-662d-4a14-902d-d59d4ef48767", "7b54861c-fb80-485a-a87f-ce3c5e088b38", "7f64b879-c8e6-4ce7-920e-cc11f6617b33", "87d6ab9e-770a-4f76-a5d3-47eccfd51428", "99e3feaa-0b72-4f76-9188-22755d30dff9", "a52bb19b-7303-4df8-9445-677cf6821ec8", "f4ea1c5a-917a-4632-b2bf-7c5a074534b5", "fafbec67-aeb1-462a-abbd-7520fc854f41"], "title": "A generic framework for parallelization of network simulations", "venue": "modeling analysis and simulation on computer and telecommunication systems", "year": 1999, "id": "b4f5fbee-8c71-41fa-8e5e-2b3bff6559a6"}
{"abstract": "We present an architecture and prototype implementation of a performance management system for cluster-based Web services. The system supports multiple classes of Web services traffic and allocates server resources dynamically so to maximize the expected value of a given cluster utility function in the face of fluctuating loads. The cluster utility is a function of the performance delivered to the various classes, and this leads to Differentiated Service. In this paper we use the average response time as the performance metric. The management system is transparent: it requires no changes in the client code, the server code, or the network interface between them. The system performs three performance management tasks: resource allocation, load balancing, and server overload protection. We use two nested levels of management mechanism. The inner level centers on queuing and scheduling of request messages. The outer level is a feedback control loop that periodically adjusts the scheduling weights and server allocations of the inner level. The feedback controller is based on an approximate first-principles model of the system, with parameters derived from continuous monitoring. We focus on SOAP-based Web services. We report experimental results that show the dynamic behavior of the system.", "authors": ["Ran Levy", "Jay Nagarajarao", "Giovanni Pacifici", "A. Spreitzer", "Asser N. Tantawi", "Alaa Youssef"], "n_citation": 169, "references": ["03e48c76-c9f4-4b7a-8e70-99a424e9a55b", "05248914-6606-4de6-9a1d-e9170a332a8f", "0cbb7775-8d9e-4b8a-9671-f62485239aec", "19072242-e914-409a-b1df-45ce926c1167", "1ffb9f60-f6be-411b-98ce-acfc4d13c457", "21cda88a-6d15-44e4-aae3-f422eb67b39e", "3eecd34f-f9b3-458b-a2c4-582418ac0759", "4aaa4916-ca14-4284-ae78-93bc49bc6c49", "5ce1bd40-63c7-4390-aa73-a59c21fac78d", "8fd6531b-c809-4e63-895b-fb91be11759d", "92f6ca5c-edb1-4385-9122-d5d47d0aea04", "9cdc8581-c722-4656-8df0-455afe76bd41", "c85dbe29-2e77-45d0-83fa-3e3a81c5f2d3", "e49e1d41-99eb-41f7-971b-d9c2544198ed"], "title": "Performance management for cluster based Web services", "venue": "integrated network management", "year": 2003, "id": "4629535f-86f2-43ca-910d-fac47448ae67"}
{"abstract": "We have developed a methodology for studying and analyzing the psychology of users performing ecologically valid WWW tasks.  A user trace  is a record of all significant states and events in the user-WWW interaction based on eye tracking data, application-level logs, and think-aloud protocols.  A user-tracing architecture  has been implemented for developing simulation models of user-WWW interaction and for comparing a simulation model (SNIF-ACT) against user-trace data. The user tracing architecture compares each action of the SNIF-ACT simulation directly against observed user actions. The model and architecture have been used to successfully match detailed user trace data from four users working on two tasks each.", "authors": ["Peter Pirolli", "Wai-Tat Fu", "Robert W. Reeder", "Stuart K. Card"], "n_citation": 37, "references": ["0bf10ae2-e3e6-4f0d-b223-c196bbfe44a3", "278f1d79-321b-4fb2-a53b-821581afdf82", "29010e7e-e4b2-4e26-89ff-e88d49c459a5", "5c15dbd7-e413-4e67-bba2-88639fb0fa5f", "5e91f696-a438-4c37-ab99-3ea30d2c4d24", "83c584f6-27a0-4965-8391-d5816da3e060", "88fcb30a-92a1-4906-8115-83a38364fa83", "a705e403-32fe-409e-9b89-71095c073bd1", "b8a11e3d-e329-43b4-8713-64707ad7a957", "bd9522f5-5922-47fa-bee1-e0df6e7ff4c6", "ddc04b78-5ad1-459d-b57c-09d9363826fb", "df1a0d04-0e77-4546-92e8-19e23c91847e", "df90477f-3da7-4abc-96f2-3769b7d6fb29", "e33a3e2f-532e-4147-8852-c95022365b75", "e6a04f3a-9b5d-4356-b389-784f71a2b59b", "fcc28285-92e3-4dfb-943e-e92e552ead31"], "title": "A user-tracing architecture for modeling interaction with the world wide web", "venue": "advanced visual interfaces", "year": 2002, "id": "b08bc91a-c57a-4c94-b2e8-ca98fbfcfbc2"}
{"abstract": "With an increasing emphasis on security, automated personal identification based on biometrics has been receiving extensive attention over the past decade. Iris recognition, as an emerging biometric recognition approach, is becoming a very active topic in both research and practical applications. In general, a typical iris recognition system includes iris imaging, iris liveness detection, and recognition. This paper focuses on the last issue and describes a new scheme for iris recognition from an image sequence. We first assess the quality of each image in the input sequence and select a clear iris image from such a sequence for subsequent recognition. A bank of spatial filters, whose kernels are suitable for iris recognition, is then used to capture local characteristics of the iris so as to produce discriminating texture features. Experimental results show that the proposed method has an encouraging performance. In particular, a comparative study of existing methods for iris recognition is conducted on an iris image database including 2,255 sequences from 213 subjects. Conclusions based on such a comparison using a nonparametric statistical method (the bootstrap) provide useful information for further research.", "authors": ["Li Ma", "Tieniu Tan", "Yunhong Wang", "Dexin Zhang"], "n_citation": 1211, "references": ["03048c5b-2f45-4d9a-8f8f-716f8ea669da", "180dea34-18e8-411d-932f-94e714651ac7", "1b333d89-cea7-4962-8284-b8d82d0abc01", "237496dc-8258-4b83-a9e4-78670d55cf8c", "2d31d7a2-01f5-44dd-aaa0-56343850e876", "2fd01f05-99c6-4dcf-b664-b7336b1a16e8", "3e259f16-b05f-442e-a7d7-30c581e580d0", "432c2bf3-2dfe-458d-95c5-bf3c1332c3f7", "48f7195e-8d1b-4a27-8ace-f32dfdb07cf5", "56f4b72a-ec39-47ac-8220-899296e7fb18", "818c1993-382d-4945-9a04-92156823efd7", "8f7e8a36-6f7e-420f-8ab9-9f597fe9e8a9", "912aabff-def4-4026-9eb9-9d04cb8fabb1", "a9bb6699-7513-414c-b9b8-d68eaeeb0299", "ea12798a-feaf-4f04-b494-7834146f613a", "f665b92e-2337-4f41-9fdc-e0cdfd4a12de"], "title": "Personal identification based on iris texture analysis", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 2003, "id": "56eac37d-41e8-4207-a502-1d70fd53e1ae"}
{"abstract": "Many non-speaking people use augmentative and alternative communication (AAC) systems to assist them to communicate with other people. Access to an AAC system is generally slow for its user, who may have other disabilities as well as being non-speaking. An AAC system can contain stored words, messages and stories for use in communication, and there can be a large quantity of such information for the user to search through and select from while he or she is trying to participate in conversation. New user interface techniques are required to assist a user to navigate through the information stored in an AAC system and select appropriate items for use during live conversation. Information visualisation techniques may be able to assist a user to overview and appraise the contents of an AAC system as part of that selection process, and therefore improve its efficiency of use. This paper outlines key AAC issues and explores visualisation techniques which may be of value in an AAC context.", "authors": ["Andrew Taylor", "John L. Arnott", "Norman Alm"], "n_citation": 50, "references": ["0e4f9d53-2005-4cf4-a631-cb96b50d988c", "3e7b8f15-19a4-4057-b962-03c80b5680fe", "5c4022aa-8675-46e7-8378-532afcf034f0", "745c9496-1a39-40d2-bf52-ca5497b5b780", "82d26ac1-2ae2-40a4-ac8e-00f5296a6c6d", "961612d3-e9af-4511-b584-1acbd05d6030", "979e23d0-bc5d-444f-8c89-33d3b998f9fd", "c2f70dcd-36aa-4b47-ba00-8ba1f63f2983", "f47e05fb-6c14-480f-ad0c-f09c9cb66489"], "title": "Visualisation to assist non-speaking users of augmentative communication systems", "venue": "", "year": 2001, "id": "77a7fe18-6bc6-4c5f-bdb9-26df4c7aab64"}
{"abstract": "We present an algorithm to learn human arm motion from demonstrations and infer the goal location (intention) of human reaching actions. To capture the complexity of human arm reaching motion, an artificial neural network (ANN) is used to represent the arm motion dynamics. The trajectories of the arm motion for reaching operation are modeled as stable dynamic systems with contracting behavior towards the goal location. The ANN is trained subjected to contraction analysis constraints. To adapt the motion model learned from a few demonstrations to novel scenarios or multiple objects, we use an interacting multiple model framework. The multiple models are obtained by translating the origin of the contracting system to different known goal locations. The posterior probabilities of the models are calculated through interactive model matched filtering carried out using extended Kalman filters (EKFs). The correct model is chosen according to the posterior probabilities to infer the correct intention. Demonstrations and measurements are recorded using a Microsoft Kinect sensor and experimental results are presented to validate the proposed algorithm.", "authors": ["Harish Chaandar Ravichandar", "Ashwin P. Dani"], "n_citation": 2, "references": ["043ade78-d8f1-48d4-9bd1-dbd5d530b7eb", "09a70c0a-0d40-4959-b108-192c5e5b6c76", "2ec61fdf-a5f6-4c99-8475-94ff006d446c", "3252ed17-b07d-4b36-8155-145afaa07d6f", "3399c14b-637b-4cf4-9caf-3cc4dc6e384d", "38284573-df44-4976-a1f4-74e21252fbb7", "5f896632-2873-45a7-8037-82d688f3b791", "692a7e8d-71a9-4a18-9391-3ad5f9d2a7cb", "702c31eb-46c4-4097-874f-ab524a9009e4", "83269965-ffdd-48a4-b8e6-f36c0b1dcec2", "96076ca3-5d34-4487-b884-37eb0271132b", "a23aecce-7fb6-48c1-beb8-1990c83b8cf5", "a5ddc149-4378-4c73-a97d-1b0eea0db1bd"], "title": "Human intention inference through interacting multiple model filtering", "venue": "", "year": 2015, "id": "e530c55e-eb9c-44da-82a7-57738ae08eb6"}
{"abstract": "A traceability scheme is a broadcast encryption scheme such that a data supplier T can trace malicious authorized users (traitors) who gave a decryption key to an unauthorized user (pirate). This paper first derives lower bounds on the sizes of keys and ciphertexts. These bounds are all tight because an optimum one-time use scheme is also presented. We then propose a multiple-use scheme which approximately meets our bounds. This scheme is proven to be secure as well as much more efficient than the schemes by Chor, Fiat and Naor. Finally, practical types of asymmetric schemes with arbiter are discussed in which T cannot frame any authorized user as a traitor.", "authors": ["Kaoru Kurosawa", "Yvo Desmedt"], "n_citation": 200, "references": ["036293cd-4a5d-4590-94ed-39f2d1d7df33", "0feb6083-1e7a-49c5-8b05-c087a2dfddfa", "20b1e7ee-f931-4278-8785-a3fa777f09c7", "4acdcd3d-4852-41ee-9fa7-bce554f90eb5", "cd631029-0e97-4ddd-8ec6-c9438d83b13d", "dbae394b-375c-41a0-b6e4-f6c673c4612e", "e6b85e11-ae21-4fed-be92-c1676fba1b3e"], "title": "Optimum traitor tracing and asymmetric schemes", "venue": "theory and application of cryptographic techniques", "year": 1998, "id": "e3ff3200-ad93-4546-96f9-f65da03a528c"}
{"abstract": "We consider systems of equations of the form Xi= \u03b1\u00b7Fi,a\u222a\u03b4i i=1,\u2026,n where A is the underlying alphabet, the Xi are variables, the Pi,a are boolean functions in the variables Xi, and each \u03b4i is either the empty word or the empty set. The symbols \u03c5 and \u222a denote concatenation and union of languages over A. We show that any such system has a unique solution which, moreover, is regular. These equations correspond to a type of automation, called boolean automation, which is a generalization of a nondeterministic automation. The equations are then used to determine the language accepted by a sequential network; they are obtainable directly from the network.", "authors": ["Janusz Brzozowski", "Ernst L. Leiss"], "n_citation": 182, "references": ["79821a8e-cf7f-42c9-a272-a99b1c41f558", "7f51f520-7bfa-4faf-8ceb-f5ba1324547f"], "title": "On equations for regular languages, finite automata, and sequential networks\u2606", "venue": "Theoretical Computer Science", "year": 1980, "id": "179851f4-98b5-4a80-a77f-5feb54e89812"}
{"abstract": "Given the joint feature-label distribution, increasing the number of features always results in decreased classification error; however, this is not the case when a classifier is designed via a classification rule from sample data. Typically, for fixed sample size, the error of a designed classifier decreases and then increases as the number of features grows. The problem is especially acute when sample sizes are very small and the potential number of features is very large. To obtain a general understanding of the kinds of feature-set sizes that provide good performance for a particular classification rule, performance must be evaluated based on accurate error estimation, and hence a model-based setting for optimizing the number of features is needed. This paper treats quadratic discriminant analysis (QDA) in the case of unequal covariance matrices. For two normal class-conditional distributions, the QDA classifier is determined according to a discriminant. The standard plug-in rule estimates the discriminant from a feature-label sample to obtain an estimate of the discriminant by replacing the means and covariance matrices by their respective sample means and sample covariance matrices. The unbiasedness of these estimators assures good estimation for large samples, but not for small samples. Our goal is to find an essentially analytic method to produce an error curve as a function of the number of features so that the curve can be minimized to determine an optimal number of features. We use a normal approximation to the distribution of the estimated discriminant. Since the mean and variance of the estimated discriminant will be exact, these provide insight into how the covariance matrices affect the optimal number of features. We derive the mean and variance of the estimated discriminant and compare feature-size optimization using the normal approximation to the estimated discriminant with optimization obtained by simulating the true distribution of the estimated discriminant. Optimization via the normal approximation to the estimated discriminant provides huge computational savings in comparison to optimization via simulation of the true distribution. Feature-size optimization via the normal approximation is very accurate when the covariance matrices differ modestly. The optimal number of features based on the normal approximation will exceed the actual optimal number when there is large disagreement between the covariance matrices; however, this difference is not important because the true misclassification error using the number of features obtained from the normal approximation and the number obtained from the true distribution differ only slightly, even for significantly different covariance matrices.", "authors": ["Jianping Hua", "Zixiang Xiong", "Edward R. Dougherty"], "n_citation": 50, "references": ["1570e0c2-bcf6-4f5a-92db-d1b0936d68d3", "3116efe2-cb74-4250-95d5-014b01fe1c8a", "470e66b0-4aa8-48ad-bd3d-f2adcf06dfa8", "4be27794-9327-4ad0-8ce9-cd349ef2bccf", "7a2d1bce-9275-4b3b-9ad7-542af7571618", "7e2fceff-0865-4bf9-86d7-3aa32aaf8f9b", "8d0419f0-7b5b-4765-839d-259b8063a6b3", "ab5018cb-1699-434e-858a-a533c0718f2a", "b1067825-8ba0-4b93-be2d-393b00193430", "ddc85076-d37f-45f7-9240-be7ef55f1c82"], "title": "Determination of the optimal number of features for quadratic discriminant analysis via the normal approximation to the discriminant distribution", "venue": "Pattern Recognition", "year": 2005, "id": "f884a67f-d0a9-491c-a5bc-bb01db832c28"}
{"abstract": "We develop a theory of online learning by defining several complexity measures. Among them are analogues of Rademacher complexity, covering numbers and fat-shattering dimension from statistical learning theory. Relationship among these complexity measures, their connection to online learning, and tools for bounding them are provided. We apply these results to various learning problems. We provide a complete characterization of online learnability in the supervised setting.", "authors": ["Alexander Rakhlin", "Karthik Sridharan", "Ambuj Tewari"], "n_citation": 76, "references": ["0f46310b-455f-4f97-9bb4-182962c0d619", "111ab1e1-cd3c-442a-8923-86e548c4324a", "69290a10-a7e0-4985-92e2-44eee6f57813", "6fe13464-786c-4668-8c16-5b0461042e78", "852f5db4-ae3f-4fb2-9892-75348a62063c", "95da7f42-613f-4847-afa8-da9de488bd8f", "9660266a-9902-48aa-a8e9-3550dd110df7", "99fa0b6e-7442-4ab7-be48-efdecc423894", "a3acccbb-3055-40d0-9f38-f85b39cac63a", "a4c0df3c-621d-4978-b93e-b8e8e0a748df", "ac5715dc-05ba-45b6-873d-b06316a7bfd3", "b1ab16c4-7c50-4dfd-90e6-82a9fb00b262", "b4c9e90b-a802-4797-a3a5-658e4b7dcd65", "baabcffe-cedb-4a58-9592-1d4b3651e1f9", "bc811988-0949-4be1-96f8-08770ec5ca1c", "d82055ec-2c02-4997-b5ff-ddfdc63b3cac", "ea98bd3b-fe01-4584-b5bc-4b7eacf78d47"], "title": "Online Learning: Random Averages, Combinatorial Parameters, and Learnability", "venue": "neural information processing systems", "year": 2010, "id": "5605a792-e853-4b08-b328-ca0be913ac14"}
{"authors": ["William J. Knottenbelt"], "n_citation": 67, "title": "Parallel performance analysis of large markov models", "venue": "", "year": 1999, "id": "51b64ca6-7d87-4f9f-aaf1-6158fc19cff9"}
{"abstract": "In grid workflow systems, a checkpoint selection strategy is responsible for selecting checkpoints for conducting temporal verification at the runtime execution stage. Existing representative checkpoint selection strategies often select some unnecessary checkpoints and omit some necessary ones because they cannot adapt to the dynamics and uncertainty of runtime activity completion duration. In this article, based on the dynamics and uncertainty of runtime activity completion duration, we develop a novel checkpoint selection strategy that can adaptively select not only necessary, but also sufficient checkpoints. Specifically, we introduce a new concept of minimum time redundancy as a key reference parameter for checkpoint selection. An important feature of minimum time redundancy is that it can adapt to the dynamics and uncertainty of runtime activity completion duration. We develop a method on how to achieve minimum time redundancy dynamically along grid workflow execution and investigate its relationships with temporal consistency. Based on the method and the relationships, we present our strategy and rigorously prove its necessity and sufficiency. The simulation evaluation further demonstrates experimentally such necessity and sufficiency and its significant improvement on checkpoint selection over other representative strategies.", "authors": ["Jinjun Chen", "Yun Yang"], "n_citation": 95, "references": ["020e47f2-7841-4ca9-8ae8-b83431f23be7", "04873255-0ba1-40bd-b7f3-a34340fcc421", "059b04ac-34ba-4e51-a53d-73322af8cdce", "0b019a74-a404-45be-b278-62493a6232bd", "16dcf513-570f-4cc7-9d04-e2b59efe2ebf", "26fd2152-9c05-461b-840f-2fc144c63751", "3dc961ba-08ef-4a42-aeff-324096d39c17", "451da5b0-f4f4-46f9-b7aa-2de6b71c9785", "4730cf22-f153-43e3-bf74-cbb71f426e32", "4e93125b-fc47-407e-969b-8e5d87a497d2", "4f64e8a6-f9d8-4a10-ac03-000c235c09a6", "56db95e5-3355-423f-9a47-29dc76c003a2", "609f9104-a903-4577-a37c-842211042aba", "68eb3d4a-ecb1-4309-89f8-d1a3b45a7dae", "6dfd93d8-aad5-412b-a1ae-5a0f94f1369e", "73d1c680-7a5e-4183-9f4c-53354dc63285", "7c193ac5-268f-44b9-8833-d9284943e96f", "7dbc52ed-0e31-4098-beff-fd7649446cf4", "8554bc31-1ac8-4630-b47e-9547d1311f01", "8d9625ab-00ea-4cdc-ad84-75c9942abc17", "a05644e8-7aa8-4062-8f1e-1ba7ca1c2bad", "a12ecc4c-4295-4ffe-8dfe-62286023fdb2", "a7b94d0d-00ac-4cf2-931d-f830755f38a4", "b5e33dc5-3f87-46ff-b35e-488a24eb5b28", "b673f8ce-a097-471b-b404-5223da0cf152", "c258f3eb-0303-4497-a185-71efaeb4bf24", "d3107ff3-c3ac-481c-a3ed-f367d2b6b1d9", "d4c79362-056c-40b5-85ff-d8d821ff8d59", "eeb4de8e-1188-473f-8b7e-311f63afcdb3"], "title": "Adaptive selection of necessary and sufficient checkpoints for dynamic verification of temporal constraints in grid workflow systems", "venue": "ACM Transactions on Autonomous and Adaptive Systems", "year": 2007, "id": "628aabc8-cd49-49ec-83f0-ceb6743de657"}
{"abstract": "The rapid prototyping of complex systems embedded in even more complex environments raises the need for a multi-level design approach. Our example is taken from mechatronic design in the automotive industry and illustrates the rapid prototyping procedure of real-time critical control laws. Our approach is based on an object-oriented structuring, not only allowing central control units but also supporting distributed control units, as needed in today's designs. The implementation of control laws is a stepwise-refined hardware-in-the-loop simulation, reducing the simulation part in each step. At the lower level, common platforms (such as FPGAs, microcontrollers or specialized platforms) can be instantiated. This is illustrated by an asynchronous data-flow processor for the high-performance rapid prototyping of cyclic iterated control laws.", "authors": ["Markus Deppe", "Michael Robrecht", "Mauro Cesar Zanella", "Wolfram Hardt"], "n_citation": 50, "references": ["0cadd91f-cea9-4144-92e2-63c674bc45f4", "dbcefb9d-54b4-4eb5-bef9-12c798fb174a"], "title": "Rapid prototyping of real-time control laws for complex mechatronic systems", "venue": "rapid system prototyping", "year": 2001, "id": "4de9b7aa-3a5b-4378-b45e-77d6c4c89449"}
{"abstract": "In this paper a property of the multi-agent consensus dynamics that relates the failure of links in the network to jump discontinuities in the derivatives of the output responses of the nodes is derived and verified analytically. At the next step, an algorithm for sensor placement is proposed, which would enable the designer to detect and isolate any link failures across the network based on the observed jump discontinuities in the derivatives of the responses of a subset of nodes. These results are explained through elaborative examples.", "authors": ["M. Amin Rahimian", "Victor M. Preciado"], "n_citation": 50, "references": ["3760c62c-bea4-48c1-a06e-d88ae8e48ea2", "4bc4d8c4-081c-49c7-8cdb-d5ba99489d26", "98e67229-36db-4902-af27-db2195f85f57", "afc7a816-3787-4290-999e-d7f867510400", "ced899b7-2334-4f0c-9432-b6c4e791f96c", "cf2c84d7-07b2-4723-82be-ada94c715808", "d3b2bbd7-cfd8-4ed2-a90b-0d5ddfda86e0", "dced6fb4-eee7-4db0-a1f6-75a6bad7ce7b"], "title": "Detection and isolation of link failures under the agreement protocol", "venue": "conference on decision and control", "year": 2013, "id": "62915a04-1257-46b3-ba63-ce5d9508a2e4"}
{"abstract": "This paper studies properties of homogeneous systems in a geometric, coordinate-free setting. A key contribution of this paper is a result relating regularity properties of a homogeneous function to its degree of homogeneity and the local behavior of the dilation near the origin. This result makes it possible to extend previous results on homogeneous systems to the geometric framework. As an application of our results, we consider finite-time stability of homogeneous systems. The main result that links homogeneity and finite-time stability is that a homogeneous system is finite-time stable if and only if it is asymptotically stable and has a negative degree of homogeneity. We also show that the assumption of homogeneity leads to stronger properties for finite-time stable systems.", "authors": ["Sanjay P. Bhat", "Dennis S. Bernstein"], "n_citation": 581, "references": ["31242b09-38f2-4e83-8a9e-e2e9c7f8098d", "8efffaa2-6401-4a06-8b96-f2cfa21086c4", "e91ae912-e71e-460d-a4c0-8e0d70599721", "f892f421-ce65-4496-aab2-986be87547fd"], "title": "Geometric homogeneity with applications to finite-time stability", "venue": "Mathematics of Control, Signals, and Systems", "year": 2005, "id": "c4f5cf9c-3945-4f53-83d6-711b16e23f3b"}
{"abstract": "We propose a new randomized method for solving global optimization problems. This method, the Nested Partitions (NP) method, systematically partitions the feasible region and concentrates the search in regions that are the most promising. The most promising region is selected in each iteration based on information obtained from random sampling of the entire feasible region and local search. The method hence combines global and local search. We first develop the method for discrete problems and then show that the method can be extended to continuous global optimization. The method is shown to converge with probability one to a global optimum in finite time. In addition, we provide bounds on the expected number of iterations required for convergence, and we suggest two stopping criteria. Numerical examples are also presented to demonstrate the effectiveness of the method.", "authors": ["Leyuan Shi", "Sigurdur Olafsson"], "n_citation": 407, "references": ["08f08859-b362-4a97-bf86-8264dfae372b", "1fc78ab7-fe19-49be-af29-22f9c049bc07", "5b97ed33-5be9-44f4-a4d6-550fead26775", "5e56873e-d84c-476c-9083-1e0f52bc9527", "67d9280d-d221-45bb-b944-5feca2b6256f", "7e11240d-fbd8-42aa-a17d-fa8d9c89077f", "9382bc59-5597-40c6-b238-50006929b3a3", "d4bd508d-160b-4018-91c9-b17c8fbc9f7d", "fe903cbc-02d7-47c8-8d10-c7c5f5d89ee9"], "title": "Nested Partitions Method for Global Optimization", "venue": "Operations Research", "year": 2000, "id": "edbbab76-1a81-4418-81f4-fdf676e7e071"}
{"abstract": "This article presents the octagon abstract domain, a relational numerical abstract domain for static analysis by abstract interpretation. It allows representing conjunctions of constraints of the form \u00b1 X \u00b1 Y ? c where X and Y range among program variables and c is a constant in ?, ?, or ? automatically inferred. Abstract elements are represented using modified Difference Bound Matrices and we use a normalization algorithm loosely based on the shortest-path closure to compute canonical representations and construct best-precision abstract transfer functions. We achieve a quadratic memory cost per abstract element and a cubic worst-case time cost per abstract operation, with respect to the number of program variables.#R##N##R##N#In terms of cost and precision, our domain is in between the well-known fast but imprecise interval domain and the costly polyhedron domain. We show that it is precise enough to treat interesting examples requiring relational invariants, and hence, out of the reach of the interval domain. We also present a packing strategy that allows scaling our domain up to large programs by tuning the amount of relationality. The octagon domain was incorporated into the ASTREE industrial-strength static analyzer and was key in proving the absence of run-time errors in large critical embedded flight control software for Airbus planes.", "authors": ["Antoine Min\u00e9"], "n_citation": 818, "references": ["05187588-ada5-47d3-ab0d-a282be6fc447", "0f083fcc-803c-4f84-9561-b13bd72daf8f", "10528455-0deb-47f9-9283-f34d2678fb94", "16de10af-0723-4411-9f12-78af39a010c1", "255534f4-a098-45ea-977b-b283e44a40ab", "32711618-120c-4f28-b61b-42c6242021c9", "34d67173-5d3f-4dbe-8c4c-1c2af7509fc0", "47c3bb24-f774-4039-8965-00af7e894b52", "7bb71afa-91b8-46e7-9008-da84e0427b93", "838d99b5-5b05-41a8-adc7-a597195fefad", "8e64727f-e1c8-4774-9ec7-da7f1c6c03a3", "9a4984f9-27d4-47eb-8bc8-0469bf540f94", "aa22f5b0-489c-4343-a8a7-e9b59a001eec", "adcf3abe-d676-4112-91fa-9e05bd5e120c", "afddbf4f-1aa5-4764-a1ad-e4a369b80140", "b123fbb4-3184-4e01-92cb-e8bab3ec5112", "b6db193d-e243-46f6-b2ef-797bd5e2df7c", "cf77cb65-97e5-4db9-b0cc-947a36b3ba77", "e54b994e-9293-4b1e-82d1-771b0fc76035", "eb3d4931-ea4f-4b50-87cc-002ad4941033", "eba94140-4f08-424d-a94c-6f6c72e677e8", "f37e8ee7-2302-4cbc-8495-a863740a09a7", "f7613f64-a684-4b23-87c5-84b749cd7da8", "fac8b38a-4904-4516-96fa-11d84129d3e1", "fbd2dd68-b572-4c22-a871-032a0f4dab6b"], "title": "The octagon abstract domain", "venue": "Higher-order and Symbolic Computation \\/ Lisp and Symbolic Computation", "year": 2006, "id": "f4270e7e-3819-424b-9ae1-93539fd8901e"}
{"abstract": "This paper describes ROGUE, an integrated planning and executing robotic agent. ROGUE is designed to be a roving office gopher unit, doing tasks such as picking up & delivering mail and returning & picking up library books, in a setup where users can post tasks for the robot to do. We have been working towards the goal of building a completely autonomous agent which can learn from its experiences and improve upon its own behaviour with time. This paper describes what we have achieved to-date: (1) a system that can generate and execute plans for multiple interacting goals which arrive asynchronously and whose task structure is not known a priori, interrupting and suspending tasks when necessary, and (2) a system which can compensate for minor problems in its domain knowledge, monitoring execution to determine when actions did not achieve expected results, and re-planning to correct failures.", "authors": ["K. Zita Haigh", "Manuela M. Veloso"], "n_citation": 79, "references": ["04b1d499-2c89-45b8-8394-45a0bcf9f4ba", "072b3029-9159-442f-9baf-70e1f55e284f", "11d0a544-2739-4834-b31f-5fc03647a451", "128628b3-4142-40f5-a6dc-880d8383cb79", "139aa333-a8b6-4f58-b7d9-d94edce83b11", "19cd3c46-f848-4eb1-932f-09da461bf2d4", "1dc1347b-4efe-499f-b743-4b35573cf934", "34db7eeb-578e-404b-ade0-b5a81fcbc0aa", "37bf58e9-a273-4bf6-8c14-48953fe09727", "42bd557b-fc37-4e8e-a288-3d69cd31fcb0", "46bb8dc7-0793-4dd4-b9cf-a20bc25930a2", "69a68aab-4332-4902-9494-9b65065f56f0", "6dcdd2ad-b86b-4b4d-b031-66485f9bbece", "7e5c26f0-dc3f-429d-89df-3e4de5fde7e8", "8abc1e16-a996-4217-b11c-d4b45a41e51a", "a115b797-205c-43d6-a1cf-f1fc76c37641", "af55f019-02fd-4afa-b12c-455d42d5e758", "b0d19b05-f3e9-4c4e-8179-990139f415f8", "b814a9e5-fa98-4953-aa1d-3e0656324abd", "baa929a3-4b86-4e05-8b0f-df6140e569b2", "bbf9ae74-ab11-420e-a169-c5fa2da55e79", "c2393782-881d-4fae-9368-b44810499d9b", "cc392e6d-f852-4f4f-a952-851d58aa979e", "d695fb0d-1b38-42bc-9e8b-0750081eac94", "d89bcec8-9486-4f9c-82c1-2842acaf305d", "e58bf310-398b-4b4d-9635-bb8cdc5d6487", "ee4bbc14-80ef-4bb0-9ec8-ce8f7be6d11c", "f86167f6-9fd7-457b-be98-301b8a98a141"], "title": "Interleaving planning and robot execution for asynchronous user requests", "venue": "intelligent robots and systems", "year": 1996, "id": "d00e10d7-3cb7-4b05-9ca4-cf8c5438533d"}
{"abstract": "We describe Byzantine fault tolerant authentication, a mechanism for public key authentication in peer-to-peer systems. Authentication is done without trusted third parties, tolerates Byzantine faults and is eventually correct if more than a threshold of the peers are honest. This paper addresses the design, correctness, and fault tolerance of authentication over insecure asynchronous networks. An anti-entropy version of the protocol is developed to provide lazy authentication with logarithmic messaging cost. The cost implications of the authentication mechanism are studied by simulation.", "authors": ["Vivek Pathak", "Liviu Iftode"], "n_citation": 60, "references": ["0af7f6f2-cda4-4327-b3f2-e92640037497", "12628fee-bee5-4204-bd7c-c27af7dd14aa", "136c4780-2f25-4068-90a5-aed6afaf2890", "1817cb27-f0e0-44b7-8c44-86020f011f46", "1882defa-dd11-4407-909c-bd09c2ea56c9", "30f88f1e-eb87-4f61-ac07-3332986f5dd9", "35ce170e-c80a-4b55-b37d-468146ac2192", "3fb43b00-905c-4a08-934d-198ea4eb66c3", "51af4708-b81c-4362-b4ee-7bdf7ace609f", "532a17ef-5f37-4ead-9f4d-2fd31369966e", "622b9599-8ce5-4380-a5e2-cee173337600", "62ba8bf9-07bf-414d-94e5-4823f5d18627", "67b31644-54e7-44e3-8e20-685343f5b867", "a9b4022d-c8e8-4dcd-8bca-1ceca1c7fe5f", "ad50b9cd-1a17-4a94-b747-4b2c9678bc3c", "ba4d1a67-fbc8-4ad7-8091-f286c105aa28", "ca394e6a-59e0-466c-a66a-d976555db689", "cf00af6f-5ecb-40bf-a578-91c39b9642f5", "ecfb2022-e18c-4e5e-8733-d8bc6f4c8fc9", "fdaa761c-d51c-4049-8f7c-274ea2b2b506"], "title": "Byzantine fault tolerant public key authentication in peer-to-peer systems", "venue": "Computer Networks", "year": 2006, "id": "e423ab4f-c138-4420-96e4-21c6e9eb5495"}
{"abstract": "The development of formal models of spatial relations is a topic of great importance in spatial reasoning, geographic information systems (GIS) and computer vision, and has gained much attention from researchers across these research areas during the past two decades. In recent years significant achievements have been made on the development of models of spatial relations between spatial objects with precisely defined boundaries. However, these models cannot be directly applied to spatial objects with indeterminate boundaries which are found in many applications in geographic analysis and image understanding. This article develops a method for approximately analyzing binary topological relations between geographic regions with indeterminate boundaries based upon previous work on topological spatial relations and fuzzy sets. In addition, examples are given to demonstrate the method and related concepts. It is shown that the eight binary topological relations between regions in a two-dimensional space can be easily determined by the method.", "authors": ["F. Benjamin Zhan"], "n_citation": 110, "references": ["02be62d6-5e65-4477-8c3a-2a1e8b59e8e7", "3bfd01ff-fb9a-4ca8-b053-50ddb694883c", "5c69bfd0-8cc4-4142-9d6e-6f39ec874081", "a53c834a-0a13-435b-8509-9c666b5cb9aa", "a85f1b27-5484-4eb1-8c26-e850bc14ace8", "b7a99cf4-f73c-43f0-9904-edb260bc2d32", "d5416e8c-21d6-4a6f-9144-e36dcd3103ff", "d735e31c-931c-452f-a82c-8495da5506aa", "d7e2ba81-f3eb-4333-a87e-08ff5dc164c1", "efbd3d54-01b4-432b-86ac-c256fff6ddf9"], "title": "Approximate analysis of binary topological relations between geographic regions with indeterminate boundaries", "venue": "soft computing", "year": 1998, "id": "b225c39f-a8c3-4339-8303-81b8183d2d8a"}
{"abstract": "In this note, it is studied how structural properties of certain linear systems can be exploited to derive reduced dimension multiparametric quadratic programs that lead to explicit piecewise linear feedback solutions to the state and input constrained linear quadratic regulation problem. The reduced dimensionality typically results in suboptimal controllers of lower complexity, with associated computational advantages in the online implementation. At the heart of the methods are state-space projections based on the singular value decomposition.", "authors": ["Tor Arne Johansen"], "n_citation": 50, "references": ["0750fcbb-3bd1-48ec-a277-b0999bf94fde", "39875331-5205-4798-a572-e93e6202b9e7", "535acba7-ae39-4cfb-82c5-c6de9446b072"], "title": "Reduced explicit constrained linear quadratic regulators", "venue": "IEEE Transactions on Automatic Control", "year": 2003, "id": "acae14a2-a148-490a-90f1-f08cbda4f59b"}
{"abstract": "A significant challenge in teaching programming to disadvantaged populations is preserving learners' motivation and confidence. Because programming requires such a diverse set of skills and knowledge, the first steps in learning to program can be highly error-prone, and can quickly exhaust whatever attention learners are willing to give to a programming task. Our approach to preserving learners' motivation is to design highly integrated support tools to prevent the errors they would otherwise make. In this paper, the results of a recent study on programming errors are summarized, and many novel error-preventing tools are proposed.", "authors": ["Andrew J. Ko"], "n_citation": 50, "references": ["505ea144-8353-456e-8adf-f0818f3bef0c", "622cc6e3-e8f7-4a6f-929a-0ca8301e9bf4", "b41bf037-a093-4593-bde4-f417dad65010", "ce9f2344-ae4d-4196-bf02-c0d164937a49", "ef162d17-771e-4aac-8869-c424361443db"], "title": "Preserving non-programmers' motivation with error-prevention and debugging support tools", "venue": "", "year": 2003, "id": "93695141-93f2-4eee-9a66-34fdf6ece74f"}
{"abstract": "This paper considers a class of approximate Riemann solver devised by Harten, Lax, and van Leer (denoted HLL) for the Euler equations of inviscid gas dynamics. In their 1983 paper, Harten, Lax, and van Leer showed how, with a priori knowledge of the signal velocities, a single-state approximate Riemann solver could be constructed so as to automatically satisfy the entropy condition and yield exact resolution of isolated shock waves. Harten, Lax, and van Leer further showed that a two-state approximation could be devised, such that both shock and contact waves would be resolved exactly. However, the full implementation of this two-state approximation was never given. We show that with an appropriate choice of acoustic and contact wave velocities, the two-state so-called HLLC construction of Toro, Spruce, and Speares will yield this exact resolution of isolated shock and contact waves. We further demonstrate that the resulting scheme is positively conservative. This property, which cannot be guaranteed by any linearized approximate Riemann solver, forces the numerical method to preserve initially positive pressures and densities. Numerical examples are given to demonstrate that the solutions generated are comparable to those produced with an exact Riemann solver, only with a stronger enforcement of the entropy condition across expansion waves.", "authors": ["P. Batten", "N. Clarke", "C. Lambert", "D. M. Causon"], "n_citation": 410, "references": [], "title": "On the Choice of Wavespeeds for the HLLC Riemann Solver", "venue": "SIAM Journal on Scientific Computing", "year": 1997, "id": "b153cae2-c706-4240-8824-127fd6ec144d"}
{"abstract": "Access control vulnerabilities, which cause privilege escalations, are among the most dangerous vulnerabilities in web applications. Unfortunately, due to the difficulty in designing and implementing perfect access checks, web applications often fall victim to access control attacks. In contrast to traditional injection flaws, access control vulnerabilities are application-specific, rendering it challenging to obtain precise specifications for static and runtime enforcement. On one hand, writing specifications manually is tedious and time-consuming, which leads to non-existent, incomplete or erroneous specifications. On the other hand, automatic probabilistic-based specification inference is imprecise and computationally expensive in general.#R##N##R##N#This paper describes the first static analysis that automatically detects access control vulnerabilities in web applications. The core of the analysis is a technique that statically infers and enforces implicit access control assumptions. Our insight is that source code implicitly documents intended accesses of each role and any successful forced browsing to a privileged page is likely a vulnerability. Based on this observation, our static analysis constructs sitemaps for different roles in a web application, compares per-role sitemaps to find privileged pages, and checks whether forced browsing is successful for each privileged page. We implemented our analysis and evaluated our tool on several real-world web applications. The evaluation results show that our tool is scalable and detects both known and new access control vulnerabilities with few false positives.", "authors": ["Fangqi Sun", "Liang Xu", "Zhendong Su"], "n_citation": 70, "references": ["00cffb94-0fb6-4135-9865-d7c291156f71", "0278bce3-e509-4ae6-b130-87a283a4b819", "08d0a1e1-e5f4-4116-920f-293692d80974", "11758d7c-f829-46a0-ae42-a0815201c5ba", "1246c1d1-c929-4665-97f2-9445c088e9ba", "1728a4a8-015c-42d0-b3ba-11c4610d9936", "261a0c04-9996-461b-a136-1d5d8938fffa", "281999d1-f75f-430c-8d8c-fa79fbf04fa2", "3127f724-df75-488c-9c85-3e60a250adcd", "3317d1f5-f673-4847-874a-74861a51294f", "350e165f-d7e9-4e99-8165-a299569d1255", "3c76df3c-3da8-434e-9325-5b66d3ee7600", "3f29f1e1-ebc2-4e3a-aad5-e0db58e6057a", "5691525e-0309-49a3-9955-6f409375c9d8", "592cb238-308f-4e3d-8117-c464b4aaad03", "5e6d87c2-6b68-4033-98cc-f7cf03a71f8b", "63570c22-0a71-4f6d-9c18-bb338e7686c9", "6c68e6ec-2f4d-48ba-a8ab-a64a94da97d8", "825783c1-9b55-47c3-ba2a-113393e33158", "8593c9f2-4b27-40af-a8ed-3d808ce9bd6c", "8de8e546-34de-4816-bf21-bc7572dc780a", "937aba29-bfe6-4eb9-bb70-dc5d7801a4bd", "9994d6e0-e4ab-44cc-a463-5f1257171f0f", "9d9c48ef-7d8d-4ebe-b3d1-0418407feeb1", "a3e42847-046f-4464-b329-0568c5a64046", "ccf8ba77-1375-444e-ba4e-fbb50d3a3712", "dfdafd84-ce57-4b9c-b503-341729225e72", "f04f9bb8-6eb4-48e3-8682-c826d94f852c"], "title": "Static detection of access control vulnerabilities in web applications", "venue": "usenix security symposium", "year": 2011, "id": "bc787df3-54cc-4104-ac8d-d2dd1b7e71f6"}
{"abstract": "Inspired by the chasm between early adopters and early majority in diffusion of technological innovations, this paper investigates how agile improvement practices can help software organizations successfully implement new processes. An action research-based improvement initiative implemented a new change-request process and tool at the telecom company Ericsson AB in Gothenburg, Sweden. The study identifies a 'guerilla tactic' that change agents can use in software organizations to cross the chasm, and it discusses lessons learned in relation to literature on diffusion of innovation and software agility. The contribution of the study is that the guerrilla tactic supports agile improvement practices and facilitates successful implementation.", "authors": ["Anna B\u00f6rjesson", "Fredrik Martinsson", "Magnus Timmer\u00e5s"], "n_citation": 18, "references": ["05e04e36-7483-4391-88d2-c11b8078b8df", "21aa6b4a-e339-40bb-82e6-cc52091db50e", "2f1a7618-e92d-4b01-87cd-2c824753dc47", "5238aecc-9da5-49cf-932f-4da2c75875cc", "52853de9-0743-4e9a-a90e-7c5a912b8f60", "6bf52203-3cf6-43e9-8f44-80392caedb58", "6bff09d0-c35b-4df6-b52a-d47778bdac0b", "80698658-ee39-4df4-bd1a-a09150149d00", "86946167-a5c3-467d-b07d-a64694ec8e04", "95581d50-25e5-4712-8a4b-8a73caa0ab95", "a1ea977a-7007-4636-9092-c5f5fbb59b7e", "b541380f-8e36-4fd8-91b3-04cf1f8d2736", "bdc94277-8125-4aff-bbcd-b5e6e1fda167", "c2d3b00e-004b-4810-9eab-1eabebf6d40e", "d06109ee-e94a-45fa-8075-260e383291c4", "d21b4e5c-0621-426f-ab06-c13aec05d2c2", "e890938d-f8fb-4627-a254-2ab6bf716615", "ff8e1306-0bd6-4508-86c2-f34f90f19aab"], "title": "Agile improvement practices in software organizations", "venue": "European Journal of Information Systems", "year": 2006, "id": "2d3a5aee-2539-4cd8-9f02-71d985d996c0"}
{"authors": ["Jyrki Katajainen", "Erkki M\u00e4kinen"], "n_citation": 4, "title": "A note on the complexity of trie compaction.", "venue": "Bulletin of The European Association for Theoretical Computer Science", "year": 1990, "id": "8c1f6a87-dd42-48f0-9dc9-cdc389ca0b97"}
{"abstract": "Abstract   Using a result of B.H. Neumann we extend Eilenberg's Equality Theorem to a general result which implies that the multiplicity equivalence problem of two (nondeterministic) multitape finite automata is decidable. As a corollary we solve a long standing open problem in automata theory, namely, the equivalence problem for multitape deterministic finite automata. The main theorem states that there is a finite test set for the multiplicity equivalence of finite automata over conservative monoids embeddable in a fully ordered group.", "authors": ["Tero Harju", "Juhani Karhum\u00e4ki"], "n_citation": 139, "references": ["332084ee-29ab-411e-9d8b-0dc9e977c5a9", "350509e5-7515-4af8-ad93-df8e5c018d1a", "772ca64f-0a90-4c36-a988-07b546759f9f", "84d3abf9-d380-4489-b98d-ab0331b7c1d7", "942a7f03-8b2f-4f95-a203-92e4dad807f2", "b0f6455a-6f99-42c5-8502-4fa535768ceb", "c360b7d4-b31c-45f4-8afb-f2e1730acb6f", "c76e46ce-11f9-4992-949b-5c82941f9cdb"], "title": "The equivalence problem of multitape finite automata", "venue": "Theoretical Computer Science", "year": 1991, "id": "34543e82-9f69-41a9-aaa1-895e8d6cad63"}
{"abstract": "We consider stratified negation in temporal logic programming. We demonstrate that the cycle-sum test (which was initially proposed for detecting deadlocks in the context of temporal functional programming) can also be used as a syntactic stratification test for temporal logic programming. Therefore, on the one hand we exhibit a class of temporal logic programs with negation which have a well-defined semantics, and on the other hand we provide further evidence that the cycle-sum test is a fundamental one in the area of temporal programming.", "authors": ["Panos Rondogiannis"], "n_citation": 50, "references": ["05ed276f-59ad-4172-9540-8282441dd482", "1c7e166d-94cb-4cdd-b23b-1fd26029ff3d", "349b4cb0-7d84-4aa8-bd0c-055804f8db1f", "40471de6-befb-4332-9026-d22b73eaac0b", "493cda6b-a010-41f7-b507-9057e846001f", "88aeb7c4-b210-4668-8472-4ce54af3b9ee", "9919e30b-5fd8-4f59-a0d1-5d740511a81b"], "title": "Stratified negation in temporal logic programming and the cycle-sum test", "venue": "Theoretical Computer Science", "year": 2001, "id": "2e0b9718-39cb-41aa-8abf-200d6213a3fe"}
{"abstract": "E-commerce transactions, in addition to the exchange of goods and services for payment, often entail an indirect transaction, where personal data are exchanged for better services or lower prices. This paper analyses buyer's and seller's privacy-related strategic choices in e-commerce transactions through game theory. We demonstrate how game theory can explain why buyers mistrust internet privacy policies and relevant technologies (e.g. P3P) and sellers hesitate to invest in data protection.", "authors": ["Spyros Kokolakis", "Anastasopoulou Kalliopi", "Maria Karyda"], "n_citation": 50, "references": ["056608c2-78d6-44c4-85a6-fe2c1fdee928", "1a3acf5f-1a6e-4de5-a93c-f88a61003e84", "21af300f-4c44-42ea-82df-2ab704de1665", "38e8c09b-b142-4888-b904-cde8b136b45c", "4c4e511a-ac75-477e-b5e4-13109edafbcb", "9dd595f7-d343-443a-ba48-5fe9ed4ff3d9", "a32b04b5-fcaa-4997-9fa7-e3b5ba2d4fcd", "d8b4cbad-7690-4ef9-8698-8864d238cdca"], "title": "An Analysis of Privacy-Related Strategic Choices of Buyers and Sellers in E-commerce Transactions", "venue": "panhellenic conference on informatics", "year": 2012, "id": "8bd6b5af-ecc9-4135-b853-b1ed34eb4848"}
{"abstract": "We present an alternative model of human cognitive development on the balance scale task. Study of this task has inspired a wide range of human and computational work. The task requires that children predict the outcome of placing a discrete number of weights at various distances on either side of a fulcrum. Our model, which features the symbolic learning algorithm C4.5 as a transition mechanism, exhibits regularities found in the human data including orderly stage progression, U-shaped development, and the torque difference effect. Unlike previous successful models of the task, the current model uses a single free parameter, is not restricted in the size of the balance scale that it can accommodate, and does not require the assumption of a highly structured output representation or a training environment biased towards weight or distance information. The model makes a number of predictions differing from those of previous computational efforts.", "authors": ["William C. Schmidt", "Charles X. Ling"], "n_citation": 36, "references": ["013dc00b-3ff5-48c3-aa39-4388f49bdb4c", "31c0add6-c347-4f2b-b82e-7a779a8c9403", "5d80f9cf-66e0-4b26-83cf-7ee6e2ac8c5b", "62549bc2-e0b3-46e8-8d32-390dded105d5", "b49c1e2b-0cd0-4950-a724-00c698e5b49d", "ba59acd1-1ed4-419a-90d8-ad47d02ba925"], "title": "A decision-tree model of balance scale development", "venue": "Machine Learning", "year": 1996, "id": "0dc6d0a4-7025-4f84-b141-48f02837d3c7"}
{"abstract": "Motivation: Progressive Multiple Sequence Alignment (MSA) methods depend on reducing an MSA to a linear profile for each alignment step. However, this leads to loss of information needed for accurate alignment, and gap scoring artifacts. Results: We present a graph representation of an MSA that can itself be aligned directly by pairwise dynamic programming, eliminating the need to reduce the MSA to a profile. This enables our algorithm (Partial Order Alignment (POA)) to guarantee that the optimal alignment of each new sequence versus each sequence in the MSA will be considered. Moreover, this algorithm introduces a new edit operator, homologous recombination, important for multidomain sequences. The algorithm has improved speed (linear time complexity) over existing MSA algorithms, enabling construction of massive and complex alignments (e.g. an alignment of 5000 sequences in 4 h on a Pentium II). We demonstrate the utility of this algorithm on a family of multidomain SH2 proteins, and on EST assemblies containing alternative splicing and polymorphism. Availability: The partial order alignment program POA is available at http://www.bioinformatics.ucla.edu/poa.", "authors": ["Christopher J. Lee", "Catherine S. Grasso", "Mark Sharlow"], "n_citation": 452, "references": ["74ed9570-1d35-4ece-958d-f8c3086cee5a", "cab268f0-b162-474e-86fd-21d623bc39e5"], "title": "Multiple sequence alignment using partial order graphs", "venue": "Bioinformatics", "year": 2002, "id": "9b44ff8b-7375-4220-bc11-fd3ca3387bea"}
{"abstract": "We designed, implemented and evaluated a new concept for direct manipulation of databases, called  dynamic queries , that allows users to formulate queries with graphical widgets, such as sliders. By providing a graphical visualization of the database and search results, users can find trends and exceptions easily. Eighteen undergraduate chemistry students performed statistically significantly faster using a dynamic queries interface compared to two interfaces both providing form fill-in as input method, one with graphical visualization output and one with all-textual output. The interfaces were used to explore the periodic table of elements and search on their properties.", "authors": ["Christopher Ahlberg", "Christopher Williamson", "Ben Shneiderman"], "n_citation": 671, "references": ["0c66ece5-fc9a-4373-b11d-5f04afa4313c", "32518aaf-9c2f-4bd7-b591-72cbabdad644", "ac077ae4-57be-495e-8a74-dfa2b770f096", "dc611e3d-8816-4950-a5f9-481744c5a6b9"], "title": "Dynamic queries for information exploration: an implementation and evaluation", "venue": "human factors in computing systems", "year": 1992, "id": "ae6581cd-e184-4ccd-aac2-e275f86d529b"}
{"authors": ["Tomio Watanabe", "Masashi Okubo"], "n_citation": 6, "title": "Virtual face-to-face communication system for human interaction analysis by synthesis", "venue": "international conference on human computer interaction", "year": 1999, "id": "3f5ba2a8-1f62-4252-a75c-31c793ea4fae"}
{"authors": ["Thomas A. Henzinger", "Orna Kupferman", "Sriram K. Rajamani"], "n_citation": 62, "title": "Fair Simulation", "venue": "international conference on concurrency theory", "year": 1997, "id": "32b1b3c1-08a4-4b2b-9525-6666359049fe"}
{"abstract": "From the users' point of view, resource management schemes may be considered as an abstract data type. An abstract specification of such schemes using axioms holding in partial algebras and relatively distributed implementations (expressed as CSP programs) are given and analyzed. Then the idea of probabilistic implementation of guard scheduling is suggested, which allows completely distributed symmetric programs. It frees the designer of an algorithm from looking for specific probabilistic algorithms, by allowing the compiler to generate probabilistic target code from nonprobabilistic source code.", "authors": ["Nissim Francez", "Michael Rodeh"], "n_citation": 56, "references": ["043bd5d0-ad50-4b72-ab3b-f45fea447540", "296054b4-a408-4c0a-8a7b-ebaf0363d75f", "78d07c73-7bc3-4ae7-998b-adf367e746d3", "e39b641b-105c-427d-8209-1ddb37645750"], "title": "A distributed abstract data type implemented by a probabilistic communication scheme", "venue": "foundations of computer science", "year": 1980, "id": "33a1e666-8ed1-4f7c-be9d-cb809f37fd4d"}
{"abstract": "Web portals and ISPs such as AOL, Microsoft Network, and Yahoo have grown more than tenfold in the past five years (1996-2001). Despite their scale, growth rates, and rapid evolution of content and features, these sites and other \"giant-scale\" services like instant messaging and Napster must be always available. Many other major Web sites such as eBay, CNN, and Wal-Mart, have similar availability requirements. The article looks at the basic model for such services, focusing on the key real-world challenges they face (high availability, evolution, and growth), and developing some principles for attacking these problems. Few of the points made in the article are addressed in the literature, and most of the conclusions take the form of principles and approaches rather than absolute quantitative evaluations. This is due partly to the author's focus on high-level design, partly to the newness of the area, and partly to the proprietary nature of some of the information (which represents 15-20 very large sites). Nonetheless, the lessons are easy to understand and apply, and they simplify the design of large systems.", "authors": ["Eric A. Brewer"], "n_citation": 319, "references": ["17e4a304-1e06-4739-930d-9e1cd232f864", "4591f25f-7cc0-4f77-a484-b4b4b4ebccb3", "6b64058c-5de2-4050-86a9-32518b3e8259", "9d11aa6c-586e-40dc-a475-094bf043431f", "c2f45764-feee-4bee-b448-92d53d8a4d3f"], "title": "Lessons from giant-scale services", "venue": "IEEE Internet Computing", "year": 2001, "id": "4f53d0b3-59e5-41d0-aaa8-a544b9bcf1a8"}
{"abstract": "An exact method is presented for discretizing a constant-coefficient, non-square, matrix differential Riccati equation, whose solution is assumed to exist. The resulting discrete-time equation gives the values that have no error at discrete-time instants for any discrete-time interval. The method is based on a matrix fractional transformation, which is more general than existing ones, for linearizing the differential Riccati equation. A numerical example is presented to compare the proposed method with that based on gage invariance and bilinearization, which has better performances than the conventional forward-difference method.", "authors": ["Kanticha Kittipeerachon", "Noriyuki Hori", "Y. Tomita"], "n_citation": 2, "references": ["a7582d8c-2c44-4aa8-8027-7a144c234dbd"], "title": "Exact Discretization of a Matrix Differential Riccati Equation With Constant Coefficients", "venue": "IEEE Transactions on Automatic Control", "year": 2009, "id": "4074258c-4d2d-4e8c-9724-3758b2e39f10"}
{"abstract": "Given a relational database and a set of fuzzy terms defined for some attributes we consider the problem of mining fuzzy quantitative association rules that may contain crisp values, intervals, and fuzzy terms in both antecedent and consequent. We present an algorithm extended from the equi-depth partition (EDP) algorithm for solving this problem. Our approach combines interval partition with pre-defined fuzzy terms and is more general.", "authors": ["Weining Zhang"], "n_citation": 101, "references": ["47acb839-d355-470e-b5d0-90da272aa74f", "82c534c6-c89d-4856-b6fc-e1cad5be4482", "c49e6979-a8e3-4d37-b515-b2a5400e9522", "e97695ef-712a-43d7-b685-5ead1dce1139", "ecd6a845-8439-49b0-abe8-f71fff81da23", "ff76e373-a259-4027-9a6f-b9874ee4113b"], "title": "Mining fuzzy quantitative association rules", "venue": "international conference on tools with artificial intelligence", "year": 1999, "id": "958e4703-66bc-4442-9bea-10911a7aeb84"}
{"authors": ["Henry Hexmoor", "David Kortenkamp", "Ian Horswill"], "n_citation": 33, "references": ["02a46801-c4d8-42cc-9361-7e77e983157d", "079090cb-9ba8-419b-845c-7cccb6039da3", "11d0a544-2739-4834-b31f-5fc03647a451", "3e7c9d8e-7b30-49d2-be56-d4d845321028", "46c4616f-186c-4a21-898e-19335bd8707d", "471a44d2-bd0b-429e-acdd-f804a8cb5ab7", "64f09813-41c4-42cd-a50b-0df590789010", "679f80f7-b07f-439e-9455-f4b7074a9024", "7a71c952-98ac-4915-915e-43fad96603d5", "991181a9-1141-4134-b971-1e28cf003545", "a933b08b-9dd2-4831-a1f5-99b19c30d914", "adcccd73-95b7-43a3-abb7-0aa004a2a716", "eb113e6d-a127-4649-9f7f-971ce8887818", "f221b60c-a3a8-4e26-8989-b9b3a103ee68"], "title": "Software architectures for hardware agents", "venue": "Journal of Experimental and Theoretical Artificial Intelligence", "year": 1997, "id": "37e8d907-781c-4b81-a1b8-b8818b2cdd1e"}
{"abstract": "Text that appears in images contains important and useful information. Detection and extraction of text in images have been used in many applications. In this paper, we propose a multiscale edge-based text extraction algorithm, which can automatically detect and extract text in complex images. The proposed method is a general-purpose text detection and extraction algorithm, which can deal not only with printed document images but also with scene text. It is robust with respect to the font size, style, color, orientation, and alignment of text and can be used in a large variety of application fields, such as mobile robot navigation, vehicle license detection and recognition, object identification, document retrieving, page segmentation, etc.", "authors": ["Xiaoqing Liu", "Jagath Samarabandu"], "n_citation": 55, "references": ["06f1baa4-5b5c-47c1-938d-13f51769eb94", "14389770-5aa8-4fa8-b1d1-5ba08a1da02d", "22bc76bd-03f4-4a59-aee4-d6f9f565d322", "3d65dee8-8145-430a-9c5c-ea958fd4db78", "ccb1b187-2d10-4008-8aa8-5e4b7f117bbe", "f3209c47-5216-4490-a8bd-662ec05f16f4"], "title": "Multiscale Edge-Based Text Extraction from Complex Images", "venue": "international conference on multimedia and expo", "year": 2006, "id": "bd0ba5fa-ac2c-4b25-9833-f890323dd469"}
{"abstract": "The construction of abstractions is essential for reducing large or infinite state systems to small or finite state systems. Boolean abstractions, where boolean variables replace concrete predicates, are an important class that subsume several abstraction schemes. We show how boolean abstractions can be constructed simply, efficiently, and precisely for infinite state systems while preserving properties in the full \u00b5-calculus. We also propose an automatic refinement algorithm which refines the abstraction until the property is verified or a counterexample is found. Our algorithm is implemented as a proof rule in the PVS verification system. With the abstraction proof rule, proof strategies combining deductive proof construction, model checking, and abstraction can be defined entirely within the PVS framework.", "authors": ["Hassen Sa\u00efdi", "Natarajan Shankar"], "n_citation": 230, "references": ["15500b32-9e14-46cf-9eeb-a8c1fbdb3aab", "2376c562-2d9e-4768-931b-7e467d885d14", "2db89dc9-8302-4d71-b197-2ff3531185ab", "2de3c73f-7f8e-49b2-875d-1672c43409ab", "5824ff23-170f-44ef-8c77-770d8568a4ab", "8e10eaa1-a6c6-4d8a-8505-81a95232888a", "9a4984f9-27d4-47eb-8bc8-0469bf540f94", "e2f00686-d81e-4d69-b5e3-88a9d8d2e7f9", "e5e5c6ee-2403-4e1e-a841-b342209127b0", "ecbaeced-0a5e-435a-9a34-c7d0a25412a4", "f56084f3-402e-40f3-b8bb-9d9d2fc72919"], "title": "Abstract and Model Check While You Prove", "venue": "computer aided verification", "year": 1999, "id": "18427a97-5bc3-4afe-9a96-769ea0982a65"}
{"authors": ["Douglas R. Smith", "Michael R. Lowry"], "n_citation": 50, "references": ["1e97a7ef-ce6d-4de5-8508-622205980795", "203885ca-caec-43b7-bf93-529834525901", "3659f2d5-bc81-467e-9488-34aff690bdc3", "38d3c30c-c691-4e1f-99e8-7058ff86907d", "5edb99f2-cc75-468e-9ca0-28ce7a1e709d", "9ae76088-6b86-4abd-85ad-e80acb2cdb8b", "aa0afc09-bec1-493d-8c1b-3aa71dfa1c44", "ffa79251-8783-4519-9bd8-87626057fba3"], "title": "Algorithm Theories and Design Tactics", "venue": "mathematics of program construction", "year": 1989, "id": "780eb9f8-7a62-4f9e-866c-7831490c109e"}
{"abstract": "A method is presented for the machine recognition of constrained, hand printed Devanagari characters. A set of very simple primitives is used, and all the Devanagari characters are looked upon as a concatenation of these primitives. Most of the decisions are taken on the basis of the presence/absence or positional relationship of these primitives; and the decision process is a multistage process, where each stage of decision making narrows down the choice regarding the class membership of the input token.", "authors": ["Ishwar K. Sethi", "B. Chatterjee"], "n_citation": 168, "references": [], "title": "Machine recognition of constrained hand printed devanagari", "venue": "Pattern Recognition", "year": 1977, "id": "72546ae3-7a20-489b-a053-d2efffd70625"}
{"abstract": "Abstract#R##N##R##N#Desk checking is known to be an effective reading technique for early detection of sequential program errors. This paper discusses how to extend desk checking for concurrent and distributed programs. In addition to exponential possible schedules, concurrent and distributed programs have execution states that include more than one process. The new distributed desk-checking technique supports the selection of schedules and execution states to be reviewed. The cross-product functional coverage technique assists in the selection process. Schedule selection guidelines that facilitate early detection and coverage are introduced. It is demonstrated that code inspection can be applied effectively to large industrial applications using the selection mechanism introduced by this technique. Industrial pilots show that distributed desk checking is an effective early error-detection review technique. Copyright \u00a9 2006 John Wiley & Sons, Ltd.", "authors": ["Amiram Hayardeny", "Shachar Fienblit", "Eitan Farchi"], "n_citation": 50, "references": ["7f1dc63a-9064-4768-a30d-3383d52aa81e", "9c1bb295-5fa0-4ad2-b842-b64d8ab9b795", "d6289f8d-fbf9-45f3-a71a-bd2ecac4c0a9"], "title": "Distributed desk checking", "venue": "Concurrency and Computation: Practice and Experience", "year": 2007, "id": "02e69d46-5d0d-45a9-9ca2-f981fe18f1dd"}
{"abstract": "The management of uncertainty in expert systems has usually been left to  ad hoc  representations and rules of combinations lacking either a sound theory or clear semantics. The objective of this paper is to establish a theoretical basis for defining the syntax and semantics of a small subset of calculi of uncertainty operating on a given term set of linguistic statements of likelihood. Each calculus is defined by specifying a negation, a conjunction and a disjunction operator. Families of Triangular norms and conorms constitute the most general representations of conjunction and disjunction operators. These families provide us with a formalism for defining an infinite number of different calculi of uncertainty. The term set will define the uncertainty  granularity , i.e. the finest level of distinction among different quantifications of uncertainty. This granularity will limit the ability to differentiate between two similar operators. Therefore, only a small finite subset of the infinite number of calculi will produce notably different results. This result is illustrated by two experiments where nine and eleven different calculi of uncertainty are used with three term sets containing five, nine, and thirteen elements, respectively. Finally, the use of context dependent rule set is proposed to select the most appropriate calculus for any given situation. Such a rule set will be relatively small since it must only describe the selection policies for a small number of calculi (resulting from the analyzed trade-off between complexity and precision).", "authors": ["Piero P. Bonissone", "Keith Decker"], "n_citation": 816, "references": ["10978c39-f7f6-4600-90c1-9901586c8cbd", "50205c68-72f9-4334-a9d6-5b01817d605f", "cd13fec9-0a7b-4061-8f44-6b0b5c92defe"], "title": "Selecting Uncertainty Calculi and Granularity: An Experiment in Trading-Off Precision and Complexity", "venue": "uncertainty in artificial intelligence", "year": 2013, "id": "47e8399c-51e1-4577-af89-59328cc1d398"}
{"abstract": "In a previous paper, we have shown the very high power of asynchronism for parallel iterative algorithms in a global context of grid computing. In this article, we study the interest of coupling load balancing with asynchronism in such algorithms. After proposing a noncentralized version of dynamic load balancing which is best suited to asynchronism, we verify its efficiency by some experiments on a general partial differential equation (PDE) problem. Finally, we give some general conditions for the use of load balancing to obtain good results with this kind of algorithm and discuss the choice of the residual as an efficient load estimator.", "authors": ["Jacques M. Bahi", "Sylvain Contassot-Vivier", "Rapha\u00ebl Couturier"], "n_citation": 73, "references": ["29823d19-56a6-4ec0-8978-2db3b5179ec8", "2e88f162-544a-4c76-8026-410f27b72f07", "34d4e37b-e575-4316-847b-d8a661b51473", "3835a59b-15ed-40de-9540-7c0b95f4b84d", "462ba500-3be6-42ac-af4d-72804e4d5b8f", "52613895-2320-49bd-8825-7f73c8dd3855", "52a2b03b-f4e1-4b68-9124-e18377de1027", "73fe3b1f-dc27-4d63-91cf-17b0ab71ca59", "7cb927e3-43d2-4863-a0a9-dfb92260fc05", "a7aa77e1-862b-4be1-ac9b-592835f1bbeb", "b566505e-d52b-4c9b-b116-d919813e5f5d", "b7ba8291-334d-4590-81ed-e787c6130348", "ec5cea52-381b-4263-ac39-5f59db9b0f91"], "title": "Dynamic load balancing and efficient load estimators for asynchronous iterative algorithms", "venue": "IEEE Transactions on Parallel and Distributed Systems", "year": 2005, "id": "8cd58859-6102-461d-b036-d33827372e45"}
{"abstract": "This paper describes some of the difficulties that may be expected in the maintenance of software developed using the new object oriented languages. The concepts of inheritance and of polymorphism provide the great strengths of these languages, but they also introduce difficulties in program analysis and understanding. The paper analyzes problems of dynamic binding, object dependencies, dispersed program structure, control of polymorphism, high-level understanding, and detailed code understanding. Examples are presented based on code from a PC Smalltalk environment and from studies of two systems under development at Bell Communications Research", "authors": ["Norman Wilde", "Ross Huitt"], "n_citation": 271, "references": ["2c08d317-3848-40af-9dfa-20c8ce584ce9", "314603d6-52ce-408b-9cca-be2fb6d5111a", "471feedc-1db9-4e00-ad0d-da1c225fc083", "50689679-8346-48f2-8d70-4dfd29f8b470", "5de64657-2100-47ee-ba9e-bcc220cb0345", "823641bc-8985-4c71-8635-a71fe94d74a7", "a3e4896d-df39-43fd-b75f-17d5f6e4dbf3", "a8e9ece1-977d-4a0b-bf9f-9158478c24e7", "be5f54af-0d8c-4718-b442-fae146715717", "cc1949cc-89fa-4c01-8b49-30a785d6ca4d", "cc558ed4-e060-4a0e-9456-cf369ab964e9", "f78d5e39-e22c-4dcc-adb0-de87aa0cb9cd"], "title": "Maintenance support for object-oriented programs", "venue": "IEEE Transactions on Software Engineering", "year": 1992, "id": "85de72e6-b477-41a7-8271-55319d857193"}
{"abstract": "In content based retrieval, color indexing is one of the most prevalent retrieval methods. Two key problems in color indexing are: (1) determination of the color space, and (2) finding the best distance measure. Most of the attention from the research literature has been focussed on the color model with little or no consideration of the noise models. By focusing on the noise model, we show how to find a distance measure which is optimal in the sense that it maximizes the similarity probability. Our results include experiments in color based retrieval and object recognition. Furthermore, we implement and test several promising algorithms from the research literature as benchmarks.", "authors": ["Nicu Sebe", "Michael S. Lew"], "n_citation": 5, "references": ["4d65c147-3ff3-4c80-82ad-760057fd2310", "5be83099-f03c-46fa-9e3d-2eb6302713fa", "d888c0d6-49bb-4b0f-98c1-5ee897878f2d"], "title": "Color based retrieval and recognition", "venue": "international conference on multimedia and expo", "year": 2000, "id": "d3ebdef7-df38-4c2e-8d79-0683d43e79dd"}
{"abstract": "One of the most important issues affecting host mobility is the location and routing scheme that allows hosts to move seamlessly from one site to another. This paper presents a method that exploits the locality properties of a host's pattern of movement and access history. Two concepts, \"local region\" and \"patron service\" are introduced based on the locality features. For each mobile host, the local region is a set of designated subnetworks within which a mobile host often moves, and the patrons are the hosts from which the majority of traffic for the mobile host originated. These are used to confine the effects of a host moving, so location updates are sent only to its local area, and to those source hosts which are most likely to call again. Our scheme has the advantages of limiting location updates, and providing optimal routing, while increasing network and host scalability. >", "authors": ["Gihwan Cho", "Lindsay Marshall"], "n_citation": 134, "references": ["0bc7c7d0-6fea-4856-9169-fa61897569b9", "4a7cb896-4ea8-41ed-b108-bb3dc4ec8717", "71b7c4aa-4408-4c69-b334-6bf3da873f07", "c33db1e2-0b46-4c0b-868f-785b8d1e6e0c", "ee4aae5e-a7fe-4521-b3f9-280d3abeb745", "ef61de99-2901-4dab-b5d1-1300c92cf925", "fdec80ec-e689-4747-9a41-a2f48ffb3a1d"], "title": "An efficient location and routing scheme for mobile computing environments", "venue": "IEEE Journal on Selected Areas in Communications", "year": 1995, "id": "13f3af99-28ed-430b-8dd7-1b0df4677366"}
{"abstract": "In this paper we give a short introduction in first-order theorem proving and the use of the theorem prover Vampire. We discuss the superposition calculus and explain the key concepts of saturation and redundancy elimination, present saturation algorithms and preprocessing, and demonstrate how these concepts are implemented in Vampire. Further, we also cover more recent topics and features of Vampire designed for advanced applications, including satisfiability checking, theory reasoning, interpolation, consequence elimination, and program analysis.", "authors": ["Laura Kov\u00e1cs", "Andrei Voronkov"], "n_citation": 127, "references": ["076990f9-f857-42e5-bc9b-8adf290ad114", "0833450f-6270-4c8a-9e09-1f20b2879e5a", "09fc7b5d-9220-4088-bdac-eb79cddc9675", "112eeff7-c265-4808-aef5-55f592540e40", "31b17c3b-4617-4eb3-a279-ac368775c68f", "365b968f-39bf-4c0c-a248-d9adbf866689", "3c821bbb-c501-428d-b62e-cc45ea740333", "3f8d5bc1-30cd-4050-ab2f-b288122d5188", "43279b72-b36a-4f94-a079-ed19b3b96798", "45fb1e4d-1fd8-4415-becc-25b4aceb9c4d", "478bd406-d11d-421e-82c8-3d9f1e3175da", "4ff522f0-4eb7-40a8-acde-823722332f93", "568df274-55a4-45fd-8ed3-c811d8117c15", "5c759cf4-9b03-4b71-9864-2982764f6f0b", "65c1b9c7-6aee-4871-bcbb-593e87493f29", "6861d7c2-6125-42fd-bd79-ac9c43b99a3a", "75d5e7b5-90b3-4160-91f4-382ab7b60b3c", "76ef0a2c-b229-4522-8606-434c7b0202f4", "7d1e46b1-960b-490a-8a7e-54f189175d79", "7e99985a-1e0f-416a-9339-5dbf4efe809f", "8cf429c1-7217-44a3-80b6-a2031bf9ca30", "90f6737e-cfeb-4ac4-9777-ed839626a645", "9849d9c4-a97f-452f-882c-42a8c6cab0b5", "9942aa5f-1625-411e-9b43-f2f9d695c778", "9967472e-b353-4ef2-84df-ff8bf4046e0c", "bac8fb47-f4d0-4757-bde5-94c3bacc41d9", "cb0dd823-f94d-4c40-b16d-030196974639", "d3d3ef18-880b-4037-b7ef-8eb7bc6a1c3d", "e08ac0df-db58-4185-93d3-7bccbf8637ff", "eb1f7669-13bb-47ae-afbe-65de9ef7713c", "f1864b5b-1135-49a9-a935-7b9b150c5cc9"], "title": "First-Order Theorem Proving and Vampire", "venue": "computer aided verification", "year": 2013, "id": "744293b8-70dd-48f9-bcb6-896cc2ad5406"}
{"abstract": "We present a novel approach to reconstruction based super- resolution that explicitly models the detector's pixel layout. Pixels in our model can vary in shape and size, and there may be gaps between adjacent pixels. Furthermore, their layout can be periodic as well as aperiodic, such as penrose tiling or a biological retina. We also present a new variant of the well known error back-projection super-resolution algorithm that makes use of the exact detector model in its back projection operator for better accuracy. Our method can be applied equally well to either periodic or aperiodic pixel tiling. Through analysis and extensive testing using synthetic and real images, we show that our approach outperforms existing reconstruction based algorithms for regular pixel arrays. We obtain significantly better results using aperiodic pixel layouts. As an interesting example, we apply our method to a retina-like pixel structure modeled by a centroidal Voronoi tessellation. We demonstrate that, in principle, this structure is better for super-resolution than the regular pixel array used in today's sensors.", "authors": ["Moshe Ben-Ezra", "Zhouchen Lin", "Bennett Wilburn"], "n_citation": 59, "references": ["1efd704a-6e17-4474-a5d4-a3e86c7fd974", "275d9701-710b-4676-9385-492e24fecc3d", "654f2bf7-9481-4a56-9ff1-f15b2ede9463", "95141678-c691-4a76-9438-25f2e1520ad0", "ab4a44eb-740a-4e6f-9c54-edd38197c935", "ae7496e2-82cf-44ec-ab38-1d640c197b8d", "e2b17346-c348-46d2-8b3c-628db4be8b11", "f0176e5b-d3a7-4214-b4e2-cf22720f6df4", "fa3c1833-9329-4fc6-b723-6a8af124a96c", "fce6b622-8275-4e84-b6df-59955f9e4d8e"], "title": "Penrose Pixels Super-Resolution in the Detector Layout Domain", "venue": "international conference on computer vision", "year": 2007, "id": "62a4e940-d2d4-4b23-8ccb-e0a4f42e6e1d"}
{"abstract": "omez et al. [Phys. Rev. Lett. 110, 028701 (2013)], some of the authors proposed a framework for the study of diffusion processes in such networks. Here, we extend the previous framework to deal with general configurations in several layers of networks and analyze the behavior of the spectrum of the Laplacian of the full multiplex. We derive an interesting decoupling of the problem that allow us to unravel the role played by the interconnections of the multiplex in the dynamical processes on top of them. Capitalizing on this decoupling we perform an asymptotic analysis that allow us to derive analytical expressions for the full spectrum of eigenvalues. This spectrum is used to gain insight into physical phenomena on top of multiplex, specifically, diffusion processes and synchronizability.", "authors": ["Albert Sol\u00e9-Ribalta", "Manlio De Domenico", "Nikos E. Kouvaris", "Albert D\u00edaz-Guilera", "Sergio G\u00f3mez", "Alex Arenas"], "n_citation": 113, "title": "Spectral properties of the Laplacian of multiplex networks", "venue": "Physical Review E", "year": 2013, "id": "b5c09307-18c5-4906-9ec7-3d4503abd2f4"}
{"abstract": "The ease of creating image forgery using image-splicing techniques will soon make our naive trust on image authenticity a tiling of the past. In prior work, we observed the capability of the bicoherence magnitude and phase features for image splicing detection. To bridge the gap between empirical observations and theoretical justifications, in this paper, an image-splicing model based on the idea of bipolar signal perturbation is proposed and studied. A theoretical analysis of the model leads to propositions and predictions consistent with the empirical observations.", "authors": ["Tian-Tsong Ng", "Shih-Fu Chang"], "n_citation": 169, "references": ["b78e0e6e-c472-4919-ae96-1a69d037609b"], "title": "A model for image splicing", "venue": "international conference on image processing", "year": 2004, "id": "74d98dc7-33e2-4c0b-9839-cf9e81b3ebe7"}
{"abstract": "In this paper, the authors describe the Adaptive Route Advisor system. It uses driver preferences and predicts routes based on a model of these driver preferences. If the predicted route is unsatisfactory the system generates additional routes that are based on driver interaction. The authors describes a pilot study using route selections to construct a personalized model. It is shown that as the accuracy of the preference model increases, the need for interaction decreases.", "authors": ["Seth Rogers", "Claude-Nicolas Fiechter", "Pat Langley"], "n_citation": 135, "references": ["3e907be0-9eca-4e7e-baa4-bca454cd6242", "67f8bda8-3783-4816-8d66-60383cf04194", "6965f2c2-0bfd-4735-9ba5-e91a260ea6e9", "e4777969-d768-4cf6-91da-bd2e85b68154"], "title": "An adaptive interactive agent for route advice", "venue": "adaptive agents and multi agents systems", "year": 1999, "id": "56756582-9929-4eef-8ebc-4a9a62db0d50"}
{"abstract": "We present a new image segmentation algorithm based on graph cuts. Our main tool is separation of each pixel p from a special point outside the image by a cut of a minimum cost. Such a cut creates a group of pixels C/sub p/ around each pixel. We show that these groups C/sub p/ are either disjoint or nested in each other and so they give a natural segmentation of the image. In addition this property allows an efficient implementation of the algorithms because for most pixels p the computation of C/sub p/ is not performed on the whole graph. We inspect all C/sub p/ and discard those which are not interesting, for example if they are too small. This procedure automatically groups small components together or merges them into nearby large clusters. Effectively, our segmentation is performed by extracting significant non-intersecting closed contours. We present interesting segmentation results on real and artificial images.", "authors": ["Olga Veksler"], "n_citation": 115, "references": ["1017d9d4-9a4c-423d-ad40-6d9bebbd6b31", "20c9c17e-7799-4588-95a6-c02bf8f31e23", "6e184d1b-925b-4918-b354-a2647e8fd945", "7b8583e6-dbd3-4d2f-859a-f1de071886f2", "8f4f3015-c03d-46e1-90fb-2c42ea2cb91f", "9438a773-c15c-4ef2-a97c-54f643ce6082", "b1c2251e-7b54-41e5-8130-10d9646e02da", "c2dd1e3a-e1d4-456c-b1b8-6ddc2d66f1ee", "d78003db-ad8a-48d2-be57-1c50e95cef72"], "title": "Image segmentation by nested cuts", "venue": "computer vision and pattern recognition", "year": 2000, "id": "65f30c74-7499-4ca3-9a89-6b31655c5750"}
{"abstract": "This paper describes a study in the evolution of distributed cooperative behavior, specifically leader election, through digital evolution and group selection. In digital evolution, a population of self-replicating computer programs exists in a user-defined computational environment and is subject to instruction-level mutations and natural selection. Group selection is the theory that the survival of the individual is linked to the survival of the group, thus encouraging cooperation. The results of experiments using the Avida digital evolution platform demonstrate that group selection can produce populations capable of electing a leader and, when that leader is terminated, electing a new leader. This result serves as an existence proof that group selection and digital evolution can produce complex cooperative behaviors, and therefore have promise in the design of robust distributed computing systems.", "authors": ["David B. Knoester", "Philip K. McKinley", "Charles Ofria"], "n_citation": 27, "references": ["0151444c-5464-46f4-9b28-7c6fd238e41c", "0224a1e1-448c-4a63-b821-77dec256862f", "307da25d-84c0-48e7-b993-2fada4280f49", "352838dd-9583-402f-be39-52df4810a25f", "3d794814-c374-4299-b518-c361c768269b", "621d1071-8350-4386-b1e8-519c4dfa8c5d", "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "6bcf9c43-3e15-4c85-8694-5cecaf2d50bf", "a881733d-c8d4-462b-8424-ad10e06596f7", "ac7e1fcf-fb69-4422-8320-24e75afd3c84", "af50a139-ebf0-4c7d-a3bb-b60e00e94942", "b6cae174-5805-4b8c-bdfb-a9884e3fec7e", "baf016f6-8f1d-406e-af74-c071cff31953", "d969305c-2643-427d-a873-c083d1e7f866", "da235f44-0e10-40f5-85a5-19768431c579", "e1830ccd-c30a-480d-926b-d055408b6783", "ee7c1b2b-ba60-40b1-b5d6-7a25966a933d", "f35d792d-1dc1-4acb-82e0-bbb3d9b384be"], "title": "Using group selection to evolve leadership in populations of self-replicating digital organisms", "venue": "genetic and evolutionary computation conference", "year": 2007, "id": "c4004aa0-d9d5-48e3-b264-136084d5fe18"}
{"abstract": "This paper presents a system for assisting in human identification using dental radiographs. The goal of the system is to archive antemortem (AM) dental images and enable content-based retrieval of AM images that have similar teeth shapes to a given postmortem (PM) dental image. During archiving, the system classifies the dental images to bitewing, periapical, and panoramic views. It then segments the teeth and the bones in the bitewing images, separates each tooth into the crown and the root, and stores the contours of the teeth in the database. During retrieval, the proposed system retrieves from the AM database the images with the most similar teeth to the PM image based on Hausdorff distance measure between the teeth contours. Experiments on a small database show that our method is effective for dental image classification and teeth segmentation, provides good results for separating each tooth into crown and root, and provides a good tool for human identification.", "authors": ["Jindan Zhou", "Mohamed Abdel-Mottaleb"], "n_citation": 127, "references": ["1be0af41-65a8-4b10-bd0c-76fd977652bc", "3b3d7569-08b1-4017-9910-2a017a00e43e", "667ed5ec-3a1b-4dfd-97ad-be5158f14574", "8bdb15c3-93fe-4448-8067-a87d8270b8b6", "96cf1253-741c-4c31-a1ec-a35e7a9e104d", "a7956261-026b-437c-bda7-b57849df8131", "be3dc921-98bb-4c9a-999c-0d9ef826dd56", "cfbdd903-d600-48a2-9ad5-f4f0483c3a9f", "d9752a5a-1603-45cc-9a21-7997750d429f", "e227f723-650b-4b40-984b-2ee38d205a94"], "title": "A content-based system for human identification based on bitewing dental X-ray images", "venue": "Pattern Recognition", "year": 2005, "id": "20e544a8-cb16-46ef-af8c-0cfe6afa18e4"}
{"abstract": "In this paper we describe and analyse an algorithm for solving the satisfiability problem. If E is a boolean formula in conjunctive normal form with n variables and r clauses, then we will show that this algorithm solves the satisfiability problem for formulas with at most k literals per clause in time O(|F|.@a\"k^n), where @a\"k is the greatest number satisfying @a\"k = 2-1/@a\"k^k^-^1 (in the case of 3-satisfiability @a\"3 = 1,6181).", "authors": ["Burkhard Monien", "Ewald Speckenmeyer"], "n_citation": 361, "references": ["72bc81b3-b0b9-48d0-8471-0db3a399360a", "8d09527f-b5ad-4902-ba34-5583f6759d3b"], "title": "Solving satisfiability in less than 2n steps", "venue": "Discrete Applied Mathematics", "year": 1985, "id": "621a09e2-30e3-4ad9-a568-b617a10e03b0"}
{"abstract": "We present a simple proof of the strong converse for identification via discrete memoryless quantum channels, based on a novel covering lemma. The new method is a generalization to quantum communication channels of Ahlswede's (1979, 1992) approach to classical channels. It involves a development of explicit large deviation estimates to the case of random variables taking values in self-adjoint operators on a Hilbert space. This theory is presented separately in an appendix, and we illustrate it by showing its application to quantum generalizations of classical hypergraph covering problems.", "authors": ["Rudolf Ahlswede", "Andreas Winter"], "n_citation": 318, "references": ["3f0445fa-deb9-41ae-9da2-b8c63b21aee2", "41df37fa-9f7a-4eac-83af-43e8b62da1fd", "bf139b19-0a02-421c-96b7-e6cc7c2c8dd4", "c4c5dd6b-4a0c-4af5-98d0-f6692051df5d", "dfbd0a42-92ca-45ad-a55c-8116dc8dcb08"], "title": "Strong converse for identification via quantum channels", "venue": "IEEE Transactions on Information Theory", "year": 2002, "id": "81591b41-b15b-4fe9-9790-372b7f0cc220"}
{"abstract": "Pizza is a strict superset of Java that incorporates three ideas from the academic community: parametric polymorphism, higher-order functions, and algebraic data types. Pizza is defined by translation into Java and compiles into the Java Virtual Machine, requirements which strongly constrain the design space. Nonetheless, Pizza fits smoothly to Java, with only a few rough edges.", "authors": ["Martin Odersky", "Philip Wadler"], "n_citation": 655, "references": ["09512e32-2003-40b3-b2d1-7c2dfc56c7c6", "12709baf-bcff-41c8-b38f-8b97bc3ea162", "1cc071b5-2460-4213-b32b-973671d2b85a", "37435dbe-5dee-47db-9cd2-61c0b883484e", "46e050ad-c758-47aa-81e5-1766c879f78a", "494a90b6-f5fd-41c9-ae03-fe9db3161224", "723f64e8-a7b3-4bbb-b75f-6a3ad5ac5ace", "7c59931e-f1e7-4ca4-8262-1303b45e7c97", "7f1dc63a-9064-4768-a30d-3383d52aa81e", "8cd10b70-98c3-47fa-88a8-b846b67a41f1", "a2adb7fa-85a5-4682-83f1-2c119e61e874", "a42b0711-68b1-4490-8eda-bbcffb00921d", "bad54083-f2f9-4d6d-b7ff-a51bcd3ebe61", "cc8c6d18-aa46-43bf-9ee8-0a47552c9c0c", "e435c51c-247b-4386-8238-0f4d5d754eca", "e57b8a47-6205-4335-bf38-a22383b02e0e"], "title": "Pizza into Java: translating theory into practice", "venue": "symposium on principles of programming languages", "year": 1997, "id": "7eabc6ca-8c4b-46e4-b331-89058cae69da"}
{"abstract": "This paper describes a formulation of reinforcement learning that enables learning in noisy, dynamic environments such as in the complex concurrent multi-robot learning domain. The methodology involves minimizing the learning space through the use of behaviors and conditions, and dealing with the credit assignment problem through shaped reinforcement in the form of heterogeneous reinforcement functions and progress estimators. We experimentally validate the approach on a group of four mobile robots learning a foraging task.", "authors": ["Maja J. Matari\u0107"], "n_citation": 178, "references": ["079090cb-9ba8-419b-845c-7cccb6039da3", "10faea31-cb77-4a47-8ec5-42f51c56c284", "28c262c0-26b2-40c7-bf25-28b9a435659a", "3131d585-bb14-4a85-b270-d84f0a161bfd", "31d0e298-50eb-4cc2-9487-60efe76b7649", "50529eab-b6cb-45ce-8101-4919d325ead2", "593bb176-2e01-43fb-90fe-930b9b4d4b89", "8becbd5e-6fb1-41a6-b7a9-f0639bc3c3ee", "98628033-2948-4f30-b6de-4364cb7a646e", "9d6572a0-9402-494c-8c9c-70e2a94d1ade", "cf8a9eb7-4701-4c1a-84ad-3d5b53117f60", "d74bf856-0301-431c-a5cf-e5e0f61a528d"], "title": "Reinforcement learning in the multi-robot domain", "venue": "Autonomous Robots", "year": 1997, "id": "374e5ebf-7e10-4825-a470-a462843125f6"}
{"abstract": "Minimizing a convex function over a convex set in  n -dimensional space is a basic, general problem with many interesting special cases. Here, we present a simple new algorithm for convex optimization based on sampling by a random walk. It extends naturally to minimizing quasi-convex functions and to other generalizations.", "authors": ["Dimitris Bertsimas", "Santosh Vempala"], "n_citation": 89, "references": ["17e7a3e8-3a9e-40b0-90b1-c1c5626d5933", "21b149a7-c96d-4f98-9780-968ad4c0da35", "23f04aaa-c3b2-492c-b6fb-a6cff8df2d52", "5ea6138a-7916-4838-91ed-be183e0c2e5e", "6a059e3f-a77e-44f8-9bb0-01ec6ae44ec8", "7c2d506e-d211-4999-9e4f-590642ce1456", "9822140a-e1c3-45b8-965b-c1c1ae40bbf6", "c2c2ebb1-5528-42f2-a357-79599fb6f790", "dc522008-6b65-4ab0-99e3-a92f0e103933"], "title": "Solving convex programs by random walks", "venue": "Journal of the ACM", "year": 2004, "id": "23cf01b2-a2fb-4724-9ad4-7521d43b2007"}
{"abstract": "Using a limited version of Estelle, from which a specification can be represented in terms of an Extended Finite State Machine (EFSM), we develop a technique to generate conformance tests which test both the data flow as well as the control flow. From the EFSM, we generate a Finite State Machine (FSM) with several transitions corresponding to a single transition of the EFSM. Moreover, the input and output parameters are also modified so that an \u201cequivalent\u201d FSM is obtained. The data flow graph (DFG) is constructed directly from the \u201cequivalent\u201d FSM. Test segments are obtained from the data flow graph as well as from the control flow graph and are combined \u201ccarefully\u201d to generate an executable test sequence. Test data for the above sequence is chosen using a mutation technique to guarantee detection of specific kinds of faults in the data flow. Control flow is tested in the conventional way.", "authors": ["Raymond E. Miller", "Sanjoy Paul"], "n_citation": 53, "references": ["190d21f3-7b6b-40c0-925f-18bb21e3b7f4", "2ac5fedd-db52-4207-ac12-b527da60b604", "a7122806-c66c-49e6-8876-70093d70f605", "b99b41f6-d8ad-4738-b1a4-f4944074be21", "cf752ca1-6232-4a5d-8fda-7dd7cb70e405", "f06db88b-9c4f-4f93-ab13-75adafe02f86"], "title": "Generating Conformance Test Sequences for Combined Control and Data Flow of Communication Protocols", "venue": "", "year": 1992, "id": "03c5be46-37f3-4ab3-b1ef-994c2c13b88d"}
{"abstract": "The highly-publicized division error in the Pentium has emphasized the importance of formal verification of arithmetic circuits. Symbolic model checking techniques based on binary decision diagrams (BDDs) have been successful in verifying control logic. However, lack of proper representation for functions that map boolean vectors into the integers has prevented this technique from being used for verifying arithmetic operations. We have developed a new technique for verifying arithmetic circuits. The new technique, called word level model checking, has been used successfully to verify circuits for division and square root computation that are based on the SRT algorithm used by the Pentium. The technique makes it possible to handle both the control logic and the data paths in the circuit. The total number of state variables exceeds 600 (which is much larger than any circuit previously handled by other symbolic model checkers).", "authors": ["Edmund M. Clarke", "Manpreet S. Khaira", "Xudong Zhao"], "n_citation": 50, "references": ["2bb33756-67db-4329-8c0d-f3c5fdab2367", "4814eca2-167a-48bd-a7e6-60150e7a54e3", "54cc593a-837d-4c23-a44a-488acc2b75ea", "69ba35cb-dff5-4c86-9c9e-ace8c4e24846", "7b3c0ff0-951d-4433-b495-328b0fadb801", "80c30f5d-1bfd-4296-902b-4b538682ab04"], "title": "Word level model checking\u2014avoiding the Pentium FDIV error", "venue": "design automation conference", "year": 1996, "id": "b698a1f6-9d30-4328-9c06-3d1740a44b3a"}
{"abstract": "In this paper, we compare the performance of multiple-input-multiple-output (MIMO) techniques applied to indoor optical wireless communications (OWC) assuming line-ofsight (LOS) channel conditions. Specifically, several 4 \u00d7 4 setups with different transmitter spacings and different positions of the receiver array are considered. The following MIMO algorithms are considered: Repetition Coding (RC), Spatial Multiplexing (SMP) and Spatial Modulation (SM). Particularly, we develop a framework to analytically approximate the bit error ratios (BERs) of these schemes and verify the theoretical bounds by simulations. The results show that due to diversity gains, RC is robust to various transmitter-receiver alignments. However, as RC does not provide spatial multiplexing gains, it requires large signal constellation sizes to enable high spectral efficiencies. In contrast, SMP enables high data rates by exploiting multiplexing gains. In order to provide these gains, SMP needs sufficiently low channel correlation. SM is a combined MIMO and digital modulation technique. We show that SM is more robust to high channel correlation compared to SMP, while enabling larger spectral efficiency compared to RC. Moreover, we investigate the effect of induced power imbalance between the multiple transmitters. It is found that power imbalance can substantially improve the performance of both SMP and SM as it reduces channel correlation. In this context, we also show that blocking some of the links is an acceptable method to reduce channel correlation. Even though the blocking diminishes the received energy, it outweighs this degradation by providing improved channel conditions for SMP and SM. For example, blocking 4 of the 16 links of the 4 \u00d7 4 setup improves the BER performance of SMP by more than 20 dB, while the effective signal to noise ratio (SNR) is reduced by about 2 dB due to the blocking. Therefore, MIMO techniques can provide gains even under LOS conditions which provide only little channel differences.", "authors": ["Thilo Fath", "Harald Haas"], "n_citation": 218, "references": ["1713a56d-64f3-4736-9d74-7ad3478f4f01", "2659531e-eb9d-4dd5-b46f-10f66a4819c6", "42878cb5-aa58-43e5-835d-380747806a15", "43636d06-45f6-4710-b338-6792498bf242", "4b90bfba-4cb5-4e3f-967b-8cb5b82672a0", "6907b8b3-79fa-4587-bc15-9ae06acfcf1e", "748a2ab3-8b5f-4d0a-9e2d-af685089843a", "76c78e0e-971c-4f44-b50e-7d48dec08c83", "a3b76762-9b90-45e6-b94a-527f643c48df", "aead31ad-ed10-4a5f-9835-778d313951ed", "b315dd1f-b1ef-44bb-82a7-67418765260d", "c1361547-3ce5-453b-ba4c-ae4510362e35", "e3857304-85d4-4b16-964e-93ea708fcf88", "e77fe682-41ab-4ec6-a637-3682bc077878"], "title": "Performance Comparison of MIMO Techniques for Optical Wireless Communications in Indoor Environments", "venue": "IEEE Transactions on Communications", "year": 2013, "id": "05a65bfb-a452-4755-80f8-727d5c3dfc57"}
{"abstract": "The paper describes first results from the AutoMoDe (automotive model-based development) project. The project's overall goal is to develop an integrated methodology for model-based development of automotive control software, based on problem-specific design notations with an explicit formal foundation. Based on the existing AutoFOCUS framework (Huber, F. et al., 1997), a tool prototype is being developed in order to illustrate and validate the key elements of our approach.", "authors": ["Dirk Ziegenbein", "Peter Braun", "Ulrich Freund", "Andreas Bauer", "Jan Romberg", "Bernhard Sch\u00e4tz"], "n_citation": 20, "references": ["33656812-d386-470b-8df7-5b109f9e94a7", "60c269e1-1923-47cc-90be-3baa666dc257", "909d6dca-da57-4998-8fb8-31eeb577a16f", "980e31bb-0117-414f-8b8f-3ac211a21123"], "title": "AutoMoDe - Model-Based Development of Automotive Software", "venue": "design, automation, and test in europe", "year": 2005, "id": "dce50dfe-0fb9-4504-940d-29ffa3fca5c6"}
{"abstract": "Femtocells, despite their name, pose a potentially large disruption to the carefully planned cellular networks that now connect a majority of the planet's citizens to the Internet and with each other. Femtocells - which by the end of 2010 already outnumbered traditional base stations and at the time of publication are being deployed at a rate of about five million a year - both enhance and interfere with this network in ways that are not yet well understood. Will femtocells be crucial for offloading data and video from the creaking traditional network? Or will femtocells prove more trouble than they are worth, undermining decades of careful base station deployment with unpredictable interference while delivering only limited gains? Or possibly neither: are femtocells just a \"flash in the pan\"; an exciting but short-lived stage of network evolution that will be rendered obsolete by improved WiFi offloading, new backhaul regulations and/or pricing, or other unforeseen technological developments? This tutorial article overviews the history of femtocells, demystifies their key aspects, and provides a preview of the next few years, which the authors believe will see a rapid acceleration towards small cell technology. In the course of the article, we also position and introduce the articles that headline this special issue.", "authors": ["Jeffrey G. Andrews", "Holger Claussen", "Mischa Dohler", "Sundeep Rangan", "Mark C. Reed"], "n_citation": 890, "references": ["00d18ef6-0caf-49f5-86ca-4760a8b09902", "00d9b5b2-84a4-4340-b0df-8adf839caf59", "06d252d7-6086-4d52-b6ab-93f2ae4dad13", "07f51ac6-bd2c-4bc1-bd89-f5fe2e7da6a0", "0ed34d5e-cd39-4599-bc88-8294940b512e", "11ec16ac-8f6a-4986-86ca-98e65a05bf78", "12768218-4b78-4b7e-b39b-938e40fd855c", "16f33bda-4e3d-448f-9fc5-c4aa0729b454", "1d614245-ba9a-4c78-9953-92fff31aa08e", "1e4c2327-2a79-4c42-95bb-9a4264883c7a", "1f481b66-5583-4f7a-b61d-b438a9f4ca1a", "22521389-930a-48ea-8440-f6ddc7f84cde", "29f73484-64b8-4ac3-bf0e-473d3f13eb06", "2f868da0-740a-4dcb-a64f-93140f3cb7a3", "3f3cdc9b-b050-4a02-99ea-fb52ab69caad", "51195eff-e6f3-4663-ba67-d14014b27e95", "52dc957b-fc82-468c-94ce-54c1af3f4721", "54c06a0c-e55c-48c3-8e00-1baf7ef921d8", "54d364a6-fcf1-445d-bcc3-ca58c22f6973", "59c9c4b0-bc67-4d38-b286-e2018eb6b047", "5fc8645b-74b2-4153-81fc-e37dce3b0470", "6cc116fc-0c78-4f07-a063-977fe012c3c7", "6fb2278a-d754-4602-8d38-330bc9ebd2f5", "7669a390-1fe5-45d3-b44f-25b250ec373b", "76e3e450-1f42-45b1-b647-c5a55b30c01f", "79f71388-f9d6-4e07-bc0c-2b7be218d89d", "7e867bd8-4ffb-4dc6-8e36-5c1dfd81ec9d", "7f22dbe0-259e-4758-955f-cd53fef75f6e", "81690344-dfd7-4a73-8a26-425233b68496", "88a0c275-1fce-4f12-a40b-2472b871811e", "90e1da0a-cb9e-4002-8489-7ac1301341c8", "94a8f960-9395-43bf-9867-032c8bddb798", "97c00129-d026-42ad-8ef9-54f8ae5358f0", "a09b89ad-a51d-4e0e-9120-7ec3212caba4", "a5e2f568-ca55-43a9-8930-3649bb39c7ca", "a6057357-3441-4764-a535-4aa7d5b9fc3b", "a8df8e98-dfa8-4bac-8063-72fe16a4f312", "ac57fe4a-713d-4035-91f1-36ca116dec00", "b06d656b-d59f-4901-96ad-7a1b30353868", "b1d44866-904a-45a0-970e-a2698293f9a7", "b2d2a210-8641-4020-aafd-091cd928af45", "b6235459-e32d-4f5a-ac4d-55484f6bc937", "b6f8fc00-3f73-407b-9592-c197f6abc1aa", "b8220a0e-e7ed-4ddb-83fd-5b5ebc778ab5", "bafc7a50-96c6-4508-a91f-1dc736f1cc6f", "c30c73a4-32af-4b53-a2e6-d51eefe5c82e", "c3a7204d-51fc-45c9-9cce-5bcf9e81d566", "c5498c46-8fcb-4794-a369-1048d7e15b37", "c611afd8-59b1-453d-8360-1926bea3fa96", "caa765b3-157e-4ca1-a94c-39ae6e8a45c7", "cb367c27-7b4c-4c55-a4b8-55e9e4563018", "d18837ea-1c26-4b70-bcbe-286c43c4aacd", "dcd812e1-c513-499a-ae5f-fb4b8f95f0df", "e03e87c0-54ef-423f-82a9-7f10ca4a00b2", "e9fcc0dd-bbeb-4177-8335-c8c1243e8600", "ec8e1342-0474-44d5-8977-003fe59e9128", "ee5ade02-a3eb-4ec6-89b5-032a1572c8ca", "ee7bd256-d41c-4979-8319-394f5fde183b", "ef708533-4801-4a44-974b-5feb7e9da3d0", "f2ea878d-47b1-4e4c-8b80-b2d79cc245b7", "f62413a7-bbd6-483e-a16c-dbc08a54262b", "fad1afc9-6dce-482b-bb36-eca2385c9d10", "ff276f02-0074-4b41-98f9-b873d705113d", "ff56835b-e3b8-4a86-8510-917c6bb58d84"], "title": "Femtocells: Past, Present, and Future", "venue": "IEEE Journal on Selected Areas in Communications", "year": 2012, "id": "2d4a27f2-1420-472d-9444-1d91d73ffd1a"}
{"abstract": "Abstract In this paper, a robust algorithm that discriminates various eye motions from the ElectroOculoGram (EOG) signals is proposed. Previous researches that use the EOG only focused on saccadic motions or blinks. However, we cover all eye motions including double/triple blinks and left/right winks. Furthermore, we suggest a novel method, which removes noises of the EOG, to increase the robustness of the discrimination. The method is called \u201can ideal velocity shape algorithm\u201d which compares the real velocity of the EOG with an ideal velocity designed under a noise free assumption. This algorithm significantly reduces the effects of the noises and thus enhances the robustness. Detected eye motions are used for aHuman-Computer Interaction (HCI) between a person and a mobile robot. In the HCI, the person successfully controlled the robot for a target tracking and point stabilization.", "authors": ["Young-Min Kim", "Nakju Lett Doh", "Youngil Youm", "Wan Kyun Chung"], "n_citation": 31, "references": [], "title": "Robust discrimination method of the electrooculogram signals for human-computer interaction controlling mobile robot", "venue": "Intelligent Automation and Soft Computing", "year": 2007, "id": "83bd2f7c-93cf-4a41-8b3f-7b01c1b9c316"}
{"abstract": "This paper exemplifies how better knowledge about human judgement strategies known as heuristics can be used to improve software processes, especially estimation and prediction processes. Human judgement heuristics work well when they exploit a fit between their structure and the structure of the environment in which they are used. This use of environmental fit may lead to amazingly good judgements based on little information and simple computations compared with more formal approaches. Sometimes, however, the heuristics may lead to poor judgements. Knowing more about the strengths and weaknesses of human judgement heuristics we may be able to (1) know when to use formal process improvement approaches and when to use less expensive expert judgements, (2) support the experts in situations where the experts\u2019 judgements strategies are known to perform poorly, (3) improve the formal processes with elements from the experts\u2019 strategies, and (4) train the experts in the use of more optimal judgement strategies. A small-scale experiment was carried out to evaluate the use of the representativeness heuristic in a software development effort estimation context. The results indicate that the actual use of the representativeness heuristic differed very much among the estimators and was not always based on an awareness of fit between the structure of the heuristic and the structure of the environment. Estimation strategies only appropriate in low uncertainty development environments were used in high uncertainty environments. A possible consequence of this finding is that expert estimators should be trained in assessing how well previous software projects predict new software projects, i.e., the uncertainty of the environment, and how this uncertainty should impact the estimation strategy.", "authors": ["Magne J\u00f8rgensen", "Dag I. K. Sj\u00f8berg"], "n_citation": 17, "references": ["58fd18b5-10fe-4037-8849-cfd34a819813", "73992d60-fec1-4b79-a6af-68b709982156", "840ff58a-8feb-414b-9f2e-22f1fee9e5e5", "b53d7e72-ec62-4cb1-bb03-591c0b01137e", "d4c3a0a8-80f6-4450-b678-639692543e25", "d712970f-941b-4809-85f9-ae41fd710589"], "title": "Software Process Improvement and Human Judgement Heuristics", "venue": "Scandinavian Journal of Information Systems", "year": 2001, "id": "30885179-c1f3-4264-a601-5b36479d1e7f"}
{"authors": ["Jes\u00fas Gim\u00e9nez", "Llu\u00eds M\u00e0rquez"], "n_citation": 109, "title": "Fast and accurate part-of-speech tagging: The SVM approach revisited.", "venue": "recent advances in natural language processing", "year": 2003, "id": "ea37a7ce-e944-43a8-b695-965a163a8f14"}
{"abstract": "Abstract#R##N##R##N#The effective and explicit management of knowledge has been presented as a key factor in the survival of companies in current business environments. The software development business is no different. The authors of this paper investigated two software processes in three small software development companies to identify the explicit and tacit knowledge management in these processes. They examine their findings under the four knowledge management categories of creation, storing, sharing and leverage. In many cases, while the knowledge exists, it is not made explicit within the organization. Making the knowledge explicit should make the software processes more effective. Therefore, the authors make recommendations for the small software development company as to how to do this. Whether this approach can ultimately help the small software development company to move to higher levels of maturity is a research question which needs to be further explored. Copyright \u00a9 2003 John Wiley & Sons, Ltd.", "authors": ["Bridget Meehan", "Ita Richardson"], "n_citation": 64, "references": ["94b70143-3504-48f9-95fb-e7072677e47f"], "title": "Identification of Software Process Knowledge Management", "venue": "Software Process: Improvement and Practice", "year": 2002, "id": "f5bfdfbf-236e-4f72-a204-aa5b96cb1f17"}
{"abstract": "Software metrics collected during project development play a critical role in software quality assurance. A software practitioner is very keen on learning which software metrics to focus on for software quality prediction. While a concise set of software metrics is often desired, a typical project collects a very large number of metrics. Minimal attention has been devoted to finding the minimum set of software metrics that have the same predictive capability as a larger set of metrics \u2013 we strive to answer that question in this paper. We present a comprehensive comparison between seven commonly-used filter-based feature ranking techniques (FRT) and our proposed hybrid feature selection (HFS) technique. Our case study consists of a very highdimensional (42 software attributes) software measurement data set obtained from a large telecommunications system. The empirical analysis indicates that HFS performs better than FRT; however, the Kolmogorov-Smirnov feature ranking technique demonstrates competitive performance. For the telecommunications system, it is found that only 10% of the software attributes are sufficient for effective software quality prediction.", "authors": ["Huanjing Wang", "Taghi M. Khoshgoftaar", "Kehan Gao", "Naeem Seliya"], "n_citation": 50, "references": ["092e30d2-667d-409b-b3e1-3cbe1f17eb48", "182b6988-6b10-48cc-aacf-69ccc96e30a8", "19d8e565-399d-47a8-bd30-8ff4fe857892", "21ffae8e-2406-4e5e-b1e1-e6a0f9a82bf1", "2cf370f6-2ade-4dae-bcde-d7d3703931b9", "2f02c44e-db7a-4359-9526-a54292179d3b", "327b458f-21f3-4977-a62c-6aae3eaa9a08", "4935259d-fca4-454d-9128-6dfed1c72357", "4fb87930-7f6c-4f03-ae22-32445138ec83", "4fbc97ff-6338-45d2-9eb0-26398a40a2c3", "82449887-fb2b-4a29-9b12-0c8e078d1e67", "92694cd0-03cc-43e9-ace6-a0279242d6be", "ac237969-3fd5-4303-83b7-a67e02afe976", "b61f0c35-2131-46c4-866f-3138f6b726ff", "ce028c76-6040-4f87-b8e7-d6741ce9d1c4", "dc71af5b-b124-4717-87e9-dd0610b74154"], "title": "High-Dimensional Software Engineering Data and Feature Selection", "venue": "international conference on tools with artificial intelligence", "year": 2009, "id": "2d574af3-3639-49fa-a4a0-13a44406873c"}
{"abstract": "An extension of the backstepping approach is proposed. It allows to globally asymptotically stabilize by bounded feedbacks families of nonlinear control systems. Explicit expressions of control laws and Lyapunov functions are given.", "authors": ["Fr\u00e9d\u00e9ric Mazenc", "Abderrhaman Iggidr"], "n_citation": 57, "references": ["233bbbb3-8501-4af9-903f-c906150be3d2"], "title": "Backstepping with bounded feedbacks", "venue": "Systems & Control Letters", "year": 2004, "id": "a881a2ba-0bb4-4735-8f66-3a49041e32ff"}
{"authors": ["Martin Farach", "Mikkel Thorup"], "n_citation": 75, "references": ["0b6419e0-ba97-468c-bc05-07920c7d0de2", "5e02c3f9-4b76-4c02-9f6b-d9b59abdfa68", "5f3aec18-993b-4ec0-ad69-df019fb83866", "82bcf02d-0db4-4dbd-a03e-dbbf0bd7c37b", "af02e640-7400-4d50-befb-c667e8d20b7a"], "title": "Fast comparison of evolutionary trees", "venue": "symposium on discrete algorithms", "year": 1994, "id": "09581af8-91c1-4364-8ca7-7cc17f3fda05"}
{"abstract": "This paper addresses the problem of mapping likely locations of a chemical source using an autonomous vehicle operating in a fluid flow. The paper reviews biological plume-tracing concepts, reviews previous strategies for vehicle-based plume tracing, and presents a new plume mapping approach based on hidden Markov methods (HMM). HMM provide efficient algorithms for predicting the likelihood of odor detection versus position, the likelihood of source location versus position, the most likely path taken by the odor to a given location, and the path between two points most likely to result in odor detection. All four are useful for solving the odor source localization problem using an autonomous vehicle. The vehicle is assumed to be capable of detecting above threshold chemical concentration and sensing the fluid flow velocity at the vehicle location. The fluid flow is assumed to vary with space and time, and to have a high Reynolds number (Re>10).", "authors": ["Jay A. Farrell", "Shuo Pang", "Wei Li"], "n_citation": 133, "references": ["041ac445-ddeb-4688-8735-68d06cb92696", "182e49d1-a337-42f6-baee-37fc9712c302", "3595fa71-68db-476e-9cb7-ad6ece6f446e", "a904e074-bf2e-4a61-a701-3477b8f9413c", "d55756b9-80be-43b6-90e6-58c390630bc5"], "title": "Plume mapping via hidden Markov methods", "venue": "systems man and cybernetics", "year": 2003, "id": "d9e9debe-7c26-4d18-a82f-06cde9f38161"}
{"abstract": "A proper tire friction model is essential to model overall vehicle dynamics for simulation, analysis, or control purposes since a ground vehicle's motion is primarily determined by the friction forces transferred from roads via tires. Motivated by the developments of high-performance antilock brake systems (ABSs), traction control, and steering systems, significant research efforts had been put into tire/road friction modeling during the past 40 years. In this paper, a review of recent developments and trends in this area is presented, with attempts to provide a broad perspective of the initiatives and multidisciplinary techniques for related research. Different longitudinal, lateral, and integrated tire/road friction models are examined. The associated friction-situation monitoring and control synthesis are discussed with a special emphasis on ABS design", "authors": ["Li Li", "Fei-Yue Wang", "Qunzhi Zhou"], "n_citation": 188, "references": ["2c53d0e8-8801-426e-93b3-879ab3d3ae05", "32697c09-a613-43d0-a327-41aa5d67ae74", "3a053470-f1b9-4f77-9489-2a8c44269b1e", "40d59477-4b6e-4b6c-bf41-ae9ed8ad21a1", "5defba78-6337-4b89-b3af-daeb1ce8d303", "65035af3-c560-4d10-a53e-67cbcfafcda4", "89c9db7a-8cc3-4e25-b821-a2a48e6b8558", "8bcfa06b-f64f-4238-ad61-7636ca520de9", "a20e7f23-11d1-409a-ad9f-f87d95b560d8", "b0e530e7-81ad-4d03-a9b3-8a01c3f1e7f6", "cc131f7e-0ca3-43e9-a8c8-e4d00d5a9e71", "cfb56e19-2bbe-4df0-9fbe-d5fd9a5e19dc", "d7d31c74-0c87-4efd-83e6-1f06d81d5519", "e45cf849-26e3-4ba2-aecc-c9d5fb68d396", "f1f0a6ed-45da-4590-b462-b08ac41069fe"], "title": "Integrated longitudinal and lateral tire/road friction modeling and monitoring for vehicle motion control", "venue": "IEEE Transactions on Intelligent Transportation Systems", "year": 2006, "id": "5fed554f-421a-4fb2-ae86-244079078cd7"}
{"abstract": "This paper proposes an adaptation of classical image-based visual servoing to a generalised imaging model where cameras are modelled as sets of 3D viewing rays. This new model leads to a generalised visual servoing control formalism that can be applied to any type of imaging system whether it be multi-camera, catadioptric, non-central, etc. In this paper the generalised 3D viewing cones are parameterised geometrically via Plucker line coordinates. The new visual servoing model is tested on an a-typical stereo-camera system with non-overlapping cameras. In this case no 3D information is available from triangulation and the system is comparable to a 2D visual servoing system with non-central ray-based control law.", "authors": ["Andrew I. Comport", "Robert E. Mahony", "Fabien Spindler"], "n_citation": 50, "references": ["01daa706-d962-4429-979a-e6d7015496ed", "055010e0-3747-4613-97b9-17e9e651f890", "15a02cd1-ea97-47c8-ac88-019d350aa88e", "17146693-b9be-4a3b-b383-c5b9af987532", "19020f53-3cb8-41ec-a653-a4661d0e2330", "1a2a7ad5-e535-45b8-8fef-918f5370622e", "1fb0afb5-43bf-4b55-a9be-fa27f6a61560", "2a3f0996-bf74-4a04-a144-3109ebfcb4dc", "35bc5933-526c-4b70-a0d4-ba59dd042ef3", "38a2cc31-1b8d-4a71-a5eb-7ff67be9d4b7", "3c8c9b68-e229-4143-9b23-85d02d92f223", "4bec656a-2f84-4166-aa09-c2780e3ac811", "5b7dc3c7-b810-472f-8f50-25f4bca87678", "740d149e-bc92-43fc-912c-a4ea44e46504", "7f4af4d2-61a4-4bcb-a663-e76c99f0ed9f", "99a5fa3a-b423-4106-a40d-569f6a4af300", "b6dcb26b-a433-4b48-8a5a-1822862001f0", "d2ad319a-4f38-4bc0-9708-0c9b9b05c7ba", "dbf78aff-2d5f-4caa-a797-2719ae1e4812", "e41bbdfc-35ef-4a59-bf07-915d1a7233ca", "f7f252f3-9986-4d3c-930e-c1c9174b3efc", "f9f306ad-4135-48e5-b976-1b2a9cb3e5c4"], "title": "A visual servoing model for generalised cameras: Case study of non-overlapping cameras", "venue": "international conference on robotics and automation", "year": 2011, "id": "db79a9bb-ec71-4813-b755-0fc85ab20351"}
{"authors": ["Kian-Lee Tan", "Pin-Kwang Eng", "Beng Chin Ooi"], "n_citation": 853, "references": ["510eec1d-f82c-4b19-b116-b8fd4c66531a", "525eb23e-8abe-4d70-89c5-e8765ef4b57f", "687f9a0a-5194-42c4-b757-1df797c4f602", "a3b93498-d489-41da-9bbf-2d87f1d3006f", "a766029a-4dd6-4b52-8c79-6daf6cdb5abd"], "title": "Efficient Progressive Skyline Computation", "venue": "very large data bases", "year": 2001, "id": "c88d0ba0-b726-4ebc-aef7-ad7068e3eaae"}
{"abstract": "Many existing rating systems for goods or services simply total the number of good and bad evaluations reported by the consumers when generating the ratings. These systems, however, make it difficult to create really reliable reports since there is no incentive for the evaluators to provide accurate or truthful reports. This paper proposes to introduce an index that represents the trust we can place on the evaluator. This index increases if the evaluator's past estimation of the reputation of goods or service is subsequently found to be true. An evaluator who earns a higher index score has more impact on the rating system. This mechanism generates fairer and more objective ratings.", "authors": ["Ko Fujimura", "Takuo Nishihara"], "n_citation": 20, "references": ["178850eb-ce3c-41eb-a905-d137a26a39e8", "d29c4aa5-1049-41e7-925f-73527afbb3e4"], "title": "Reputation rating system based on past behavior of evaluators", "venue": "electronic commerce", "year": 2003, "id": "d3b3f02f-e6ad-43da-a5b7-ff5f6ebf9e88"}
{"abstract": "In classification, machine learning algorithms can suffer a performance bias when data sets are unbalanced. Data sets are unbalanced when at least one class is represented by only a small number of training examples (called the minority class), while the other class(es) make up the majority. In this scenario, classifiers can have good accuracy on the majority class, but very poor accuracy on the minority class(es). This paper proposes a multiobjective genetic programming (MOGP) approach to evolving accurate and diverse ensembles of genetic program classifiers with good performance on both the minority and majority of classes. The evolved ensembles comprise of nondominated solutions in the population where individual members vote on class membership. This paper evaluates the effectiveness of two popular Pareto-based fitness strategies in the MOGP algorithm (SPEA2 and NSGAII), and investigates techniques to encourage diversity between solutions in the evolved ensembles. Experimental results on six (binary) class imbalance problems show that the evolved ensembles outperform their individual members, as well as single-predictor methods such as canonical GP, naive Bayes, and support vector machines, on highly unbalanced tasks. This highlights the importance of developing an effective fitness evaluation strategy in the underlying MOGP algorithm to evolve good ensemble members.", "authors": ["Urvesh Bhowan", "Mark Johnston", "Mengjie Zhang", "Xin Yao"], "n_citation": 89, "references": ["11685c96-7a83-48ec-af6d-8b2910ba6311", "11bf32d0-5bd5-4714-9a61-ccc8bd05b6ed", "1409ed0b-3982-476c-8dc3-18bc36bf9202", "1ca19102-96fb-4b4b-a469-88ad17f36b11", "253d2647-3561-4dd3-ae0d-b3a22468b9a5", "2a8fdcde-5301-4977-8121-2be189ce6693", "2b612a49-10e1-4d1d-928a-80e2bfb002f9", "2ca3cac1-99ee-425a-a62c-3b5f82d4b8d0", "3127a977-8822-4850-8a7a-e044f02bd0f7", "33fa6959-74fe-49ef-a729-19f522b4b519", "37c2f68f-51d9-4a2b-85b3-63f4c46155c9", "40ab97bc-ab6b-44f9-bbd6-5667394ee34a", "456fcf70-3e42-42f8-acc0-05011194e70d", "4ad0ec01-9108-4155-9b83-a3b7b32116c5", "56479493-6d36-418e-a0d2-76e4601e0521", "5bf5988b-6b06-4dcb-862e-a33570cce668", "5cc34537-57e7-46f5-9e4d-dfa550090502", "648e33cb-036f-4b06-a645-488bd3f5123c", "65d5ccdc-7022-45b0-adf9-0385273b1283", "6c871065-76b8-44f3-97d5-ac3bce951421", "756c083a-7673-4dd1-adcb-57e1484322db", "7e45b406-4ee0-467f-acc6-8c31ed9d1315", "8026f56a-a93e-4933-8ead-c9aa9e3f0498", "87b6c1da-c179-412e-8934-228784c9c82b", "94fc2478-2bdf-427e-b3fd-055daa2674ff", "a73daf01-7d5b-433b-8ddf-e255761a0ebc", "a93d83fc-7fdd-4d7b-a266-1a9fa01996da", "ac5b04c8-f911-4611-88e7-03ca9c10f651", "b2559e2b-4870-444b-a63e-90fc33387955", "bcdb7caf-03b7-4b54-a9e6-08e7692c3f01", "c061069f-29d1-46d4-9974-dede8d5461f9", "c4ced251-1bec-407b-99fa-7629a9f8229f", "c5665ad6-daa3-4bfe-9cff-8838d8aeaa5b", "c894d353-eb12-4d27-8418-e6668e393802", "e167c4c0-bd40-4867-baed-fa27e0139ee9", "e394356e-0c8d-4eb5-bff3-52a6da333bd0", "e61b6fa6-6e08-47e2-ae77-adcde48e750e", "ef37f76a-507e-4fa7-bf34-a46ce477d4a4", "f30c9881-2001-43ac-bbc0-35ab18c92bcd", "fffa0e5e-2163-4465-ad66-5816e9ed7f0e"], "title": "Evolving Diverse Ensembles Using Genetic Programming for Classification With Unbalanced Data", "venue": "IEEE Transactions on Evolutionary Computation", "year": 2013, "id": "dfa193e5-3b9f-4438-ab71-54813cc13299"}
{"authors": ["Sture H\u00e4gglund"], "n_citation": 50, "references": ["7a34c634-8e5e-4b05-80f0-0afc62c25c9a", "8f6c698c-e643-4a6f-902a-63ed999f45e8", "d33fe94e-a7dc-4e2d-8d56-2765d94888d6"], "title": "Introducing expert critiquing systems", "venue": "Knowledge Engineering Review", "year": 1993, "id": "bd642361-a891-4f9b-a9b0-4a9ce819c9e1"}
{"abstract": "We present a system for the whole road sign detection and recognition task. Road sign regions are detected and extracted from real-world scenes on the basis of their color and shape features. Color segmentation is performed introducing a dynamic threshold in the pixel aggregation process on the HSV color space. The dynamic threshold allows the reduction of hue instability in real scenes depending on external brightness variation. Experimental results, using real road images in different environment conditions, are also reported.", "authors": ["Salvatore Vitabile", "Giorgio Pollaccia", "Giovanni Pilato", "Filippo Sorbello"], "n_citation": 138, "references": ["20bb101f-8261-4c77-be03-b48094d1326c", "4259da16-cec2-4dcb-889e-3b90e46f39a8", "a31a9b9b-7b31-49a5-b192-8a37069680e0"], "title": "Road signs recognition using a dynamic pixel aggregation technique in the HSV color space", "venue": "international conference on image analysis and processing", "year": 2001, "id": "e50ef0f8-9eef-4724-ba89-0e7d63375d48"}
{"abstract": "A new multichannel MAC protocol called hop-reservation multiple access (HRMA) for wireless ad-hoc networks (multi-hop packet radio networks) is introduced, specified and analyzed. HRMA is based on simple half-duplex, very slow frequency-hopping spread spectrum (FHSS) radios and takes advantage of the time synchronization necessary for frequency-hopping. HRMA allows a pair of communicating nodes to reserve a frequency hop using a reservation and handshake mechanism that guarantee collision-free data transmission in the presence of hidden terminals. We analyze the throughput achieved in HRMA for the case of a hypercube network topology assuming variable-length packets, and compare it against the multichannel slotted ALOHA protocol, which represents the current practice of MAC protocols in commercial ad-hoc networks based on spread spectrum radios, such as Metricom's Ricochet system. The numerical results show that HRMA can achieve much higher throughput than multichannel slotted ALOHA within the traffic-load ranges of interest, especially when the average packet length is large compared to the duration of a dwell time in the frequency hopping sequence, in which case the maximum throughput of HRMA is close to the maximum possible value.", "authors": ["Zhenyu Yang", "J. J. Garcia-Luna-Aceves"], "n_citation": 293, "references": ["0b93552e-74e8-483f-82cb-5c04e1cd9232", "795ac717-1d24-4688-84c5-984d615cfcc6"], "title": "Hop-reservation multiple access (HRMA) for ad-hoc networks", "venue": "international conference on computer communications", "year": 1999, "id": "a6e8d7c2-13dd-4093-bf5f-aa8f130f9151"}
{"abstract": "This paper presents a failure detection service (FDS) and a flexible failure handling framework (Grid-WFS) as a fault tolerance mechanism on the Grid. The FDS enables the detection of both task crashes and user-defined exceptions. A major challenge in providing such a generic failure detection service on the Grid is to detect those failures without requiring any modification to both the Grid protocol and the local policy of each Grid node. This paper describes how to overcome the challenge by using a notification mechanism which is based on the interpretation of notification messages being delivered from the underlying Grid resources. The Grid-WFS built on top of FDS allows users to achieve failure recovery in a variety of ways depending on the requirements and constraints of their applications. Central to the framework is flexibility in handling failures. This paper describes how to achieve the flexibility by the use of workflow structure as a high-level recovery policy specification, which enables support for multiple failure recovery techniques, the separation of failure handling strategies from the application code, and user-defined exception handlings. Finally, this paper presents an experimental evaluation of the Grid-WFS using a simulation, demonstrating the value of supporting multiple failure recovery techniques in Grid applications to achieve high performance in the presence of failures.", "authors": ["Soonwook Hwang", "Carl Kesselman"], "n_citation": 175, "references": ["08e02aa6-3ef9-4b25-8de6-a42ca9a60577", "18831dc8-e399-499d-8da1-a7befe5d7055", "349b1a29-5e0f-421e-b4f7-5290441be737", "41318979-3d2d-464e-85e4-372bdd6430c5", "46a3e9cb-d27b-498a-9762-1f9cd516bc48", "47d0e8d9-79e9-4584-bffb-35937bcd29d3", "493fd722-ed06-4a05-a44d-0fd76cfcacbd", "4f64e8a6-f9d8-4a10-ac03-000c235c09a6", "64472c04-d171-4b64-aef2-b21e9078d287", "735dedeb-a935-4e6e-b071-4f7e3edfebb8", "81807c20-6e70-4da3-9eef-61bff68534b3", "897ab9b6-59c8-4abb-8cee-00a707370165", "8ec189e8-5b8e-43a2-91a2-59b25ecc8f9f", "9553fde5-7523-4944-abb2-ce12a6d02afc", "9cdc54f0-f1a0-4422-ac16-d9164d9371ee", "a8c8d72a-c965-45df-8354-47c96bfb67d0", "a92a1d22-00d1-4ab7-81e7-32d8b2dd0453", "abb6e113-b288-46a1-91de-7b48a3cce765", "b6457b57-76f8-4d6e-afdd-594864aef737", "c2f67467-3138-4d37-a743-10340dc3ea44", "e9065010-fc6a-4170-8087-7c99eaa84b4c", "fd2c1d27-30e7-4004-a891-81062e14089f"], "title": "A Flexible Framework for Fault Tolerance in the Grid", "venue": "Journal of Grid Computing", "year": 2003, "id": "c40cbd53-bb10-47f8-b023-c5355ff6f8c6"}
{"abstract": "Support for the incremental design of aspects themselves has been neglected, even as the use of aspects in conjunction with underlying systems is gaining acceptance. The ways in which aspects can cooperate or interfere with each other need to be made explicit at the design level. An aspect architecture, a new software architecture viewtype, is proposed, and its general principles are explained. An instantiation for extending UML is described, where designs of aspects provide maximal flexibility, and a new  concern diagram  is provided to show how aspects can be combined to treat different concerns of a system. An example shows aspect architecture views of a digital sound recorder.", "authors": ["Mika Katara", "Shmuel Katz"], "n_citation": 134, "references": ["0c9bff7e-ec5c-4bbe-84bc-5fbc5ad88a08", "102dadec-d797-4d1c-a9da-4fa2035d2d6b", "1486864a-f785-433a-ba5d-ee64d9d3b33e", "217bf7fb-aa70-4360-8f15-ea52de6861a0", "367f9960-f1a4-44f6-aab5-5ccfef086b8d", "3ddb69c4-2d27-41c5-91fa-4f7e2c5ddcfb", "604822ac-cb3d-4f6b-bec0-735addd21851", "64c0a88a-65d2-435c-85fc-25a71934d4af", "827f5cff-5d69-4bd3-a514-ace157dd3327", "9152db9b-6e40-47ef-bff0-261f06ba0a6b", "9ee9bc73-e7c0-4b00-a8ea-53f953a2ca91", "b1ef94c8-9033-4481-8065-05f35b2ad063", "b42e41fe-9dc9-44c7-a80c-a35c6597039d", "c54cc73a-5797-43d8-b13a-a827dbad649d", "d6e6974e-9138-4f12-8e9b-239ad2c046f7"], "title": "Architectural views of aspects", "venue": "aspect-oriented software development", "year": 2003, "id": "686f31e5-3651-4857-aa44-b84336c5e41f"}
{"abstract": "Current Electronic Toll Pricing (ETP) implementations rely on on-board units sending fine-grained location data to the service provider. We present PrETP, a privacy-preserving ETP system in which on-board units can prove that they use genuine data and perform correct operations while disclosing the minimum amount of location data. PrETP employs a cryptographic protocol, Optimistic Payment, which we define in the ideal-world/real-world paradigm, construct, and prove secure under standard assumptions. We provide an efficient implementation of this construction and build an on-board unit on an embedded microcontroller which is, to the best of our knowledge, the first self-contained prototype that supports remote auditing. We thoroughly analyze our system from a security, legal and performance perspective and demonstrate that PrETP is suitable for low-cost commercial applications.", "authors": ["Josep Balasch", "Alfredo Rial", "Carmela Troncoso", "Bart Preneel", "Ingrid Verbauwhede", "Christophe Geuens"], "n_citation": 124, "references": ["029a26c6-fe23-4ede-b93f-1083f750b025", "038919b7-ac0a-4de7-b8f0-6a861a991388", "0cd8e313-cd1c-4dc1-9571-fd6289b43de8", "11992152-052a-46f2-bd24-014a5effd9b3", "1cd9c054-f5a3-4daf-8639-ae2ed9203cff", "287082dd-0ac7-42aa-bdcc-86378e384892", "2cb3b6dc-a667-4d1e-a2da-4288cfe1130d", "930e66eb-7f8f-439f-8a43-0f0efd9ab4f5", "9339c7e9-d9e0-47dd-b328-ae3c5ee64244", "93a8dead-8694-4e04-8732-9f1f72c4aa57", "9a6700e2-11ac-436f-8f08-057e78e9f585", "a64594fa-8c15-4d2c-aba2-d42878495f64", "ba4d1a67-fbc8-4ad7-8091-f286c105aa28", "c03d2f84-d383-4ba9-a430-c943bf1f9de4", "d893a420-a00d-4756-b447-2862ed178eaa", "ea30a9e7-8421-4cd3-8004-81dd4ccf7a43", "ed9fd379-3452-4101-8087-28b5794b1866"], "title": "PrETP: privacy-preserving electronic toll pricing", "venue": "usenix security symposium", "year": 2010, "id": "85dd7bd4-86cc-450c-bbe9-9facdc244ad8"}
{"authors": ["Markus Jakobsson"], "n_citation": 176, "references": ["0029dab5-4f99-4eee-8a20-9b11d88ae894", "0beff7f4-e56e-40e7-ae39-eb40c1f3751a", "1466a0e7-657f-42d5-941c-3632c5bebfd4", "1e756054-39bf-4670-830c-f4e20aebaf30", "24b09171-b17c-4f06-9a66-d6a0f5e0bf01", "2c33bdb1-6f8e-4453-8e10-5153056ae70f", "2d39758f-1b65-4a8e-8e87-bbfd0bfb98c5", "5debdfd0-1406-44ed-bd15-7c2e2b824135", "772da49e-1632-4f82-bdbd-996f928eddf9", "98f543e3-d61c-4099-ae96-237816472592", "ac0db18c-141b-499a-9499-bc11ed2a61bc", "c8d3bf01-8a69-4996-a524-5d93af937c57", "dcd41f70-c632-4e61-b6f4-da351c5b8612", "e1d20fe3-46b3-4fb1-a293-e36d292ad8d3"], "title": "Flash mixing", "venue": "principles of distributed computing", "year": 1999, "id": "89ca3305-259b-40ac-9f13-4737dd0aa460"}
{"abstract": "In this paper, we investigate what role the network topology plays when controlling a network of mobile robots. This is a question of key importance in the emerging area of human-swarm interaction and we approach this question by letting a human user inject control signals at a single leader-node, which are then propagated throughout the network. Based on a user study, it is found that some topologies are more amenable to human control than others, which can be interpreted in terms of the rank of the controllability matrix of the underlying network dynamics, as well as, measures of node centrality on the leader of the network.", "authors": ["Jean-Pierre de la Croix", "Magnus Egerstedt"], "n_citation": 24, "references": ["2768199c-b9d6-4001-94d3-e6429c93bc5f", "75a570b9-a94d-418d-84ea-b4bbf32ff04c", "ab35dc68-62bd-4c54-81d3-9a8406827489"], "title": "Controllability Characterizations of Leader-Based Swarm Interactions", "venue": "national conference on artificial intelligence", "year": 2012, "id": "d0174b9f-456c-4cac-86b7-b26b23d3ef04"}
{"abstract": "This article considers approaches which rerank the output of an existing probabilistic parser. The base parser produces a set of candidate parses for each input sentence, with associated probabilities that define an initial ranking of these parses. A second model then attempts to improve upon this initial ranking, using additional features of the tree as evidence. The strength of our approach is that it allows a tree to be represented as an arbitrary set of features, without concerns about how these features interact or overlap and without the need to define a derivation or a generative model which takes these features into account. We introduce a new method for the reranking task, based on the boosting approach to ranking problems described in Freund et al. (1998). We apply the boosting method to parsing the Wall Street Journal treebank. The method combined the log-likelihood under a baseline model (that of Collins [1999]) with evidence from an additional 500,000 features over parse trees that were not included in the original model. The new model achieved 89.75% F-measure, a 13% relative decrease in F measure error over the baseline model's score of 88.2%. The article also introduces a new algorithm for the boosting approach which takes advantage of the sparsity of the feature space in the parsing data. Experiments show significant efficiency gains for the new algorithm over the obvious implementation of the boosting approach. We argue that the method is an appealing alternative\u2014in terms of both simplicity and efficiency\u2014to work on feature selection methods within log-linear (maximum-entropy) models. Although the experiments in this article are on natural language parsing (NLP), the approach should be applicable to many other NLP problems which are naturally framed as ranking tasks, for example, speech recognition, machine translation, or natural language generation.", "authors": ["Michael J. Collins", "Terry Y. Koo"], "n_citation": 812, "references": ["0084c826-9869-48ff-a9af-340511b62a37", "01f443e7-ea4c-48a7-8081-745c3fa62769", "094f9d37-c370-446f-988f-bbeb9542922f", "17f811d8-8607-4270-bbec-1cc7883edd68", "1f73723c-b904-4d93-8045-d8de3772fb27", "23dafe78-613e-436f-a552-f797778cccb2", "290e0375-d2ad-4bec-a94f-f05e1580125b", "2b8b3ae5-276d-4586-a8d4-d1b83b02d0ba", "2cb1c41b-b9f6-41e7-9b8f-b55ff20903a8", "310cbba4-d88d-4bf4-a4f2-738f91b5f8c8", "47899190-57a8-4d62-85f0-e5802ac85e8e", "4c7c4ff6-4c16-43c4-8baa-73a4c0648dac", "4c9df9cf-99ab-4c22-88d4-f1440332377c", "51f1493d-ce3b-4589-8373-55940026fecd", "6b3483b2-504d-454e-8f03-e58ad4c7f4b0", "6c2fee35-a596-416a-bd8a-a7966324f71e", "6d986416-3e63-41bd-89e4-3668e30e0e5a", "74f1bc60-45c3-4999-abc9-c00372a12237", "772b8d93-c03a-47b9-8153-37fb9f61320c", "852d4703-36db-4c8c-814c-6cd2273b536b", "85415160-c71b-49de-b62a-7cf8ee2a60a8", "92ce68f7-4fbb-4138-8502-ec0ce7d07125", "97684b69-4da6-4fb3-b40c-32c58752f708", "9fc20670-64f0-4f04-8fe4-a0ff8d9905b2", "ae12659d-5fde-4ec3-91fd-4dc443c374ca", "ae829318-5d10-461d-9c99-34a95a3f8732", "c3575d4a-31ba-4089-abbc-0d47a81929dd", "cb9433c1-1338-477a-af39-dbaa772e46bb", "cd503b2e-70ed-47f8-81d4-94250e617191", "cf0b5d61-b3ea-48c1-a716-c86f4cd8c089", "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706", "db26488d-78be-44b1-a343-e896f43c5d29", "dff9fa95-09ff-4fb4-aaec-14fac29bf491", "efc0f8d3-3633-4e89-95de-18ffa0efddde", "fa512d50-e535-4feb-91d0-42b071e08a4f"], "title": "Discriminative Reranking for Natural Language Parsing", "venue": "international conference on machine learning", "year": 2000, "id": "5538b634-04f3-4d09-bb4e-90055817e3b1"}
{"abstract": "Dunhuang Mogao Cave, located in Gansu province, is a typical Chinese heritage site. Well preserved, the caves contain more than 555 grottoes, 2,000 painted statues, and 5,000 square meters of wall paintings. Scientists and artists have worked for a long time on how to preserve and restore the murals' colors, but have not found satisfactory methods. Discovering how to use advanced computer techniques to preserve, restore, and reuse Dunhuang fresco art information is a very interesting and complex task. In our project, we integrate many techniques, such as image processing, information retrieval, knowledge representation, and intelligent reasoning, to deal with these problems. Restoration of the frescoes is the basic focus of our project. Because of human activity, most of the frescoes fade day-by-day, with some seriously damaged. We propose a new, intelligent approach to color restoration. Each restored fresco will be preserved in the fresco database along with the original. For many of the Dunhuang frescoes, the key to preservation is to find an effective method for organizing, storing, managing, and retrieving the fresco data. We adopt content- and semantics-based image retrieval methods to solve these problems. Our fresco database will support Dunhuang pattern creation and virtual cave travel, reusing the fresco art information from the database. In this article, we mainly focus on the color restoration and retrieval techniques we use for fresco preservation.", "authors": ["Xiangyang Li", "Dongming Lu", "Yunhe Pan"], "n_citation": 37, "references": [], "title": "Color restoration and image retrieval for Dunhuang fresco preservation", "venue": "IEEE MultiMedia", "year": 2000, "id": "63fb5a94-2417-48bc-9f72-055cbd1cbeb4"}
{"abstract": "We present a model for designing wormhole routing algorithms that are deadlock free, livelock free, minimal or nonminimal, and maximally adaptive. A unique feature of this model is that it is not based on adding physical or virtual channels to network topologies (though it can be applied to networks with extra channels). Instead, the model is based on analyzing the directions in which packets can turn in a network and the cycles that the turns can form. Prohibiting just enough turns to break all of the cycles produces routing algorithms that are deadlock free, livelock free, minimal or nonminimal, and maximally adaptive for the network. In this paper, we focus on the two most common network topologies for wormhole routing,  n -dimensional mesh, just a quarter of the  turns must be prohibited to prevent deadlock. The remaining three quarters of the turns permit partial adaptiveness in routing. Partially adaptive routing algorithms are described for 2D meshes,  n -dimensional meshes,  k -ary  n -cubes, and hypercubes. Simulations of partially adaptive and nonadaptive routing algorithms for 2D meshes and hypercubes show that which algorithm has the lowest latencies and highest sustainable throughput depends on the pattern of message traffic. For nonuniform traffic, partially adaptive routing algorithms perform better than non-adaptive ones.", "authors": ["Christopher J. Glass", "Lionel M. Ni"], "n_citation": 1302, "references": ["1ee2b5ab-23ff-4e78-aff1-c3a313a6cdfe", "28c6006e-2ef0-47e2-84e7-01bfd7ff9045", "36192b73-7e9c-4adb-a017-a2b578693ff9", "7085d711-8e16-48b0-b559-e06249bef42b", "7ace2068-ac2f-4567-8c0d-94b418f79fba", "a0e3a3ae-fb40-4346-96b2-95ed2b80ce41", "b3fc362d-79ea-49fc-9983-6fbf937ac694", "bde93a31-e5d8-4baa-adbb-dda63b68d92a", "c29bc764-afec-45e7-9367-132a96f87355", "c629aa2c-f5ee-4dda-a86a-11955ef81277", "e7b327d7-c44f-416b-80a5-f13af22a8e3f"], "title": "The turn model for adaptive routing", "venue": "international symposium on computer architecture", "year": 1992, "id": "73739568-56c1-4153-a32c-3961d4edb81f"}
{"abstract": "A conceptual schema is essentially required to effectively and efficiently manage and manipulate dynamically and continuously changing data and information of moving features. In the paper, spatiotemporal schema (STS) is proposed to describe characteristics of moving features and to efficiently manage moving features data, including the necessity aspects: abstract data types, dynamic attributes, spatiotemporal topological relationships and a minimum set of spatiotemporal operations. On the basis of the proposal of schema, spatiotemporal object-based class library (STOCL) is further developed for the implementation of STS, which allows development of various spatiotemporal queries and simulations. The conceptual schema and implemented object library are then applied to the development of passengers' movement simulation and pattern analysis in railway stations in Tokyo.", "authors": ["Rong Xie", "Ryosuke Shibasaki"], "n_citation": 9, "references": ["0cb61938-314e-4046-a5fa-d546c988523d", "137de291-af63-4fe8-92f2-44a1e11a2ada", "42b33af3-c669-4b4e-b137-24ddfed1172e", "5cfb60ea-879c-4f11-9eba-37f440897a05", "795533d4-fcfd-4854-8381-ec1dc4888336", "85c7b0b4-a874-48d2-9292-0ccd7d3e7274", "8b2275b9-fd7f-41ba-9925-3e28bccc7d62", "a4044f44-96eb-42f9-ba75-125d7eca7170", "b6caccd3-d282-427c-a278-3399e434c522", "bc7c1161-f60f-473b-b98f-036ba489f195", "dbe5ae2e-bbc0-4508-8df5-3ec95c784fa8"], "title": "A unified spatiotemporal schema for representing and querying moving features", "venue": "international conference on management of data", "year": 2005, "id": "2a0203c2-80b2-44f6-bfb8-dc7953f3787b"}
{"abstract": "To have general validity, empirical results must converge. To be credible, an experimental science must understand the limitations and be able to explain the disagreements of empirical results. We describe an experiment to replicate previous studies which claim that estimation by analogy outperforms regression models. In the experiment, 68 experienced practitioners each estimated a project from a dataset of 48 industrial COTS projects. We applied two treatments, an analogy tool and a regression model, and we used the estimating performance when aided by the historical data as the control. We found that our results do not converge with previous results. The reason is that previous studies have used other datasets and partially different data analysis methods, and last but not least, the tools have been validated in isolation from the tool users. This implies that the results are sensitive to the experimental design: the characteristics of the dataset, the norms for removing outliers and other data points from the original dataset, the test metrics, significance levels, and the use of human subjects and their level of expertise. Thus, neither our results nor previous results are robust enough to claim any general validity.", "authors": ["Ingunn Myrtveit", "Erik Stensrud"], "n_citation": 207, "references": ["77705cb6-95f2-4be0-a7bc-f0a90b0efdc0", "91dc1d1f-6803-44ec-8d93-073db4ba289f", "c49fb9c7-c826-4b12-aa32-dd6ad5c3e2e7", "ea7875e9-9866-4b23-84c7-990e72a49b5a"], "title": "A controlled experiment to assess the benefits of estimating with analogy and regression models", "venue": "IEEE Transactions on Software Engineering", "year": 1999, "id": "d712970f-941b-4809-85f9-ae41fd710589"}
{"abstract": "This paper investigates the reaction of a living insect to electric stimulation. Artificial electrical stimulation is one of the tools of neuroethology to investigate the neural system. By creating artificial inputs to the system, specific reaction can be observed. The escape turn is a well-known reaction pattern of an insect in response to the appearance of a predator. In the first part we analyze the locomotory reaction of an insect (Periplaneta Americana) to various electrical stimuli. These stimulus-reaction measurements are done on a light-weight styro-foam trackball which is connected to a computer. This allows us to record the turning rate and the forward movement of the insect in response to antennal stimulation. Based on this data a simple mathematical model is established. As a simple example of an autonomous bio-robotic system and to verify the black-box model an electronic backpack which does line-tracking has been built. Using two photosensors as inputs the electronic backpack forces the insect to walk along a black line.", "authors": ["Raphael Holzer", "Isao Shimoyama"], "n_citation": 117, "references": ["6cbe24ae-11ec-4d55-951d-5d9bae13aed8"], "title": "Locomotion control of a bio-robotic system via electric stimulation", "venue": "intelligent robots and systems", "year": 1997, "id": "b99ecf85-6b3e-4592-a675-a66d14f7b245"}
{"abstract": "We describe a theory of authentication and a system that implements it. Our theory is based on the notion of principal and a \"speaks for\" relation between principals. A simple principal either has a name or is a communication channel; a compound principal can express an adopted role or delegation of authority. The theory explains how to reason about a principal's authority by deducing the other principals that it can speak for; authenticating a channel is one important application. We use the theory to explain many existing and proposed mechanisms for security. In particular, we describe the system we have built. It passes principals efficiently as arguments or results of remote procedure calls, and it handles public and shared key encryption, name lookup in a large name space, groups of principals, loading programs, delegation, access control, and revocation.", "authors": ["Butler W. Lampson", "Mart\u00edn Abadi", "Michael Burrows", "Edward P. Wobber"], "n_citation": 153, "references": ["02343dbf-14f5-496b-b210-b6eaf9e6bdc1", "0ab8c0f9-fdba-428d-81a3-da79d759598e", "0f267b92-aac1-476b-be8f-cdd929149783", "12c9937a-8e9c-425e-ac5d-6e74963f0194", "3fb43b00-905c-4a08-934d-198ea4eb66c3", "4547a622-6888-4c6c-ba86-c1258f3263a1", "5376f94d-6ba7-487c-ada2-e7f621c0ed50", "6a9c2062-e8eb-4584-8d40-35f8ed4e40d2", "8db006a8-3189-4bfc-a04a-acba36d0df7a", "aabd8f07-c961-4df7-98b9-759c8667497c", "ab7c3e56-2475-48e6-95de-1558f3e123e4", "ac60da1d-628d-430a-a62b-0d1ea9e1c4b8", "ca394e6a-59e0-466c-a66a-d976555db689", "fe9d2177-5770-40ec-acd2-2fc1ce394947"], "title": "Authentication in distributed systems: theory and practice", "venue": "symposium on operating systems principles", "year": 1991, "id": "4ae908db-c25f-4879-b1d9-bd0db7878737"}
{"abstract": "Boosted decision trees typically yield good accuracy, precision, and ROC area. However, because the outputs from boosting are not well calibrated posterior probabilities, boosting yields poor squared error and cross-entropy. We empirically demonstrate why AdaBoost predicts distorted probabilities and examine three calibration methods for correcting this distortion: Platt Scaling, Isotonic Regression, and Logistic Correction. We also experiment with boosting using log-loss instead of the usual exponential loss. Experiments show that Logistic Correction and boosting with log-loss work well when boosting weak models such as decision stumps, but yield poor performance when boosting more complex models such as full decision trees. Platt Scaling and Isotonic Regression, however, significantly improve the probabilities predicted by", "authors": ["Alexandru Niculescu-Mizil", "Richard A. Caruana"], "n_citation": 117, "references": ["0acc7238-b413-4cde-b0d0-ccd14a73f16e", "17f811d8-8607-4270-bbec-1cc7883edd68", "3b1e602b-7f54-49a0-a1e6-84309b17e46c", "4e5e46d1-6ade-4145-9e32-4904bd35a15f", "5bfea9e5-b796-468c-8099-1dbd56d31b66", "5fd62342-2791-4f96-bc00-11975718e35d", "6f8f9bc0-3c9a-4583-8819-2bd39263bd15", "85415160-c71b-49de-b62a-7cf8ee2a60a8", "cd503b2e-70ed-47f8-81d4-94250e617191", "ea663c54-1e05-471c-b4ef-080d12409d8d"], "title": "Obtaining Calibrated Probabilities from Boosting", "venue": "uncertainty in artificial intelligence", "year": 2012, "id": "50504d7f-4fe5-4c2c-8ee0-e9ae8a827cf6"}
{"abstract": "Algorithms that must deal with complicated global functions of many variables often exploit the manner in which the given functions factor as a product of \"local\" functions, each of which depends on a subset of the variables. Such a factorization can be visualized with a bipartite graph that we call a factor graph, In this tutorial paper, we present a generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph. Following a single, simple computational rule, the sum-product algorithm computes-either exactly or approximately-various marginal functions derived from the global function. A wide variety of algorithms developed in artificial intelligence, signal processing, and digital communications can be derived as specific instances of the sum-product algorithm, including the forward/backward algorithm, the Viterbi algorithm, the iterative \"turbo\" decoding algorithm, Pearl's (1988) belief propagation algorithm for Bayesian networks, the Kalman filter, and certain fast Fourier transform (FFT) algorithms.", "authors": ["Frank R. Kschischang", "Brendan J. Frey", "Hans-Andrea Loeliger"], "n_citation": 5767, "references": ["6f9aeb94-bd72-4ac6-8ec4-4c3f98dcb993", "7963ab0f-472d-47ec-a2d9-d21d72e390b2", "7d13dc57-6231-4275-bbd6-ecc7a2935795", "8285b7c1-a2cd-4916-ad56-afc0eceeb815", "8611c7fe-134c-47dd-8ae2-0bf04fe8f224", "9ec287ca-9bbf-4b96-96e3-fdb78a808228", "b897fabf-4e80-4491-87db-3e5bb81a8bd3", "c5a3d783-7e53-43b0-9ef5-a333af312ced"], "title": "Factor graphs and the sum-product algorithm", "venue": "IEEE Transactions on Information Theory", "year": 2001, "id": "8cea470a-9c6d-4137-8f4c-acda7e0d1904"}
{"abstract": "Gamification is growing increasingly prevalent as a means to incentivize user engagement of social media sites that rely on user contributions.  Badges , or equivalent rewards, such as top-contributor lists that are used to recognize a user's contributions on a site, clearly appear to be valued by users who actively pursue and compete for them. However, different sites use different badge  designs , varying how, and for what, badges are awarded. Some sites, such as StackOverflow, award badges for meeting fixed levels of contribution. Other sites, such as Amazon and Y! Answers, reward users for being among some top set of contributors on the site, corresponding to a competitive standard of performance. Given that users value badges, and that contributing to a site requires effort, how badges are designed will affect the incentives\u2014therefore the participation and effort\u2014elicited from strategic users on a site.   We take a game-theoretic approach to badge design, analyzing the incentives created by widely used badge designs in a model in which winning a badge is valued, effort is costly, and potential contributors to the site endogenously decide whether or not to participate, and how much total effort to put into their contributions to the site. We analyze equilibrium existence, as well as equilibrium participation and effort, in an absolute standards mechanism  M  \u03b1  in which badges are awarded for meeting some  absolute  level of (observed) effort, and a  relative  standards mechanism  M  \u03c1  corresponding to competitive standards, as in a top-\u03c1 contributor badge. We find that equilibria always exist in both mechanisms, even when the value from winning a badge depends endogenously on the number of other winners. However,  M  \u03b1  has zero-participation equilibria for standards that are too high, whereas all equilibria in  M  \u03c1  elicit nonzero participation for all possible \u03c1,  provided  that \u03c1 is specified as a fixed number rather than as a fraction of actual contributors (note that the two are not equivalent in a setting with endogenous participation). Finally, we ask whether or not a site should explicitly announce the number of users winning a badge. The answer to this question is determined by the curvature of the value of winning the badge as a function of the number of other winners.", "authors": ["David Easley", "Arpita Ghosh"], "n_citation": 74, "references": ["033fe469-1f2b-4ad5-98d0-2660adf4e905", "4dafc3e3-2429-497f-b49c-528f919dd995", "61835453-79a8-4e80-9e60-6385124de03b", "72450f5f-d79d-4603-8dfb-833fc3e7697d", "8be8b1aa-23ad-413d-9195-1a7983213266", "8c63b5ef-6e29-4a69-9bdd-1f635e81fb88", "a8f4a025-04b6-46a7-a150-ab010f17fc4b", "ac33ea9b-a27c-4ae3-9a66-635e39cb3fa7", "b0ac7c07-0a30-407d-95f2-6dc3ea28981e", "d080d65e-5a68-47d9-90fc-871c6669e865", "edbfa9de-30a4-48ba-8e60-b52584939679"], "title": "Incentives, gamification, and game theory: an economic approach to badge design", "venue": "electronic commerce", "year": 2013, "id": "77be4ffe-3850-4f29-8d89-c11321f842bb"}
{"abstract": "Actor-based modeling has been successfully applied to the representation of concurrent and distributed systems. Besides having an appropriate and efficient way for modeling these systems, one needs a formal verification approach for ensuring their correctness. In this paper, we develop an actor-based model for describing such systems, use temporal logic to specify properties of the model, and apply different abstraction and verification methods for verifying that the model meets its specification. We use a compositional verification approach for verifying safety properties of these models. For that we introduce a notion of component, based on an user-defined decomposition of the model. Components are more abstract than the model itself, and so we can reduce the state space of the model which makes it more amenable to model checking techniques. We prove that our abstraction technique preserves a set of behavioral specifications in temporal logic. The soundness of the abstraction is proved by the weak simulation relation between the constructs.", "authors": ["Marjan Sirjani", "Ali Movaghar", "Amin Shali", "Frank S. de Boer"], "n_citation": 123, "references": ["0ad112b1-0567-4ebc-8c2f-183e88757a0a", "0c8be467-2b4f-4811-835f-57fb124017f0", "17fb2c08-a610-438f-a0f6-f3aa33edff3e", "1dc59882-baf4-454c-a665-6fc985b821d4", "2f6e4c23-5cf1-491e-be25-a4601f836d51", "33a9282b-bc75-4734-bda1-d43a0cf42a92", "35bcc287-feb9-4590-8601-1bab794ebe6b", "3c423560-3c66-4eb1-b448-cdcabcf132b6", "4757ce83-5af8-4deb-8ba3-ceb36df4c797", "5e8f42f0-535a-4ace-b5cb-dcd10c32e79c", "6140a0e3-7113-4586-ab69-551ada879894", "6e12c5c0-acce-4a52-a59c-f7a912731d92", "6f45828a-82d4-4306-bc4f-f7fb31d4298e", "77d2ea65-9174-464d-a871-60b33377035c", "7aef9f4d-ec6a-470d-b859-d321a73f704f", "8ae890ea-35a0-4907-b8f7-7d56daa9e8cb", "8bc1f31b-8589-4fe9-b3b2-0b3da2da7640", "8ca31a79-cc09-4cef-b784-b73feed2199f", "922dedbd-dde0-4fdb-8b5a-1e44bdae286c", "944f9b4d-bd4b-4a33-8f33-43332b6f793d", "9464be88-80de-463e-af0c-83562b7744ff", "97d229d7-4079-489a-9f63-5209ff52d810", "aa3e2ab0-63c9-4c08-b788-8415f35dea23", "ab808365-8074-4457-9ca8-45a6b43849d9", "afcaf0ab-5528-48ba-a284-0e6bad6675e4", "b0fa7616-45a4-4ff5-af2f-6faf3d2c51ab", "c00bbb49-6e29-4103-8883-55acd23c248b", "d173a00c-d248-4e4d-92dd-8546cdf940f4", "defb1881-112a-41cc-bfb7-42c28e1f1541", "fbc6546b-3001-40e3-876f-2c07c38a4071", "ff06e10f-0e6d-4cea-9e4b-ce3c5e9cfb8a"], "title": "Modeling and Verification of Reactive Systems using Rebeca", "venue": "Fundamenta Informaticae", "year": 2004, "id": "ce260a48-ea50-4c46-9365-d1278710660a"}
{"abstract": "In this paper we study a reactive extension of constraint logic programming (CLP). Our primary concerns are search problems in a dynamic environment, where interactions with the user (e.g. in interactive multi-criteria optimization problems) or interactions with the physical world (e.g. in time evolving problems) can be modeled and solved efficiently. Our approach is based on a complete set of query manipulation commands for both the addition and the deletion of constraints and atoms in the query. We define a fully incremental model of execution which, contrary to other proposals, retains as much information as possible from the last derivation preceding a query manipulation command. The completeness of the execution model is proved in a simple framework of transformations for CSLD derivations, and of constraint propagation seen as chaotic iteration of closure operators. A prototype implementation of this execution model is described and evaluated on two applications.", "authors": ["Fran\u00e7ois Fages", "Julian Fowler", "Thierry Sola"], "n_citation": 35, "references": ["21844d83-e6d2-4fb5-b887-24a7935c809e", "21be3d51-c7cd-4248-b326-3f472d250796", "2fb3bd66-88e0-4769-b0ae-3fbdc59cbbef", "41e9cdf7-e36a-4296-b23d-695a9a963e0e", "429aa3f6-e5cc-45a0-a93f-3e6449d64c93", "51f4ae2e-e6e1-4321-8dd9-aa39fc78031f", "5f51ea51-f867-430a-a837-16e4e53154ab", "801aa7d0-baec-4337-abf0-d87dc2f43cda", "91d11947-e646-4222-9df4-c32b9d82b94f", "930110cc-1608-495e-999d-0101a36ae70c", "b7b55066-4d8d-4673-969b-254838723339", "c24278c4-5209-47b5-b2b8-11f0684f1d64", "d033e17a-7cf6-4ce0-ac63-d80b03820e04", "e2cddc71-90a9-45f1-b863-da5e42a955e0"], "title": "Experiments in reactive constraint logic programming", "venue": "Journal of Logic Programming", "year": 1998, "id": "55af7ce9-d664-4ad0-b1e1-05875393ef54"}
{"abstract": "This chapter has two parts. In Part I, we present an overview of issues in modeling Multi Agent Systems (MAS), discuss what features and components are required for a MAS infrastructure, and present a model of a generic infrastructure. In addition, we present RETSINA as an example of an implemented MAS infrastructure. In Part II, we present issues in agent and service discovery and interoperation through a set of domain independent active and intelligent registries, called middle agents.", "authors": ["Katia P. Sycara"], "n_citation": 57, "references": ["0c1e459a-9540-49b9-909c-40eb5167605d", "0f1a0f90-ead9-4609-a621-f5380ec95cf7", "2f53b167-06ed-4217-b520-7ac21ed02964", "2fa3b915-dd17-46b8-b535-b69cae9d46b0", "339ebc77-f3bc-452c-84b4-b22f9f68d69d", "35766377-84d0-4aee-8272-7747946b3d9f", "3ba8cb0c-13b9-473f-b22f-6e7dc7ec2d7e", "40ec5a76-44fd-4a35-9341-3bb191b8da97", "41ca5b20-9bfa-4f98-9865-087f685519b4", "438602f2-7821-4e57-8812-10e4023b2db3", "463623d9-06f4-49b9-813f-21f78d726f3b", "464d930b-15b4-4b9d-8c8b-7753d24fcc18", "4a71d48b-3751-426a-8606-17a7a48be585", "4f7d5280-29b9-42a2-b95f-bfa8e7961265", "4fb37de3-f523-4c82-bd65-884a52c0c4c0", "52981000-ff96-4be5-bf49-acd608ba3af0", "55f9c2d5-33af-4a6e-a666-b9a85fcbf625", "5d2291ed-ef8c-4ac4-8124-389119c0103f", "609fabe4-129f-4c4c-8905-2f9896534c89", "6287ec50-c92f-4695-a3d0-d9d365da6aa3", "6b8caca2-ce9a-47a6-af3c-e3efbda4f73c", "71e354c6-7cec-41ed-8a17-82dea44a4022", "7ab2f7a0-3141-483f-9dc2-44f9cc36305d", "8473bc8c-594f-497b-befd-817f56bdef33", "85ab0381-32c5-476b-9adf-f4ad08ae0968", "8e453141-0092-48aa-99a1-07baa4343f2b", "93d45f93-cc9f-4b87-9ff0-1e955e34ec09", "972912ff-ab0e-43d7-9312-1c457bec38c4", "9cbb9fef-209c-4c51-a68b-1ef93c0e5b82", "a0fd18e9-db7e-4f0c-8dc7-dfd9e875e2df", "a67625f4-16a9-42cf-a71a-2d59bcc0ce59", "ac7265af-a4fc-410a-8c2e-25936fd5b4d5", "aed60d95-2ef8-4bd9-a9ff-672c1fee150e", "b2b5c39e-2113-49ec-b4f6-1174802ff0ca", "b38b9aa0-6b45-4d1c-9ac1-126e67cc073f", "b42dbeb0-7dda-49f8-a35e-fb237420c2a4", "b9df0849-e0bb-479d-b7cc-2e27de18aad9", "bd8245cd-deba-4254-b9bb-3340b1c35000", "d2271d34-2c62-4a52-9be4-676aded19ca8", "d55b22d6-2cf2-48c2-ba9c-ae3cf440c3ad", "d58097ce-853d-455f-9184-8c83eedd4968", "d7c6a633-675a-4294-9cc6-6614e5e20b65", "d9c7cc6d-0067-4dae-848b-fcbe35b4aec9", "dc73d9d9-f38c-4df6-9919-07fb2f4e2c87", "dcfa2965-5699-4f07-9f0a-f798c6edb4d1", "dd10f383-9fd3-4944-a8c9-30b456cde099", "e878dcd1-2d02-480a-891b-accfb53fb5d4", "ed0341b0-66f2-4c68-a2bc-e2fa5acd828b", "edf35ca2-c793-4d99-8609-04154b35f16d", "f71d9f2b-8740-40fe-bf78-5f88e5d72076", "fa7f3de9-462a-4f96-88aa-6d97b4e8e377"], "title": "Multi-agent infrastructure, agent discovery , middle agents for Web services and interoperation", "venue": "european agent systems summer school", "year": 2001, "id": "f89bf89e-744b-4b44-8c5c-00e31c3cab84"}
{"abstract": "Wireless mesh networks (WMNs) consist of mesh routers and mesh clients, where mesh routers have minimal mobility and form the backbone of WMNs. They provide network access for both mesh and conventional clients. The integration of WMNs with other networks such as the Internet, cellular, IEEE 802.11, IEEE 802.15, IEEE 802.16, sensor networks, etc., can be accomplished through the gateway and bridging functions in the mesh routers. Mesh clients can be either stationary or mobile, and can form a client mesh network among themselves and with mesh routers. WMNs are anticipated to resolve the limitations and to significantly improve the performance of ad hoc networks, wireless local area networks (WLANs), wireless personal area networks (WPANs), and wireless metropolitan area networks (WMANs). They are undergoing rapid progress and inspiring numerous deployments. WMNs will deliver wireless services for a large variety of applications in personal, local, campus, and metropolitan areas. Despite recent advances in wireless mesh networking, many research challenges remain in all protocol layers. This paper presents a detailed study on recent advances and open research issues in WMNs. System architectures and applications of WMNs are described, followed by discussing the critical factors influencing protocol design. Theoretical network capacity and the state-of-the-art protocols for WMNs are explored with an objective to point out a number of open research issues. Finally, testbeds, industrial practice, and current standard activities related to WMNs are highlighted. ed by discussing the critical factors influencing protocol design. Theoretical network capacity and the state-of-the-art protocols for WMNs are explored with an objective to outline a number of open research issues. Finally, testbeds, industrial practice, and current standard activities related to WMNs are highlighted.", "authors": ["Ian F. Akyildiz", "Xudong Wang", "Weilin Wang"], "n_citation": 4843, "references": ["02eefe0f-b029-4fbb-b41a-906e8f04639d", "03a67937-3823-48ca-8b6c-98bf2774800b", "04d08d28-706c-492a-b2a2-68be407e3ce4", "0998b7fa-b6ab-4494-8f8a-80136f4ddbd2", "11ce2a5f-c26f-4d92-83da-65ba632c1195", "12b6f373-f5d1-46f4-85ee-16ee239ee862", "14a274e3-6ec3-40f7-80ad-334711dc3222", "190378e2-8617-4add-835c-3e7ed4805bd1", "1b7ff6d2-5664-4f68-b6b0-7ec24900db9e", "22b55f59-1aa1-4dc4-92fe-5e82014652cf", "2659531e-eb9d-4dd5-b46f-10f66a4819c6", "269e006a-d493-4ade-be8b-cfc3b56d5752", "29424b9c-c448-4679-8472-044e701a11ea", "2962277b-7da6-4a64-9dbd-6ca9370c577d", "29f75862-97b4-4116-9e91-70bde085bcca", "2b06e029-ba76-4924-96ce-815670c8e2e3", "32591c3e-f867-4910-91ec-ce8d8113767a", "35239e8a-a6d8-4297-8818-e8965b5d2472", "380c3e95-47c3-4e83-ba1a-be8351b787d8", "3a8d5801-1361-43d4-a4cd-e70133c245d4", "3d32516c-e687-4b1d-8788-646dddfd7008", "3f538b4c-767e-4749-82f9-9a970e9f83e6", "425664d5-08ce-49f6-979d-5e6eff993ed2", "42f3128f-69d0-4659-8039-d2e45f4cbb4f", "474dd419-342a-4a4b-9f04-85803e77459c", "4cfd1b21-4c46-47c5-88ed-9bff442a8165", "53509df6-4f4f-4652-bf8a-43098126e01b", "58d586c7-9f54-45ee-8349-62526bbdc1f9", "5a878cce-f516-4bcb-84fa-8f19f1656099", "66a2e736-3c79-46db-bfa4-340cb1cd1c1a", "6b4920a9-9dbd-411e-9618-0dd545bc97d7", "71cec942-481a-4e22-a5e9-ff40ba582e5d", "735f0549-832b-4c65-bf41-70039c3d63b8", "809c50af-7512-4ca9-ad47-b8e1dd6ba77b", "83034d86-0f0f-4082-8752-91759086afaa", "83b5fe2e-6156-4963-9a80-1dd52c4d71bc", "880c15cf-7b29-4c58-a601-c1f0affd1808", "8c1ed25a-4316-48e1-9dab-9185e4b9af42", "8ca979cf-f9d5-451a-84a7-e91ca2a592e2", "8cc9ea80-563f-4e62-bda9-8ff6d71cf6ae", "8d372af4-9bbd-499c-a00d-c6cfd91f6dfb", "96318e18-6d91-4f89-8739-24f6d2a30b5f", "96b245c2-47a5-4aec-89f0-d2a362124845", "98783db9-d399-4537-9eaa-8964f92d99c7", "9de43d04-c7fa-48a9-b092-67c2888745d4", "a08d8f1a-5612-46dc-9af0-9ee800438b0a", "a301962a-6d47-4fcc-9a89-5c67e1fac20f", "a7be922e-d9fc-4df1-98ba-02afcbb0cb37", "aed9b791-eaec-40f8-94df-fdef3291f6d5", "af92cf97-d046-4072-a64b-001789344745", "b5741c8a-84a5-4b8d-9e5e-29d97732b48f", "b612af14-d537-4a3d-8bb7-cd5c6d248927", "b68a422e-b2f3-4cf4-86ec-453b1de928dc", "b97cdda8-3d21-4197-8c05-235cd9ff447f", "bc3c7b56-c0cd-4762-b8f1-dd53fa3905aa", "c041e7c4-39f4-4b29-aed9-95a346efb2ea", "c7a0e971-e3f6-457b-8de5-693528bc6d9a", "c9985150-ff5a-489c-93ca-8e626dc4dc46", "ca44ad79-a14d-4ba2-a118-e0dde960d3ba", "ccabb476-c38d-4867-bf93-60f1abe6e95b", "cd7b4b1f-8614-4fab-8c33-a89394f0d6f9", "d158cc4a-309b-4425-82b1-4f7f336c5c42", "d33673af-391e-43b0-bd73-f5e02fb81531", "d7bebab6-5327-4744-b315-a1d19e3989ab", "e01cbb09-7ac9-480b-b49b-e1198c5e33e0", "e2d56e70-7eb7-495c-91b4-b11b127cd278", "e4047eee-fc9e-4f97-b354-64ef1d941719", "eda5c9f4-7ed3-4663-a1a0-15ec4828af4d", "ee99bfa9-086e-4d9a-9494-56a8281b8b78", "f09510a5-a108-46c3-917d-0d8d145c4a0e", "f3046808-ca07-4fb2-a8d5-9821b37e4f7b", "f3267c01-b670-4b7a-a3a5-79088c0d90ab", "f5a0a0a7-e045-4da5-815b-41964cffbaab", "f65a4365-2696-47f3-849b-501792da7e23", "f85ab3f5-3596-4704-a57e-873e6e0a80a9", "fb2003f6-ed7b-424e-94b2-6b150f8e7302", "fc160e6d-da14-40c6-8b68-725aa841f6b2"], "title": "Wireless mesh networks: a survey", "venue": "Computer Networks", "year": 2005, "id": "b857298c-92c9-4f05-a704-3b9fc6be06e3"}
{"abstract": "This brief deals with the tracking control design of a helicopter laboratory experimental setup. In order to be able to realize highly dynamic flight maneuvers, both input and state constraints have to be systematically accounted for within the control design procedure. The mathematical model being considered constitutes a nonlinear mathematical mechanical system with two control inputs and three degrees of freedom. The control concept consists of an inversion-based feedforward controller for trajectory tracking and a feedback controller for the trajectory error dynamics. The design of the feedforward controller for a point-to-point flight maneuver is traced back to the solution of a 2-point boundary value problem in the Byrnes-Isidori normal form of the mathematical model. By utilizing special saturation functions, the given constraints in the inputs and states can be systematically incorporated in the overall design process. In order to capture model uncertainties and external disturbance, an optimal state feedback controller is designed on the basis of the model linearization along the desired trajectories. The proposed control scheme is implemented in a real-time environment, and the feasibility and the excellent performance are demonstrated by means of experimental results.", "authors": ["Thomas Kiefer", "Knut Graichen", "Andreas Kugi"], "n_citation": 50, "references": ["0ce96a31-047e-48b3-ae2a-f60176b80454", "14475d55-2fa4-4d92-aa04-f3617fb7feb7", "4a10e1c6-c7bb-426a-b24f-be3bd498e7f3", "5e65aff7-7407-4e29-a4b6-649ddaa9f319", "880b0b42-6863-48f9-b57b-2b5d1bb543a3"], "title": "Trajectory Tracking of a 3DOF Laboratory Helicopter Under Input and State Constraints", "venue": "IEEE Transactions on Control Systems and Technology", "year": 2010, "id": "5fb127c2-19cc-490e-9d85-d793a69aa93b"}
{"abstract": "This study reports the results of using minimum description length (MDL) analysis to model unsupervised learning of the morphological segmentation of European languages, using corpora ranging in size from 5,000 words to 500,000 words. We develop a set of heuristics that rapidly develop a probabilistic morphological grammar, and use MDL as our primary tool to determine whether the modifications proposed by the heuristics will be adopted or not. The resulting grammar matches well the analysis that would be developed by a human morphologist.In the final section, we discuss the relationship of this style of MDL grammatical analysis to the notion of evaluation metric in early generative grammar.", "authors": ["John A. Goldsmith"], "n_citation": 824, "references": ["1789fb82-1014-4327-abb5-82b00c7c58c0", "3cc7d99b-2563-47ab-a83a-3555a2bf2736", "4237caaf-4104-4bad-afe3-012b12bf3092", "6429b259-a7f3-466f-8c71-fd6d6b402404", "69f00f82-45eb-4e2b-b239-5526d80f11ea", "db191c92-2ef7-48a0-bf6d-4331f76793e5", "e6e270fd-cfc0-429d-b2f2-1e985679cd75"], "title": "Unsupervised learning of the morphology of a natural language", "venue": "Computational Linguistics", "year": 2001, "id": "146f034b-d4e4-48ef-b0f9-fdff1e9fc25e"}
{"abstract": "Total order broadcast protocols have been successfully applied as the basis for the construction of many fault- tolerant distributed systems. Unfortunately, the implemen- tation of such a primitive can be expensive both in terms of communication steps and of number of messages ex- changed. To alleviate this problem, optimistic total order protocols have been proposed. This paper addresses the problem of offering optimistic total order in geographically wide-area systems. We present a protocol that outperforms previous work, by minimizing the average latency of the op- timistic notification.", "authors": ["Jos\u00e9 Mocito", "Ana Resp\u00edcio", "Lu\u00eds E. T. Rodrigues"], "n_citation": 50, "references": ["1d0fe498-793f-4dc8-938b-712a8c952a65", "2c9ad354-66eb-4463-89d6-819e71a3e693", "8ee79427-1fa8-4327-b5ae-148f324e1430", "a592d206-a4fd-42f3-8d5b-a34732a7e78f", "c017ac96-8892-4ce2-8d7a-b837f7768872", "c8bfbb6e-f032-4b61-90e9-58cda772ef18", "c93abb4e-959f-49ad-8dd4-554a6c3e7d09", "debfb842-ffa1-4161-805c-1fbe769b9fee"], "title": "On Statistically Estimated Optimistic Delivery in Wide-Area Total Order Protocols", "venue": "pacific rim international symposium on dependable computing", "year": 2006, "id": "05599f60-a037-44fb-85ea-9b86bc7e4747"}
{"authors": ["Manuel F. Bertoa", "Antonio Vallecillo", "F\u00e9lix Garc\u00eda"], "n_citation": 38, "references": ["118e5409-4199-4c2d-a7e1-bacaac2d31e2", "1dc9abd9-efa3-4eef-af5d-c04feb8f7710", "620150d0-8acf-467e-b69d-dd831c5b59c9", "6fafa162-bb5f-409e-a204-a444fc2bc20c", "7101be81-c857-4eb5-addb-7ea92d7151c8", "f7988457-2b94-4021-be0a-945a692055e3"], "title": "An Ontology for Software Measurement", "venue": "", "year": 2006, "id": "8b32ce91-f067-4284-8e83-8c3d4cfcd586"}
{"abstract": "Abstract   Completion modulo a congruence is a method for constructing a presentation of an equational theory as a rewrite system that defines unique normal forms with respect to the congruence. We formulate this completion method as an equational inference system and present techniques for proving the correctness of procedures based on the inference system. Our correctness results cover generalized and improved versions of the Peterson-Stickel and the Jouannaud-Kirchner procedure.", "authors": ["Leo Bachmair", "Nachum Dershowitz"], "n_citation": 100, "references": ["01d41f9c-728d-449e-9127-5ec9aeaecf4a", "09394184-6073-47da-b7bd-b7203482536d", "1e459f12-9ffa-43aa-8dcf-f22a6b8d2d5a", "3cfc8d40-8a97-4fd1-8d66-33caf713a389", "609be490-70d0-4e56-9ebb-3cc563e304d2", "61f1cb4b-f39f-49a1-80e2-87cfb387f59e", "6d08958e-79c0-4bec-97e6-ab363407cf4d", "87434422-5462-42ba-abbf-469e025a347e", "a53cb184-5ec1-4ecc-8777-1ca58e95055c", "b3527ee9-e743-47dd-83b4-52fe28921ace", "ca7b9a4e-94a3-4a1a-bf8a-6c2e05da2212", "da654f3c-283e-4e9d-8332-c22d1e25858b", "e97f9cea-e702-4387-9686-a69a7a272e90", "f81b1630-bd58-4a7f-8ebc-c030a3059b87", "ff6007a5-a170-4508-9407-6a05ef3d0c8c"], "title": "Completion for rewriting modulo a congruence", "venue": "rewriting techniques and applications", "year": 1987, "id": "d8df051d-f0c0-41b5-a392-7f3fad8e85a1"}
{"abstract": "This paper presents extensions to Spec Explorer to automate the testing of software applications through their GUIs based on a formal specification in Spec$\\sharp$. Spec Explorer, a tool developed at Microsoft Research, already supports automatic generation and execution of test cases for API testing, but requires that the actions described in the model are bound to methods in a .Net assembly. The tool described in this paper extends Spec Explorer to automate GUI testing: it adds the capability to gather information about the physical GUI objects that are the target of the user actions described in the model; and it automatically generates a .Net assembly with methods that simulate those actions upon the GUI application under test. The GUI modelling and the overall test process supported by these tools are described. The approach is illustrated with the Notepad application.", "authors": ["Ana C. R. Paiva", "Jo\u00e3o Pascoal Faria", "Nikolai Tillmann", "Raul Moreira Vidal"], "n_citation": 71, "references": ["08606f3e-bccf-4e0f-93d4-40871e8c0c74", "09396ced-6ed3-4695-8853-99ee52fc22cb", "3ba0a4f4-0d83-4c99-a34f-8c48c45080dc", "736150d2-ee57-4155-be20-9afef76d6e78", "81866c11-d73f-4308-af9f-aebe8a521745", "f0da0661-a305-4b3a-a5a3-4d1f6c77c1f7", "ff456593-2b0f-454a-b321-c16eb4339d35"], "title": "A model-to-implementation mapping tool for automated model-based GUI testing", "venue": "formal methods", "year": 2005, "id": "94bb6430-53fd-4311-8041-a0dda9efa490"}
{"abstract": "What is the intellectual core of the information systems discipline? This study uses latent semantic analysis to examine a large body of published IS research in order to address this question. Specifically, the abstracts of all research papers over the time period from 1985 through 2006 published in three top IS research journals-MIS Quarterly, Information Systems Research, and Journal of Management Information Systems-were analyzed. This analysis identified five core research areas: (1) information technology and organizations; (2) IS development; (3) IT and individuals; (4) IT and markets; and (5) IT and groups. Over the time frame of our analysis, these core topics have remained quite stable. However, the specific research themes within each core area have evolved significantly, reflecting research that has focused less on technology development and more on the social context in which information technologies are designed and used. As such, this analysis demonstrates that the information systems academic discipline has maintained a relatively stable research identity that focuses on how IT systems are developed and how individuals, groups, organizations, and markets interact with IT.", "authors": ["Anna Sidorova", "Nicholas Evangelopoulos", "Joseph S. Valacich", "Thiagarajan Ramakrishnan"], "n_citation": 358, "references": ["0895c22d-37c5-4c8f-9202-a32ebd2cb0c0", "1c95d184-179f-44d1-88a8-5fab9e567e69", "1ce7a9a3-91c4-45d6-984a-e1d240fd81aa", "234e66a9-10a1-41b7-9bc5-5615de1de1e3", "270913a0-698b-45c3-b25e-c0d21ba5d8ab", "293405ad-3794-4bef-9a9b-72e222ca4ffc", "4684f1d5-5616-43df-a0c4-239ff332bf78", "4ac9ab99-6756-4c58-9850-b662a5d68fcd", "596ca41b-d651-4093-b2e0-847f07e84149", "5987786a-0a9f-4ee5-9b7a-0d4733b6139d", "5d7a48c5-605f-45df-856c-7053120194fc", "5e6ba10f-32c8-45c5-8e2d-52f5fc53c5f5", "5ea58cda-ef87-4b9f-9a2b-b8723b012b39", "61268585-6c39-4085-8f80-72eb7075aa92", "633334e6-c7f5-40cb-a9e4-47cce55c8b7f", "6763e855-fe8c-4e8b-b27b-f2b2945439bd", "68befeb4-b362-471c-8e35-5e405725aabd", "7c014e33-f14a-4ea2-8936-43fd0a6a4625", "7c0b19c1-c444-4a35-8e1e-03b448a706a8", "7f963b7c-b622-462d-97b5-4e761209e6ff", "89655e6c-2373-4a18-bf34-56bfa9f01fa3", "8ae3ede5-7f99-4cac-921e-a92eda6d61a2", "929960d9-ffdd-4cac-b24d-06ad4e437501", "ac14afe6-de4d-4056-b2ac-0f6e36f369a2", "c579716f-4905-44eb-9ba2-3e30c5e2ed73", "c7dd6f19-f9a3-4dd8-9b6a-b9bc63f9e2a1", "ca3ea94c-932c-4017-917e-269fb1938eed", "cd5e6dc8-d3fd-4af7-8425-bfa9cf3c787a", "cfa1fba3-eb4f-4b21-9f7d-adf2d58cb532", "d3ca543b-a6d3-4dac-af08-b8e591340aaf", "d3f16cec-2101-4860-a858-36ade451090f", "de9349d7-7ab9-4a4d-9fe0-e58791fedbc4", "e1ee4f5e-bfdb-49ea-b109-5c58f3f381c8", "e2386822-a40c-4c16-a29e-a59242aab27a", "e2f71639-fffe-474a-b9b8-7e8ed0fbe8fd", "e50c837b-b2ad-4d36-838c-2fd153268d9e", "e9abffef-c6bf-44da-a673-be480773dbbb", "f098566e-e57a-4c82-ac93-4c41b0b5c02d"], "title": "Uncovering the intellectual core of the information systems discipline", "venue": "Management Information Systems Quarterly", "year": 2008, "id": "4ab7ea99-87bb-45fc-b550-58d3cd06300b"}
{"abstract": "DNA nanotechnology uses the information processing capabilities of nucleic acids to design self-assembling, programmable structures and devices at the nanoscale. Devices developed to date have been programmed to implement logic circuits and neural networks, capture or release specific molecules, and traverse molecular tracks and mazes. Here we investigate the use of requirements engineering methods to make DNA nanotechnology more productive, predictable, and safe. We use goal-oriented requirements modeling to identify, specify, and analyze a product family of DNA nanodevices, and we use PRISM model checking to verify both common properties across the family and properties that are specific to individual products. Challenges to doing requirements engineering in this domain include the error-prone nature of nanodevices carrying out their tasks in the probabilistic world of chemical kinetics, the fact that roughly a nanomole (a 1 followed by 14 0s) of devices are typically deployed at once, and the difficulty of specifying and achieving modularity in a realm where devices have many opportunities to interfere with each other. Nevertheless, our results show that requirements engineering is useful in DNA nanotechnology and that leveraging the similarities among nanodevices in the product family improves the modeling and analysis by supporting reuse.", "authors": ["Robyn R. Lutz", "Jack H. Lutz", "James I. Lathrop", "Titus H. Klinge", "Divita Mathur", "Donald M. Stull", "Taylor Bergquist", "Eric Henderson"], "n_citation": 13, "references": ["09da855a-b565-45a6-9da5-2383cbbc05b3", "0cac4db7-f110-4ef4-bd74-2307af2329c4", "2c3526d4-0cc0-424d-9808-cb89c9c13df7", "35fb95d4-d156-4599-9181-99bc88f6da99", "4875679e-8520-4a8b-8f3f-102d2990a07b", "4a2e8608-faf3-4c7b-8942-194f573a8e47", "646f3f6c-04b6-4258-940e-40d653a3cae1", "64fea07d-b4ea-4e01-972b-d221c29ed51a", "838e2aec-3186-4c62-ae89-57c82192c5c2", "85ae7a7b-cdcd-4b8c-b364-6eb7cbff3ce8", "98f5968e-56c3-4f6b-a84c-5649e1f76968", "9e17e96d-725c-40a8-9131-972609233662", "a6ef769c-4b98-48d1-8334-147341e6dbf6", "d9aaeb25-5e82-44fc-9caf-1cb24d55e826", "e66bdadd-73f8-492f-8fe8-f46afae9e4e5", "e681c7eb-769b-4f78-96d1-b7420cbbd075", "ee662075-2ec2-4ac8-9e18-0fa6fd056d22", "f08cbffa-9467-4c74-a284-7db15837ac53", "f1eecad9-9c5a-4e38-bbab-36657885c8ca", "f947314b-9a49-4b41-825b-b5b9b53a7370"], "title": "Requirements analysis for a product family of DNA nanodevices", "venue": "workshop on hot topics in operating systems", "year": 2012, "id": "38a31b7d-120f-44fb-813b-4bb7368fd568"}
{"abstract": "A divertible protocol is a protocol between three parties in which one party is able to divert another party's proof of some facts to prove some other facts to the other party. This paper presents a divertible protocol to prove multi-variant polynomial relations. Its direct application to blind group signature is also shown.", "authors": ["Khanh Quoc Nguyen", "Yi Mu", "Vijay Varadharajan"], "n_citation": 19, "references": ["38118c07-e41c-4e20-81b2-89c9014555e7", "6f88cedd-17a0-44c7-9476-767e7e6caec9", "93b84c61-0636-4d00-8d2b-ce6353f8c8d6", "b089b6af-f280-423f-a56c-c927bf44628c", "b554271c-ffbc-42ad-ba93-a3a17ec3a693", "c03d2f84-d383-4ba9-a430-c943bf1f9de4", "cbb57722-edcd-45c4-ad66-0646c56baa40", "d893a420-a00d-4756-b447-2862ed178eaa", "e9650618-c45c-4a4f-adea-bd47e125977e", "f045bf8a-f8dd-4c60-973c-05854a2361e2"], "title": "Divertible Zero-Knowledge Proof of Polynominal Relations and Blind Group Signature", "venue": "australasian conference on information security and privacy", "year": 1999, "id": "2229ad64-760c-4c8a-bce4-c4c61f1777fd"}
{"abstract": "Ficus is a flexible replication facility with optimistic concurrency control designed to span a wide range of scales and network environments. Support for partitioned operation is fundamental to the Ficus design but was not widely exercised in early Ficus use. This paper reports recent experiences using Ficus in settings where some replicas are only occasionally connected to a network, and hence partitioned operation is the rule rather than the exception. The authors conclude that with some tuning, Ficus adapted quite well to primarily disconnected operation. >", "authors": ["John S. Heidemann", "W Thomas Page", "Richard Guy", "Gerald J. Popek"], "n_citation": 129, "references": ["5b7a91c2-bfbf-40ff-8c0f-6d5e9b31ab24", "5f0e3bf6-a29f-456d-81be-f4c89bd62912"], "title": "Primarily disconnected operation: experiences with Ficus", "venue": "", "year": 1992, "id": "bbbf2e5d-a325-41b0-8e9c-a3a57c3a0ba1"}
{"abstract": "It has been noted that software localization does not always fit well into agile software development. This poster aims to illustrate the relationship between the two by examining how localization issues occur in agile projects. A list of common localization issues is presented and examined as to where and why they can be caused during development and if there is a connection to agile methodologies. The poster serves as an introduction to our research in this area.", "authors": ["Malte Ressin", "Jose Abdelnour-Nocera", "Andy Smith"], "n_citation": 4, "references": ["34705783-4749-4fb1-bd06-77e35b2ec3a0", "58fd8297-aa15-4e38-a810-dc0a547c2c95", "ffddefb0-7261-49c2-a4d4-b92db30dce49"], "title": "Defects and Agility: Localization Issues in Agile Development Projects", "venue": "", "year": 2011, "id": "0f07a119-4d73-4dde-b9e5-d0b5419e6d66"}
{"abstract": "This paper evaluates the effectiveness of query translation and disambiguation as well as expansion techniques on the CLEF Collections, using the SMART Information Retrieval System. We focus on the query translation, disambiguation and methods used to improve the effectiveness of information retrieval. A dictionary-based method in combination with a statistics-based method is used to avoid the problem of translation ambiguity. In addition, two expansion strategies are tested to see whether they improve the effectiveness of information retrieval: expansion via relevance feedback before and after translation as well as expansion via domain feedback after translation. This method achieved 85.30% of the monolingual counterpart, in terms of average precision.", "authors": ["Fatiha Sadat", "Akira Maeda", "Masatoshi Yoshikawa", "Shunsuke Uemura"], "n_citation": 14, "references": ["0e927e21-19c1-465b-bad4-defd43be9e17", "56bdde8a-8fcf-46e0-a426-ce2d695d4e62", "8cfd8f8d-2580-47e6-8e97-7cb448f292a9"], "title": "Query Expansion Techniques for the CLEF Bilingual Track", "venue": "cross language evaluation forum", "year": 2001, "id": "c077fcb8-60e9-4310-bf98-c6a10353c209"}
{"abstract": "The principles on which artificial workload model design is currently based are reviewed. Design methods are found wanting for three main reasons: their resource orientation, with the selection of resources often unrelated to the performance impact of resource demands; their avoiding to define an accuracy criterion for the resulting workload model; and their ignoring the dynamics of the workload to be modeled. An attempt at establishing conceptual foundations for the design of interactive artificial workloads is described. The problems found in current design methods are taken into account, and sufficient conditions for the applicability of these methods are determined. The study also provides guidance for some of the decisions to be made in workload model design using one of the current methods.", "authors": ["Domenico Ferrari"], "n_citation": 78, "references": ["218592c8-e0ae-4291-9c92-9a5f20856687", "259e1c27-720e-42ab-b8de-47fda29eb43a", "ab9071d1-716a-41e2-9b7c-1cafb3e3ef41", "be3f2a1d-46e5-4f34-9444-0f7337b93f8a", "bf56a51c-f8e2-4aef-9166-9c59138ad7ad", "c41c576d-12d9-41fe-b272-7c75633f6d71", "fd0827cd-5709-4048-94fd-572968165b1e"], "title": "On the foundations of artificial workload design", "venue": "measurement and modeling of computer systems", "year": 1984, "id": "d7c7f64d-fcc3-411c-b1e2-89785d89452d"}
{"abstract": "Browser-based attribute-exchange protocols enable users of normal web browsers to conveniently send attributes, such as authentication or demographic data, to web sites. Such protocols might become very common and almost mandatory in general consumer scenarios over the next few years. We derive the privacy requirements on such protocols from general privacy principles and study their consequences for the protocol design. We also survey to what extent proposals like Microsoft's Passport, IBM's e-Community Single Signon, SAML, Shibboleth, the Liberty Alliance specifications and a protocol BBAE of our own conform to these design consequences, and how one could go forward.", "authors": ["Birgit Pfitzmann", "Michael Waidner"], "n_citation": 53, "references": ["4d65b7f9-edb0-49e2-adca-eb5351080f84", "8407778d-e0dc-4ba3-a91f-1bc7dac81690", "884b3fca-596b-441c-b07e-d0c55eb3188b", "a1a2e545-209d-44e6-ae28-06a2fbc8231d", "ca394e6a-59e0-466c-a66a-d976555db689"], "title": "Privacy in browser-based attribute exchange", "venue": "workshop on privacy in the electronic society", "year": 2002, "id": "3a3d42a7-77de-446f-bd24-7592b8eee931"}
{"abstract": "This paper presents basic concepts, framework and roadmaps to develop interoperability of enterprise applications and software. The paper is a summary of the main work carried out in Europe to elaborate interoperability development roadmaps and to prepare forthcoming R&D projects under the Six Framework Programme (FP6). The originality of the approach is to tackle interoperability problem from multiple but integrated views. The state-of-the-art, user requirements and visions relating to develop interoperability are presented. Recommendations for future works are discussed and conclusions given at the end.", "authors": ["David Chen", "Guy Doumeingts"], "n_citation": 66, "references": ["30a0ca0b-4086-4a31-90fe-c34394869f8e", "8923211e-0201-4ed4-bdb7-ef0fc2efac53", "f53fe2e4-a271-4415-a15e-f6679eb7d69b"], "title": "European initiatives to develop interoperability of enterprise applications\u2014basic concepts, framework and roadmap", "venue": "Annual Reviews in Control", "year": 2003, "id": "ce2dd56c-132a-4395-a1db-d6d990876b92"}
{"authors": ["Hamed Shisheh Foroush", "Sonia Martinez"], "n_citation": 11, "references": ["01dd2e38-d2b7-4a8c-b1a7-53e03aefc7c3", "1209604d-8d42-45e4-a444-0525f61eea38", "173b1a29-ab8c-4e51-82a1-6628baccf2ff", "1d24db91-733f-4854-b091-fe485e9cb326", "20c3aba6-5b56-41c2-a321-35f79517e848", "2fae253d-85cb-41ee-b3c0-185c7cd2974b", "33cd147d-d6e9-46b4-9c15-42a6820500e8", "38feb657-2aed-414d-97dc-452c4720a16c", "3ef642df-b7b7-47c1-8bbd-cc242faa3dd0", "5a818468-a579-4f08-8c65-493bcdeaeae3", "5ec6f3cd-8004-43f9-997b-45a301ea102e", "5fbef487-fc66-441d-860b-1bffab12c660", "a2080517-4c72-45fd-ab51-c6f994c984db", "a88aa7f5-7a01-4b64-a913-011087ea9e20", "aa3e9165-b26c-4441-bd2e-d7752f1906d8", "ac2e8959-4c7b-4787-931a-34dfa0196b94", "b1a30975-8cc4-4ccb-b546-bb072c3c80a9"], "title": "On Multi-Input Controllable Linear Systems Under Unknown Periodic DoS Jamming Attacks.", "venue": "", "year": 2013, "id": "3e6e01f6-2822-4680-822c-29ea9c2956f6"}
{"abstract": "Failure detectors (or, more accurately, failure suspectors, or FS) appear to be a fundamental service upon which to build fault-tolerant, distributed applications. It is shown that an FS with very weak semantics (i.e. that delivers failure and recovery information in no specific order) suffices to implement virtually synchronous communication (VSC) in an asynchronous system subject to process crash failures and network partitions. The VSC paradigm is particularly useful in asynchronous systems and greatly simplifies building fault-tolerant applications that mask failures by replicating processes. The authors suggest a three-component architecture to implement virtually synchronous communication: (1) at the lowest level, the FS component; on top of it, (2a) a component that defines new views, and (2b) a component that reliably multicasts messages within a view.", "authors": ["Andr\u00e9 Schiper", "Aleta Ricciardi"], "n_citation": 105, "references": ["136c4780-2f25-4068-90a5-aed6afaf2890", "1dad3e11-e793-453c-86d1-c65c8a3c887c", "4176a011-7b5c-4668-91f1-70d7a65ef1d9", "5110c9ed-463f-44e1-b258-4a78e3cbe110", "575215ab-dad7-430d-9434-0f19c3928931", "5f6e5360-1940-48a6-91d7-786b741d1478", "72da6716-1ab3-4ebf-881c-314a8592a649", "765a5f62-24d9-4ae0-a6d9-79c143d6d5eb", "7683a759-5e97-4eb3-a5a9-644907ac1e75", "79461625-c980-4705-bfa0-704db88aa73f", "8b495c61-ea6e-4c7b-9b45-3121ab994aa8", "9db9578a-6f45-4630-a7ac-854a93cd5c55", "9eac8f56-e6ce-4d57-89ba-6f1119209b9a", "c4e12a20-3c0e-499b-bbd8-8ca899a70da1", "d39108b7-ae80-4086-8f34-38e176832079", "d50b5611-37df-4d50-a240-4ebb29c4aa35"], "title": "Virtually-synchronous communication based on a weak failure suspector", "venue": "", "year": 1993, "id": "981ed588-d96f-498d-a120-affc370ae14f"}
{"abstract": "Random number generators of the mixed congruential type have recently been proposed. They appear to have some advantages over those of the multiplicative type, except that their statistical behavior is unsatisfactory in some cases. It is shown theoretically that a certain class of these mixed generators should be expected to fail statistical tests for randomness. Extensive testing confirms this hypothesis and makes possible a more precise definition of the unsatisfactory class. It is concluded that the advantages of mixed generators can be realized only in special circumstances. On machines with relatively short multiplication times the multiplicative generators are to be preferred.", "authors": ["J. L. Allard", "A. R. Dobell", "T. E. Hull"], "n_citation": 26, "references": ["0248f4aa-9c66-4a5b-bf1a-bf480dd61ccb", "3cd6bd32-88a6-4a64-8b4d-5af63096ff6a", "e0bcf598-68b3-4de5-8b5a-f03f69823c6a"], "title": "Mixed Congruential Random Number Generators for Decimal Machines", "venue": "Journal of the ACM", "year": 1963, "id": "5b779d24-2f12-4641-a9e5-902563c11bd2"}
{"abstract": "The dynamic nature of highly autonomous agents within distributed systems is difficult to specify with existing requirements techniques. However, capturing the possibly shifting configurations of agents in the requirements specification is essential for safe reuse of agents. The contribution of this work is an extensible agent-oriented requirements specification template for distributed systems that supports safe reuse. We make two basic claims for this idea. First, by adopting a product-line-like approach, it exploits component reuse during system evolution. Second, the template allows ready integration with an existing tool-supported, safety analysis technique sensitive to dynamic variations within the components (i.e., agents) of a system. To illustrate these claims, we apply the requirements specification template and safety analysis to a real-world context-aware, distributed satellite system.", "authors": ["Josh Dehlinger", "Robyn R. Lutz"], "n_citation": 32, "references": ["064ce9f0-4bc2-45e5-8583-0e050d233c81", "2c727d91-b7bc-4288-a4f4-60b156a94187", "326da744-cf73-4128-948a-58a08ab78b63", "365ac4aa-5611-41ad-8018-6dba33f27ada", "5e94e889-e70e-4a59-87f2-9aafc3449c98", "7281029e-9726-4dfb-b64e-fbc1d4cc3c13", "a6a9747d-a2fe-4d60-a5b0-f4b5ca56c17f", "aa032f20-515b-4789-975e-fe2cfade36c7", "c786706b-171b-4476-85d0-3a18819142c2", "e8071820-9a33-4a0a-98a5-1658d3d6e8e0", "fc86547c-bf92-4301-a274-1ceedca42d94"], "title": "A product-line requirements approach to safe reuse in multi-agent systems", "venue": "ACM Sigsoft Software Engineering Notes", "year": 2005, "id": "4373e927-8ab8-4a95-a1be-6acce65e2727"}
{"abstract": "In the standard generative Model-driven Architecture (MDA), adapting the models of an existing system requires re-generation and restarting of that system. This is due to a strong separation between the modeling environment and the runtime environment. Certain current approaches remove this separation, allowing a system to be changed smoothly when the model changes. These approaches are, however, based on interpretation of modeling information rather than on generation, as in MDA. This paper describes an architecture that supports fine-grained evolution combined with generative model-driven development. Fine-grained changes are applied in a generative model-driven way to a system that has itself been developed in this way. To achieve this, model changes must be propagated correctly toward impacted elements. The impact of a model change flows along three dimensions: implementation, data (instances), and modeled dependencies. These three dimensions are explicitly represented in an integrated modeling-runtime environment to enable traceability. This implies a fundamental rethinking of MDA.", "authors": ["Theo Dirk Meijler", "Jan Pettersen Nytun", "Andreas Prinz", "Hans Wortmann"], "n_citation": 15, "references": ["00199e54-1891-4e79-b6e5-ca2b631753d4", "040f368a-5c89-44c1-bbd3-c8fb2cd32e38", "042cf0e4-faa9-4d76-8b0d-f1fe9646aaf4", "048f2a4c-9ed7-4f40-8641-94ddbdebc091", "0697277c-f339-48cd-b805-b6c8ce59c211", "085ba3f1-6356-40d7-b191-442590360e8e", "0fcad505-603e-45ec-873b-64fc4c958c6d", "14df238b-c2b9-4ef3-b92c-e10389326439", "22b85f26-df7c-467d-b1aa-5d9d3ae2d8b2", "28f4aa8f-399b-4b78-9af5-2453fa078286", "375c2717-72f2-4136-b0ef-8f3073494a04", "3aab7045-5ae8-47c8-a675-79a6c2e7694b", "3fac4a85-0bba-4a1c-aad5-759e2a0ce8c6", "40d5d62c-353e-408b-8256-2c59128ca519", "50689679-8346-48f2-8d70-4dfd29f8b470", "5a343813-1254-4847-a1db-2bc0480c3d56", "5db62f3e-d72c-497d-bf90-19d4b4fdf55f", "62ca07bb-49c1-4833-84d7-378c769295d7", "6f027909-7629-490a-adcd-fd083ce923c2", "73c565f0-f1e5-4e5a-9efc-4b53372bc4fe", "73e5ee19-673e-4f86-be1a-49e1b4ff9a3b", "8bce7416-bd0c-40ba-859b-3c7e27f38a82", "8c30bffe-4692-4c54-875d-ed5d52022ce3", "91bd5bed-21b6-4344-a446-917b483f5827", "95ac0b83-36fa-4ce4-91b2-a5d206e06555", "9a4181a5-70d2-48b7-945d-8d72d9c74874", "9cee608b-8c28-403c-bcb4-aec0f595a952", "9ee4a463-c534-4f36-841e-a15b0458c517", "ad5064e6-561d-4545-bf22-9550fee5bd6f", "b6cae174-5805-4b8c-bdfb-a9884e3fec7e", "d0801d36-ecfd-4b86-b78d-62000a6caf02", "d82a02bb-cc47-4113-b2ff-bb4f9339f2f9", "db9446f3-b707-40a8-b765-50556376bdc9", "e28e269b-2f85-437b-8b51-745866d22a93", "e3949ba8-e048-4bc5-8aa5-5a415ecc1d2f", "e3ba6428-74ba-41c2-9bd7-148a2c6308a8", "f2998233-e390-4217-a3c1-0189883873bb", "fcf11b61-a2f4-4b64-9f77-f2e3d8177b15"], "title": "Supporting fine-grained generative model-driven evolution", "venue": "international conference on model transformation", "year": 2010, "id": "3de9511f-310f-4f99-8d35-258c1b7d11f0"}
{"abstract": "We introduce XIML (eXtensible Interface Markup Language), a proposed common representation for interaction data. We claim that XIML fulfills the requirements that we have found essential for a language of its type: (1) it supports design, operation, organization, and evaluation functions, (2) it is able to relate the abstract and concrete data elements of an interface, and (3) it enables knowledge-based systems to exploit the captured data.", "authors": ["Angel R. Puerta", "Jacob Eisenstein"], "n_citation": 323, "references": ["5d64ab8c-c9e4-4f21-83f0-46d8477350b3", "95220f17-d29c-49ee-b556-96ca8624fc0b"], "title": "XIML: a common representation for interaction data", "venue": "intelligent user interfaces", "year": 2002, "id": "14e0aef9-7abd-4167-9266-bf716467a3dd"}
{"abstract": "Topic models based on latent Dirichlet allocation (LDA) assume a predefined vocabulary. This is reasonable in batch settings but not reasonable for streaming and online settings. To address this lacuna, we extend LDA by drawing topics from a Dirichlet process whose base distribution is a dis- tribution over all strings rather than from a finite Dirichlet. We develop inference using online vari- ational inference and\u2014to only consider a finite number of words for each topic\u2014propose heuris- tics to dynamically order, expand, and contract the set of words we consider in our vocabulary. We show our model can successfully incorporate new words and that it performs better than topic models with finite vocabularies in evaluations of topic quality and classification performance.", "authors": ["Ke Zhai", "Jordan L. Boyd-Graber"], "n_citation": 50, "references": ["02e393a1-7186-43d6-8c17-50802b5530af", "1d8aad5a-e384-4408-89ba-bfcc5be65502", "29f294e7-618e-4121-9564-420b6ec1615b", "32198690-fdd8-40d8-98b1-f2bed40b2e05", "32d18b97-b9f3-4b43-8eed-c91ec375b527", "5317fbe4-f12c-414c-93e3-2bb094131ddd", "548f8efe-f694-4ca0-98aa-42346d8ad0ff", "5ca24373-921c-4d98-bd59-dde8bc3880e0", "6b2b23e0-f2e5-43d7-bc57-4ebe3df724c4", "70865e0b-edf5-4976-8595-83c05d09676a", "70cd6ea3-7a47-4b03-a125-eeee7d5ccacd", "8026f56a-a93e-4933-8ead-c9aa9e3f0498", "9a0e01fd-96a5-481f-92ef-cffb86a3c859", "c315c904-4da8-42a5-bd83-9866ef5c34a9", "c342b8a6-cd87-410b-8f22-401cfc696488", "c6109c25-27e5-4c6f-b527-83e8825554be", "c98c6d21-9bd1-451e-b0bd-e54d73d2701c", "d05a104c-6d43-451b-a2e2-7d065fe8bec4", "d38a74f0-1628-4d0e-92cf-72e3f6f6b6f7", "d5c3a7d8-865f-4a16-8efa-b93af220c04c", "deeb9df2-0021-4d21-8cf7-90554a7804ae", "e9a13666-2463-4c37-9299-b3c4e80ad124", "efbd8f24-96b7-487d-b902-987cf5ef92eb", "fc972a77-e6c7-420c-a452-67f7610a2470", "feb3a6a8-887d-4998-8c08-62bfa8404d02"], "title": "Online Latent Dirichlet Allocation with Infinite Vocabulary", "venue": "international conference on machine learning", "year": 2013, "id": "23cd8f39-6ad0-4d5a-8f42-3ffad1e41c55"}
{"abstract": "We model the behavior of a fifo-queue as a monoid of transformations that are induced by sequences of writing and reading. We describe this monoid by means of a confluent and terminating semi-Thue system and study some of its basic algebraic properties such as conjugacy. Moreover, we show that while several properties concerning its rational subsets are undecidable, their uniform membership problem is \\({{\\mathsf {N}}}{{\\mathsf {L}}}\\)-complete. Furthermore, we present an algebraic characterization of this monoid\u2019s recognizable subsets. Finally, we prove that it is not Thurston-automatic.", "authors": ["Martin Huschenbett", "Dietrich Kuske", "Georg Zetzsche"], "n_citation": 50, "references": ["04a3a2b2-e346-4aac-8e12-5da52abba972", "054f22d4-8616-4fd4-8eff-2b75a9b1d2eb", "212baeef-144f-4813-b9de-93413a6a26f8", "332084ee-29ab-411e-9d8b-0dc9e977c5a9", "4b21a6d1-b450-4837-b7b0-3cb1a2a8a113", "5221c96a-50e0-45db-9216-276c0eb7a050", "f0902ef5-33af-47f3-9167-247bd19b4436"], "title": "The monoid of queue actions", "venue": "Semigroup Forum", "year": 2016, "id": "47be856d-1f7e-4d97-affd-b11ea78b4a9f"}
{"abstract": "Recently there have been a number of works that model the zero pronoun resolution with the concept called 'center.' However, the usefulness of the previous centering frameworks has not fully evaluated with naturally occurring discourses. Furthermore, the previous centering theory has handled only the phenomena in successive simple sentences and has not adequately addressed the way to handle complex sentences that are prevalent in naturally occurring discourses. In this paper, we present a method to handle complex sentences with the centering theory and describe our framework that identifies the autecedents of zero pronouns in naturally occurring Japanese discourses. We also present the evaluation of our framework with real discourses.", "authors": ["Okumura Manabu", "Tamura Kouji"], "n_citation": 50, "references": ["0444f46a-d639-4ed3-ac42-b8fe9d0968ac", "2ec8c8a9-f78d-478e-9f8c-70ccced5c93a", "359bd98a-79e3-4a8a-96d0-517276d79102", "363ae5c2-3c49-45d2-b7d3-1010f9925989", "4951f730-6e5e-43bd-82b4-6ab3e844a6b0", "60cbe556-7db4-4137-a6f4-5f853a9fe2b7", "61480cc2-3693-4aea-9063-87a97ae9e376", "91b20505-73dd-4564-b9b0-260d4828f148", "e7c7faf3-1017-43cb-a8d4-5b307c399175", "f0a5e86a-36b0-4c47-b085-0d35f15e9e8e", "f5dbbc9f-c8fc-4818-81b7-44e62db5a285"], "title": "Zero pronoun resolution in Japanese discourse based on centering theory", "venue": "international conference on computational linguistics", "year": 1996, "id": "a7f4e358-276d-4f98-b7f2-a5355543a13e"}
{"abstract": "We will apply a system-internal combination of memory-based learning classifiers to the CoNLL-2000 shared task: finding base chunks. Apart from testing different combination methods, we will also examine if dividing the chunking process in a boundary recognition phase and a type identification phase would aid performance.", "authors": ["Erik F. Tjong Kim Sang"], "n_citation": 62, "references": ["0b1f5092-4b64-4d5e-8bf7-15295db41f4f", "0ba88635-896d-431a-a37a-49ebb7c74749", "31f54397-343f-4b98-b19e-7600734ed2d1", "5a542967-6031-4500-9bdf-f3cd017857d1", "74f70b67-2424-4a83-9c6a-62f3ea2cad4a", "d0cf7193-4447-4fdd-aa4e-fce6746b8b7d"], "title": "Text chunking by system combination", "venue": "", "year": 2000, "id": "c171e946-ef93-4928-914e-ab64332a2480"}
{"abstract": "We define an operational semantics for a large part of the Android platform, encompassing the Dalvik bytecode but also, and more importantly, the inter-component communication mechanism used inside Android applications. This semantics is intended to provide a formal basis for the development of static analyses that consider the complex flow of information exposed by the cooperating components of Android applications.", "authors": ["\u00c9tienne Payet", "Fausto Spoto"], "n_citation": 18, "references": ["00f4c1d6-7224-4c69-8bf7-08f1478594dc", "2c47f7e0-31fb-4765-a9e8-898c47b4e4cf", "3c456b9a-1f87-47a4-8505-aceabbff0d1c", "3e5b1e46-d6c9-4d8d-8b9a-eb6296b3a9ae", "3f7b0ee2-1a9a-42db-9e00-ce61e697799f", "472285e8-0254-40e5-9039-761846df1e63", "5190b376-7923-445f-a891-d1bac46fd35d", "c064e9ed-090c-4113-a08d-0abeeb8d066a", "da82e048-1d80-4bc5-984a-3746904f65b2", "e6510c10-61e7-48b3-9565-4577ad7ad15b", "fc2384c8-1124-48ac-b4e9-fcb5715d3f45"], "title": "An operational semantics for android activities", "venue": "partial evaluation and semantic-based program manipulation", "year": 2014, "id": "5330b492-b76e-41b7-a694-a71a109c03c4"}
{"abstract": "We consider different ways to control the magnification in self-organizing maps (SOM) and neural gas (NG). Starting from early approaches of magnification control in vector quantization, we then concentrate on different approaches for SOM and NG. We show that three structurally similar approaches can be applied to both algorithms that are localized learning, concave-convex learning, and winner-relaxing learning. Thereby, the approach of concave-convex learning in SOM is extended to a more general description, whereas the concave-convex learning for NG is new. In general, the control mechanisms generate only slightly different behavior comparing both neural algorithms. However, we emphasize that the NG results are valid for any data dimension, whereas in the SOM case, the results hold only for the one-dimensional case.", "authors": ["Thomas Villmann", "Jens Christian Claussen"], "n_citation": 85, "references": ["07b3a51a-83be-46fe-b440-7c4e3e821bff", "0c6cf3c4-cab2-407b-830a-30c8cc919c0c", "12d9a81f-f846-40ec-9c1e-1c62e24fe909", "2834deb1-eaf2-40c8-899c-fdf2d28e556f", "2eaa8cb8-3419-44aa-bd41-b9ddb3f08c3a", "3dcce91e-5032-466a-b052-01d5ab976e4e", "43988db0-7689-4085-ba94-0e48a748b5c1", "47c61f1f-a000-4382-afaa-5a9e08330749", "4a29b56b-b74e-4945-9017-61a7ab844fd9", "4a706cbc-2c7b-4f85-bcc9-1b6b03f16e89", "4cc5fb0d-716e-4707-9114-36a0b01876e3", "4e6f22d6-473d-4377-ac47-baba338fc59d", "7fe95e88-417b-4b70-b951-650a32f73f02", "801da66d-7b75-4cbc-a393-8f44b72a7442", "89aab853-7e21-47c3-aca5-f8e840356644", "9132939c-9d33-4065-b39a-dd1d284aa0c7", "99f3f81f-397d-4b8d-a417-7b23bfc87025", "9b507dee-56f3-483f-94de-25e61ead046f", "a1957b43-5855-4649-8e9b-722246a4ee62", "a388da07-1608-4b15-aa08-a6cbb53be603", "a49e7333-e2da-46f2-b941-ce1326c32327", "a684a889-a21f-4ddf-96d1-ab04393ecc72", "b928341f-6f73-4c80-93a8-290a8c5a9ac9", "bfc3188a-576b-4fb9-9b5a-40037dcf4838", "cd1750e9-a92e-4446-be61-c9414f3628d0", "d1df45f9-5578-4a0c-b080-f97f39358366", "d36202a4-6107-4c39-b6fa-5abdc6af1167", "e657347b-ef42-4ada-a4af-a22547dab299", "ec0c146d-ff15-4f73-8ea1-55268340ab42", "f10777c8-6708-4043-b9ba-a7548ef617a2", "f1e1ebca-e0c8-4dbb-a488-72e9e49d9dad", "f4ded15e-fab3-4896-86de-2abc73b4f9e9", "fd69b995-8e76-4cdd-a460-217dadb15492"], "title": "Magnification Control in Self-Organizing Maps and Neural Gas", "venue": "Neural Computation", "year": 2006, "id": "7a70ce09-2b9a-4074-9097-1f6e806ac3ee"}
{"abstract": "During the software development process, developers are often faced with problem solving situations. For instance, it is common the occurrence of exceptions, that originate stack traces in the Console View of the IDE. These situations motivate the developer to use the Web to search for information. However, there is a gap between the IDE and the Web, requiring developers to spend significant time searching for relevant information and navigating through web pages in a Web browser. We propose to process the information of exception stack traces and retrieve question-answering web resources to help developers. We developed a tool that integrates recommendation of question/answer web resources in Eclipse, according to the context of these exception stack traces. The results of a preliminary experimentation are promising, showing that our approach performs better than a simple keyword-based approach.", "authors": ["Joel Cordeiro", "Bruno Antunes", "Paulo Gomes"], "n_citation": 50, "references": ["162e511f-902a-47eb-bdb8-df20e41924ba", "52c7fe50-86ed-4b2a-90e1-e576e27b6d50", "54c7f3b5-5694-4014-9817-1b42923c01f5", "5978d5c6-942d-4f16-8e71-e645f25ac0e4", "5d6c6662-67af-4500-833a-c9f93979217e", "922211f9-342c-4537-9df7-ca3a236b647b", "a9bebd1c-c583-4824-8c04-3bd6d66aad50", "cb191d39-0288-4263-a0f9-c63d5c673284", "dd1bb6c3-505b-444b-bb6d-236595404d1f"], "title": "Context-based recommendation to support problem solving in software development", "venue": "", "year": 2012, "id": "b91f939e-41d2-4b91-8561-d8b5bcb10826"}
{"abstract": "Workflow systems are popular in daily business processing. Since vulnerability cannot be totally removed from a workflow management system, successful attacks always happen and may inject malicious tasks or incorrect data into the workflow system. Referring to the incorrect data further corrupt more data objects in the system, which comprises the integrity level of the system. This problem cannot be efficiently solved by existing defense mechanisms, such as access control, intrusion detection, and checkpoints. In this paper, we propose a practical solution for online attack recovery of workflows. The recovery system discovers all damages caused by the malicious tasks that the intrusion detection system reports and automatically repairs the damages based on data and control dependencies among workflow tasks. We analyze the behaviors of our attack recovery system based on the continuous time Markov chain model. The analytical results demonstrate that our system is practical when the parameters of the system are reasonably designed.", "authors": ["Meng Yu", "Peng Liu", "Wanyu Zang"], "n_citation": 44, "references": ["11f52fe3-4eca-4818-9bcf-9e24cdc76fb5", "2f182a8d-380f-4f42-ab22-3629730446b4", "2faae6b7-41e8-49b9-ac18-333fc066ca09", "6224b87f-336f-4acb-adfa-93ed7fa3d104", "a43e5df7-17f2-4923-a4c7-9f628efbf357", "b444d0f9-0325-4edf-b3a6-144ea5f0ca72", "ec129a04-1877-4223-9669-ec6921cf75af", "ee83c563-1733-40d1-a512-a8751e001a53", "f6b8341a-0222-4ed4-a326-29d7d9edad08"], "title": "Self-healing workflow systems under attacks", "venue": "international conference on distributed computing systems", "year": 2004, "id": "3a7be73f-419d-4d6e-92fb-7f5a4b2b2148"}
{"abstract": "Summary - Process, workflow, and groupware projects both in the commercial and research worlds have each approached the problem of human communication and coordination with different sets of tools and technologies implemented from different perspectives. Activity dependencies and the philosophical assumptions about how work is performed are managed differently in each discipline. While most of these tools represent promising approaches, they have yet to be widely adopted, particularly in the face of increased usage of online information through the WWW and computer networks. Electronic information coming to the individual and into the corporation is becoming increasingly unmanageable. People are able to create information regardless of their location or method of access due to increasing mobility and interoperability of the tools they use. Because of the common concerns, trends are moving towards overlap and convergence of requirements. However, these communities have yet to identify the union of cross-discipline requirements for a supporting technical infrastructure addressing the level of flexibility, scalability, and support for evolution over time required in these realworld settings. This paper surveys the current approaches to project communication and coordination, details the range of requirements across several related disciplines, and identifies various tradeoffs and trends which may effect the adoption, design, and evolution of an advanced technical workflow infrastructure.", "authors": ["Gregory Alan Bolcer", "Richard N. Taylor"], "n_citation": 73, "references": ["03d4ccbf-d029-4793-801e-be213b0a86ab", "03ff2c6d-b925-435d-9595-7ef830d314a6", "096b80b2-6e89-4ee5-9aeb-345495e9056c", "09beb38b-017b-4c99-a9c5-2bde1e29542f", "0b9ac3a1-01af-42a5-af12-85d7189ea8eb", "0d261b6a-c94a-4d5e-b44e-eb6ae46581fc", "17779c7a-961f-4a1a-8a3d-48dd51193ef0", "1b1a53ee-4a32-45d4-b5b9-4c75c4043de4", "1df93780-c7cb-49e4-885a-7f1c50a2280d", "2157775f-f3ab-4efb-84e3-ab593a0c3139", "216dd5ba-6e1f-48ee-b24b-93327a0949a0", "3163963f-d1f1-4aa0-a525-3f99adeed109", "32ca3daa-14a3-4005-ae79-49969fdd979d", "352b431a-4192-48c8-b802-ec1257f90561", "35785a90-c318-4ebd-8f6c-b1df34964a41", "36cac293-ee33-4c1a-a9c7-0787a7c37bb0", "3ff297f0-d5bd-4629-8a18-5d508e413e9c", "406f694d-b550-4761-bfad-a7d61833d528", "4097e3d1-333b-484b-8553-9807f6c8fb6c", "4c979d88-2108-4065-8bd0-b34ec8cbf11c", "4ccff0a0-d130-43a8-b3a5-f27fb02ffe56", "4d4b8513-5b47-4f1b-93b1-7fef29e0e518", "5550b9d7-9532-4b68-9d83-fef9613bcee8", "59900f1b-0025-4c03-84d7-dc4bc2dccb9f", "5c798661-8c7a-46d0-ab1f-3f1966546e0a", "64472c04-d171-4b64-aef2-b21e9078d287", "68b26df6-aec9-43eb-b17f-aacabed53bc6", "6c849fa6-7d3e-478a-92e9-21c37974ae0f", "72af55e9-abe9-4d57-a961-cd05aaa738e4", "76dd63d9-5daa-4ac3-8ea4-2c2c4ac93f42", "78c32f28-ce79-4586-b40c-2803c6dac693", "7f1dc63a-9064-4768-a30d-3383d52aa81e", "88a96503-e816-4af5-9b82-392e330e5db5", "8f1dad1e-a4af-4d68-9d13-013910a3e356", "95f668c5-4d25-423b-b136-18146b9b176b", "9d12aa61-a93a-4c06-bc8b-2420300bbb4e", "9ebf2cbd-ae53-487a-8410-d2a5c706f133", "a13a126e-37f7-4fad-8cfe-a3184320d64a", "ad3b42a6-f3ef-4b8b-867c-76df8738ad31", "b0c6eaf3-da91-4731-a95e-58618d474c1b", "bdc94277-8125-4aff-bbcd-b5e6e1fda167", "c19516ed-226e-4576-8d3a-36cfd3c8fb4c", "c4033a23-cf28-4e01-89b2-368be6d1f0c0", "c660d926-a480-4afb-b692-2cf3a4f8ca6e", "cb47d0fc-6659-4ac8-b175-3cd32fab0abd", "d4cb7dff-4a97-4efb-9a91-b0861e7602ee", "d970e93e-98e2-426a-92f8-f5d40e54f0a8", "d9d55e84-f252-438c-b819-20583f5bad2c", "e075bb6a-aad5-49ab-abc2-a8f098b64e1a", "e50fa3ec-9688-4a57-8ea8-07c502a07919", "e927699f-c24e-49fa-9cff-db1e77776285", "e9ad62a7-612c-4581-ac73-8b008c5f797a", "ebef4cd8-7d0f-4144-ac22-8dd4c0fffb73", "ec60a010-f6b3-4dd8-ba57-35feadea84af", "f9817e18-25bc-4cf0-ae0f-3764c1a34799", "f9e0c309-030b-4c17-8566-6b7354124720", "fa26b232-9c8c-4982-a140-eae87fab5b57", "fab24135-f4e2-44c5-ab9f-676b726f598d", "fbca8108-2171-4212-b479-23c3837bc28e"], "title": "Advanced Workflow Management Technologies", "venue": "Software Process: Improvement and Practice", "year": 1998, "id": "560ba00a-b900-4e7b-a223-88644b5b965a"}
{"abstract": "Cigarette smoking is a major global public health issue and the leading cause of preventable death in the United States. Toward a goal of designing better smoking cessation treatments, system identification techniques are applied to intervention data to describe smoking cessation as a process of behaviour change. System identification problems that draw from two modelling paradigms in quantitative psychology (statistical mediation and self-regulation) are considered, consisting of a series of continuous-time estimation problems. A continuous-time dynamic modelling approach is employed to describe the response of craving and smoking rates during a quit attempt, as captured in data from a smoking cessation clinical trial. The use of continuous-time models provide benefits of parsimony, ease of interpretation, and the opportunity to work with uneven or missing data.", "authors": ["Kevin P. Timms", "Daniel E. Rivera", "Linda M. Collins", "Megan E. Piper"], "n_citation": 11, "references": ["09784998-5bcd-4348-a2ed-2ef79ad55381", "5601ea95-97f9-4a10-aeec-efe0f621668d", "902daaa0-a2cf-4421-a256-547114f2b625", "933e8b0f-d324-4a75-9e72-59fe6db336e6", "cd76c15d-0e5b-43e0-8264-888d059fb7ef", "d121541f-f103-480f-a13a-d1da481948ec"], "title": "Continuous-Time System Identification of a Smoking Cessation Intervention.", "venue": "International Journal of Control", "year": 2014, "id": "c297a832-1002-48f6-bcbc-db4f8c008f97"}
{"abstract": "Abstract The use of network-based parallel computing is gaining an increasing popularity for different reasons. Its exploitation depends on the availability of simple but effective methodologies to parallelize applications, and the availability of portable and efficient communication libraries to develop parallel programs. These two items are necessary to obtain performance advantages, and to ensure software portability and reusability. In this paper we present our experience in parallelizing, in a systematic way, a class of Geographical Information Systems applications. We discuss the use of two well-known communication libraries (PVM and Linda). Performance results are also reported.", "authors": ["Andrea Clematis", "Bianca Falcidieno", "Michela Spagnuolo"], "n_citation": 17, "references": ["0fc2786c-7059-45b0-b52f-a997a90ffee9", "35add510-41d5-4147-8675-8d56e84ed93b", "3c2b6887-7b44-42c2-bf79-ac44c38a5eb7", "53e2e1b8-1670-49da-9d87-5cbb17415063", "59c732a7-663a-44e1-a568-1b4af6a98888", "745eef74-c3b4-4e4b-a92c-5dc6ea72b11a", "e0398fde-a5f7-4720-91a7-6316c7f0db06", "f1117085-8a11-47b0-8301-1b7b32c09ba6"], "title": "Parallel processing on heterogeneous networks for GIS applications", "venue": "International Journal of Geographic Information Systems", "year": 1996, "id": "6361e63f-0cce-48e1-b700-d7c01f4b8b6c"}
{"authors": ["Ulrike Sattler"], "n_citation": 55, "title": "Terminological knowledge representation systems in a process engineering application", "venue": "", "year": 1998, "id": "6eb47b72-bf86-4e1b-b64b-566825e5400d"}
{"abstract": "We present a sound type-based 'usage analysis' for a realistic lazy functional language. Accurate information on the usage of program subexpressions in a lazy functional language permits a compiler to perform a number of useful optimisations. However, existing analyses are either ad-hoc and approximate, or defined over restricted languages.Our work extends the Once Upon A Type system of Turner, Mossin, and Wadler (FPCA'95). Firstly, we add type polymorphism, an essential feature of typed functional programming languages. Secondly, we include general Hsskell-style user-defined algebraic data types. Thirdly, we explain and solve the 'poisoning problem', which causes the earlier analysis to yield poor results. Interesting design choices turn up in each of these areas.Our analysis is sound with respect to a Launchbury-style operational semantics, and it is straightforward to implement. Good results have been obtained from a prototype implementation, and we are currently integrating the system into the Glasgow Haskell Compiler.", "authors": ["Keith Wansbrough", "Simon L. Peyton Jones"], "n_citation": 71, "references": ["001bf369-31a1-4ac7-9460-afeefcdeea15", "02295960-52f6-41f5-b9c4-8ef1996fdb0a", "17d5c483-cf53-432b-bb1c-ad54dcabaeac", "1fd3f84d-9a5f-4a6b-b84c-58d7d40655b1", "21d3fc3b-da3e-4b5a-9d72-ac72a15df43b", "43ab3a12-d68e-4f19-a7d9-8c5f43ccfa7f", "50256aa5-05cf-4f36-8dec-77bcefa98bd1", "5d54bdce-3326-4707-be32-564c756450a6", "5de56286-91f3-49cb-ab3a-6e98b4abf0d8", "82aa9af7-36ca-4954-bb20-ab26ee946551", "910b6285-e68c-427d-ba9a-f77981c2894d", "9e18b4c0-7b19-46d5-a6d2-1edeffaa194d", "a7476d9f-a32a-4ce6-b637-672eeb14463e", "c53b9595-998f-4fd5-8450-7b5f709f25f7", "cb2a819f-48d2-4a58-b966-e3933e5a3a1c", "e955b928-fc12-4e79-84d1-e936ea6a49d7"], "title": "Once upon a polymorphic type", "venue": "symposium on principles of programming languages", "year": 1999, "id": "a96c0d76-802e-4cfc-9e4a-a69a76106fb5"}
{"abstract": "We present a framework of syntactic models for the definition and implementation of visual languages. We analyze a wide range of existing visual languages and, for each of them, we propose a characterization according to a syntactic model. The framework has been implemented in the Visual Language Compiler-Compiler (VLCC) system. VLCC is a practical, flexible and extensible tool for the automatic generation of visual programming environments which allows to implement visual languages once they are modeled according to a syntactic model.", "authors": ["Gennaro Costagliola", "A. De Lucia", "Sergio Orefice", "Genny Tortora"], "n_citation": 50, "references": ["0d261b6a-c94a-4d5e-b44e-eb6ae46581fc", "170ef136-59f9-40dd-8c91-4e68cb7c924e", "1f0a8ead-915f-4340-8501-edb05f2d28e4", "2b85e570-cfb6-4be2-b488-a9e24a5655d1", "3573ee48-4571-4a6e-9715-a1b2f0eaffe0", "478d61db-de9d-4f0e-81df-9a72714bd911", "5377916d-b86d-43cc-9dd7-76f0d221424a", "56ade88b-a40a-4567-b5de-e0b846f7c176", "5e3ff344-0d96-4db0-b98b-c686ca6d153e", "7a5e84ff-ce4a-4571-ba33-eb6b35c5397f", "7a7d675f-91c2-4f4c-a604-5f616a9fc9f9", "7ea32def-dd27-4ded-8579-787e729a5388", "7fd01415-9737-4352-b44f-56bd475a115c", "91d89ad7-e2c9-4384-9a60-68aee87a0565", "aa2626d2-1f26-42e8-bdae-db838eb8bc31", "aa99bb4a-1767-45f7-a25c-4374181a0fb9", "aaad4d08-18eb-4a66-b062-11d824bfb00a", "b1fae319-06f0-4712-8646-03ec2b87d5c4", "b75e0d44-f947-4922-be73-5e1fb7512fae", "bc1dc80c-0805-4943-9cec-8723670336ad", "bc55a28f-1e19-445b-8e35-265135fd9315", "bfadb62a-a572-49a5-877f-718fea853445", "c40bffa2-02cc-4e6f-8484-40a6132b608f", "c79ec49e-60c2-41f0-b12f-0ea518134a7f", "cdbf5f28-d815-47a5-a190-9aa32d259224", "e1aac4c1-f631-4cf7-bd37-d199249d322d", "e3710520-2dd2-4d56-9133-12ef16d73c80", "fcff6e7d-7609-4356-a711-05c51a519a3f"], "title": "A framework of syntactic models for the implementation of visual languages", "venue": "", "year": 1997, "id": "747e89ca-d160-4d5f-b288-159a0b17bd7c"}
{"abstract": "Multicast group communication is a useful augmentation to CORBA both for fault-tolerant and highly available applications and for groupware and cooperative work applications. However, different multicast group communication protocols are appropriate in different environments, e.g. local area vs. wide area networks, and Internet vs. ATM. In this paper, we present a multicast group communication engine and bridge for CORBA that allows different multicast group communication protocols to cooperate. The group communication engine places Lamport timestamps on messages, and multicasts messages to object groups using one or more group communication protocols. The group communication protocols reliably deliver the timestamped messages in timestamp order to the group communication engine, which integrates these streams of messages into a single stream for delivery in timestamp order.", "authors": ["Louise E. Moser", "P. M. Melliar-Smith", "P. Naraimhan", "Ruppert R. Koch", "Karlo Berket"], "n_citation": 50, "references": ["07d1c868-222a-40f3-b914-2d03362e5ede", "136c4780-2f25-4068-90a5-aed6afaf2890", "23bf6722-20e5-4cff-ae33-bdf0ffd14bae", "2cb441e0-2033-4762-84b4-86146ec8bd03", "7e174fc0-3dae-466a-93cd-b10fe45bcaa3", "821ecb6c-1cd6-4ce3-a45a-d87641f5b558", "870b655d-408c-4e98-87be-8a83bf1e27e0", "b24f49f2-7001-4fca-a44e-c0a4acd0322e", "b5635a67-86ea-4fb1-93ba-c9b198344628", "b6a05570-3e8b-46f8-aa87-30258f882304", "c41c12e7-e703-40db-9163-88090faecb05", "c92ab2ef-2d59-4edc-9a41-6ba6fb7c926e", "e7857381-83eb-4350-baad-3d12decd3cb7", "eba8686f-28e9-4525-a908-5f4467b25298"], "title": "Multicast group communication for CORBA", "venue": "", "year": 1999, "id": "398683e8-0393-4f3c-a186-3ed3595e9efe"}
{"abstract": "In this paper we present MD, a logical model for OLAP systems, and show how it can be used in the design of multidimensional databases. Unlike other models for multidimensional databases, MD is independent of any specific implementation (relational or proprietary multidimensional) and as such it provides a clear separation between practical and conceptual aspects. In this framework, we present a design methodology, to obtain an MD scheme from an operational database. We then show how an MD database can be implemented, describing translations into relational tables and into multidimensional arrays.", "authors": ["Luca Cabibbo", "Riccardo Torlone"], "n_citation": 388, "references": ["80e90b76-a451-4fbf-98c4-bda3c3f51466", "ca6e8d30-37b3-4e0f-a771-671532d77b38", "d3c5fc62-2f5b-4ab2-a321-564ef9232643", "fb2defa9-999c-47c5-8b2e-1314f053cbfc"], "title": "A Logical Approach to Multidimensional Databases", "venue": "extending database technology", "year": 1998, "id": "64bb5fc1-f41a-47e8-b336-e48373ab81c0"}
{"abstract": "The Hough transform (HT) is a popular tool for line detection due to its robustness to noise and missing data. However, the computational cost associated to its voting scheme has prevented software implementations to achieve real-time performance, except for very small images. Many dedicated hardware designs have been proposed, but such architectures restrict the image sizes they can handle. We present an improved voting scheme for the HT that allows a software implementation to achieve real-time performance even on relatively large images. Our approach operates on clusters of approximately collinear pixels. For each cluster, votes are cast using an oriented elliptical-Gaussian kernel that models the uncertainty associated with the best-fitting line with respect to the corresponding cluster. The proposed approach not only significantly improves the performance of the voting scheme, but also produces a much cleaner voting map and makes the transform more robust to the detection of spurious lines.", "authors": ["Leandro A. F. Fernandes", "Manuel M. Oliveira"], "n_citation": 339, "references": ["010e8977-1ff2-4c21-b2c6-3d15a6788d09", "0ff7c995-1ad2-4b55-9a38-ab8a1192313c", "2910b819-c8b5-4e96-a133-ed2fb0e85020", "340c6e6c-4daf-4136-8c51-a2bbfd713d33", "3dcc09a3-6106-48dc-98f2-40858f983851", "3f1ca1a8-fa52-48e8-a4ad-e97db54a0183", "6c82fbcc-4297-4513-a7a8-31575762f005", "6dc8831a-d7f5-4eae-993e-856f91a326f6", "743b4976-2d8a-4210-ab42-70184f397876", "78dd7c1a-bc00-4993-bd41-8e5da9a7fe5b", "8174dee8-466a-48f0-9bb3-5d141fe69e82", "c301a39d-72d2-44e0-8dd5-aa153eb40fa3", "c76ab2f4-a4ec-46d5-b5dd-6174685b5b4e", "e46bb6ea-7b67-4edf-8cd4-a51ce64cff19", "eac44870-7d5c-4021-96ca-7533ca115a88"], "title": "Real-time line detection through an improved Hough transform voting scheme", "venue": "Pattern Recognition", "year": 2008, "id": "578d3c50-5f6d-43de-93ea-e88f74e48c3b"}
{"abstract": "In this paper, we describe the concept of music scene description and address the problem of detecting melody and bass lines in real-world audio signals containing the sounds of various instruments. Most previous pitch-estimation methods have had difficulty dealing with such complex music signals because these methods were designed to deal with mixtures of only a few sounds. To enable estimation of the fundamental frequency (F0) of the melody and bass lines, we propose a predominant-F0 estimation method called PreFEst that does not rely on the unreliable fundamental component and obtains the most predominant F0 supported by harmonics within an intentionally limited frequency range. This method estimates the relative dominance of every possible F0 (represented as a probability density function of the F0) by using MAP (maximum a posteriori probability) estimation and considers the F0s temporal continuity by using a multiple-agent architecture. Experimental results with a set of ten music excerpts from compact-disc recordings showed that a real-time system implementing this method was able to detect melody and bass lines about 80% of the time these existed. \ufffd 2004 Elsevier B.V. All rights reserved.", "authors": ["Masataka Goto"], "n_citation": 320, "references": ["14c5a617-96f9-477c-8997-96d78e9d4736", "215099e1-a327-479f-b2b8-bdadd398fb16", "3b0885bf-8c4a-4c93-9592-02f7cc0d1090", "5229ef07-46ad-4178-8c31-2027fb28007b", "68887c01-d0b5-49d0-ba62-4ea5964b898d", "68c75f0a-9539-45fd-92ff-0f96ec41cd10", "99d72878-dbae-4035-95fe-c5c72b25b030", "a063de1b-e015-4b3d-aa34-169156904504", "b2924e09-9e24-49be-af6e-b1538249a20b", "cf932a29-330f-4c59-9386-f9c4c8ff53c5", "cfd80ba8-fa3d-4a8b-ba1d-abe96036fceb", "facc215c-579b-4f02-a594-64b77f103de5"], "title": "A real-time music-scene-description system: predominant-F0 estimation for detecting melody and bass lines in real-world audio signals \u2606", "venue": "Speech Communication", "year": 2004, "id": "74e07bbb-8302-4d7c-bd17-6871d19b2a90"}
{"authors": ["Nabil R. Adam", "Yelena Yesha"], "n_citation": 109, "references": ["00d6c856-1976-4845-91ac-20b126879afe", "16fb90c7-64db-4630-81a8-1cbe11b50f63", "17f01f85-4909-41b7-bafd-88939c01894a", "1b8b8701-651e-4b56-bada-bb0d443e7d16", "4a4e2821-7cca-4e9d-9e42-931dbba7c376", "4e9d1c47-a4da-4311-bc98-a8b9feb2f8fa", "64472c04-d171-4b64-aef2-b21e9078d287", "65592b6b-8b86-4f02-9334-3da92352b29d", "726a2b5b-8a27-4c3c-96fb-c69a612b9f80", "762215eb-18fe-470b-835b-b890f5933af9", "7eecb3f4-2719-4cc3-9ce2-f41bade5c021", "81fed280-cdd8-4d7d-bb6a-8d46288e9009", "8500cf58-97a6-4d41-8184-12851133a84d", "9489a56e-051b-4da3-8664-5c021debcc06", "a50b857c-0dae-458d-93c1-70c016f5d715", "d78617fe-e385-41ce-a8de-502a6e3582a0", "fb5b7aa5-5d68-45b9-be8b-36d217d940d7", "fe26781b-7333-4003-b925-70fcfb2caf6e"], "title": "Strategic directions in electronic commerce and digital libraries: towards a digital agora", "venue": "ACM Computing Surveys", "year": 1996, "id": "d9b87367-dea7-47dd-a0c9-de7bc197c0ff"}
{"authors": ["Eduardo B. Fernandez"], "n_citation": 69, "references": ["00f9e7df-444c-4c97-a13a-49ac6c337511", "080501df-9d8e-4d72-8e8f-87e1d478984c", "2b05b088-8a65-436c-854a-9ec182edba4b", "2ebc6e31-7ffd-4e39-a8b9-facc69c13bc1", "5f918a33-1f00-4bb4-9633-2f49f6f1a457", "8d7c6534-42c2-4479-a4e2-6c62e78f37b9"], "title": "A Methodology for Secure Software Design.", "venue": "", "year": 2004, "id": "cc1bc688-08d2-4d27-be90-e50c38124136"}
{"abstract": "Presents an end-to-end solution to the cooperative control problem represented by the scenario where M unmanned air vehicles (UAVs) are assigned to transition through N known target locations in the presence of dynamic threats. The problem is decomposed into the subproblems of: 1) cooperative target assignment; 2) coordinated UAV intercept; 3) path planning; 4) feasible trajectory generation; and 5) asymptotic trajectory following. The design technique is based on a hierarchical approach to coordinated control. Simulation results are presented to demonstrate the effectiveness of the approach.", "authors": ["Randal W. Beard", "Timothy W. McLain", "Michael A. Goodrich", "Erik P. Anderson"], "n_citation": 766, "references": ["05c105c6-5299-4832-91f0-f409d96b8412", "0e86b7b6-8e9e-4e41-8132-33323f9ac73c", "23ed5f1a-f9e1-4260-a702-a4c9801e2b5e", "27043473-e69d-4381-8201-224d01e2d432", "4e86ab99-7537-44aa-8446-f256922c934d", "85948cf8-4220-4e31-b4c4-f42a04cdedb3", "8a37c902-804f-401e-8c3a-e82eccceef93", "9523efac-a4f0-4a2e-9c6f-dab61599df94", "9a664284-9ad2-4d32-9188-bb9ff243727e", "b546dd1a-7e2d-4527-ba3c-2e6ce5e0a405", "cf67fec2-4114-4337-8b5e-30b29eefa263"], "title": "Coordinated target assignment and intercept for unmanned air vehicles", "venue": "international conference on robotics and automation", "year": 2002, "id": "f1a73fc7-7682-4223-bd3d-f3c9f2079284"}
{"abstract": "This paper presents a powerful image understanding system that utilizes a semantic-syntactic (or attributed-synibolic) representation scheme in the form of attributed relational graphs (ARG's) for comprehending the global information contents of images. Nodes in the ARG represent the global image features, while the relations between those features are represented by attributed branches between their corresponding nodes. The extraction of ARG representation from images is achieved by a multilayer graph transducer scheme. This scheme is basically a rule-based system that uses a combination of model-driven and data-driven concepts in performing a hierarchical symbolic mapping of the image information content from the spatial-domain representation into a global representation. Further analysis and inter-pretation of the imagery data is performed on the extracted ARG representation. A distance measure between images is defined in terms of the distance between their respective ARG representations. The distance between two ARG's and the inexact matching of their respective components are calculated by an efficient dynamic programming technique. The system handles noise, distortion, and ambiguity in real-world images by two means, namely, through modeling and embedding them into the transducer's mapping rules, as well as through the appropriate cost of error-transformation for the inexact matching of the ARG image representation. Two illustrative experiments are presented to demonstrate some capabilities of the proposed system. Experiment I deals with locating objects in multiobject scenes, while Experiment II is concerned with target detection in SAR images.", "authors": ["M.A. Eshera", "King-Sun Fu"], "n_citation": 236, "references": ["1be1646d-991f-4924-8695-026e5375e163", "3ec1b558-1e7c-4288-9861-c8337413e376", "5b2f70c5-ac67-4944-9e51-5f6bcc6b9da5", "610a296d-a9b1-4545-bed5-0a09ebd6e4dd", "8652612a-9673-4d74-90f5-30958bb08e43", "8adc4905-f58c-4bd3-ad73-57948e09b982", "9efe43e2-b843-4558-809b-a8cab7fd26ef", "a6f3185b-590d-4032-9594-a3c9b232c213", "ac7cba14-6224-4b92-9915-abf71d8eba87", "b0a11515-b7ea-4c37-b2eb-7941a26929f4", "cd614b9c-ea38-441e-8076-89a63c66d7c4"], "title": "An Image Understanding System Using Attributed Symbolic Representation and Inexact Graph-Matching", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "year": 1986, "id": "42eba9dc-62d5-45eb-abbb-9af59ca81c6f"}
{"abstract": "Hardware-software codesign results of concurrent embedded real-time systems are often not easily verifiable. The main difficulty lies in the different time-scales of the embedded hardware, of the embedded software, and of the environment. This rate difference causes state-space explosions and hence coverification has been mostly restricted to the initial system specifications. Currently, most codesign tools or methodologies only support validation in the form of cosimulation and testing. Here, we propose a new formal coverification method based on linear hybrid automata. The basic problems found in most coverification tasks are presented and solved. For complex systems, a simplification strategy is proposed to attack state-space explosions in formal coverification. Experimental results show the feasibility of our approach and the increase in verification scalability through the application of the proposed method.", "authors": ["Pao-Ann Hsiung"], "n_citation": 50, "references": ["0ce0ff68-9121-4fa1-a53f-c6c844d63ee8", "1000db79-802a-4f1a-87ea-e0305d513f07", "1eb621bf-d554-429d-92e3-c50b4dcedfda", "2aad0487-4476-4820-a19a-a09b10d1f284", "4ea3bdcf-84eb-459c-968c-26d98f35b3f1", "4f68a351-cecd-471f-885e-59e6ff7c82c2", "57323af6-4abb-4519-af10-a31ad2ccfa1f", "62d964e6-f113-4ab8-b9a9-ce444b7358a7", "88ad4d73-56e1-40df-afeb-a333e5d3f0ee", "b4534765-7630-40db-8240-f5c9fc99ed5b", "d49e4b8d-98a7-48fa-9c5b-2337b3942d76"], "title": "Timing coverification of concurrent embedded real-time systems", "venue": "", "year": 1999, "id": "3e0a073e-88be-4319-9d31-f721441b75c2"}
{"authors": ["David Pointcheval", "Jacques Stern"], "n_citation": 50, "references": ["3144d48f-145a-41e8-be30-0fb908a5b315", "3fb43b00-905c-4a08-934d-198ea4eb66c3", "48256bd6-01d8-41f8-828e-d2d0876d47e8", "52f76585-4489-4d31-8b2c-725f391761cb", "6f4501b5-f9bf-4f6c-9098-5014bc8cdcbf", "84535f53-8dd0-4de9-a99f-e0c570454697", "93b84c61-0636-4d00-8d2b-ce6353f8c8d6", "9e1e46c7-2752-4322-b191-45b4eb3115e1", "a631ca46-80fd-43dd-8b81-987050c883ca", "ac0db18c-141b-499a-9499-bc11ed2a61bc", "c662a3e3-c554-49a1-863e-cfc150023c47", "d893a420-a00d-4756-b447-2862ed178eaa", "dfc4268d-4487-4e19-be4f-3f38a0a3cbc1", "ec83bc35-2adf-4bff-a33b-bd26b66d4f96", "f045bf8a-f8dd-4c60-973c-05854a2361e2", "f31fd2e0-c0bd-4301-8868-0b73fc7bb5dd"], "title": "New blind signatures equivalent to factorization (extended abstract)", "venue": "computer and communications security", "year": 1997, "id": "9c0d85b2-eb5c-4843-86ab-805bbf4bbcd2"}
{"authors": ["Eric C. R. Hehner"], "n_citation": 21, "title": "Bunch theory: A simple set theory for computer science", "venue": "Information Processing Letters", "year": 1981, "id": "089b4091-137a-4735-9da7-927e55ee8712"}
{"abstract": "Transactional memory provides a new concurrency control mechanism that avoids many of the pitfalls of lock-based synchronization. High-performance software transactional memory (STM) implementations thus far provide  weak atomicity : Accessing shared data both inside and outside a transaction can result in unexpected, implementation-dependent behavior. To guarantee isolation and consistent ordering in such a system, programmers are expected to enclose all shared-memory accesses inside transactions.   A system that provides  strong atomicity  guarantees isolation even in the presence of threads that access shared data outside transactions. A strongly-atomic system also orders transactions with conflicting non-transactional memory operations in a consistent manner.   In this paper, we discuss some surprising pitfalls of weak atomicity, and we present an STM system that avoids these problems via strong atomicity. We demonstrate how to implement non-transactional data accesses via efficient read and write barriers, and we present compiler optimizations that further reduce the overheads of these barriers. We introduce a  dynamic escape analysis  that differentiates private and public data at runtime to make barriers cheaper and a  static not-accessed-in-transaction  analysis that removes many barriers completely. Our results on a set of Java programs show that strong atomicity can be implemented efficiently in a high-performance STM system.", "authors": ["Tatiana Shpeisman", "Vijay Menon", "Ali-Reza Adl-Tabatabai", "Steven Balensiefer", "Dan Grossman", "Richard L. Hudson", "Katherine F. Moore", "Bratin Saha"], "n_citation": 205, "references": ["00caa936-0730-4b6b-bec0-dd9d7e9110bd", "0be23b12-eadb-445c-8b86-1543f151b3f2", "17d60dc9-9dc8-47c8-a6af-b5e5226589e1", "1e009ada-41e2-4d36-9ed7-ca7441eed994", "1f973151-3c29-4199-a28c-612f7388d5cc", "220a3b9b-f350-4eb0-af0c-c45f8d8ff58d", "2694f41b-c769-4b50-a395-d78cee0fc955", "2a1a717b-356a-44f6-a7cb-749ebcece1ef", "2cf9ab57-251a-4737-a4b0-5ecd2979a895", "36db137b-5deb-4d5d-b6c4-b3abf1fc7984", "398bb790-5076-4c0c-9e2f-0b4b6ebe2a0a", "3c9affe5-a987-43bd-89a9-68eb9762659b", "4498fa9a-5539-4959-ae95-565282e25389", "460deb6a-fd08-43dd-aff2-1eafbad0a53b", "47d0e8d9-79e9-4584-bffb-35937bcd29d3", "5133dd9f-fd4c-48f2-8e72-05b406204ecc", "5156f45d-b9fd-400a-8301-9af1a0db5fc2", "59705501-0cbe-46af-b65f-e05e55ad0934", "62ea2256-8334-46fa-8ca1-aac92c4f5818", "632d15e0-5e63-4566-b83f-39a23052d729", "672797f3-4ef8-447d-b3c1-0299fcd88343", "690e99b1-52db-44cd-b6ce-38008d4dc761", "72ce85d6-4093-4f4e-bb4c-c38f5d3d52ce", "7425b860-87f6-42c3-8770-09ae99ec753c", "7d5bb803-38e1-416a-b933-30b3dda8ab3c", "7f0f937c-f854-47ff-b5fb-aca9314414b9", "801f0553-588b-436e-9db6-a3dabd4dc279", "8382fe5a-5c04-4401-9452-160a570a67b7", "84f44703-492a-46c1-8215-9dfdd3874b16", "8deaac5f-1724-46c6-bde4-f92200d473a8", "9a35e743-3b94-4cee-be73-0393bdb05854", "ac2db84c-f187-4d7e-9876-784818c6f6e4", "b18b98cf-ac2e-48fc-abc7-babd450fdec1", "b3d40eb6-0f75-4df9-9127-2bc433cc6525", "b817817d-6c9d-4925-920b-eb23f2d3deca", "bc0137f1-44f5-47c7-b8d9-048b4b50485b", "bde52d0d-99f1-4b7c-8a87-06a1aa51190b", "c6d9c64e-46c0-4fd8-92b9-3753f47a7807", "cb07a6bc-7acc-4eb5-964f-c8ece4a6ed65", "d8b422c6-dc69-45eb-a188-b2c5b7c70511", "e181f962-bd0d-47ed-b1ee-828e46d2ea54", "f23003f8-31ac-48fa-bd75-71aaa801767e", "f4fadecb-999d-4ce4-9aaa-d611db939b5a", "f7061ce9-5a20-44ae-9117-7ced2102295b", "fb21843d-428b-4475-8666-17cd3adaceba", "fd5aa677-6a9a-48b3-a820-175f9f9b3c7d", "fe62a189-7e0f-4129-802b-a992fd12666e"], "title": "Enforcing isolation and ordering in STM", "venue": "programming language design and implementation", "year": 2007, "id": "ff36a292-7603-4b90-a7b5-7d8fa9df32f8"}
{"abstract": "A recent trend in mainstream desktop systems is the use of general-purpose graphics processor units (GPGPUs) to obtain order-of-magnitude performance improvements. CUDA has emerged as a popular programming model for GPGPUs for use by C/C++ programmers. Given the widespread use of modern object-oriented languages with managed runtimes like Java and C#, it is natural to explore how CUDA-like capabilities can be made accessible to those programmers as well. In this paper, we present a programming interface called JCUDA that can be used by Java programmers to invoke CUDA kernels. Using this interface, programmers can write Java codes that directly call CUDA kernels, and delegate the responsibility of generating the Java-CUDA bridge codes and host-device data transfer calls to the compiler. Our preliminary performance results show that this interface can deliver significant performance improvements to Java programmers. For future work, we plan to use the JCUDA interface as a target language for supporting higher level parallel programming languages like X10 and Habanero-Java.", "authors": ["Yonghong Yan 0001", "Max Grossman", "Vivek Sarkar"], "n_citation": 148, "references": ["2cf9ab57-251a-4737-a4b0-5ecd2979a895", "32b36be7-6710-4db2-926c-d7340af48f52", "3e1c18a5-d987-4930-a9f3-4c2682ab11a1", "526c142f-54a4-49ba-88d2-c7901da7268f", "571e9ea0-b1b4-4682-a5c4-679f4c7a2840", "7dfc3abb-efc5-447a-afe3-b2df8d9bd8a7", "aacc1197-ea89-4c25-8950-52bb021029b8", "c15a9c00-161e-44ea-9f5e-43e17fa12fa7", "e8a36a78-5fdc-4201-b5ab-b0603da95906", "fa70de7c-bf19-40af-b87b-319f4bd73723"], "title": "JCUDA: A Programmer-Friendly Interface for Accelerating Java Programs with CUDA", "venue": "european conference on parallel processing", "year": 2009, "id": "1ced947d-6208-4eba-b94e-b2141c14971e"}
{"authors": ["David A. Van Veldhuizen", "Gary B. Lamont"], "n_citation": 172, "references": ["104e4609-9734-4e6e-87ce-b7557da01385", "6a6b9aa6-683f-4c7c-b06e-9c3018d10fd3", "9cf177c9-48f2-4743-823d-950b096f0008", "bac5da35-9009-41a3-b758-21aec812a9ee", "c6553383-a300-4d96-b68a-398ea1b4389a", "c6fed450-131c-49e9-bf77-321ff0ea38bf", "d219069c-e1bd-4217-8893-12092fb1a98d", "fbbddfd2-5b7c-4f54-8718-5fe1f58ebf33", "fdcd3431-da24-40ab-95b6-bff28036cb0e"], "title": "Multiobjective evolutionary algorithm test suites", "venue": "acm symposium on applied computing", "year": 1999, "id": "9beeb5c2-3a91-4980-985b-fb6657043b7a"}
{"abstract": "Abstract   This paper gives an assessment of the current state of the art in handwriting recognition. It summarizes the lessons learned, the difficulties involved, and the challenges ahead. Based on a review of the recent achievements in off-line computer recognition of totally unconstrained handwritten characters, and extensive research, the authors attempt to identify new frontiers for research which may lead to further breakthroughs in this field. They will present some evidences and novel ideas on ways of stretching the limits of handwriting recognition systems aiming at outperforming human beings.", "authors": ["Ching Y. Suen", "Raymond Legault", "Christine P. Nadal", "Mohamed Cheriet", "Louisa Lam"], "n_citation": 138, "references": ["0292b1ce-0cbb-4ffd-9116-a9a8544a9ec9", "0a550e7d-118e-48d8-8ee0-1b6b9cd69862", "1a905ecf-1c27-4454-b3e7-07af4440f3b7", "44cfaec8-af50-40b4-ae48-bae030752404", "4c0c4415-e15f-4e4f-b67b-492a93116bd3", "6b1c4abc-a859-4035-8646-ead92fd46617", "6db331b9-8c9d-4143-afa8-f0f1103ee897", "87fbe050-8050-419f-941b-fe844e783e01", "b17ecec5-839a-47c8-98cc-75521ea376dc", "bb08006d-9062-471e-b357-36ce7574b3bc", "d04c4f43-6e3c-4a45-b8ae-444f551402f4", "fbd685a6-09fc-4e94-80ac-30391d4e8657", "fe8911eb-4d18-4b19-b018-e847144d137a"], "title": "Building a new generation of handwriting recognition systems", "venue": "Pattern Recognition Letters", "year": 1993, "id": "2c44d3f7-1ede-42e6-95e4-b3fe1607a4b7"}
{"abstract": "An algorithm for closest-point queries is given. The problem is this: given a set S of n points in d-dimensional space, build a data structure so that given an arbitrary query point p, a closest point in S to p can be found quickly. The measure of distance is the Euclidean norm. This is sometimes called the post-office problem. The new data structure will be termed an RPO tree, from Randomized Post Office. The expected time required to build an RPO tree is $O(n^{\\lceil {{d / 2}} \\rceil (1 + \\epsilon )} )$, for any fixed $\\epsilon > 0$, and a query can be answered in $O(\\log n)$ worst-case time. An RPO tree requires $O(n^{\\lceil {{d / 2}} \\rceil (1 + \\epsilon )} )$ space in the worst case. The constant factors in these bounds depend on d and $\\epsilon $. The bounds are average-case due to the randomization employed by the algorithm, and hold for any set of input points. This result approaches the $\\Omega (n^{\\lceil {{d / 2}} \\rceil } )$ worst-case time required for any algorithm that constructs the Voronoi...", "authors": ["Kenneth L. Clarkson"], "n_citation": 202, "references": ["18689b9f-f135-4f24-8e7a-c7f2751b16cf", "6867a27b-4b3c-4bfc-8dd1-286630cb69cd", "76c004a0-487a-4313-a344-fc4a299e4b66", "87e277b2-8947-494d-8e96-39379ea30523", "ca869b3c-0bc2-483a-be0d-19179c98899d", "cebc84ef-686b-43dd-ae70-90208e78cb83", "e4447755-77f6-4529-a4c0-93d44cb74b2f", "f773d6ce-5d99-457b-8dcb-2e4259c28187", "f96ff341-9e37-4ed7-98c4-d99ebfddd9d7"], "title": "A randomized algorithm for closest-point queries", "venue": "SIAM Journal on Computing", "year": 1988, "id": "be9cbf3c-2975-4226-b6b9-3d4b4ebe8a66"}
{"authors": ["Walter R. Bischofberger", "Rudolf K. Keller"], "n_citation": 12, "title": "Enhancing the Software Life Cycle by Prototyping.", "venue": "Software - Concepts and Tools \\/ Structured Programming", "year": 1989, "id": "bce0bffc-b394-4b80-9102-5d427c16b4f9"}
{"abstract": "Abstract#R##N##R##N#Web-based search engines such as Google and NorthernLight return documents that are relevant to a user query, not answers to user questions. We have developed an architecture that augments existing search engines so that they support natural language question answering. The process entails five steps: query modulation, document retrieval, passage extraction, phrase extraction, and answer ranking. In this article, we describe some probabilistic approaches to the last three of these stages. We show how our techniques apply to a number of existing search engines, and we also present results contrasting three different methods for question answering. Our algorithm, probabilistic phrase reranking (PPR), uses proximity and question type features and achieves a total reciprocal document rank of .20 on the TREC8 corpus. Our techniques have been implemented as a Web-accessible system, called NSIR.", "authors": ["Dragomir R. Radev", "Weiguo Fan", "Hong Qi", "Harris Wu", "Amardeep Grewal"], "n_citation": 251, "references": ["00afa0f8-55fd-4ed7-9138-7481cda4e0b2", "050f3d56-45c0-4c32-86fb-db2fe9b5fb88", "21c5d7f1-a94d-4fc3-8f33-9fed671586de", "3f8a05a6-9e14-4b3a-82d3-b7c77579f689", "4345d2af-412d-4074-bc7a-6eca74b9c6f4", "48c96aa0-6337-4431-bee6-abe55cfce8f2", "4a48d1c0-8255-49d4-8800-66fa0cf7560d", "565115b7-fd72-444c-8e98-d7d55b4cc51e", "5852af83-03ef-4b99-a2b0-afacd9c1a417", "8e4034e3-be93-4f02-8970-da8fa1aef09d", "a0744059-9a0b-4c25-b36d-c1f2c2f28454", "c22f481d-7534-4009-8c80-78c6639748dc", "c366a883-4a71-4f2d-8b60-2ba627bf1997", "e9295842-8676-4545-9f9b-7dc3f76a72d0", "ee8e502a-2b6d-4423-aeac-7e2eeac9eeec", "fd1b92b9-abea-4e0c-944b-4751e2334c00"], "title": "Probabilistic question answering on the Web", "venue": "Journal of the Association for Information Science and Technology", "year": 2005, "id": "bf252933-5f87-4137-8c26-5609beff527d"}
{"abstract": "Various program complexity measures have been proposed to assess maintainability. Only relatively few empirical studies have been conducted to back up these assessments through empirical evidence. Researchers have mostly conducted controlled experiments or correlated metrics with indirect maintainability indicators such as defects or change frequency. This paper uses a different approach. We investigate whether metrics agree with complexity as perceived by programmers. We show that, first, programmers' opinions are quite similar and, second, only few metrics and in only few cases reproduce complexity rankings similar to human raters. Data-flow metrics seem to better match the viewpoint of programmers than control-flow metrics, but even they are only loosely correlated. Moreover we show that a foolish metric has similar or sometimes even better correlation than other evaluated metrics, which raises the question how meaningful the other metrics really are. In addition to these results, we introduce an approach and associated statistical measures for such multi-rater investigations. Our approach can be used as a model for similar studies.", "authors": ["Bernhard Katzmarski", "Rainer Koschke"], "n_citation": 50, "references": ["02e0342a-33d3-4d3f-9f1d-b14081edbc39", "0f9c558f-48db-4a16-92a6-a0cd9f4aaab2", "11b4635f-1693-48aa-96ac-22d7ba540c24", "11df7d57-bad8-4b0b-8ce8-e26c6d9eb2b0", "137f88f4-e09f-4c9b-8b15-8351b2e888dd", "1cba78d4-e0db-4e90-926e-2e6297f70f29", "1fb1acb3-8797-49f7-9ace-6f9809dc5301", "29b58ca9-7e3a-4b87-93d4-8bf59379d9b0", "32238a09-0bce-4e8c-9e02-f85aa2e6f0e8", "38289f6e-87df-4379-a057-514d4da5d747", "3c6cc30f-979e-44c8-9761-15b81c7f90cb", "3ec83272-5261-4ab4-aa43-6bf350cc45c6", "4b3c953e-0797-4d57-9dd6-5dd950162ea2", "53bc46ee-ba03-44ee-b56f-ce8140ca0e78", "58f4802e-a62d-4827-a9ea-2573c0bd9e1a", "5b58b0a8-6d15-482f-88d4-546c505ce60d", "6c53a09c-58b7-4195-84d8-dd3a442b9dac", "6e6202cd-6dbe-4bba-b198-326f2168c517", "842e96df-fb8b-43ba-8643-4b3714b44dbf", "88cba468-ac49-4acb-b61e-8f9c6735d4c8", "89fa5897-771d-4855-ad40-3e01c085236c", "9b614366-a540-4fd0-ac12-7b00bfca58b2", "a0c07545-7743-485e-8a5e-e209da005587", "b0537c20-634c-4534-bd56-07e497f1a57f", "b7439cab-8bf1-42e5-bd8c-23273aa4d5af", "b75c555c-8f6d-4366-b2a5-28c79cded9ae", "bc3eee18-dec3-47c8-8908-d9dc1e1197ee", "bcb4936f-f855-4323-863d-d208972ad579", "c47ad26e-8df8-4130-b80c-bda27273635b", "d1641855-866e-4b35-b5e7-5ba1415b1eb0", "d1fbd7d6-f1a4-4f68-9d1c-3a7706f844aa", "d2c0bb3b-27f9-4ba0-b5b3-d988a8ec8129", "d3fd4fe9-74cd-4911-b5e1-3ea4fabcd906", "d5a44f14-60d8-4dd8-98a2-f805830df6cd", "d6127b22-a4bc-4783-9d1b-7163e33b9f5a", "da236a5b-d7a4-423c-a344-a5afe9b444a0", "e6462ac5-07b2-4ec8-bc30-d91e0351f9ea"], "title": "Program complexity metrics and programmer opinions", "venue": "international conference on program comprehension", "year": 2012, "id": "52b852eb-6a9e-4b4e-8252-4805da07ddad"}
{"abstract": "Abstract   Andrew Baker's approach to reasoning about actions is the most robust circumscriptive approach currently known. Investigation of its applicability to nondeterministic actions reveals that this approach does not allow us to draw some intuitively plausible conclusions. Also, it does not always generate the proper existence of situations axiom. The limitations are traced to an unexpected interference of the axioms encoding observations with the minimization. A modification that avoids the shortcomings is suggested.", "authors": ["G. Neelakantan Kartha"], "n_citation": 40, "references": ["024853b3-562d-4151-b27d-5e8547b4192f", "3268e35e-ed9c-44bc-baea-e291552c1f72", "36219e05-6ac2-4261-82d4-545095fb27e4", "43959b1e-98f1-45c5-a7eb-cfeb9ce364d9", "888d2b34-fe35-4ba6-9853-384a262fc10a", "8d9d97d8-d45a-42cc-b7dc-43184634d63e", "8e444c82-db67-4693-93ec-13610cdcdc0c", "a836c1ef-1140-4724-b372-e33630acbd8b", "e75ee784-a8be-4461-810f-11572d1b5689", "f0627063-b053-458f-b70c-db2ed7aed89c"], "title": "Two counterexamples related to Baker's approach to the frame problem", "venue": "Artificial Intelligence", "year": 1994, "id": "87e95645-41d6-4122-8367-a54ccc733a5f"}
{"abstract": "Collective communication performance is critical in a number of MPI applications yet relatively few results are available to assess the performance of MPI implementations specially for shared memory multiprocessors. In this paper we focus on the most widely used primitive, broadcast, and present experimental results for the Sun Enterprise 10000. We compare the performance of the Sun MPI primitives with our implementation based on a quasi-optimal algorithm. Our tests highlight advantages and drawbacks of vendors' implementations of collective communication primitives and suggest that the choice of the best algorithm may depend on exogenous factors like load balancing among tasks.", "authors": ["Massimo Bernaschi", "Giorgio Richelli"], "n_citation": 8, "references": ["14f8ce87-0af7-45fb-8864-80b0b6a3ae42", "2a6c663b-c74c-4384-bb23-b18664f0f442", "76a62faf-4387-40fe-b265-e6bf58d2b330", "cbbd6b29-db80-4cc2-bc60-cc5727c838ed", "e8132a0f-bf90-43fc-abc5-01933d062a91", "f294ffb1-a7c5-4198-9090-d51d1d948a97"], "title": "MPI collective communication operations on large shared memory systems", "venue": "", "year": 2001, "id": "8200d21e-5797-41c6-9532-22dad431207b"}
{"abstract": "The authors discuss the role of information retrieval, interface design, and cognitive science in hypertext research. They present a user-centered framework for information-seeking that has been used in evaluating two hypertext systems. They apply the framework to key design issues related to information retrieval in hypertext systems. >", "authors": ["Gary Marchionini", "Ben Shneiderman"], "n_citation": 707, "references": ["0122dc00-0388-47b7-8691-ca5888ae9423", "02473f4a-3389-4f97-84c6-5f01056f3f64", "0d1077d6-5a4b-416b-aa74-c4f800f4c1ea", "7b9e41a4-f679-4a51-8baa-5d6a4a23f804"], "title": "Finding facts vs. browsing knowledge in hypertext systems", "venue": "IEEE Computer", "year": 1988, "id": "21e6c5b4-b587-4735-9c73-f50f6e9996e6"}
{"abstract": "We present an approach to designing verified digital systems by a sequence of small local refinements. Refinements in this approach are not limited to a library of predefined transformations for which theorems have been previously established. Rather, the approach relies on localizing the refinement steps in such a way that they can be verified efficiently by model checking. Toward this end, a compositional rule is proposed by which each design refinement may be verified independently, in an abstract environment. This rule supports the use of downward refinement maps, which translate abstract behavior detailed behavior. These maps may involve temporal transformations, including delay. The approach is supported by a verification tool based on symbolic model checking.", "authors": ["Kenneth L. McMillan"], "n_citation": 197, "references": ["27c32374-d8a1-4992-85cc-409f54b14e21", "5a11bdba-a1e0-4fa3-b721-28881da79107", "79b15e00-42fe-418c-89dc-65ae58844cf9", "cb7f1493-4bc3-479c-9061-08fc9f0d1cae", "d9e3358b-6050-47bb-9633-4be8fb0c1618", "e8d788e8-f8da-4183-9817-ae756a852c31", "ed8dc42b-c472-4fcc-9d0a-55f3043446dc"], "title": "A Compositional Rule for Hardware Design Refinement", "venue": "computer aided verification", "year": 1997, "id": "3242a942-3ba2-4aa0-89a3-79a8a733adb7"}
{"abstract": "The changing economic and labor conditions have motivated firms to outsource professional services activities to skilled personnel in less expensive labor markets. This offshoring phenomenon is studied from a political, economic, technological and strategic perspective. Next, an analytical model is developed for achieving strategic advantage from offshoring based on global partnerships. The model studies the impact of offshoring with respect to the complexity and strategic nature of the tasks and presents a decision strategy for obtaining value through offshoring of increasingly complex tasks. The result is an integrated \u00e2\u20ac\u015324-hour knowledge factory\u00e2\u20ac that is based on a sustainable global model rather than a short term fiscal model. This 24-hour paradigm embodies the shift-style workforce that evolved for the manufacturing sector during the Industrial Revolution and relies on a set of critical success factors in the current environment. A case example is provided from IBM to illustrate these underlying critical success factors.", "authors": ["Amar Gupta", "Satwik Seshasai", "Sourav Mukherji", "Auroop R. Ganguly"], "n_citation": 94, "references": ["00bd6464-257e-49d5-a4e9-87968fb5b731", "442428e2-0205-422c-b958-3c974990d88a", "499b0378-8035-4959-b240-4673e992d192", "4d636b47-cc92-46ff-9eb9-5e8bf023494b", "901c6db8-d41e-4611-b4b0-a27eaade40c6", "a7b42605-ba34-4f35-b7e9-8f784fdbca5a", "ac79486c-47ec-4492-81aa-930c5d6762fc", "e647e8ed-d3cb-4017-ab1d-99b4a9f4dd95"], "title": "Offshoring: The Transition From Economic Drivers Toward Strategic Global Partnership and 24-Hour Knowledge Factory", "venue": "Journal of Electronic Commerce in Organizations", "year": 2007, "id": "0aa637d0-e4f1-4376-9eb8-1a376825fa7e"}
{"abstract": "This paper presents DEDALE, a spatial database system intended to overcome some limitations of current systems by providing an abstract and non-specialized data model and query language for the representation and manipulation of spatial objects. DEDALE relies on a logical model based on linear constraints, which generalizes the constraint database model of [KKR90]. While in the classical constraint model, spatial data is always decomposed into its convex components, in DEDALE holes are allowed to fit the need of practical applications. The logical representation of spatial data although slightly more costly in memory, has the advantage of simplifying the algorithms. DEDALE relies on nested relations, in which all sorts of data (thematic, spatial, etc.) are stored in a uniform fashion. This new data model supports declarative query languages, which allow an intuitive and efficient manipulation of spatial objects. Their formal foundation constitutes a basis for practical query optimization. We describe several evaluation rules tailored for geometric data and give the specification of an optimizer module for spatial queries. Except for the latter module, the system has been fully implemented upon the O 2  DBMS, thus proving the effectiveness of a constraint-based approach for the design of spatial database systems.", "authors": ["St\u00e9phane Grumbach", "Philippe Rigaux", "Luc Segoufin"], "n_citation": 174, "references": ["31f98830-86fa-4345-9749-14007d9c6fc8", "36835739-8f41-433a-9190-a945a84830be", "510eec1d-f82c-4b19-b116-b8fd4c66531a", "650263fe-7ae9-408e-bc06-ccb383464313", "783e5a24-8505-4817-9566-36b1a478a6be", "7bfbe4ca-728f-48b3-b837-feae3e172598", "920332d9-143e-4f35-ba60-49dea18c0ab7", "a025fb54-c719-406e-8459-3ff83368c291", "b16cb3e5-731a-4c46-a8e9-7bef05e04533", "b2d48a35-ceab-4fc3-8a72-d1bb265c779d", "b91308b2-2cc9-4283-956d-b36d78b9dcdb", "bcc1d438-ba69-4d0d-b00e-5dec59cf9b9e", "bf94a78f-5436-4cc0-b60a-a6cf22c6b2dd", "d10f840c-1003-48b5-8aec-3ecc0957c658", "d6ffd0e7-61aa-4dea-9fe0-4345e2382e96", "e930195e-baa4-4d42-9d5f-e042fcaf5a9e", "eb430105-9adc-4cbd-977b-c166465f976d", "ed155ba7-b3c8-422f-9986-8c8188cccb7a", "ef30fcd7-0bd5-4a07-81b7-786fa89ef14a", "f9f9abe8-2d24-4a50-9fee-c4c832463b2d", "fc785301-a163-40ae-a920-dfb2e679d6a3"], "title": "The DEDALE system for complex spatial queries", "venue": "international conference on management of data", "year": 1998, "id": "ef656efb-104e-4607-b6b0-c5752fb157db"}
{"abstract": "Producing oil from gas-lift wells are often faced with severe producing oscillatory flow regimes. A major source of the oscillations is recognized as casing-heading instability which is caused by dynamic interaction between injection gas and multiphase fluid. This phenomenon poses strict production-related challenges in terms of lower average production and strain on downstream equipment. In this paper, an effective solution is proposed based on integration of an online interpretation dynamic model and a nonlinear model predictive control (NMPC) scheme. The paper uses adaptive growing and pruning radial basis function (GAP-RBF) neural networks (NNs) to recursively capture the essential dynamics of casing-heading instability in a nonlinear model structure. Extended Kalman filter (EKF) and unscented Kalman filter (UKF) are comparatively investigated to adaptively train modified GAP-RBF NNs. NMPC methodology is developed on the basis of the identified nonlinear NN model for real-time stabilization of casing-heading instability in an oil reservoir equipped with a gas-lift production well. A set of test studies has been conducted to explore the superior performance of the proposed adaptive NMPC controller under different scenarios for an oil reservoir simulated in ECLIPSE and linked to a complementary gas-lifted oil well simulated in programming environment.", "authors": ["Karim Salahshoor", "Sepide Zakeri", "M. H. Sefat"], "n_citation": 4, "references": ["488334de-e20d-4f72-b5d8-702c96230281", "76ffdc16-0f27-483d-8b88-a0dddbe97d87", "dfc718cb-4943-4ffb-8212-3a1b9cc973c6", "e17732de-c304-419f-b5b5-d20863d3bff7", "f4a2cddc-7076-474e-89b4-95890ac8336a"], "title": "Stabilization of gas-lift oil wells by a nonlinear model predictive control scheme based on adaptive neural network models", "venue": "Engineering Applications of Artificial Intelligence", "year": 2013, "id": "bc156574-8415-4fbc-adcf-25656cd71f0d"}
{"abstract": "Abstract#R##N##R##N#Suibokuga is a style of monochrome painting characterized by the use of Chinese black ink (sumi), a complex interaction between brush, ink and paper, and such visual features as Noutan (shade), Kasure (scratchiness), and Nijimi (blur). In this paper we present a simple behavioural model of water and ink particles based on a 2D cellular automaton computational model, and its application to a Suibokuga-like rendering of 3D trees. Copyright \u00a9 1999 John Wiley & Sons, Ltd.", "authors": ["Qing Zhang", "Youetsu Sato", "Junya Takahashi", "Kazunobu Muraoka", "Norishige Chiba"], "n_citation": 112, "references": ["211d0047-ad93-4be3-b839-7193f1c2cf90", "225f93aa-d0ff-4c5c-af2f-12f7861bb502", "31430883-7f41-4011-903f-5a35f6c758dc", "33015cd4-0358-4b8a-ade1-a5bbfa8405bd", "66f1f659-a757-400c-bf6f-c681f42f36f8", "8b8199de-5ee5-4a90-a2f4-0977ecbf814c", "92c6a657-ad2e-49fe-b4b8-ec165ac7da0e", "9990e2f9-4422-463a-b382-2cdff9e2458f", "b4e492b8-53b4-4586-8ffe-34309bf23bdd", "b911e10e-36b9-4e6b-a268-2ca6697350ce", "cf322a9b-7156-4dbe-b88d-1fe30b8e6adc", "d8318e81-5613-4b89-80bb-1908a155bea1", "e195041e-b35f-4e15-b2b0-9fcc8ffb4030", "ea104645-3044-48a9-867f-ae2c629ee72f"], "title": "Simple cellular automaton\u2010based simulation of ink behaviour and its application to Suibokuga\u2010like 3D rendering of trees", "venue": "Journal of Visualization and Computer Animation", "year": 1999, "id": "e5f269a0-8483-4625-aee2-ca230687f787"}
{"abstract": "From its first introduction in this same conference, the original prototype of the Semantic Bookmarking tool Semantic Turkey has undergone a deep and extensive revision process, breaking the boundaries of its original intents and going more and more towards an extensible platform for Knowledge Management and Acquisition based on Semantic Web technologies. Following its recent official release, we discuss here the main innovations of this system, its potential applications and future plans for its improvement.", "authors": ["Maria Teresa Pazienza", "Noemi Scarpato", "Armando Stellato", "Andrea Turbati"], "n_citation": 8, "references": ["6f50deca-bfcf-4059-b147-a06131a195a2", "8a00cd33-0399-418f-a0bc-58bf487b1a92", "c483d45a-8e41-431b-8224-7d934d772b99", "dd85a6a6-193f-4dc1-a9b0-85874b00a16b", "e10a83fd-8f2e-4176-a0ee-e6d290fa2ff2", "e8d48526-dc52-42cb-b8e6-684c22614e52", "e9344703-254e-4648-9769-5e07cd0f844a", "f11b73ff-d624-490b-a2f5-2e72e697e023", "f6c784da-0013-413a-8cce-0c2e285b3a87"], "title": "Din din! The (Semantic) Turkey is served!", "venue": "semantic web applications and perspectives", "year": 2008, "id": "8489dfad-b6aa-4d81-93bd-12444c9aef39"}
{"abstract": "We discuss basic prediction theory and its impact on classification success evaluation, implications for learning algorithm design, and uses in learning algorithm execution. This tutorial is meant to be a comprehensive compilation of results which are both theoretically rigorous and quantitatively useful.There are two important implications of the results presented here. The first is that common practices for reporting results in classification should change to use the test set bound. The second is that train set bounds can sometimes be used to directly motivate learning algorithms.", "authors": ["John Langford"], "n_citation": 271, "references": ["063e2cb9-a717-4993-9707-eea0196630a7", "1372bb21-9e33-4f92-95a3-d58301e5869b", "24627c32-96e9-4f6d-8193-059b20e2f57e", "3d40ad00-7d62-4fbb-8d4e-62af82db0593", "7f02ee69-69d0-466b-891e-18a98f6aecb5", "b70971da-e6ea-4e0f-9742-f60a259c6c63", "f1b80f20-5db2-4a73-9113-ab20176f5152", "fab009f6-19f4-4eed-af8c-62776947aef3"], "title": "Tutorial on Practical Prediction Theory for Classification", "venue": "Journal of Machine Learning Research", "year": 2005, "id": "f9041852-6593-4f7b-88ce-1591287e73bc"}
{"authors": ["Jitendra Malik", "Ruth Rosenholtz"], "n_citation": 51, "references": ["5b84e2fc-3ba7-42e7-8c21-dd98add58f6f", "611be2d9-59fd-4dc3-82cb-c8e7c0ed2b03", "7026aa56-a197-4bee-ac69-b74e09b2d4e2", "77422639-d382-4455-b4ad-b2b47b44f2f5", "c233b742-ec5c-4600-8e6d-1f747bef3a5c", "dbda5e2e-32b1-49fa-a264-0316edb5c9d0", "e2ebd9ae-ed07-4a4a-acf2-9dee7f02192d", "e92b5d69-ceae-4180-8fb8-ba7676041a74", "f08af7d2-d03e-4fd8-8c26-6c4cadafc059", "f534affc-459f-4b62-8f2d-7fabc355afb4"], "title": "Recovering surface curvature and orientation from texture distortion: A least squares algorithm and sensitivity analysis", "venue": "european conference on computer vision", "year": 1994, "id": "c228394c-89f6-4d8c-b088-c88cce672ae5"}
{"authors": ["James J. Peterka"], "n_citation": 2, "title": "A Method for Obtaining Specific Values of Compiling-Parameter Functions", "venue": "Journal of the ACM", "year": 1962, "id": "3d9a120a-96c2-4d73-a65e-f418d391ce29"}
{"abstract": "An semi-automatic technique for creating 3D models of creatures suitable for animation is presented. An anatomically based canonical model is deformed, given a sparse set of feature points derived from measurements describing the target animal. The layered canonical model is built on top of an articulated structure hierarchy and contains a representation of the animal's skeleton, muscles, and skin. The joint hierarchy and associated body components are transformed based on the input data. A denser set of feature points is then automatically generated from the new underlying structural components. The feature points are used to deform the attached mesh skin representation, using a segmented interpolation approach. Results are shown using measurements from a scale model and from a live horse. Our main contributions are (1) a novel approach for automatically reconstructing complete jointed creatures from an anatomically based canonical model of similar structure; and (2) an integrated application of skin interpolation for both morphing and animation. In this research, we have addressed the problem in the context of modeling and animating horses; however, the general techniques that we have developed could be applied to a wide range of creatures, at the cost of constructing a canonical model for each creature type.", "authors": ["Maryann Simmons", "Jane Wilhelms", "Allen Van Gelder"], "n_citation": 17, "references": ["16c99b8e-a56d-438f-9b9d-80bea2b89423", "1babfbdb-97db-4174-b4b1-e4269d0721bf", "1d1e1537-8889-4aa3-9e21-35bebdbf0521", "2bbcd656-eb94-49a1-b533-bff1fab0abab", "3b0f81cc-1648-4536-88b5-9b67e32ae0ba", "3bde8473-296e-40fd-bbe3-010e2108187a", "3c9d2c67-a996-41a6-a73e-b2c3ea8aa510", "52e6593a-0c00-4e0a-8eda-e7d703a062f5", "536c75e5-9cb5-4aef-a18e-edbe2dbd4d05", "59f0396d-fb83-446d-b76c-aef9b01839a7", "626e5511-6d8c-454f-9d2c-5ff15ce5fe2a", "862b36dc-5404-4986-b294-3f0ad9b736c0", "87d30e57-7b54-4b29-a259-0cdf01e85637", "9e33c655-8bd8-40ce-a32d-f4a2d1335bd1", "9fe9b557-5b4a-41d8-bf09-6e97cc85bf1e", "b54351af-995c-4f53-8f2f-ec8659543e12", "c46fec48-56c2-4ef1-afca-39bb5e3416cb", "c9251894-d283-48c3-8b30-e2afb9765496", "ce94a72a-fbd0-4829-9dc7-08e0c9f3ca8d", "e61b9dd4-bc17-4f5a-a5b3-a6f5e480dd8e"], "title": "Model-based reconstruction for creature animation", "venue": "international conference on computer graphics and interactive techniques", "year": 2002, "id": "55fc7939-a449-4c11-a4a5-70642dc7c80a"}
{"abstract": "We construct a hierarchy of semantics by successive abstract interpretations. Starting from the maximal trace semantics of a transition system, we derive the big-step semantics, termination and nontermination semantics, Plotkin's natural, Smyth's demoniac and Hoare's angelic relational semantics and equivalent nondeterministic denotational semantics (with alternative powerdomains to the Egli-Milner and Smyth constructions), D. Scott's deterministic denotational semantics, the generalized and Dijkstra's conservative/liberal predicate transformer semantics, the generalized/total and Hoare's partial correctness axiomatic semantics and the corresponding proof methods. All the semantics are presented in a uniform fixpoint form and the correspondences between these semantics are established through composable Galois connections, each semantics being formally calculated by abstract interpretation of a more concrete one using Kleene and/or Tarski fixpoint approximation transfer theorems. Copyright 2002 Elsevier Science B.V.", "authors": ["Patrick Cousot"], "n_citation": 256, "references": ["051c0195-a265-4e2a-9213-bdd97db17875", "25bbd073-680b-4f59-9e60-b8cc74636a2b", "2c9f525b-b5dc-467b-beae-13205d3fdb67", "348819b9-e25a-4d61-bd8c-ae84098fb9cb", "35c8c06c-2ad0-46b4-9e92-2d684f3abd94", "3687e9f5-b340-4897-9d55-234753fc1b44", "3a5a68d0-f02f-4b06-8e38-32d2b71ac464", "3e463040-e697-4c3c-a555-5635b90ef134", "436370d1-94a5-4c49-8887-eacca6c70af6", "48e7fc33-5f27-4fe2-8aca-08ff07798fba", "4b8d5647-b891-4bd0-b974-010bb0a27d6f", "62f4c764-2113-4b45-af21-112e6dffb822", "635e2014-6579-4acf-9737-49593bc74701", "66496a4d-7d36-4484-8529-2755ec3941e5", "74c1c232-f2f9-4281-93cb-fe19e7c63166", "8050a7e9-b4d2-4578-9446-7563e2af1cc6", "829153b8-eccf-4aae-b86f-6b463db3dc75", "945aa434-667d-4359-84f1-e40ba5f2b540", "9904955c-0004-4b9f-b0a5-7e2beddf0d96", "9a4984f9-27d4-47eb-8bc8-0469bf540f94", "b8fe9053-5526-426e-a2bf-97cf443abc89", "c4db240a-243b-4b05-8e2f-edbe050eae25", "c711a3aa-9c7d-4b1e-b65c-4ba7d3190e6e", "cb895c6b-db56-4984-a71a-7bfd04f05105", "d08b12af-87ac-48ec-8b4e-c9bf20a1b907", "dc1327fc-5c08-44c2-ad35-859ba6309c4e", "e8010941-174a-4fc4-aff8-ebe0b32bc9cb"], "title": "Constructive design of a hierarchy of semantics of a transition system by abstract interpretation", "venue": "Theoretical Computer Science", "year": 2002, "id": "05fefbba-b84c-470a-9865-65403d4165f4"}
{"abstract": "Software for embedded systems must cope with a variety of stringent constraints, such as real-time requirements, small memory footprints, and low power consumption. It is usually implemented using low-level programming languages, and as a result has not benefitted from component-based software development techniques. This paper describes a data-centric component model for embedded devices that (i) minimizes the number of concurrent tasks needed to implement the system, (ii) allows one to verify whether components meet their deadlines by applying rate monotonic analysis, and (iii) can generate and verify schedules using constraint logic programming. This model forms the foundation for a suite of tools for specifying, composing, verifying and deploying embedded software components developed in the context of the PECOS project.", "authors": ["Roel Wuyts", "St\u00e9phane Ducasse", "Oscar Nierstrasz"], "n_citation": 30, "references": ["6172970c-9c43-4e39-af5d-427c6929d0f1", "9c00b540-465c-4559-ad30-09c09cbea903", "aeb47436-3cf0-4a03-b814-bc5a7db6adb6", "ba0ffed5-3044-4547-a891-3891007c44de", "c24278c4-5209-47b5-b2b8-11f0684f1d64", "c40bffa2-02cc-4e6f-8484-40a6132b608f", "d38f2f4c-3436-4f14-a76b-f96aa46f5d51", "e20c2c3e-f0e1-45cb-a3f6-fd28cd1a5057", "f81cd366-5095-4c4a-b645-2cd27b8a38fd"], "title": "A data-centric approach to composing embedded, real-time software components", "venue": "component based software engineering", "year": 2005, "id": "2b6bcf11-6685-467b-8446-c2135294324c"}
{"abstract": "In a communication network, a good rate allocation algorithm should reflect the utilities of the users while being fair. We investigate this fundamental problem of achieving the system optimal rates in the sense of maximizing aggregate utility, in a distributed manner, using only the information available at the end hosts of the network. This is done by decomposing the overall system problem into subproblems for the network and for the individual users by introducing a pricing scheme. The users are to solve the problem of maximizing individual net utility, which is the utility less the amount they pay. We provide algorithms for the network to adjust its prices and the users to adjust their window sizes such that at an equilibrium the system optimum is achieved. Further, the equilibrium prices are such that the system optimum achieves weighted proportional fairness. It is notable that the update algorithms of the users do not require any explicit feedback from the network, rendering them easily deployable over the Internet. Our scheme is incentive compatible in that there is no benefit to the users to lie about their utilities.", "authors": ["Richard J. La", "Venkat Anantharam"], "n_citation": 313, "references": ["12aa9206-d296-429b-aeae-5e432e9923b6", "2e8af6ad-3dae-4a03-8ede-a1373759a231", "3a4257ae-9cdb-46fb-a5af-70255dfb9d48", "4854b363-f03e-4667-abad-2de7ca3d2315", "8fd6531b-c809-4e63-895b-fb91be11759d", "bc208779-e44c-4ed9-a034-ab0035ccfe9d", "bca0bb44-aa53-4e36-bd83-e6570150e5c7", "bcdad5ca-e2f6-4fd3-8f7a-3113fbe40a7a", "c9822cc4-85d5-43f9-bfef-4d4d8b4ea687", "d2b7db5d-bc47-48c7-a173-865fed9bff96", "ef8a79a5-e4c7-48e1-aa6f-3426e6315442", "f0960be2-9efd-4ed9-8e5f-7bcb30b3805b"], "title": "Utility-based rate control in the Internet for elastic traffic", "venue": "IEEE\\/ACM Transactions on Networking", "year": 2002, "id": "a9a0b66a-1946-48be-a0e1-c44976d6231d"}
{"abstract": "Two different notions of Byzantine Agreement - immediate and eventually - are defined depending on whether the agreement involves an action to be performed synchronously or not. The lower bounds for time complexity depend on what kind of agreement has to be achieved. All previous algorithms to reach Byzantine Agreement ensure immediate agreement. We present two algorithms that in many cases reach the second type of agreement faster than previously known algorithms showing that there actually is a difference between the two notions: Eventual Byzantine Agreement can be reached earlier than Immediate.", "authors": ["Danny Dolev", "Ruediger Reischuk", "H. Raymond Strong"], "n_citation": 57, "references": ["4641f0c1-ae2d-41e5-9c34-b16f9286a858", "4dc2d46c-60b3-48c0-8209-b27042b57fa9", "532a17ef-5f37-4ead-9f4d-2fd31369966e", "60884a73-4770-43d0-a046-5d55c64b9cc3", "63621934-ccab-4828-93fc-4958bbfb9346", "682653a2-5bbb-46f9-924b-68b562276d31", "68912f2a-9e5e-4b85-b59e-b973f44b94ca", "8997c5e4-c28c-4a24-b125-93714bc319bc", "8a2dca1d-8d5a-4d34-a89d-4ae99b2b3a5a", "92a8b32d-4ebf-42fd-b268-99c6c42c8148", "99e29079-8915-4121-83ac-7e10d96c1477", "eea606d2-87c8-4015-8404-30d60261b198"], "title": "'Eventual' is earlier than 'immediate'", "venue": "foundations of computer science", "year": 1982, "id": "04c27324-b9b4-491e-aa5f-d726c4d31ac4"}
{"authors": ["Max Dauchet"], "n_citation": 50, "references": ["0b5d74e0-16f7-45d4-a8ed-c2ed78289c68", "16c147bf-2317-4f21-b403-5193f80b5429", "2fbceb14-533b-4014-8711-5ef6d0e39225", "43dc5cb6-3966-4fe8-9f44-67d00d0e1b92", "a7a8488c-8fdd-444c-85a0-6058e9247e41", "be9bd168-a5a8-4c1a-948f-a55eb578acbc", "ecefbe61-fb7a-43a7-be19-01ef548b5b84", "f452bcda-6d32-42b7-a41c-2980e1880579", "f750b43a-2c12-4c8a-a4d5-e8fe3ce55207"], "title": "Rewriting and Tree Automata", "venue": "Advances in Computers", "year": 1993, "id": "c158b4f7-9157-4879-815f-4d494b742379"}
{"authors": ["Ester M. Garz\u00f3n", "Inmaculada Garc\u00eda"], "n_citation": 50, "references": ["16f956c5-39b2-4bf2-8648-511aa78b1bd5", "91528d1c-37ee-4f86-b33e-d19b6ea9c6f9", "d1ecaea6-5280-450e-aa48-70d1b7c4db7e"], "title": "Parallel implementation of the Lanczos method for sparse matrices: analysis of data distributions", "venue": "international conference on supercomputing", "year": 1996, "id": "ba040ed7-cce2-49d1-b93f-c3a453939f47"}
{"abstract": "In this paper we introduce an abstract theory of normative reasoning, whose central notion is the generation of obligations, permissions and institutional facts from conditional norms. We present various semantics and their proof systems. The theory can be used to classify and compare new candidates for standards of normative reasoning, and to explore more elaborate forms of normative reasoning than studied thus far.", "authors": ["Silvano Colombo Tosatto", "Guido Boella", "Leendert W. N. van der Torre", "Serena Villata"], "n_citation": 50, "references": ["0393e045-edab-4bf0-bbf2-8f2686398235", "1c7ddbd7-046a-4333-aa6b-c4ce698d6fad", "231c55f9-6d9c-43ba-9b2d-dd173c6e91f0", "3f26fe4d-3c16-4514-8e08-0749c8386433", "45588102-4678-495f-982d-f8556307668b", "456871c2-1e54-42b5-a619-f1827f2d96ec", "529b2eaa-0414-4509-b2cb-a38bbb2d7ae3", "571f1843-371e-4816-9746-79b54a494a35", "5e8e3302-68c9-4514-90ed-2aa72d28629e", "676c5366-3d25-4982-8bcb-6986cb6ccbac", "8f25e27e-cf6f-4457-acc7-204f377b2ed2", "a5a8093c-149e-4380-a13b-b82a76335de9", "ad5583bd-fb3b-4088-9b3a-92db58053a81", "d11f82ca-a0c8-49ba-8007-4bad93ce6eb2", "f4fd1962-b19e-4e64-8d1b-2a11d9c5323c"], "title": "Abstract Normative Systems: Semantics and Proof Theory", "venue": "principles of knowledge representation and reasoning", "year": 2012, "id": "041813b3-5fa7-4117-b115-5969632190d7"}
{"abstract": "To design a probabilistic reasoning system, it might be necessary to construct the graphical structure of probabilistic network, from a given set of conditional independencies (CIs). It should be emphasized that certain redundant CIs must be removed before applying construction methods and algorithms. In this paper, firstly we discuss how to remove redundant CIs from a given set of CIs with the same context, which results in a reduced cover for the input CIs set, and then we suggest an algorithm to remove redundancy from arbitrary input CIs set. The resulting set of CIs after such a 'clean' procedure is unique. The conflicting CIs can be easily identified and removed, if necessary, so as to construct the desired graphical structure.", "authors": ["S. K. Michael Wong", "Tao Lin", "Dan Wu"], "n_citation": 3, "references": ["248489fa-59e6-426d-a25d-d8fda43082ab", "5c72cd80-2a7d-4354-aa76-4ef489f2f467", "a35a2078-055d-4557-8ef6-62b235fa48ef", "ae73cad8-b3ad-4a10-a74d-a3dddefc9a0f", "b00445b2-74f9-49de-a228-16ed2a4eb9b7", "b04e5fda-f400-4118-93d1-5c17e23db7fa", "b6ba1cd3-3297-4eb1-8a18-76fd56f70a77", "d3e00e7e-1c64-4d7a-b2b2-1ad98ba4c706", "f58170d7-321a-4bcf-9d56-2df52e07b6ac", "f8b2045f-195e-420f-9516-df72eeb7df74", "fbd140c0-4a90-4ab7-aec7-e50ecaa0e340"], "title": "Construction of a Non-redundant Cover for Conditional Independencies", "venue": "canadian conference on artificial intelligence", "year": 2002, "id": "8ecee9f8-1bd3-4c3d-936c-2b855b508f31"}
{"abstract": "Abstract   A common basis is suggested for the optical flow estimation approaches of Nagel (1983), Haralick and Lee (1983) and Tretiak and Pastor (1984). Based on a discussion of these approaches, an exact solution for the system of partial differential equations proposed by Horn and Schunck (1981) is given at gray value corners and extrema. The insight gained by this solution results in a modification of the \u201coriented smoothness\u201d approach of Nagel (1983) which thereby becomes considerably simpler. In addition, the optical flow estimation approach of Hildreth (1983, 1984) can be shown to represent a kind of special case of this modified \u201coriented smoothness\u201d approach in a more direct manner than discussed in Nagel (1984).", "authors": ["Hans-Hellmut Nagel"], "n_citation": 591, "references": ["0d66d358-49fa-4d9c-931e-98c828313246", "1a0d4a74-896d-4fdf-a011-9ebaef3fc87a", "52016213-5767-4c30-a22f-e5b4e0956b39", "7335fccc-dde8-4196-8f90-09a488c5cd68", "83e7f895-4622-45d4-ba94-05999b1b5be3", "b4f62fbe-1de4-42b1-afee-be46007f7734", "c349411e-b528-42ba-b046-b2598b22fff7", "d98d389d-ca5f-43f4-b9bc-7dbea42e718e", "e40eaf4b-30e2-4f81-8115-9ce5464f7220"], "title": "On the estimation of optical flow: relations between different approaches and some new results", "venue": "Artificial Intelligence", "year": 1987, "id": "93a5ad9b-7ab6-49ae-86d8-16f8137be7c6"}
{"abstract": "The paper is concerned with control of switched linear systems, and proves two new fundamental results (equivalence and separation) about feedback policies for these systems. Addressed is the problem of jointly synthesizing a switching rule and a feedback controller for guaranteed stability and performance levels subject to well-posedness-like constraints. Two main results of the paper are the equivalence of open-loop and closed-loop switching, and the separation between switching and feedback. That is, open-loop switching rules are non-conservative for stabilization and performance optimization, and in output feedback control they can be obtained separately from the feedback controller. The synthesis conditions for switching and feedback are convex and expressed in terms of linear matrix inequalities.", "authors": ["Ji Woong Lee", "Geir E. Dullerud"], "n_citation": 50, "references": ["0fa594af-f0b7-4d72-9512-ece392d45629", "22f41b0f-eb9a-4412-8ea5-b459ab80578b", "33c93126-576a-46cd-ab14-8a49208d4691", "92adc393-d97d-4365-96b5-2167eb5272e7", "987dc70e-959e-47de-a313-0eabd979464b", "ba676a5a-23f6-429a-bc4e-898ee1410699", "c9dac1ed-2e53-4c1c-b28b-63cedfe0473c", "dd152c21-ffd1-45ea-93f4-2471b7c5ba48", "e34559d8-8ff1-4b91-bc3a-5d36cc6c4326", "e3f40554-65dd-4adc-841e-7c0ea02a6f29", "e844abfa-e467-4bab-bfb6-500429c5c445", "f53efada-6e0a-403e-a49b-d3c6e9389560"], "title": "Joint synthesis of switching and feedback for linear systems in discrete time", "venue": "", "year": 2011, "id": "0d1bb64d-5390-4499-a8e0-809fc7ca59f4"}
{"abstract": "We provide a model-theoretic framework for inves- tigating and comparing a variety of mereotopological theories with respect to (i) the intended interpretation of their connec- tion primitives, and (ii) the composition of their intended do- mains (e.g., whether or not they allow for boundary elements).", "authors": ["Anthony G. Cohn", "Achille C. Varzi"], "n_citation": 52, "references": ["00ae2773-3978-4023-9b65-ac4559eef30b", "29ee3bf7-dd2e-4d51-8641-a24fac553549", "37b7dee1-e972-4f4e-b0d1-818a78ff275c", "6662e83b-e31c-4c5d-8ee5-ee440ef31a0c", "95c544e2-44cd-4076-a6d4-c7cf30c999e8", "a5dea3c1-af37-4d62-ba16-b107af48dad9", "b98d12b1-faa5-4a00-84ef-90a40b95cf63", "c7f8ab66-486d-44a0-ac15-36f106f74017", "d491e2d8-8a9f-4d6a-9a8a-70e4b86c4886"], "title": "Connection Relations in Mereotopology", "venue": "european conference on artificial intelligence", "year": 1998, "id": "7b812748-9098-41b2-a25e-95beea930544"}
{"abstract": "A randomized approach is considered for a feasibility problem on a parameter-dependent linear matrix inequality (LMI). In particular, a gradient-based and an ellipsoid-based randomized algorithms are improved by introduction of a stopping rule. The improved algorithms stop after a bounded number of iterations and this bound is of polynomial order in the problem size. When the algorithms stop, either of the following two events occurs: (i) they find with high confidence a probabilistic solution, which satisfies the given LMI for most of the parameter values; (ii) they detect in an approximate sense the non-existence of a deterministic solution, which satisfies the given LMI for all the parameter values. These results are important because the original randomized algorithms have issues to be settled on detection of convergence, on the speed of convergence, and on the assumption of feasibility. The improved algorithms can be adapted for an optimization problem constrained by a parameter-dependent LMI. A numerical example shows the efficacy of the proposed algorithms.", "authors": ["Yasuaki Oishi"], "n_citation": 27, "references": ["27e55d87-f095-4acc-b40b-04262d57ca7b", "4775ea76-c970-44ac-a980-b3e5c0695eaf", "4a0e7be4-e50d-4d38-ad0e-e16edd6b265a", "4a45106a-7080-4887-8cc7-ce7cc41d7dc8", "4e4b299c-4596-4567-af47-3cc278bd28f7", "78245876-1c72-49ce-9664-c0543bd727fa", "8435adbc-5898-49a6-a017-955132822b2f", "91d0ca7b-4f31-4f0b-ac17-d2c884120f8a", "e0583d5e-bbf7-41e3-ac0e-f71f37961acd", "efadf6c3-bd72-47ec-a5d1-0fe1c8c99635", "f27b582f-152b-45ba-b676-ee40fa9f7801", "f456ecf4-8396-4736-ba06-c794c38fd0d5"], "title": "Brief paper: Polynomial-time algorithms for probabilistic solutions of parameter-dependent linear matrix inequalities", "venue": "Automatica", "year": 2007, "id": "624b51de-0e58-4a13-b2ed-290402118916"}
{"abstract": "We built on previous work to develop an evaluation method that can be used to select expert system applications which are most likely to be successfully implemented. Both essential and desirable features of an expert system application are discussed. Essential features are used to ensure that the application does not require technology beyond the state of the art. Desirable features help point to the applications that stand the greatest chance for successful implementation. Advice on helpful directions for evaluating candidate expert system applications is also given.", "authors": ["James R. Slagle", "Michael R. Wick"], "n_citation": 83, "title": "A method for evaluating candidate expert system applications", "venue": "Ai Magazine", "year": 1988, "id": "558d055b-ff27-4a6c-bb89-6db8aa3743d1"}
{"abstract": "Even though ICT convergence is a well-established and a-dopted concept, there is no consensus about the underlying software engineering approach to convergent ICT systems. Telecom engineers and software engineers traditionally use different approaches when developing services and applications. A main question is whether or not the differences are justified and should be maintained in the context of convergence? In this paper, we seek to answer this question by analyzing the different nature of the telecom domain and the computing domain. We identify a few fundamental differences that must be bridged when making convergent systems and we investigate how UML can be used as an enabler to build such bridges.", "authors": ["Rolv Br\u00e6k", "Jacqueline Floch"], "n_citation": 50, "references": ["0f55f34b-111d-4334-8e8c-c18741cd8157", "1412ff23-1344-4034-87ac-344cc850f0b3", "5c759cf4-9b03-4b71-9864-2982764f6f0b", "64153bc0-0c3a-4c5d-be93-b0f29bafc84f", "bc757c41-bb3d-4ef2-8670-7d1c55749d5b"], "title": "ICT convergence: modeling issues", "venue": "system analysis and modeling", "year": 2004, "id": "18367917-420f-48a4-b41c-214a029ffab5"}
{"abstract": "Advertising on mobile devices has large potential due to the very personal and intimate nature of the devices and high targeting possibilities. We introduce a novel B-MAD system for delivering permission-based location-aware mobile advertisements to mobile phones using Bluetooth positioning and Wireless Application Protocol (WAP) Push. We present a thorough quantitative evaluation of the system in a laboratory environment and qualitative user evaluation in form of a field trial in the real environment of use. Experimental results show that the system provides a viable solution for realizing permission-based mobile advertising.", "authors": ["Lauri Aalto", "Nicklas G\u00f6thlin", "Jani Korhonen", "Timo Ojala"], "n_citation": 381, "references": ["09966736-36da-4fec-9b3b-caa9498e1384", "0d2b0ad1-0823-4b53-9dfa-f6ee39f533d7", "13e63f08-b9c2-43de-8108-b3fd6874ebcc", "1b560815-0d8d-44be-915b-af39eb7395e6", "6e3ef5bc-bdf8-4b98-b844-3a9b91549018", "736cb738-0714-47a6-860a-1afa623bb923", "79960c98-28d7-4c6f-8306-a485342a9378", "bfbe67da-f49f-4862-b207-b526906d3712", "f2b8f7e1-8671-4b28-92e1-20852b51dbc6"], "title": "Bluetooth and WAP push based location-aware mobile advertising system", "venue": "international conference on mobile systems, applications, and services", "year": 2004, "id": "40490c8b-d490-4024-8620-b4582245d7b2"}
{"abstract": "Abstract : The paper develops some ideas expounded in a previous paper. It distinguishes a number of ways of using parallelism, including disjoint processes, competition, cooperation, communication and colluding. In each case an axiomatic proof rule is given. Some light is thrown on traps or ON conditions. The program structuring methods described in the report are not suitable for the construction of operating systems.", "authors": ["C. A. R. Hoare"], "n_citation": 81, "references": ["01ab3421-c13d-4293-81b5-184ec0f19712", "2cead482-021c-45d5-a90a-5229da83cbe5"], "title": "Parallel programming: an axiomatic approach", "venue": "", "year": 1975, "id": "89d8394e-e94c-41e7-8745-74a961f49374"}
{"abstract": "Query refinement can help users find information on the Internet more effectively. This feature has been implemented in a PASS (personalized abstract search services) system, a Web-based, domain-specific search engine for searching abstracts of research papers. The system uses a fuzzy ontology of term associations to support the feature. The ontology is automatically built in two stages using information obtained from the system's collection. A preliminary user study reveals that query refinement is one of the most important features of the system.", "authors": ["Dwi H. Widyantoro", "John Yen"], "n_citation": 149, "references": ["407ceb18-464f-4ab3-b731-68f7681fb26d", "e52ca406-8e6c-434d-b81e-eb133f35c936", "e5e1e41c-774c-4bb4-a087-bcd02fd37b0f", "e75d8e62-a86d-4241-953f-1b315005d920"], "title": "A fuzzy ontology-based abstract search engine and its user studies", "venue": "ieee international conference on fuzzy systems", "year": 2001, "id": "7efd86b1-ba6a-46d9-a32b-afadacb2daa1"}
{"abstract": "We present SensOrg, a computer music instrument designed as a modular assembly of input/output devices and musical software, mapped and arranged according to functional characteristics of the musician-instrument system. Using tangible bits and malleable atoms, we externally represented the musical software functionality in a physical interface which is freezable yet totally flexible.", "authors": ["Roel Vertegaal", "Tamas Ungvary"], "n_citation": 50, "references": ["9197b376-968a-4f81-9a59-c3cffa534827"], "title": "Tangible bits and malleable atoms in the design of a computer music instrument", "venue": "human factors in computing systems", "year": 2001, "id": "ad2c390c-eb62-4ed5-800f-b89a1abe7e1c"}
{"abstract": "Understanding how host load changes over time is instrumental in predicting the execution time of tasks or jobs, such as in dynamic load balancing and distributed soft real-time systems. To improve this understanding, we collected week-long, 1 Hz resolution traces of the Digital Unix 5 second exponential load average on over 35 different machines including production and research cluster machines, compute servers, and desktop workstations. Separate sets of traces were collected at two different times of the year. The traces capture all of the dynamic load information available to user-level programs on these machines. We present a detailed statistical analysis of these traces here, including summary statistics, distributions, and time series analysis results. Two significant new results are that load is self-similar and that it displays epochal behavior. All of the traces exhibit a high degree of self-similarity with Hurst parameters ranging from 0.73 to 0.99, strongly biased toward the top of that range. The traces also display epochal behavior in that the local frequency content of the load signal remains quite stable for long periods of time (150-450 s mean) and changes abruptly at epoch boundaries. Despite these complex behaviors, we have found that relatively simple linear models are sufficient for short-range host load prediction.", "authors": ["Peter A. Dinda"], "n_citation": 161, "references": ["6ed13d45-3965-4a51-bc0c-c7a49f49af56", "71f1eb0e-6fa4-4d80-a94c-0921320c2587", "72114231-1ee7-4408-8263-9d5fd21199cf", "7d371899-f6a5-4e16-8365-835827db041e", "96fead9d-0bcc-4fae-b400-30ed44e82666", "beaebb8c-0681-4d63-aae9-9bcafeb6eedf", "c1977037-8120-462d-8d5f-b36065f11b15", "c94a3952-f1f2-4a1e-9254-96f195ca7e5b", "cbd46ce7-a3c8-4e82-bd3f-50f6db2e5fc6", "d2a57597-5f45-4c41-8020-03cdfc0ebb3f", "e593759c-0dd4-4e2f-9fde-40d6a64a521c", "eaa614b9-4d95-4564-b609-166c3b2c9d9d", "fe936596-cab6-4eae-9188-4ab9f238780c"], "title": "The statistical properties of host load", "venue": "Scientific Programming", "year": 1999, "id": "59c85516-a4e4-4ae4-95ea-248f3579c1a2"}
{"abstract": "Agent orientation is currently pursued primarily as a software paradigm. Software with characteristics such as autonomy, sociality, reactivity and pro-activity, and communicative and cooperative abilities are expected to offer greater functionality and higher quality, in comparison to earlier paradigms such as object orientation. Agent models and languages are thus intended as abstractions of computational behaviour, eventually to be realized in software programs. However, for the successful application of any software technology, the software system must be understood and analyzed in the context of its environment in the world. This paper argues for a notion of agent suitable for modelling the strategic relationships among agents in the world, so that users and stakeholders can reason about the implications of alternate technology solutions and social structures, thus to better decide on solutions that address their strategic interests and needs. The discussion draws on recent work in requirements engineering and agent-oriented methodologies. A small example from telemedicine is used to illustrate.", "authors": ["Eric S. K. Yu"], "n_citation": 145, "references": ["02426ca1-b6f8-4880-912c-a0b841bbf4c9", "176c4aaa-f2c1-4d30-bf5d-d39b5ada43ff", "1c207b02-780c-4b1f-a31d-6ec077839064", "2134bf3b-fd89-4724-90ce-5993b4fa3218", "2381be4d-1af4-4a6f-96f1-21d854b5935d", "32db78ad-1c6a-4277-a594-0a82f381abe0", "365ac4aa-5611-41ad-8018-6dba33f27ada", "3cdcd294-7e7e-45c3-97b6-c28a10c567e3", "3d42e778-caa2-4d8e-9b92-43ed00bc7fe9", "42ea6086-62ba-4bfa-b59c-4e454c848818", "43e74ea3-85e6-42af-9109-e6b4665c5b84", "602965f2-9ebd-4dae-9b05-6c4611cd3dc4", "69220232-821f-4e21-8d99-3decfb2f9da6", "6e671665-f037-41a2-ba11-a881d9f119df", "7b22ebb1-b7cc-4fd0-b25d-84920e7f714b", "95ad8766-6d2b-45d9-a275-e411ae736aa4", "9b9c464b-2a7e-4063-b2f3-0c1653964207", "af758934-597a-401d-9801-bfd60aeabe80", "b0abc2d8-7868-4867-bbd2-ce0976a60d6d", "b1a10077-957f-4c0a-9047-9cf02644aae6", "c0d2b44d-14d3-4047-842e-8aa5f66d4554", "c399a9cb-515a-4dfe-b6c5-81ffc7a3e1a1", "c85c4f66-7765-4a23-b9ea-7498c94f3c29", "e16dd38f-6e8d-4358-8118-4049c5b9f10b", "e603fbbb-9ebd-4679-a4d0-31b03f43ecc8"], "title": "Agent-Oriented Modelling: Software versus the World", "venue": "", "year": 2001, "id": "e2da2c26-a62c-42ee-9fe7-ee614efd9516"}
{"abstract": "We present the first stabilizing, unidirectional, deterministic token ring where each process has a constant number of states. In our token ring, each process has three bits, or eight states. In comparison, all previous stabilizing, unidirectional rings are probabilistic or have at least one process withnstates, wherenis an upper bound on the number of processes in the ring. The simplicity of our token ring makes it an attractive candidate for hardware implementation.", "authors": ["Mohamed G. Gouda", "F. Furman Haddix"], "n_citation": 39, "references": ["2cab318b-c91f-423e-a667-a91d09930cb5", "33de8856-0b19-450b-b18c-c38288e941ec", "c58bbb44-4fa4-403c-90c8-be4ccac7111c", "e21e1096-38e9-4014-bee9-861a384c3eb1"], "title": "The Stabilizing Token Ring in Three Bits", "venue": "Journal of Parallel and Distributed Computing", "year": 1996, "id": "d8cbef24-e9a4-4f90-810d-0541af8c3f1b"}
{"abstract": "Many steganographic systems are weak against visual and statistical attacks. Systems without these weaknesses offer only a relatively small capacity for steganographic messages. The newly developed algorithm F5 withstands visual and statistical attacks, yet it still offers a large steganographic capacity. F5 implements matrix encoding to improve the efficiency of embedding. Thus it reduces the number of necessary changes. F5 employs permutative straddling to uniformly spread out the changes over the whole steganogram.", "authors": ["Andreas Westfeld"], "n_citation": 628, "references": ["dd688bf5-42da-49ef-9da7-cbb8acfe1579", "e140b64c-0d81-4aae-bf34-376e39306d62"], "title": "F5-A Steganographic Algorithm", "venue": "information hiding", "year": 2001, "id": "2e866ed3-52d4-440d-a5a7-05d0902c215d"}
{"abstract": "Performance of the digital clock recovery scheme proposed by F.M. Gardner (1986), when applied to quadrature-amplitude-modulation (QAM) microwave radio communication systems is investigated. In particular, it is shown how to improve such a scheme by means of appropriate prefiltering of the incoming signal. The impulse response of the shaping filter is designed to achieve pattern-jitter-free clock recovery in the case of an ideal transmission channel. The impact of multipath fading on synchronizer performance is evaluated by means of computer simulation. >", "authors": ["Nunzio Aldo D'Andrea", "Marco Luise"], "n_citation": 71, "references": ["3e77a8b8-053a-4c60-b025-219de7df55c4", "6deee59b-61a3-4017-8442-b5aeacaeb32f", "e35f7cc4-a6c6-49b2-b23b-84c315580f36"], "title": "Design and analysis of a jitter-free clock recovery scheme for QAM systems", "venue": "IEEE Transactions on Communications", "year": 1993, "id": "079d21ac-d870-41bc-a471-7049bb9470a5"}
{"abstract": "This paper is concerned with the engineering of systems that are themselves comprised of other component systems, and where each of the component systems serves organizational and human purposes.i\u00be i\u00be These component purposes may be locally managed and optimized independently, or nearly so, of the objectives to be met by the composite system.i\u00be i\u00be There are a number of inherent characteristics of these systems, and such related terms as systems of systems (SOS) or federations of systems (FOS) or federated systems of systems (F-SOS) are often used to characterize them.i\u00be i\u00be It is asserted that the resultant systems generally possess the characteristics of complex adaptive systems.i\u00be i\u00be We provide an overview of the literature describing these engineering efforts and provide plausible strategies for systems engineering and management of SOS and FOS that are based on the principles of a 'new federalism'.i\u00be i\u00be Finally, the implications of these plausible SOS and FOS systems engineering and management concepts are discussed with emphasis on evolutionary acquisition in the style of DoD and Intelligence Community related programs.", "authors": ["Andrew P. Sage", "Christopher D. Cuppan"], "n_citation": 435, "references": ["be1dcc1e-a52e-4bb7-a19a-c2764f6efd83", "eb284910-ca3f-44d3-8362-6d2fff451705"], "title": "On the Systems Engineering and Management of Systems of Systems and Federations of Systems", "venue": "", "year": 2001, "id": "e69e6a65-13d5-40f2-b5b3-61adcef08781"}
{"abstract": "The verification of a particular class of infinite-state systems, namely, systems consisting of finite-state processes that communicate via unbounded lossy FIFO channels, is considered. This class is able to model, e.g., link protocols such as the Alternating Bit Protocol and HDLC. For this class of systems, it is shown that several interesting verification problems are decidable by giving algorithms for verifying: the reachability problem (whether a finite set of global states is reachable from some other global state of the system); the safety property over traces, formulated as regular sets of allowed finite traces; and eventuality properties (whether all computations of a system eventually reach a given set of states). The algorithms are used to verify some idealized sliding-window protocols with reasonable time and space resources. >", "authors": ["Parosh Aziz Abdulla", "Bengt Jonsson"], "n_citation": 401, "references": ["09d4f1c5-a20f-44a2-a911-a7709c9b8020", "22bf363a-dba5-4e97-9215-e9827fe45702", "3c392e53-5e3b-44c4-a4fa-b64819023d06", "625fea4d-d61e-49d2-899e-1891e14856fd", "67f8b466-f5ef-42e6-834b-840b06c6b13e", "7914a8d8-005e-458a-ac26-9b919d99da8c", "85d49262-16e3-4751-92e2-709a101156aa", "8c511081-0997-44e2-b06e-88b533e24584", "8d8ae06a-54a1-4175-82f9-7cd7d7f88900", "a0e01511-9865-4416-b87f-0a4dc5fb10bc", "c1102d81-fb2c-4701-94c6-47feea928648"], "title": "Verifying programs with unreliable channels", "venue": "logic in computer science", "year": 1993, "id": "5c012fda-c4f3-4878-9873-cc80caf71c84"}
{"abstract": "A variant of nearest-neighbor (NN) pattern classification and supervised learning by learning vector quantization (LVQ) is described. The decision surface mapping method (DSM) is a fast supervised learning algorithm and is a member of the LVQ family of algorithms. A relatively small number of prototypes are selected from a training set of correctly classified samples. The training set is then used to adapt these prototypes to map the decision surface separating the classes. This algorithm is compared with NN pattern classification, learning vector quantization, and a two-layer perceptron trained by error backpropagation. When the class boundaries are sharply defined (i.e., no classification error in the training set), the DSM algorithm outperforms these methods with respect to error rates, learning rates, and the number of prototypes required to describe class boundaries. >", "authors": ["Shlomo Geva", "Joaquin Sitte"], "n_citation": 156, "references": ["3bed407c-16ce-4d68-97e6-909d924cc949", "5880d47f-8b99-416d-a743-28d6b49f7ba9"], "title": "Adaptive nearest neighbor pattern classification", "venue": "IEEE Transactions on Neural Networks", "year": 1991, "id": "6ba0833b-b6fa-4d07-ac69-5a4016f60c96"}
{"abstract": "The inheritance anomaly [23] refers to the serious difficulty in combining inheritance and concurrency in a simple and satisfactory way within a concurrent object-oriented language. The problem is closely connected with the need to impose synchronization constraints on the acceptance of a message by an object. In most concurrent object-oriented languages this synchronization is achieved by synchronization code controlling the acceptance of messages by objects. Synchronization code is often hard to inherit and tends to require extensive redefinitions. The solutions that have appeared so far in the literature to alleviate this problem seem to implicitly assume that better, more reusable, mechanisms are needed to create and structure synchronization code. The approach taken in this paper is to consider the inheritance anomaly as a problem caused by the very presence of synchronization code. The goal is then to completely eliminate synchronization code. This is achieved by using order-sorted rewriting logic, an abstract model of concurrent computation that is machine-independent and extremely fine grain, and that can be used directly to program concurrent object-oriented systems. Our proposed solution involves a distinction between two different notions of inheritance, a type-theoretic one called class inheritance, and a notion called module inheritance that supports reuse and modification of code. These two different notions address two different ways in which the inheritance anomaly can appear; for each of them we propose declarative solutions in which no explicit synchronization code is ever used.", "authors": ["Jos\u00e9 Meseguer"], "n_citation": 111, "references": ["1e459f12-9ffa-43aa-8dcf-f22a6b8d2d5a", "38ca153b-ae43-41c0-b440-a0e66874aa84", "414f57c6-3f1f-4da5-8c26-b6e1c2f62120", "54fa72d2-6fe8-4c43-bd82-55e4bb1b8112", "5efdf9b2-a2e2-4929-9728-00fbca01e604", "6e9a72d9-dbc3-478c-8828-2e8f618fb428", "72372cde-2406-43b0-872f-eca1a24f048b", "74ca2b1e-5c25-4ae5-a45e-767b804baa95", "7a1bcc6b-4450-4d03-b6cf-8e42d7939002", "7b96c3b1-acf1-4038-b5fc-60a9af3fac2f", "7f4bb55f-2aa7-402e-a955-9e190dee2793", "acbb3760-1fc3-41e0-bd85-b1eed2f6fb4d", "b7de590f-582e-482a-86b4-7d01c7f4129c", "be9bd168-a5a8-4c1a-948f-a55eb578acbc", "d52ecb60-977b-4607-8a5e-0ba0bcd53e8b", "e5bf88c2-91b2-4ef3-874e-8845c9152dcc"], "title": "Solving the Inheritance Anomaly in Concurrent Object-Oriented Programming", "venue": "european conference on object-oriented programming", "year": 1993, "id": "d4665462-9ed2-46ef-9bd6-d096a7107e45"}
{"abstract": "This paper develops the separating capacities of families of nonlinear decision surfaces by a direct application of a theorem in classical combinatorial geometry. It is shown that a family of surfaces having d degrees of freedom has a natural separating capacity of 2d pattern vectors, thus extending and unifying results of Winder and others on the pattern-separating capacity of hyperplanes. Applying these ideas to the vertices of a binary n-cube yields bounds on the number of spherically, quadratically, and, in general, nonlinearly separable Boolean functions of n variables. It is shown that the set of all surfaces which separate a dichotomy of an infinite, random, separable set of pattern vectors can be characterized, on the average, by a subset of only 2d extreme pattern vectors. In addition, the problem of generalizing the classifications on a labeled set of pattern points to the classification of a new point is defined, and it is found that the probability of ambiguous generalization is large unless the number of training patterns exceeds the capacity of the set of separating surfaces.", "authors": ["Thomas M. Cover"], "n_citation": 1669, "references": ["c8a92b83-0d39-498c-883c-481cc1b2691d", "d9b4ddfd-5ba2-44b2-a972-579dd34b1962"], "title": "Geometrical and Statistical Properties of Systems of Linear Inequalities with Applications in Pattern Recognition", "venue": "IEEE Transactions on Electronic Computers", "year": 1965, "id": "db3572c6-2a7e-47d7-9aec-1f57291c55d5"}
{"abstract": "The NRL Protocol Analyzer (NPA) is a tool for the formal specification and analysis of cryptographic protocols that has been used with great effect on a number of complex real-life protocols. It probably outranks any of the existing tools in the sheer range of the types of attacks it is able to model and discover. However, the techniques in NPA lack an independent formal specification and model, and instead are closely intertwined with other NPA features. The main contribution of this paper is to rectify this problem by giving for the first time a precise formal specification of one of the main features of the NPA inference system: its grammar-based techniques for invariant generation, as well as a backwards reachability analysis method that captures some of the key features of the NPA. This formal specification is given within the well-known rewriting framework so that the inference system is specified as a set of rewrite rules modulo an equational theory describing the behavior of the cryptographic algorithms involved.", "authors": ["Santiago Escobar", "Catherine Meadows", "Jos\u00e9 Meseguer"], "n_citation": 29, "references": ["1428ad04-f857-4b63-bce9-4dfd06539429", "14fe688b-05b6-4580-9af6-a02e7490a3d5", "2b329348-9dd1-418b-959d-ebb1f4b63c74", "520a135b-4055-43bd-96d2-39c490533199", "669cfff1-0651-4ae1-896e-d1f402c09d17", "734027ab-06cb-4ae8-bd5b-1c979b222465", "7b53a871-2122-4249-9361-5fc4d506f2de", "804cb992-d1ab-4d00-a6d4-db8f089f1c69", "81245a3c-4859-4224-9c00-cf5454df0d58", "ab7c3e56-2475-48e6-95de-1558f3e123e4", "c4e123b6-cfda-481e-af75-e4275fc0a3cb", "c9c5560f-67ca-4d45-8b2e-8263766686ca", "d8046a26-1b86-4e09-b28c-e5e62e0215ab", "f7937748-4a03-4d66-a770-39c88cc8320f"], "title": "A rewriting-based inference system for the NRL protocol analyzer: grammar generation", "venue": "formal methods", "year": 2005, "id": "b13bb593-6600-4cc7-a0bd-276934bc6101"}
{"abstract": "We consider classification problems in which the class labels are organized into an abstraction hierarchy in the form of a class taxonomy. We define a structured label classification problem. We explore two approaches for learning classifiers in such a setting. We also develop a class of performance measures for evaluating the resulting classifiers. We present preliminary results that demonstrate the promise of the proposed approaches.", "authors": ["Feihong Wu", "Jun Zhang", "Vasant Honavar"], "n_citation": 42, "references": ["150e8cf7-1123-4da1-b211-00f42811e53b", "5a8e6ec1-4de9-4b56-a7a3-e1572ce9dbac", "68d26331-e331-47a6-8541-f537ce817e97", "e1c5c332-54a3-4452-b9bc-58726c069a5f"], "title": "Learning classifiers using hierarchically structured class taxonomies", "venue": "symposium on abstraction reformulation and approximation", "year": 2005, "id": "e420d90e-cff5-477b-973f-339d8971393a"}
{"abstract": "An increasing, degree of rich and dynamic content and abundant links are making Web pages visually cluttered. This paper presents a numerical tool to evaluate the screen complexity of a Web page using four critical measurements: size complexity, local density, grouping, and alignment. In the empirical study, we first translate the real screens from four first pages on Ebay auction web sites to serve as model screens that contain the structure of complexity without content. We subsequently compare the complexity values calculated from the model screens with the viewers' judgment from the real screens. The resemblance between the results indicates that the tool is useful.", "authors": ["Fong-Ling Fu", "Shao-Yuan Chiu", "Chiu Hung Su"], "n_citation": 3, "references": ["05f97613-1a87-485a-9c66-12fcfc712bf8", "19cb14fe-f1a4-4c25-9e67-3b4acafe59f3", "22111af3-91b0-44e0-92e8-d39f0d8be7a8"], "title": "Measuring the screen complexity of web pages", "venue": "", "year": 2007, "id": "75f7e2a7-e2e7-4526-8972-96edf2ca133f"}
{"abstract": "This paper introduces a multi-Principal-Distribution-Model (PDM) method and Hidden Markov Model (HMM) for gesture recognition. To track the hand-shape, it uses the PDM model which is built by learning patterns of variability from a training set of correctly annotated images. However, it can only fit the hand examples that are similar to shapes of the corresponding training set. For gesture recognition, we need to deal with a large variety of hand-shapes. Therefore, we divide all the training hand shapes into a number of similar groups, with each group trained for an individual PDM shape model. Finally, we use the HMM to determine model transition among these PDM shape models. From the model transition sequence, the system can identify the continuous gestures representing one-digit or two-digit numbers.", "authors": ["Chung-Lin Huang", "Ming-Shan Wu", "Sheng-Hung Jeng"], "n_citation": 21, "references": ["083bb3ca-ab27-45c8-91ef-1d132e068a94", "67cfb6a4-846a-4f7d-9fca-1fc9337663cd", "748763b2-b9d4-41cf-9d00-8763a7902da9", "923f5d0a-23a3-4fb1-bee7-ec72122709a4", "b87cd1cd-b3fb-4407-9ee1-a4471715b8db", "c7d3b537-17dc-4357-99ae-2a3e193f9b0e"], "title": "Gesture recognition using the multi-PDM method and hidden Markov model", "venue": "Image and Vision Computing", "year": 2000, "id": "803e1c67-6daa-453f-8401-3489f30113e2"}
{"authors": ["Arie van Deursen"], "n_citation": 4, "references": ["4bcc7b6d-dd77-41f1-ac1a-3a86b26a6d02"], "title": "Beyond Page Objects: Testing Web Applications with State Objects", "venue": "ACM Queue", "year": 2015, "id": "b9c93119-f1fe-419c-854b-7a842b06bd69"}
{"abstract": "From the Publisher:#R##N#This book presents a unified theory of Generalized Stochastic Petri Nets (GSPNs) together with a set of illustrative examples from different application fields. The continuing success of GSPNs and the increasing interest in using them as a modelling paradigm for the quantitative analysis of distributed systems suggested the preparation of this volume with the intent of providing newcomers to the field with a useful tool for their first approach. Readers will find a clear and informal explanation of the concepts followed by formal definitions when necessary or helpful. The largest section of the book however is devoted to showing how this methodology can be applied in a range of domains.", "authors": ["M. Ajmone Marsan", "Gianfranco Balbo", "Gianni Conte", "Susanna Donatelli", "Giuliana Franceschinis"], "n_citation": 984, "title": "Modelling with Generalized Stochastic Petri Nets", "venue": "measurement and modeling of computer systems", "year": 1998, "id": "2d1b3485-4b45-4f2f-882e-6c6239c3ae70"}
{"abstract": "A new skeletonization algorithm called the safe-point thinning algorithm (SPTA) is proposed that is suitable for binary patterns. The SPTA is informally explained and is also defined in a formal algorithmic manner. The experimental performance of the SPTA is compared with 14 other skeletonization algorithms that have been proposed by other researchers. Results show that SPTA is the fastest and that it produces skeletons of good quality.", "authors": ["Nabil Jean Naccache", "Rajjan Shinghal"], "n_citation": 305, "title": "SPTA: A proposed algorithm for thinning binary patterns", "venue": "systems man and cybernetics", "year": 1984, "id": "9d416518-bfc3-454c-8688-f7e05b04ba12"}
{"abstract": "We describe two reversible line-drawing methods for cartographic applications based on the kinetic (moving-point) Voronoi diagram. Our objectives were to optimize the user's ability to draw and edit the map, rather than to produce the most efficient batch- oriented algorithm for large data sets, and all our algorithms are based on local operations (except for basic point location). Because the deletion of individual points or line segments is a necessary part of the manual editing process, incremental insertion and deletion is used. The original concept used here is that, as a curve (line) is the locus of a moving point, then segments are drawn by maintaining the topology of a single moving point (MP, or the \"pen\") as it moves through the topological network (visualized as either the Voronoi diagram or Delaunay triangulation). The trailing line accumulates the adjacency relationships of MP. There are thus three parts to our method: the maintenance of MP in the DT/VD; the use of MP to draw the constrained edges in the Delaunay triangulation; and the use of MP to draw the line segment Voronoi diagram. In all cases deletion is the inverse of the original drawing: move MP so as to \"roll up\" the desired segment. This approach also has the interesting property that a \"log file\" of all operations may be preserved, allowing reversion to previous map states, or \"dates\", as required.", "authors": ["Christopher M. Gold", "Maciej Dakowicz"], "n_citation": 10, "references": ["06d5ee43-254e-4c7c-a401-b6bc29b08579", "38d78246-9c3c-4507-9d83-c73a5ab61621", "438b6ca2-2270-425e-8267-1a774a8b2aad", "4cf2d215-d398-418b-95e5-1c26867ecdb1", "4f4d1779-e147-49e0-a193-78331adce152", "638558f1-31d7-4857-9f49-e8d9edc129f2", "688e3106-873c-4568-b465-1f95ce2619e6", "69f6e102-5558-439a-a8b6-62661ec74edc", "70e017b3-5711-4eae-aaa5-099139440342", "75e84c9e-031e-4b81-8f28-64f1876822a1", "c8d71ca7-605d-4b67-9bb7-eda7011c1c76", "d1a32379-d352-4575-a2c2-cd436026177c", "e33f4125-17ab-4cbf-9140-9585ec348e4d"], "title": "Kinetic Voronoi/Delaunay Drawing Tools", "venue": "", "year": 2006, "id": "c8eaf138-57db-4e7a-a332-7c6b6c7eb4bc"}
{"abstract": "Multithreaded programming is notoriously difficult to get right. A key problem is non-determinism, which complicates debugging, testing, and reproducing errors. One way to simplify multithreaded programming is to enforce deterministic execution, but current deterministic systems for C/C++ are incomplete or impractical. These systems require program modification, do not ensure determinism in the presence of data races, do not work with general-purpose multithreaded programs, or run up to 8.4\u00d7 slower than pthreads.   This paper presents Dthreads, an efficient deterministic multithreading system for unmodified C/C++ applications that replaces the pthreads library. Dthreads enforces determinism in the face of data races and deadlocks. Dthreads works by exploding multithreaded applications into multiple processes, with private, copy-on-write mappings to shared memory. It uses standard virtual memory protection to track writes, and deterministically orders updates by each thread. By separating updates from different threads, Dthreads has the additional benefit of eliminating false sharing. Experimental results show that Dthreads substantially outperforms a state-of-the-art deterministic runtime system, and for a majority of the benchmarks evaluated here, matches and occasionally exceeds the performance of pthreads.", "authors": ["Tongping Liu", "Charlie Curtsinger", "Emery D. Berger"], "n_citation": 232, "references": ["1e388021-01b7-4b53-9718-6247afbf32d5", "32f03b19-e0f9-4fe4-9ffc-8ecf34b16d33", "3d6e0048-d364-432c-832a-ef4a93947e82", "432796bb-9585-4623-9fd8-d7abbcbb46c9", "53e08976-11f1-4b22-a529-1db27efd3104", "59e8e711-4ce2-454c-916c-5a070f573ec1", "6acd1b5a-dd4c-4d6b-8619-a907e91a32ab", "7d6124eb-3b72-4797-bf12-6d4ab5eb9083", "7e182520-45bd-491b-855c-31aceef3d6f7", "892457f9-f629-4ff4-90c2-5645fc901135", "897fbd3b-d963-4fa1-aacc-8a6324391b91", "89fe661e-83a3-4fd1-83db-075620e034a8", "a53254d3-f77a-4bb4-ad71-c15d5d7a315f", "a6037021-9d1c-4d74-8e25-d2341d054066", "a676a66d-37ff-4651-bb43-96250c5e03a3", "b6bf9b19-6b77-42fa-882d-a95defdc965b", "c036912f-ac89-48b8-85b4-ceff1d08e32a", "d2ebc645-06b6-427b-b083-952b3a6feef5"], "title": "Dthreads: efficient deterministic multithreading", "venue": "symposium on operating systems principles", "year": 2011, "id": "5c159b20-e221-4bdb-b7f9-b811a81e5d99"}
{"abstract": "We study the problem of computing zigzag persistence of a sequence of homology groups and study a particular sequence derived from the levelsets of a real-valued function on a topological space. The result is a local, symmetric interval descriptor of the function. Our structural results establish a connection between the zigzag pairs in this sequence and extended persistence, and in the process resolve an open question associated with the latter. Our algorithmic results not only provide a way to compute zigzag persistence for any sequence of homology groups, but combined with our structural results give a novel algorithm for computing extended persistence. This algorithm is easily parallelizable and uses (asymptotically) less memory.", "authors": ["Gunnar Carlsson", "Vin de Silva", "Dmitriy Morozov"], "n_citation": 117, "references": ["24b20c8b-3147-426f-83dd-36c6214554ec", "5a054b8e-ebc9-48b8-af14-46da3a790ec4", "5ad5ef3d-48f9-4093-8841-22cab9df049f", "5c2a3288-9936-4360-a1b5-99f79d16fba5", "8fa68462-2afa-4207-b2a6-54100b2913e8", "a1b70da0-3936-41e7-9344-e7716a295e5e", "b4c496e3-1e9d-4253-b734-42c208cdb81a", "dae4ad89-0811-4db5-8dbb-add6aba82c53"], "title": "Zigzag persistent homology and real-valued functions", "venue": "symposium on computational geometry", "year": 2009, "id": "d1a0fe85-b1f8-4950-a08b-ab4d10c3c154"}
{"abstract": "We propose a mathematical framework for object detection using logic operations as a structure for defining multi-channel segmentation. The model combines object information from the different channels into any logic combination. We consider active contour methods which use one initial contour that would evolve from the information given in each channel simultaneously. Specific models are derived based on the single-channel region based ''active contours without edges'' [IEEE Trans. Image Process. 10 (2) (2001) 266] model. Numerical experiments show that the method is able to find general intersections, unions, and complements of the regions of objects of both synthetic and realistic images.", "authors": ["Berta Sandberg", "Tony F. Chan"], "n_citation": 35, "references": ["088d00cf-ed12-4552-8958-8b550401f355", "1c63e1d5-b963-455b-829d-e4f3eb63a36a", "443fb8d3-09ba-45a2-98a6-597799c3e63c", "62b2deab-4872-45e6-bc02-7913cbe40009", "66b1ef75-0e28-4786-b6c1-73289741ddcf", "79d41652-2a9c-4b39-ad06-7e8474c0e47d", "7bda3def-639b-47b7-a882-1a5c35ab9693", "93f8e68c-fbda-4afd-a381-ec590ed9068a", "970d3cf0-11a6-4c04-b8e1-7eaca9dbc757", "ea153145-d877-4893-acc2-b9c7f48ab005", "fc9a9ab5-7585-419a-8d2f-cdddd99a5c25"], "title": "A logic framework for active contours on multi-channel images", "venue": "Journal of Visual Communication and Image Representation", "year": 2005, "id": "d7ffc4cd-4715-4743-b099-4e8b72c96fc7"}
{"abstract": "Clone detection provides a scalable and efficient way to detect similar codes, while program differencing is a powerful and effective way to analyze similar codes. CloneDiff, a Program Dependence Graphs (PDGs) differencing tool, complements clone detection with program differencing for the purpose of characterizing clones. It captures semantic information of clones from PDGs, and uses graph matching techniques to compute a precise characterization of clones in terms of a category of semantic differences.", "authors": ["Yinxing Xue", "Zhenchang Xing", "Stan Jarzabek"], "n_citation": 5, "references": ["0bc7d483-0597-4295-a144-7f2127b1e998", "2448f6ce-230a-495c-8cab-21a8bf2865eb", "a69de53e-f078-47c5-adf1-92572a649dcd", "ceb6c751-dbd3-4952-b242-e084430367f2", "e0d50d4e-55c8-4f3d-9ff8-88a91d765305"], "title": "CloneDiff: semantic differencing of clones", "venue": "", "year": 2011, "id": "2027ba8c-7a8c-4d76-9a14-8fb112a64f5d"}
{"authors": ["Rosa M. Carro", "Alvaro Ortigosa", "Johann H. Schlichter"], "n_citation": 26, "references": ["355cbf87-f4d4-4f79-8a50-6ce1a0a90620", "600fa2e2-e947-4c99-a885-bdf5290deda8", "60b1fa54-71fa-43e4-9c23-9d99349e69fc", "9da6ca60-6359-4385-9651-ea507c7804e9", "a63daf60-f4be-463f-819b-6240e87abd5f", "cd2279af-c12e-4756-8621-da86d4144a86", "d565a704-8da3-434d-84cd-005f0e2bd601"], "title": "A Rule-Based Formalism for Describing Collaborative Adaptive Courses", "venue": "", "year": 2003, "id": "71a928da-b0ca-400d-b30f-62d50fece492"}
{"abstract": "A method to compute the L\"2 gain is developed for the class of linear periodic continuous-time systems that admit a finite-dimensional state-space realisation. A bisection search for the smallest upper bound on the gain is employed, where at each step an equivalent discrete-time problem is considered via the well-known technique of time-domain lifting. The equivalent problem involves testing a bound on the gain of a linear shift-invariant discrete-time system, with the same state dimension as the periodic continuous-time system. It is shown that a state-space realisation of the discrete-time system can be constructed from point solutions to a linear differential equation and two differential Riccati equations, all subject to only single-point boundary conditions. These are well behaved over the corresponding one period intervals of integration, and as such, the required point solutions can be computed via standard methods for ordinary differential equations. A numerical example is presented and comparisons made with alternative techniques.", "authors": ["Michael Cantoni", "Henrik Sandberg"], "n_citation": 50, "references": ["83091942-b9f0-4305-bf6d-f780a884ef57", "892f1b39-b7cf-4d07-b635-f98d932d3eaa"], "title": "Brief paper: Computing the L2 gain for linear periodic continuous-time systems", "venue": "Automatica", "year": 2009, "id": "8ae4fc04-57ec-43aa-8c26-f2da1d938556"}
{"abstract": "The inability of software reuse to reach its full potential lies partially in the product-centric way in which we view software development. Methods are needed that help us reason about product families and degrees of support that can be offered for problem domains. This paper uses a \"domain lifecycle\" to formalize a process in which increasing levels of formality can be provided as a domain matures. The first step in this process is to collect and disseminate project experiences that can accelerate the process of identifying and refining application domains with significant impact in a software development organization. This approach facilitates the reuse of a broad spectrum of knowledge at multiple levels of formality. Based on empirical investigations of a software development organization, a prototype of a case-based organizational memory repository for software development practices is presented and assessed for its impact on reusing software development knowledge.", "authors": ["Scott Henninger"], "n_citation": 16, "references": ["0c1b7588-ff14-4aea-ad85-1cc451c02faf", "18386382-99fa-4eae-bf9e-4c4b07d6f802", "1881977e-6cec-434b-863d-e332fdbaf916", "37ac407b-3d52-429a-beda-559e99f3753d", "3d6f2881-462d-49c3-b9d0-cfa997c3cb5b", "3dbe9480-7071-46b5-ad7f-278756ff73de", "50189eb4-52fc-4a6a-86ee-6a7b279e1e4e", "7f4872b0-d490-4ea5-9a08-514a1f7ee324", "8136f8b0-daa7-4575-b480-a65479edba63", "83bea0dc-8682-453b-a4c8-f37648a5a00b", "92829bae-e23e-4a3b-8e4a-35afc5856514", "c49ea9f3-b8e3-41c3-84a4-3631a218382e", "d3f504cd-3381-4bba-b2e2-0cb21e364a71", "fbca8108-2171-4212-b479-23c3837bc28e"], "title": "Accelerating the successful reuse of problem solving knowledge through the domain lifecycle", "venue": "", "year": 1996, "id": "ebf1854c-ef24-4848-804b-751053ac9534"}
{"authors": ["Gunnar Brataas", "Svein O. Hallsteinsen", "Romain Rouvoy", "Frank Eliassen"], "n_citation": 35, "references": ["00199e54-1891-4e79-b6e5-ca2b631753d4", "2abeb54d-6aef-4401-ab3b-9b62e6d4abfd", "34fe62d9-99b4-4fd6-81fa-214a26e80d83", "352838dd-9583-402f-be39-52df4810a25f", "361ad61c-6454-4458-8767-1deff4089f4a", "62c9b046-ea25-4465-a6ae-f9588be6430a", "643288f8-5a36-4fc4-9889-bbd27644f2ac", "79616380-8ef6-4beb-925c-c5c01129dd78", "8f591312-7d82-4d0d-9a5c-837edcd8415b", "c2efe6de-11a6-4719-8915-87092a876e84"], "title": "Scalability of Decision Models for Dynamic Product Lines", "venue": "software product lines", "year": 2007, "id": "579deaee-47c7-4ca8-b162-37027525d5b9"}
{"abstract": "We propose a CDMA-based power controlled medium access protocol for mobile ad hoc networks (MANETs). Unlike previously proposed protocols, ours accounts for the multiple access interference (MAI), thereby addressing the notorious near-far problem that undermines the throughput performance in MANETs. Channel-gain information obtained from overheard RTS and CTS packets over an out-of-band control channel is used to dynamically bound the transmission power of mobile terminals in the vicinity of a receiver. By properly estimating the required transmission power for data packets, the proposed protocol allows for interference-limited simultaneous transmissions to take place in the neighborhood of a receiving terminal. Simulation results indicate that compared to the IEEE 802.11 approach, the proposed protocol achieves a significant increase in network throughput at no additional cost in energy consumption.", "authors": ["Alaa Muqattash", "Marwan Krunz"], "n_citation": 309, "references": ["277cd65c-dcb3-4347-835b-e058f2e057f1", "30e4f067-742f-4ad5-b8b0-66d3e8b6303f", "321a3269-e8be-4069-9371-0fa33e30d360", "50bb8fed-57b5-4acf-85ba-3249e91ac0f6", "7374be98-dfe4-4663-ab08-5e3eedec92a2", "7b625230-914e-46e9-b9a9-4fc881ae3842", "8d6fd396-f822-45f9-a060-4baa827c5aca", "f65a4365-2696-47f3-849b-501792da7e23", "fe9a64a7-aa51-4435-82b7-64fb2a63ed6d"], "title": "CDMA-based MAC protocol for wireless ad hoc networks", "venue": "mobile ad hoc networking and computing", "year": 2003, "id": "21949de9-2c5b-45ea-b6ee-089896e1303e"}
{"abstract": "Combinatorial testing is an important approach to detecting interaction errors for a system with several parameters. Existing research in this area assumes that all parameters of the system under test are always effective. However, in many realistic applications, there may exist some parameters that can disable other parameters in certain conditions. These parameters are called shielding parameters. Shielding parameters make test cases generated by the existing test model, which uses the Mixed Covering Array (MCA), fail in exposing some potential errors that should be detected. In this paper, the Mixed Covering Array with Shielding parameters (MCAS) is proposed to describe such problems. Then test cases can be generated by constructing MCAS\u2019s in three different approaches. According to the experimental results, our test model can generate satisfactory test cases for combinatorial testing with shielding parameters.", "authors": ["Baiqiang Chen", "Jun Yan", "Jian Zhang"], "n_citation": 12, "references": ["0c034abd-615a-409c-9a63-913fac625bef", "63c55cce-fb10-4c5e-aa2f-f870b4b5f1e6", "67e00237-2736-411a-b5db-64658070c17a", "6cd7a1a2-cc4f-45ab-986d-5c8f9ce4309f", "9f6f0a1b-bd91-497b-8237-43bd83576a24", "d97590aa-895e-42e3-8f8a-ce07cb403c58"], "title": "Combinatorial Testing with Shielding Parameters", "venue": "asia-pacific software engineering conference", "year": 2010, "id": "a4d75655-d269-4526-9166-57a75c824b2a"}
{"abstract": "In ( Holz and Loew, 1994a \u00a0; \u00a0 Holz and Loew, 1994b ), we presented a metric for use in classifier-independent feature analysis called relative feature importance (RFI). RFI was shown to correctly rank features on a variety of two-class multi-cluster, mixed-distribution problems, including problems that cannot be solved using the marginal distributions of the features. We present here a complete design for RFI, including new results on parameter settings and calculation details determined on two-class problems. We then show that, using the design arising from exploration of two-class problems, RFI extends naturally and successfully to multi-class problems.", "authors": ["Hilary J. Holz", "Murray H. Loew"], "n_citation": 6, "references": ["ec845766-944c-4c12-8fa7-0cd11b523b7a"], "title": "Multi-class classifier-independent feature analysis", "venue": "Pattern Recognition Letters", "year": 1997, "id": "0e67be82-e68c-461a-ae41-80ac3c017b85"}
{"abstract": "The concept of relative bid privacy in auction is proposed, which does not conceal the bids, but conceals the link between them and the corresponding bidders. Relative bid privacy leads to three advantages: high efficiency, the bidding values can be very precise and any auction rule can be applied. A new mix network is designed and applied to implement relative bid privacy efficiently. Two rounds of shuffling are employed in the mix network, so that fairness can be achieved in the auction without any trust and relative bid privacy is achieved even in abnormal situations.", "authors": ["Kun Peng", "Colin Boyd", "Ed Dawson", "Kapalee Viswanathan"], "n_citation": 50, "references": ["0a69e3ab-2c22-4e7e-85b4-3746b65e4e6a", "0af9d4c7-22c4-42fc-a1cb-27d32db41f64", "160834cc-caef-4a3a-9c07-22d6b531623b", "1b46e1b0-61d4-407d-a44b-e3b842b4ff84", "1ee68967-435a-4b08-9d5e-bbf1c98bdc92", "3b9c9d3b-ca22-4c1b-ae03-d9da384b3e3b", "41260ba8-5dde-4c99-83d1-e1ac541362f3", "4de4dffe-2527-4460-9a02-67823aba9775", "5b18767e-41df-4a56-aea5-6bf69575b1fd", "6f1309c6-4b4a-4855-9788-c30bf8c41d15", "710b2242-41b5-446c-853f-e66208082c1e", "792d69b0-aacd-4f22-b306-16bfa7b43667", "83ee37ec-7fb2-40a8-b684-551ae049c8bb", "84b01f17-dec4-4d17-b7bd-9277af2cdcf8", "930908d3-7ccb-4aa8-a505-c1a9ff2070eb", "99debae8-a5da-4ec6-8309-a904cdaa9880", "a4cd1856-1d68-4688-8cbe-dc09c3cf377f", "af44b3ab-8852-4238-b494-c2e339d1db8a", "af9b6b75-7d53-4502-9acb-70c70165ff3d", "e1d20fe3-46b3-4fb1-a293-e36d292ad8d3", "faeefe5b-a41c-4e99-bd9a-0cb1a5dfa3fa"], "title": "Efficient Implementation of Relative Bid Privacy in Sealed-Bid Auction", "venue": "workshop on information security applications", "year": 2003, "id": "7f973898-17ee-47ea-b88e-1514242c8ad3"}
{"abstract": "Angelic nondeterminism can play an important role in program development. It simplifies specifications, for example in deriving programs with a refinement calculus; it is the formal basis of regular expressions; and Floyd relied on it to concisely express backtracking algorithms such as N-queens.   We show that angelic nondeterminism is also useful during the development of deterministic programs. The semantics of our angelic operator are the same as Floyd's but we use it as a substitute for yet-to-be-written deterministic code; the final program is fully deterministic. The angelic operator divines a value that makes the program meet its specification, if possible. Because the operator is executable, it allows the programmer to test incomplete programs: if a program has no safe execution, it is already incorrect; if a program does have a safe execution, the execution may reveal an implementation strategy to the programmer.   We introduce refinement-based angelic programming, describe our embedding of angelic operators into Scala, report on our implementation with bounded model checking, and describe our experience with two case studies. In one of the studies, we use angelic operators to modularize the Deutsch-Schorr-Waite (DSW) algorithm. The modularization is performed with the notion of a parasitic stack, whose incomplete specification was instantiated for DSW with angelic nondeterminism.", "authors": ["Rastislav Bodik", "Satish Chandra", "Joel Galenson", "Doug Kimelman", "Nicholas Tung", "Shaon Barman", "Casey Rodarmor"], "n_citation": 43, "references": ["01ab3421-c13d-4293-81b5-184ec0f19712", "042a331d-33a2-4bba-b27f-5b9177008612", "16e205e5-4929-4700-8df4-6ccfc7f96250", "2410eaa6-1ccb-41ce-8151-d6a73d323b5d", "3aedcb26-5b33-4371-96e5-68890754fb0f", "9086a437-bdde-48ba-963b-e9e6991d46f5", "a7e2cd93-7f9d-4948-931e-76f9ab3eeacb", "b0f6455a-6f99-42c5-8502-4fa535768ceb", "b30aaca8-d1eb-4f4a-bc77-047526e5570c", "c00bbb49-6e29-4103-8883-55acd23c248b", "d13d9aa6-ce11-434a-b409-c9a0b4ad3445", "fef69f3a-4f9c-4d6e-84b6-7624bbea3e15"], "title": "Programming with angelic nondeterminism", "venue": "symposium on principles of programming languages", "year": 2010, "id": "7413bee3-b547-42d1-951f-863b3af44bde"}
{"abstract": "In this paper, we present  Vigilare system , a kernel integrity monitor that is architected to snoop the bus traffic of the host system from a separate independent hardware. This  snoop-based monitoring  enabled by the Vigilare system, overcomes the limitations of the  snapshot-based monitoring  employed in previous kernel integrity monitoring solutions. Being based on inspecting snapshots collected over a certain interval, the previous hardware-based monitoring solutions cannot detect  transient attacks  that can occur in between snapshots. We implemented a prototype of the Vigilare system on Gaisler's grlib-based system-on-a-chip (SoC) by adding  Snooper  hardware connections module to the host system for bus snooping. To evaluate the benefit of snoop-based monitoring, we also implemented similar SoC with a snapshot-based monitor to be compared with. The Vigilare system detected all the transient attacks without performance degradation while the snapshot-based monitor could not detect all the attacks and induced considerable performance degradation as much as 10% in our tuned STREAM benchmark test.", "authors": ["Hyungon Moon", "Ho-Joon Lee", "Jihoon Lee", "Kihwan Kim", "Yunheung Paek", "Brent ByungHoon Kang"], "n_citation": 66, "references": ["0c23defd-5cc4-45c2-940c-aa6b2cf72fc0", "1507328c-7eaf-491f-a20a-4d8f3ef4ed29", "1a1e66ac-5457-4b67-bba2-a9957f7886b0", "67889628-d984-4c89-b722-0d0a3d6e8f00", "7412e600-d315-49a1-b7ee-abcf1134bd63", "7f636427-d8bb-4c7c-8b4d-eef5d6026627", "940d0bea-e5f8-49a4-a6f8-ac7bfec66321", "b109da56-918d-45b9-bfa5-07227fa0246f", "b997567a-2fda-453f-8917-d508c137ed0f", "c4597017-4519-48cd-b4b6-2952e4bb53e7", "c4e4280d-ece1-4bd2-ae39-296ad3e7f0d9", "d29a580b-cdf9-4e80-8a9e-e692db1a42b6", "d76e3cc9-402d-4101-a678-5c05370e7568", "eafbd356-d8ac-4bcf-b9ed-9d50bf806d84", "fcced25f-ce89-4e16-aa21-dd6a5f222f3e"], "title": "Vigilare: toward snoop-based kernel integrity monitor", "venue": "computer and communications security", "year": 2012, "id": "f1d1be1d-9ca0-48db-9327-146a8babd025"}
{"abstract": "We deal with temporal aspects of distributed systems, introducing and studying a new model called timed distributed \u03c0-calculus. This model extends distributed \u03c0-calculus with timers, transforming the communication channels into temporary resources. Distributed \u03c0-calculus describes located interactions between processes with restricted access to resources. We introduce time constraints by considering timeout timers for channels. Combining these timers with types and locations, we provide a formal framework able to describe complex systems with constraints on time and on resource access. Its typing system and operational semantics are presented. It is proved that the passage of time does not interfere with the typing system. The new model is proved to be sound by using a method based on subject reduction.", "authors": ["Gabriel Ciobanu", "Cristian Prisacariu"], "n_citation": 59, "references": ["21d3fc3b-da3e-4b5a-9d72-ac72a15df43b", "48beac3d-d180-4e6e-9360-d631a787c16c", "4e9a04f1-f844-467a-97a6-5999f6ee39bc", "6f45828a-82d4-4306-bc4f-f7fb31d4298e", "c6c9d2bf-cf62-4a0a-926a-0da6d5ca04ac", "d08b12af-87ac-48ec-8b4e-c9bf20a1b907", "fbc814bc-3465-4652-bb50-455f9999f424"], "title": "Timers for Distributed Systems", "venue": "Electronic Notes in Theoretical Computer Science", "year": 2006, "id": "474cdefe-942a-452d-9247-0ef12933f9aa"}
{"authors": ["Xumin Nie", "David A. Plaisted"], "n_citation": 20, "references": ["112eeff7-c265-4808-aef5-55f592540e40", "125dde08-93db-454c-bea3-227b89e7f6a8", "22b152ec-1ba5-4dbe-bfa0-efe410f44f58", "4384f8c0-deac-4572-9b7d-4ef2fe3476fb", "99390949-b4cd-48ce-99ef-c0299763488c", "cead012c-f1cb-4ac2-8897-aad9af95de4c", "fd2e6eda-4411-4aa7-b6b7-2d4b9b95e5e6"], "title": "A Complete Semantic Back Chaining Proof System", "venue": "conference on automated deduction", "year": 1990, "id": "a81116d4-2c9c-4769-82dc-a333074dc876"}
{"authors": ["Mark S. Fox", "Bradley P. Allen", "Gary Strohm"], "n_citation": 147, "references": ["6ae40bf6-98f3-4715-a2b1-fa842ef2a55a", "701b6533-fc68-4d22-9878-849da1226c04"], "title": "Job-shop scheduling: an investigation in constraint-directed reasoning", "venue": "national conference on artificial intelligence", "year": 1982, "id": "807276c1-40f2-4eab-bfc7-3e84aaca1bc7"}
{"abstract": "In this paper, we first present an Object Composition Petri Nets (OCPN) based model methodology for describing the dynamic behaviour of the multiple video objects and user interactions during the entire MPEG-4 video session; then, a Group of Video Object Plane (GOV) based periodical scheduling algorithm is proposed to assign the encoder tasks to a cluster of workstations with load balancing guarantee. The scheduling scheme can allocate the tasks efficiently according to the timing constraints as well as user interactions. The performance of the encoder can scale according to the number of workstations used. The experiment results indicate that a real-time encoding rate can be achieved for the sequences with multiple video objects.", "authors": ["Yong He", "Ishfaq Ahmad", "Minglei Liou"], "n_citation": 50, "references": ["74c8c826-341e-4872-98a4-c281eacb1e5f", "b09795f0-bc50-4307-bec8-36af890df09a", "e265d8be-11cf-4b4e-ad11-9e51441f4547"], "title": "Modeling and Scheduling for MPEG-4 Based Video Encoder Using a Cluster of Workstations", "venue": "parallel computing", "year": 1999, "id": "9a535865-0798-4210-a4ad-0e1cda90c9ee"}
{"authors": ["Karl-Rudolf Moll", "Manfred Broy", "Markus Pizka", "Tilman Seifert", "Klaus Bergner", "Andreas Rausch"], "n_citation": 50, "references": ["3c4a7476-a0f1-4f65-b972-ac7b1ae996c0", "669b92be-fa26-4795-9c34-82e03d3cd050", "d20e5212-c1b9-44c1-82fb-399427626d55"], "title": "Erfolgreiches Management von Software-Projekten", "venue": "Informatik Spektrum", "year": 2004, "id": "4b8e71da-2616-46f4-9c45-15476844fbb7"}
{"abstract": "IP Mobility management protocols are divided into two kinds of category: host-based and network-based mobility protocol. The former category, such as MIPv6 protocol and its enhancements (e.g., HMIPv6 and FMIPv6), supports the mobility of a Mobile Node (MN) to roam across network domains. This is done through the involvement of MN in the mobility-related signalling, which requires protocol stack modification and IP address changes on the MN. The latter category, such as PMIPv6 protocol, handles mobility management on behalf of the MN thereby enabling it to connect and roam within localized domains, which requires neither protocol stack modification nor IP address change of the MN. PMIPv6 attracts attention in the Internet and telecommunication societies by improving the performance of the MN's communication to fulfil the requirements of QoS for real-time services. In this article, we present IPv6 features to support mobile systems and survey the mobility management services along with their techniques, strategies and protocol categories, and elaborate upon the classification and comparison among various mobility management protocols. Furthermore, it identifies and discusses several issues and challenges facing mobility management along with an evaluation and comparison of several relevant mobility studies.", "authors": ["Ibrahim Al-Surmi", "Mohamed Othman", "Borhanuddin Mohd Ali"], "n_citation": 39, "references": ["0151bac2-e60c-41b6-b138-bb43fbdc9e84", "074fdc0a-26e9-43c9-b306-963599ec8793", "0cb5dd25-7323-4c48-8b9b-1d3a31268c53", "0f61e0d0-56e5-49e0-a2b8-a4589ea0e13d", "11919ba4-a60c-4081-8bc1-eb8773da9575", "11ec4eb7-f1a5-4e10-9897-0d7c06bf32cf", "1547432d-5c5c-41e3-b0c9-0be78a50212d", "1b26071b-65ea-455e-b8cb-7c90397ccb19", "2a253687-a638-48ed-b121-646e78fba00f", "30049c87-d30f-4086-9557-cd1ee90804ff", "36ae17c3-337e-4426-af3f-4e631e79a8e4", "45e08528-762d-4cb1-a9aa-69026d77fd05", "49846890-3408-4e6a-944a-d659ee26dfb8", "4b753db7-ba04-4f15-8200-3f887f4f0713", "4becad75-97cb-4f01-9db1-49879eb79b4b", "50e9a6d7-4f88-43ce-b61f-c5e2598df094", "618f00f1-18d2-4378-9217-d55b5d3b41df", "641026a6-a327-4341-9535-52ce5555f0d2", "656d1628-2091-4c24-b302-8944f2c0a46e", "67101a39-49a6-4034-a6dd-530371e118f3", "74705aa0-6c63-46e6-a6c7-16ef463333a7", "7a0b7c8f-1dc8-463d-88d6-a8d59e30fa8c", "7f941c31-eed4-46cb-93cb-4dbaa714eec7", "90608cc5-a3f7-4304-b91c-e2808907d366", "913685fc-5ac2-4fdc-b648-da20677d9b06", "a1ff3057-588c-4492-bf60-d2c22310590a", "a6424630-71d6-44dd-a36b-f32cd02b8a82", "a6629440-90bf-41b4-811b-4f206b1a6703", "aed9b791-eaec-40f8-94df-fdef3291f6d5", "b63723ef-03df-4e65-b2cb-9bcaedc84afd", "b86a91ae-7643-499b-b897-41c0c47069ee", "d23fb76f-620b-4bea-8a8b-5ba9c17ba239", "d3f9c0df-ca03-48a8-9218-f1a3b55d1a26", "d4a17a82-f5f7-4d00-bc94-e6dd22d8706a", "d5abed0c-ac74-43fa-b19e-2870bf98a900", "dc950fc1-8e87-4c7a-a629-3b496d8da46a", "ebfd99c0-7140-419d-9abb-2f8c4cb83be6", "faaffaaa-cdb7-44b5-a02f-c464d6269e4f"], "title": "Review: Mobility management for IP-based next generation mobile networks: Review, challenge and perspective", "venue": "Journal of Network and Computer Applications", "year": 2012, "id": "d3db35d0-7cb6-4cef-871f-03677a0ac6a8"}
{"abstract": "This paper describes the results of a 5-year research programme into evaluating and improving the quality of data models. The theoretical base for this work was a data model quality management framework proposed by Moody and Shanks (In: P. Loucopolous (Ed.), Proceedings of the 13th International Conference on the Entity Relationship Approach, Manchester, England, December 14-17, 1994). A combination of field and laboratory research methods (action research, laboratory experiments and systems development) was used to empirically validate the framework. This paper describes how the framework was used to: (a) quality assure a data model in a large application development project (product quality); (b) reengineer application development processes to build quality into the data analysis process (process quality); (c) investigate differences between data models produced by experts and novices; (d) provide automated support for the evaluation process (the Data Model Quality Advisor). The results of the research have been used to refine and extend the framework, to the point that it is now a stable and mature approach.", "authors": ["Daniel L. Moody", "Graeme G. Shanks"], "n_citation": 259, "references": ["1c95d184-179f-44d1-88a8-5fab9e567e69", "24e9bdde-7412-4956-ada2-5c0c0bba29cd", "30b01eb1-7e9f-471a-9513-087edfc4d172", "3761a6c4-dbbc-4d54-aff8-372050a04f77", "3b56f498-fc46-4d95-9ac5-90af7a359b8a", "41de53c6-ae14-4507-80df-56c80dbaca18", "4f86ddba-d8ae-486f-a00e-1670a7c49d2e", "5690960f-ca5d-4ef2-8ffa-ffa1072a23a4", "6d05e6fe-a3af-4e09-a8c4-8789f6e24c73", "80fe8011-0010-420c-a3c0-4868693f0bce", "8b8804d5-a240-4134-bc87-01c6ac4b68c3", "8e6cd374-880c-4d8b-be09-f0f661d2106c", "940589ad-9cc9-4f76-8e6d-f3b3cd6c4263", "94584b62-bbde-42f3-9472-e7f1ac37fe50", "969e29d4-53a9-4a5c-9831-04e3efc6b2f7", "9a60f21f-ad8b-445b-988b-bacb3b2bf9e0", "b20f6ebd-ac7b-46c1-acb8-5f23b7c988b1", "c5fcf879-74d6-4520-83b4-43cfb9d5757d", "d169eecc-adbe-4278-b9e6-106aa543b0f7", "d9d2426a-2923-4819-9b33-9e5aa98f64bb", "e9e110f3-606a-4fd8-9363-1dd81efcab76", "ea87fc9c-898c-4ffb-8d7d-92badb554904", "f976f70a-0530-4cb7-a92d-49f795909f78", "fb57281f-10bf-4f6e-8c9d-c2a1b4075389"], "title": "Improving the quality of data models: empirical validation of a quality management framework", "venue": "Information Systems", "year": 2003, "id": "61486ad9-148b-405f-ba9a-671dd14a8bcd"}
{"authors": ["Michel Bidoit", "Marie-Claude Gaudel", "A. Mauboussin"], "n_citation": 50, "references": ["0db6766f-f5bd-4984-8efa-f6b7201531ea", "3221eeb4-59b4-4151-9429-856ce893925a", "811445e0-eff0-4aed-b11c-dce921bc1439", "9fbc8287-e572-480a-a131-2ab48760b0f7", "c8974d31-a1de-4a8f-ba50-fc9c143f393a", "dd206865-aa43-4c41-9d0d-52d114c99480", "e5bc97a9-2d39-44b0-8081-c3cf94f31a5f"], "title": "How to make algebraic specifications more understandable", "venue": "", "year": 1987, "id": "8034f297-2407-4857-94c7-9e59cfef9ff6"}
{"authors": ["Thomas Zimmerman"], "n_citation": 1074, "references": ["c26ca1b5-606e-4116-af63-7315bd45caf6"], "title": "Personal area networks: near-field intrabody communication", "venue": "Ibm Systems Journal", "year": 1996, "id": "75ae9f51-13ad-409c-9315-141fb4fcfcf4"}
{"abstract": "Simply being more organized will not make the reuse problem go away. The issues are technical, not managerial. The answers lie in object-oriented design.", "authors": ["Bertrand Meyer"], "n_citation": 487, "references": ["a3307bf0-7eb5-48f0-964d-fc2df9fb42be", "ab6b51b8-61ac-4e95-b5fa-e0c1b055ecb1"], "title": "Reusability: The Case for Object-Oriented Design", "venue": "IEEE Software", "year": 1987, "id": "c82b2c72-f485-4e8e-9a89-cf2f07a9a4d6"}
{"authors": ["Markus Stra\u00dfer", "Markus Schwehm"], "n_citation": 172, "references": ["1153fc31-d831-4eb2-8816-4423e60d89f5", "22dc34f7-bd6a-4f3f-822c-6fe8d6d2bf43", "32508b34-7eb3-4bb6-ab35-b31a73557b8f", "3d7c4f57-421b-4728-9cab-fd292dfe2f1f"], "title": "A Performance Model for Mobile Agent Systems.", "venue": "parallel and distributed processing techniques and applications", "year": 1997, "id": "8664d60b-41e7-4cbc-b5c8-410a497ae98a"}
{"abstract": "In this age of digital impersonation, biometric techniques are being used increasingly as a hedge against identity theft. The premise is that a biometric - a measurable physical characteristic or behavioral trait - is a more reliable indicator of identity than legacy systems such as passwords and PINs. There are three general ways to identify yourself to a computer system, based on what you know, what you have, or who you are. Biometrics belong to the \"who you are\" class and can be subdivided into behavioral and physiological approaches. Behavioral approaches include signature recognition, voice recognition, keystroke dynamics, and gait analysis. Physiological approaches include fingerprints; iris and retina scans; hand, finger, face, and ear geometry; hand vein and nail bed recognition; DNA; and palm prints. In this article, we focus on the two most popular biometric techniques: fingerprints and iris scans.", "authors": ["Alfred C. Weaver"], "n_citation": 252, "references": ["12f518f4-43cf-40aa-91d8-8b239ac18788", "179568d4-ac6d-49a7-92e0-fefd5373c53c", "1f839aa1-7808-45b9-b9bd-c22f08d9a46e", "3e26cbdc-4a20-438e-aac1-1bcb2205991d", "4043767f-122d-4f34-b81f-01c810d17e28", "49f1cd0a-9d2f-4d0f-b369-07f909042d51", "4c8220d6-4654-467f-82fe-2c099406f485", "4f3b5bd2-1178-43be-99e0-e81c286847f9", "62cc2e88-0884-4676-84e2-0daa40f0baaa", "67c004f6-c028-4c6f-bad1-e65dbfdddc1e", "75915e95-17bf-42ea-9983-885f0476dd10", "7b2367a4-50c3-4a3f-90df-011382e0769f", "7c931981-f219-486b-b6f8-719ccef22e5f", "7e8ad8bb-682c-4939-b23e-fe3aafdbd64a", "803af597-6e09-41c7-be51-e9eb7007ec20", "82ce9c27-f1b5-4e92-8508-e8b0c7c5819d", "976c4962-f8c9-40f1-8888-777f5199861d", "a6f1bac9-d33b-4ab6-aeb0-963ab92803d1", "b12ee550-9b61-4070-8c1f-c456d28b3f39", "b78f54f2-2244-4b4f-9905-174c8cb23a82", "be0a8dc9-e1d6-4352-a67c-3fc9b9ad6e02", "c356dd36-b3d0-4d26-a0d7-412c232d4cf7", "c622713e-00d9-44d3-8ae9-c89cf30b86eb", "c8121c73-83d3-4159-90bb-01c8c9c8779e", "cdefa654-2b5c-40a5-8ea4-272c0c5251dc", "d1dd0266-07e6-4541-83a2-3349cd0175e4", "e227f723-650b-4b40-984b-2ee38d205a94", "e84c7452-3e18-4597-ae26-49d8ff7551bb", "f3db1a91-06c8-4414-8d52-717106dfdfb1", "faf6da43-12ac-4f81-8d78-3bab2d92cc98"], "title": "Biometric authentication", "venue": "IEEE Computer", "year": 2006, "id": "267c333e-61a8-46e4-8ef0-b4f502c50735"}
{"abstract": "The relation between the requirements specification and the design has been widely investigated with the aim to bridge the gap between the two artifacts. The goal is to find effective mechanisms to generate the system design starting from the analysis and specification of the requirements. This paper contributes to this research stream with an approach to create early design models from requirement artifacts. The approach weaves together the analysis and design phases favoring a tight collaboration between analysts and designers. It is based on Problem Frames, decomposition and re-composition patterns and supported by the System Modeling Language. The proposed solution has the potentiality of easing the development, shortening the development cycle and reducing the associated cost. The proposed design generation guidelines have been implemented as ATLAS Transformation Language rules in a model-based transformation process. The entire approach is model driven, allowing for the generation of the design model through transformations applied to the requirements model. The design model is automatically generated through the application of the transformation rules described in the paper. The proposed rules are fairly general and can be applied to any analysis model built according to the proposed analysis guidelines. The transformation process can be easily re-implemented using any suitable modeling tool that includes the ATLAS Transformation Language interpretation engine.", "authors": ["Pietro Colombo", "Ferhat Khendek", "Luigi Lavazza"], "n_citation": 12, "references": ["02efb630-6dec-43b0-831c-a704bf3953db", "04d92d9a-d88c-4e70-b239-78456cdfe4fd", "07732fec-7b31-442f-b79c-346f52107428", "0909a28a-6a32-490b-84e6-148fc65ad108", "0d261b6a-c94a-4d5e-b44e-eb6ae46581fc", "10e7f555-0a04-4b0b-8b55-d2c0900df444", "2c65e67d-e7d4-4403-819c-910776e5310a", "34681e35-f6a9-4f56-88ed-94b4783a9a4e", "36fa078d-fb30-4419-ba98-d1bd3dcbf319", "374720f5-35ca-451b-a4c1-7674d33b0121", "4f0a6bcf-3188-4b59-8e73-d6ff03b615af", "66da3f29-8b45-4dc6-baa4-8e1a05df8807", "6c1c1d90-1c48-442a-9665-840fe2da0a48", "7ff14a04-d26d-4c9f-8afd-a0d50cc50fac", "9415bc3a-aaed-4fd1-a5cc-d41be4218962", "9cee608b-8c28-403c-bcb4-aec0f595a952", "b38d0472-3ef2-4aa9-a5d5-b7c89299ab62", "c79e40d3-f620-426c-a119-4ff082349c93", "dfa289ce-4011-48fd-ad4c-82b46efd44be"], "title": "Bridging the gap between requirements and design: An approach based on Problem Frames and SysML", "venue": "Journal of Systems and Software", "year": 2012, "id": "65840712-5196-4dbf-8b48-3d25a70cdeeb"}
{"authors": ["Melvin Fitting"], "n_citation": 129, "references": ["09c19ddd-b0a4-477d-bc0b-025882bca35a", "1230592d-e2ad-49fe-a050-f4dbed461817", "2c763af0-dbcb-44ae-a9da-132dd456ddc7", "3ef04644-ad5e-4085-8579-59288a2d4db7", "3f76eb00-3cb3-4e78-9c01-f7c56ebe309f", "4a41abc2-f115-41aa-8dc9-6af04dc2735d", "4d996c8b-b144-410a-a8c5-97e6ec25b289", "59442d4f-e128-4803-bd71-3ad02a79f5d2", "5a568ce9-f7db-4f4c-a604-094cb719e5b4", "5c8fa7cc-9ead-444f-8c8c-3f9f471e430e", "72377be5-7b7c-4b9a-a89c-667b9c9589d3", "7bff8f61-7ff6-4c87-9e25-5b5410f31027", "9f80a041-d5ed-4f55-8d58-888bea30cbb6", "ad48d181-a78c-4cfb-9e1f-01d2d7377467", "b2c7648f-135e-4fdf-920b-954f7b03bb5b", "cc418fe3-8d27-44d8-a770-8f6d5aca956e", "d0a5e3fd-fa5e-47f8-9a31-046534b50665", "e22908da-10e5-49ec-93ed-2d7b1e1e8da3", "fc5e77b6-d149-4c56-b11f-5aa8bbe65a94"], "title": "The family of stable models", "venue": "Journal of Logic Programming", "year": 1993, "id": "1e53ae81-41aa-42ac-9265-488c647b2f07"}
{"abstract": "We have designed, implemented and evaluated an end-to-end system spellchecking and autocorrection system that does not require any manually annotated training data. The World Wide Web is used as a large noisy corpus from which we infer knowledge about misspellings and word usage. This is used to build an error model and an n-gram language model. A small secondary set of news texts with artificially inserted misspellings are used to tune confidence classifiers. Because no manual annotation is required, our system can easily be instantiated for new languages. When evaluated on human typed data with real misspellings in English and German, our web-based systems outperform baselines which use candidate corrections based on hand-curated dictionaries. Our system achieves 3.8% total error rate in English. We show similar improvements in preliminary results on artificial data for Russian and Arabic.", "authors": ["Casey Whitelaw", "Ben Hutchinson", "Grace Y. Chung", "Gerard Ellis"], "n_citation": 109, "references": ["10b46196-2b40-45f6-8c27-89ac24eec0ac", "18a074b8-8b62-4707-87f1-a974f37ae88f", "2ef8d7bb-3451-49fe-ba1d-70dc6a9786ab", "4ec4d5ac-4cfd-4ed4-a19a-d78f217fc279", "51590c0d-d3ce-4fb1-95f8-179f47540dbf", "5c5e34fe-2b36-4244-8a6e-08ec3d5ec8e0", "6772d645-847c-49b5-99ba-1182524f80bf", "a2530144-b6fd-4659-84f5-73a470275dd4", "b6f96238-c356-49c9-9638-53e39931954c", "c54f1011-f031-4551-92d6-bc2a4034f55c", "c8323642-f362-4ef3-bcc6-7ed07536c658", "d072f2dd-6600-4b6a-930d-e22c1edb54f3", "d713277b-9518-4cf9-8ca0-0acbb55e13f0", "fc6e584e-351a-4148-84f8-5845077c1e41"], "title": "Using the Web for Language Independent Spellchecking and Autocorrection", "venue": "empirical methods in natural language processing", "year": 2009, "id": "ba9b0152-142a-4b8f-b6c3-36d64f99b96e"}
{"authors": ["M.J. van Kreveld", "Iris Reinbacher", "Avi Arampatzis", "R. van Zwol"], "n_citation": 22, "references": ["03648d82-c68e-43e1-956a-79c5bfaca10f", "1f4baf99-e32d-4934-8b67-3225f9a58715", "4263ad67-f662-41bc-8856-169532af4f61", "8a241aa9-efd5-4ad4-9dcf-8116edb1e349", "9911f58c-d90b-4054-9c8d-a1c63e3599e9", "b546dd1a-7e2d-4527-ba3c-2e6ce5e0a405", "bd1c02f3-6c41-4502-b560-b430773d9b87", "bda45c60-bb84-42d0-b227-da383ddd68bb", "c0e17cf1-8b04-41f7-b2ce-a4beb26e7dc0", "e8325d31-dfb0-467c-a56e-48a95eeea2c0", "f0995081-d768-419c-8745-f4ace27e9608"], "title": "Distributed Ranking Methods for Geographic Information Retrieval", "venue": "european workshop on computational geometry", "year": 2004, "id": "bcf07251-2edc-474c-baab-98e3d70da25d"}
{"abstract": "An emergent class of web applications blurs the boundary between single user application and online public space. Recently popular web applications like del.icio.us help manage information traditionally kept on personal machines, while allowing for sharing with the community at large. An analysis of del.icio.us, a web-based bookmarks manager, shows that users who perceive greater degrees of social presence are more likely to annotate their bookmarks with information that could facilitate the sharing and discovery of bookmarks for other del.icio.us users. The design principles of del.icio.us and similar systems along with the findings of the present analysis reveal useful implications for the design of information sharing systems and knowledge repositories.", "authors": ["Kathy J. Lee"], "n_citation": 33, "references": ["17fbbb03-8b91-4ea6-af29-9fc8fd1f4364", "919fe77c-eef7-412a-a7cf-e19c70b249fa", "c000f664-8505-4bdd-bab9-2a1ef52e52a7"], "title": "What goes around comes around: an analysis of del.icio.us as social space", "venue": "conference on computer supported cooperative work", "year": 2006, "id": "ac91d9f8-f4c6-485f-80c1-bcf1fd802cb0"}
{"abstract": "In this paper, the multiagent coordination problem is studied. This problem is addressed for a class of robots for which control Lyapunov functions can be found. The main result is a suite of theorems about formation maintenance, task completion time, and formation velocity. It is also shown how to moderate the requirement that, for each individual robot, there exists a control Lyapunov function. An example is provided that illustrates the soundness of the method.", "authors": ["Petter \u00d6gren", "Magnus Egerstedt", "Xiaoming Hu"], "n_citation": 324, "references": ["05dc7361-18e9-42d3-8948-f49f7017a3ef", "435d486d-ddea-4938-8bc4-297067c11dda", "4e86ab99-7537-44aa-8446-f256922c934d", "85e69023-a620-4e24-9a19-0791b8b33b11"], "title": "A control Lyapunov function approach to multiagent coordination", "venue": "international conference on robotics and automation", "year": 2002, "id": "ee265d03-1a69-4425-b248-bd68bc9ed6e0"}
{"abstract": "An innate characteristic of the development of ontologies is that they are often created by independent groups of expertise, which generates the necessity of merging and aligning ontologies covering over- lapping domains. However, a central issue in the merging process is the evaluation of the differences between two ontologies, viz. the establish- ment of a similarity measure between their concepts. Many algorithms and tools have been proposed for merging of ontologies, but the major- ity of them disregard the structural properties of the source ontologies, focusing mostly on syntactic analysis. This article focuses on the align- ment of ontologies through Formal Concept Analysis, a data analysis technique founded on lattice theory, and on the use of similarity mea- sures to identify cross-ontology related concepts.", "authors": ["Kleber Xavier Sampaio de Souza", "Joseph G. Davis"], "n_citation": 45, "references": ["2fa89208-874a-4fb9-9386-b6a366913fab", "67a6c092-2038-44d4-81a8-e026bb696c60", "730f2812-48ba-47ce-a85a-be2518c927a4", "7a5c3c34-e108-4525-9a94-74e5bd1e10b1", "87866b76-cdd0-4473-85e9-3061088bbfef", "892d5d27-8e30-4ab2-b157-3eb1639e2a1d", "b0d313be-bd63-4b35-a3ac-4b1298b6a46f", "c1619b0d-323a-45c0-aad6-9e3161163492", "cb3a2ecd-8bdb-4900-b08f-3fa2627a9e1a", "ef3b30a6-5e79-4e5f-9e00-c62bf80e0dee", "f76afbb8-98f7-4c1c-89a8-619a6c724509"], "title": "Aligning Ontologies and Evaluating Concept Similarities", "venue": "cooperative information systems", "year": 2004, "id": "bf62bf57-6247-41ed-85bd-d84cbb965bff"}
{"abstract": "This paper proposes a solution based on forward error recovery, oriented towards providing dependability of composite Web services. While exploiting their possible support for fault tolerance (e.g., transactional support at the level of each service), the proposed solution has no impact on the autonomy of the individual Web services, our solution lies in system structuring in terms of co-operative atomic actions that have a well-defined behavior, both in the absence and in the presence of service failures. More specifically, we define the notion of Web Service Composition Action (WSCA), based on the Coordinated Atomic Action concept, which allows structuring composite Web services in terms of dependable actions. Fault tolerance can then be obtained as an emergent property of the aggregation of several potentially non-dependable services. We further introduce a framework enabling the development of composite Web services based on WSCAs, consisting of an XML-based language for the specification of WSCAs.", "authors": ["Val\u00e9rie Issarny", "Ferda Tartanoglu", "Alexander Romanovsky", "Nicole Levy"], "n_citation": 119, "references": ["32d1330f-04d0-4670-aaa8-2d6f7f476eb3", "47d0e8d9-79e9-4584-bffb-35937bcd29d3", "91bd5bed-21b6-4344-a446-917b483f5827", "aba105e3-ffd5-43c0-8b55-e658e8d0a591", "bdbbf916-3baa-4de9-a5a1-6934ab1cbf4c", "d3df0c36-fe01-4297-afe4-a4dcd847d3d6", "e176f645-79c2-4346-8964-828eb5a4017c", "e25ada62-be77-4729-b950-83ecdbdf8d49", "f08a1ef2-a6ca-4057-bd31-a71b10e6630b"], "title": "Coordinated forward error recovery for composite Web services", "venue": "symposium on reliable distributed systems", "year": 2003, "id": "68174169-acbe-4c78-9dfe-7f82192c85c3"}
{"abstract": "The design of algorithms that explore multiple representation languages and explore different search spaces has an intuitive appeal. In the context of classification problems, algorithms that generate multivariate trees are able to explore multiple representation languages by using decision tests based on a combination of attributes. The same applies to model trees algorithms, in regression domains, but using linear models at leaf nodes. In this paper we study where to use combinations of attributes in regression and classification tree learning. We present an algorithm for multivariate tree learning that combines a univariate decision tree with a linear function by means of constructive induction. This algorithm is able to use decision nodes with multivariate tests, and leaf nodes that make predictions using linear functions. Multivariate decision nodes are built when growing the tree, while functional leaves are built when pruning the tree. The algorithm has been implemented both for classification problems and regression problems. The experimental evaluation shows that our algorithm has clear advantages with respect to the generalization ability when compared against its components, two simplified versions, and competes well against the state-of-the-art in multivariate regression and classification trees.", "authors": ["Jo\u00e3o Gama"], "n_citation": 172, "references": ["01cf82c6-1ffc-4ab6-acbd-32168856bcb8", "03c65362-4803-46af-b539-1d2e3519e000", "2ed02b36-2c89-43e4-a0d7-b5e01a16d8ae", "473308a4-a098-4eae-8bbf-8c30bc7701a4", "4bd85613-9015-4603-a9b2-3ae9bd153780", "9d391f89-9fbd-438a-bbba-57f8fe085e0c", "bd1f5543-addf-4db6-b6f1-9fb3edeeb1d4", "c3addfce-21af-41b6-af69-d4423095e921"], "title": "Functional Trees", "venue": "discovery science", "year": 2001, "id": "8ed6c561-0706-4724-b0f3-bbce686ec3c6"}
{"abstract": "1. Introduction.- I. Constraint Programming.- 2. Algorithm = Logic + Control.- 3. Preliminaries of Syntax and Semantics.- 4. Logic Programming.- 5. Constraint Logic Programming.- 6. Concurrent Constraint Logic Programming.- 7. Constraint Handling Rules.- II. Constraint Systems.- 8. Constraint Systems and Constraint Solvers.- 9. Boolean Algebra B.- 10. Rational Trees RT.- 11. Linear Polynomial Equations R.- 12. Finite Domains FD.- 13. Non-linear Equations I.- III. Applications.- 14. Market Overview.- 15. Optimal Sender Placement for Wireless Communication.- 16. The Munich Rent Advisor.- 17. University Course Timetabling.- IV. Appendix.- A. Foundations from Logic.- A.1 First-Order Logic: Syntax and Semantics.- A.2 Basic Calculi and Normal Forms.- A.2.1 Substitutions.- A.2.2 Negation Normal Form and Prenex Form.- A.2.3 Skolemization.- A.2.4 Clauses.- A.2.5 Resolution.- List of Figures.- References.", "authors": ["Thom Fruewirth", "Slim Abdennadher"], "n_citation": 267, "title": "Essentials of Constraint Programming", "venue": "", "year": 2003, "id": "46d87e14-1ac6-4bf3-b160-daa7874e369f"}
{"abstract": "Vision systems that have successfully supported nontrivial tasks have invariably taken advantage of constraints derived from the task and environment to increase reliability and lower the complexity of perception. We propose that it is possible to build a general purpose vision system, that is, one that can support a wide variety of tasks, and take advantage of such constraints. The central idea within our proposed architecture is the reactive skill. Skills are concurrent control routines assembled at run time using instructions from a symbolic execution system. Visual modules are used as resources in the construction of these skills. Skills control the agent as continuous feedback loops but are constructed using discrete, symbolic instructions. The key to general-purpose vision is the ability to parametrize the primitive elements of the vision system and to compose visual and control routines in a variety of ways. We demonstrate the architecture in the context of an implemented example task of a robot collecting trash off a floor and depositing it in a garbage can.", "authors": ["R. James Firby", "Roger E. Kahn", "Peter N. Prokopowicz", "Michael J. Swain"], "n_citation": 91, "references": ["02a46801-c4d8-42cc-9361-7e77e983157d", "0315de88-d8c3-479b-a022-9a8e5f08ff59", "079090cb-9ba8-419b-845c-7cccb6039da3", "1fb3e817-8a70-4d41-a13c-ce01f77b6d1e", "9dc1f371-a985-4a08-a612-9b6fd679eceb", "f86167f6-9fd7-457b-be98-301b8a98a141", "fb952281-dcde-4f1c-a204-28b6434d11d7"], "title": "An architecture for vision and action", "venue": "international joint conference on artificial intelligence", "year": 1995, "id": "243cc944-267b-4475-85d1-49e0f8517b77"}
{"abstract": "Domain-specific generators will increasingly rely on graphical specification languages-applets-for declarative specifications of target applications. Applets will provide front-ends to generators and related tools to produce customized code on demand. Critical to the success of this approach will be domain-specific design wizards, tools that guide users in their selection of components for constructing particular applications. In this paper, we present the P3 ContainerStore applet, its generator and design wizard.", "authors": ["Don S. Batory", "Gang Chen", "Eric P. Robertson", "T.-M. Wang"], "n_citation": 50, "references": ["18386382-99fa-4eae-bf9e-4c4b07d6f802", "36ed50a5-a73e-41be-9060-de6c0ca9dce0", "3b468df8-f7f6-4769-9ba4-d4e1361f6d47", "3f25e07e-e420-4db4-87d6-d17e46ec65b1", "431fd4f4-7564-478f-8014-157c48123d7a", "5c6d7c3a-603c-4ad0-ad50-243e032e48fb", "6d8f9f73-2703-4142-93a2-2983e9b5f050", "710dfeb0-860a-43b7-a599-c8952ff7ab6c", "764548fe-1c42-4024-bbbb-e6fb2c873a62", "7eabc6ca-8c4b-46e4-b331-89058cae69da", "8e6de404-6e86-4d3b-8bf6-b7ec2394b0ff", "91dc9071-57cf-43ca-a85d-c019a8d076a6", "9c97d7ce-15b9-4044-8b9b-7b261dcc2415", "d897f49c-d25f-43cf-ab58-4facde92b539", "f148fff2-51b2-4915-9e95-d9ed29040f58", "f5606708-5fe2-4a2a-8f57-69f006d05f51", "fc7003f3-20c8-4f46-acbc-b95e151f9001"], "title": "Design wizards and visual programming environments for generators", "venue": "", "year": 1998, "id": "35335804-0138-4433-a35b-5bb33fa4f170"}
{"abstract": "This paper presents an on-the-fly and symbolic technique for efficiently checking timed automata emptiness. It is symbolic because it uses the simulation graph (instead of the region graph). It is on-the-fly because the simulation graph is generated during the test for emptiness. We have implemented a verification tool called Profounder based on this technique. To our knowledge, Profounder is the only available tool for checking emptiness of timed Buchi automata. To illustrate the practical interest of our approach, we show the performances of the tool on a non-trivial case study.", "authors": ["Stavros Tripakis", "Sergio Yovine", "Ahmed Bouajjani"], "n_citation": 92, "references": ["05187588-ada5-47d3-ab0d-a282be6fc447", "22c9d128-04ca-4534-b2f1-92ac6104a2b6", "2383e70b-0513-4e40-9719-a4c3eb46589c", "26de5fdd-1e16-44fc-a14e-020b82050cdd", "323c35ba-101b-46ad-9c44-315e6d7a4534", "342dc751-0033-4567-9aff-6dd8713105ec", "48978913-7441-4636-8352-75a7bc484d23", "5fd2c45b-9be0-4805-a635-c23a04cf1f66", "756b4570-813b-486f-b38a-b55b050065e7", "77897401-f388-47a7-b928-ca7c09b93526", "7cc4e717-e7e8-4397-ac85-21c76eee9c1c", "7d6d7735-2002-4067-a26f-5cf93aa590f1", "814ddbb3-620e-407a-a546-401d411a7024", "82afb34a-cb4f-42e2-9438-fe181fcd5445", "938a6c45-2d37-40de-ad35-75518f6cd042", "bb5f4e29-4ed5-4097-9702-cde7f2f4ffd9", "c1102d81-fb2c-4701-94c6-47feea928648", "cb3cec59-ff10-4070-bda4-b440614d59b7", "d0a7a105-adb7-49a9-b64f-b52aa00173f3", "f1289e28-b103-4a9b-8a3f-903d7e8f5c60", "f5f1b6cd-64e7-428f-bd7a-90c92ed50bde", "f996597b-a03f-41f0-93b8-cbc366754d21"], "title": "Checking Timed B\u00fcchi Automata Emptiness Efficiently", "venue": "formal methods", "year": 2005, "id": "7d0aacf2-c65e-4bec-a38e-2177b8fec842"}
{"abstract": "Given $n$ points in the plane, the degree-$K$ spanning-tree problem asks for a spanning tree of minimum weight in which the degree of each vertex is at most $K$. This paper addresses the problem of computing low-weight degree-$K$ spanning trees for $K>2$. It is shown that for an arbitrary collection of $n$ points in the plane, there exists a spanning tree of degree 3 whose weight is at most 1.5 times the weight of a minimum spanning tree. It is shown that there exists a spanning tree of degree 4 whose weight is at most 1.25 times the weight of a minimum spanning tree. These results solve open problems posed by Papadimitriou and Vazirani. Moreover, if a minimum spanning tree is given as part of the input, the trees can be computed in $O(n)$ time. #R##N#The results are generalized to points in higher dimensions. It is shown that for any $d \\ge 3$, an arbitrary collection of points in $\\Re^d$ contains a spanning tree of degree 3 whose weight is at most 5/3 times the weight of a minimum spanning tree. This is the first paper that achieves factors better than 2 for these problems.", "authors": ["Samir Khuller", "Balaji Raghavachari", "Neal E. Young"], "n_citation": 99, "title": "Low-Degree Spanning Trees of Small Weight", "venue": "SIAM Journal on Computing", "year": 1996, "id": "f03d4791-7e28-4e8f-8516-7315dde6caca"}
{"abstract": "To achieve high throughput rates today's computers perform several operations simultaneously. Not only are I/O operations performed concurrently with computing, but also, in multiprocessors, several computing operations are done concurrently. A major problem in the design of such a computing system is the connecting together of the various parts of the system (the I/O devices, memories, processing units, etc.) in such a way that all the required data transfers can be accommodated. One common scheme is a high-speed bus which is time-shared by the various parts; speed of available hardware limits this scheme. Another scheme is a cross-bar switch or matrix; limiting factors here are the amount of hardware (an m \u00d7 n matrix requires m \u00d7 n cross-points) and the fan-in and fan-out of the hardware.", "authors": ["Kenneth E. Batcher"], "n_citation": 2021, "title": "Sorting networks and their applications", "venue": "", "year": 1968, "id": "98db48cc-68f2-4464-ac90-a02fcfc37e48"}
{"abstract": "Self-organizing maps are popular algorithms for unsupervised learning and data visualization. Exploiting the link between vector quantization and mixture modeling, we derive expectation-maximization (EM) algorithms for self-organizing maps with and without missing values. We compare self-organizing maps with the elastic-net approach and explain why the former is better suited for the visualization of high-dimensional data. Several extensions and improvements are discussed. As an illustration we apply a self-organizing map based on a multinomial distribution to market basket analysis.", "authors": ["Tom Heskes"], "n_citation": 175, "references": ["0630dc36-6a9d-420e-bc57-752f3fbe25a7", "11ccee7f-099b-403a-b538-d70c29b30e15", "1691a31e-e9a3-4002-b78d-1190a45fbc3e", "64cfc2ca-62b4-4944-b8f4-6c3d10a875c9", "69df0789-a06f-4166-9c34-93047de2673d", "6ce645b9-765d-4660-9df1-5d6ac65040b5", "76606d3b-000a-4517-9ad5-b9bc479b53b0", "77f3d063-9bf6-4397-9825-5d8602512e0a", "89e37f3a-4cc8-417f-a6fd-ae8bdd492fda", "8a6a4c08-fdc8-49c4-8e73-23e7fdb466d6", "9eb4bb10-1cc7-478e-916f-04a072a87751", "ab5b7fdf-5cb1-4974-8b0a-b7dd238e1345", "d69ac865-0323-4a3d-92aa-a1aff7065add", "de28025b-6da0-4b5b-9fac-f0cde736641d", "e3f27652-688a-457b-ad96-07a7e3c05543"], "title": "Self-organizing maps, vector quantization, and mixture modeling", "venue": "IEEE Transactions on Neural Networks", "year": 2001, "id": "ab07d380-043e-472e-8542-f524561e1129"}
{"abstract": "This paper proposes an efficient indexing scheme for searching large iris biometric database that achieves invariance to similarity transformations, illumination and occlusion. The proposed scheme considers local descriptors as well as relative spatial configuration for claiming identity. To overcome the effect of non-uniform illumination and partial occlusion due to eyelids, local features are extracted from noise independent annular iris image using scale invariant feature transform (SIFT). The detected keypoints are used to index iris database by applying geometric hashing scheme that is robust to similarity transformations as well as occlusion. During iris retrieval, geometric hashed location from query iris image is obtained to access the appropriate bin of hash table and for every entry found there, a vote is casted. The iris images that receive more than certain number of votes are considered as possible candidates. In order to find the potential matches, the keypoint descriptor of the list of possible candidates is matched with the query iris. Since only small portion of database is scanned to find a match it reduces the query retrieval time and improves accuracy. This approach is tested on UBIRIS, BATH, CASIA and IITK iris databases and shows a substantial improvement over exhaustive search technique in terms of time and accuracy.", "authors": ["Hunny Mehrotra", "Banshidhar Majhi", "Phalguni Gupta"], "n_citation": 57, "references": ["11a01e81-de5d-4544-bb84-1804438ea49f", "180dea34-18e8-411d-932f-94e714651ac7", "2958fc5c-15e8-45e7-8da8-d2e0fa46f0c7", "3e259f16-b05f-442e-a7d7-30c581e580d0", "3ed30dc3-52d9-4ff4-9975-cb1f393813bb", "44cd76fd-7bd2-4d3d-91af-e277c408a995", "5c486db7-d3a5-407b-88ee-2308deab9033", "5f84f09f-7644-447c-89e1-8dc9ee334197", "775985ee-0869-4921-889e-250bdfc5f196", "784216e5-56e4-44ac-a1aa-90080d267c3b", "7bc16670-14c7-4095-981e-841eade83682", "857d32c8-6a21-4f09-98fe-fa346f57b847", "93351f78-1b4b-4a66-9489-db37265e2c8b", "9fd679f4-8989-436b-87a6-d09dbbbeeead", "a1915b16-7275-47cd-843e-b16a99efb708", "b944f77f-113b-4a02-ae5e-d4a124b8fd5b", "c426ee2a-90ca-4a1b-96ed-47a8cccc4882", "ce2216b8-9b47-4ed9-9067-5865b5defc88", "d2a8c3e1-bc17-46e5-b600-1b6bfe79b42e", "e5458fa1-b597-4fe3-9871-37157e42225e"], "title": "Robust iris indexing scheme using geometric hashing of SIFT keypoints", "venue": "Journal of Network and Computer Applications", "year": 2010, "id": "449b48ff-626d-48c4-a617-1ea07238dcef"}
{"abstract": "The development of successful case-based design aids depends both on the CBR processes themselves and on crucial questions of integrating the CBR system into the larger task context: how to make the CBR component provide information at the right time and in the right form, how to access relevant information from additional information sources to supplement the case library, how to capture information for use downstream and how to unobtrusively acquire new cases. This paper presents a set of design principles and techniques that integrate methods from CBR and information retrieval to address these questions. The paper illustrates their application through a case study of the Stamping Advisor, a tool to support feasibility analysis for stamped metal automotive parts.", "authors": ["David B. Leake", "Lawrence Birnbaum", "Kristian J. Hammond", "Cameron Marlow", "Hao Yang"], "n_citation": 50, "references": ["0e5a7cf0-701d-4acc-90f8-c9a9aabf1d2e", "28bd092b-5271-4773-bbdc-a514ed612a08", "817802c4-8083-42ab-8b41-6001588b5eb3", "e1eb7492-c795-424f-ac86-e5cd2745f70c", "ef3cfe55-9708-4d1a-9baa-901873cc1f26"], "title": "Integrating Information Resources: A Case Study of Engineering Design Support", "venue": "international conference on case based reasoning", "year": 1999, "id": "f81cd282-bb56-4e2b-809a-21323cc4264b"}
{"abstract": "We consider virtual partitioning (VP), which is a scheme for sharing a resource among several traffic classes in an efficient, fair, and robust manner. In the preliminary design stage, each traffic class is allocated a nominal capacity, which is based on expected offered traffic and required quality of service. During operations, if the current capacity usage by a class exceeds its nominal allocation, then it is declared to be in \"overload,\" and a state-dependent trunk reservation mechanism gives it lower priority in the admission of new calls. We develop efficient computational algorithms for the case of heterogeneous traffic, and perform extensive numerical experiments to demonstrate the accuracy of the various approximations. The performance of VP is examined and compared to that of complete sharing and complete partitioning. Particular weight is placed on robustness, meaning that traffic classes with arrival rates conforming to the design continue to receive the required quality of service, despite the presence of misbehaving classes with excessive arrival rates. We adopt a reward-penalty paradigm as a combined measure for efficiency and fairness, and show that not only is the revenue generated by VP extremely close to the maximum achievable value, but that the structural form of the optimal policy also closely resembles that of VP. The numerical results confirm that the scheme is efficient, fair, and very robust.", "authors": ["Simon C. Borst", "Debasis Mitra"], "n_citation": 114, "references": ["18045fc6-78d5-4dac-bfb8-11f21c0f8638", "585dc888-d394-4b4d-9c0e-57f6bf0f835a", "62358912-57e1-473a-aa08-fc7cedf391d6", "827d2528-3dbf-4f6e-a85b-c04509347e62"], "title": "Virtual partitioning for robust resource sharing: computational techniques for heterogeneous traffic", "venue": "IEEE Journal on Selected Areas in Communications", "year": 1998, "id": "6f7d082a-7fc4-4807-b43a-1895de306833"}
{"abstract": "A resistive memory network that has no crossover wiring is proposed to overcome the hardware limitations to size and functional complexity that is associated with conventional analogue neural networks. The proposed memory network is based on simple network cells that are arranged in a hierarchical modular architecture. Cognitive functionality of this network is demonstrated by an example of character recognition. The network is trained by an evolutionary process to completely recognise characters deformed by random noise, rotation, scaling and shifting.", "authors": ["Alex Pappachen James", "Sima Dimitrijev"], "n_citation": 50, "references": ["26df4f22-d291-401e-ba25-0f015cd3a754", "cb729f63-f5bb-458c-bafe-2795ae206341"], "title": "Cognitive memory network", "venue": "Electronics Letters", "year": 2010, "id": "f5395ebd-7146-4351-9304-2fc6d2214168"}
{"abstract": "Privacy of personal location information is becoming an increasingly important issue. We refine a method, called the mix zone, developed to enhance user privacy in location-based services. We improve the mathematical model, examine and minimise computational complexity and develop a method of providing feedback to users.", "authors": ["Alastair R. Beresford", "Frank Stajano"], "n_citation": 510, "references": ["4758c16a-cbb4-4269-963c-90e435a5cc9f", "7f4ffc09-0fc9-4ad5-be8e-aaea47755c50", "b4ca9e3f-d878-430d-a354-aa1731291b73", "e1f6913d-2d77-47e9-8f14-a78a746a7642"], "title": "Mix zones: user privacy in location-aware services", "venue": "ieee international conference on pervasive computing and communications", "year": 2004, "id": "6836076e-1019-46fa-9f9a-b8c3cc4e812f"}
{"abstract": "By the term 'professional end user developers' we mean people such as research scientists who work in highly technical, knowledge-rich domains and who develop software in order to further their professional goals. In common with other end user developers, professional end user developers do not describe themselves as software engineers and have no formal training in software engineering. They differ from most other end user developers, however, in that learning programming languages rarely presents them with any problem. In this paper, drawing on data from field studies of different groups of professional end users, we examine the problems that such people face in meeting the demands of software development given the culture in which they work and their normal development practice. Understanding these problems is an essential prerequisite to developing tools, techniques etcetera to support professional end user development.", "authors": ["Judith Segal"], "n_citation": 41, "references": ["144b94f5-32c0-469b-9e34-da8d46330825", "17b96fcb-ff29-4e1c-b289-e95f291b1f54", "1dff0894-ca58-42de-bad8-955da57632d3", "47f7e054-6a0f-4643-90fc-c0e3cc7050ef", "59501400-312d-43f7-8dc2-116f24fdb352", "78e92935-3d8b-4156-b211-54f58a34e692", "8922eb75-7a2b-4bfa-b360-0d3fdd5c8b92", "ae2b1e4d-3f20-460a-b2c1-21a05ae80c56", "f8046e47-744d-4737-b2ae-b5388af3054a"], "title": "Some Problems of Professional End User Developers", "venue": "", "year": 2007, "id": "72789d56-e4d7-4db6-9c2a-e57a9479cb47"}
{"abstract": "SUMMARY Systematic design testing, in which executable models of behaviours are tested using inputs that exercise scenarios, can help reveal flaws in designs before they are implemented in code. In this paper a technique for testing executable forms of UML (Unified Modelling Language) models is described and test adequacy criteria based on UML model elements are proposed. The criteria can be used to define test objectives for UML designs. The UML design test criteria are based on the same premise underlying code test criteria: coverage of relevant building blocks of models is highly likely to uncover faults. The test adequacy criteria proposed in this paper are based on building blocks for UML class and interaction diagrams. Class diagram criteria are used to determine the object configurations on which tests are run, while interaction diagram criteria are used to determine the sequences of messages that should be tested. Copyright c 2003 John Wiley & Sons, Ltd.", "authors": ["Anneliese Amschler Andrews", "Robert B. France", "Sudipto Ghosh", "Gerald Craig"], "n_citation": 182, "references": ["06e5c898-bf44-4b6e-9e4a-1b2bb1930f29", "14df238b-c2b9-4ef3-b92c-e10389326439", "5b087deb-dc0e-49e0-96b9-c2f79ccefb01", "5edf8e80-e11f-4ddc-8051-23ec0b49c6a9", "7865e2fe-028f-4871-84f0-3f471b7d1cd8", "98ea78dc-4ed1-4c9a-b560-6108053b7e4d", "9f919569-bb11-498d-a0b0-fd1ffda2918f", "a02d7385-b5ae-4714-9d2e-550ee224cd3f", "b20594db-14f2-427f-9986-b6159bd21ac7", "bac1950b-5604-4553-972a-19bf54df2cd7", "db680839-374a-45a2-ba65-31590b859464", "e6b37806-0ffc-4a1a-9f87-a6749a4d1ebb", "ee8e6e24-9815-49cc-a1c2-185818a1bdab"], "title": "Test adequacy criteria for UML design models", "venue": "Software Testing, Verification & Reliability", "year": 2003, "id": "f9a374d6-df63-4e4f-8f60-edb57540d00a"}
{"abstract": "The class of non-Horn, function-free databases is investigated and several aspects of the problem of using theorem proving techniques for such databases are considered. This includes exploring the treatment of negative information and extending the existing method, suggested by Minker, to accept non-unit negative clauses. It is shown that the algorithms based on the existing methods for the treatment of negative information can be highly inefficient. An alternative approach is suggested and a simpler algorithm based on it is given. The problems associated with query answering in non-Horn databases are addressed and compared with those for the Horn case. It is shown that the query evaluation process can be computationaly difficult in the general case. Conditions under which the process is simplified are discussed. The topic of non-Horn general laws is considered and some guidelines are suggested to divide such laws into derivation rules and integrity constraints. The effect of such a division on the query evaluation process is discussed.", "authors": ["Adnan H. Yahya", "Lawrence J. Henschen"], "n_citation": 176, "references": ["0ddf76fa-53bb-4506-bbee-ceba26e2ef8b", "2c763af0-dbcb-44ae-a9da-132dd456ddc7", "37a0bc0a-0b3d-481c-8459-02c8c6931bef", "4c9a7f28-6ea9-4d6c-a7db-88585cd0b54b", "ba35be38-02bc-4218-af09-c8b38fbd22b7"], "title": "Deduction in non-Horn databases", "venue": "Journal of Automated Reasoning", "year": 1985, "id": "b86ff135-5f40-483d-9d85-62e21878b5e4"}
{"abstract": "Underwater acoustic sensor networks are quite different from terrestrial wireless sensor networks. Localization for underwater applications is different due to the bandwidth limited acoustic communication, sparsely distributed network deployment, and more expensive and powerful sensor nodes. In this paper, we propose a new scheme to achieve better localization accuracy for underwater acoustic sensor networks. Instead of using the commonly adopted circle-based event detection and least squares algorithm based location estimation, the proposed scheme utilizes the hyperbola-based approach for event localization and a normal distribution for estimation error modeling and calibration. Our analysis and simulation results indicate that the performance of the proposed scheme is clearly better than those from the least squares location estimation based localization schemes.", "authors": ["Tao Bian", "Ramachandran Venkatesan", "Cheng Li"], "n_citation": 50, "references": ["0b03064a-bc50-406a-9b86-be833c3620d8", "114060ec-4c95-4a1b-8aa8-a2f0b0b0aa8f", "1579f0f1-9dea-4a4f-9456-834056b3afa5", "4537c552-baa1-45ff-a0ca-954995b56e7e", "508464ea-4685-46f0-9da4-63ce90a440a5", "51df5b81-95c2-4929-8d78-24a52ccec37f", "6825e7be-db72-4377-a599-6667ef0bd553", "6f3c6b9c-4b5f-4320-ac88-a02b4f312f19", "72794138-71c9-4d28-b947-e6dd30a72388", "7e8163f2-34a7-4316-bc79-3d9189ce15ec", "8ceb22cd-3aaf-4f1a-8828-78ff5aa24ad4", "9efda63c-320d-46b0-8a7b-175012a2936f", "b3d38c4e-534f-48e1-a66d-1c1d9bbc4432", "f7059804-a6ee-4c6f-bb87-a858e90262b1"], "title": "Design and Evaluation of a New Localization Scheme for Underwater Acoustic Sensor Networks", "venue": "global communications conference", "year": 2009, "id": "8cb66f5d-b0e4-4262-9925-c4fe9268efd1"}
{"abstract": "Compilers sometimes generate correct sequential code but break the concurrency memory model of the programming language: these subtle compiler bugs are observable only when the miscompiled functions interact with concurrent contexts, making them particularly hard to detect. In this work we design a strategy to reduce the hard problem of hunting concurrency compiler bugs to differential testing of sequential code and build a tool that puts this strategy to work. Our first contribution is a theory of sound optimisations in the C11/C++11 memory model, covering most of the optimisations we have observed in real compilers and validating the claim that common compiler optimisations are sound in the C11/C++11 memory model. Our second contribution is to show how, building on this theory, concurrency compiler bugs can be identified by comparing the memory trace of compiled code against a reference memory trace for the source code. Our tool identified several mistaken write introductions and other unexpected behaviours in the latest release of the gcc compiler.", "authors": ["Robin Morisset", "Pankaj Pawan", "Francesco Zappa Nardelli"], "n_citation": 50, "references": ["03b31f60-3f6d-45ca-bf30-fc1d0eac496e", "09917ab1-62f0-419d-b0cf-5ee82457f15a", "33c32b5c-ee15-4346-a135-e67478b93b11", "6d1d7ace-3aa6-4d4a-906e-78eb9703e046", "78f14868-31f5-4122-90c0-889b00bba24a", "79e65c38-4c95-4fe5-9917-80749ea10976", "824bdcf9-0415-4d86-b93f-3789fd2d053c", "8dc99aaa-2dab-4d0d-bd87-666981376da8", "9353512f-fdd2-4d0c-b237-86798657d977", "99f31255-f831-4d37-a3cd-fffd56c818d3", "9e17ca08-423e-4a93-ad66-ed8e0db2ef8f", "bd8ee8a8-0dce-4cbf-9908-c4c42fafe5d4", "bf35b50a-762b-40f9-90e6-fe19daad008c", "c9314031-43dc-4861-9b82-507194c659cf", "e2dc5dce-f6b2-4418-99e4-bfb84205cdfb", "ee67921c-8962-422c-b7e2-865d80e3fec4", "fe6a73d0-0f2c-4e56-a415-9c063393999b"], "title": "Compiler testing via a theory of sound optimisations in the C11/C++11 memory model", "venue": "programming language design and implementation", "year": 2013, "id": "e52b97fc-83e4-4f42-91da-665becd5d4a8"}
{"abstract": "How can micro-blogging activities on Twitter be leveraged for user modeling and personalization? In this paper we investigate this question and introduce a framework for user modeling on Twitter which enriches the semantics of Twitter messages (tweets) and identifies topics and entities (e.g. persons, events, products) mentioned in tweets. We analyze how strategies for constructing hashtag-based, entity-based or topic-based user profiles benefit from semantic enrichment and explore the temporal dynamics of those profiles. We further measure and compare the performance of the user modeling strategies in context of a personalized news recommendation system. Our results reveal how semantic enrichment enhances the variety and quality of the generated user profiles. Further, we see how the different user modeling strategies impact personalization and discover that the consideration of temporal profile patterns can improve recommendation quality.", "authors": ["Fabian Abel", "Qi Gao", "Geert-Jan Houben", "Ke Tao"], "n_citation": 343, "references": ["12b5f05e-19e3-42ba-82e5-030ad311e3ae", "23d1b731-a119-4ce7-90e6-392a038373be", "60798bc3-51e5-41b8-8276-4afaa47fd0d3", "6b726561-c9f1-4b28-b99a-ef27867d0965", "ab3c771c-9d22-41ff-b7e7-e71cecdd7a0a", "b112d246-add3-409a-9a09-03d4ef07ef00", "bff7828e-8d95-4e45-87c0-e420272ceb41", "da773e14-5247-4600-8da8-2452699899d9", "e268c20a-da6e-4708-bf8e-583dc013aae2", "edc9ac42-597c-425f-aa22-54012cd32d7d", "ef7d7dff-ffac-4ddf-9434-62d54218cc4d"], "title": "Analyzing user modeling on twitter for personalized news recommendations", "venue": "", "year": 2011, "id": "6bebd8b1-bf91-4c41-bf5b-d81b944e82d4"}
{"abstract": "It is widely acknowledged in the HCI community that much can be gained from bringing aspects from the field into the lab, and this principle is dominating within usability groups in Danish Industry. The paper describes three such Danish usability groups and their experiments with turning the tables by using aspects from the lab in the methods applied in the field during field work projects. The context of use plays an important role for a richer understanding of the usability of particular products. As such, implications of this is not surprising, neither theoretically nor empirically. What is interesting, however, is how findings of this type are instantiated in the particular cases; how the three usability groups have used the lab approaches to aid them in working in the field and how the new methods may enhance their existing methodological toolkit. The message of the paper is that there are a variety of ways in which the theoretically driven, pre-planned, and predirected may meet the situated and open minded, both when usability work is conducted in the field and in the lab.", "authors": ["Christina Nielsen"], "n_citation": 50, "references": ["23a6b32a-4094-4dd6-a232-79604c747ace", "3d62d2fb-cd0e-4820-ae2b-d87c06b2ad12", "5408bafe-7744-4aef-897b-3a59be4920f6", "7cf818cb-9a04-4a29-a3d3-e8e7d150cb09"], "title": "Testing in the field", "venue": "asia pacific computer and human interaction", "year": 1998, "id": "8469b511-5d76-4010-b5bc-251f928582be"}
{"abstract": "Initial system specifications, such as use-case scenarios and properties, only partially specify the future system. We posit that synthesizing partial component-level behavior models from these early specifications can improve software development practices. In this paper, we provide a novel algorithm for deriving a Modal Transition System (MTS) for individual system components from system-level scenario and property specifications. The generated MTSs capture the possible component implementations that (1) necessarily provide the behavior required by the scenarios, (2) restrict behavior forbidden by the properties, and (3) leave the behavior that is neither explicitly required nor forbidden as undefined. We also show how our algorithm helps to discover potential design flaws.", "authors": ["Ivo Krka", "Yuriy Brun", "George Edwards", "Nenad Medvidovic"], "n_citation": 48, "references": ["15a2d332-783d-4a0e-900c-faadda3c080c", "1eaee7f5-ff41-4111-83ea-d0128c85dfe6", "2d89c9b9-0744-4b0b-9cee-d6c294871ce4", "3023929a-c93e-49c5-b03f-7fb0414d94df", "35f43c7b-a3ed-4dec-b519-0137daf11936", "4dc40f3c-6018-4b56-9740-dce8c270331b", "5d58db83-a1f9-4a94-a617-e14d0bb142db", "62fb3e25-0569-4641-a40d-59d2ff00f278", "698fb75d-9711-41db-83db-caf2bfdcb4d8", "8441111e-b7fb-497f-a359-06afd07b92df", "8915cffe-4ff0-45b2-9d7e-476b39fd57b3", "af441cc5-1428-4eed-be6a-aefdd6246676", "b782bd93-bc3b-4672-bbae-60da52e3c7fd", "ceaa0454-19eb-4173-9aa8-7615fd775afd", "d47c7ca7-d286-4967-a9ad-475da9e23908", "e6420626-dd31-4e33-ab3e-7781aeb3673a"], "title": "Synthesizing partial component-level behavior models from system specifications", "venue": "foundations of software engineering", "year": 2009, "id": "5b9c4eba-6bc1-4f98-ac32-77a6164f51a9"}
{"abstract": "Boolean equation systems (BESs) allow to represent various problems encountered in the area of propositional logic programming and verification of concurrent systems. Several sequential algorithms for global and local BES resolution have been proposed so far, mainly in the field of verification; however, these algorithms do not scale up satisfactorily as the size of BESs increases. In this paper, we propose a distributed algorithm, called DSOLVE, which performs the local resolution of a BES using a set of machines connected by a network. Our experiments for solving large BESs using clusters of PCs show linear speedups and a scalable behaviour of DSOLVE w.r.t. its sequential counterpart.", "authors": ["Christophe Joubert", "Radu Mateescu"], "n_citation": 17, "references": ["0772e128-db0e-4126-91b3-19d4c9f25dcb", "4bbd3304-71e9-43cd-9fc5-1a611dfdc86e", "5f36f994-d2e1-45d2-b25e-f415bd66b64b", "63d6c293-821c-4509-85b0-19fd0f17c1a8", "8d883e04-3ca4-412e-944d-d84117598578", "acf8970e-51a8-4729-a2a3-054ad1669412", "f5c17edd-1952-43dd-b87c-8aad2f2acebf"], "title": "Distributed local resolution of Boolean equation systems", "venue": "parallel, distributed and network-based processing", "year": 2005, "id": "03890f9a-98d9-40d8-8838-9b4283b7df34"}
{"abstract": "Gaze-contingent displays (GCDs) attempt to balance the amount of information displayed against the visual information processing capacity of the observer through real-time eye movement sensing. Based on the assumed knowledge of the instantaneous location of the observer's focus of attention, GCD content can be \"tuned\" through several display processing means. Screen-based displays alter pixel level information generally matching the resolvability of the human retina in an effort to maximize bandwidth. Model-based displays alter geometric-level primitives along similar goals. Attentive user interfaces (AUIs) manage object- level entities (e.g., windows, applications) depending on the assumed attentive state of the observer. Such real-time display manipulation is generally achieved through non-contact, unobtrusive tracking of the observer's eye movements. This paper briefly reviews past and present display techniques as well as emerging graphics and eye tracking technology for GCD development.", "authors": ["Andrew T. Duchowski", "Nathan Cournia", "Hunter A. Murphy"], "n_citation": 38, "references": ["02ad2ee4-f101-4df0-b2cf-9e9a4cc29904", "18f60569-7925-4733-8aab-c43681754d68", "1b09f055-7a87-448d-ab20-1e2a7d8def1f", "2b034c51-bc32-43f7-803c-aa52e8d97141", "2fccf202-8d0e-408f-87e3-73d29a2cb42f", "647f35ee-79cb-42f1-974a-90d1c13ec86b", "7039b734-4a12-4f7e-af93-5ae1ee1fff2f", "78bb9d95-ff45-4aa1-8217-6d97f723fdbf", "8458569d-486b-4ae7-80b8-9ffdcaebaf1d", "9ecac0ea-d548-4b3d-b77d-bed14dc8c030", "aa35596d-5f0b-4307-b1b0-f55957b4e6cb", "c1a2db1a-6d25-4c28-93bd-47ab5d1c015d", "ee5d65ac-705b-4360-b609-f5b2387af53b", "f319dfed-9f43-45ce-a71c-7a54b014fdf5", "f4d25abf-526d-48ce-8ddf-b0d7429a43aa", "f52a126a-77f3-4ba2-aea9-703327954e81"], "title": "Gaze-contingent displays: a review.", "venue": "Cyberpsychology, Behavior, and Social Networking", "year": 2004, "id": "435b1e24-a029-4baf-ab97-63bd37d7c7b2"}
{"abstract": "Software development has not reached the maturity of other engineering disciplines; it is still challenging to produce software that works reliably, is easy to use and maintain, and arrives within budget and on time. In addition, relatively small software systems for highly specific applications are in increasing demand. This need requires a significantly different approach to software development from that used by their large, monolithic, general-purpose software counterparts such as Microsoft Word. The paper discusses the use of components for rapid distributed software development. It reports on the the experience of a large testbed called Educational Software Components of Tomorrow (www.escot.org), supported by the US National Science Foundation.", "authors": ["Alexander Repenning", "Andri Ioannidou", "Michele Payton", "Wenming Ye", "Jeremy Roschelle"], "n_citation": 83, "references": ["0b817c23-572b-480a-b859-e6bc843677c2", "5140aab9-3888-498c-a7af-5d9ad175c679", "61427750-8703-40ba-ae1d-638993d44fef", "7b23b5b0-2711-4fd6-8cb4-2958d4401549", "8ec7b584-8c6d-4fa3-8fe2-40e303180f55", "a979fd72-4898-4bf0-b9ad-06623c8a61f9", "c6045537-5b41-4de6-8ae4-6754bf8f92af", "e437d2db-033f-4d6a-9773-3323efe3a91c", "ec29b85f-9291-47a4-94e1-ac4bf6d95fcb", "fbe4b78a-f159-436c-a464-992f9e8fb4a6"], "title": "Using components for rapid distributed software development", "venue": "IEEE Software", "year": 2001, "id": "c92f88fb-ff1e-4427-9723-be5f53f7beec"}
{"abstract": "A fast and simple algorithm for approximately calculating the principal components PCs of a dataset and so reducing its dimensionality is described. This Simple Principal Components Analysis SPCA method was used for dimensionality reduction of two high-dimensional image databases, one of handwritten digits and one of handwritten Japanese characters. It was tested and compared with other techniques. On both databases SPCA shows a fast convergence rate compared with other methods and robustness to the reordering of the samples.", "authors": ["Matthew Partridge", "Rafael A. Calvo"], "n_citation": 168, "references": ["8b2c0aff-4589-4e0f-aae4-4f84a4413406"], "title": "Fast Dimensionality Reduction and Simple PCA", "venue": "intelligent data analysis", "year": 1998, "id": "ae4917d5-94ec-40c1-973c-b91dc77fac5b"}
{"abstract": "In their initial proposal for structural computing (SC), Nurnberg et al. [18] point to hypertext argumentation systems as an example of an application domain in which structure is of first-order importance. In this paper we summarise the goals and implementation of a knowledge based hypertext environment called ScholOnto (for Scholarly Ontologies), which aims to provide researchers with computational support in representing and analysing the structure of scholarly claims, argumentation and perspectives. A specialised web server will provide a medium for researchers to contest the significance of concepts and emergent structures. In so doing, participants construct an evolving structure that reflects a community's understandings of its field, and which can support computational services for scholars. Using structural analyses of scholarly argumentation, we consider the connections with structural computing, and propose a number of requirements for generic SC environments.", "authors": ["Simon Buckingham Shum", "John Domingue", "Enrico Motta"], "n_citation": 50, "references": ["0956decd-a933-40fb-a16d-a20d7f6d6249", "1688f58e-26e1-416c-97b8-06fbd2018e32", "1f45e4d9-2a66-406a-9305-7bf923c6d0dc", "4fb95778-2786-4cba-a91a-bb7ed8bd81a0", "508fdff9-2322-476f-bc73-7c35d5c9744b", "69842946-50bf-41d3-87ce-07c597d0211e", "71d26d59-68d9-4e84-8ee7-789d6eb299bf", "73dd187e-7e5c-404d-bde2-7e47123175ec", "8ef9c55a-1a61-4abb-a7c6-3a48c3002643", "e94be101-304f-4b98-90ed-7438a7ee9192", "f52e4da3-1231-468c-84d9-f0706e1c0d3d", "fc43547f-cc69-4577-ab17-a095ca76c3e7"], "title": "Scholarly Discourse as Computable Structure", "venue": "acm conference on hypertext", "year": 2000, "id": "19e3db0a-ac7d-45bd-8f41-2110b8bff0b7"}
{"abstract": "The paper shows a novel approach to model and control interactive objects for simulations with virtual human agents when real time interactivity is essential. A general conceptualization is made to model objects with behaviors that can provide: information about their functionality changes in appearance from parameterized deformations, and a complete plan for each possible interaction with a virtual human. Such behaviors are described with simple primitive commands, following the actual trend of many standard scene graph file formats that connects language with movements and events to create interactive animations. In our case, special attention is given to correctly interpret object behaviors in parallel; a situation that arrives when many human agents interact at the same time with one same object.", "authors": ["Marcelo Kallmann", "Daniel Thalmann"], "n_citation": 95, "references": ["1d42c285-4fd6-4f55-9189-7c04d67b87ff", "1d84757b-86a9-4015-9c8e-1e255521e3c8", "2cfb9edd-5a33-4d6a-99ca-d735900da359", "339a5972-6362-4d77-8c6b-3095ab05eb5d", "354f51aa-25da-46ba-9d72-4c2fd47db307", "5f04688c-f150-44d5-9314-333715bbbf0e", "74bb76be-611a-4311-9154-c311a0b9d3b1", "85d4fef1-ab57-4663-bc04-77556c2ea1f3", "b17abdd1-9e02-47b9-8298-e848538e6f48", "bf3bb8d7-062c-44d8-9d9d-c8af6de3fd4b", "c78283e7-75c4-49ae-a651-8c36369013b7", "c8d95f03-04a8-40f2-944c-11283d21aa98", "d48c5960-1a34-42fb-94a2-7a3e5e73a1cd"], "title": "A behavioral interface to simulate agent-object interactions in real time", "venue": "", "year": 1999, "id": "f57769c3-2660-4bba-abe8-8b984a2455ac"}
{"abstract": "On chip multiprocessors (CMPs) platforms, multiple co-scheduled applications can severely degrade performance and quality of service (QoS) when they contend for last-level cache (LLC) resources. Whether an application will impose destructive interference on co-scheduled applications is largely dependent on its own inherent cache access behavior characteristics. In this work, we first present case studies that show how inter-application interferences result in undesirable performance in both shared and private cache based LLC designs. We then propose a new online approach for application cache behavior identification on the basis of detailed simulation and analysis with SPEC CPU2006 benchmarks. We demonstrate that our approach can more concisely identify application cache behaviors. Moreover, the proposed approach can be implemented directly in hardware to dynamically identify the application cache behaviors at runtime. Finally, we show with two case studies that how the proposed approach can be adopted by both shared and private based cache sharing mechanisms, i.e. cache partitioning algorithms (CPAs) and cache spilling techniques, for more concise cache resource management.", "authors": ["Xiaomin Jia", "Jiang Jiang", "Tianlei Zhao", "Shubo Qi", "Minxuan Zhang"], "n_citation": 3, "references": ["1744ba28-4261-4e03-943b-0b1a7e8c9f0b", "191e60ce-306a-495c-b2e9-f9f1c2890646", "196da8ec-342a-40bf-a7db-69549bac3fff", "26354423-48fc-4d5a-88bb-4ad234361255", "26d36318-b26e-4bfd-adfb-a64c05a456b0", "2c8b3b23-a840-4c7e-bd1d-7fc3b3ff83e0", "437b6b56-a171-42dd-adce-5be215a3d2e1", "5394d502-c504-45ab-b691-307206182f20", "59becf27-d94a-4eb9-9f47-2a8986102eef", "6374a07c-68d4-4cb7-bd48-f0700e80ef74", "66b9881c-7a20-4388-b574-fe547c0b3162", "677753c6-fd30-47c8-99e8-c35edf6bb699", "a0cfbea4-310b-4762-a451-6b8b58391e4e", "c7967aba-9e39-4f16-bc70-90f11c61a3ea", "d8f965a8-74d7-4fcd-8567-1d3b37c25f6b", "fb0f0c77-73ba-4c23-aa81-53f02c81fff6"], "title": "Towards Online Application Cache Behaviors Identification in CMPs", "venue": "high performance computing and communications", "year": 2010, "id": "38595a4e-bb78-4404-8299-3548de064b8c"}
{"abstract": "It is shown that time-dependent periodic control can improve the fuel economy of vehicles in cruise. The time-dependent controls considered are relaxed steady-state (RSS) control, quasi-steady-state (QSS) control and quasi-relaxed steady-state (QRSS) control. Examples are given which show that QRSS control may give better performance than either RSS or QSS control. Properties of optimal cost functions, dependent on the minimum required average speed, are derived. The possibility or impossibility of improved performance through the use of QRSS, QSS and RSS control is investigated in terms of assumptions on the vehicle drag and fuel-consumption functions.", "authors": ["Elmer G. Gilbert"], "n_citation": 74, "references": [], "title": "Paper: Vehicle cruise: Improved fuel economy by periodic control", "venue": "Automatica", "year": 1976, "id": "c8cc1128-0a3a-4773-8726-8c9cb64c8cf9"}
{"abstract": "Existing approaches to modelling software systems all too often neglect the issue of component-mismatch identification and resolution. The traditional view of software development overemphasises synthesis at the expense of analysis; the latter frequently being seen as problem which only needs to be dealt with during the integration stage towards the end of a development project. The paper discusses two software modelling and analysis techniques, all tool supported, and emphasises the vital role analysis can play in identifying and resolving risks early on. The work also combines model based development (e.g. architectural modelling) with component based development (e.g. COTS and legacy system), and shows how their mismatch-detection capabilities complement one another to provide a more comprehensive coverage of development risks", "authors": ["Alexander Egyed", "Nenad Medvidovic", "Cristina Gacek"], "n_citation": 44, "references": ["0e6e9efc-a102-4874-9098-33c00272803d", "2aba7b23-019b-40bd-a739-eabe9486f4df", "2cde3231-5ee8-409b-99ff-9c54547be4e3", "42ea6086-62ba-4bfa-b59c-4e454c848818", "5003beef-7572-4fd9-b043-36c385adfc0b", "502076a0-ff08-41a8-b118-a8dadd357d4a", "53a359cf-aa54-4df9-b994-2813170d26ce", "61394dbb-e4c4-4b87-82e0-f0bf109afa4c", "67113b9d-5a7a-4f04-9b81-fe5d2ab00b58", "746294f6-0356-4684-9b4b-480ad83d0e9a", "7d0df85e-4746-40b7-bbf0-8b03f14dd285", "7f98ff3f-83eb-4aaa-87d2-92df44d5aa68", "8292d169-f379-4939-a8dd-67f6bfafa956", "85c1de96-97f5-478f-aa27-3c8581595c15", "9f1e1f2a-cbf6-49c0-acbc-075c072bdcc4", "b88df68a-c239-4b12-aa57-d0e65e00bdea", "ba1b9b3f-d911-4ad6-bd03-afa54de2ccee", "c2b3f6cf-e